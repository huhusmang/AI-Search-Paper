[
    {
        "@score": "1",
        "@id": "256536",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "81/8013-1",
                        "text": "Penghui Li 0001"
                    },
                    {
                        "@pid": "227/7173-1",
                        "text": "Mingxue Zhang 0001"
                    }
                ]
            },
            "title": "FuzzCache: Optimizing Web Application Fuzzing Through Software-Based Data Cache.",
            "venue": "CCS",
            "pages": "511-524",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/0001024",
            "doi": "10.1145/3658644.3670278",
            "ee": "https://doi.org/10.1145/3658644.3670278",
            "url": "https://dblp.org/rec/conf/ccs/0001024",
            "abstract": "Fuzzing has shown great promise in detecting vulnerabilities in server-side web applications. In this work, we introduce an innovative software-based data cache mechanism that complements and improves all existing web application fuzzing tools. Our key observation is that a great proportion of execution time (e.g., 50%) of web applications is spent on fetching data from two major sources: database and network; our in-depth investigation reveals that the same data is oftenrepeatedlyfetched across fuzzing trials. We thus design a new solution, FuzzCache, that stores the data into software-based caches, mitigating the need for repeated and expensive data fetches. FuzzCache exposes the cached data across fuzzing trials through inter-process shared memory segments. It also, as the first work, incorporates just-in-time compilation to avoid the performance overhead associated with interpreting PHP code in real time, thereby enhancing execution efficiency.",
            "pdf_url": "",
            "keywords": [
                "Web Application Fuzzing",
                "Data Caching",
                "Performance Optimization",
                "Vulnerability Detection",
                "Just-In-Time Compilation"
            ]
        },
        "url": "URL#256536",
        "sema_paperId": "b75b9df5f107a2d766b1fa700f3554a74f54dec8"
    },
    {
        "@score": "1",
        "@id": "256537",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "172/4550-1",
                        "text": "Zhiyuan Yu 0001"
                    },
                    {
                        "@pid": "54/2788-6",
                        "text": "Ao Li 0006"
                    },
                    {
                        "@pid": "392/3383",
                        "text": "Ruoyao Wen"
                    },
                    {
                        "@pid": "98/4032",
                        "text": "Yijia Chen"
                    },
                    {
                        "@pid": "181/2597-17",
                        "text": "Ning Zhang 0017"
                    }
                ]
            },
            "title": "PhySense: Defending Physically Realizable Attacks for Autonomous Systems via Consistency Reasoning.",
            "venue": "CCS",
            "pages": "3853-3867",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/00010WC024",
            "doi": "10.1145/3658644.3690236",
            "ee": "https://doi.org/10.1145/3658644.3690236",
            "url": "https://dblp.org/rec/conf/ccs/00010WC024",
            "abstract": "Autonomous vehicles (AVs) empowered by deep neural networks (DNNs) are bringing transformative changes to our society. However, they are generally susceptible to adversarial attacks, especially physically realizable perturbations that can mislead perception and cause catastrophic outcomes. While existing defenses have shown success, there remains a pressing need for improved robustness while maintaining efficiency to meet real-time system operations. To tackle these challenges, we introduce PhySense, a complementary solution that leverages multi-faceted reasoning for misclassification detection and correction. This defense is built on physical characteristics, including static and dynamic object attributes and their interrelations. To effectively integrate these diverse sources, we develop a system based on the conditional random field that models objects and relationships as a spatial-temporal graph for holistic reasoning on the perceived scene. To ensure the defense does not violate the timing requirement of the real-time cyber-physical control loop, we profile the run-time characteristics of the workloads to parallelize and pipeline the execution of the defense implementation. The efficacy of PhySense is experimentally validated through simulations of datasets and real-world driving tests. It also demonstrates resiliency against adaptive attacks, and the potential of applying underlying principles to other modalities beyond vision.",
            "keywords": [
                "Autonomous Vehicles",
                "Adversarial Attacks",
                "Misclassification Detection",
                "Consistency Reasoning",
                "Real-time Defense"
            ]
        },
        "url": "URL#256537",
        "sema_paperId": "063d56ff2174b58654d1030da6a8e6d970f97f64"
    },
    {
        "@score": "1",
        "@id": "256538",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "360/7470",
                        "text": "Shenao Wang 0001"
                    },
                    {
                        "@pid": "62/2555-8",
                        "text": "Feng Dong 0008"
                    },
                    {
                        "@pid": "245/1620",
                        "text": "Hangfeng Yang"
                    },
                    {
                        "@pid": "180/7981",
                        "text": "Jingheng Xu"
                    },
                    {
                        "@pid": "50/8499-1",
                        "text": "Haoyu Wang 0001"
                    }
                ]
            },
            "title": "CanCal: Towards Real-time and Lightweight Ransomware Detection and Response in Industrial Environments.",
            "venue": "CCS",
            "pages": "2326-2340",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/00010YX024",
            "doi": "10.1145/3658644.3690269",
            "ee": "https://doi.org/10.1145/3658644.3690269",
            "url": "https://dblp.org/rec/conf/ccs/00010YX024",
            "abstract": "Ransomware attacks have emerged as one of the most significant cybersecurity threats. Despite numerous proposed detection and defense methods, existing approaches face two fundamental limitations in large-scale industrial applications: intolerable system overheads and notorious alert fatigue. To address these challenges, we propose CanCal, a real-time and lightweight ransomware detection system. Specifically, CanCal selectively filters suspicious processes by the monitoring layers and then performs in-depth behavioral analysis to isolate ransomware activities from benign operations, minimizing alert fatigue while ensuring lightweight computational and storage overhead. The experimental results on a large-scale industrial environment~(1,761 ransomware, ~3 million events, continuous test over 5 months) indicate that CanCal is as effective as state-of-the-art techniques while enabling rapid inference within 30ms and real-time response within a maximum of 3 seconds. CanCal dramatically reduces average CPU utilization by 91.04% (from 6.7% to 0.6%) and peak CPU utilization by 76.69% (from 26.6% to 6.2%), while avoiding 76.50% (from 3,192 to 750) of the inspection efforts from security analysts. By the time of this writing, CanCal has been integrated into a commercial product and successfully deployed on 3.32 million endpoints for over a year. From March 2023 to April 2024, CanCal successfully detected and thwarted 61 ransomware attacks, demonstrating the effectiveness of CanCal in combating sophisticated ransomware threats in real-world scenarios.",
            "keywords": [
                "Ransomware Detection",
                "Industrial Cybersecurity",
                "Behavioral Analysis",
                "Alert Fatigue",
                "Real-time Response"
            ]
        },
        "url": "URL#256538",
        "sema_paperId": "bf09d524430aa72e641bbaa7004c11aea853ce17"
    },
    {
        "@score": "1",
        "@id": "256539",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "03/9437",
                        "text": "Neil Gong 0001"
                    },
                    {
                        "@pid": "181/2688-2",
                        "text": "Qi Li 0002"
                    },
                    {
                        "@pid": "67/6767-3",
                        "text": "Xiaoli Zhang 0003"
                    }
                ]
            },
            "title": "AACD &apos;24: 11th ACM Workshop on Adaptive and Autonomous Cyber Defense.",
            "venue": "CCS",
            "pages": "4884-4885",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/00010Z24",
            "doi": "10.1145/3658644.3691333",
            "ee": "https://doi.org/10.1145/3658644.3691333",
            "url": "https://dblp.org/rec/conf/ccs/00010Z24",
            "abstract": "The eleventh ACM Workshop on Adaptive and Autonomous Cyber Defense (AACD) will be held on October 14, 2024, in conjunction with the ACM Conference on Computer and Communications Security (CCS). AACD represents a cutting-edge approach to cybersecurity, where systems leverage AI and machine learning to dynamically detect, respond to, and mitigate evolving cyber threats in real time, minimizing the need for human intervention. A key aspect of this approach is adaptability-autonomous systems can assess attacker behavior, anticipate future threats, and adjust their defenses proactively. As cyberattacks grow more sophisticated, this transition from static defense strategies to dynamic, automated responses offers organizations a more resilient way to protect against emerging threats. The workshop will focus on discussing the challenges and opportunities inherent in this advanced cybersecurity paradigm.",
            "pdf_url": "",
            "keywords": [
                "Adaptive Cyber Defense",
                "Autonomous Systems",
                "Real-time Threat Mitigation",
                "AI-driven Security",
                "Dynamic Defense Strategies"
            ]
        },
        "url": "URL#256539",
        "sema_paperId": "36c851a883fb4212777b725e16b7d2195c48e694"
    },
    {
        "@score": "1",
        "@id": "256540",
        "info": {
            "authors": {
                "author": {
                    "@pid": "205/5551-1",
                    "text": "Zitao Chen 0001"
                }
            },
            "title": "Catch Me if You Can: Detecting Unauthorized Data Use in Training Deep Learning Models.",
            "venue": "CCS",
            "pages": "5098-5100",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/000124",
            "doi": "10.1145/3658644.3690858",
            "ee": "https://doi.org/10.1145/3658644.3690858",
            "url": "https://dblp.org/rec/conf/ccs/000124",
            "abstract": "The rise of deep learning (DL) has led to a surging demand for training data, which incentivizes the creators of DL models to trawl through the Internet for training materials. Meanwhile, users often have limited control over whether their data (e.g., facial images) are used to train DL models without their consent, which has engendered pressing concerns.",
            "pdf_url": "",
            "keywords": [
                "Unauthorized Data Use",
                "Data Consent",
                "Training Data Privacy",
                "Deep Learning Models",
                "Data Ownership"
            ]
        },
        "url": "URL#256540",
        "sema_paperId": "283f7c9f848f1bd039c522b1cd030db9ea30a489"
    },
    {
        "@score": "1",
        "@id": "256541",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "338/8910",
                        "text": "Davide Davoli 0001"
                    },
                    {
                        "@pid": "63/5617",
                        "text": "Martin Avanzini"
                    },
                    {
                        "@pid": "42/6705",
                        "text": "Tamara Rezk"
                    }
                ]
            },
            "title": "On Kernel&apos;s Safety in the Spectre Era (And KASLR is Formally Dead).",
            "venue": "CCS",
            "pages": "1091-1105",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/0001AR24",
            "doi": "10.1145/3658644.3670332",
            "ee": "https://doi.org/10.1145/3658644.3670332",
            "url": "https://dblp.org/rec/conf/ccs/0001AR24",
            "abstract": "The efficacy of address space layout randomization has been formally demonstrated in a shared-memory model by Abadi et al., contingent on specific assumptions about victim programs. However, modern operating systems, implementing layout randomization in the kernel, diverge from these assumptions and operate on a separate memory model with communication through system calls. In this work, we relax Abadi et al.'s language assumptions while demonstrating that layout randomization offers a comparable safety guarantee in a system with memory separation. However, in practice, speculative execution and side-channels are recognized threats to layout randomization. We show that kernel safety cannot be restored for attackers capable of using side-channels and speculative execution and introduce a new condition, that allows us to formally prove kernel safety in the Spectre era. Our research demonstrates that under this condition, the system remains safe without relying on layout randomization. We also demonstrate that our condition can be sensibly weakened, leading to enforcement mechanisms that can guarantee kernel safety for safe system calls in the Spectre era.",
            "pdf_url": "",
            "keywords": [
                "Kernel Safety",
                "Address Space Layout Randomization",
                "Speculative Execution",
                "Side-Channel Attacks",
                "Spectre Vulnerabilities"
            ]
        },
        "url": "URL#256541",
        "sema_paperId": "dae01ea3741b913649312f928c2646eac7b23903"
    },
    {
        "@score": "1",
        "@id": "256542",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "75/5483-1",
                        "text": "Yibin Yang 0001"
                    },
                    {
                        "@pid": "19/72",
                        "text": "David Heath"
                    },
                    {
                        "@pid": "95/1548",
                        "text": "Carmit Hazay"
                    },
                    {
                        "@pid": "65/6001",
                        "text": "Vladimir Kolesnikov"
                    },
                    {
                        "@pid": "64/4755",
                        "text": "Muthuramakrishnan Venkitasubramaniam"
                    }
                ]
            },
            "title": "Tight ZK CPU: Batched ZK Branching with Cost Proportional to Evaluated Instruction.",
            "venue": "CCS",
            "pages": "3095-3109",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/0001HHKV24",
            "doi": "10.1145/3658644.3690289",
            "ee": "https://doi.org/10.1145/3658644.3690289",
            "url": "https://dblp.org/rec/conf/ccs/0001HHKV24",
            "abstract": "We explore Zero-Knowledge Proofs (ZKPs) of statements expressed as programs written in high-level languages, e.g., C or assembly. At the core of executing such programs in ZK is the repeated evaluation of a CPU step, achieved by branching over the CPU's instruction set. This approach is general and covers traversal-execution of a program's control flow graph (CFG): here CPU instructions are straight-line program fragments (of various sizes) associated with the CFG nodes. This highlights the usefulness of ZK CPUs with alargenumber of instructions ofvarying sizes.",
            "pdf_url": "",
            "keywords": [
                "Zero-Knowledge Proofs",
                "High-Level Languages",
                "Control Flow Graph",
                "CPU Instruction Evaluation",
                "Batched ZK Branching"
            ]
        },
        "url": "URL#256542"
    },
    {
        "@score": "1",
        "@id": "256543",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "37/5914-1",
                        "text": "Wonhee Cho 0001"
                    },
                    {
                        "@pid": "67/2420",
                        "text": "Guillaume Hanrot"
                    },
                    {
                        "@pid": "79/5777",
                        "text": "Taeseong Kim"
                    },
                    {
                        "@pid": "185/0488",
                        "text": "Minje Park"
                    },
                    {
                        "@pid": "03/2822",
                        "text": "Damien Stehl\u00e9"
                    }
                ]
            },
            "title": "Fast and Accurate Homomorphic Softmax Evaluation.",
            "venue": "CCS",
            "pages": "4391-4404",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/0001HKPS24",
            "doi": "10.1145/3658644.3670369",
            "ee": "https://doi.org/10.1145/3658644.3670369",
            "url": "https://dblp.org/rec/conf/ccs/0001HKPS24",
            "abstract": "Homomorphic encryption is one of the main solutions for building secure and privacy-preserving solutions for Machine Learning as a Service, a major challenge in a society where AI becomes more and more pervasive. This motivates the development of homomorphic algorithms for the main building blocks of AI, typically for the components of the various types of neural networks architectures.",
            "pdf_url": "",
            "keywords": [
                "Homomorphic Encryption",
                "Privacy-Preserving Computation",
                "Softmax Evaluation",
                "Neural Network Components",
                "Machine Learning as a Service"
            ]
        },
        "url": "URL#256543"
    },
    {
        "@score": "1",
        "@id": "256544",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "225/0416",
                        "text": "Kaifeng Huang 0001"
                    },
                    {
                        "@pid": "277/9206",
                        "text": "Chenhao Lu"
                    },
                    {
                        "@pid": "343/9013",
                        "text": "Yiheng Cao"
                    },
                    {
                        "@pid": "61/9197",
                        "text": "Bihuan Chen 0001"
                    },
                    {
                        "@pid": "14/6370-1",
                        "text": "Xin Peng 0001"
                    }
                ]
            },
            "title": "VMud: Detecting Recurring Vulnerabilities with Multiple Fixing Functions via Function Selection and Semantic Equivalent Statement Matching.",
            "venue": "CCS",
            "pages": "3958-3972",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/0001LC0024",
            "doi": "10.1145/3658644.3690372",
            "ee": "https://doi.org/10.1145/3658644.3690372",
            "url": "https://dblp.org/rec/conf/ccs/0001LC0024",
            "abstract": "The widespread use of open-source software (OSS) has led to extensive code reuse, making vulnerabilities in OSS significantly pervasive. The vulnerabilities due to code reuse in OSS are commonly known as vulnerable code clones (VCCs) or recurring vulnerabilities. Existing approaches primarily employ clone-based techniques to detect recurring vulnerabilities by matching vulnerable functions in software projects. These techniques do not incorporate specially designed mechanisms for vulnerabilities with multiple fixing functions (VM). Typically, they generate a signature for each fixing function and report VM using a matching-one-in-all approach. However, the variation in vulnerability context across diverse fixing functions results in varying accuracy levels in detecting VM, potentially limiting the effectiveness of existing methods.",
            "pdf_url": "",
            "keywords": [
                "Open-Source Software Vulnerabilities",
                "Vulnerable Code Clones",
                "Recurring Vulnerabilities",
                "Function Selection",
                "Semantic Equivalent Statement Matching"
            ]
        },
        "url": "URL#256544",
        "sema_paperId": "6b1fb57ff097371542fafecf7aecf38adb3bfc82"
    },
    {
        "@score": "1",
        "@id": "256545",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "214/2394-1",
                        "text": "Hanwen Feng 0001"
                    },
                    {
                        "@pid": "354/8621",
                        "text": "Tiancheng Mai"
                    },
                    {
                        "@pid": "17/2212-5",
                        "text": "Qiang Tang 0005"
                    }
                ]
            },
            "title": "Scalable and Adaptively Secure Any-Trust Distributed Key Generation and All-hands Checkpointing.",
            "venue": "CCS",
            "pages": "2636-2650",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/0001M024",
            "doi": "10.1145/3658644.3690253",
            "ee": "https://doi.org/10.1145/3658644.3690253",
            "url": "https://dblp.org/rec/conf/ccs/0001M024",
            "abstract": "The classical distributed key generation protocols (DKG) are resurging due to their widespread applications in blockchain. While efforts have been made to improve DKG communication, practical large-scale deployments are still yet to come due to various challenges, including the heavy overhead (particularly broadcast) in adversarial cases. In this paper, we propose a practical DKG for DLog-based cryptosystems, which achieves (quasi-)linear computation and communication per-node cost with the help of a common coin, even in the face of the maximal amount of Byzantine nodes. Moreover, our protocol is secure against adaptive adversaries, which can corrupt less than half of all nodes. The key to our improvements lies in delegating the most costly operations to anAny-Trustgroup together with a set of techniques for adaptive security. Moreover, we present a generic transformer that enables us to efficiently deploy a conventional distributed protocol like our DKG, even when the participants have differentweights.",
            "pdf_url": "",
            "keywords": [
                "Distributed Key Generation",
                "Blockchain Security",
                "Byzantine Fault Tolerance",
                "Adaptive Security",
                "Common Coin Protocol"
            ]
        },
        "url": "URL#256545"
    },
    {
        "@score": "1",
        "@id": "256546",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "133/7191-1",
                        "text": "Manish Shukla 0001"
                    },
                    {
                        "@pid": "291/4512",
                        "text": "Shubham Malaviya"
                    },
                    {
                        "@pid": "14/6843",
                        "text": "Sachin Lodha"
                    }
                ]
            },
            "title": "Poster: Context-Based Effective Password Detection in Plaintext.",
            "venue": "CCS",
            "pages": "5066-5068",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/0001ML24",
            "doi": "10.1145/3658644.3691380",
            "ee": "https://doi.org/10.1145/3658644.3691380",
            "url": "https://dblp.org/rec/conf/ccs/0001ML24",
            "abstract": "From an enterprise perspective, storage of passwords in plaintext on a computer hard disk is a serious concern. Such password storage practice helps a malicious agent to do privilege escalation, install a backdoor, disable critical monitoring tools, and allow them to laterally move within organization's network. Considering the exploitability of the plaintext password stored on a storage device, it is imperative for an organization to identify such files and safeguard them without causing disruption to a user's work routine. In this work, we present a context-based password discovery solution for plaintext that performs multi-step context discovery for reducing false positives and negatives. Moreover, we protect all the identified files using an on-the-fly user authentication layer, which helps in preventing automated or command-line-based access to sensitive content in case of a cyberattack.",
            "pdf_url": "",
            "keywords": [
                "Password Security",
                "Plaintext Storage",
                "Context-Based Detection",
                "False Positives",
                "User Authentication Layer"
            ]
        },
        "url": "URL#256546",
        "sema_paperId": "b7701bafe2d1b09554bc72993e60c5e7328996e3"
    },
    {
        "@score": "1",
        "@id": "256547",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "30/10661",
                        "text": "Ling Ren 0001"
                    },
                    {
                        "@pid": "180/5609",
                        "text": "Muhammad Haris Mughees"
                    },
                    {
                        "@pid": "392/3013",
                        "text": "I Sun"
                    }
                ]
            },
            "title": "Simple and Practical Amortized Sublinear Private Information Retrieval using Dummy Subsets.",
            "venue": "CCS",
            "pages": "1420-1433",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/0001MS24",
            "doi": "10.1145/3658644.3690266",
            "ee": "https://doi.org/10.1145/3658644.3690266",
            "url": "https://dblp.org/rec/conf/ccs/0001MS24",
            "abstract": "Recent works in amortized sublinear Private Information Retrieval (PIR) have demonstrated great potential. Despite the inspiring progress, existing schemes in this new paradigm are still faced with various challenges and bottlenecks, including large client storage, high communication, poor practical efficiency, need for non-colluding servers, or restricted client query sequences. We present simple and practical amortized sublinear stateful private information retrieval schemes without these drawbacks using new techniques in hint construction and usage. In particular, we introduce a dummy set to the client\u2019s request to eliminate any leakage or correctness failures. Our techniques can work with two non-colluding servers or a single server. The resulting PIR schemes achieve practical efficiency. The online response overhead is only twice that of simply fetching the desired entry without privacy. For a database with 2 28 entries of 32-byte, each query of our two-server scheme consumes 34 KB of communication and 2.7 milliseconds of computation, and each query of our single-server scheme consumes amortized 47 KB of communication and 4.5 milliseconds of computation. These results are one or more orders of magnitude better than prior works.",
            "keywords": [
                "Private Information Retrieval",
                "Amortized Sublinear PIR",
                "Dummy Subsets",
                "Client Query Efficiency",
                "Non-Colluding Servers"
            ]
        },
        "url": "URL#256547",
        "sema_paperId": "89d0b25e9895805e30229477610b71e6cbd95a0d"
    },
    {
        "@score": "1",
        "@id": "256548",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "175/8858-1",
                        "text": "Zihao Li 0001"
                    },
                    {
                        "@pid": "390/8831",
                        "text": "Xinghao Peng"
                    },
                    {
                        "@pid": "270/2519",
                        "text": "Zheyuan He"
                    },
                    {
                        "@pid": "53/1565",
                        "text": "Xiapu Luo"
                    },
                    {
                        "@pid": "19/1766-2",
                        "text": "Ting Chen 0002"
                    }
                ]
            },
            "title": "fAmulet: Finding Finalization Failure Bugs in Polygon zkRollup.",
            "venue": "CCS",
            "pages": "971-985",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/0001PHL024",
            "doi": "10.1145/3658644.3690243",
            "ee": "https://doi.org/10.1145/3658644.3690243",
            "url": "https://dblp.org/rec/conf/ccs/0001PHL024",
            "abstract": "Zero-knowledge layer 2 protocols emerge as a compelling approach to overcoming blockchain scalability issues by processing transactions through the transaction finalization process. During this process, transactions are efficiently processed off the main chain. Besides, both the transaction data and the zero-knowledge proofs of transaction executions are reserved on the main chain, ensuring the availability of transaction data as well as the correctness and verifiability of transaction executions. Hence, any bugs that cause the transaction finalization failure are crucial, as they impair the usability of these protocols and the scalability of blockchains. In this work, we conduct the first systematic study on finalization failure bugs in zero-knowledge layer 2 protocols, and define two kinds of such bugs. Besides, we design fAmulet, the first tool to detect finalization failure bugs in Polygon zkRollup, a prominent zero-knowledge layer 2 protocol, by leveraging fuzzing testing. To trigger finalization failure bugs effectively, we introduce a finalization behavior model to guide our transaction fuzzer to generate and mutate transactions for inducing diverse behaviors across each component (e.g., Sequencer) in the finalization process. Moreover, we define bug oracles according to the distinct bug definitions to accurately detect bugs. Through our evaluation, fAmulet can uncover twelve zero-day finalization failure bugs in Polygon zkRollup, and cover at least 20.8% more branches than baselines. Furthermore, through our preliminary study, fAmulet uncovers a zero-day finalization failure bug in Scroll zkRollup, highlighting the generality of fAmulet to be applied to other zero-knowledge layer 2 protocols. At the time of writing, all our uncovered bugs have been confirmed and fixed by Polygon zkRollup and Scroll zkRollup teams.",
            "keywords": [
                "Zero-Knowledge Protocols",
                "Layer 2 Solutions",
                "Transaction Finalization",
                "Finalization Failure Bugs",
                "Polygon zkRollup"
            ]
        },
        "url": "URL#256548",
        "sema_paperId": "804b79dcee8b90dc187cefe0545b47550e429437"
    },
    {
        "@score": "1",
        "@id": "256549",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "63/10955",
                        "text": "Pankaj Dayama 0001"
                    },
                    {
                        "@pid": "19/6766",
                        "text": "Vinayaka Pandit"
                    },
                    {
                        "@pid": "163/2345",
                        "text": "Sikhar Patranabis"
                    },
                    {
                        "@pid": "27/2328",
                        "text": "Abhishek Singh"
                    },
                    {
                        "@pid": "67/3470",
                        "text": "Nitin Singh"
                    }
                ]
            },
            "title": "Poster: A Secure Multiparty Computation Platform for Squeaky-Clean Data Rooms.",
            "venue": "CCS",
            "pages": "5069-5071",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/0001PPSS24",
            "doi": "10.1145/3658644.3691371",
            "ee": "https://doi.org/10.1145/3658644.3691371",
            "url": "https://dblp.org/rec/conf/ccs/0001PPSS24",
            "abstract": "Modern approaches for multiparty secure collaboration must strike the right balance between rich analytics and requisite data privacy guarantees, especially in the face of new regulations. While cryptographic technologies such as fully homomorphic encryption (FHE) and secure multiparty computation (MPC) provide strong, provable security guarantees as standalone tools, deploying them in practice throws up a myriad of challenges, including usability constraints and lack of precise specification of privacy guarantees. In this work, we propose a novel framework for real-world deployment of cryptographic privacy preserving techniques that achieves the twin goals of practical usability in real-world setting and provable privacy guarantees from users' perspective. To this end, we formalize the notion of asecure computation platform(SCP) for privacy preserving data collaboration, and introduce a model for precise specification of privacy guarantees for multiparty workflows. We then describe abstractions of a set of cryptoprimitives, that are usable by non-experts in cryptography. We present two demo workflows that empirically validate our claims, and serve as potential building blocks for the development of squeaky-clean data rooms with practical performance and privacy guarantees.",
            "pdf_url": "",
            "keywords": [
                "Secure Multiparty Computation",
                "Privacy Preserving Techniques",
                "Cryptographic Privacy",
                "Data Collaboration",
                "Usability in Cryptography"
            ]
        },
        "url": "URL#256549",
        "sema_paperId": "584232433d1fdac718d6b4d7a6f8dc9b8bfb9e65"
    },
    {
        "@score": "1",
        "@id": "256550",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "05/4011-1",
                        "text": "Daniel Escudero 0001"
                    },
                    {
                        "@pid": "40/11429",
                        "text": "Antigoni Polychroniadou"
                    },
                    {
                        "@pid": "66/7929",
                        "text": "Yifan Song"
                    },
                    {
                        "@pid": "251/1580",
                        "text": "Chenkai Weng"
                    }
                ]
            },
            "title": "Multi-Verifier Zero-Knowledge Proofs for Any Constant Fraction of Corrupted Verifiers.",
            "venue": "CCS",
            "pages": "4092-4106",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/0001PSW24",
            "doi": "10.1145/3658644.3670357",
            "ee": "https://doi.org/10.1145/3658644.3670357",
            "url": "https://dblp.org/rec/conf/ccs/0001PSW24",
            "abstract": "In this work we study the efficiency of Zero-Knowledge (ZK) arguments of knowledge, particularly exploring Multi-Verifier ZK (MVZK) protocols as a midway point between Non-Interactive ZK and Designated-Verifier ZK, offering versatile applications across various domains. We introduce a new MVZK protocol designed for the preprocessing model, allowing any constant fraction of verifiers to be corrupted, potentially colluding with the prover. Our contributions include the first MVZK over rings. Unlike recent prior works on fields in the dishonest majority case, our protocol demonstrates communication complexity independent of the number of verifiers, contrasting the linear complexity of previous approaches. This key advancement ensures improved scalability and efficiency. We provide an end-to-end implementation of our protocol. The benchmark shows that it achieves a throughput of 1.47 million gates per second for 64 verifiers with 50% corruption, and 0.88 million gates per second with 75% corruption.",
            "pdf_url": "",
            "keywords": [
                "Zero-Knowledge Proofs",
                "Multi-Verifier Zero-Knowledge",
                "Corrupted Verifiers",
                "Communication Complexity",
                "Scalability and Efficiency"
            ]
        },
        "url": "URL#256550",
        "sema_paperId": "9db6a0433bd942ea226c4716c98c35cae46f3da0"
    },
    {
        "@score": "1",
        "@id": "256551",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "44/5966-1",
                        "text": "Daniel Collins 0001"
                    },
                    {
                        "@pid": "277/3602",
                        "text": "Doreen Riepel"
                    },
                    {
                        "@pid": "389/6322",
                        "text": "Si An Oliver Tran"
                    }
                ]
            },
            "title": "On the Tight Security of the Double Ratchet.",
            "venue": "CCS",
            "pages": "4747-4761",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/0001RT24",
            "doi": "10.1145/3658644.3690360",
            "ee": "https://doi.org/10.1145/3658644.3690360",
            "url": "https://dblp.org/rec/conf/ccs/0001RT24",
            "abstract": "The Signal Protocol is a two-party secure messaging protocol used in applications such as Signal, WhatsApp, Google Messages and Facebook Messenger and is used by billions daily. It consists of two core components, one of which is the Double Ratchet protocol that has been the subject of a line of work that aims to understand and formalise exactly what security it provides. Existing models capture strong guarantees including resilience to state exposure in both forward security (protecting past secrets) and post-compromise security (restoring security), adaptive state corruptions, message injections and out-of-order message delivery. Due to this complexity, prior work has failed to provide security guarantees that do not degrade in the number of interactions, even in the single-session setting.",
            "pdf_url": "",
            "keywords": [
                "Double Ratchet Protocol",
                "Signal Protocol",
                "Secure Messaging",
                "State Exposure",
                "Forward and Post-Compromise Security"
            ]
        },
        "url": "URL#256551"
    },
    {
        "@score": "1",
        "@id": "256552",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "227/7262-1",
                        "text": "Xinlei He 0001"
                    },
                    {
                        "@pid": "148/9731",
                        "text": "Xinyue Shen"
                    },
                    {
                        "@pid": "191/1578",
                        "text": "Zeyuan Chen"
                    },
                    {
                        "@pid": "b/MichaelBackes1",
                        "text": "Michael Backes 0001"
                    },
                    {
                        "@pid": "06/6785-16",
                        "text": "Yang Zhang 0016"
                    }
                ]
            },
            "title": "MGTBench: Benchmarking Machine-Generated Text Detection.",
            "venue": "CCS",
            "pages": "2251-2265",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/0001SC0024",
            "doi": "10.1145/3658644.3670344",
            "ee": "https://doi.org/10.1145/3658644.3670344",
            "url": "https://dblp.org/rec/conf/ccs/0001SC0024",
            "abstract": "Nowadays, powerful large language models (LLMs) such as ChatGPT have demonstrated revolutionary power in a variety of tasks. Consequently, the detection of machine-generated texts (MGTs) is becoming increasingly crucial as LLMs become more advanced and prevalent. These models have the ability to generate human-like language, making it challenging to discern whether a text is authored by a human or a machine. This raises concerns regarding authenticity, accountability, and potential bias. However, existing methods for detecting MGTs are evaluated using different model architectures, datasets, and experimental settings, resulting in a lack of a comprehensive evaluation framework that encompasses various methodologies. Furthermore, it remains unclear how existing detection methods would perform against powerful LLMs. In this paper, we fill this gap by proposing the first benchmark framework for MGT detection against powerful LLMs, named MGTBench. Extensive evaluations on public datasets with curated texts generated by various powerful LLMs such as ChatGPT-turbo and Claude demonstrate the effectiveness of different detection methods. Our ablation study shows that a larger number of words in general leads to better performance and most detection methods can achieve similar performance with much fewer training samples. Moreover, we delve into a more challenging task: text attribution. Our findings indicate that the model-based detection methods still perform well in the text attribution task. To investigate the robustness of different detection methods, we consider three adversarial attacks, namely paraphrasing, random spacing, and adversarial perturbations. We discover that these attacks can significantly diminish detection effectiveness, underscoring the critical need for the development of more robust detection methods.",
            "keywords": [
                "Machine-Generated Text Detection",
                "Large Language Models",
                "Text Attribution",
                "Detection Robustness",
                "Adversarial Attacks"
            ]
        },
        "url": "URL#256552",
        "sema_paperId": "e7ba478aad9b9534a9f632b85ad87177f5587189"
    },
    {
        "@score": "1",
        "@id": "256553",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "34/10042",
                        "text": "Felix G\u00fcnther 0001"
                    },
                    {
                        "@pid": "67/675",
                        "text": "Douglas Stebila"
                    },
                    {
                        "@pid": "245/0250",
                        "text": "Shannon Veitch"
                    }
                ]
            },
            "title": "Obfuscated Key Exchange.",
            "venue": "CCS",
            "pages": "2385-2399",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/0001SV24",
            "doi": "10.1145/3658644.3690220",
            "ee": "https://doi.org/10.1145/3658644.3690220",
            "url": "https://dblp.org/rec/conf/ccs/0001SV24",
            "abstract": "Censorship circumvention tools enable clients to access endpoints in a network despite the presence of a censor. Censors use a variety of techniques to identify content they wish to block, including filtering traffic patterns that are characteristic of proxy or circumvention protocols and actively probing potential proxy servers. Circumvention practitioners have developedfully encrypted protocols(FEPs), intended to have traffic that appears indistinguishable from random. A FEP is typically composed of a key exchange protocol to establish shared secret keys, and then a secure channel protocol to encrypt application data; both must avoid revealing to observers that an obfuscated protocol is in use.",
            "pdf_url": "",
            "keywords": [
                "Censorship Circumvention",
                "Obfuscated Protocols",
                "Fully Encrypted Protocols",
                "Traffic Obfuscation",
                "Key Exchange Protocols"
            ]
        },
        "url": "URL#256553"
    },
    {
        "@score": "1",
        "@id": "256554",
        "info": {
            "authors": {
                "author": {
                    "@pid": "34/2615-2",
                    "text": "Weidong Zhu 0002"
                }
            },
            "title": "Leveraging Storage Semantics to Enhance Data Security and Privacy.",
            "venue": "CCS",
            "pages": "5116-5118",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/000224",
            "doi": "10.1145/3658644.3690864",
            "ee": "https://doi.org/10.1145/3658644.3690864",
            "url": "https://dblp.org/rec/conf/ccs/000224",
            "abstract": "Data within a system travels through an I/O path from its generation in an application to its final storage on a device. Ensuring data security and privacy is a significant design concern, but heavily modulated storage stacks complicate understanding the data, thus presenting challenges to maintaining these properties. For example, the firmware in a storage device cannot interpret the semantics of an I/O request from the host, making it challenging to employ a semantic-aware malware defense in the storage device. Additionally, the evolution of storage media can weaken data privacy protection guarantees due to varying physical characteristics. Preserving the guarantee of data security and privacy requires understanding storage semantics, which provides insights into the data content and the architectural components within the storage system.",
            "pdf_url": "",
            "keywords": [
                "Data Security",
                "Data Privacy",
                "Storage Semantics",
                "I/O Path Analysis",
                "Malware Defense"
            ]
        },
        "url": "URL#256554",
        "sema_paperId": "a87d74b402021e041581837e858b4d4a3bbe5691"
    },
    {
        "@score": "1",
        "@id": "256555",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "02/7206-2",
                        "text": "Jaehyung Kim 0002"
                    },
                    {
                        "@pid": "318/5126",
                        "text": "Jinyeong Seo"
                    },
                    {
                        "@pid": "145/5981",
                        "text": "Yongsoo Song"
                    }
                ]
            },
            "title": "Simpler and Faster BFV Bootstrapping for Arbitrary Plaintext Modulus from CKKS.",
            "venue": "CCS",
            "pages": "2535-2546",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/0002SS24",
            "doi": "10.1145/3658644.3670302",
            "ee": "https://doi.org/10.1145/3658644.3670302",
            "url": "https://dblp.org/rec/conf/ccs/0002SS24",
            "abstract": "Bootstrapping is currently the only known method for constructing fully homomorphic encryptions. In the BFV scheme specifically, bootstrapping aims to reduce the error of a ciphertext while preserving the encrypted plaintext. The existing BFV bootstrapping methods follow the same pipeline, relying on the evaluation of a digit extraction polynomial to annihilate the error located in the least significant digits. However, due to its strong dependence on performance, bootstrapping could only utilize a limited form of plaintext modulus, such as a power of a small prime number.",
            "pdf_url": "",
            "keywords": [
                "Fully Homomorphic Encryption",
                "BFV Scheme",
                "Bootstrapping",
                "Plaintext Modulus",
                "Error Reduction"
            ]
        },
        "url": "URL#256555"
    },
    {
        "@score": "1",
        "@id": "256556",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "260/4200-2",
                        "text": "Bo Hui 0002"
                    },
                    {
                        "@pid": "238/9094",
                        "text": "Haolin Yuan"
                    },
                    {
                        "@pid": "03/9437",
                        "text": "Neil Gong 0001"
                    },
                    {
                        "@pid": "01/99",
                        "text": "Philippe Burlina"
                    },
                    {
                        "@pid": "28/8733",
                        "text": "Yinzhi Cao"
                    }
                ]
            },
            "title": "PLeak: Prompt Leaking Attacks against Large Language Model Applications.",
            "venue": "CCS",
            "pages": "3600-3614",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/0002Y0BC24",
            "doi": "10.1145/3658644.3670370",
            "ee": "https://doi.org/10.1145/3658644.3670370",
            "url": "https://dblp.org/rec/conf/ccs/0002Y0BC24",
            "abstract": "Large Language Models (LLMs) enable a new ecosystem with many downstream applications, called LLM applications, with different natural language processing tasks. The functionality and performance of an LLM application highly depend on its system prompt, which instructs the backend LLM on what task to perform. Therefore, an LLM application developer often keeps a system prompt confidential to protect its intellectual property. As a result, a natural attack, called prompt leaking, is to steal the system prompt from an LLM application, which compromises the developer's intellectual property. Existing prompt leaking attacks primarily rely on manually crafted queries, and thus achieve limited effectiveness. In this paper, we design a novel, closed-box prompt leaking attack framework, called PLeak, to optimize an adversarial query such that when the attacker sends it to a target LLM application, its response reveals its own system prompt. We formulate finding such an adversarial query as an optimization problem and solve it with a gradient-based method approximately. Our key idea is to break down the optimization goal by optimizing adversary queries for system prompts incrementally, i.e., starting from the first few tokens of each system prompt step by step until the entire length of the system prompt. We evaluate PLeak in both offline settings and for real-world LLM applications, e.g., those on Poe, a popular platform hosting such applications. Our results show that PLeak can effectively leak system prompts and significantly outperforms not only baselines that manually curate queries but also baselines with optimized queries that are modified and adapted from existing jailbreaking attacks. We responsibly reported the issues to Poe and are still waiting for their response. Our implementation is available at this repository: https://github.com/BHui97/PLeak.",
            "keywords": [
                "Large Language Model Applications",
                "Prompt Leaking",
                "Intellectual Property Theft",
                "Adversarial Query Optimization",
                "System Prompt Extraction"
            ]
        },
        "url": "URL#256556",
        "sema_paperId": "59665f0126b3442edcf93ae58285b610b5fe9991"
    },
    {
        "@score": "1",
        "@id": "256557",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "30/10768-3",
                        "text": "Cong Wu 0003"
                    },
                    {
                        "@pid": "27/4364-3",
                        "text": "Jing Chen 0003"
                    },
                    {
                        "@pid": "11/7704-1",
                        "text": "Ziming Zhao 0001"
                    },
                    {
                        "@pid": "59/1028-8",
                        "text": "Kun He 0008"
                    },
                    {
                        "@pid": "87/10142",
                        "text": "Guowen Xu"
                    },
                    {
                        "@pid": "77/8060-1",
                        "text": "Yueming Wu 0001"
                    },
                    {
                        "@pid": "46/1165",
                        "text": "Haijun Wang"
                    },
                    {
                        "@pid": "39/5544-1",
                        "text": "Hongwei Li 0001"
                    },
                    {
                        "@pid": "51/3710-3",
                        "text": "Yang Liu 0003"
                    },
                    {
                        "@pid": "50/2192-1",
                        "text": "Yang Xiang 0001"
                    }
                ]
            },
            "title": "TokenScout: Early Detection of Ethereum Scam Tokens via Temporal Graph Learning.",
            "venue": "CCS",
            "pages": "956-970",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/0003C00X0WL0024",
            "doi": "10.1145/3658644.3690234",
            "ee": "https://doi.org/10.1145/3658644.3690234",
            "url": "https://dblp.org/rec/conf/ccs/0003C00X0WL0024",
            "abstract": "Decentralized finance has experienced phenomenal growth, revolutionizing the landscape of financial transactions and asset management via blockchain. Yet, this swift growth brings with it substantial challenges, notably the surge in scam tokens, imposing significant security threats on cryptocurrency investments and trading. Existing detection methods of scam token, primarily relying on analyzing contract codes or transaction patterns, struggle to catch increasingly sophisticated tactics employed by scammers. For example, contract-based analysis are unable to identify scams lacking overt malicious code, e.g., most rugpulls, while transaction-based methods generally lack the foresight to early-detect potential risks.",
            "pdf_url": "",
            "keywords": [
                "Decentralized Finance",
                "Ethereum",
                "Scam Tokens",
                "Temporal Graph Learning",
                "Rugpull Detection"
            ]
        },
        "url": "URL#256557",
        "sema_paperId": "b28ba982c3736257136c27387eb1367e78b188d7"
    },
    {
        "@score": "1",
        "@id": "256558",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "15/1300-6",
                        "text": "Ying Gao 0006"
                    },
                    {
                        "@pid": "386/7838",
                        "text": "Yuanchao Luo"
                    },
                    {
                        "@pid": "340/3710",
                        "text": "Longxin Wang"
                    },
                    {
                        "@pid": "31/5736",
                        "text": "Xiang Liu"
                    },
                    {
                        "@pid": "82/3116",
                        "text": "Lin Qi"
                    },
                    {
                        "@pid": "35/7092",
                        "text": "Wei Wang"
                    },
                    {
                        "@pid": "219/1495",
                        "text": "Mengmeng Zhou"
                    }
                ]
            },
            "title": "Efficient Scalable Multi-Party Private Set Intersection(-Variants) from Bicentric Zero-Sharing.",
            "venue": "CCS",
            "pages": "4137-4151",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/0006LWLQWZ24",
            "doi": "10.1145/3658644.3690245",
            "ee": "https://doi.org/10.1145/3658644.3690245",
            "url": "https://dblp.org/rec/conf/ccs/0006LWLQWZ24",
            "abstract": "Multi-party private set intersection (MPSI) allows n (n\\geq3) participants, each holding a dataset of sizem, to compute the intersection of their sets without revealing any additional information. We extract a primitive calledbicentric zero-sharing,which can reduce MPSI to two-party PSI between two central participants named Pivot and Leader. We introduce an efficient instantiation of bicentric zero-sharing, which involves a round of sharing and reconstruction of an oblivious key-value store (OKVS) object. We then combine this construction with two-party PSI to propose a new efficient scalable MPSI protocol. We also propose protocols for computing MPSI variants based on bicentric zero-sharing, such as multi-party private set intersection cardinality (MPSI-CA) and multi-party threshold private set intersection (MTPSI).",
            "pdf_url": "",
            "keywords": [
                "Multi-Party Private Set Intersection",
                "Bicentric Zero-Sharing",
                "Oblivious Key-Value Store",
                "MPSI Variants",
                "Private Set Intersection Cardinality"
            ]
        },
        "url": "URL#256558",
        "sema_paperId": "34d9a999099da315e48873c0cd8bf1d55f523aec"
    },
    {
        "@score": "1",
        "@id": "256559",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "92/748-7",
                        "text": "Wei Dong 0007"
                    },
                    {
                        "@pid": "303/0338",
                        "text": "Qiyao Luo"
                    },
                    {
                        "@pid": "141/9910",
                        "text": "Giulia Fanti"
                    },
                    {
                        "@pid": "80/4580",
                        "text": "Elaine Shi"
                    },
                    {
                        "@pid": "43/1219-1",
                        "text": "Ke Yi 0001"
                    }
                ]
            },
            "title": "Almost Instance-optimal Clipping for Summation Problems in the Shuffle Model of Differential Privacy.",
            "venue": "CCS",
            "pages": "1939-1953",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/0007LFS024",
            "doi": "10.1145/3658644.3690225",
            "ee": "https://doi.org/10.1145/3658644.3690225",
            "url": "https://dblp.org/rec/conf/ccs/0007LFS024",
            "abstract": "Differentially private mechanisms achieving worst-case optimal error bounds (e.g., the classical Laplace mechanism) are well-studied in the literature. However, when typical data are far from the worst case, \\emph{instance-specific} error bounds -- which depend on the largest value in the dataset -- are more meaningful. For example, consider the sum estimation problem, where each user has an integer $x_i$ from the domain $\\{0,1,\\dots,U\\}$ and we wish to estimate $\\sum_i x_i$. This has a worst-case optimal error of $O(U/\\varepsilon)$, while recent work has shown that the clipping mechanism can achieve an instance-optimal error of $O(\\max_i x_i \\cdot \\log\\log U /\\varepsilon)$. Under the shuffle model, known instance-optimal protocols are less communication-efficient. The clipping mechanism also works in the shuffle model, but requires two rounds: Round one finds the clipping threshold, and round two does the clipping and computes the noisy sum of the clipped data. In this paper, we show how these two seemingly sequential steps can be done simultaneously in one round using just $1+o(1)$ messages per user, while maintaining the instance-optimal error bound. We also extend our technique to the high-dimensional sum estimation problem and sparse vector aggregation (a.k.a. frequency estimation under user-level differential privacy).",
            "keywords": [
                "Differential Privacy",
                "Shuffle Model",
                "Instance-specific Error Bounds",
                "Clipping Mechanism",
                "Sum Estimation"
            ]
        },
        "url": "URL#256559",
        "sema_paperId": "406ae39c56a40c3e53b385b503e2e54d96b0dd53"
    },
    {
        "@score": "1",
        "@id": "256560",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "335/6237",
                        "text": "Zhou Zhang 0016"
                    },
                    {
                        "@pid": "179/7914",
                        "text": "Song Bian 0001"
                    },
                    {
                        "@pid": "223/0159",
                        "text": "Zian Zhao"
                    },
                    {
                        "@pid": "358/0128",
                        "text": "Ran Mao"
                    },
                    {
                        "@pid": "162/1287",
                        "text": "Haoyi Zhou"
                    },
                    {
                        "@pid": "183/1847",
                        "text": "Jiafeng Hua"
                    },
                    {
                        "@pid": "34/756",
                        "text": "Yier Jin"
                    },
                    {
                        "@pid": "121/1665",
                        "text": "Zhenyu Guan"
                    }
                ]
            },
            "title": "ArcEDB: An Arbitrary-Precision Encrypted Database via (Amortized) Modular Homomorphic Encryption.",
            "venue": "CCS",
            "pages": "4613-4627",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/00160ZMZHJG24",
            "doi": "10.1145/3658644.3670384",
            "ee": "https://doi.org/10.1145/3658644.3670384",
            "url": "https://dblp.org/rec/conf/ccs/00160ZMZHJG24",
            "abstract": "Fully homomorphic encryption (FHE) based database outsourcing is drawing growing research interests. At its current state, there exist two primary obstacles against FHE-based encrypted databases (EDBs): i) low data precision, and ii) high computational latency. To tackle the precision-performance dilemma, we introduce ArcEDB, a novel FHE-based SQL evaluation infrastructure that simultaneously achieves high data precision and fast query evaluation. Based on a set of new plaintext encoding schemes, we are able to execute arbitrary-precision ciphertext-to-ciphertext homomorphic comparison orders of magnitude faster than existing methods. Meanwhile, we propose efficient conversion algorithms between the encoding schemes to support highly composite SQL statements, including advanced filter-aggregation and multi-column synchronized sorting. We perform comprehensive experiments to study the performance characteristics of ArcEDB. In particular, we show that ArcEDB can be up to 57\u00d7 faster in homomorphic filtering and up to 20\u00d7 faster over end-to-end SQL queries when compared to the state-of-the-art FHE-based EDB solutions. Using ArcEDB, a SQL query over a 10K-row time-series EDB with 64-bit timestamps only runs for under one minute.",
            "pdf_url": "",
            "keywords": [
                "Homomorphic Encryption",
                "Encrypted Database",
                "Data Precision",
                "Computational Latency",
                "SQL Query Evaluation"
            ]
        },
        "url": "URL#256560"
    },
    {
        "@score": "1",
        "@id": "256561",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "47/722-25",
                        "text": "Yue Zhang 0025"
                    },
                    {
                        "@pid": "79/7563",
                        "text": "Zhen Ling"
                    },
                    {
                        "@pid": "44/6222",
                        "text": "Michael Cash"
                    },
                    {
                        "@pid": "155/8291",
                        "text": "Qiguang Zhang"
                    },
                    {
                        "@pid": "326/1449",
                        "text": "Christopher Morales-Gonzalez"
                    },
                    {
                        "@pid": "323/5547",
                        "text": "Qun Zhou Sun"
                    },
                    {
                        "@pid": "49/2189",
                        "text": "Xinwen Fu"
                    }
                ]
            },
            "title": "Collapse Like A House of Cards: Hacking Building Automation System Through Fuzzing.",
            "venue": "CCS",
            "pages": "1761-1775",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/0025LCZMSF24",
            "doi": "10.1145/3658644.3690216",
            "ee": "https://doi.org/10.1145/3658644.3690216",
            "url": "https://dblp.org/rec/conf/ccs/0025LCZMSF24",
            "abstract": "Building Automation Systems (BAS) play a pivotal role in modern smart buildings, integrating sensors, controllers, and software to manage crucial functions such as HVAC, lighting, and more. The global smart building market is on the rise, underscoring the importance of securing BAS networks. This paper introduces the Building Automation System Evaluator (BASE), a specialized fuzzer designed to assess the security of BAS networks. BAS networks typically involve a BAS client communicating with a BAS server through BAS protocols (e.g., BACnet, KNX), each presenting unique challenges in BAS network fuzzing. These challenges encompass complex packet structures and sequencing in BAS protocols, closed-source clients with indeterminable code coverage, and unobservable server status with limited throughput. BASE automatically identifies protocol structures, dynamically instruments clients for code coverage analysis, and monitors responses for new coverage areas. Collected timestamps are used to estimate the input scan intervals of servers, optimizing throughput. We evaluated BASE on various BAS servers and clients, uncovering 13 new vulnerabilities. Furthermore, we present three attack case studies, highlighting the real-world security implications of these vulnerabilities in BAS systems, such as delayed fire detection, loss of climate control, and security breaches. We reported our findings to the respective vendors, who acknowledged the implications, and some have subsequently patched their systems based on our reports.",
            "pdf_url": "",
            "keywords": [
                "Building Automation Systems",
                "Fuzzing",
                "Security Vulnerabilities",
                "BAS Protocols",
                "BASE Tool"
            ]
        },
        "url": "URL#256561",
        "sema_paperId": "47721ae40086e7d373219c37ab33e759dfe598d3"
    },
    {
        "@score": "1",
        "@id": "256562",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "47/722-25",
                        "text": "Yue Zhang 0025"
                    },
                    {
                        "@pid": "283/5636",
                        "text": "Melih Sirlanci"
                    },
                    {
                        "@pid": "127/9829",
                        "text": "Ruoyu Wang 0001"
                    },
                    {
                        "@pid": "49/4102-1",
                        "text": "Zhiqiang Lin 0001"
                    }
                ]
            },
            "title": "When Compiler Optimizations Meet Symbolic Execution: An Empirical Study.",
            "venue": "CCS",
            "pages": "4212-4225",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/0025SWL24",
            "doi": "10.1145/3658644.3670372",
            "ee": "https://doi.org/10.1145/3658644.3670372",
            "url": "https://dblp.org/rec/conf/ccs/0025SWL24",
            "abstract": "Compileroptimizationsintendtotransforma programinto asemantic-equivalent one with improved performance, but it is unclear how these optimizations may impact the performance of dynamic symbolic execution (DSE) on binary code. To systematically understand the impact of compiler optimizations on two popular DSE techniques (i.e., symbolic exploration and symbolic tracing), this paper presents an empirical study that quantifies 209 GCC compilation flags and 73 Clang compilation flags to reveal both positive and negative optimizations to DSE. Our data set contains 992 unique test cases, which are produced from 3 , 449 source files in the GCC test suite. After analyzing 2 , 978 , 976 binary programs that we compiled with two compilers and various compilation flags, we found that although some optimizations make DSE faster, most optimizations will actually slow down DSE. Our analysis further reveals root causes behind these impacts. The most positive impacts that optimizations have on DSE come from the reduction of the number of instructions and program paths, whereas negative impacts are caused by a series of unexpected behaviors, including increased numbers of instructions or program paths, library function inlining preventing DSE engines from using function summaries, and arithmetic optimizations leading to more sophisticated constraints. Being the first in-depth analysis on why compiler flags influence the performance of DSE, this project sheds light on program transformations that can be applied before performing DSE tasks for better performance.",
            "keywords": [
                "Compiler Optimizations",
                "Dynamic Symbolic Execution",
                "Empirical Study",
                "Binary Code Performance",
                "GCC and Clang Compilation Flags"
            ]
        },
        "url": "URL#256562",
        "sema_paperId": "5f89ac70af21d495a78e1e32e71854b0ce7d7ce6"
    },
    {
        "@score": "1",
        "@id": "256563",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "50/3402-26",
                        "text": "Bo Li 0026"
                    },
                    {
                        "@pid": "10/3878-1",
                        "text": "Wenyuan Xu 0001"
                    },
                    {
                        "@pid": "202/6440",
                        "text": "Jieshan Chen"
                    },
                    {
                        "@pid": "06/6785-16",
                        "text": "Yang Zhang 0016"
                    },
                    {
                        "@pid": "166/1912",
                        "text": "Minhui Xue 0001"
                    },
                    {
                        "@pid": "63/1591-12",
                        "text": "Shuo Wang 0012"
                    },
                    {
                        "@pid": "86/9673",
                        "text": "Guangdong Bai"
                    },
                    {
                        "@pid": "21/8884",
                        "text": "Xingliang Yuan"
                    }
                ]
            },
            "title": "LAMPS &apos;24: ACM CCS Workshop on Large AI Systems and Models with Privacy and Safety Analysis.",
            "venue": "CCS",
            "pages": "4888-4889",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/00260CZ00BY24",
            "doi": "10.1145/3658644.3691335",
            "ee": "https://doi.org/10.1145/3658644.3691335",
            "url": "https://dblp.org/rec/conf/ccs/00260CZ00BY24",
            "abstract": "With large AI systems and models (LAMs) playing an ever-growing role across diverse applications, their impact on the privacy and cybersecurity of critical infrastructure has become a pressing concern. The LAMPS workshop is dedicated to tackling these emerging challenges, promoting dialogue on cutting-edge developments and ethical issues in safeguarding LAMs within critical infrastructure contexts. Bringing together leading experts from around the world, this workshop will delve into the complex privacy and cybersecurity risks posed by LAMs in critical sectors. Attendees will explore innovative solutions, exchange best practices, and contribute to shaping the future research agenda, emphasizing the crucial balance between advancing AI technologies and securing critical digital and physical infrastructures.",
            "pdf_url": "",
            "keywords": [
                "Large AI Systems",
                "Privacy Analysis",
                "Cybersecurity Risks",
                "Critical Infrastructure",
                "Ethical Issues in AI"
            ]
        },
        "url": "URL#256563",
        "sema_paperId": "97227b4436d72f968267b26e615706e7c8322b12"
    },
    {
        "@score": "1",
        "@id": "256564",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "89/5615-28",
                        "text": "Bo Chen 0028"
                    },
                    {
                        "@pid": "392/3296",
                        "text": "Caleb Rother"
                    },
                    {
                        "@pid": "332/2962",
                        "text": "Josh Dafoe"
                    }
                ]
            },
            "title": "Poster: A Full-stack Secure Deletion Framework for Modern Computing Devices.",
            "venue": "CCS",
            "pages": "4967-4969",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/0028RD24",
            "doi": "10.1145/3658644.3691369",
            "ee": "https://doi.org/10.1145/3658644.3691369",
            "url": "https://dblp.org/rec/conf/ccs/0028RD24",
            "abstract": "Secure data deletion is of critical importance for complying with retention regulations and safeguarding user privacy. In this work, we have proposed the first full-stack secure deletion design addressing both external storage and internal memory for secure deletion. Preliminary experimental results are provided to justify feasibility of the proposed design.",
            "pdf_url": "",
            "keywords": [
                "Secure Data Deletion",
                "Full-stack Framework",
                "External Storage",
                "Internal Memory",
                "User Privacy"
            ]
        },
        "url": "URL#256564",
        "sema_paperId": "2b3d4929c7cd080f8f5a5b3753bc6e29e7be95ba"
    },
    {
        "@score": "1",
        "@id": "256565",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "316/4375",
                        "text": "Kasra Abbaszadeh"
                    },
                    {
                        "@pid": "283/4885",
                        "text": "Christodoulos Pappas"
                    },
                    {
                        "@pid": "k/JonathanKatz",
                        "text": "Jonathan Katz"
                    },
                    {
                        "@pid": "18/9002",
                        "text": "Dimitrios Papadopoulos 0001"
                    }
                ]
            },
            "title": "Zero-Knowledge Proofs of Training for Deep Neural Networks.",
            "venue": "CCS",
            "pages": "4316-4330",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/AbbaszadehPK024",
            "doi": "10.1145/3658644.3670316",
            "ee": "https://doi.org/10.1145/3658644.3670316",
            "url": "https://dblp.org/rec/conf/ccs/AbbaszadehPK024",
            "abstract": "A zero-knowledge proof of training (zkPoT) enables a party to prove that they have correctly trained a committed model based on a committed dataset without revealing any additional information about the model or the dataset. An ideal zkPoT should offer provable security and privacy guarantees, succinct proof size and verifier runtime, and practical prover efficiency. In this work, we present Kaizen, a zkPoT targeted for deep neural networks (DNNs) that achieves all these goals at once. Our construction enables a prover to iteratively train their model via (mini-batch) gradient descent, where the number of iterations need not be fixed in advance; at the end of each iteration, the prover generates a commitment to the trained model parameters attached with a succinct zkPoT, attesting to the correctness of the executed iterations. The proof size and verifier time are independent of the number of iterations.",
            "pdf_url": "",
            "keywords": [
                "Zero-Knowledge Proofs",
                "Model Training Verification",
                "Deep Neural Networks",
                "Privacy Guarantees",
                "Proof Efficiency"
            ]
        },
        "url": "URL#256565"
    },
    {
        "@score": "1",
        "@id": "256566",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "386/7637",
                        "text": "David Adei"
                    },
                    {
                        "@pid": "265/8774",
                        "text": "Varun Madathil"
                    },
                    {
                        "@pid": "252/6374",
                        "text": "Sathvik Prasad"
                    },
                    {
                        "@pid": "117/3983",
                        "text": "Bradley Reaves"
                    },
                    {
                        "@pid": "72/7642",
                        "text": "Alessandra Scafuro"
                    }
                ]
            },
            "title": "J\u00e4ger: Automated Telephone Call Traceback.",
            "venue": "CCS",
            "pages": "2042-2056",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/AdeiMPRS24",
            "doi": "10.1145/3658644.3690290",
            "ee": "https://doi.org/10.1145/3658644.3690290",
            "url": "https://dblp.org/rec/conf/ccs/AdeiMPRS24",
            "abstract": "Unsolicited telephone calls that facilitate fraud or unlawful telemarketing continue to overwhelm network users and the regulators who prosecute them. The first step in prosecuting phone abuse is traceback --- identifying the call originator. This fundamental investigative task currently requires hours of manual effort per call. In this paper, we introduce J\u00e4ger, a distributed secure call traceback system. J\u00e4ger can trace a call in a few seconds, even with partial deployment, while cryptographically preserving the privacy of call parties, carrier trade secrets like peers and call volume, and limiting the threat of bulk analysis. We establish definitions and requirements of secure traceback, then develop a suite of protocols that meet these requirements using witness encryption, oblivious pseudorandom functions, and group signatures. We prove these protocols secure in the universal composibility framework. We then demonstrate that J\u00e4ger has low compute and bandwidth costs per call, and these costs scale linearly with call volume. J\u00e4ger provides an efficient, secure, privacy-preserving system to revolutionize telephone abuse investigation with minimal costs to operators.",
            "pdf_url": "",
            "keywords": [
                "Call Traceback",
                "Telephone Fraud",
                "Privacy Preservation",
                "Distributed Systems",
                "Unsolicited Calls"
            ]
        },
        "url": "URL#256566"
    },
    {
        "@score": "1",
        "@id": "256567",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "299/1497",
                        "text": "Michael Aerni"
                    },
                    {
                        "@pid": "84/6889",
                        "text": "Jie Zhang"
                    },
                    {
                        "@pid": "158/7224",
                        "text": "Florian Tram\u00e8r"
                    }
                ]
            },
            "title": "Evaluations of Machine Learning Privacy Defenses are Misleading.",
            "venue": "CCS",
            "pages": "1271-1284",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/AerniZT24",
            "doi": "10.1145/3658644.3690194",
            "ee": "https://doi.org/10.1145/3658644.3690194",
            "url": "https://dblp.org/rec/conf/ccs/AerniZT24",
            "abstract": "Empirical defenses for machine learning privacy forgo the provable guarantees of differential privacy in the hope of achieving higher utility while resisting realistic adversaries. We identify severe pitfalls in existing empirical privacy evaluations (based on membership inference attacks) that result in misleading conclusions. In particular, we show that prior evaluations fail to characterize the privacy leakage of the most vulnerable samples, use weak attacks, and avoid comparisons with practical differential privacy baselines. In 5 case studies of empirical privacy defenses, we find that prior evaluations underestimate privacy leakage by an order of magnitude. Under our stronger evaluation, none of the empirical defenses we study are competitive with a properly tuned, high-utility DP-SGD baseline (with vacuous provable guarantees).",
            "keywords": [
                "Machine Learning Privacy",
                "Empirical Privacy Defenses",
                "Membership Inference Attacks",
                "Differential Privacy",
                "Privacy Leakage"
            ]
        },
        "url": "URL#256567",
        "sema_paperId": "985634ecda76043ce74aa4cac436d2bf6ce5e32b"
    },
    {
        "@score": "1",
        "@id": "256568",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "67/340",
                        "text": "Amit Agarwal"
                    },
                    {
                        "@pid": "12/9528",
                        "text": "Elette Boyle"
                    },
                    {
                        "@pid": "77/5616",
                        "text": "Nishanth Chandran"
                    },
                    {
                        "@pid": "94/4510",
                        "text": "Niv Gilboa"
                    },
                    {
                        "@pid": "66/11477-1",
                        "text": "Divya Gupta 0001"
                    },
                    {
                        "@pid": "05/667",
                        "text": "Yuval Ishai"
                    },
                    {
                        "@pid": "218/7156",
                        "text": "Mahimna Kelkar"
                    },
                    {
                        "@pid": "238/0150-1",
                        "text": "Yiping Ma 0001"
                    }
                ]
            },
            "title": "Secure Sorting and Selection via Function Secret Sharing.",
            "venue": "CCS",
            "pages": "3023-3037",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/AgarwalBCG0IK024",
            "doi": "10.1145/3658644.3690359",
            "ee": "https://doi.org/10.1145/3658644.3690359",
            "url": "https://dblp.org/rec/conf/ccs/AgarwalBCG0IK024",
            "abstract": "We revisit the problem of concretely efficient secure computation of sorting and selection (e.g., maximum, median, or top-k) on secret-shared data, focusing on the case of security against a single semi-honest party. Previous solutions either have a high communication overhead or many rounds of interaction, even when allowing input-independent preprocessing.",
            "pdf_url": "",
            "keywords": [
                "Secure Computation",
                "Function Secret Sharing",
                "Sorting and Selection",
                "Semi-Honest Security",
                "Communication Efficiency"
            ]
        },
        "url": "URL#256568",
        "sema_paperId": "019bb3a1b49a332ed4693df0aa3a97f204753b38"
    },
    {
        "@score": "1",
        "@id": "256569",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "49/2855-6",
                        "text": "Shubham Agarwal 0006"
                    },
                    {
                        "@pid": "221/4157",
                        "text": "Aurore Fass"
                    },
                    {
                        "@pid": "136/8343",
                        "text": "Ben Stock"
                    }
                ]
            },
            "title": "Peeking through the window: Fingerprinting Browser Extensions through Page-Visible Execution Traces and Interactions.",
            "venue": "CCS",
            "pages": "2117-2131",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/AgarwalFS24",
            "doi": "10.1145/3658644.3670339",
            "ee": "https://doi.org/10.1145/3658644.3670339",
            "url": "https://dblp.org/rec/conf/ccs/AgarwalFS24",
            "abstract": "Browser extensions are third-party add-ons that provide myriads of features to their users while browsing on the Web. Extensions often interact with the websites a user visits and perform various operations such as DOM-based manipulation, script injections, and so on. However, this also enables nefarious websites to track their visitors by fingerprinting extensions. Researchers in the past have shown that extensions are susceptible to fingerprinting based on the resources they include, the styles they deploy, or the DOM-based modifications they perform. Fortunately, the current extension ecosystem contains safeguards against many such known issues through appropriate defense mechanisms. We present the first study to investigate the fingerprinting characteristics of extension-injected code in pages\u2019 JavaScript names-pace and through other observable side-effects like changed cookies. Doing so, we find that many extensions inject JavaScript that pol-lutes the applications\u2019 global namespace by registering variables. It also enables the attacker application to monitor the execution of the injected code by overwriting the JavaScript APIs and capturing execution traces through the stacktrace , the set of APIs invoked, etc. Further, extensions also store data on the client side and perform event-driven functionalities that aid in attribution. Through our tests, we find 2,747 Chrome and 572 Firefox extensions to be susceptible to fingerprinting. Unfortunately, none of the existing defense mechanisms prevent extensions from being fingerprinted through our proposed vectors. Therefore, we also suggest potential measures for developers and browser vendors to safeguard the extension ecosystem against such fingerprinting attempts.",
            "keywords": [
                "Browser Extensions",
                "Fingerprinting",
                "JavaScript Injection",
                "Execution Traces",
                "Client-Side Tracking"
            ]
        },
        "url": "URL#256569",
        "sema_paperId": "a57f8baf68390a5fcb139628a49df7277d907dc6"
    },
    {
        "@score": "1",
        "@id": "256570",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "292/3790",
                        "text": "Abdulrahman Alhaidari"
                    },
                    {
                        "@pid": "59/1592",
                        "text": "Balaji Palanisamy"
                    },
                    {
                        "@pid": "11/748",
                        "text": "Prashant Krishnamurthy"
                    }
                ]
            },
            "title": "Poster: FlashGuard: Real-time Disruption of Non-Price Flash Loan Attacks in DeFi.",
            "venue": "CCS",
            "pages": "5039-5041",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/AlhaidariPK24",
            "doi": "10.1145/3658644.3691385",
            "ee": "https://doi.org/10.1145/3658644.3691385",
            "url": "https://dblp.org/rec/conf/ccs/AlhaidariPK24",
            "abstract": "Flash loan attacks threaten decentralized finance (DeFi) protocols, which constitute a Total Value Locked (TVL) of more than 106 billion. These attacks exploit the atomicity property in blockchains to drain funds within a single block. Existing research overlooks the mitigation of non-price flash loan attacks, which mostly exploit zero-day vulnerabilities. These attacks are challenging to detect as they are highly time-sensitive and each instance of the attack is complex and has a unique pattern. To address this challenge, we present FlashGuard, a runtime detection and mitigation framework for non-price flash loan attacks. FlashGuard communicates directly with the miners and bypasses the public mempool, where attack transactions usually reside. We utilize the temporary time window where transactions are visible in the mempool but not yet confirmed. Once the attack is detected, FlashGuard dispatches a dusting counter-transaction for the victim contract to the miners directly within the same block to disrupt the attack's atomicity and change the smart contract state. This forces the malicious transaction to revert. FlashGuard ensures that the series of operations that are required for a non-price flash loan attack cannot be completed atomically, leading to a failure of the attack. Our evaluation using 20 historical attacks that exploited protocol vulnerabilities shows an outstanding detection rate for FlashGuard with minimal false positives, and effective attack disruption and indicates that FlashGuard could have rescued about $405.71 million in losses.",
            "pdf_url": "",
            "keywords": [
                "Decentralized Finance (DeFi)",
                "Flash Loan Attacks",
                "Vulnerability Mitigation",
                "Real-time Detection",
                "Atomicity Disruption"
            ]
        },
        "url": "URL#256570",
        "sema_paperId": "b41c7a9890a4aecbf62a7bf56ae9aa007787bd66"
    },
    {
        "@score": "1",
        "@id": "256571",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "322/1111",
                        "text": "Mir Masood Ali"
                    },
                    {
                        "@pid": "139/5540",
                        "text": "Peter Snyder"
                    },
                    {
                        "@pid": "20/4340",
                        "text": "Chris Kanich"
                    },
                    {
                        "@pid": "33/5454",
                        "text": "Hamed Haddadi"
                    }
                ]
            },
            "title": "Unbundle-Rewrite-Rebundle: Runtime Detection and Rewriting of Privacy-Harming Code in JavaScript Bundles.",
            "venue": "CCS",
            "pages": "2192-2206",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/AliSKH24",
            "doi": "10.1145/3658644.3690262",
            "ee": "https://doi.org/10.1145/3658644.3690262",
            "url": "https://dblp.org/rec/conf/ccs/AliSKH24",
            "abstract": "This work presents Unbundle-Rewrite-Rebundle (URR), a system for detecting privacy-harming portions of bundled JavaScript code and rewriting that code at runtime to remove the privacy-harming behavior without breaking the surrounding code or overall application. URR is a novel solution to the problem of JavaScript bundles, where websites pre-compile multiple code units into a single file, making it impossible for content filters and ad-blockers to differentiate between desired and unwanted resources. Where traditional content filtering tools rely on URLs, URR analyzes the code at the AST level, and replaces harmful AST sub-trees with privacy-and-functionality maintaining alternatives. We present an open-sourced implementation of URR as a Firefox extension and evaluate it against JavaScript bundles generated by the most popular bundling system (Webpack) deployed on the Tranco 10k. We evaluate URR by precision (1.00), recall (0.95), and speed (0.43s per script) when detecting and rewriting three representative privacy-harming libraries often included in JavaScript bundles, and find URR to be an effective approach to a large-and-growing blind spot unaddressed by current privacy tools.",
            "keywords": [
                "JavaScript Privacy",
                "Code Rewriting",
                "Runtime Detection",
                "Privacy-Harming Code",
                "JavaScript Bundles"
            ]
        },
        "url": "URL#256571",
        "sema_paperId": "149bc27c6039ee138770ae3553dac9e33ed1c7cf"
    },
    {
        "@score": "1",
        "@id": "256572",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "322/9516",
                        "text": "Rabiah Alnashwan"
                    },
                    {
                        "@pid": "48/450",
                        "text": "Yang Yang"
                    },
                    {
                        "@pid": "361/1683",
                        "text": "Yilu Dong"
                    },
                    {
                        "@pid": "146/8257",
                        "text": "Prosanta Gope"
                    },
                    {
                        "@pid": "165/0256",
                        "text": "Behzad Abdolmaleki"
                    },
                    {
                        "@pid": "83/7270",
                        "text": "Syed Rafiul Hussain"
                    }
                ]
            },
            "title": "Strong Privacy-Preserving Universally Composable AKA Protocol with Seamless Handover Support for Mobile Virtual Network Operator.",
            "venue": "CCS",
            "pages": "2057-2071",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/AlnashwanYDGAH24",
            "doi": "10.1145/3658644.3690331",
            "ee": "https://doi.org/10.1145/3658644.3690331",
            "url": "https://dblp.org/rec/conf/ccs/AlnashwanYDGAH24",
            "abstract": "Consumers seeking a new mobile plan have many choices in the present mobile landscape. The Mobile Virtual Network Operator (MVNO) has recently gained considerable attention among these options. MVNOs offer various benefits, making them an appealing choice for a majority of consumers. These advantages encompass flexibility, access to cutting-edge technologies, enhanced coverage, superior customer service, and substantial cost savings. Even though MVNO offers several advantages, it also creates some security and privacy concerns for the customer simultaneously. For instance, in the existing solution, MVNO needs to hand over all the sensitive details, including the users' identities and master secret keys of their customers, to a mobile operator (MNO) to validate the customers while offering any services. This allows MNOs to have unrestricted access to the MVNO subscribers' location and mobile data, including voice calls, SMS, and Internet, which the MNOs frequently sell to third parties (e.g., advertisement companies and surveillance agencies) for more profit. Although critical for mass users, such privacy loss has been historically ignored due to the lack of practical and privacy-preserving solutions for registration and handover procedures in cellular networks. In this paper, we propose a universally composable authentication and handover scheme with strong user privacy support, where each MVNO user can validate a mobile operator (MNO) and vice-versa without compromising user anonymity and unlinkability support. Here, we anticipate that our proposed solution will most likely be deployed by the MVNO(s) to ensure enhanced privacy support to their customer(s).",
            "keywords": [
                "Mobile Virtual Network Operator (MVNO)",
                "Privacy-Preserving Protocols",
                "User Anonymity",
                "Handover Procedures",
                "Universally Composable Authentication"
            ]
        },
        "url": "URL#256572",
        "sema_paperId": "3e9e64061b36abbc075670012bb307bf723414d1"
    },
    {
        "@score": "1",
        "@id": "256573",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "84/8371",
                        "text": "M\u00e1rio S. Alvim"
                    },
                    {
                        "@pid": "220/4193",
                        "text": "Natasha Fernandes"
                    },
                    {
                        "@pid": "m/AnnabelleMcIver",
                        "text": "Annabelle McIver"
                    },
                    {
                        "@pid": "380/6281",
                        "text": "Gabriel H. Nunes"
                    }
                ]
            },
            "title": "The Privacy-Utility Trade-off in the Topics API.",
            "venue": "CCS",
            "pages": "1106-1120",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/AlvimFMN24",
            "doi": "10.1145/3658644.3670368",
            "ee": "https://doi.org/10.1145/3658644.3670368",
            "url": "https://dblp.org/rec/conf/ccs/AlvimFMN24",
            "abstract": "The ongoing deprecation of third-party cookies by web browser vendors has sparked the proposal of alternative methods to support more privacy-preserving personalized advertising on web browsers and applications. The Topics API is being proposed by Google to provide third-parties with\"coarse-grained advertising topics that the page visitor might currently be interested in\". In this paper, we analyze the re-identification risks for individual Internet users and the utility provided to advertising companies by the Topics API, i.e. learning the most popular topics and distinguishing between real and random topics. We provide theoretical results dependent only on the API parameters that can be readily applied to evaluate the privacy and utility implications of future API updates, including novel general upper-bounds that account for adversaries with access to unknown, arbitrary side information, the value of the differential privacy parameter $\\epsilon$, and experimental results on real-world data that validate our theoretical model.",
            "keywords": [
                "Privacy-Preserving Advertising",
                "Topics API",
                "Re-identification Risks",
                "Advertising Utility",
                "Differential Privacy"
            ]
        },
        "url": "URL#256573",
        "sema_paperId": "4deb32b9a2ad68d9f067b104c7a7723d868ffd30"
    },
    {
        "@score": "1",
        "@id": "256574",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "178/5234",
                        "text": "Miguel Ambrona"
                    },
                    {
                        "@pid": "64/5418",
                        "text": "Pooya Farshim"
                    },
                    {
                        "@pid": "218/6993",
                        "text": "Patrick Harasser"
                    }
                ]
            },
            "title": "Block Ciphers in Idealized Models: Automated Proofs and New Security Results.",
            "venue": "CCS",
            "pages": "2771-2785",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/AmbronaFH24",
            "doi": "10.1145/3658644.3690222",
            "ee": "https://doi.org/10.1145/3658644.3690222",
            "url": "https://dblp.org/rec/conf/ccs/AmbronaFH24",
            "abstract": "We develop and implement AlgoROM, a tool to systematically analyze the security of a wide class of symmetric primitives in idealized models of computation. The schemes that we consider are those that can be expressed over an alphabet consisting of XOR and function symbols for hash functions, permutations, or block ciphers.",
            "pdf_url": "",
            "keywords": [
                "Block Ciphers",
                "Idealized Models",
                "Automated Proofs",
                "Symmetric Primitives",
                "Security Analysis"
            ]
        },
        "url": "URL#256574"
    },
    {
        "@score": "1",
        "@id": "256575",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "168/8830",
                        "text": "Mohammad Hassan Ameri"
                    },
                    {
                        "@pid": "30/8037",
                        "text": "Jeremiah Blocki"
                    }
                ]
            },
            "title": "Conditional Encryption with Applications to Secure Personalized Password Typo Correction.",
            "venue": "CCS",
            "pages": "4643-4657",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/AmeriB24",
            "doi": "10.1145/3658644.3690374",
            "ee": "https://doi.org/10.1145/3658644.3690374",
            "url": "https://dblp.org/rec/conf/ccs/AmeriB24",
            "abstract": "We introduce the notion of a conditional encryption scheme as an extension of public key encryption. In addition to the standard public key algorithms ($\\mathsf{KG}$, $\\mathsf{Enc}$, $\\mathsf{Dec}$) for key generation, encryption and decryption, a conditional encryption scheme for a binary predicate $P$ adds a new conditional encryption algorithm $\\mathsf{CEnc}$. The conditional encryption algorithm $c=\\mathsf{CEnc}_{pk}(c_1,m_2,m_3)$ takes as input the public encryption key $pk$, a ciphertext $c_1 = \\mathsf{Enc}_{pk}(m_1)$ for an unknown message $m_1$, a control message $m_2$ and a payload message $m_3$ and outputs a conditional ciphertext $c$. Intuitively, if $P(m_1,m_2)=1$ then the conditional ciphertext $c$ should decrypt to the payload message $m_3$. On the other hand if $P(m_1,m_2) = 0$ then the ciphertext should not leak any information about the control message $m_2$ or the payload message $m_3$ even if the attacker already has the secret decryption key $sk$. We formalize the notion of conditional encryption secrecy and provide concretely efficient constructions for a set of predicates relevant to password typo correction. Our practical constructions utilize the Paillier partially homomorphic encryption scheme as well as Shamir Secret Sharing. We prove that our constructions are secure and demonstrate how to use conditional encryption to improve the security of personalized password typo correction systems such as TypTop. We implement a C++ library for our practically efficient conditional encryption schemes and evaluate the performance empirically. We also update the implementation of TypTop to utilize conditional encryption for enhanced security guarantees and evaluate the performance of the updated implementation.",
            "keywords": [
                "Conditional Encryption",
                "Password Typo Correction",
                "Security Protocols",
                "Homomorphic Encryption",
                "Information Leakage"
            ]
        },
        "url": "URL#256575",
        "sema_paperId": "d6adf768651adcfd515614a0a8053145d5fa39b9"
    },
    {
        "@score": "1",
        "@id": "256576",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "300/9139",
                        "text": "Abdul Haddi Amjad"
                    },
                    {
                        "@pid": "172/6776",
                        "text": "Muhammad Ali Gulzar"
                    }
                ]
            },
            "title": "Poster: How Do Visually Impaired Users Navigate Accessibility Challenges in an Ad-Driven Web?",
            "venue": "CCS",
            "pages": "5021-5023",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/AmjadG24",
            "doi": "10.1145/3658644.3691389",
            "ee": "https://doi.org/10.1145/3658644.3691389",
            "url": "https://dblp.org/rec/conf/ccs/AmjadG24",
            "abstract": "Website accessibility is crucial for inclusiveness and regulatory compliance. While third-party advertisements (ads) are essential for funding free web services, they pose significant accessibility challenges. When developers lease space to ad-serving technologies like DoubleClick, they lose control over the accessibility of ad content. Even highly accessible websites can have their adherence to Web Content Accessibility Guidelines (WCAG) undermined by third-party ads. We conduct an investigation into the accessibility of ads across 430K website elements, including nearly 100K ad elements. Our study aims to evaluate the prevalence of inaccessible ads and their impact on overall website accessibility. Our findings reveal that 67% of websites experience increased accessibility violations due to ads, with common issues including Focus Visible (WCAG 2.4.7) and On Input (WCAG 3.2.2). Ad-serving technologies such as Taboola, DoubleClick, and RevContent frequently serve ads that do not meet WCAG standards. Inaccessible ads can significantly increase privacy risks for users with disabilities, as these ads may force them to engage with potentially unsafe or misleading content without proper accessibility features to protect their information.",
            "pdf_url": "",
            "keywords": [
                "Web Accessibility",
                "Third-Party Advertisements",
                "Inaccessible Ads",
                "WCAG Compliance",
                "Privacy Risks for Users with Disabilities"
            ]
        },
        "url": "URL#256576",
        "sema_paperId": "5ed87c30e56628b57ce6e3db11e0006cb2018e91"
    },
    {
        "@score": "1",
        "@id": "256577",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "300/9139",
                        "text": "Abdul Haddi Amjad"
                    },
                    {
                        "@pid": "290/6330",
                        "text": "Shaoor Munir"
                    },
                    {
                        "@pid": "83/9528",
                        "text": "Zubair Shafiq"
                    },
                    {
                        "@pid": "172/6776",
                        "text": "Muhammad Ali Gulzar"
                    }
                ]
            },
            "title": "Blocking Tracking JavaScript at the Function Granularity.",
            "venue": "CCS",
            "pages": "2177-2191",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/AmjadMSG24",
            "doi": "10.1145/3658644.3670329",
            "ee": "https://doi.org/10.1145/3658644.3670329",
            "url": "https://dblp.org/rec/conf/ccs/AmjadMSG24",
            "abstract": "Modern websites extensively rely on JavaScript to implement both functionality and tracking. Existing privacy enhancing content blocking tools struggle against mixed scripts, which simultaneously implement both functionality and tracking, because blocking the script would break functionality and not blocking it would allow tracking. We propose Not.js, a fine grained JavaScript blocking tool that operates at the function level granularity. Not.js's strengths lie in analyzing the dynamic execution context, including the call stack and calling context of each JavaScript function, and then encoding this context to build a rich graph representation. Not.js trains a supervised machine learning classifier on a webpage's graph representation to first detect tracking at the JavaScript function level and then automatically generate surrogate scripts that preserve functionality while removing tracking. Our evaluation of Not.js on the top 10K websites demonstrates that it achieves high precision (94%) and recall (98%) in detecting tracking JavaScript functions, outperforming the state of the art while being robust against off the shelf JavaScript obfuscation. Fine grained detection of tracking functions allows Not.js to automatically generate surrogate scripts that remove tracking JavaScript functions without causing major breakage. Our deployment of Not.js shows that mixed scripts are present on 62.3% of the top 10K websites, with 70.6% of the mixed scripts being third party that engage in tracking activities such as cookie ghostwriting. We share a sample of the tracking functions detected by Not.js within mixed scripts not currently on filter lists with filter list authors, who confirm that these scripts are not blocked due to potential functionality breakage, despite being known to implement tracking.",
            "keywords": [
                "JavaScript Tracking",
                "Function Granularity",
                "Privacy Enhancements",
                "Dynamic Execution Context",
                "Surrogate Script Generation"
            ]
        },
        "url": "URL#256577",
        "sema_paperId": "ab84173b2bad2bb9d352854f467706d45ecb10eb"
    },
    {
        "@score": "1",
        "@id": "256578",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "65/3235",
                        "text": "Erik Anderson"
                    },
                    {
                        "@pid": "06/1661",
                        "text": "Melissa Chase"
                    },
                    {
                        "@pid": "187/0789",
                        "text": "F. Bet\u00fcl Durak"
                    },
                    {
                        "@pid": "146/7941",
                        "text": "Kim Laine"
                    },
                    {
                        "@pid": "251/1580",
                        "text": "Chenkai Weng"
                    }
                ]
            },
            "title": "Precio: Private Aggregate Measurement via Oblivious Shuffling.",
            "venue": "CCS",
            "pages": "1819-1833",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/AndersonCDLW24",
            "doi": "10.1145/3658644.3670280",
            "ee": "https://doi.org/10.1145/3658644.3670280",
            "url": "https://dblp.org/rec/conf/ccs/AndersonCDLW24",
            "abstract": "We introduce Precio, a new secure aggregation method for computing layered histograms and sums over secret shared data in a client-server setting. Precio is motivated by ad conversion measurement scenarios, where online advertisers and ad networks want to measure the performance of ad campaigns without requiring privacy-invasive techniques, such as third-party cookies. Precio has linear (communication) complexity in the number of data points and guarantees differentially private outputs. We formally analyze its security and privacy and present a thorough performance evaluation. The protocol supports much larger domains than Prio. It supports much more flexible aggregates than the DPF-based solution and in some settings has up to four orders of magnitude better performance",
            "keywords": [
                "Secure Aggregation",
                "Differential Privacy",
                "Client-Server Model",
                "Ad Conversion Measurement",
                "Layered Histograms"
            ]
        },
        "url": "URL#256578",
        "sema_paperId": "2ca87cc76a3e2a5b8568b5c194f0540250d2664e"
    },
    {
        "@score": "1",
        "@id": "256579",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "205/7547",
                        "text": "S\u00e9bastien Andreina"
                    },
                    {
                        "@pid": "270/1642",
                        "text": "Tobias Cloosters"
                    },
                    {
                        "@pid": "73/7564",
                        "text": "Lucas Davi"
                    },
                    {
                        "@pid": "315/0746",
                        "text": "Jens-Rene Giesen"
                    },
                    {
                        "@pid": "308/6435",
                        "text": "Marco Gutfleisch"
                    },
                    {
                        "@pid": "36/1531",
                        "text": "Ghassan Karame"
                    },
                    {
                        "@pid": "201/9227",
                        "text": "Alena Naiakshina"
                    },
                    {
                        "@pid": "380/2633",
                        "text": "Houda Naji"
                    }
                ]
            },
            "title": "Defying the Odds: Solana&apos;s Unexpected Resilience in Spite of the Security Challenges Faced by Developers.",
            "venue": "CCS",
            "pages": "4226-4240",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/AndreinaCDGGKNN24",
            "doi": "10.1145/3658644.3670333",
            "ee": "https://doi.org/10.1145/3658644.3670333",
            "url": "https://dblp.org/rec/conf/ccs/AndreinaCDGGKNN24",
            "abstract": "Solana gained considerable attention as one of the most popular blockchain platforms for deploying decentralized applications. Compared to Ethereum, however, we observe a lack of research on how Solana smart contract developers handle security, what challenges they encounter, and how this affects the overall security of the ecosystem. To address this, we conducted the first comprehensive study on the Solana platform consisting of a 90-minute Solana smart contract code review task with 35 participants followed by interviews with a subset of seven participants. Our study shows, quite alarmingly, that none of the participants could detect all important security vulnerabilities in a code review task and that 83% of the participants are likely to release vulnerable smart contracts. Our study also sheds light on the root causes of developers' challenges with Solana smart contract development, suggesting the need for better security guidance and resources. In spite of these challenges, our automated analysis on currently deployed Solana smart contracts surprisingly suggests that the prevalence of vulnerabilities - especially those pointed out as the most challenging in our developer study - is below 0.3%. We explore the causes of this counter-intuitive resilience and show that frameworks, such as Anchor, are aiding Solana developers in deploying secure contracts.",
            "keywords": [
                "Solana Blockchain",
                "Smart Contract Development",
                "Security Vulnerabilities",
                "Developer Challenges",
                "Automated Analysis"
            ]
        },
        "url": "URL#256579",
        "sema_paperId": "5ea2307fbb8fcc83e75960c7572d70bf5da4edb4"
    },
    {
        "@score": "1",
        "@id": "256580",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "312/6801",
                        "text": "Ananya Appan"
                    },
                    {
                        "@pid": "19/72",
                        "text": "David Heath"
                    },
                    {
                        "@pid": "30/10661",
                        "text": "Ling Ren 0001"
                    }
                ]
            },
            "title": "Oblivious Single Access Machines - A New Model for Oblivious Computation.",
            "venue": "CCS",
            "pages": "3080-3094",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/AppanH024",
            "doi": "10.1145/3658644.3690352",
            "ee": "https://doi.org/10.1145/3658644.3690352",
            "url": "https://dblp.org/rec/conf/ccs/AppanH024",
            "abstract": "Oblivious RAM (ORAM) allows a client to securely outsource memory storage to an untrusted server. It has been shown that no ORAM can simultaneously achieve small bandwidth blow-up, small client storage, and a single roundtrip of latency. We consider a weakening of the RAM model, which we call the Single Access Machine (SAM) model. In the SAM model, each memory slot can be written to at most once and read from at most once. We adapt existing tree-based ORAM to obtain an oblivious SAM (OSAM) that has \ud835\udc42 ( log \ud835\udc5b ) bandwidth blow-up (which we show is optimal), small client storage, and a single roundtrip. OSAM unlocks improvements to oblivious data structures/algorithms. For instance, we achieve oblivious unbalanced binary trees (e.g. tries, splay trees). By leveraging splay trees, we obtain a notion of caching ORAM , where an access in the worst case incurs amortized \ud835\udc42 ( log 2 \ud835\udc5b ) bandwidth blow-up and \ud835\udc42 ( log \ud835\udc5b ) roundtrips, but in many common cases (e.g. sequential scans) incurs only amortized \ud835\udc42 ( log \ud835\udc5b ) bandwidth blow-up and \ud835\udc42 ( 1 ) roundtrips. We also give new oblivious graph algorithms, including computing minimum spanning trees and single source shortest paths, in which the OSAM client reads/writes \ud835\udc42 (| \ud835\udc38 | \u00b7 log | \ud835\udc38 |) words using \ud835\udc42 (| \ud835\udc38 |) roundtrips, where | \ud835\udc38 | is the number of edges. This improves over prior custom solutions by a log factor. At a higher level, OSAM provides a general model for oblivious computation. We construct a programming interface around OSAM that supports arbitrary pointer-manipulating programs such that dereferencing a pointer to an object incurs \ud835\udc42 ( log \ud835\udc51 log \ud835\udc5b ) bandwidth blowup and \ud835\udc42 ( log \ud835\udc51 ) roundtrips, where \ud835\udc51 is the number of pointers to that object. This new interface captures a wide variety of data structures and algorithms (e.g.,",
            "keywords": [
                "Oblivious RAM",
                "Single Access Machine",
                "Oblivious Computation",
                "Bandwidth Blow-up",
                "Oblivious Data Structures"
            ]
        },
        "url": "URL#256580",
        "sema_paperId": "5fef79f33c20e507e94641a614c17f131be6beaf"
    },
    {
        "@score": "1",
        "@id": "256581",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "351/6536",
                        "text": "Sven Argo"
                    },
                    {
                        "@pid": "50/6307",
                        "text": "Tim G\u00fcneysu"
                    },
                    {
                        "@pid": "275/3570",
                        "text": "Corentin Jeudy"
                    },
                    {
                        "@pid": "289/1887",
                        "text": "Georg Land"
                    },
                    {
                        "@pid": "04/11043",
                        "text": "Adeline Roux-Langlois"
                    },
                    {
                        "@pid": "121/9530",
                        "text": "Olivier Sanders"
                    }
                ]
            },
            "title": "Practical Post-Quantum Signatures for Privacy.",
            "venue": "CCS",
            "pages": "1523-1537",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ArgoGJLRS24",
            "doi": "10.1145/3658644.3670297",
            "ee": "https://doi.org/10.1145/3658644.3670297",
            "url": "https://dblp.org/rec/conf/ccs/ArgoGJLRS24",
            "abstract": "The transition to post-quantum cryptography has been an enormous challenge and effort for cryptographers over the last decade, with impressive results such as the future NIST standards. However, the latter has so far only considered central cryptographic mechanisms (signatures or KEM) and not more advanced ones, e.g., targeting privacy-preserving applications. Of particular interest is the family of solutions called blind signatures, group signatures and anonymous credentials, for which standards already exist, and which are deployed in billions of devices. Such a family does not have, at this stage, an efficient post-quantum counterpart although very recent works improved this state of affairs by offering two different alternatives: either one gets a system with rather large elements but a security proved under standard assumptions or one gets a more efficient system at the cost of ad-hoc interactive assumptions or weaker security models. Moreover, all these works have only considered size complexity without implementing the quite complex building blocks their systems are composed of. In other words, the practicality of such systems is still very hard to assess, which is a problem if one envisions a post-quantum transition for the corresponding systems/standards.",
            "pdf_url": "",
            "keywords": [
                "Post-Quantum Cryptography",
                "Privacy-Preserving Applications",
                "Blind Signatures",
                "Group Signatures",
                "Anonymous Credentials"
            ]
        },
        "url": "URL#256581"
    },
    {
        "@score": "1",
        "@id": "256582",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "392/3318",
                        "text": "Andreas Athanasiou"
                    },
                    {
                        "@pid": "71/3271",
                        "text": "Kangsoo Jung"
                    },
                    {
                        "@pid": "p/CPalamidessi",
                        "text": "Catuscia Palamidessi"
                    }
                ]
            },
            "title": "Poster: Protection against Source Inference Attacks in Federated Learning using Unary Encoding and Shuffling.",
            "venue": "CCS",
            "pages": "5036-5038",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/AthanasiouJP24",
            "doi": "10.1145/3658644.3691411",
            "ee": "https://doi.org/10.1145/3658644.3691411",
            "url": "https://dblp.org/rec/conf/ccs/AthanasiouJP24",
            "abstract": "Federated Learning (FL) enables clients to train a joint model without disclosing their local data. Instead, they share their local model updates with a central server that moderates the process and creates a joint model. However, FL is susceptible to a series of privacy attacks. Recently, the source inference attack (SIA) has been proposed where an honest-but-curious central server tries to identify exactly which client owns a specific data record. n this work, we propose a defense against SIAs by using a trusted shuffler, without compromising the accuracy of the joint model. We employ a combination of unary encoding with shuffling, which can effectively blend all clients' model updates, preventing the central server from inferring information about each client's model update separately. In order to address the increased communication cost of unary encoding we employ quantization. Our preliminary experiments show promising results; the proposed mechanism notably decreases the accuracy of SIAs without compromising the accuracy of the joint model.",
            "keywords": [
                "Federated Learning",
                "Source Inference Attack",
                "Privacy Protection",
                "Unary Encoding",
                "Model Update Shuffling"
            ]
        },
        "url": "URL#256582",
        "sema_paperId": "20ea649fae8d71e27a473b67aa6ffbef1818ba3e"
    },
    {
        "@score": "1",
        "@id": "256583",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "23/1509",
                        "text": "Nuttapong Attrapadung"
                    },
                    {
                        "@pid": "392/2937",
                        "text": "Kota Isayama"
                    },
                    {
                        "@pid": "74/5752",
                        "text": "Kunihiko Sadakane"
                    },
                    {
                        "@pid": "306/1046",
                        "text": "Kazunari Tozawa"
                    }
                ]
            },
            "title": "Secure Parallel Computation with Oblivious State Transitions.",
            "venue": "CCS",
            "pages": "3008-3022",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/AttrapadungIST24",
            "doi": "10.1145/3658644.3690315",
            "ee": "https://doi.org/10.1145/3658644.3690315",
            "url": "https://dblp.org/rec/conf/ccs/AttrapadungIST24",
            "abstract": "We introduceOblivious Parallel Stateful Computation(OPSC), a form of secure multi-party computation (MPC) tailored for stateful machine computation models emphasizing parallel execution across multiple data. OPSC enables parties to compute multiple results simultaneously in a parallel fashion, leveraging all data from current states and auxiliary inputs dynamically entered at that point. With its parallel and dynamic nature, OPSC holds promise for privacy-preserving applications in intricate decision-making scenarios involving multiple agents, such as traffic analyses, individual consumer behavior economics, and epidemiological simulations.",
            "pdf_url": "",
            "keywords": [
                "Oblivious Parallel Stateful Computation",
                "Secure Multi-Party Computation",
                "Privacy-Preserving Applications",
                "Parallel Execution",
                "Dynamic State Transitions"
            ]
        },
        "url": "URL#256583",
        "sema_paperId": "aa891ee418a4c65fd0260e6c4bf97ff92b43422b"
    },
    {
        "@score": "1",
        "@id": "256584",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "265/9073",
                        "text": "Lukas Aumayr"
                    },
                    {
                        "@pid": "183/6375",
                        "text": "Zeta Avarikioti"
                    },
                    {
                        "@pid": "25/3571",
                        "text": "Matteo Maffei"
                    },
                    {
                        "@pid": "29/4490",
                        "text": "Subhra Mazumdar 0001"
                    }
                ]
            },
            "title": "Securing Lightning Channels against Rational Miners.",
            "venue": "CCS",
            "pages": "393-407",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/AumayrAM024",
            "doi": "10.1145/3658644.3670373",
            "ee": "https://doi.org/10.1145/3658644.3670373",
            "url": "https://dblp.org/rec/conf/ccs/AumayrAM024",
            "abstract": "Payment channel networks (e.g., the Lightning Network in Bitcoin) constitute one of the most popular scalability solutions for blockchains. Their safety relies on parties being online to detect fraud attempts on-chain and being able to timely react by publishing certain transactions on-chain. However, a cheating party may bribe miners in order to censor those transactions, resulting in loss of funds for the cheated party: these attacks are known in the literature as timelock bribing attacks. In this work, we present the first channel construction that does not require parties to be online and, at the same time, is resistant to timelock bribing attacks.",
            "pdf_url": "",
            "keywords": [
                "Payment Channel Networks",
                "Lightning Network",
                "Timelock Bribing Attacks",
                "Channel Construction",
                "Offline Security"
            ]
        },
        "url": "URL#256584"
    },
    {
        "@score": "1",
        "@id": "256585",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "44/2529",
                        "text": "Erman Ayday"
                    },
                    {
                        "@pid": "61/3091",
                        "text": "Jaideep Vaidya"
                    }
                ]
            },
            "title": "WPES &apos;24: 23rd Workshop on Privacy in the Electronic Society (WPES).",
            "venue": "CCS",
            "pages": "4893",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/AydayV24",
            "doi": "10.1145/3658644.3691544",
            "ee": "https://doi.org/10.1145/3658644.3691544",
            "url": "https://dblp.org/rec/conf/ccs/AydayV24",
            "abstract": "We are excited to welcome you to the 23nd Workshop on Privacy in the Electronic Society (WPES'24). The WPES workshop has a long-standing tradition of showcasing work from academia, industry, and government presenting novel research on theoretical and practical aspects of electronic privacy, as well as experimental studies of fielded systems. We requested two types of submissions: Full papers (up to 12 pages of results in the ACM double-column format, excluding bibliography and appendices) and short papers (up to 4 pages for results) that are preliminary or that simply require few pages to describe.",
            "pdf_url": "",
            "keywords": [
                "Privacy in Electronic Society",
                "Electronic Privacy",
                "Fielded Systems",
                "Research Submission",
                "Workshop on Privacy"
            ]
        },
        "url": "URL#256585",
        "sema_paperId": "0103e546195f2ca5961fc1295a43de81b0f4feb2"
    },
    {
        "@score": "1",
        "@id": "256586",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "335/1121",
                        "text": "Solayman Ayoubi"
                    },
                    {
                        "@pid": "t/SebastienTixeuil",
                        "text": "S\u00e9bastien Tixeuil"
                    },
                    {
                        "@pid": "89/10040",
                        "text": "Gregory Blanc"
                    },
                    {
                        "@pid": "156/8757",
                        "text": "Houda Jmila"
                    }
                ]
            },
            "title": "Demo: Towards Reproducible Evaluations of ML-Based IDS Using Data-Driven Approaches.",
            "venue": "CCS",
            "pages": "5081-5083",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/AyoubiTBJ24",
            "doi": "10.1145/3658644.3691368",
            "ee": "https://doi.org/10.1145/3658644.3691368",
            "url": "https://dblp.org/rec/conf/ccs/AyoubiTBJ24",
            "abstract": "Network-based Intrusion Detection Systems (NIDS) are crucial in cybersecurity, but evaluation methodologies are outdated and lack standardization, resulting in incomplete and unreliable assessments. To address these issues, we first proposed a comprehensive evaluation framework for Machine Learning-based Intrusion Detection Systems [1]. This framework accounts for the unique aspects, strengths, and weaknesses of ML algorithms. However, the initial proposition lacked practicality, as it presented an abstract methodology without a substantive solution. In this paper, we present a demo of FREIDA a precise and concrete implementation of our framework, featuring an easy-to-use graphical interface. We also outline FREIDA's evaluation methodology and demonstrate its application in evaluating IDS using a dataset from the literature.",
            "pdf_url": "",
            "keywords": [
                "Network-based Intrusion Detection Systems",
                "Evaluation Methodology",
                "Machine Learning Algorithms",
                "Reproducibility",
                "FREIDA"
            ]
        },
        "url": "URL#256586",
        "sema_paperId": "43e1c0cdb18afaa94b88ba87cfb5b4f219efea74"
    },
    {
        "@score": "1",
        "@id": "256587",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "139/5759",
                        "text": "Zhongjie Ba"
                    },
                    {
                        "@pid": "357/3695",
                        "text": "Jieming Zhong"
                    },
                    {
                        "@pid": "334/4133",
                        "text": "Jiachen Lei"
                    },
                    {
                        "@pid": "76/185-7",
                        "text": "Peng Cheng 0007"
                    },
                    {
                        "@pid": "27/10136",
                        "text": "Qinglong Wang"
                    },
                    {
                        "@pid": "148/4477",
                        "text": "Zhan Qin"
                    },
                    {
                        "@pid": "31/5772-1",
                        "text": "Zhibo Wang 0001"
                    },
                    {
                        "@pid": "20/6179-1",
                        "text": "Kui Ren 0001"
                    }
                ]
            },
            "title": "SurrogatePrompt: Bypassing the Safety Filter of Text-to-Image Models via Substitution.",
            "venue": "CCS",
            "pages": "1166-1180",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/BaZL0WQ0024",
            "doi": "10.1145/3658644.3690346",
            "ee": "https://doi.org/10.1145/3658644.3690346",
            "url": "https://dblp.org/rec/conf/ccs/BaZL0WQ0024",
            "abstract": "Advanced text-to-image models such as DALL$\\cdot$E 2 and Midjourney possess the capacity to generate highly realistic images, raising significant concerns regarding the potential proliferation of unsafe content. This includes adult, violent, or deceptive imagery of political figures. Despite claims of rigorous safety mechanisms implemented in these models to restrict the generation of not-safe-for-work (NSFW) content, we successfully devise and exhibit the first prompt attacks on Midjourney, resulting in the production of abundant photorealistic NSFW images. We reveal the fundamental principles of such prompt attacks and suggest strategically substituting high-risk sections within a suspect prompt to evade closed-source safety measures. Our novel framework, SurrogatePrompt, systematically generates attack prompts, utilizing large language models, image-to-text, and image-to-image modules to automate attack prompt creation at scale. Evaluation results disclose an 88% success rate in bypassing Midjourney's proprietary safety filter with our attack prompts, leading to the generation of counterfeit images depicting political figures in violent scenarios. Both subjective and objective assessments validate that the images generated from our attack prompts present considerable safety hazards.",
            "keywords": [
                "Text-to-Image Models",
                "Content Safety",
                "Prompt Attacks",
                "NSFW Content Generation",
                "SurrogatePrompt Framework"
            ]
        },
        "url": "URL#256587",
        "sema_paperId": "e1decb86f2a6aba8682d2fc4e427424b0b49e0d0"
    },
    {
        "@score": "1",
        "@id": "256588",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "320/2171",
                        "text": "Renas Bacho"
                    },
                    {
                        "@pid": "59/6303-1",
                        "text": "Christoph Lenzen 0001"
                    },
                    {
                        "@pid": "184/3870",
                        "text": "Julian Loss"
                    },
                    {
                        "@pid": "348/5924",
                        "text": "Simon Ochsenreither"
                    },
                    {
                        "@pid": "251/8063",
                        "text": "Dimitrios Papachristoudis"
                    }
                ]
            },
            "title": "GRandLine: Adaptively Secure DKG and Randomness Beacon with (Log-)Quadratic Communication Complexity.",
            "venue": "CCS",
            "pages": "941-955",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Bacho0LOP24",
            "doi": "10.1145/3658644.3690287",
            "ee": "https://doi.org/10.1145/3658644.3690287",
            "url": "https://dblp.org/rec/conf/ccs/Bacho0LOP24",
            "abstract": "Arandomness beaconis a source of continuous and publicly verifiable randomness which is of crucial importance for many applications. Existing works on randomness beacons suffer from at least one of the following drawbacks: (i) security only against static (i.e., non-adaptive) adversaries, (ii) each epoch takes many rounds of communication, or (iii) computationally expensive tools such as proof-of-work (PoW) or verifiable delay functions (VDF). In this work, we introduce GRandLine, the first adaptively secure randomness beacon protocol that overcomes all these limitations while preserving simplicity and optimal resilience in the synchronous network setting. We achieve our result in two steps. First, we design a novel distributed key generation (DKG) protocol GRand that runs in O(\u03bb n2log n ) bits of communication but, unlike most conventional DKG protocols, outputs both secret and public keys as group elements. Here, \u03bb denotes the security parameter. Second, following termination of GRand, parties can use their keys to derive a sequence of randomness beacon values, where each random value costs only a single asynchronous round and O(\u03bb n2) bits of communication. We implement GRandLine and evaluate it using a network of up to 64 parties running in geographically distributed AWS instances. Our evaluation shows that GRandLine can produce about 2 beacon outputs per second in a network of 64 parties. We compare our protocol to the state-of-the-art randomness beacon protocols OptRand (NDSS '23), BRandPiper (CCS '21), and Drand, in the same setting and observe that it vastly outperforms them.",
            "pdf_url": "",
            "keywords": [
                "Randomness Beacon",
                "Distributed Key Generation",
                "Adaptive Security",
                "Communication Complexity",
                "GRandLine"
            ]
        },
        "url": "URL#256588"
    },
    {
        "@score": "1",
        "@id": "256589",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "162/8945",
                        "text": "Christian Badertscher"
                    },
                    {
                        "@pid": "216/6635",
                        "text": "Fabio Banfi"
                    },
                    {
                        "@pid": "12/9728",
                        "text": "Jesus Diaz"
                    }
                ]
            },
            "title": "What Did Come Out of It? Analysis and Improvements of DIDComm Messaging.",
            "venue": "CCS",
            "pages": "4732-4746",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/BadertscherBD24",
            "doi": "10.1145/3658644.3690300",
            "ee": "https://doi.org/10.1145/3658644.3690300",
            "url": "https://dblp.org/rec/conf/ccs/BadertscherBD24",
            "abstract": "Self-Sovereign Identity (SSI) empowers individuals and organizations with full control over their data. Decentralized identifiers (DIDs) are at its center, where a DID contains a collection of public keys associated with an entity, and further information to enable entities to engage via secure and private messaging across different platforms. A crucial stepping stone is DIDComm, a cryptographic communication layer that is in production with version 2. Due to its widespread and active deployment, a formal study of DIDComm is highly overdue.",
            "pdf_url": "",
            "keywords": [
                "Self-Sovereign Identity",
                "Decentralized Identifiers",
                "DIDComm",
                "Cryptographic Communication",
                "Formal Study of DIDComm"
            ]
        },
        "url": "URL#256589"
    },
    {
        "@score": "1",
        "@id": "256590",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "58/5271",
                        "text": "David Baelde"
                    },
                    {
                        "@pid": "160/4605",
                        "text": "Adrien Koutsos"
                    },
                    {
                        "@pid": "271/1296",
                        "text": "Justine Sauvage"
                    }
                ]
            },
            "title": "Foundations for Cryptographic Reductions in CCSA Logics.",
            "venue": "CCS",
            "pages": "2814-2828",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/BaeldeKS24",
            "doi": "10.1145/3658644.3690193",
            "ee": "https://doi.org/10.1145/3658644.3690193",
            "url": "https://dblp.org/rec/conf/ccs/BaeldeKS24",
            "abstract": "The Computationally Complete Symbolic Attacker (CCSA) approach to security protocol verification relies on probabilistic logics to reason about the interaction traces between a protocol and an arbitrary adversary. The proof assistant Sqirrel implements one such logic. CCSA logics come with cryptographic axioms whose soundness derives from the security of standard cryptographic games, e.g. PRF, EUF, IND-CCA. Unfortunately, these axioms are complex to design and implement; so far, these tasks are manual, ad hoc and error-prone. We solve these issues by providing a formal and systematic method for deriving axioms from cryptographic games. Our method relies on synthesizing an adversary against some cryptographic game, through the notion of bi-deduction. Con-cretely, we define a rich notion of bi-deduction, justify how to use it to derive cryptographic axioms, provide a proof system for bi-deduction, and an automatic proof-search method which we implemented in Sqirrel.",
            "keywords": [
                "Cryptographic Reductions",
                "CCSA Logics",
                "Probabilistic Logics",
                "Cryptographic Axioms",
                "Bi-Deduction"
            ]
        },
        "url": "URL#256590",
        "sema_paperId": "642bc4272e8e572bfa0000b519db17950a1786e5"
    },
    {
        "@score": "1",
        "@id": "256591",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "213/9150",
                        "text": "Eugene Bagdasarian"
                    },
                    {
                        "@pid": "46/6275",
                        "text": "Vitaly Shmatikov"
                    }
                ]
            },
            "title": "Mithridates: Auditing and Boosting Backdoor Resistance of Machine Learning Pipelines.",
            "venue": "CCS",
            "pages": "4480-4494",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/BagdasarianS24",
            "doi": "10.1145/3658644.3690337",
            "ee": "https://doi.org/10.1145/3658644.3690337",
            "url": "https://dblp.org/rec/conf/ccs/BagdasarianS24",
            "abstract": "Machine learning (ML) models trained on data from potentially untrusted sources are vulnerable to poisoning. A small, maliciously crafted subset of the training inputs can cause the model to learn a\"backdoor\"task (e.g., misclassify inputs with a certain feature) in addition to its main task. Recent research proposed many hypothetical backdoor attacks whose efficacy heavily depends on the configuration and training hyperparameters of the target model. Given the variety of potential backdoor attacks, ML engineers who are not security experts have no way to measure how vulnerable their current training pipelines are, nor do they have a practical way to compare training configurations so as to pick the more resistant ones. Deploying a defense requires evaluating and choosing from among dozens of research papers and re-engineering the training pipeline. In this paper, we aim to provide ML engineers with pragmatic tools to audit the backdoor resistance of their training pipelines and to compare different training configurations, to help choose one that best balances accuracy and security. First, we propose a universal, attack-agnostic resistance metric based on the minimum number of training inputs that must be compromised before the model learns any backdoor. Second, we design, implement, and evaluate Mithridates a multi-stage approach that integrates backdoor resistance into the training-configuration search. ML developers already rely on hyperparameter search to find configurations that maximize the model's accuracy. Mithridates extends this standard tool to balance accuracy and resistance without disruptive changes to the training pipeline. We show that hyperparameters found by Mithridates increase resistance to multiple types of backdoor attacks by 3-5x with only a slight impact on accuracy. We also discuss extensions to AutoML and federated learning.",
            "keywords": [
                "Backdoor Resistance",
                "Training Pipeline Auditing",
                "Hyperparameter Optimization",
                "Poisoning Attacks",
                "Mithridates"
            ]
        },
        "url": "URL#256591",
        "sema_paperId": "6e8a9aef98269f89c1d6307114d94da0205fa6d5"
    },
    {
        "@score": "1",
        "@id": "256592",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "213/9150",
                        "text": "Eugene Bagdasarian"
                    },
                    {
                        "@pid": "254/3039",
                        "text": "Ren Yi"
                    },
                    {
                        "@pid": "287/5098",
                        "text": "Sahra Ghalebikesabi"
                    },
                    {
                        "@pid": "129/1254",
                        "text": "Peter Kairouz"
                    },
                    {
                        "@pid": "87/88",
                        "text": "Marco Gruteser"
                    },
                    {
                        "@pid": "80/4366",
                        "text": "Sewoong Oh"
                    },
                    {
                        "@pid": "06/8421",
                        "text": "Borja Balle"
                    },
                    {
                        "@pid": "47/5036",
                        "text": "Daniel Ramage"
                    }
                ]
            },
            "title": "AirGapAgent: Protecting Privacy-Conscious Conversational Agents.",
            "venue": "CCS",
            "pages": "3868-3882",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/BagdasarianYGKG24",
            "doi": "10.1145/3658644.3690350",
            "ee": "https://doi.org/10.1145/3658644.3690350",
            "url": "https://dblp.org/rec/conf/ccs/BagdasarianYGKG24",
            "abstract": "The growing use of large language model (LLM)-based conversational agents to manage sensitive user data raises significant privacy concerns. While these agents excel at understanding and acting on context, this capability can be exploited by malicious actors. We introduce a novel threat model where adversarial third-party apps manipulate the context of interaction to trick LLM-based agents into revealing private information not relevant to the task at hand. Grounded in the framework of contextual integrity, we introduce AirGapAgent, a privacy-conscious agent designed to prevent unintended data leakage by restricting the agent's access to only the data necessary for a specific task. Extensive experiments using Gemini, GPT, and Mistral models as agents validate our approach's effectiveness in mitigating this form of context hijacking while maintaining core agent functionality. For example, we show that a single-query context hijacking attack on a Gemini Ultra agent reduces its ability to protect user data from 94% to 45%, while an AirGapAgent achieves 97% protection, rendering the same attack ineffective.",
            "keywords": [
                "Conversational Agents",
                "Privacy Protection",
                "Data Leakage",
                "Contextual Integrity",
                "Context Hijacking"
            ]
        },
        "url": "URL#256592",
        "sema_paperId": "50a78ce0151b551ca7287ce946e44b2cd5b8a684"
    },
    {
        "@score": "1",
        "@id": "256593",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "298/2788",
                        "text": "Yijie Bai"
                    },
                    {
                        "@pid": "54/6824",
                        "text": "Zhongming Ma"
                    },
                    {
                        "@pid": "50/10586",
                        "text": "Yanjiao Chen"
                    },
                    {
                        "@pid": "243/3091",
                        "text": "Jiangyi Deng"
                    },
                    {
                        "@pid": "375/6492",
                        "text": "Shengyuan Pang"
                    },
                    {
                        "@pid": "150/4295",
                        "text": "Yan Liu"
                    },
                    {
                        "@pid": "10/3878-1",
                        "text": "Wenyuan Xu 0001"
                    }
                ]
            },
            "title": "Alchemy: Data-Free Adversarial Training.",
            "venue": "CCS",
            "pages": "3808-3822",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/BaiMCDPL024",
            "doi": "10.1145/3658644.3670395",
            "ee": "https://doi.org/10.1145/3658644.3670395",
            "url": "https://dblp.org/rec/conf/ccs/BaiMCDPL024",
            "abstract": "Machine learning models have become integral to various aspects of daily life, prompting increased vulnerability to adversarial attacks. Adversarial training is one of the most promising and practical methods to enhance model robustness. Existing adversarial training methods, however, assume access to the original training data. But nowadays, more and more users directly download models from the open-source model platforms or tech companies, but the original training datasets are usually unreleased because of commercial interests or privacy. In such scenarios, the user cannot utilize the former adversarial training methods to improve model robustness because of the lack of original training datasets.",
            "pdf_url": "",
            "keywords": [
                "Adversarial Training",
                "Model Robustness",
                "Data Privacy",
                "Open-Source Models",
                "Data-Free Training"
            ]
        },
        "url": "URL#256593",
        "sema_paperId": "298e8c39c85a09a86ff64d9ac07d3eaa1e9df7eb"
    },
    {
        "@score": "1",
        "@id": "256594",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "294/4945",
                        "text": "Shuangpeng Bai"
                    },
                    {
                        "@pid": "334/9029",
                        "text": "Zhechang Zhang"
                    },
                    {
                        "@pid": "70/2543-4",
                        "text": "Hong Hu 0004"
                    }
                ]
            },
            "title": "CountDown: Refcount-guided Fuzzing for Exposing Temporal Memory Errors in Linux Kernel.",
            "venue": "CCS",
            "pages": "1315-1329",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/BaiZ024",
            "doi": "10.1145/3658644.3690320",
            "ee": "https://doi.org/10.1145/3658644.3690320",
            "url": "https://dblp.org/rec/conf/ccs/BaiZ024",
            "abstract": "Kernel use-after-free (UAF) bugs are severe threats to system security due to their complex root causes and high exploitability. We find that 36.1% of recent kernel UAF bugs are caused by improper uses of reference counters, dubbed refcount-related UAF bugs. Current kernel fuzzing tools based on code coverage can detect common memory errors, but none of them is aware of the root cause. As a consequence, they only trigger refcount-related UAF bugs passively and coincidentally, and may miss many deep hidden vulnerabilities. To actively trigger refcount-related UAF bugs, in this paper, we propose CountDown, a novel refcount-guided kernel fuzzer. CountDown collects diverse refcount operations from kernel executions and reshapes syscall relations based on commonly accessed refcounts. When generating user-space programs, CountDown prefers to combine syscalls that ever access the same refcounts, aiming to trigger complex refcount behaviors. It also injects refcount-decreasing and refcount-accessing syscalls to intentionally free the refcounted object and trigger invalid accesses through dangling pointers. We test CountDown on mainstream Linux kernels and compare it with popular fuzzers. On average, our tool can detect 66.1% more UAF bugs and 32.9% more KASAN reports than state-of-the-art tools. CountDown has found nine new kernel memory bugs, where two are fixed and one is confirmed.",
            "keywords": [
                "Kernel Fuzzing",
                "Use-After-Free Bugs",
                "Reference Counting",
                "Memory Errors",
                "Temporal Memory Errors"
            ]
        },
        "url": "URL#256594",
        "sema_paperId": "2ef52b83b2bf8b11d11cb3ae63417351ebf6857b"
    },
    {
        "@score": "1",
        "@id": "256595",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "46/7643",
                        "text": "Foteini Baldimtsi"
                    },
                    {
                        "@pid": "09/2637",
                        "text": "Konstantinos Kryptos Chalkias"
                    },
                    {
                        "@pid": "08/3672-1",
                        "text": "Yan Ji 0001"
                    },
                    {
                        "@pid": "367/4139",
                        "text": "Jonas Lindstr\u00f8m"
                    },
                    {
                        "@pid": "235/4793",
                        "text": "Deepak Maram"
                    },
                    {
                        "@pid": "11/10299",
                        "text": "Ben Riva"
                    },
                    {
                        "@pid": "88/4138-1",
                        "text": "Arnab Roy 0001"
                    },
                    {
                        "@pid": "265/8748",
                        "text": "Mahdi Sedaghat"
                    },
                    {
                        "@pid": "348/5952",
                        "text": "Joy Wang"
                    }
                ]
            },
            "title": "zkLogin: Privacy-Preserving Blockchain Authentication with Existing Credentials.",
            "venue": "CCS",
            "pages": "3182-3196",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/BaldimtsiC0LMR024",
            "doi": "10.1145/3658644.3690356",
            "ee": "https://doi.org/10.1145/3658644.3690356",
            "url": "https://dblp.org/rec/conf/ccs/BaldimtsiC0LMR024",
            "abstract": "For many users, a private key based wallet serves as the primary entry point to blockchains. Commonly recommended wallet authentication methods, such as mnemonics or hardware wallets, can be cumbersome. This difficulty in user onboarding has significantly hindered the adoption of blockchain-based applications.",
            "pdf_url": "",
            "keywords": [
                "Blockchain Authentication",
                "Privacy-Preserving",
                "User Onboarding",
                "Private Key Management",
                "Existing Credentials"
            ]
        },
        "url": "URL#256595"
    },
    {
        "@score": "1",
        "@id": "256596",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "286/6250",
                        "text": "Akhil Bandarupalli"
                    },
                    {
                        "@pid": "174/9588",
                        "text": "Adithya Bhat"
                    },
                    {
                        "@pid": "57/95",
                        "text": "Saurabh Bagchi"
                    },
                    {
                        "@pid": "12/3394",
                        "text": "Aniket Kate"
                    },
                    {
                        "@pid": "r/MichaelKReiter",
                        "text": "Michael K. Reiter"
                    }
                ]
            },
            "title": "Random Beacons in Monte Carlo: Efficient Asynchronous Random Beacon without Threshold Cryptography.",
            "venue": "CCS",
            "pages": "2621-2635",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/BandarupalliBBK24",
            "doi": "10.1145/3658644.3670326",
            "ee": "https://doi.org/10.1145/3658644.3670326",
            "url": "https://dblp.org/rec/conf/ccs/BandarupalliBBK24",
            "abstract": "Regular access to unpredictable and bias-resistant randomness is important for applications such as blockchains, voting, and secure distributed computing. Distributed random beacon protocols address this need by distributing trust across multiple nodes, with the majority of them assumed to be honest. Numerous applications across the blockchain space have led to the proposal of several distributed random beacon protocols, with some already implemented. However, many current random beacon systems rely on threshold cryptographic setups or exhibit high computational costs, while others expect the network to be partial or bounded synchronous. To overcome these limitations, we propose HashRand, a computation and communication-efficient asynchronous random beacon protocol that only demands secure hash and pairwise secure channels to generate beacons. HashRand has a per-node amortized communication complexity of O( \ud835\udf06\ud835\udc5b log ( \ud835\udc5b )) bits per beacon. The computational efficiency of HashRand is attributed to the two orders of magnitude lower time of a one-way Hash computation compared to discrete log exponentiation. Interestingly, besides reduced overhead, HashRand achieves Post-Quantum security by leveraging the secure Hash function against quantum adversaries, setting it apart from other random beacon protocols that use discrete log cryptography. In a geo-distributed testbed of \ud835\udc5b = 136 nodes, HashRand produces 78 beacons per minute, which is at least 5x higher than Spurt [IEEE S&P\u201922]. We also demonstrate the practical utility of HashRand by implementing a Post-Quantum secure Asynchronous SMR protocol, which has a response rate of over 135k transactions per second at a latency of 2 . 3 seconds over a WAN for \ud835\udc5b = 16 nodes.",
            "keywords": [
                "Random Beacon Protocols",
                "Asynchronous Systems",
                "Post-Quantum Security",
                "Hash Functions",
                "Distributed Randomness Generation"
            ]
        },
        "url": "URL#256596",
        "sema_paperId": "f5d6c5c4619dee879349ac0e7301627b02ec7fe3"
    },
    {
        "@score": "1",
        "@id": "256597",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "294/6531",
                        "text": "Huaifeng Bao"
                    },
                    {
                        "@pid": "11/444",
                        "text": "Wenhao Li"
                    },
                    {
                        "@pid": "202/2279",
                        "text": "Zhaoxuan Li"
                    },
                    {
                        "@pid": "276/4806",
                        "text": "Han Miao"
                    },
                    {
                        "@pid": "29/4680-8",
                        "text": "Wen Wang 0008"
                    },
                    {
                        "@pid": "77/1318-1",
                        "text": "Feng Liu 0001"
                    }
                ]
            },
            "title": "Poster: PGPNet: Classify APT Malware Using Prediction-Guided Prototype Network.",
            "venue": "CCS",
            "pages": "5063-5065",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/BaoLLMWL24",
            "doi": "10.1145/3658644.3691396",
            "ee": "https://doi.org/10.1145/3658644.3691396",
            "url": "https://dblp.org/rec/conf/ccs/BaoLLMWL24",
            "abstract": "As the popularity of Advanced Persistent Threat (APT) grows, APT malware group classification has attracted more attention recently. However, most of previous methods use simple classifiers for group classification, ignoring the bias caused by the sparse number of revealed malware and the differences in functionality distribution of most groups. In this paper, we propose a Prediction-Guided Prototype Network (PGPNet) that could quickly adapt to new classification tasks with limited supervised samples based on the meta-learning architecture. Adding malware functionality classification as an auxiliary task is beneficial for feature learning, and the bias of distribution differences is eliminated by intervening the predicted results into the group classifier. Experimental results on a APT malware dataset show that PGPNet successfully exploits the contextual information and predictions of the auxiliary task and achieves state-of-the-art performance.",
            "pdf_url": "",
            "keywords": [
                "APT Malware Classification",
                "Prototype Network",
                "Meta-Learning",
                "Functionality Classification",
                "Contextual Information"
            ]
        },
        "url": "URL#256597",
        "sema_paperId": "eafdf96f5b5996f5bface7c328354eccf3585be6"
    },
    {
        "@score": "1",
        "@id": "256598",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "331/2788",
                        "text": "Nils Bars"
                    },
                    {
                        "@pid": "207/4015",
                        "text": "Moritz Schloegel"
                    },
                    {
                        "@pid": "342/3697",
                        "text": "Nico Schiller"
                    },
                    {
                        "@pid": "155/0020",
                        "text": "Lukas Bernhard"
                    },
                    {
                        "@pid": "h/ThorstenHolz",
                        "text": "Thorsten Holz"
                    }
                ]
            },
            "title": "No Peer, no Cry: Network Application Fuzzing via Fault Injection.",
            "venue": "CCS",
            "pages": "750-764",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/BarsSSBH24",
            "doi": "10.1145/3658644.3690274",
            "ee": "https://doi.org/10.1145/3658644.3690274",
            "url": "https://dblp.org/rec/conf/ccs/BarsSSBH24",
            "abstract": "Network-facing applications are commonly exposed to all kinds of attacks, especially when connected to the internet. As a result, web servers like Nginx or client applications such as curl make every effort to secure and harden their code to rule out memory safety violations. One would expect this to include regular fuzz testing, as fuzzing has proven to be one of the most successful approaches to uncovering bugs in software. Yet, surprisingly little research has focused on fuzzing network applications. When studying the underlying reasons, we find that the interactive nature of communication, its statefulness, and the protection of exchanged messages render typical fuzzers ineffective. Attempts to replay recorded messages or modify them on the fly only work for specific targets and often lead to early termination of communication. In this paper, we discuss these challenges in detail, highlighting how the focus of existing work on protocol state space promises little relief. We propose a fundamentally different approach that relies on fault injection rather than modifying messages. Effectively, we force one of the communication peers into a weird state where its output no longer matches the expectations of the target peer, potentially uncovering bugs. Importantly, this weird peer can still properly encrypt/sign the protocol message, overcoming a fundamental challenge of current fuzzers. In effect, we leave the communication system intact but introduce small corruptions. Since we can turn either the server or the client into the weird peer, our approach is the first that can effectively test client-side network applications. Evaluating 16 targets, we show that Fuzztruction-Net outperforms other fuzzers in terms of coverage and bugs found. Overall, Fuzztruction-Net uncovered 23 new bugs in well-tested software, such as the web servers Nginx and Apache HTTPd and the OpenSSH client.",
            "keywords": [
                "Network Application Fuzzing",
                "Fault Injection",
                "Communication Protocols",
                "Bug Discovery",
                "Client-Side Testing"
            ]
        },
        "url": "URL#256598",
        "sema_paperId": "68e9f3aeea76726358f9078897efce3e169c0580"
    },
    {
        "@score": "1",
        "@id": "256599",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "b/GBarthe",
                        "text": "Gilles Barthe"
                    },
                    {
                        "@pid": "91/7541",
                        "text": "Marcel B\u00f6hme"
                    },
                    {
                        "@pid": "208/7309",
                        "text": "Sunjay Cauligi"
                    },
                    {
                        "@pid": "124/1916",
                        "text": "Chitchanok Chuengsatiansup"
                    },
                    {
                        "@pid": "98/8283",
                        "text": "Daniel Genkin"
                    },
                    {
                        "@pid": "118/6449",
                        "text": "Marco Guarnieri"
                    },
                    {
                        "@pid": "367/7167",
                        "text": "David Mateos Romero"
                    },
                    {
                        "@pid": "30/1431",
                        "text": "Peter Schwabe"
                    },
                    {
                        "@pid": "56/2742",
                        "text": "David Wu"
                    },
                    {
                        "@pid": "90/10901",
                        "text": "Yuval Yarom"
                    }
                ]
            },
            "title": "Testing Side-channel Security of Cryptographic Implementations against Future Microarchitectures.",
            "venue": "CCS",
            "pages": "1076-1090",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/BartheBCCGGRSWY24",
            "doi": "10.1145/3658644.3670319",
            "ee": "https://doi.org/10.1145/3658644.3670319",
            "url": "https://dblp.org/rec/conf/ccs/BartheBCCGGRSWY24",
            "abstract": "How will future microarchitectures impact the security of existing cryptographic implementations? As we cannot keep reducing the size of transistors, chip vendors have started developing new microarchitectural optimizations to speed up computation. A recent study (Sanchez Vicarte et al., ISCA 2021) suggests that these optimizations might open the Pandora's box of microarchitectural attacks. However, there is little guidance on how to evaluate the security impact of future optimization proposals. To help chip vendors explore the impact of microarchitectural optimizations on cryptographic implementations, we develop (i) an expressive domain-specific language, called LmSpec, that allows them to specify the leakage model for the given optimization and (ii) a testing framework, called LmTest, to automatically detect leaks under the specified leakage model within the given implementation. Using this framework, we conduct an empirical study of 18 proposed microarchitectural optimizations on 25 implementations of eight cryptographic primitives in five popular libraries. We find that every implementation would contain secret-dependent leaks, sometimes sufficient to recover a victim's secret key, if these optimizations were realized. Ironically, some leaks are possible only because of coding idioms used to prevent leaks under the standard constant-time model.",
            "keywords": [
                "Microarchitectural Security",
                "Cryptographic Implementations",
                "Side-channel Attacks",
                "Leakage Models",
                "Microarchitectural Optimizations"
            ]
        },
        "url": "URL#256599",
        "sema_paperId": "598f59b803948fac66336328dd868cf6b657711c"
    },
    {
        "@score": "1",
        "@id": "256600",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "67/1939",
                        "text": "Lejla Batina"
                    },
                    {
                        "@pid": "95/137",
                        "text": "Chip-Hong Chang"
                    },
                    {
                        "@pid": "50/7968",
                        "text": "Ulrich R\u00fchrmair"
                    },
                    {
                        "@pid": "66/8277",
                        "text": "Jakub Szefer"
                    }
                ]
            },
            "title": "ASHES &apos;24: Workshop on Attacks and Solutions in Hardware Security.",
            "venue": "CCS",
            "pages": "4909-4910",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/BatinaCRS24",
            "doi": "10.1145/3658644.3691546",
            "ee": "https://doi.org/10.1145/3658644.3691546",
            "url": "https://dblp.org/rec/conf/ccs/BatinaCRS24",
            "abstract": "The workshop on \"Attacks and Solutions in HardwarE Security (ASHES)\" welcomes any theoretical and practical works on hardware security, including attacks, solutions, countermeasures, proofs, classification, formalization, and implementations. Besides mainstream research, ASHES puts some focus on new and emerging scenarios: This includes the Internet of Things (IoT), nuclear weapons inspections, arms control, consumer and infrastructure security, or supply chain security, among others. ASHES also welcomes works on special purpose hardware, such as lightweight, low-cost, and energy-efficient devices, or non-electronic security systems.",
            "pdf_url": "",
            "keywords": [
                "Hardware Security",
                "Attacks",
                "Countermeasures",
                "Internet of Things (IoT)",
                "Supply Chain Security"
            ]
        },
        "url": "URL#256600",
        "sema_paperId": "076fe6eae9624a2672f24051057730362113210b"
    },
    {
        "@score": "1",
        "@id": "256601",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "230/8062",
                        "text": "Josh Beal"
                    },
                    {
                        "@pid": "148/2252",
                        "text": "Ben Fisch"
                    }
                ]
            },
            "title": "Derecho: Privacy Pools with Proof-Carrying Disclosures.",
            "venue": "CCS",
            "pages": "3197-3211",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/BealF24",
            "doi": "10.1145/3658644.3670270",
            "ee": "https://doi.org/10.1145/3658644.3670270",
            "url": "https://dblp.org/rec/conf/ccs/BealF24",
            "abstract": "Aprivacy poolenables clients to deposit units of a cryptocurrency into a shared pool where ownership of deposited currency is tracked via a system of cryptographically hidden records. Clients may later withdraw from the pool without linkage to previous deposits. Some privacy pools also support hidden transfer of currency ownership within the pool. In August 2022, the U.S. Department of Treasury sanctioned Tornado Cash, the largest Ethereum privacy pool, on the premise that it enables illicit actors to hide the origin of funds, citing its usage by the DPRK-sponsored Lazarus Group to launder over $455 million dollars worth of stolen cryptocurrency. This ruling effectively made it illegal for U.S. persons/institutions to use or accept funds that went through Tornado Cash, sparking a global debate among privacy rights activists and lawmakers. Against this backdrop, we presentDerecho,a system that institutions could use to request cryptographic attestations of fund origins rather than naively rejecting all funds coming from privacy pools. Derecho is a novel application ofproof-carrying data,which allows users to propagate allowlist membership proofs through a privacy pool's transaction graph. Derecho is backwards-compatible with existing Ethereum privacy pool designs, adds no overhead in gas costs, and costs users only a few seconds to produce attestations.",
            "pdf_url": "",
            "keywords": [
                "Privacy Pools",
                "Cryptographic Attestations",
                "Proof-Carrying Data",
                "Fund Origin Verification",
                "Tornado Cash Sanctions"
            ]
        },
        "url": "URL#256601"
    },
    {
        "@score": "1",
        "@id": "256602",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "308/2301",
                        "text": "Nathaniel Bennett"
                    },
                    {
                        "@pid": "34/2615-2",
                        "text": "Weidong Zhu 0002"
                    },
                    {
                        "@pid": "210/9653",
                        "text": "Benjamin Simon"
                    },
                    {
                        "@pid": "305/4348",
                        "text": "Ryon Kennedy"
                    },
                    {
                        "@pid": "22/4463",
                        "text": "William Enck"
                    },
                    {
                        "@pid": "14/3295",
                        "text": "Patrick Traynor"
                    },
                    {
                        "@pid": "82/1935",
                        "text": "Kevin R. B. Butler"
                    }
                ]
            },
            "title": "RANsacked: A Domain-Informed Approach for Fuzzing LTE and 5G RAN-Core Interfaces.",
            "venue": "CCS",
            "pages": "2027-2041",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Bennett0SKETB24",
            "doi": "10.1145/3658644.3670320",
            "ee": "https://doi.org/10.1145/3658644.3670320",
            "url": "https://dblp.org/rec/conf/ccs/Bennett0SKETB24",
            "abstract": "Cellular network infrastructure serves as the backbone of modern mobile wireless communication. As such, cellular cores must be proactively secured against external threats to ensure reliable service. Compromised base station attacks against the core are a rising threat to cellular networks, while user device inputs have long been considered as an attack vector; despite this, few techniques exist to comprehensively test RAN-Core interfaces against malicious input. In this work, we devise a fuzzing framework that perfor-mantly fuzzes cellular interfaces accessible from a base station or user device, overcoming several challenges in fuzzing specific to LTE/5G network components. We also introduce ASNFuzzGen, a tool that compiles ASN.1 specifications into structure-aware fuzzing modules, thereby facilitating effective fuzzing exploration of complex cellular protocols. We run fuzzing campaigns against seven open-source and commercial cores and discover 119 vulnerabilities, with 93 CVEs assigned. Our results reveal common implementation mistakes across several cores that lead to vulnerabilities, and the successful coordination of patches for these vulnerabilities across several vendors demonstrates the practical impact ASNFuzzGen has on hardening user-exposed cellular systems.",
            "keywords": [
                "Cellular Network Security",
                "RAN-Core Interfaces",
                "Fuzzing Framework",
                "Vulnerability Discovery",
                "ASN.1 Specifications"
            ]
        },
        "url": "URL#256602",
        "sema_paperId": "cea37457d35bd04e370bcb874ff1a0a6acbc684f"
    },
    {
        "@score": "1",
        "@id": "256603",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "322/3493",
                        "text": "Loris Bergerat"
                    },
                    {
                        "@pid": "175/5881",
                        "text": "Ilaria Chillotti"
                    },
                    {
                        "@pid": "199/9665",
                        "text": "Damien Ligier"
                    },
                    {
                        "@pid": "154/6414",
                        "text": "Jean-Baptiste Orfila"
                    },
                    {
                        "@pid": "04/11043",
                        "text": "Adeline Roux-Langlois"
                    },
                    {
                        "@pid": "294/0685",
                        "text": "Samuel Tap"
                    }
                ]
            },
            "title": "New Secret Keys for Enhanced Performance in (T)FHE.",
            "venue": "CCS",
            "pages": "2547-2561",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/BergeratCLORT24",
            "doi": "10.1145/3658644.3670376",
            "ee": "https://doi.org/10.1145/3658644.3670376",
            "url": "https://dblp.org/rec/conf/ccs/BergeratCLORT24",
            "abstract": "Fully Homomorphic Encryption has known impressive improvements in the last 15 years, going from a technology long thought to be impossible to an existing family of encryption schemes able to solve a plethora of practical use cases related to the privacy of sensitive information. Recent results mainly focus on improving techniques within the traditionally defined framework of GLWE-based schemes, but the recent CPU implementation improvements are mainly incremental. To keep improving this technology, one solution is to modify the aforementioned framework, by using slightly different hardness assumptions.",
            "pdf_url": "",
            "keywords": [
                "Fully Homomorphic Encryption",
                "GLWE-based Schemes",
                "Encryption Performance",
                "Hardness Assumptions",
                "Secret Keys"
            ]
        },
        "url": "URL#256603",
        "sema_paperId": "ec56876d455bc498155fcd5a312aa630d5f91632"
    },
    {
        "@score": "1",
        "@id": "256604",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "241/7229",
                        "text": "Alex Berke"
                    },
                    {
                        "@pid": "242/4852",
                        "text": "Tobin South"
                    },
                    {
                        "@pid": "322/0695",
                        "text": "Robert Mahari"
                    },
                    {
                        "@pid": "69/5528",
                        "text": "Kent Larson"
                    },
                    {
                        "@pid": "p/AlexPentland",
                        "text": "Alex Pentland"
                    }
                ]
            },
            "title": "Poster: zkTax: A Pragmatic Way to Support Zero-Knowledge Tax Disclosures.",
            "venue": "CCS",
            "pages": "4952-4954",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/BerkeSMLP24",
            "doi": "10.1145/3658644.3691421",
            "ee": "https://doi.org/10.1145/3658644.3691421",
            "url": "https://dblp.org/rec/conf/ccs/BerkeSMLP24",
            "abstract": "Tax returns contain financial information of interest to third parties: public officials are asked to share financial data for transparency, companies seek to assess the financial status of business partners, and individuals need to prove their income to third-parties. Tax returns also contain sensitive data such that sharing them in their entirety undermines privacy. We outline how zero-knowledge cryptography may be applied to address this tension by allowing individuals and organizations to make provable claims about select information in their tax returns without revealing additional information, in a way that can be independently verified by third parties. We highlight key system goals and design specifications for this zero-knowledge tax disclosure system (zkTax) and present a prototype implementation. The prototype consists of three distinct services that can be distributed: a tax authority that provides signed tax documents; a Redact & Prove Service that enables users to redact tax documents and produce a zero-knowledge proof attesting the provenance of the redacted data; and a Verify Service to check the validity of claims. We demonstrate how zkTax could be implemented with minimal changes to existing tax infrastructure, allowing the system to be extensible to other contexts and jurisdictions. This work provides a practical example of how distributed tools leveraging cryptography can enhance existing government or financial infrastructures, providing immediate transparency alongside privacy without system overhauls.",
            "pdf_url": "",
            "keywords": [
                "Zero-Knowledge Cryptography",
                "Tax Disclosure",
                "Privacy Preservation",
                "Financial Data Verification",
                "Sensitive Information Redaction"
            ]
        },
        "url": "URL#256604",
        "sema_paperId": "ef351aa886cc92d53c1d0b8a13b0ba42a251e801"
    },
    {
        "@score": "1",
        "@id": "256605",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "155/0020",
                        "text": "Lukas Bernhard"
                    },
                    {
                        "@pid": "342/3697",
                        "text": "Nico Schiller"
                    },
                    {
                        "@pid": "207/4015",
                        "text": "Moritz Schloegel"
                    },
                    {
                        "@pid": "331/2788",
                        "text": "Nils Bars"
                    },
                    {
                        "@pid": "h/ThorstenHolz",
                        "text": "Thorsten Holz"
                    }
                ]
            },
            "title": "DarthShader: Fuzzing WebGPU Shader Translators &amp; Compilers.",
            "venue": "CCS",
            "pages": "690-704",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/BernhardSSBH24",
            "doi": "10.1145/3658644.3690209",
            "ee": "https://doi.org/10.1145/3658644.3690209",
            "url": "https://dblp.org/rec/conf/ccs/BernhardSSBH24",
            "abstract": "A recent trend towards running more demanding web applications, such as video games or client-side LLMs, in the browser has led to the adoption of the WebGPU standard that provides a cross-platform API exposing the GPU to websites. This opens up a new attack surface: Untrusted web content is passed through to the GPU stack, which traditionally has been optimized for performance instead of security. Worsening the problem, most of WebGPU cannot be run in the tightly sandboxed process that manages other web content, which eases the attacker's path to compromising the client machine. Contrasting its importance, WebGPU shader processing has received surprisingly little attention from the automated testing community. Part of the reason is that shader translators expect highly structured and statically typed input, which renders typical fuzzing mutations ineffective. Complicating testing further, shader translation consists of a complex multi-step compilation pipeline, each stage presenting unique requirements and challenges. In this paper, we propose DarthShader, the first language fuzzer that combines mutators based on an intermediate representation with those using a more traditional abstract syntax tree. The key idea is that the individual stages of the shader compilation pipeline are susceptible to different classes of faults, requiring entirely different mutation strategies for thorough testing. By fuzzing the full pipeline, we ensure that we maintain a realistic attacker model. In an empirical evaluation, we show that our method outperforms the state-of-the-art fuzzers regarding code coverage. Furthermore, an extensive ablation study validates our key design. DarthShader found a total of 39 software faults in all modern browsers -- Chrome, Firefox, and Safari -- that prior work missed. For 15 of them, the Chrome team assigned a CVE, acknowledging the impact of our results.",
            "keywords": [
                "WebGPU",
                "Shader Compilation",
                "Fuzzing",
                "Security Vulnerabilities",
                "Shader Translators"
            ]
        },
        "url": "URL#256605",
        "sema_paperId": "6457f7cfb150c2e3fe27cdf7aa05fc5db0f2c15a"
    },
    {
        "@score": "1",
        "@id": "256606",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "191/4048",
                        "text": "Divyanshu Bhardwaj"
                    },
                    {
                        "@pid": "381/9777",
                        "text": "Sandhya Saravanan"
                    },
                    {
                        "@pid": "77/5616",
                        "text": "Nishanth Chandran"
                    },
                    {
                        "@pid": "66/11477-1",
                        "text": "Divya Gupta 0001"
                    }
                ]
            },
            "title": "Securely Training Decision Trees Efficiently.",
            "venue": "CCS",
            "pages": "4673-4687",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/BhardwajSC024",
            "doi": "10.1145/3658644.3670268",
            "ee": "https://doi.org/10.1145/3658644.3670268",
            "url": "https://dblp.org/rec/conf/ccs/BhardwajSC024",
            "abstract": "Decision trees are an important class of supervised learning algorithms. When multiple entities contribute data to train a decision tree (e.g. for fraud detection in the financial sector), data privacy concerns necessitate the use of a privacy-enhancing technology such as secure multi-party computation (MPC) in order to secure the underlying training data. Prior state-of-the-art (Hamadaet al.[18]) construct an MPC protocol for decision tree training with a communication of O(hmN log N), when building a decision tree of height h for a training dataset of N samples, each having m attributes.",
            "pdf_url": "",
            "keywords": [
                "Decision Trees",
                "Secure Multi-Party Computation",
                "Data Privacy",
                "Fraud Detection",
                "Efficient Training Protocols"
            ]
        },
        "url": "URL#256606"
    },
    {
        "@score": "1",
        "@id": "256607",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "331/2323",
                        "text": "Abhishek Bhaskar"
                    },
                    {
                        "@pid": "61/1749",
                        "text": "Paul Pearce"
                    }
                ]
            },
            "title": "Understanding Routing-Induced Censorship Changes Globally.",
            "venue": "CCS",
            "pages": "437-451",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/BhaskarP24",
            "doi": "10.1145/3658644.3670336",
            "ee": "https://doi.org/10.1145/3658644.3670336",
            "url": "https://dblp.org/rec/conf/ccs/BhaskarP24",
            "abstract": "Internet censorship is pervasive, with significant effort dedicated to understanding what is censored, and where. Prior censorship work however have identified significant inconsistencies in their results; experiments show unexplained non-determinism thought to be caused by censor load, end-host geographic diversity, or incomplete censorship -- inconsistencies which impede reliable, repeatable and correct understanding of global censorship. In this work we investigate the extent to which Equal-cost Multi-path (ECMP) routing is the cause for these inconsistencies, developing methods to measure and compensate for them. We find ECMP routing significantly changes observed censorship across protocols, censor mechanisms, and in 17 countries. We identify that previously observed non-determinism or regional variations are attributable to measurements between fixed end-hosts taking different routes based on Flow-ID; i.e., choice of intra-subnet source IP or ephemeral source port leads to differences in observed censorship. To achieve this we develop new route-stable censorship measurement methods that allow consistent measurement of DNS, HTTP, and HTTPS censorship. We find ECMP routing yields censorship changes across 42% of IPs and 51% of ASes, but that impact is not uniform. We identify numerous causes of the behavior, ranging from likely failed infrastructure, to routes to the same end-host taking geographically diverse paths which experience differences in censorship en-route. Finally, we explore our results in the context of prior global measurement studies, exploring first the applicability of our findings to prior observed variations, and then demonstrating how specific experiments from two studies could be impacted by, and specific results are explainable by, ECMP routing. Our work points to methods for improving future studies, reducing inconsistencies and increasing repeatability.",
            "keywords": [
                "Internet Censorship",
                "Routing Mechanisms",
                "Equal-cost Multi-path (ECMP)",
                "Censorship Measurement",
                "Non-determinism in Censorship"
            ]
        },
        "url": "URL#256607",
        "sema_paperId": "7c8fc4ea9b9e1896b53b8ac67f04c9895384ead3"
    },
    {
        "@score": "1",
        "@id": "256608",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "346/3242",
                        "text": "Lorenzo Binosi"
                    },
                    {
                        "@pid": "386/4294",
                        "text": "Gregorio Barzasi"
                    },
                    {
                        "@pid": "145/1618",
                        "text": "Michele Carminati"
                    },
                    {
                        "@pid": "z/StefanoZanero",
                        "text": "Stefano Zanero"
                    },
                    {
                        "@pid": "163/9937",
                        "text": "Mario Polino"
                    }
                ]
            },
            "title": "The Illusion of Randomness: An Empirical Analysis of Address Space Layout Randomization Implementations.",
            "venue": "CCS",
            "pages": "1360-1374",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/BinosiBCZP24",
            "doi": "10.1145/3658644.3690239",
            "ee": "https://doi.org/10.1145/3658644.3690239",
            "url": "https://dblp.org/rec/conf/ccs/BinosiBCZP24",
            "abstract": "Address Space Layout Randomization (ASLR) is a crucial defense mechanism employed by modern operating systems to mitigate exploitation by randomizing processes' memory layouts. However, the stark reality is that real-world implementations of ASLR are imperfect and subject to weaknesses that attackers can exploit. This work evaluates the effectiveness of ASLR on major desktop platforms, including Linux, MacOS, and Windows, by examining the variability in the placement of memory objects across various processes, threads, and system restarts. In particular, we collect samples of memory object locations, conduct statistical analyses to measure the randomness of these placements and examine the memory layout to find any patterns among objects that could decrease this randomness. The results show that while some systems, like Linux distributions, provide robust randomization, others, like Windows and MacOS, often fail to adequately randomize key areas like executable code and libraries. Moreover, we find a significant entropy reduction in the entropy of libraries after the Linux 5.18 version and identify correlation paths that an attacker could leverage to reduce exploitation complexity significantly. Ultimately, we rank the identified weaknesses based on severity and validate our entropy estimates with a proof-of-concept attack. In brief, this paper provides the first comprehensive evaluation of ASLR effectiveness across different operating systems and highlights opportunities for Operating System (OS) vendors to strengthen ASLR implementations.",
            "keywords": [
                "Address Space Layout Randomization",
                "Memory Layout Randomization",
                "Operating System Security",
                "Entropy Reduction",
                "Exploitation Complexity"
            ]
        },
        "url": "URL#256608",
        "sema_paperId": "608609196410fc3496dc5929f2066792ef9e4e62"
    },
    {
        "@score": "1",
        "@id": "256609",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "86/8008",
                        "text": "Sam Blackshear"
                    },
                    {
                        "@pid": "263/7221",
                        "text": "Andrey Chursin"
                    },
                    {
                        "@pid": "11/1148",
                        "text": "George Danezis"
                    },
                    {
                        "@pid": "134/6580",
                        "text": "Anastasios Kichidis"
                    },
                    {
                        "@pid": "176/5301",
                        "text": "Lefteris Kokoris-Kogias"
                    },
                    {
                        "@pid": "32/6533-1",
                        "text": "Xun Li 0001"
                    },
                    {
                        "@pid": "84/3576",
                        "text": "Mark Logan"
                    },
                    {
                        "@pid": "359/6016",
                        "text": "Ashok Menon"
                    },
                    {
                        "@pid": "320/3713",
                        "text": "Todd Nowacki"
                    },
                    {
                        "@pid": "170/4315",
                        "text": "Alberto Sonnino"
                    },
                    {
                        "@pid": "189/1645",
                        "text": "Brandon Williams"
                    },
                    {
                        "@pid": "82/10609",
                        "text": "Lu Zhang"
                    }
                ]
            },
            "title": "Sui Lutris: A Blockchain Combining Broadcast and Consensus.",
            "venue": "CCS",
            "pages": "2606-2620",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/BlackshearCDKKL24",
            "doi": "10.1145/3658644.3670286",
            "ee": "https://doi.org/10.1145/3658644.3670286",
            "url": "https://dblp.org/rec/conf/ccs/BlackshearCDKKL24",
            "abstract": "Sui Lutris is the first smart-contract platform to sustainably achieve sub-second finality. It achieves this significant decrease by employing consensusless agreement not only for simple payments but for a large variety of transactions. Unlike prior work, Sui Lutris neither compromises expressiveness nor throughput and can run perpetually without restarts. Sui Lutris achieves this by safely integrating consensuless agreement with a high-throughput consensus protocol that is invoked out of the critical finality path but ensures that when a transaction is at risk of inconsistent concurrent accesses, its settlement is delayed until the total ordering is resolved. Building such a hybrid architecture is especially delicate during reconfiguration events, where the system needs to preserve the safety of the consensusless path without compromising the long-term liveness of potentially misconfigured clients. We thus develop a novel reconfiguration protocol, the first to provably show the safe and efficient reconfiguration of a consensusless blockchain. Sui Lutris is currently running in production and underpins the Sui smart-contract platform. Combined with the use of Objects instead of accounts it enables the safe execution of smart contracts that expose objects as a first-class resource. In our experiments Sui Lutris achieves latency lower than 0.5 seconds for throughput up to 5,000 certificates per second (150k ops/s with transaction blocks), compared to the state-of-the-art real-world consensus latencies of 3 seconds. Furthermore, it gracefully handles validators crash-recovery and does not suffer visible performance degradation during reconfiguration.",
            "pdf_url": "",
            "keywords": [
                "Blockchain Technology",
                "Smart Contracts",
                "Consensus Mechanisms",
                "Finality",
                "Reconfiguration Protocol"
            ]
        },
        "url": "URL#256609"
    },
    {
        "@score": "1",
        "@id": "256610",
        "info": {
            "authors": {
                "author": {
                    "@pid": "b/DanBoneh",
                    "text": "Dan Boneh"
                }
            },
            "title": "Cryptography and Computer Security: A View From the Year 2100.",
            "venue": "CCS",
            "pages": "1",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Boneh24",
            "doi": "10.1145/3658644.3690378",
            "ee": "https://doi.org/10.1145/3658644.3690378",
            "url": "https://dblp.org/rec/conf/ccs/Boneh24",
            "abstract": "What will computer security look like in the year 2100? This talk will begin with a few predictions that aim to suggest a few research directions in the present. We will then transition to the exciting area of applied zero knowledge proofs, an area that has seen tremendous growth in recent years. We will describe some of the new ideas in the space and focus on a number of remarkable real-word applications of these techniques. The talk will be self contained and accessible to all.",
            "pdf_url": "",
            "keywords": [
                "Cryptography",
                "Computer Security",
                "Zero Knowledge Proofs",
                "Applied Cryptography",
                "Real-World Applications"
            ]
        },
        "url": "URL#256610",
        "sema_paperId": "7a68cbc789c01b799cc2269bafb10921e0be7696"
    },
    {
        "@score": "1",
        "@id": "256611",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "392/3134",
                        "text": "Huan Bui"
                    },
                    {
                        "@pid": "392/3118",
                        "text": "Harper Lienerth"
                    },
                    {
                        "@pid": "58/2521-2",
                        "text": "Chenglong Fu 0002"
                    },
                    {
                        "@pid": "74/7731",
                        "text": "Meera Sridhar"
                    }
                ]
            },
            "title": "Poster: TAPChecker: Model Checking in Trigger-Action Rules Generation Using Large Language Models.",
            "venue": "CCS",
            "pages": "4994-4996",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/BuiL0S24",
            "doi": "10.1145/3658644.3691416",
            "ee": "https://doi.org/10.1145/3658644.3691416",
            "url": "https://dblp.org/rec/conf/ccs/BuiL0S24",
            "abstract": "The integration of large language models (LLMs) in smart home systems holds significant promise for automating the generation of Trigger-Action Programming (TAP) rules, potentially streamlining smart home user experiences and enhancing convenience. However, LLMs lack of holistic view of smart home IoT deployments and may introduce TAP rules that result in hazards. This paper explores the application of LLM for generating TAP rules and applying formal verification to validate and ensure the safety of TAP rules generated by LLMs. By systematically analyzing and verifying these rules, we aim to identify and mitigate potential security vulnerabilities. Furthermore, we propose a feedback mechanism to refine the LLM's output, enhancing its reliability and safety in generating automation rules. Through this approach, we seek to bridge the gap between the efficiency of LLMs and the stringent security requirements of smart IoT systems, fostering a safer automation environment.",
            "pdf_url": "",
            "keywords": [
                "Smart Home Automation",
                "Trigger-Action Programming",
                "Formal Verification",
                "Security Vulnerabilities",
                "Large Language Models"
            ]
        },
        "url": "URL#256611",
        "sema_paperId": "823e60b9527c9f53d1dc1a98f020ae853585c677"
    },
    {
        "@score": "1",
        "@id": "256612",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "382/0039",
                        "text": "Alexander Burton"
                    },
                    {
                        "@pid": "318/5022",
                        "text": "Samir Jordan Menon"
                    },
                    {
                        "@pid": "32/10400-1",
                        "text": "David J. Wu 0001"
                    }
                ]
            },
            "title": "Respire: High-Rate PIR for Databases with Small Records.",
            "venue": "CCS",
            "pages": "1463-1477",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/BurtonM024",
            "doi": "10.1145/3658644.3690328",
            "ee": "https://doi.org/10.1145/3658644.3690328",
            "url": "https://dblp.org/rec/conf/ccs/BurtonM024",
            "abstract": "Private information retrieval (PIR) is a key building block in many privacy-preserving systems, and recent works have made significant progress on reducing the concrete computational costs of single-server PIR. However, existing constructions have high communication overhead, especially for databases with small records. In this work, we introduce Respire, a lattice-based PIR scheme tailored for databases of small records. To retrieve a single record from a database with over a million 256-byte records, the Respire protocol requires just 6.1 KB of online communication; this is a 5.9x reduction compared to the best previous lattice-based scheme. Moreover, Respire naturally extends to support batch queries. Compared to previous communication-efficient batch PIR schemes, Respire achieves a 3.4-7.1x reduction in total communication while maintaining comparable throughput (200-400 MB/s). The design of Respire relies on new query compression and response packing techniques based on ring switching in homomorphic encryption.",
            "pdf_url": "",
            "keywords": [
                "Private Information Retrieval",
                "Lattice-based Cryptography",
                "Communication Efficiency",
                "Batch Queries",
                "Small Record Databases"
            ]
        },
        "url": "URL#256612"
    },
    {
        "@score": "1",
        "@id": "256613",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "392/3164",
                        "text": "Louis Cattepoel"
                    },
                    {
                        "@pid": "248/0549",
                        "text": "Donika Mirdita"
                    },
                    {
                        "@pid": "94/7397",
                        "text": "Haya Schulmann"
                    },
                    {
                        "@pid": "90/308",
                        "text": "Michael Waidner"
                    }
                ]
            },
            "title": "Poster: Kill Krill or Proxy RPKI.",
            "venue": "CCS",
            "pages": "4922-4924",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/CattepoelMSW24",
            "doi": "10.1145/3658644.3691390",
            "ee": "https://doi.org/10.1145/3658644.3691390",
            "url": "https://dblp.org/rec/conf/ccs/CattepoelMSW24",
            "abstract": "Resource Public Key Infrastructure (RPKI), designed to protect Internet routing from hijacks, is gaining traction: over 50% of prefixes have digital certificates, at least 27% of Autonomous Systems actively validate certificates against BGP announcements, and filter invalid routing announcements. In this study, we present the first security analysis of Krill, the only public and open-source RPKI publication point software. Publication points are hosted by the five Regional Internet Registries across the globe, or by independent Internet operators that wish to manage their own RPKI repositories.",
            "pdf_url": "",
            "keywords": [
                "Resource Public Key Infrastructure (RPKI)",
                "Internet Routing Security",
                "Krill Software",
                "Routing Hijacks",
                "BGP Validation"
            ]
        },
        "url": "URL#256613",
        "sema_paperId": "37c2f13ff8c8fa11a772d7f9cfcf5c9c94b0129b"
    },
    {
        "@score": "1",
        "@id": "256614",
        "info": {
            "authors": {
                "author": {
                    "@pid": "322/1174",
                    "text": "Adam Caulfield"
                }
            },
            "title": "Towards Secure Runtime Auditing of Remote Embedded System Software.",
            "venue": "CCS",
            "pages": "5092-5094",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Caulfield24",
            "doi": "10.1145/3658644.3690856",
            "ee": "https://doi.org/10.1145/3658644.3690856",
            "url": "https://dblp.org/rec/conf/ccs/Caulfield24",
            "abstract": "Low-cost and energy-efficient microcontroller units (MCUs) increasingly perform critical tasks at the edge of modern systems despite their inherent vulnerabilities. To assess their security in remote deployments, Control Flow Attestation (CFA) offers a technique for a Verifier (Vrf) to remotely detect attacks that illegally alter the software or the runtime behavior of a Prover MCU (Prv) by producing a log of all control flow transfers during task execution (CFLog). Current CFA techniques cannot ensure Vrf receives CFLogfrom a compromised Prv, allowing it to ignore CFA requests and preventing Vrf vulnerability analysis. This dissertation proposal introduces architectures to achieve runtime auditing, guaranteeing the delivery of runtime evidence and enabling Vrf to remediate detected compromises. The first approach uses a hardware-software co-design, and the second approach leverages Trusted Execution Environments (TEEs) to provide the same guarantees without hardware modifications. Future work will focus on further challenges, such as enabling application-specific storage/latency optimizations and automated vulnerability analysis of runtime evidence.",
            "pdf_url": "",
            "keywords": [
                "Embedded System Security",
                "Control Flow Attestation",
                "Runtime Auditing",
                "Microcontroller Vulnerabilities",
                "Trusted Execution Environments (TEEs)"
            ]
        },
        "url": "URL#256614",
        "sema_paperId": "9b5e0125814d84925fd00b6ac2f0d729c5172d1e"
    },
    {
        "@score": "1",
        "@id": "256615",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "272/8141",
                        "text": "Katharina Ceesay-Seitz"
                    },
                    {
                        "@pid": "264/9973",
                        "text": "Flavien Solt"
                    },
                    {
                        "@pid": "121/2685",
                        "text": "Kaveh Razavi"
                    }
                ]
            },
            "title": "\u03bcCFI: Formal Verification of Microarchitectural Control-flow Integrity.",
            "venue": "CCS",
            "pages": "213-227",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Ceesay-SeitzSR24",
            "doi": "10.1145/3658644.3690344",
            "ee": "https://doi.org/10.1145/3658644.3690344",
            "url": "https://dblp.org/rec/conf/ccs/Ceesay-SeitzSR24",
            "abstract": "Formal verification of hardware often requires the creation of clock-cycle accurate properties that need tedious and error-prone adaptations for each design. Property violations further require attention from verification engineers to identify affected instructions. This oftentimes manual effort hinders the adoption of formal verification at scale. This paper introduces Microarchitectural Control-Flow Integrity (\u03bcCFI), a new general security property that can capture multiple classes of vulnerabilities under different threat models, most notably the microarchitectural violation of constant-time execution and (micro-)architectural vulnerabilities that allow an attacker to hijack the (architectural) control flow. We show a novel approach for the verification of \u03bcCFI using a single property that checks for information flows from instruction operands to the program counter by injecting taint at appropriate clock cycles. To check arbitrary sequences of instructions and associate property violations to a specific Instruction Under Verification (IUV), we propose techniques for declassifying tainted data when it is being written to registers and forwarded from the IUV through architecturally known paths. We show that our verification approach is low effort (e.g., requires tagging six signals) while capturing all interactions between unbounded sequences of instructions in the extended threat model of \u00f8urname. We verify four RISC-V CPUs against \u03bcCFI and prove that \u03bcCFI is satisfied in many cases while detecting five new security vulnerabilities (4 CVEs), three of which are in Ibex, which has already been checked by state-of-the-art verification approaches.",
            "pdf_url": "",
            "keywords": [
                "Microarchitectural Control-Flow Integrity",
                "Formal Verification",
                "RISC-V CPUs",
                "Security Vulnerabilities",
                "Information Flow Verification"
            ]
        },
        "url": "URL#256615",
        "sema_paperId": "5bc26f629cc42782a1d81df5ca4e82c6963743cf"
    },
    {
        "@score": "1",
        "@id": "256616",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "296/2589",
                        "text": "Sof\u00eda Celi"
                    },
                    {
                        "@pid": "177/2253",
                        "text": "Alex Davidson"
                    }
                ]
            },
            "title": "Call Me By My Name: Simple, Practical Private Information Retrieval for Keyword Queries.",
            "venue": "CCS",
            "pages": "4107-4121",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/CeliD24",
            "doi": "10.1145/3658644.3670271",
            "ee": "https://doi.org/10.1145/3658644.3670271",
            "url": "https://dblp.org/rec/conf/ccs/CeliD24",
            "abstract": "We introduce ChalametPIR: a single-server Private Information Retrieval (PIR) scheme supporting fast, low-bandwidthkeywordqueries, with a conceptually very simple design. In particular, we develop a generic framework for converting PIR schemes for index queries over flat arrays (based on the Learning With Errors problem) into keyword PIR. This involves representing a key-value map using any probabilistic filter that permits reconstruction of elements from inclusion queries (e.g. Cuckoo filters). In particular, we make use of recently developedBinary Fuse filtersto construct ChalametPIR, with minimal efficiency blow-up compared with state-of-the-art index-based schemes (all costs bounded by a factor of (\u2264 1.08)). Furthermore, we show that ChalametPIR achieves runtimes and financial costs that are factors of between (6x)-(11x) and (3.75x)-(11.4x) more efficient, respectively, than state-of-the-art keyword PIR approaches, for varying database configurations. Bandwidth costs are additionally reduced or remain competitive, depending on the configuration. Finally, we believe that our application of Binary Fuse filters can have independent value towards developing efficient variants of related cryptographic primitives (e.g. private set intersection), that already benefit from using less efficient filter constructions.",
            "pdf_url": "",
            "keywords": [
                "Private Information Retrieval",
                "Keyword Queries",
                "Binary Fuse Filters",
                "Efficiency",
                "Low-bandwidth"
            ]
        },
        "url": "URL#256616"
    },
    {
        "@score": "1",
        "@id": "256617",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "122/7958",
                        "text": "Yuan Chang"
                    },
                    {
                        "@pid": "20/11184",
                        "text": "Chun-Chia Huang"
                    },
                    {
                        "@pid": "62/6630",
                        "text": "Tatsuya Mori"
                    },
                    {
                        "@pid": "59/7124",
                        "text": "Hsu-Chun Hsiao"
                    }
                ]
            },
            "title": "Poster: YFuzz: Data-Driven Fuzzing.",
            "venue": "CCS",
            "pages": "4958-4960",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ChangHMH24",
            "doi": "10.1145/3658644.3691420",
            "ee": "https://doi.org/10.1145/3658644.3691420",
            "url": "https://dblp.org/rec/conf/ccs/ChangHMH24",
            "abstract": "Code coverage is an effective objective for guiding fuzzers to explore code and identify bugs, and it has been a key factor in the success of greybox fuzzing. However, code coverage has a critical limitation: coverage-guided fuzzers can miss bugs even when the associated code is covered. This limitation arises because merely executing the associated code is often insufficient to trigger a bug; specific conditions are usually also required. These conditions are not fully captured by code coverage, which focuses only on whether the code was executed. To address this problem, we propose a new objective: value state coverage, an additional dimension in coverage metrics that is orthogonal to code coverage. Value state is a combination of the values assigned to program variables and the order of their assignment, and by measuring the coverage of value states, we can guide a fuzzer to explore the triggering conditions of bugs. We also introduce Data-Driven Fuzzing , a novel fuzzing technique that focuses on value state coverage, and utilizes security-related variables, mutation strategies, and extreme values captured at run-time to effectively discover bugs. We implemented our approach in a prototype fuzzer named YFuzz . YFuzz has found 12 bugs in programs included in the OSS-Fuzz project, including 4 assigned CVEs, indicating that our approach is effective in finding bugs.",
            "keywords": [
                "Fuzzing",
                "Value State Coverage",
                "Code Coverage Limitations",
                "Bug Discovery",
                "Data-Driven Fuzzing"
            ]
        },
        "url": "URL#256617",
        "sema_paperId": "ef0fa9167d545a4e7f4e503cb605609b7a6a7f8c"
    },
    {
        "@score": "1",
        "@id": "256618",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "245/4979",
                        "text": "Sylvain Chatel"
                    },
                    {
                        "@pid": "325/5407",
                        "text": "Christian Knabenhans"
                    },
                    {
                        "@pid": "66/7821",
                        "text": "Apostolos Pyrgelis"
                    },
                    {
                        "@pid": "01/4825",
                        "text": "Carmela Troncoso"
                    },
                    {
                        "@pid": "h/JPHubaux",
                        "text": "Jean-Pierre Hubaux"
                    }
                ]
            },
            "title": "VERITAS: Plaintext Encoders for Practical Verifiable Homomorphic Encryption.",
            "venue": "CCS",
            "pages": "2520-2534",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ChatelKPTH24",
            "doi": "10.1145/3658644.3670282",
            "ee": "https://doi.org/10.1145/3658644.3670282",
            "url": "https://dblp.org/rec/conf/ccs/ChatelKPTH24",
            "abstract": "Homomorphic encryption has become a practical solution for protecting the privacy of computations on sensitive data. However, existing homomorphic encryption pipelines do not guarantee the correctness of the computation result in the presence of a malicious adversary. We propose two plaintext encodings compatible with state-of-the-art fully homomorphic encryption schemes that enable practical client-verification of homomorphic computations while supporting all the operations required for modern privacy-preserving analytics. Based on these encodings, we introduce VERITAS, a ready-to-use library for the verification of computations executed over encrypted data. VERITAS is the first library that supports the verification of any homomorphic operation. We demonstrate its practicality for various applications and, in particular, we show that it enables verifiability of homomorphic analytics with less than 3x computation overhead compared to the homomorphic encryption baseline.",
            "pdf_url": "",
            "keywords": [
                "Homomorphic Encryption",
                "Verifiable Computation",
                "Client Verification",
                "Privacy-Preserving Analytics",
                "Computation Overhead"
            ]
        },
        "url": "URL#256618",
        "sema_paperId": "3c1c4bd332219118d17be33d571630e8b441ef37"
    },
    {
        "@score": "1",
        "@id": "256619",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "353/7618",
                        "text": "Xijia Che"
                    },
                    {
                        "@pid": "65/425",
                        "text": "Yi He"
                    },
                    {
                        "@pid": "53/8376",
                        "text": "Xuewei Feng"
                    },
                    {
                        "@pid": "30/3530-1",
                        "text": "Kun Sun 0001"
                    },
                    {
                        "@pid": "181/2626-2",
                        "text": "Ke Xu 0002"
                    },
                    {
                        "@pid": "181/2688-2",
                        "text": "Qi Li 0002"
                    }
                ]
            },
            "title": "BlueSWAT: A Lightweight State-Aware Security Framework for Bluetooth Low Energy.",
            "venue": "CCS",
            "pages": "2087-2101",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/CheHF0XL24",
            "doi": "10.1145/3658644.3670397",
            "ee": "https://doi.org/10.1145/3658644.3670397",
            "url": "https://dblp.org/rec/conf/ccs/CheHF0XL24",
            "abstract": "Bluetooth Low Energy (BLE) is a short-range wireless communication technology for resource-constrained IoT devices. Unfortunately, BLE is vulnerable to session-based attacks, where previous packets construct exploitable conditions for subsequent packets to compromise connections. Defending against session-based attacks is challenging because each step in the attack sequence is legitimate when inspected individually. In this paper, we present BlueSWAT, a lightweight state-aware security framework for protecting BLE devices. To perform inspection on the session level rather than individual packets, BlueSWAT leverages a finite state machine (FSM) to monitor sequential actions of connections at runtime. Patterns of session-based attacks are modeled as malicious transition paths in the FSM. To overcome the heterogeneous IoT environment, we develop a lightweight eBPF framework to facilitate universal patch distribution across different BLE architectures and stacks, without requiring device reboot. We implement BlueSWAT on 5 real-world devices with different chips and stacks to demonstrate its cross-device adaptability. On our dataset with 101 real-world BLE vulnerabilities, BlueSWAT can mitigate 76.1% of session-based attacks, outperforming other defense frameworks. In our end-to-end application evaluation, BlueSWAT patches introduce an average of 0.073% memory overhead and negligible latency.",
            "keywords": [
                "Bluetooth Low Energy",
                "IoT Security",
                "Session-Based Attacks",
                "Finite State Machine",
                "eBPF Framework"
            ]
        },
        "url": "URL#256619",
        "sema_paperId": "d813e4f7bf6ba79b9914566ed7c697cbc03bbab2"
    },
    {
        "@score": "1",
        "@id": "256620",
        "info": {
            "authors": {
                "author": {
                    "@pid": "26/9777",
                    "text": "Mingming Chen"
                }
            },
            "title": "Evolving Network Security in the Era of Network Programmability.",
            "venue": "CCS",
            "pages": "5101-5103",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Chen24",
            "doi": "10.1145/3658644.3690859",
            "ee": "https://doi.org/10.1145/3658644.3690859",
            "url": "https://dblp.org/rec/conf/ccs/Chen24",
            "abstract": "Software-defined networking (SDN) is a centralized network architecture enabling dynamic, programmable, and flexible network management, which advances technologies like network security. However, it also introduces new vulnerabilities due to the segregation of data, control, and application planes, creating additional attack surfaces and security gaps from the increased complexity of programmability, flexibility, and scalability.",
            "pdf_url": "",
            "keywords": [
                "Software-Defined Networking (SDN)",
                "Network Programmability",
                "Network Security Vulnerabilities",
                "Attack Surfaces",
                "Control Plane Segregation"
            ]
        },
        "url": "URL#256620",
        "sema_paperId": "820f4a4da40d3c04f2dc98603ad3e4e8b346154e"
    },
    {
        "@score": "1",
        "@id": "256621",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "76/6411",
                        "text": "Peter Chen"
                    },
                    {
                        "@pid": "02/8772",
                        "text": "Guannan Liu"
                    },
                    {
                        "@pid": "81/4036-1",
                        "text": "Haining Wang 0001"
                    }
                ]
            },
            "title": "Poster: Acoustic Side-Channel Attack on Robot Vacuums.",
            "venue": "CCS",
            "pages": "5027-5029",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ChenL024",
            "doi": "10.1145/3658644.3691372",
            "ee": "https://doi.org/10.1145/3658644.3691372",
            "url": "https://dblp.org/rec/conf/ccs/ChenL024",
            "abstract": "Robot vacuums have become a ubiquitous appliance, offering un- paralleled convenience and efficiency in maintaining cleanliness in both residential and commercial spaces. However, these devices also present a convenient method for attackers to gather information about the robot's surroundings. In this study, we investigate the feasibility of acoustic side-channel attacks on robot vacuums and demonstrate that sensitive information can be easily obtained by analyzing the sound produced by the robot. We extract various characteristic features and spectrograms from the sound emitted during robot movement and classify them using Multilayer Perception and Convolutional Neural Network. The evaluation results demonstrate the effectiveness of the acoustic attacks, with both machine learning models achieving more than 95% accuracy in classifying the robot's movement based on acoustic signals. Using our ML model, we demonstrate that robot cleaning path can be effectively identified with 96% accuracy. To mitigate such a threat, we perform a simulation where random noise is added to the sound samples, which effectively reduce the motion identification accuracy to 43%.",
            "pdf_url": "",
            "keywords": [
                "Acoustic Side-Channel Attack",
                "Robot Vacuums",
                "Information Leakage",
                "Sound Analysis",
                "Motion Identification"
            ]
        },
        "url": "URL#256621",
        "sema_paperId": "52a99959af779b8b11441ba65fc7bf317908e83d"
    },
    {
        "@score": "1",
        "@id": "256622",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "26/9777",
                        "text": "Mingming Chen"
                    },
                    {
                        "@pid": "l/TomLaPorta",
                        "text": "Thomas La Porta"
                    },
                    {
                        "@pid": "124/0389",
                        "text": "Teryl Taylor"
                    },
                    {
                        "@pid": "126/9907",
                        "text": "Frederico Araujo"
                    },
                    {
                        "@pid": "45/576",
                        "text": "Trent Jaeger"
                    }
                ]
            },
            "title": "Manipulating OpenFlow Link Discovery Packet Forwarding for Topology Poisoning.",
            "venue": "CCS",
            "pages": "3704-3718",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ChenPTAJ24",
            "doi": "10.1145/3658644.3690345",
            "ee": "https://doi.org/10.1145/3658644.3690345",
            "url": "https://dblp.org/rec/conf/ccs/ChenPTAJ24",
            "abstract": "Software-defined networking (SDN) is a centralized, dynamic, and programmable network management technology that enables flexible traffic control and scalability. SDN facilitates network administration through a centralized view of the underlying physical topology; tampering with this topology view can result in catastrophic damage to network management and security. To underscore this issue, we introduce Marionette, a new topology poisoning technique that manipulates OpenFlow link discovery packet forwarding to alter topology information. Our approach exposes an overlooked yet widespread attack vector, distinguishing itself from traditional link fabrication attacks that tamper, spoof, or relay discovery packets at the data plane. Unlike localized attacks observed in existing methods, our technique introduces a globalized topology poisoning attack that leverages control privileges. Marionette implements a reinforcement learning algorithm to compute a poisoned topology target, and injects flow entries to achieve a long-lived stealthy attack. Our evaluation shows that Marionette successfully attacks five open-source controllers and nine OpenFlow-based discovery protocols. Marionette overcomes the state-of-the-art topology poisoning defenses, showcasing a new class of topology poisoning that initiates on the control plane. This security vulnerability was ethically disclosed to OpenDaylight, and CVE-2024-37018 has been assigned.",
            "keywords": [
                "Software-Defined Networking",
                "Topology Poisoning",
                "OpenFlow Protocol",
                "Link Discovery Manipulation",
                "Control Plane Attack"
            ]
        },
        "url": "URL#256622",
        "sema_paperId": "e959994e54d3c59378e4500ea5f0669df780147c"
    },
    {
        "@score": "1",
        "@id": "256623",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "307/6373",
                        "text": "Guanzhong Chen"
                    },
                    {
                        "@pid": "375/5949",
                        "text": "Zhenghan Qin"
                    },
                    {
                        "@pid": "28/4785",
                        "text": "Mingxin Yang"
                    },
                    {
                        "@pid": "20/770",
                        "text": "Yajie Zhou"
                    },
                    {
                        "@pid": "06/7732",
                        "text": "Tao Fan"
                    },
                    {
                        "@pid": "128/2982",
                        "text": "Tianyu Du"
                    },
                    {
                        "@pid": "68/1538",
                        "text": "Zenglin Xu"
                    }
                ]
            },
            "title": "Unveiling the Vulnerability of Private Fine-Tuning in Split-Based Frameworks for Large Language Models: A Bidirectionally Enhanced Attack.",
            "venue": "CCS",
            "pages": "2904-2918",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ChenQYZFDX24",
            "doi": "10.1145/3658644.3690295",
            "ee": "https://doi.org/10.1145/3658644.3690295",
            "url": "https://dblp.org/rec/conf/ccs/ChenQYZFDX24",
            "abstract": "Recent advancements in pre-trained large language models (LLMs) have significantly influenced various domains. Adapting these models for specific tasks often involves fine-tuning (FT) with private, domain-specific data. However, privacy concerns keep this data undisclosed, and the computational demands for deploying LLMs pose challenges for resource-limited data holders. This has sparked interest in split learning (SL), a Model-as-a-Service (MaaS) paradigm that divides LLMs into smaller segments for distributed training and deployment, transmitting only intermediate activations instead of raw data. SL has garnered substantial interest in both industry and academia as it aims to balance user data privacy, model ownership, and resource challenges in the private fine-tuning of LLMs. Despite its privacy claims, this paper reveals significant vulnerabilities arising from the combination of SL and LLM-FT:the Not-too-far property of fine-tuningandthe auto-regressive nature of LLMs.Exploiting these vulnerabilities, we propose Bidirectional Semi-white-box Reconstruction (BiSR), the first data reconstruction attack (DRA) designed to target both the forward and backward propagation processes of SL. BiSR utilizes pre-trained weights as prior knowledge, combining a learning-based attack with a bidirectional optimization-based approach for highly effective data reconstruction. Additionally, it incorporates a Noise-adaptive Mixture of Experts (NaMoE) model to enhance reconstruction performance under perturbation. We conducted systematic experiments on various mainstream LLMs and different setups, empirically demonstrating BiSR's state-of-the-art performance. Furthermore, we thoroughly examined three representative defense mechanisms, showcasing our method's capability to reconstruct private data even in the presence of these defenses.",
            "pdf_url": "",
            "keywords": [
                "Split Learning",
                "Large Language Models",
                "Private Fine-Tuning",
                "Data Reconstruction Attack",
                "Bidirectional Semi-white-box Reconstruction (BiSR)"
            ]
        },
        "url": "URL#256623"
    },
    {
        "@score": "1",
        "@id": "256624",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "55/2712",
                        "text": "Xiaoyi Chen"
                    },
                    {
                        "@pid": "44/10369",
                        "text": "Siyuan Tang"
                    },
                    {
                        "@pid": "72/1974",
                        "text": "Rui Zhu"
                    },
                    {
                        "@pid": "71/10892",
                        "text": "Shijun Yan"
                    },
                    {
                        "@pid": "59/3349",
                        "text": "Lei Jin"
                    },
                    {
                        "@pid": "148/9655",
                        "text": "Zihao Wang"
                    },
                    {
                        "@pid": "214/2382",
                        "text": "Liya Su"
                    },
                    {
                        "@pid": "90/545-1",
                        "text": "Zhikun Zhang 0001"
                    },
                    {
                        "@pid": "06/6268",
                        "text": "Xiaofeng Wang 0006"
                    },
                    {
                        "@pid": "90/3951",
                        "text": "Haixu Tang"
                    }
                ]
            },
            "title": "The Janus Interface: How Fine-Tuning in Large Language Models Amplifies the Privacy Risks.",
            "venue": "CCS",
            "pages": "1285-1299",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ChenTZYJWSZWT24",
            "doi": "10.1145/3658644.3690325",
            "ee": "https://doi.org/10.1145/3658644.3690325",
            "url": "https://dblp.org/rec/conf/ccs/ChenTZYJWSZWT24",
            "abstract": "The rapid advancements of large language models (LLMs) have raised public concerns about the privacy leakage of personally identifiable information (PII) within their extensive training datasets. Recent studies have demonstrated that an adversary could extract highly sensitive privacy data from the training data of LLMs with carefully designed prompts. However, these attacks suffer from the model's tendency to hallucinate and catastrophic forgetting (CF) in the pre-training stage, rendering the veracity of divulged PIIs negligible. In our research, we propose a novel attack, Janus, which exploits the fine-tuning interface to recover forgotten PIIs from the pre-training data in LLMs. We formalize the privacy leakage problem in LLMs and explain why forgotten PIIs can be recovered through empirical analysis on open-source language models. Based upon these insights, we evaluate the performance of Janus on both open-source language models and two latest LLMs, i.e., GPT-3.5-Turbo and LLaMA-2-7b. Our experiment results show that Janus amplifies the privacy risks by over 10 times in comparison with the baseline and significantly outperforms the state-of-the-art privacy extraction attacks including prefix attacks and in-context learning (ICL). Furthermore, our analysis validates that existing fine-tuning APIs provided by OpenAI and Azure AI Studio are susceptible to our Janus attack, allowing an adversary to conduct such an attack at a low cost.",
            "keywords": [
                "Large Language Models",
                "Privacy Leakage",
                "Fine-Tuning",
                "PII Recovery",
                "Janus Attack"
            ]
        },
        "url": "URL#256624",
        "sema_paperId": "33f6b9aa455a8563252b242cb575705e782958f0"
    },
    {
        "@score": "1",
        "@id": "256625",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "64/5207",
                        "text": "Jung Hee Cheon"
                    },
                    {
                        "@pid": "239/8871",
                        "text": "Hyeongmin Choe"
                    },
                    {
                        "@pid": "148/1467",
                        "text": "Alain Passel\u00e8gue"
                    },
                    {
                        "@pid": "03/2822",
                        "text": "Damien Stehl\u00e9"
                    },
                    {
                        "@pid": "368/7367",
                        "text": "Elias Suvanto"
                    }
                ]
            },
            "title": "Attacks Against the IND-CPAD Security of Exact FHE Schemes.",
            "venue": "CCS",
            "pages": "2505-2519",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/CheonCPSS24",
            "doi": "10.1145/3658644.3690341",
            "ee": "https://doi.org/10.1145/3658644.3690341",
            "url": "https://dblp.org/rec/conf/ccs/CheonCPSS24",
            "abstract": "A recent security model for fully homomorphic encryption (FHE), called IND-CPADsecurity and introduced by Li and Micciancio [Eurocrypt'21], strengthens IND-CPA security by giving the attacker access to a decryption oracle for ciphertexts for which it should know the underlying plaintexts. This includes ciphertexts that it (honestly) encrypted and those obtained from the latter by evaluating circuits that it chose. Li and Micciancio singled out the CKKS FHE scheme for approximate data [Asiacrypt'17] by giving an IND-CPADattack on it and claiming that IND-CPA security and IND-CPADsecurity coincide for exact FHE schemes.",
            "pdf_url": "",
            "keywords": [
                "Fully Homomorphic Encryption",
                "IND-CPAD Security",
                "Exact FHE Schemes",
                "Decryption Oracle",
                "Security Model"
            ]
        },
        "url": "URL#256625"
    },
    {
        "@score": "1",
        "@id": "256626",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "61/1937",
                        "text": "C\u00e9line Chevalier"
                    },
                    {
                        "@pid": "350/5826",
                        "text": "Guirec Lebrun"
                    },
                    {
                        "@pid": "71/9245",
                        "text": "Ange Martinelli"
                    },
                    {
                        "@pid": "267/7955",
                        "text": "Abdul Rahman Taleb"
                    }
                ]
            },
            "title": "Quarantined-TreeKEM: A Continuous Group Key Agreement for MLS, Secure in Presence of Inactive Users.",
            "venue": "CCS",
            "pages": "2400-2414",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ChevalierLMT24",
            "doi": "10.1145/3658644.3690265",
            "ee": "https://doi.org/10.1145/3658644.3690265",
            "url": "https://dblp.org/rec/conf/ccs/ChevalierLMT24",
            "abstract": "The recently standardized secure group messaging protocol Messaging Layer Security (MLS) is designed to ensure asynchronous communications within large groups, with an almost-optimal communication cost and the same security level as point-to-point secure messaging protocols such as Signal. In particular, the core sub-protocol of MLS, a Continuous Group Key Agreement (CGKA) called TreeKEM, must generate a common group key that respects the fundamental security properties of post-compromise security and forward secrecy which mitigate the effects of user corruption over time",
            "pdf_url": "",
            "keywords": [
                "Messaging Layer Security (MLS)",
                "Continuous Group Key Agreement",
                "TreeKEM",
                "Post-Compromise Security",
                "Forward Secrecy"
            ]
        },
        "url": "URL#256626"
    },
    {
        "@score": "1",
        "@id": "256627",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "80/752",
                        "text": "Kevin Childs"
                    },
                    {
                        "@pid": "304/8162",
                        "text": "Cassidy Gibson"
                    },
                    {
                        "@pid": "392/3053",
                        "text": "Anna Crowder"
                    },
                    {
                        "@pid": "250/9724",
                        "text": "Kevin Warren"
                    },
                    {
                        "@pid": "361/0817",
                        "text": "Carson Stillman"
                    },
                    {
                        "@pid": "141/9244",
                        "text": "Elissa M. Redmiles"
                    },
                    {
                        "@pid": "17/8357",
                        "text": "Eakta Jain"
                    },
                    {
                        "@pid": "14/3295",
                        "text": "Patrick Traynor"
                    },
                    {
                        "@pid": "82/1935",
                        "text": "Kevin R. B. Butler"
                    }
                ]
            },
            "title": "&quot;I Had Sort of a Sense that I Was Always Being Watched...Since I Was&quot;: Examining Interpersonal Discomfort From Continuous Location-Sharing Applications.",
            "venue": "CCS",
            "pages": "4197-4211",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ChildsGCWSRJTB24",
            "doi": "10.1145/3658644.3690342",
            "ee": "https://doi.org/10.1145/3658644.3690342",
            "url": "https://dblp.org/rec/conf/ccs/ChildsGCWSRJTB24",
            "abstract": "Continuous location sharing (CLS) applications are widely used for safety and social convenience. However, these applications have privacy concerns that can be used for control and harm. To understand user concerns, we performed the largest user study of CLS application usage performed to date, with 1500 of 3000 users indicating they use CLS applications and 896 of these users completing surveys. From survey responses, we conducted 23 interviews with participants who had uncomfortable experiences. With these interviews, we perform thematic analysis grounded by sociological frameworks of power dynamics and social exchange theory. We observe that CLS application users face discomfort related to three primary categories that build on each other: (1) overstepped boundaries, (2) continued discomfort, and (3) lifestyle-impacting behaviors. With this foundational understanding, we suggest features that aim to reduce relationship imbalances that CLS applications enable. Our resulting study demonstrates that CLS applications contribute to interpersonal discomfort, highlighting the need for design changes.",
            "pdf_url": "",
            "keywords": [
                "Continuous Location Sharing",
                "User Privacy",
                "Interpersonal Discomfort",
                "Power Dynamics",
                "Social Exchange Theory"
            ]
        },
        "url": "URL#256627",
        "sema_paperId": "f21c4088a6ae87ce75680a814b8bcb2445b7e895"
    },
    {
        "@score": "1",
        "@id": "256628",
        "info": {
            "authors": {
                "author": {
                    "@pid": "239/8871",
                    "text": "Hyeongmin Choe"
                }
            },
            "title": "Toward Practical Threshold FHE: Low Communication, Computation and Interaction.",
            "venue": "CCS",
            "pages": "5107-5109",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Choe24",
            "doi": "10.1145/3658644.3690861",
            "ee": "https://doi.org/10.1145/3658644.3690861",
            "url": "https://dblp.org/rec/conf/ccs/Choe24",
            "abstract": "Fully Homomorphic Encryption (FHE) is a promising primitive for evaluating arbitrary circuits while maintaining the user's privacy with an optimal round of communications. However, extending FHE to Threshold FHE and transitioning from two-party to multi-party settings presents some challenges, such as distributed key generation or decryption. When focusing on distributed decryption, it requires an exponentially large ciphertext modulus, which degrades communication efficiency.",
            "pdf_url": "",
            "keywords": [
                "Fully Homomorphic Encryption",
                "Threshold FHE",
                "Distributed Decryption",
                "Ciphertext Modulus",
                "Communication Efficiency"
            ]
        },
        "url": "URL#256628",
        "sema_paperId": "b97154d3ac9dde40771df1cedd891cb8628971dc"
    },
    {
        "@score": "1",
        "@id": "256629",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "392/3189",
                        "text": "Zander Chown"
                    },
                    {
                        "@pid": "56/11081",
                        "text": "Aarathi Prasad"
                    }
                ]
            },
            "title": "Poster: Privacy Norms for Fertility Data in the Roe v. Wade era.",
            "venue": "CCS",
            "pages": "4919-4921",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ChownP24",
            "doi": "10.1145/3658644.3691406",
            "ee": "https://doi.org/10.1145/3658644.3691406",
            "url": "https://dblp.org/rec/conf/ccs/ChownP24",
            "abstract": "This poster presents results from a study to better understand the opinions and concerns actual or potential users of fertility-tracking apps have with regards to privacy and disclosure of their data. We expect these results will guide the creation of contextual norms that the apps should abide by to protect user privacy.",
            "pdf_url": "",
            "keywords": [
                "Fertility Data Privacy",
                "Fertility-Tracking Apps",
                "User Concerns",
                "Data Disclosure",
                "Privacy Norms"
            ]
        },
        "url": "URL#256629",
        "sema_paperId": "15c6c708bd97755db2b46ac94b5eeb5e8fffc0f0"
    },
    {
        "@score": "1",
        "@id": "256630",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "277/2335",
                        "text": "Neophytos Christou"
                    },
                    {
                        "@pid": "344/1644",
                        "text": "Alexander J. Gaidis"
                    },
                    {
                        "@pid": "117/6972",
                        "text": "Vaggelis Atlidakis"
                    },
                    {
                        "@pid": "87/1029",
                        "text": "Vasileios P. Kemerlis"
                    }
                ]
            },
            "title": "Eclipse: Preventing Speculative Memory-error Abuse with Artificial Data Dependencies.",
            "venue": "CCS",
            "pages": "3913-3927",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ChristouGAK24",
            "doi": "10.1145/3658644.3690201",
            "ee": "https://doi.org/10.1145/3658644.3690201",
            "url": "https://dblp.org/rec/conf/ccs/ChristouGAK24",
            "abstract": "Historically, researchers have treated memory safety-based and speculative execution attacks as two separate domains. Recent work has introduced Speculative Memory-error Abuse (SMA) attacks, which combine memory corruption vulnerabilities with Spectre-like primitives. Using SMA, an attacker can leak sensitive program information and defeat a wide variety of memory-corruption miti-gations, including (K)ASLR, software-based XOM, and even ARM PA, eventually carrying out an end-to-end (architecturally-visible) exploit. We present Eclipse : a novel protection scheme against SMA attacks. Eclipse works by propagating artificial data dependencies onto sensitive data, preventing the CPU from using attacker-controlled data during speculative execution. We demonstrate that Eclipse provides comprehensive protection against speculative-probing and PACMAN-style attacks, two prominent examples of SMA attacks that target both the x86(-64) and ARM architectures. We evaluate the performance of Eclipse on x86-64 and demonstrate that it introduces minimal overhead, compared to alternative hardening approaches, incurring \u2248 0%\u20139 . 5% slowdown on SPEC CPU 2017, up to 8 . 6% slowdown in real-world applications, and negligible overhead in the Linux kernel.",
            "keywords": [
                "Speculative Execution Attacks",
                "Memory Safety",
                "Speculative Memory-error Abuse (SMA)",
                "Artificial Data Dependencies",
                "Performance Overhead"
            ]
        },
        "url": "URL#256630",
        "sema_paperId": "18b51fdb5cfe583927bc883800e46d478f8acad8"
    },
    {
        "@score": "1",
        "@id": "256631",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "258/1233",
                        "text": "Zhixuan Chu"
                    },
                    {
                        "@pid": "59/2227-2",
                        "text": "Yan Wang 0002"
                    },
                    {
                        "@pid": "139/8073",
                        "text": "Longfei Li"
                    },
                    {
                        "@pid": "31/5772-1",
                        "text": "Zhibo Wang 0001"
                    },
                    {
                        "@pid": "148/4477",
                        "text": "Zhan Qin"
                    },
                    {
                        "@pid": "20/6179-1",
                        "text": "Kui Ren 0001"
                    }
                ]
            },
            "title": "A Causal Explainable Guardrails for Large Language Models.",
            "venue": "CCS",
            "pages": "1136-1150",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ChuWL0Q024",
            "doi": "10.1145/3658644.3690217",
            "ee": "https://doi.org/10.1145/3658644.3690217",
            "url": "https://dblp.org/rec/conf/ccs/ChuWL0Q024",
            "abstract": "Large Language Models (LLMs) have shown impressive performance in natural language tasks, but their outputs can exhibit undesirable attributes or biases. Existing methods for steering LLMs toward desired attributes often assume unbiased representations and rely solely on steering prompts. However, the representations learned from pre-training can introduce semantic biases that influence the steering process, leading to suboptimal results. We propose LLMGuardrail, a novel framework that incorporates causal analysis and adversarial learning to obtain unbiased steering representations in LLMs. LLMGuardrail systematically identifies and blocks the confounding effects of biases, enabling the extraction of unbiased steering representations. Additionally, it includes an explainable component that provides insights into the alignment between the generated output and the desired direction. Experiments demonstrate LLMGuardrail's effectiveness in steering LLMs toward desired attributes while mitigating biases. Our work contributes to the development of safe and reliable LLMs that align with desired attributes.",
            "keywords": [
                "Large Language Models",
                "Causal Analysis",
                "Bias Mitigation",
                "Steering Representations",
                "Explainable AI"
            ]
        },
        "url": "URL#256631",
        "sema_paperId": "a658fd83058ee4727ae41317ec5ced0dd7c2a13c"
    },
    {
        "@score": "1",
        "@id": "256632",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "21/4435",
                        "text": "Gabriela F. Ciocarlie"
                    },
                    {
                        "@pid": "41/4686",
                        "text": "Xinming Ou"
                    }
                ]
            },
            "title": "ACM CCS 2024 Doctoral Symposium.",
            "venue": "CCS",
            "pages": "5087-5088",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/CiocarlieO24",
            "doi": "10.1145/3658644.3698218",
            "ee": "https://doi.org/10.1145/3658644.3698218",
            "url": "https://dblp.org/rec/conf/ccs/CiocarlieO24",
            "abstract": "ACM CCS started Doctoral Symposium in 2024 to provide PhD students who are in the middle of their dissertation research an opportunity to present their work to the broader research community and get feedback. We briefly describe the design of the first CCS Doctoral Symposium, the rationale, and the submission/acceptance status.",
            "pdf_url": "",
            "keywords": [
                "Doctoral Symposium",
                "PhD Research",
                "Dissertation Feedback",
                "Research Community",
                "Submission Process"
            ]
        },
        "url": "URL#256632",
        "sema_paperId": "e67515f41e7a7b4143d66df872ec83f61e1da2d1"
    },
    {
        "@score": "1",
        "@id": "256633",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "08/10126",
                        "text": "Ryan Craven"
                    },
                    {
                        "@pid": "383/4073",
                        "text": "Matthew S. Mickelson"
                    }
                ]
            },
            "title": "FEAST&apos;24: Sixth Workshop on Forming an Ecosystem Around Software Transformation.",
            "venue": "CCS",
            "pages": "4898-4899",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/CravenM24",
            "doi": "10.1145/3658644.3691553",
            "ee": "https://doi.org/10.1145/3658644.3691553",
            "url": "https://dblp.org/rec/conf/ccs/CravenM24",
            "abstract": "The Sixth Workshop on Forming an Ecosystem Around Software Transformation (FEAST) revives the series, with the original five events taking place from 2016-2020. FEAST is concerned with all aspects of achieving effective, robust, and appraisable late-stage transformation of software for security. Late-stage transformations allow third parties to deeply tailor existing software to their mission, customizing it with little to no access to source code or support from the original developer. Research has shown that late-stage software customization is of particular benefit to security-conscious software consumers who must use closed-source or source-free binary software components in mission-critical settings, or who must harden software against newly emerging attacks not anticipated during the software\u2019s original design and development. However, there is still a long way to go toward achieving sound and robust transformations whose holistic benefits to deployed software are fully appraisable. Motivated by these outstanding challenges, FEAST continues in its goal to form an active ecosystem of strategies and tools for accomplishing source-free binary code transformation reliably and on-demand.",
            "keywords": [
                "Software Transformation",
                "Late-Stage Customization",
                "Binary Code Transformation",
                "Security-Conscious Software",
                "Source-Free Software Modification"
            ]
        },
        "url": "URL#256633",
        "sema_paperId": "e34676c11eb5e66bbb4891db70d8891d7ebf174c"
    },
    {
        "@score": "1",
        "@id": "256634",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "17/2282",
                        "text": "Cas Cremers"
                    },
                    {
                        "@pid": "240/8159",
                        "text": "Alexander Dax"
                    },
                    {
                        "@pid": "272/7168",
                        "text": "Niklas Medinger"
                    }
                ]
            },
            "title": "Keeping Up with the KEMs: Stronger Security Notions for KEMs and Automated Analysis of KEM-based Protocols.",
            "venue": "CCS",
            "pages": "1046-1060",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/CremersDM24",
            "doi": "10.1145/3658644.3670283",
            "ee": "https://doi.org/10.1145/3658644.3670283",
            "url": "https://dblp.org/rec/conf/ccs/CremersDM24",
            "abstract": "Key Encapsulation Mechanisms (KEMs) are a critical building block for hybrid encryption and modern security protocols, notably in the post-quantum setting. Given the asymmetric public key of a recipient, the primitive establishes a shared secret key between sender and recipient. In recent years, a large number of abstract designs and concrete implementations of KEMs have been proposed, e.g., in the context of the NIST process for post-quantum primitives. In this work, we (i) establish stronger security notions for KEMs, and (ii) develop a symbolic analysis method to analyze security protocols that use KEMs. First, we generalize existing security notions for KEMs in the computational setting, introduce several stronger security notions and prove their relations. Our new properties formalize in which sense outputs of the KEM uniquely determine, i.e., bind , other values. Our new binding properties can be used, e.g., to prove the absence of attacks that were not captured by prior security notions, such as re-encapsulation attacks. Second, we develop a family of fine-grained symbolic models that correspond to our hierarchy of computational security notions, and are suitable for the automated analysis of KEM-based security protocols. We encode our models as a library in the framework of the Tamarin prover. Given a KEM-based protocol, our approach can automatically derive the minimal binding properties required from the KEM; or, if also given a concrete KEM, can analyze if the protocol meets its security goals. In case studies, Tamarin automatically discovers, e.g., that the key exchange protocol proposed in the original Kyber paper [12] requires stronger properties from the KEM than were proven in [12].",
            "keywords": [
                "Key Encapsulation Mechanisms",
                "Post-Quantum Cryptography",
                "Security Notions",
                "Symbolic Analysis",
                "Re-encapsulation Attacks"
            ]
        },
        "url": "URL#256634",
        "sema_paperId": "1595bf5aeac22f59191215838f4592153f952cec"
    },
    {
        "@score": "1",
        "@id": "256635",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "222/9411",
                        "text": "Lesly-Ann Daniel"
                    },
                    {
                        "@pid": "99/4141",
                        "text": "Vineet Rajani"
                    }
                ]
            },
            "title": "The 19th Workshop on Programming Languages and Analysis for Security (PLAS 2024).",
            "venue": "CCS",
            "pages": "4896-4897",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/DanielR24",
            "doi": "10.1145/3658644.3691336",
            "ee": "https://doi.org/10.1145/3658644.3691336",
            "url": "https://dblp.org/rec/conf/ccs/DanielR24",
            "abstract": "PLAS provides a forum for exploring and evaluating the use of programming language and program analysis techniques for promoting security in the complete range of software systems, from compilers to machine-learned models and smart contracts. The workshop encourages proposals of new, speculative ideas, evaluations of new or known techniques in practical settings, and discussions of emerging threats and problems. It also hosts position papers that are radical, forward-looking, and lead to lively and insightful discussions influential to the future research at the intersection of programming languages and security.",
            "pdf_url": "",
            "keywords": [
                "Programming Languages",
                "Program Analysis",
                "Software Security",
                "Emerging Threats",
                "Smart Contracts"
            ]
        },
        "url": "URL#256635",
        "sema_paperId": "f6807a7062fe7d117c74695d52840786b30057e1"
    },
    {
        "@score": "1",
        "@id": "256636",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "31/6808-1",
                        "text": "Sourav Das 0001"
                    },
                    {
                        "@pid": "146/0078",
                        "text": "Sisi Duan"
                    },
                    {
                        "@pid": "195/9149",
                        "text": "Shengqi Liu"
                    },
                    {
                        "@pid": "256/9085",
                        "text": "Atsuki Momose"
                    },
                    {
                        "@pid": "30/10661",
                        "text": "Ling Ren 0001"
                    },
                    {
                        "@pid": "s/VShoup",
                        "text": "Victor Shoup"
                    }
                ]
            },
            "title": "Asynchronous Consensus without Trusted Setup or Public-Key Cryptography.",
            "venue": "CCS",
            "pages": "3242-3256",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/DasDLM0S24",
            "doi": "10.1145/3658644.3670327",
            "ee": "https://doi.org/10.1145/3658644.3670327",
            "url": "https://dblp.org/rec/conf/ccs/DasDLM0S24",
            "abstract": "Byzantine consensus is a fundamental building block in distributed cryptographic problems. Despite decades of research, most existing asynchronous consensus protocols require a strong trusted setup and expensive public-key cryptography. In this paper, we study asynchronous Byzantine consensus protocols that do not rely on a trusted setup and do not use public-key cryptography such as digital signatures. We give an Asynchronous Common Subset (ACS) protocol whose security is only based on cryptographic hash functions modeled as a random oracle. Our protocol hasO(\u03ban3) total communication and runs in expectedO(1) rounds. The fact that we use only cryptographic hash functions also means that our protocol is post-quantum secure. The minimal use of cryptography and the small number of rounds make our protocol practical. We implement our protocol and evaluate it in a geo-distributed setting with up to 128 machines. Our experimental evaluation shows that our protocol is more efficient than the only other setup-free consensus protocol that has been implemented to date. En route to our asynchronous consensus protocols, we also introduce new primitives called asynchronous secret key sharing and cover gather, which may be of independent interest.",
            "pdf_url": "",
            "keywords": [
                "Asynchronous Consensus",
                "Byzantine Consensus",
                "Trusted Setup",
                "Cryptographic Hash Functions",
                "Post-Quantum Security"
            ]
        },
        "url": "URL#256636"
    },
    {
        "@score": "1",
        "@id": "256637",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "214/7137",
                        "text": "Pritam Dash"
                    },
                    {
                        "@pid": "339/1213",
                        "text": "Ethan Chan"
                    },
                    {
                        "@pid": "91/5344",
                        "text": "Karthik Pattabiraman"
                    }
                ]
            },
            "title": "SpecGuard: Specification Aware Recovery for Robotic Autonomous Vehicles from Physical Attacks.",
            "venue": "CCS",
            "pages": "1849-1863",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/DashCP24",
            "doi": "10.1145/3658644.3690210",
            "ee": "https://doi.org/10.1145/3658644.3690210",
            "url": "https://dblp.org/rec/conf/ccs/DashCP24",
            "abstract": "Robotic Autonomous Vehicles (RAVs) rely on their sensors for perception, and follow strict mission specifications (e.g., altitude, speed, and geofence constraints) for safe and timely operations. Physical attacks can corrupt the RAVs' sensors, resulting in mission failures. Recovering RAVs from such attacks demands robust control techniques that maintain compliance with mission specifications even under attacks to ensure the RAV's safety and timely operations. We propose SpecGuard, a technique that complies with mission specifications and performs safe recovery of RAVs. There are two innovations in SpecGuard. First, it introduces an approach to incorporate mission specifications and learn a recovery control policy using Deep Reinforcement Learning (Deep-RL). We design a compliance-based reward structure that reflects the RAV's complex dynamics and enables SpecGuard to satisfy multiple mission specifications simultaneously. Second, SpecGuard incorporates state reconstruction, a technique that minimizes attack induced sensor perturbations. This reconstruction enables effective adversarial training, and optimizing the recovery control policy for robustness under attacks. We evaluate SpecGuard in both virtual and real RAVs, and find that it achieves 92% recovery success rate under attacks on different sensors, without any crashes or stalls. SpecGuard achieves 2X higher recovery success than prior work, and incurs about 15% performance overhead on real RAVs.",
            "keywords": [
                "Robotic Autonomous Vehicles",
                "Mission Specifications",
                "Sensor Attacks",
                "Recovery Control Policy",
                "Deep Reinforcement Learning"
            ]
        },
        "url": "URL#256637",
        "sema_paperId": "cff0bf15ba46c8b4998dead0529e79901341dd7f"
    },
    {
        "@score": "1",
        "@id": "256638",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "54/8100",
                        "text": "Ali Dehghantanha"
                    },
                    {
                        "@pid": "13/4425",
                        "text": "Reza M. Parizi"
                    },
                    {
                        "@pid": "66/7949",
                        "text": "Gregory Epiphaniou"
                    }
                ]
            },
            "title": "AutonomousCyber &apos;24 - Workshop on Autonomous Cybersecurity.",
            "venue": "CCS",
            "pages": "4911-4913",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/DehghantanhaPE24",
            "doi": "10.1145/3658644.3691547",
            "ee": "https://doi.org/10.1145/3658644.3691547",
            "url": "https://dblp.org/rec/conf/ccs/DehghantanhaPE24",
            "abstract": "Autonomous cybersecurity represents a significant evolution in information security, where systems independently detect, respond to, and neutralize cyber threats without the need for human intervention. This level of autonomy is a more advanced stage in cybersecurity, enabling systems not only to execute tasks but also to interpret contexts, make decisions, and adapt strategies in realtime. The shift towards autonomy promises enhanced adaptability, faster response times, and a reduction in human error. This domain stands out for its unique blend of advanced Machine Learning (ML) systems such as Reinforcement Learning (RL)-driven and Quantum Machine Learning (QML)-based agents with cybersecurity automation techniques such as automated patch management systems, automated incident response systems to forge self-reliant cybersecurity systems. The AutonomousCyber workshop provides a venue for presenting and discussing new developments in this field.",
            "pdf_url": "",
            "keywords": [
                "Autonomous Cybersecurity",
                "Reinforcement Learning",
                "Quantum Machine Learning",
                "Cyber Threat Detection",
                "Automated Incident Response"
            ]
        },
        "url": "URL#256638",
        "sema_paperId": "4de07758b11b16608c02b36c81a6817fc6a67252"
    },
    {
        "@score": "1",
        "@id": "256639",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "247/1165",
                        "text": "Xinhao Deng"
                    },
                    {
                        "@pid": "181/2688-2",
                        "text": "Qi Li 0002"
                    },
                    {
                        "@pid": "181/2626-2",
                        "text": "Ke Xu 0002"
                    }
                ]
            },
            "title": "Robust and Reliable Early-Stage Website Fingerprinting Attacks via Spatial-Temporal Distribution Analysis.",
            "venue": "CCS",
            "pages": "1997-2011",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Deng0024",
            "doi": "10.1145/3658644.3670272",
            "ee": "https://doi.org/10.1145/3658644.3670272",
            "url": "https://dblp.org/rec/conf/ccs/Deng0024",
            "abstract": "Website Fingerprinting (WF) attacks identify the websites visited by users by performing traffic analysis, compromising user privacy. Particularly, DL-based WF attacks demonstrate impressive attack performance. However, the effectiveness of DL-based WF attacks relies on the collected complete and pure traffic during the page loading, which impacts the practicality of these attacks. The WF performance is rather low under dynamic network conditions and various WF defenses, particularly when the analyzed traffic is only a small part of the complete traffic. In this paper, we propose Holmes, a robust and reliable early-stage WF attack. Holmes utilizes temporal and spatial distribution analysis of website traffic to effectively identify websites in the early stages of page loading. Specifically, Holmes develops adaptive data augmentation based on the temporal distribution of website traffic and utilizes a supervised contrastive learning method to extract the correlations between the early-stage traffic and the pre-collected complete traffic. Holmes accurately identifies traffic in the early stages of page loading by computing the correlation of the traffic with the spatial distribution information, which ensures robust and reliable detection according to early-stage traffic. We extensively evaluate Holmes using six datasets. Compared to nine existing DL-based WF attacks, Holmes improves the F1-score of identifying early-stage traffic by an average of 169.18%. Furthermore, we replay the traffic of visiting real-world dark web websites. Holmes successfully identifies dark web websites when the ratio of page loading on average is only 21.71%, with an average precision improvement of 169.36% over the existing WF attacks.",
            "pdf_url": "",
            "keywords": [
                "Website Fingerprinting",
                "Traffic Analysis",
                "User Privacy",
                "Early-Stage Detection",
                "Spatial-Temporal Distribution"
            ]
        },
        "url": "URL#256639"
    },
    {
        "@score": "1",
        "@id": "256640",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "d/YvoDesmedt",
                        "text": "Yvo Desmedt"
                    },
                    {
                        "@pid": "262/6226",
                        "text": "Alireza Kavousi"
                    },
                    {
                        "@pid": "162/4180",
                        "text": "Aydin Abadi"
                    }
                ]
            },
            "title": "Poster: Byzantine Discrepancy Attacks against Calendar, Set-intersection and Nations.",
            "venue": "CCS",
            "pages": "5057-5059",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/DesmedtKA24",
            "doi": "10.1145/3658644.3691379",
            "ee": "https://doi.org/10.1145/3658644.3691379",
            "url": "https://dblp.org/rec/conf/ccs/DesmedtKA24",
            "abstract": "Nowadays Communication Security usually refers to digital communication and in particular via the Internet. We explain why the topic should be broadened to include any communication, in particular when done in person, e.g., with co-authors, colleagues, reporters, etc.",
            "pdf_url": "",
            "keywords": [
                "Byzantine Discrepancy Attacks",
                "Communication Security",
                "In-person Communication",
                "Set-intersection",
                "Calendar Attacks"
            ]
        },
        "url": "URL#256640",
        "sema_paperId": "45d5bbd4ead0d7f9a08b43b3104930bb4f92b3c3"
    },
    {
        "@score": "1",
        "@id": "256641",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "205/7539",
                        "text": "Jiawen Diao"
                    },
                    {
                        "@pid": "308/5004",
                        "text": "Shengmin Zhao"
                    },
                    {
                        "@pid": "99/5866",
                        "text": "Jianguo Xie"
                    },
                    {
                        "@pid": "165/8399",
                        "text": "Rongna Xie"
                    },
                    {
                        "@pid": "98/6225",
                        "text": "Guozhen Shi"
                    }
                ]
            },
            "title": "Poster: DoHunter: A feature fusion-based LLM for DoH tunnel detection.",
            "venue": "CCS",
            "pages": "5012-5014",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/DiaoZXXS24",
            "doi": "10.1145/3658644.3691400",
            "ee": "https://doi.org/10.1145/3658644.3691400",
            "url": "https://dblp.org/rec/conf/ccs/DiaoZXXS24",
            "abstract": "DNS over HTTPS (DoH) reduces the risk of privacy leakage of DNS queries, but it also provides a covert communication channel for malicious activities. In this paper, we propose a method for malicious encrypted traffic identification, which harnesses the advanced context comprehension of Large Language Model (LLM) and incorporates expert features to detect anomalies. The evaluation results show that the method proposed in this paper can not only identify common and emerging malicious DoH tunnel tools such as dns2tcp, iodine, and dnstt, but also identify weaponized DoH traffic within a real APT attack, with a recall of 0.9995.",
            "pdf_url": "",
            "keywords": [
                "DNS over HTTPS",
                "Malicious Traffic Detection",
                "Anomaly Detection",
                "DoH Tunnel Identification",
                "APT Attack Detection"
            ]
        },
        "url": "URL#256641",
        "sema_paperId": "d9dc2c4f924c747495af9a60673fdb46f277daa0"
    },
    {
        "@score": "1",
        "@id": "256642",
        "info": {
            "authors": {
                "author": {
                    "@pid": "184/4250",
                    "text": "Sayanton V. Dibbo"
                }
            },
            "title": "Novel Privacy Attacks and Defenses Against Neural Networks.",
            "venue": "CCS",
            "pages": "5113-5115",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Dibbo24",
            "doi": "10.1145/3658644.3690863",
            "ee": "https://doi.org/10.1145/3658644.3690863",
            "url": "https://dblp.org/rec/conf/ccs/Dibbo24",
            "abstract": "This dissertation comprises five papers that focus on a novel paradigm of privacy attack, i.e.,model inversion(MI) attack, where the adversarial goal is to infer or reconstruct training samples. In particular, these works are aligned with investigating MI privacy attacks, designing novel realistic MI attacks under restricted realistic capabilities, and introducing novel robust defense techniques against these attacks. At first, we focus on the systematization of MI attacks from the literature review (IEEE CSF). This opened up ways to investigate MI attacks on the tabular dataset. We developed novel MI attacks for inferring sensitive private training data, published in USENIX Security. Then, we worked on exploring MI attacks with limited adversarial capabilities (IEEE SaTML), i.e., when adversaries do not have access to the same data distributions as model training data. All these streams of work on privacy attack designing enabled the design of novel defenses against MI attacks. We have developed a novel sparse coding architecture (SCA), which shows 1.1-18.3 times more robustness against MI attacks while not significantly compromising model accuracy. This exciting work has just been published at ECCV 2024 this year and inspires us to improve the defense further by designing systematic techniques to drop highly sensitive features during training that can also provide provable privacy bounds.",
            "pdf_url": "",
            "keywords": [
                "Model Inversion Attack",
                "Privacy Attacks",
                "Sparse Coding Architecture",
                "Adversarial Capabilities",
                "Sensitive Feature Protection"
            ]
        },
        "url": "URL#256642",
        "sema_paperId": "1773177ed787dc275f55f48ede7e1eab3c924fab"
    },
    {
        "@score": "1",
        "@id": "256643",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "381/0147",
                        "text": "Gabriele Digregorio"
                    },
                    {
                        "@pid": "354/4184",
                        "text": "Roberto Alessandro Bertolini"
                    },
                    {
                        "@pid": "392/3371",
                        "text": "Francesco Panebianco"
                    },
                    {
                        "@pid": "163/9937",
                        "text": "Mario Polino"
                    }
                ]
            },
            "title": "Poster: libdebug, Build Your Own Debugger for a Better (Hello) World.",
            "venue": "CCS",
            "pages": "4976-4978",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/DigregorioBPP24",
            "doi": "10.1145/3658644.3691391",
            "ee": "https://doi.org/10.1145/3658644.3691391",
            "url": "https://dblp.org/rec/conf/ccs/DigregorioBPP24",
            "abstract": "Automated debugging, long pursued in a variety of fields from software engineering to cybersecurity, requires a framework that offers the building blocks for a programmable debugging workflow. However, existing debuggers are primarily tailored for human interaction, and those designed for programmatic debugging focus on kernel space, resulting in limited functionality in userland. To fill this gap, we introduce libdebug, a Python library for programmatic debugging of userland binary executables. libdebug offers a user-friendly API that enables developers to build custom debugging tools for various applications, including software engineering, reverse engineering, and software security. It is released as an open-source project, along with comprehensive documentation to encourage use and collaboration across the community. We demonstrate the versatility and performance of libdebug through case studies and benchmarks, all of which are publicly available. We find that the median latency of syscall and breakpoint handling in libdebug is 3 to 4 times lower compared to that of GDB.",
            "pdf_url": "",
            "keywords": [
                "Programmatic Debugging",
                "Userland Debugging",
                "Custom Debugging Tools",
                "Python Library",
                "Performance Benchmarking"
            ]
        },
        "url": "URL#256643",
        "sema_paperId": "66c1e5386039f69b15f5c4b6941a6b7726388fe5"
    },
    {
        "@score": "1",
        "@id": "256644",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "254/8202",
                        "text": "Wenxin Ding"
                    },
                    {
                        "@pid": "387/9793",
                        "text": "Cathy Y. Li"
                    },
                    {
                        "@pid": "217/9308",
                        "text": "Shawn Shan"
                    },
                    {
                        "@pid": "z/BenYZhao",
                        "text": "Ben Y. Zhao"
                    },
                    {
                        "@pid": "20/134-2",
                        "text": "Hai-Tao Zheng 0002"
                    }
                ]
            },
            "title": "Understanding Implosion in Text-to-Image Generative Models.",
            "venue": "CCS",
            "pages": "1211-1225",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/DingLSZZ24",
            "doi": "10.1145/3658644.3690205",
            "ee": "https://doi.org/10.1145/3658644.3690205",
            "url": "https://dblp.org/rec/conf/ccs/DingLSZZ24",
            "abstract": "Recent works show that text-to-image generative models are surprisingly vulnerable to a variety of poisoning attacks. Empirical results find that these models can be corrupted by altering associations between individual text prompts and associated visual features. Furthermore, a number of concurrent poisoning attacks can induce\"model implosion,\"where the model becomes unable to produce meaningful images for unpoisoned prompts. These intriguing findings highlight the absence of an intuitive framework to understand poisoning attacks on these models. In this work, we establish the first analytical framework on robustness of image generative models to poisoning attacks, by modeling and analyzing the behavior of the cross-attention mechanism in latent diffusion models. We model cross-attention training as an abstract problem of\"supervised graph alignment\"and formally quantify the impact of training data by the hardness of alignment, measured by an Alignment Difficulty (AD) metric. The higher the AD, the harder the alignment. We prove that AD increases with the number of individual prompts (or concepts) poisoned. As AD grows, the alignment task becomes increasingly difficult, yielding highly distorted outcomes that frequently map meaningful text prompts to undefined or meaningless visual representations. As a result, the generative model implodes and outputs random, incoherent images at large. We validate our analytical framework through extensive experiments, and we confirm and explain the unexpected (and unexplained) effect of model implosion while producing new, unforeseen insights. Our work provides a useful tool for studying poisoning attacks against diffusion models and their defenses.",
            "keywords": [
                "Text-to-Image Generation",
                "Poisoning Attacks",
                "Model Robustness",
                "Cross-Attention Mechanism",
                "Model Implosion"
            ]
        },
        "url": "URL#256644",
        "sema_paperId": "98048df70d84f62ea0ef753675631bb147ae091d"
    },
    {
        "@score": "1",
        "@id": "256645",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "280/3914",
                        "text": "Thien-Phuc Doan"
                    },
                    {
                        "@pid": "392/3304",
                        "text": "Hung Dinh-Xuan"
                    },
                    {
                        "@pid": "392/3361",
                        "text": "Taewon Ryu"
                    },
                    {
                        "@pid": "18/4048",
                        "text": "Inho Kim"
                    },
                    {
                        "@pid": "53/5025",
                        "text": "Woongjae Lee"
                    },
                    {
                        "@pid": "90/4214",
                        "text": "Kihun Hong"
                    },
                    {
                        "@pid": "85/4245",
                        "text": "Souhwan Jung"
                    }
                ]
            },
            "title": "Trident of Poseidon: A Generalized Approach for Detecting Deepfake Voices.",
            "venue": "CCS",
            "pages": "2222-2235",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/DoanDRKLHJ24",
            "doi": "10.1145/3658644.3690311",
            "ee": "https://doi.org/10.1145/3658644.3690311",
            "url": "https://dblp.org/rec/conf/ccs/DoanDRKLHJ24",
            "abstract": "Deepfakes, an increasingly prevalent form of information attack, pose serious threats to security and privacy. Deepfake voice attacks, in particular, have the potential to cause widespread disruption, creating an urgent need for an effective detection system. In this research, we propose the Trident of Poseidon - a novel set of triad training strategies aimed at enhancing the generalizability of deepfake voice detection models. Our solution comprises three key components: (1) Supervised Contrastive Learning, (2) Hard Negative Mining by Audio Re-synthesizing, and (3) Effective Proactive Batch Sampling. Together, these enable the model to learn more robust features. Our extensive experiments demonstrate that our approach outperforms existing methods in both in-domain and out-of-domain testing scenarios, making significant strides toward securing digital media against deepfake voice attacks.",
            "pdf_url": "",
            "keywords": [
                "Deepfake Voice Detection",
                "Supervised Contrastive Learning",
                "Hard Negative Mining",
                "Audio Re-synthesizing",
                "Proactive Batch Sampling"
            ]
        },
        "url": "URL#256645",
        "sema_paperId": "e12b0f3431c26144ec9e6a1d0e2356b6730a189c"
    },
    {
        "@score": "1",
        "@id": "256646",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "38/286",
                        "text": "Kai Du"
                    },
                    {
                        "@pid": "65/4872",
                        "text": "Jianfeng Wang"
                    },
                    {
                        "@pid": "14/2795",
                        "text": "Jiaojiao Wu"
                    },
                    {
                        "@pid": "201/1129",
                        "text": "Yunling Wang"
                    }
                ]
            },
            "title": "Scalable Equi-Join Queries over Encrypted Database.",
            "venue": "CCS",
            "pages": "4002-4016",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/DuWWW24",
            "doi": "10.1145/3658644.3690377",
            "ee": "https://doi.org/10.1145/3658644.3690377",
            "url": "https://dblp.org/rec/conf/ccs/DuWWW24",
            "abstract": "Secure join queries over encrypted databases, the most expressive class of SQL queries, have attracted extensive attention recently. The state-of-the-art JXT (Jutla et al. ASIACRYPT 2022) enables join queries on encrypted relational databases without pre-computing all possible joins. However, JXT can merely support join queries over two tables (in encrypted databases) with some high-entropy join attributes. In this paper, we propose an equi-join query protocol over two tables dubbed JXT+, that allows the join attributes with arbitrary names instead of JXT requiring the identical name for join attributes. JXT+ reduces the query complexity from O(\\ell_1 \\cdot \\ell_2) to O(\\ell_1) as compared to JXT, where \\ell_1 and \\ell_2 denote the numbers of matching records in two tables respectively. Furthermore, we present JXT++, thefirstequi-join queries across three or more tables over encrypted databases without pre-computation. Specifically, JXT++ supports joins of arbitrary attributes, i.e., all attributes (even low-entropy) can be candidates for join, while JXT requires high-entropy join attributes. In addition, JXT++ can alleviate sub-query leakage on three or more tables, which hides the leakage from the matching records of two-table join. Finally, we implement and compare our proposed schemes with the state-of-the-art JXT. The experimental results demonstrate that both of our schemes are superior to JXT in search and storage costs. In particular, JXT+ (resp.,JXT++) brings a saving of 49% (resp.,68%) in server storage cost and achieves a speedup of 51.7\u00d7 (resp.,54.3\u00d7) in search latency.",
            "pdf_url": "",
            "keywords": [
                "Encrypted Databases",
                "Equi-Join Queries",
                "Join Protocols",
                "Query Complexity",
                "Sub-query Leakage"
            ]
        },
        "url": "URL#256646"
    },
    {
        "@score": "1",
        "@id": "256647",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "187/0789",
                        "text": "F. Bet\u00fcl Durak"
                    },
                    {
                        "@pid": "343/6451",
                        "text": "Laurane Marco"
                    },
                    {
                        "@pid": "240/7738",
                        "text": "Abdullah Talayhan"
                    },
                    {
                        "@pid": "v/SergeVaudenay",
                        "text": "Serge Vaudenay"
                    }
                ]
            },
            "title": "Non-Transferable Anonymous Tokens by Secret Binding.",
            "venue": "CCS",
            "pages": "2460-2474",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/DurakMTV24",
            "doi": "10.1145/3658644.3670338",
            "ee": "https://doi.org/10.1145/3658644.3670338",
            "url": "https://dblp.org/rec/conf/ccs/DurakMTV24",
            "abstract": "Non-transferability (NT) is a security notion which ensures that credentials are only used by their intended owners. Despite its importance, it hasnotbeen formally treated in the context of anonymous tokens (AT) which are lightweight anonymous credentials. In this work, we consider a client who \"buys\" access tokens which are forbidden to be transferred although anonymously redeemed. We extensively study the trade-offs between privacy (obtained through anonymity) and security in AT through the notion of non-transferability. We formalise new security notions, design a suite of protocols with various flavors of NT, prove their security, and implement the protocols to assess their efficiency. Finally, we study the existing anonymous credentials which offer NT, and show that they cannot automatically be used as AT without security and complexity implications.",
            "pdf_url": "",
            "keywords": [
                "Anonymous Tokens",
                "Non-Transferability",
                "Privacy",
                "Security Protocols",
                "Anonymous Credentials"
            ]
        },
        "url": "URL#256647"
    },
    {
        "@score": "1",
        "@id": "256648",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "10/10785",
                        "text": "Moumita Dutta"
                    },
                    {
                        "@pid": "115/4391",
                        "text": "Chaya Ganesh"
                    },
                    {
                        "@pid": "163/2345",
                        "text": "Sikhar Patranabis"
                    },
                    {
                        "@pid": "379/1680",
                        "text": "Shubh Prakash"
                    },
                    {
                        "@pid": "67/3470",
                        "text": "Nitin Singh"
                    }
                ]
            },
            "title": "Batching-Efficient RAM using Updatable Lookup Arguments.",
            "venue": "CCS",
            "pages": "4077-4091",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/DuttaGPPS24",
            "doi": "10.1145/3658644.3670356",
            "ee": "https://doi.org/10.1145/3658644.3670356",
            "url": "https://dblp.org/rec/conf/ccs/DuttaGPPS24",
            "abstract": "RAM (random access memory) is an important primitive in verifiable computation. In this paper, we focus on realizing RAM with efficient batching property, i.e, proving a batch ofmupdates on a RAM of size N while incurring a cost that is sublinear in N. Classical approaches based on Merkle-trees or address ordered transcripts to model RAM correctness are either concretely inefficient, or incur linear overhead in the size of the RAM. Recent works explore cryptographic accumulators based on unknown-order groups (RSA, class-groups) to model the RAM state. While recent RSA accumulator based approaches offer significant improvement over classical methods, they incur linear overhead in the size of the accumulated set to compute witnesses, as well as prohibitive constant overheads.",
            "pdf_url": "",
            "keywords": [
                "Verifiable Computation",
                "Random Access Memory (RAM)",
                "Batch Processing",
                "Cryptographic Accumulators",
                "Update Efficiency"
            ]
        },
        "url": "URL#256648"
    },
    {
        "@score": "1",
        "@id": "256649",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "86/5357",
                        "text": "Stefan Dziembowski"
                    },
                    {
                        "@pid": "71/4369",
                        "text": "Sebastian Faust"
                    },
                    {
                        "@pid": "303/4548",
                        "text": "Tomasz Lizurej"
                    },
                    {
                        "@pid": "389/6159",
                        "text": "Marcin Mielniczuk"
                    }
                ]
            },
            "title": "Secret Sharing with Snitching.",
            "venue": "CCS",
            "pages": "840-853",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/DziembowskiFLM24",
            "doi": "10.1145/3658644.3690296",
            "ee": "https://doi.org/10.1145/3658644.3690296",
            "url": "https://dblp.org/rec/conf/ccs/DziembowskiFLM24",
            "abstract": "We address the problem of detecting and punishing shareholder collusion in secret-sharing schemes. We do it in the recently proposed cryptographic model calledindividual cryptography(Dziembowski, Faust, and Lizurej, Crypto 2023), which assumes that there exist tasks that can be efficiently computed by a single machine but distributing this computation across multiple (mutually distrustful devices) is infeasible.",
            "pdf_url": "",
            "keywords": [
                "Secret Sharing",
                "Collusion Detection",
                "Individual Cryptography",
                "Shareholder Punishment",
                "Mutually Distrustful Devices"
            ]
        },
        "url": "URL#256649"
    },
    {
        "@score": "1",
        "@id": "256650",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "303/4711",
                        "text": "Sebastian H. Faller"
                    },
                    {
                        "@pid": "256/9210",
                        "text": "Tobias Handirk"
                    },
                    {
                        "@pid": "146/7916",
                        "text": "Julia Hesse"
                    },
                    {
                        "@pid": "156/9112",
                        "text": "M\u00e1t\u00e9 Horv\u00e1th"
                    },
                    {
                        "@pid": "63/3592",
                        "text": "Anja Lehmann"
                    }
                ]
            },
            "title": "Password-Protected Key Retrieval with(out) HSM Protection.",
            "venue": "CCS",
            "pages": "2445-2459",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/FallerHHHL24",
            "doi": "10.1145/3658644.3690358",
            "ee": "https://doi.org/10.1145/3658644.3690358",
            "url": "https://dblp.org/rec/conf/ccs/FallerHHHL24",
            "abstract": "Password-protected key retrieval (PPKR) enables users to store and retrieve high-entropy keys from a server securely. The process is bootstrapped from a human-memorizable password only, addressing the challenge of how end-users can manage cryptographic key material. The core security requirement is protection against a corrupt server, which should not be able to learn the key or offline- attack it through the password protection. PPKR is deployed at a large scale with the WhatsApp Backup Protocol (WBP), allowing users to access their encrypted messaging history when switching to a new device. Davies et al. (Crypto'23) formally analyzed the WBP, proving that it satisfies most of the desired security. The WBP uses the OPAQUE protocol for password-based key exchange as a building block and relies on the server using a hardware security module (HSM) for most of its protection. In fact, the security analysis assumes that the HSM is incorruptible - rendering most of the heavy cryptography in the WBP obsolete.",
            "pdf_url": "",
            "keywords": [
                "Password-Protected Key Retrieval",
                "Cryptographic Key Management",
                "WhatsApp Backup Protocol",
                "Server Corruption Resistance",
                "HSM Security Assumptions"
            ]
        },
        "url": "URL#256650"
    },
    {
        "@score": "1",
        "@id": "256651",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "261/5148",
                        "text": "Francesca Falzon"
                    },
                    {
                        "@pid": "48/9365",
                        "text": "Esha Ghosh"
                    },
                    {
                        "@pid": "39/780",
                        "text": "Kenneth G. Paterson"
                    },
                    {
                        "@pid": "t/RobertoTamassia",
                        "text": "Roberto Tamassia"
                    }
                ]
            },
            "title": "PathGES: An Efficient and Secure Graph Encryption Scheme for Shortest Path Queries.",
            "venue": "CCS",
            "pages": "4047-4061",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/FalzonGPT24",
            "doi": "10.1145/3658644.3670305",
            "ee": "https://doi.org/10.1145/3658644.3670305",
            "url": "https://dblp.org/rec/conf/ccs/FalzonGPT24",
            "abstract": "The increasing importance of graph databases and cloud storage services prompts the study of private queries on graphs. We propose PathGES, a graph encryption scheme (GES) for single-pair shortest path queries. PathGES is efficient and mitigates the state-of-the-art attack by Falzon and Paterson (2022) on the GES by Ghosh, Kamara, and Tamassia (2021), while only incurring an additional logarithmic factor in storage overhead. PathGES leverages a novel data structure that minimizes leakage and server computation.",
            "pdf_url": "",
            "keywords": [
                "Graph Encryption",
                "Shortest Path Queries",
                "Data Privacy",
                "Cloud Storage Security",
                "Leakage Minimization"
            ]
        },
        "url": "URL#256651"
    },
    {
        "@score": "1",
        "@id": "256652",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "77/4730",
                        "text": "Zheng Fang"
                    },
                    {
                        "@pid": "12/5838-81",
                        "text": "Tao Wang 0081"
                    },
                    {
                        "@pid": "227/7192",
                        "text": "Lingchen Zhao"
                    },
                    {
                        "@pid": "52/10864",
                        "text": "Shenyi Zhang"
                    },
                    {
                        "@pid": "75/10470",
                        "text": "Bowen Li"
                    },
                    {
                        "@pid": "255/9411",
                        "text": "Yunjie Ge"
                    },
                    {
                        "@pid": "181/2688-2",
                        "text": "Qi Li 0002"
                    },
                    {
                        "@pid": "48/4825-1",
                        "text": "Chao Shen 0001"
                    },
                    {
                        "@pid": "75/5723-2",
                        "text": "Qian Wang 0002"
                    }
                ]
            },
            "title": "Zero-Query Adversarial Attack on Black-box Automatic Speech Recognition Systems.",
            "venue": "CCS",
            "pages": "630-644",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/FangWZZLGLS024",
            "doi": "10.1145/3658644.3670309",
            "ee": "https://doi.org/10.1145/3658644.3670309",
            "url": "https://dblp.org/rec/conf/ccs/FangWZZLGLS024",
            "abstract": "In recent years, extensive research has been conducted on the vulnerability of ASR systems, revealing that black-box adversarial example attacks pose significant threats to real-world ASR systems. However, most existing black-box attacks rely on queries to the target ASRs, which is impractical when queries are not permitted. In this paper, we propose ZQ-Attack, a transfer-based adversarial attack on ASR systems in the zero-query black-box setting. Through a comprehensive review and categorization of modern ASR technologies, we first meticulously select surrogate ASRs of diverse types to generate adversarial examples. Following this, ZQ-Attack initializes the adversarial perturbation with a scaled target command audio, rendering it relatively imperceptible while maintaining effectiveness. Subsequently, to achieve high transferability of adversarial perturbations, we propose a sequential ensemble optimization algorithm, which iteratively optimizes the adversarial perturbation on each surrogate model, leveraging collaborative information from other models. We conduct extensive experiments to evaluate ZQ-Attack. In the over-the-line setting, ZQ-Attack achieves a 100% success rate of attack (SRoA) with an average signal-to-noise ratio (SNR) of 21.91dB on 4 online speech recognition services, and attains an average SRoA of 100% and SNR of 19.67dB on 16 open-source ASRs. For commercial intelligent voice control devices, ZQ-Attack also achieves a 100% SRoA with an average SNR of 15.77dB in the over-the-air setting.",
            "keywords": [
                "Automatic Speech Recognition",
                "Adversarial Attack",
                "Black-box Attack",
                "Zero-query Setting",
                "Surrogate Models"
            ]
        },
        "url": "URL#256652",
        "sema_paperId": "34a6996309ac36a4d6d657fbbf9ecfdf006e8239"
    },
    {
        "@score": "1",
        "@id": "256653",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "157/0863",
                        "text": "Minghong Fang"
                    },
                    {
                        "@pid": "168/4566",
                        "text": "Zifan Zhang"
                    },
                    {
                        "@pid": "259/6782",
                        "text": "Hairi"
                    },
                    {
                        "@pid": "158/4888",
                        "text": "Prashant Khanduri"
                    },
                    {
                        "@pid": "49/1245-2",
                        "text": "Jia Liu 0002"
                    },
                    {
                        "@pid": "05/2887",
                        "text": "Songtao Lu"
                    },
                    {
                        "@pid": "69/10440-1",
                        "text": "Yuchen Liu 0001"
                    },
                    {
                        "@pid": "03/9437",
                        "text": "Neil Gong 0001"
                    }
                ]
            },
            "title": "Byzantine-Robust Decentralized Federated Learning.",
            "venue": "CCS",
            "pages": "2874-2888",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/FangZHK0LL024",
            "doi": "10.1145/3658644.3670307",
            "ee": "https://doi.org/10.1145/3658644.3670307",
            "url": "https://dblp.org/rec/conf/ccs/FangZHK0LL024",
            "abstract": "Federated learning (FL) enables multiple clients to collaboratively train machine learning models without revealing their private training data. In conventional FL, the system follows the server-assisted architecture (server-assisted FL), where the training process is coordinated by a central server. However, the server-assisted FL framework suffers from poor scalability due to a communication bottleneck at the server, and trust dependency issues. To address challenges, decentralized federated learning (DFL) architecture has been proposed to allow clients to train models collaboratively in a serverless and peer-to-peer manner. However, due to its fully decentralized nature, DFL is highly vulnerable to poisoning attacks, where malicious clients could manipulate the system by sending carefully-crafted local models to their neighboring clients. To date, only a limited number of Byzantine-robust DFL methods have been proposed, most of which are either communication-inefficient or remain vulnerable to advanced poisoning attacks. In this paper, we propose a new algorithm called BALANCE (Byzantine-robust averaging through local similarity in decentralization) to defend against poisoning attacks in DFL. In BALANCE, each client leverages its own local model as a similarity reference to determine if the received model is malicious or benign. We establish the theoretical convergence guarantee for BALANCE under poisoning attacks in both strongly convex and non-convex settings. Furthermore, the convergence rate of BALANCE under poisoning attacks matches those of the state-of-the-art counterparts in Byzantine-free settings. Extensive experiments also demonstrate that BALANCE outperforms existing DFL methods and effectively defends against poisoning attacks.",
            "keywords": [
                "Decentralized Federated Learning",
                "Byzantine Robustness",
                "Poisoning Attacks",
                "Model Averaging",
                "Local Similarity"
            ]
        },
        "url": "URL#256653",
        "sema_paperId": "8ad0952102852d75ee4152f93c35ace97c2e01ca"
    },
    {
        "@score": "1",
        "@id": "256654",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "138/9001",
                        "text": "Antonio Faonio"
                    },
                    {
                        "@pid": "99/2744-1",
                        "text": "Dario Fiore 0001"
                    },
                    {
                        "@pid": "37/7121-1",
                        "text": "Luigi Russo 0001"
                    }
                ]
            },
            "title": "Real-World Universal zkSNARKs are Non-Malleable.",
            "venue": "CCS",
            "pages": "3138-3151",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Faonio0024",
            "doi": "10.1145/3658644.3690351",
            "ee": "https://doi.org/10.1145/3658644.3690351",
            "url": "https://dblp.org/rec/conf/ccs/Faonio0024",
            "abstract": "Simulation extractability is a strong security notion of zkSNARKs that guarantees that an attacker who produces a valid proof must know the corresponding witness, even if the attacker had prior access to proofs generated by other users. Notably, simulation extractability implies that proofs are non-malleable and is of fundamental importance for applications of zkSNARKs in distributed systems. In this work, we study sufficient and necessary conditions for constructing simulation-extractable universal zkSNARKs via the popular design approach based on compiling polynomial interactive oracle proofs (PIOP). Our main result is the first security proof that popular universal zkSNARKs, such as PLONK and Marlin, as deployed in the real world, are simulation-extractable. Our result fills a gap left from previous work (Faonio et al. TCC'23, and Kohlweiss et al. TCC'23) which could only prove the simulation extractability of the \"textbook\" versions of these schemes and does not capture their optimized variants, with all the popular optimization tricks in place, that are eventually implemented and deployed in software libraries.",
            "pdf_url": "",
            "keywords": [
                "zkSNARKs",
                "Simulation Extractability",
                "Universal zkSNARKs",
                "Non-Malleability",
                "PLONK and Marlin"
            ]
        },
        "url": "URL#256654"
    },
    {
        "@score": "1",
        "@id": "256655",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "97/535",
                        "text": "Kassem Fawaz"
                    },
                    {
                        "@pid": "55/3115",
                        "text": "Magnus Almgren"
                    }
                ]
            },
            "title": "CPSIoTSec&apos;24: Sixth Workshop on CPS&amp;IoT Security and Privacy.",
            "venue": "CCS",
            "pages": "4903-4904",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/FawazA24",
            "doi": "10.1145/3658644.3691550",
            "ee": "https://doi.org/10.1145/3658644.3691550",
            "url": "https://dblp.org/rec/conf/ccs/FawazA24",
            "abstract": "The sixth Workshop on CPS & IoT Security and Privacy is set to take place in Salt Lake City, UT, USA, on October 18, 2024, in conjunction with the ACM Conference on Computer and Communications Security (CCS'24). This workshop marks the amalgamation of two workshops held in 2019: one focused on the security and privacy of cyber-physical systems, while the other one centered on the security and privacy of IoT. The primary objective of this workshop is to create a collaborative forum that brings together academia, industry experts, and governmental entities, encouraging them to contribute cutting-edge research, share demonstrations or hands-on experiences, and engage in discussions. This year, our call for contributions encompassed a broad spectrum, including full research papers, work-in-progress submissions, and one-page abstracts. The workshop program includes eight full-length papers on the security and privacy of CPS/IoT, alongside six shorter papers that present original or work-in-progress research. Furthermore, the workshop will feature one distinguished keynote presentation by Prof. Alvaro Cardenas, a world-renowned expert in CPS security. The talk will offer insights into how the state of CPS security has evolved since 2007. The complete CPSIoTSec'24 workshop proceedings are available at https://doi.org/10.1145/3658644.3691550.",
            "pdf_url": "",
            "keywords": [
                "CPS Security",
                "IoT Security",
                "Privacy",
                "Cyber-Physical Systems",
                "Research Collaboration"
            ]
        },
        "url": "URL#256655",
        "sema_paperId": "c94512067443840062d2310888b758d94ee529be"
    },
    {
        "@score": "1",
        "@id": "256656",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "335/1864",
                        "text": "Xinguo Feng"
                    },
                    {
                        "@pid": "247/9274",
                        "text": "Zhongkui Ma"
                    },
                    {
                        "@pid": "152/5077",
                        "text": "Zihan Wang"
                    },
                    {
                        "@pid": "392/3293",
                        "text": "Eu Joe Chegne"
                    },
                    {
                        "@pid": "42/6228",
                        "text": "Mengyao Ma"
                    },
                    {
                        "@pid": "165/0106",
                        "text": "Alsharif Abuadbba"
                    },
                    {
                        "@pid": "86/9673",
                        "text": "Guangdong Bai"
                    }
                ]
            },
            "title": "Uncovering Gradient Inversion Risks in Practical Language Model Training.",
            "venue": "CCS",
            "pages": "3525-3539",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/FengMWCMAB24",
            "doi": "10.1145/3658644.3690292",
            "ee": "https://doi.org/10.1145/3658644.3690292",
            "url": "https://dblp.org/rec/conf/ccs/FengMWCMAB24",
            "abstract": "The gradient inversion attack has been demonstrated as a significant privacy threat to federated learning (FL), particularly in continuous domains such as vision models. In contrast, it is often considered less effective or highly dependent on impractical training settings when applied to language models, due to the challenges posed by thediscretenature of tokens in text data. As a result, its potential privacy threats remain largely underestimated, despite FL being an emerging training method for language models. In this work, we propose a domain-specific gradient inversion attack named GRAB (<u>gra</u>dient inversion withhy<u>b</u>ridoptimization). GRAB features two alternating optimization processes to address the challenges caused by practical training settings, including a simultaneous optimization on dropout masks between layers for improved token recovery and a discrete optimization for effective token sequencing. GRAB can recover a significant portion (up to 92.9% recovery rate) of the private training data, outperforming the attack strategy of utilizing discrete optimization with an auxiliary model by notable improvements of up to 28.9% recovery rate in benchmark settings and 48.5% recovery rate in practical settings. GRAB provides a valuable step forward in understanding this privacy threat in the emerging FL training mode of language models.",
            "pdf_url": "",
            "keywords": [
                "Gradient Inversion Attack",
                "Federated Learning",
                "Language Models",
                "Privacy Threats",
                "Data Recovery"
            ]
        },
        "url": "URL#256656",
        "sema_paperId": "f5e188bf62ea4340cd78fbee2c3f97b315907395"
    },
    {
        "@score": "1",
        "@id": "256657",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "207/6572",
                        "text": "Ellis Fenske"
                    },
                    {
                        "@pid": "24/3059-1",
                        "text": "Aaron Johnson 0001"
                    }
                ]
            },
            "title": "Bytes to Schlep? Use a FEP: Hiding Protocol Metadata with Fully Encrypted Protocols.",
            "venue": "CCS",
            "pages": "1982-1996",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Fenske024",
            "doi": "10.1145/3658644.3690198",
            "ee": "https://doi.org/10.1145/3658644.3690198",
            "url": "https://dblp.org/rec/conf/ccs/Fenske024",
            "abstract": "Fully Encrypted Protocols (FEPs) have arisen in practice as a technique to avoid network censorship. Such protocols are designed to produce messages that appear completely random. This design hides communications metadata, such as version and length fields, and makes it difficult to even determine what protocol is being used. Moreover, these protocols frequently support padding to hide the length of protocol fields and the contained message. These techniques have relevance well beyond censorship circumvention, as protecting protocol metadata has security and privacy benefits for all Internet communications. The security of FEP designs depends on cryptographic assumptions, but neither security definitions nor proofs exist for them. We provide novel security definitions that capture the metadata-protection goals of FEPs. Our definitions are given in both the datastream and datagram settings, which model the ubiquitous TCP and UDP interfaces available to protocol designers. We prove relations among these new notions and existing security definitions. We further present new FEP constructions and prove their security. Finally, we survey existing FEP candidates and characterize the extent to which they satisfy FEP security. We identify novel ways in which these protocols are identifiable, including their responses to the introduction of data errors and the sizes of their smallest protocol messages.",
            "pdf_url": "",
            "keywords": [
                "Fully Encrypted Protocols",
                "Metadata Protection",
                "Network Censorship",
                "Protocol Identification",
                "Security Definitions"
            ]
        },
        "url": "URL#256657"
    },
    {
        "@score": "1",
        "@id": "256658",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "148/2252",
                        "text": "Ben Fisch"
                    },
                    {
                        "@pid": "329/5777",
                        "text": "Arthur Lazzaretti"
                    },
                    {
                        "@pid": "116/0645-4",
                        "text": "Zeyu Liu 0004"
                    },
                    {
                        "@pid": "p/CharalamposPapamanthou",
                        "text": "Charalampos Papamanthou"
                    }
                ]
            },
            "title": "ThorPIR: Single Server PIR via Homomorphic Thorp Shuffles.",
            "venue": "CCS",
            "pages": "1448-1462",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/FischL0P24",
            "doi": "10.1145/3658644.3690326",
            "ee": "https://doi.org/10.1145/3658644.3690326",
            "url": "https://dblp.org/rec/conf/ccs/FischL0P24",
            "abstract": "Private Information Retrieval (PIR) is a two player protocol where the client, given some query x \u03b5 [N], interacts with the server, which holds aN-bit string DB, in order to privately retrieve DB[x]. In this work, we focus on the single-server client-preprocessing model, initially proposed by Corrigan-Gibbs and Kogan (EUROCRYPT 2020), where the client and server first run a joint preprocessing algorithm, after which the client can retrieve elements from DB privately in time sublinear inN. Most known constructions of single-server client-preprocessing PIR follow one of two paradigms: They feature either (1) a linear-bandwidth offline phase where the client downloads the whole database from the server, or (2) a sublinear-bandwidth offline phase where however the server has to compute a large-depth (\u03a9\u03bb(N)) circuit under fully-homomorphic encryption (FHE) in order to execute the preprocessing phase.",
            "pdf_url": "",
            "keywords": [
                "Private Information Retrieval",
                "Single-Server Model",
                "Client-Preprocessing",
                "Homomorphic Encryption",
                "Thorp Shuffles"
            ]
        },
        "url": "URL#256658"
    },
    {
        "@score": "1",
        "@id": "256659",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "72/5460",
                        "text": "Marc Fischlin"
                    },
                    {
                        "@pid": "307/8716",
                        "text": "Olga Sanina"
                    }
                ]
            },
            "title": "Fake It till You Make It: Enhancing Security of Bluetooth Secure Connections via Deferrable Authentication.",
            "venue": "CCS",
            "pages": "4762-4776",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/FischlinS24",
            "doi": "10.1145/3658644.3670360",
            "ee": "https://doi.org/10.1145/3658644.3670360",
            "url": "https://dblp.org/rec/conf/ccs/FischlinS24",
            "abstract": "The Bluetooth protocol for wireless connection between devices comes with several security measures to protect confidentiality and integrity of data. At the heart of these security protocols lies the Secure Simple Pairing, wherewith the devices can negotiate a shared key before communicating sensitive data. Despite the good intentions, the Bluetooth security protocol has repeatedly been shown to be vulnerable, especially with regard to active attacks on the Secure Simple Pairing.",
            "pdf_url": "",
            "keywords": [
                "Bluetooth Security",
                "Secure Simple Pairing",
                "Wireless Communication",
                "Deferrable Authentication",
                "Active Attacks"
            ]
        },
        "url": "URL#256659"
    },
    {
        "@score": "1",
        "@id": "256660",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "83/4622",
                        "text": "Apostolos P. Fournaris"
                    },
                    {
                        "@pid": "99/9960-1",
                        "text": "Paolo Palmieri 0001"
                    }
                ]
            },
            "title": "CCSW 2024 - Cloud Computing Security Workshop.",
            "venue": "CCS",
            "pages": "4900",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Fournaris024",
            "doi": "10.1145/3658644.3691548",
            "ee": "https://doi.org/10.1145/3658644.3691548",
            "url": "https://dblp.org/rec/conf/ccs/Fournaris024",
            "abstract": "The CCSW workshop aims to bring together researchers and practitioners to explore all aspects of security in cloud-centric and outsourced computing. In CCSW 2024, based on the papers that have been accepted, the workshop is focused on applied cryptographic schemes and protocols for the cloud, cloud-based leakage related attacks and their countermeasures, trusted computing technology in clouds, binary analysis of software for cloud protection, network security mechanisms using AI anomaly detection as well as security for emerging cloud programming models (like extended Berkeley Packet Filter, eBPF, programs). Throughout the years, the workshop particularly encourages novel paradigms and controversial ideas not covered by traditional cloud security research, serving as a fertile ground for creative debate and interaction in security-sensitive areas of computing impacted by cloud technologies. The workshop received 20 submissions, 15 of which passed through a thorough review process of at least 3 reviewers, and 7 of them were accepted for publication and presentation.",
            "pdf_url": "",
            "keywords": [
                "Cloud Security",
                "Applied Cryptography",
                "Cloud Leakage Attacks",
                "Trusted Computing",
                "AI Anomaly Detection"
            ]
        },
        "url": "URL#256660",
        "sema_paperId": "f1472ca8d2c8223338dd7e711a46652c599d3d5e"
    },
    {
        "@score": "1",
        "@id": "256661",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "362/4156",
                        "text": "Jens Frie\u00df"
                    },
                    {
                        "@pid": "248/0549",
                        "text": "Donika Mirdita"
                    },
                    {
                        "@pid": "94/7397",
                        "text": "Haya Schulmann"
                    },
                    {
                        "@pid": "90/308",
                        "text": "Michael Waidner"
                    }
                ]
            },
            "title": "Byzantine-Secure Relying Party for Resilient RPKI.",
            "venue": "CCS",
            "pages": "49-63",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/FriessMSW24",
            "doi": "10.1145/3658644.3690368",
            "ee": "https://doi.org/10.1145/3658644.3690368",
            "url": "https://dblp.org/rec/conf/ccs/FriessMSW24",
            "abstract": "To protect against prefix hijacks, Resource Public Key Infrastructure (RPKI) has been standardized. To enjoy the security guarantees of RPKI validation, networks need to install a new component, the relying party validator, which fetches and validates RPKI objects and provides them to border routers. However, recent work shows that relying parties experience failures when retrieving RPKI objects and are vulnerable to attacks, all of which can disable RPKI validation. Therefore even the few adopters are not necessarily secure. We make the first proposal that significantly improves the resilience and security of RPKI. We develop BRP, a Byzantine-Secure relying party implementation. In BRP the relying party nodes redundantly validate RPKI objects and reach a global consensus through voting. BRP provides an RPKI equivalent of public DNS, removing the need for networks to install, operate, and upgrade their own relying party instances while avoiding the need to trust operators of BRP nodes. We show through simulations and experiments that BRP, as an intermediate RPKI service, results in less load on RPKI publication points and a robust output despite RPKI repository failures, jitter, and attacks. We engineer BRP to be fully backward compatible and readily deployable - it does not require any changes to the border routers and the RPKI repositories. We demonstrate that BRP can protect many networks transparently, with either a decentralized or centralized deployment. BRP can be set up as a network of decentralized volunteer deployments, similarly to NTP and TOR, where different operators participate in the peering process with their node, and provide resilient and secure relying party validation to the Internet. BRP can also be hosted by a single operator as a centralized service, e.g., on one cloud or CDN, and provides RPKI validation benefits even when hosted on a single network.",
            "keywords": [
                "RPKI",
                "Byzantine-Secure",
                "Relying Party",
                "Prefix Hijacks",
                "RPKI Validation Resilience"
            ]
        },
        "url": "URL#256661",
        "sema_paperId": "9f4812d7e8bf6ddeefe18c7dde80c90930571949"
    },
    {
        "@score": "1",
        "@id": "256662",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "07/5701",
                        "text": "Mario Fritz"
                    },
                    {
                        "@pid": "34/4605",
                        "text": "Christoph Krau\u00df"
                    },
                    {
                        "@pid": "04/4298",
                        "text": "Hans-Joachim Hof"
                    }
                ]
            },
            "title": "CSCS &apos;24 - Cyber Security in CarS Workshop.",
            "venue": "CCS",
            "pages": "4914-4916",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/FritzKH24",
            "doi": "10.1145/3658644.3691551",
            "ee": "https://doi.org/10.1145/3658644.3691551",
            "url": "https://dblp.org/rec/conf/ccs/FritzKH24",
            "abstract": "The increasing attack surface of modern cars and the new regulatory requirements for cybersecurity (like UNECE R155) made cybersecurity an important part of car design. The \"CSCS'24 Cyber Security in Cars Workshop\" is designed to address current topics in the rapidly evolving automotive cybersecurity domain. The goal is to bring together academia and industry to find novel solutions for cybersecurity problems in the automotive domain. CSCS'24 is the first CSCS workshop co-located with ACM CCS. Nonetheless, it is founded on a series of events known as the \"ACM Cyber Security in Cars Symposium (CSCS symposium)\" that lasted from 2017 until 2023. CSCS'24 welcomes any theoretical or practical contributions to the rich field of automotive cybersecurity, including secure automotive communication, ECU system security, and aspects of Cyber Security Management Systems (CSMS).",
            "pdf_url": "",
            "keywords": [
                "Automotive Cybersecurity",
                "Cybersecurity Regulations",
                "Secure Automotive Communication",
                "ECU System Security",
                "Cyber Security Management Systems (CSMS)"
            ]
        },
        "url": "URL#256662",
        "sema_paperId": "4554d2a62135e4684a79b5f92935dda92862f0b0"
    },
    {
        "@score": "1",
        "@id": "256663",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "274/0756",
                        "text": "Chuanpu Fu"
                    },
                    {
                        "@pid": "181/2688-2",
                        "text": "Qi Li 0002"
                    },
                    {
                        "@pid": "03/8774-1",
                        "text": "Meng Shen 0001"
                    },
                    {
                        "@pid": "181/2626-2",
                        "text": "Ke Xu 0002"
                    }
                ]
            },
            "title": "Detecting Tunneled Flooding Traffic via Deep Semantic Analysis of Packet Length Patterns.",
            "venue": "CCS",
            "pages": "3659-3673",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/FuL0024",
            "doi": "10.1145/3658644.3670353",
            "ee": "https://doi.org/10.1145/3658644.3670353",
            "url": "https://dblp.org/rec/conf/ccs/FuL0024",
            "abstract": "Distributed denial-of-service (DDoS) protection services capture various flooding attacks by analyzing traffic features. However, existing services are unable to accurately detect tunneled attack traffic because the tunneling protocols encrypt both packet headers and payloads, which hide the traffic features used for detection, and can thus evade these detection services. In this paper, we develop Exosphere, which detects tunneled attack traffic by analyzing packet length patterns, without investigating any information in packets. Specifically, it utilizes a deep learning based method to analyze the semantics of packet patterns, i.e., the features represent the strong correlations between flooding packets with similar length patterns, and classify attack traffic according to these semantic features. We prove that the strong correlations of packet length patterns ensure the theoretical guarantee of applying semantic analysis to recognize correlated attack packets. We prototype Exosphere with FPGAs and deploy it in a real-world institutional network. The experimental results demonstrate that Exosphere achieves 0.967 F1 accuracy, while detecting flooding traffic generated by unseen attacks and misconfigurations. Moreover, it achieves 0.996 AUC accuracy on existing datasets including various stealthy attacks, and thus significantly outperforms the existing deep learning models. It achieves accuracy comparable to the best performances achieved by 12 state-of-the-art methods that cannot detect tunneled flooding traffic, while improving their efficiency by 6.19 times.",
            "pdf_url": "",
            "keywords": [
                "Tunneled Flooding Traffic",
                "DDoS Protection",
                "Packet Length Patterns",
                "Semantic Analysis",
                "Deep Learning Detection"
            ]
        },
        "url": "URL#256663",
        "sema_paperId": "b570fabe9dc4d5aef9853234d15b2051cd9def2f"
    },
    {
        "@score": "1",
        "@id": "256664",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "227/2135",
                        "text": "Yucheng Fu"
                    },
                    {
                        "@pid": "145/3288-1",
                        "text": "Tianhao Wang 0001"
                    }
                ]
            },
            "title": "Benchmarking Secure Sampling Protocols for Differential Privacy.",
            "venue": "CCS",
            "pages": "318-332",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/FuW24",
            "doi": "10.1145/3658644.3690257",
            "ee": "https://doi.org/10.1145/3658644.3690257",
            "url": "https://dblp.org/rec/conf/ccs/FuW24",
            "abstract": "Differential privacy (DP) is widely employed to provide privacy protection for individuals by limiting information leakage from the aggregated data. Two well-known models of DP are the central model and the local model. The former requires a trustworthy server for data aggregation, while the latter requires individuals to add noise, significantly decreasing the utility of aggregated results. Recently, many studies have proposed to achieve DP with Secure Multi-party Computation (MPC) in distributed settings, namely, the distributed model, which has utility comparable to central model while, under specific security assumptions, preventing parties from obtaining others' information. One challenge of realizing DP in distributed model is efficiently sampling noise with MPC. Although many secure sampling methods have been proposed, they have different security assumptions and isolated theoretical analyses. There is a lack of experimental evaluations to measure and compare their performances. We fill this gap by benchmarking existing sampling protocols in MPC and performing comprehensive measurements of their efficiency. First, we present a taxonomy of the underlying techniques of these sampling protocols. Second, we extend widely used distributed noise generation protocols to be resilient against Byzantine attackers. Third, we implement discrete sampling protocols and align their security settings for a fair comparison. We then conduct an extensive evaluation to study their efficiency and utility.",
            "keywords": [
                "Differential Privacy",
                "Secure Multi-party Computation",
                "Distributed Model",
                "Noise Sampling Protocols",
                "Byzantine Resilience"
            ]
        },
        "url": "URL#256664",
        "sema_paperId": "afc93ef72f3af66a05f844d21700217f6ebdae9f"
    },
    {
        "@score": "1",
        "@id": "256665",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "145/1898",
                        "text": "Weimin Fu"
                    },
                    {
                        "@pid": "227/4494",
                        "text": "Yifang Zhao"
                    },
                    {
                        "@pid": "34/756",
                        "text": "Yier Jin"
                    },
                    {
                        "@pid": "13/10726",
                        "text": "Xiaolong Guo"
                    }
                ]
            },
            "title": "Poster: Enhance Hardware Domain Specific Large Language Model with Reinforcement Learning for Resilience.",
            "venue": "CCS",
            "pages": "5060-5062",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/FuZJG24",
            "doi": "10.1145/3658644.3691384",
            "ee": "https://doi.org/10.1145/3658644.3691384",
            "url": "https://dblp.org/rec/conf/ccs/FuZJG24",
            "abstract": "To enhance the performance of large language models (LLMs) on hardware design tasks, we focus on training with reinforcement learning(RL) to improve LLMs' syntax synthesis and functional verification performance. We observed significant gains in power, performance, and area (PPA) metrics by applying RL. Specifically, DeepSeek Code saw a 23.6% performance increase, while the RTLCoder improved by 7.86%. Our findings demonstrate the effectiveness of RL in refining LLMs for more accurate hardware generation, considering power and area consumption. This approach offers a promising direction for generating hardware resilient to side-channel attacks in computer systems.",
            "pdf_url": "",
            "keywords": [
                "Hardware Design",
                "Large Language Models",
                "Reinforcement Learning",
                "Syntax Synthesis",
                "Functional Verification"
            ]
        },
        "url": "URL#256665",
        "sema_paperId": "84062bc65e878d7d544ed35b2b215cfa940e8797"
    },
    {
        "@score": "1",
        "@id": "256666",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "115/4391",
                        "text": "Chaya Ganesh"
                    },
                    {
                        "@pid": "290/7231",
                        "text": "Shreyas Gupta"
                    },
                    {
                        "@pid": "64/6728",
                        "text": "Bhavana Kanukurthi"
                    },
                    {
                        "@pid": "263/0602",
                        "text": "Girisha Shankar"
                    }
                ]
            },
            "title": "Secure Vickrey Auctions with Rational Parties.",
            "venue": "CCS",
            "pages": "4062-4076",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/GaneshGKS24",
            "doi": "10.1145/3658644.3670311",
            "ee": "https://doi.org/10.1145/3658644.3670311",
            "url": "https://dblp.org/rec/conf/ccs/GaneshGKS24",
            "abstract": "In this work, we construct a second price (Vickrey) auction protocol (SPA), which does not require any auctioneers and ensures total privacy in the presence of rational parties participating in the auction. In particular, the confidentiality of the highest bid and the identity of the second highest bidder are protected. We model the bidders participating in the second price auction as rational, computationally bounded and privacy-sensitive parties. These are self-interested agents who care about winning the auction more than learning about the private bids of other parties. A rational party does not deviate from the protocol arbitrarily but does so only for its own individual 'advantage' -- without any consideration for others. Such an advantage is modelled using suitable utility functions.",
            "pdf_url": "",
            "keywords": [
                "Vickrey Auctions",
                "Auction Protocols",
                "Rational Bidders",
                "Privacy Preservation",
                "Second Price Auction"
            ]
        },
        "url": "URL#256666"
    },
    {
        "@score": "1",
        "@id": "256667",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "115/4391",
                        "text": "Chaya Ganesh"
                    },
                    {
                        "@pid": "154/6735",
                        "text": "Vineet Nair"
                    },
                    {
                        "@pid": "02/99",
                        "text": "Ashish Sharma"
                    }
                ]
            },
            "title": "Dual Polynomial Commitment Schemes and Applications to Commit-and-Prove SNARKs.",
            "venue": "CCS",
            "pages": "884-898",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/GaneshNS24",
            "doi": "10.1145/3658644.3690219",
            "ee": "https://doi.org/10.1145/3658644.3690219",
            "url": "https://dblp.org/rec/conf/ccs/GaneshNS24",
            "abstract": "In this work, we introduce a primitive called a dual polynomial commitment scheme that allows linking together a witness committed to using a univariate polynomial commitment scheme with a witness inside a multilinear polynomial commitment scheme. This yields commit-and-prove (CP) SNARKs with the flexibility of going back and forth between univariate and multilinear encodings of witnesses. This is in contrast to existing CP frameworks that assume compatible polynomial commitment schemes between different components of the proof systems. In addition to application to CP, we also show that our notion yields a version of Spartan with better proof size and verification complexity, at the cost of a more expensive prover.",
            "pdf_url": "",
            "keywords": [
                "Dual Polynomial Commitment",
                "Commit-and-Prove SNARKs",
                "Univariate Polynomial Commitment",
                "Multilinear Polynomial Commitment",
                "Proof Size and Verification Complexity"
            ]
        },
        "url": "URL#256667"
    },
    {
        "@score": "1",
        "@id": "256668",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "284/8917",
                        "text": "Georgi Ganev"
                    },
                    {
                        "@pid": "30/495",
                        "text": "Kai Xu"
                    },
                    {
                        "@pid": "36/6225",
                        "text": "Emiliano De Cristofaro"
                    }
                ]
            },
            "title": "Graphical vs. Deep Generative Models: Measuring the Impact of Differentially Private Mechanisms and Budgets on Utility.",
            "venue": "CCS",
            "pages": "1596-1610",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/GanevXC24",
            "doi": "10.1145/3658644.3690215",
            "ee": "https://doi.org/10.1145/3658644.3690215",
            "url": "https://dblp.org/rec/conf/ccs/GanevXC24",
            "abstract": "Generative models trained with Differential Privacy (DP) can produce synthetic data while reducing privacy risks. However, navigating their privacy-utility tradeoffs makes finding the best models for specific settings/tasks challenging. This paper bridges this gap by profiling how DP generative models for tabular data distribute privacy budgets across rows and columns, which is one of the primary sources of utility degradation. We compare graphical and deep generative models, focusing on the key factors contributing to how privacy budgets are spent, i.e., underlying modeling techniques, DP mechanisms, and data dimensionality. Through our measurement study, we shed light on the characteristics that make different models suitable for various settings and tasks. For instance, we find that graphical models distribute privacy budgets horizontally and thus cannot handle relatively wide datasets for a fixed training time; also, the performance on the task they were optimized for monotonically increases with more data but could also overfit. Deep generative models spend their budgets per iteration, so their behavior is less predictable with varying dataset dimensions, but are more flexible as they could perform better if trained on more features. Moreover, low levels of privacy ($\\epsilon\\geq100$) could help some models generalize, achieving better results than without applying DP. We believe our work will aid the deployment of DP synthetic data techniques by navigating through the best candidate models vis-a-vis the dataset features, desired privacy levels, and downstream tasks.",
            "keywords": [
                "Differential Privacy",
                "Generative Models",
                "Privacy-Utility Tradeoffs",
                "Synthetic Data",
                "Graphical vs. Deep Models"
            ]
        },
        "url": "URL#256668",
        "sema_paperId": "a03086a3aa238ace8fb934a4891266ea76e6e045"
    },
    {
        "@score": "1",
        "@id": "256669",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "43/2694",
                        "text": "Rui Gao"
                    },
                    {
                        "@pid": "82/4194",
                        "text": "Zhiguo Wan"
                    },
                    {
                        "@pid": "241/9318",
                        "text": "Yuncong Hu"
                    },
                    {
                        "@pid": "73/4432",
                        "text": "Huaqun Wang"
                    }
                ]
            },
            "title": "A Succinct Range Proof for Polynomial-based Vector Commitment.",
            "venue": "CCS",
            "pages": "3152-3166",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/GaoWHW24",
            "doi": "10.1145/3658644.3670324",
            "ee": "https://doi.org/10.1145/3658644.3670324",
            "url": "https://dblp.org/rec/conf/ccs/GaoWHW24",
            "abstract": "A range proof serves as a protocol for the prover to prove to the verifier that a committed number lies in a specified range, such as [0,2n), without disclosing the actual value. Range proofs find extensive application in various domains. However, the efficiency of many existing schemes diminishes significantly when confronted with batch proofs encompassing multiple elements.",
            "pdf_url": "",
            "keywords": [
                "Range Proofs",
                "Vector Commitment",
                "Batch Proofs",
                "Polynomial-based Proofs",
                "Efficiency"
            ]
        },
        "url": "URL#256669"
    },
    {
        "@score": "1",
        "@id": "256670",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "90/3256",
                        "text": "Adri\u00e0 Gasc\u00f3n"
                    },
                    {
                        "@pid": "05/667",
                        "text": "Yuval Ishai"
                    },
                    {
                        "@pid": "218/7156",
                        "text": "Mahimna Kelkar"
                    },
                    {
                        "@pid": "42/8016",
                        "text": "Baiyu Li"
                    },
                    {
                        "@pid": "238/0150-1",
                        "text": "Yiping Ma 0001"
                    },
                    {
                        "@pid": "07/5590-1",
                        "text": "Mariana Raykova 0001"
                    }
                ]
            },
            "title": "Computationally Secure Aggregation and Private Information Retrieval in the Shuffle Model.",
            "venue": "CCS",
            "pages": "4122-4136",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/GasconIKL0024",
            "doi": "10.1145/3658644.3670391",
            "ee": "https://doi.org/10.1145/3658644.3670391",
            "url": "https://dblp.org/rec/conf/ccs/GasconIKL0024",
            "abstract": "The shuffle model has recently emerged as a popular setting for differential privacy, where clients can communicate with a central server using anonymous channels or an intermediate message shuffler. This model was also explored in the context of cryptographic tasks such assecure aggregationandprivate information retrieval(PIR). However, this study was almost entirely restricted to the stringent notion of information-theoretic security.",
            "pdf_url": "",
            "keywords": [
                "Shuffle Model",
                "Differential Privacy",
                "Secure Aggregation",
                "Private Information Retrieval",
                "Information-Theoretic Security"
            ]
        },
        "url": "URL#256670"
    },
    {
        "@score": "1",
        "@id": "256671",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "389/6468",
                        "text": "Emanuele Di Giandomenico"
                    },
                    {
                        "@pid": "93/2334-21",
                        "text": "Yong Li 0021"
                    },
                    {
                        "@pid": "04/2350",
                        "text": "Sven Sch\u00e4ge"
                    }
                ]
            },
            "title": "Protoss: Protocol for Tight Optimal Symmetric Security.",
            "venue": "CCS",
            "pages": "4718-4731",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Giandomenico0S24",
            "doi": "10.1145/3658644.3690252",
            "ee": "https://doi.org/10.1145/3658644.3690252",
            "url": "https://dblp.org/rec/conf/ccs/Giandomenico0S24",
            "abstract": "We present Protoss, a new balanced PAKE protocol with optimal communication efficiency. Messages are only 160 bits long and the computational complexity is lower than all previous approaches. Our protocol is proven secure in the random oracle model and features a security proof in a strong security model with multiple parties and multiple sessions while allowing for generous attack queries including multiple Test-queries. Moreover, the proof is in the practically relevant single-bit model (that is harder to achieve than the multiple-bit model) and tightly reduces to the Strong Square Diffie-Hellman assumption (SSQRDH). This allows for very efficient, theoretically-sound instantiations and tight compositions with symmetric primitives.",
            "pdf_url": "",
            "keywords": [
                "Password-Authenticated Key Exchange (PAKE)",
                "Communication Efficiency",
                "Strong Square Diffie-Hellman",
                "Security Proof",
                "Symmetric Primitives"
            ]
        },
        "url": "URL#256671",
        "sema_paperId": "b7095a14c0335d4ade53bcbf52c27d34adca9b84"
    },
    {
        "@score": "1",
        "@id": "256672",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "260/7068",
                        "text": "Adwait Godbole"
                    },
                    {
                        "@pid": "173/9817",
                        "text": "Yatin A. Manerkar"
                    },
                    {
                        "@pid": "s/SanjitASeshia",
                        "text": "Sanjit A. Seshia"
                    }
                ]
            },
            "title": "SemPat: From Hyperproperties to Attack Patterns for Scalable Analysis of Microarchitectural Security.",
            "venue": "CCS",
            "pages": "2756-2770",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/GodboleMS24",
            "doi": "10.1145/3658644.3690214",
            "ee": "https://doi.org/10.1145/3658644.3690214",
            "url": "https://dblp.org/rec/conf/ccs/GodboleMS24",
            "abstract": "Microarchitectural security verification of software has seen the emergence of two broad classes of approaches. The first uses non-interference-based semantic security properties which are verified for a given program and a given model of the hardware microarchitecture. The second is based on attack patterns , which, if found in a program execution, indicates the presence of an exploit. We observe that while the former uses a formal specification that can capture several gadget variants targeting the same vulnerability, it is limited by the scalability of verification. Patterns, while more scalable, must be currently constructed manually, as they are narrower in scope and sensitive to gadget-specific structure. This work develops a technique that, given a non-interference-based semantic security hyperproperty, automatically generates attack patterns up to a certain complexity parameter (called the skeleton size). Thus, we combine the advantages of both approaches: security can be specified by a hyperproperty that uniformly captures several gadget variants, while automatically generated patterns can be used for scalable verification. We implement our approach in a tool and demonstrate the ability to generate new patterns, (e.g., for SpectreV1, SpectreV4) and improved scalability using the generated patterns over hyperproperty-based verification.",
            "keywords": [
                "Microarchitectural Security",
                "Hyperproperties",
                "Attack Patterns",
                "Scalable Verification",
                "Spectre Vulnerabilities"
            ]
        },
        "url": "URL#256672",
        "sema_paperId": "f7a6418432a482f70138056ab43b9a98936f937c"
    },
    {
        "@score": "1",
        "@id": "256673",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "172/0408",
                        "text": "Aarushi Goel"
                    },
                    {
                        "@pid": "225/9829",
                        "text": "Mathias Hall-Andersen"
                    },
                    {
                        "@pid": "185/1661",
                        "text": "Gabriel Kaptchuk"
                    }
                ]
            },
            "title": "Dora: A Simple Approach to Zero-Knowledge for RAM Programs.",
            "venue": "CCS",
            "pages": "869-883",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/GoelHK24",
            "doi": "10.1145/3658644.3690213",
            "ee": "https://doi.org/10.1145/3658644.3690213",
            "url": "https://dblp.org/rec/conf/ccs/GoelHK24",
            "abstract": "Existing protocols for proving the correct execution of a RAM program in zero-knowledge are plagued by a processor expressiveness tradeoff : supporting fewer instructions results in smaller processor circuits (which improves performance), but may result in more program execution steps because non-supported instruction must be emulated over multiple processor steps (diminishing performance). We present Dora , a very simple and concretely efficient zero-knowledge protocol for RAM programs that sidesteps this tension by making it (nearly) free to add additional instructions to the processor. The computational and communication complexity of proving each step of a computation in Dora , is constant in the number of supported instructions. Dora \u2019s approach is united by intuitive abstraction we call a ZKBag, a cryptographic primitive constructed from linearly homomorphic commitments that captures the properties of a physical bag. We implement Dora and demonstrate that on commodity hardware it can prove the correct execution of a processor with thousands of instruction, each of which has thousands of gates, in just a few milliseconds per step.",
            "keywords": [
                "Zero-Knowledge Proofs",
                "RAM Programs",
                "Processor Circuits",
                "Cryptographic Primitive",
                "ZKBag"
            ]
        },
        "url": "URL#256673",
        "sema_paperId": "d067abab64fb3b0ad8728ffe9813bf03d1b04cfd"
    },
    {
        "@score": "1",
        "@id": "256674",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "268/5832",
                        "text": "Xueluan Gong"
                    },
                    {
                        "@pid": "392/3202",
                        "text": "Rubin Wei"
                    },
                    {
                        "@pid": "222/8592",
                        "text": "Ziyao Wang"
                    },
                    {
                        "@pid": "199/8201",
                        "text": "Yuchen Sun"
                    },
                    {
                        "@pid": "223/1371",
                        "text": "Jiawen Peng"
                    },
                    {
                        "@pid": "50/10586",
                        "text": "Yanjiao Chen"
                    },
                    {
                        "@pid": "75/5723-2",
                        "text": "Qian Wang 0002"
                    }
                ]
            },
            "title": "Beowulf: Mitigating Model Extraction Attacks Via Reshaping Decision Regions.",
            "venue": "CCS",
            "pages": "3838-3852",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/GongWWSPC024",
            "doi": "10.1145/3658644.3670267",
            "ee": "https://doi.org/10.1145/3658644.3670267",
            "url": "https://dblp.org/rec/conf/ccs/GongWWSPC024",
            "abstract": "Machine Learning as a Service (MLaaS) enables resource-constrained users to access well-trained models through a publicly accessible Application Programming Interface (API) on a pay-per-query basis. Nevertheless, model owners may face the potential threats of model extraction attacks where malicious users replicate valuable commercial models based on query results. Existing defenses against model extraction attacks, however, either sacrifice prediction accuracy or fail to thwart more advanced attacks. In this paper, we propose a novel model extraction defense, dubbed Beowulf 1, which draws inspiration from theoretical findings that models with complex and narrow decision regions are difficult to be reproduced. Rather than arbitrarily altering decision regions, which may jeopardize the predictive capacity of the victim model, we introduce a dummy class, carefully synthesized using both random and adversarial noises. The random noise broadens the coverage of the dummy class, and the adversarial noise impacts decision regions near decision boundaries with normal classes. To further improve the model utility, we propose to employ data augmentation methods to seamlessly integrate the dummy class and the normal classes. Extensive evaluations on CIFAR-10, GTSRB, CIFAR-100, and ImageNette datasets demonstrate that Beowulf can significantly reduce the extraction accuracy of 6 state-of-the-art model extraction attacks by as much as 80%. Moreover, we show that Beowulf is also robust to adaptive model extraction attacks.",
            "pdf_url": "",
            "keywords": [
                "Model Extraction Attacks",
                "Decision Regions",
                "Dummy Class Synthesis",
                "Adversarial Noise",
                "Data Augmentation"
            ]
        },
        "url": "URL#256674",
        "sema_paperId": "9e3844cfb19402bde4df26cb1e1810faae8d5881"
    },
    {
        "@score": "1",
        "@id": "256675",
        "info": {
            "authors": {
                "author": {
                    "@pid": "329/5534",
                    "text": "Bhavish Raj Gopal"
                }
            },
            "title": "Privacy-Preserving Graph Analysis.",
            "venue": "CCS",
            "pages": "5125-5127",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Gopal24",
            "doi": "10.1145/3658644.3690867",
            "ee": "https://doi.org/10.1145/3658644.3690867",
            "url": "https://dblp.org/rec/conf/ccs/Gopal24",
            "abstract": "Graphs are a fundamental tool for modelling data in diverse real-world applications such as communication networks, traffic systems, and social networks. However, graph data is often distributed across multiple data owners and contains sensitive information, posing significant privacy concerns that impede collaborative analysis. This research aims to overcome these challenges by developing privacy-preserving solutions for graph analysis using the technique of secure multiparty computation (MPC). We review existing MPC-based approaches for privacy-preserving graph analysis, identifying their limitations in efficiency, scalability and adaptability. Furthermore, we present our results in enhancing privacy-preserving graph analysis and highlight the remaining challenges. We discuss potential strategies to overcome these challenges, including designing efficient primitives, leveraging different computational settings, and incorporating hardware accelerations to improve performance. Through these advancements, our research aims to make secure graph analysis both practical and widely applicable, ensuring privacy while enabling valuable insights from distributed graph data.",
            "pdf_url": "",
            "keywords": [
                "Privacy-Preserving Graph Analysis",
                "Secure Multiparty Computation",
                "Distributed Graph Data",
                "Efficiency and Scalability",
                "Privacy Challenges in Graph Analysis"
            ]
        },
        "url": "URL#256675",
        "sema_paperId": "c94c4d3f88c13ca11e2a56cfbc9719821deea4a7"
    },
    {
        "@score": "1",
        "@id": "256676",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "276/5011",
                        "text": "Yuechun Gu"
                    },
                    {
                        "@pid": "03/8106",
                        "text": "Jiajie He"
                    },
                    {
                        "@pid": "32/4592",
                        "text": "Keke Chen"
                    }
                ]
            },
            "title": "Demo: FT-PrivacyScore: Personalized Privacy Scoring Service for Machine Learning Participation.",
            "venue": "CCS",
            "pages": "5075-5077",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/GuHC24",
            "doi": "10.1145/3658644.3691366",
            "ee": "https://doi.org/10.1145/3658644.3691366",
            "url": "https://dblp.org/rec/conf/ccs/GuHC24",
            "abstract": "Data privacy has been a top concern in the AI era. Despite the recent development of differentially private learning methods, controlled data access remains a mainstream method for protecting data privacy in many industrial and research environments. In controlled data access, authorized model builders work in a restricted environment to access sensitive data, which can fully preserve data utility with reduced risk of data leak. However, unlike differential privacy, there is no quantitative measure for individual data contributors to tell their privacy risk before participating in a machine learning task. We developed the demo prototype FT-PrivacyScore to show that it's possible to efficiently and quantitatively estimate the privacy risk of participating in a model fine-tuning task. The demo source code will be available at https://github.com/RhincodonE/demo_privacy_scoring.",
            "pdf_url": "",
            "keywords": [
                "Data Privacy",
                "Privacy Risk Assessment",
                "Controlled Data Access",
                "Differential Privacy",
                "Machine Learning Participation"
            ]
        },
        "url": "URL#256676",
        "sema_paperId": "5bb7b6bfd0f9e3d15a3fbaabe39c22aa6c7b2c9b"
    },
    {
        "@score": "1",
        "@id": "256677",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "299/5309",
                        "text": "Shixuan Guan"
                    },
                    {
                        "@pid": "181/2853-17",
                        "text": "Kai Li 0017"
                    }
                ]
            },
            "title": "Characterizing Ethereum Address Poisoning Attack.",
            "venue": "CCS",
            "pages": "986-1000",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Guan024",
            "doi": "10.1145/3658644.3690277",
            "ee": "https://doi.org/10.1145/3658644.3690277",
            "url": "https://dblp.org/rec/conf/ccs/Guan024",
            "abstract": "This paper presents the first comprehensive analysis of the address poisoning attack surged on the Ethereum blockchain. This phishing attack typically exploits the address shortening feature of Ethereum explorers and digital wallets (e.g., Etherscan and MetaMask) by crafting token transfer events with a seemingly correct address to poison victims\u2019 transfer history, waiting for them to mistakenly transfer assets to the attacker\u2019s address. To systematically detect and characterize the address poisoning attack, we developed a detection system named Poison-Hunter , which can recognize the attacker\u2019s crafted transfers and detect the phishing addresses controlled by the attacker. By applying Poison-Hunter to Ethereum blocks produced from Nov. 2022 to Feb. 2024, we have detected millions of phishing transfers and phishing addresses. Our analysis shows that the attacker has predominantly targeted USDC and USDT token holders and used a phishing address that looks highly similar to a benign one. We also find that the sender of legitimate transfers was the primary target of this attack. Furthermore, by tracing the transaction history of the detected phishing addresses, we reveal that over 1,800 victim addresses have lost crypto assets, with a potential financial loss of up to $144 million US dollars. Among them, about $90 million of loss are confirmed by this work. Finally, our analysis suggests that 98% of phishing addresses are controlled by four entities, which collected nearly 92% of the total profits. Overall, this paper sheds light on the tactics utilized in the address poisoning attack and its scale and impact on the Ethereum blockchain, emphasizing the urgent need for an effective detection and prevention mechanism against such a phishing activity.",
            "keywords": [
                "Ethereum Blockchain",
                "Address Poisoning Attack",
                "Phishing Attack",
                "Token Transfer Exploitation",
                "Financial Loss in Cryptocurrency"
            ]
        },
        "url": "URL#256677",
        "sema_paperId": "5c70bda1b28570df2188c72d54667910c549476f"
    },
    {
        "@score": "1",
        "@id": "256678",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "314/6762",
                        "text": "Ece Gumusel"
                    },
                    {
                        "@pid": "80/6791-7",
                        "text": "Yue Xiao 0007"
                    },
                    {
                        "@pid": "142/1169",
                        "text": "Yue Qin"
                    },
                    {
                        "@pid": "348/8439",
                        "text": "Jiaxin Qin"
                    },
                    {
                        "@pid": "129/1113",
                        "text": "Xiaojing Liao"
                    }
                ]
            },
            "title": "Understanding Legal Professionals&apos; Practices and Expectations in Data Breach Incident Reporting.",
            "venue": "CCS",
            "pages": "2711-2725",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/GumuselXQQL24",
            "doi": "10.1145/3658644.3690357",
            "ee": "https://doi.org/10.1145/3658644.3690357",
            "url": "https://dblp.org/rec/conf/ccs/GumuselXQQL24",
            "abstract": "Legal professionals are essential in analyzing data breach incident reports and guiding the response to comply with data privacy laws and regulations. Their expertise helps mitigate privacy and security risks and prevents failures in privacy compliance. However, little research has been done to understand how legal professionals perceive, react to, and face challenges within the data breach incident reporting procedure. In this study, we conducted a simulated incident report assessment experiment and semi-structured interviews with 33 legal professionals who varied in age, gender, and legal background. We reported the criteria used by legal professionals to identify privacy-related items and also uncovered that the agreement among legal professionals on the concepts of privacy-related items is low. Furthermore, we presented findings regarding the perceptions and strategies of legal professionals concerning legal and regulatory compliance, as well as the key features of incident responses that facilitate efficient analysis of data privacy and security law compliance. After taking into account the challenges and suggestions provided by legal professionals, we concluded this study with recommendations for enhancing the effectiveness of legal compliance analysis for incident responses.",
            "pdf_url": "",
            "keywords": [
                "Data Breach Incident Reporting",
                "Legal Compliance",
                "Privacy Law",
                "Legal Professionals",
                "Incident Response Analysis"
            ]
        },
        "url": "URL#256678",
        "sema_paperId": "2f2cdba90cbed5351746656245f26fde9f56688a"
    },
    {
        "@score": "1",
        "@id": "256679",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "128/2249",
                        "text": "Wentao Guo"
                    },
                    {
                        "@pid": "392/3363",
                        "text": "Aditya Kishore"
                    },
                    {
                        "@pid": "94/1554",
                        "text": "Adam J. Aviv"
                    },
                    {
                        "@pid": "20/7983",
                        "text": "Michelle L. Mazurek"
                    }
                ]
            },
            "title": "A Qualitative Analysis of Practical De-Identification Guides.",
            "venue": "CCS",
            "pages": "1611-1625",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/GuoKAM24",
            "doi": "10.1145/3658644.3690270",
            "ee": "https://doi.org/10.1145/3658644.3690270",
            "url": "https://dblp.org/rec/conf/ccs/GuoKAM24",
            "abstract": "De-identifying microdata is necessary yet difficult. Myriad techniques exist, which reduce risk and preserve utility to varying, often unclear extents. We conducted a thematic analysis of 38 online de-identification guides for practitioners, to understand what content they contain and how they are designed to support decision-making and execution. We highlight trends and differences between guides, and we find some concerning patterns, including inconsistent definitions of key terms, gaps in coverage of threats to de-identification, and areas for improvement in usability. We identify directions for future research and suggest changes to de-identification guidance in order to better support practitioners in conducting effective de-identification.",
            "keywords": [
                "De-identification",
                "Microdata",
                "Data Privacy",
                "Thematic Analysis",
                "Guidance Usability"
            ]
        },
        "url": "URL#256679",
        "sema_paperId": "ce8cb80330a1609c4d4de65d77c4d221efcbfbea"
    },
    {
        "@score": "1",
        "@id": "256680",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "77/7625",
                        "text": "Zhiyong Guo"
                    },
                    {
                        "@pid": "288/6749",
                        "text": "Mingqing Kang"
                    },
                    {
                        "@pid": "90/5014",
                        "text": "V. N. Venkatakrishnan"
                    },
                    {
                        "@pid": "88/4984",
                        "text": "Rigel Gjomemo"
                    },
                    {
                        "@pid": "28/8733",
                        "text": "Yinzhi Cao"
                    }
                ]
            },
            "title": "ReactAppScan: Mining React Application Vulnerabilities via Component Graph.",
            "venue": "CCS",
            "pages": "585-599",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/GuoKVGC24",
            "doi": "10.1145/3658644.3670331",
            "ee": "https://doi.org/10.1145/3658644.3670331",
            "url": "https://dblp.org/rec/conf/ccs/GuoKVGC24",
            "abstract": "React, a single-page application framework, has recently become popular among web developers due to its flexible and convenient management of web application states via a syntax extension to JavaScript, called JSX (JavaScript and XML). Despite its abundant functionalities, the security of React, especially vulnerability detection, still lags: many existing vulnerability detection works do not support JSX let alone React Data Flow introduced by React components. The only exception is CodeQL, which supports JSX syntax. However, CodeQL cannot properly track React Data Flow across different components for detecting vulnerabilities. In this paper, we design a novel framework, called ReactApp-Scan, which constructs a Component Graph (CoG) for tracking Re-actDataFlowand detectingvulnerabilitiesfollowingbothJavaScript and React data flows. Specifically, ReactAppScan relies on abstract interpretation to build such a component graph via tracking component lifecycles and then detects vulnerabilities via finding paths be-tween sources and sinks. Our evaluation shows that ReactAppScan detects 61 zero-day vulnerabilities in real-world React applications. We have responsibly reported all the vulnerabilities and so far six vulnerabilities have been fixed and two have been acknowledged.",
            "keywords": [
                "React Security",
                "Vulnerability Detection",
                "Component Graph",
                "React Data Flow",
                "Zero-day Vulnerabilities"
            ]
        },
        "url": "URL#256680",
        "sema_paperId": "f0a4210c2f9ed0bfd7d3decf855775683dad0495"
    },
    {
        "@score": "1",
        "@id": "256681",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "367/9427",
                        "text": "Anna Yoo Jeong Ha"
                    },
                    {
                        "@pid": "268/5494",
                        "text": "Josephine Passananti"
                    },
                    {
                        "@pid": "359/4253",
                        "text": "Ronik Bhaskar"
                    },
                    {
                        "@pid": "217/9308",
                        "text": "Shawn Shan"
                    },
                    {
                        "@pid": "367/9391",
                        "text": "Reid Southen"
                    },
                    {
                        "@pid": "20/134-2",
                        "text": "Hai-Tao Zheng 0002"
                    },
                    {
                        "@pid": "z/BenYZhao",
                        "text": "Ben Y. Zhao"
                    }
                ]
            },
            "title": "Organic or Diffused: Can We Distinguish Human Art from AI-generated Images?",
            "venue": "CCS",
            "pages": "4822-4836",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/HaPBSSZZ24",
            "doi": "10.1145/3658644.3670306",
            "ee": "https://doi.org/10.1145/3658644.3670306",
            "url": "https://dblp.org/rec/conf/ccs/HaPBSSZZ24",
            "abstract": "The advent of generative AI images has completely disrupted the art world. Distinguishing AI generated images from human art is a challenging problem whose impact is growing over time. A failure to address this problem allows bad actors to defraud individuals paying a premium for human art and companies whose stated policies forbid AI imagery. It is also critical for content owners to establish copyright, and for model trainers interested in curating training data in order to avoid potential model collapse. There are several different approaches to distinguishing human art from AI images, including classifiers trained by supervised learning, research tools targeting diffusion models, and identification by professional artists using their knowledge of artistic techniques. In this paper, we seek to understand how well these approaches can perform against today's modern generative models in both benign and adversarial settings. We curate real human art across 7 styles, generate matching images from 5 generative models, and apply 8 detectors (5 automated detectors and 3 different human groups including 180 crowdworkers, 4000+ professional artists, and 13 expert artists experienced at detecting AI). Both Hive and expert artists do very well, but make mistakes in different ways (Hive is weaker against adversarial perturbations while Expert artists produce higher false positives). We believe these weaknesses will remain as models continue to evolve, and use our data to demonstrate why a combined team of human and automated detectors provides the best combination of accuracy and robustness.",
            "keywords": [
                "Generative AI Art",
                "Art Detection",
                "AI vs Human Art",
                "Image Classification",
                "Artistic Techniques"
            ]
        },
        "url": "URL#256681",
        "sema_paperId": "dd44a086729e962af046aff808385b523fbcd856"
    },
    {
        "@score": "1",
        "@id": "256682",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "234/8769",
                        "text": "Dongqi Han"
                    },
                    {
                        "@pid": "58/5311",
                        "text": "Zhiliang Wang"
                    },
                    {
                        "@pid": "39/10651",
                        "text": "Ruitao Feng"
                    },
                    {
                        "@pid": "63/7146",
                        "text": "Minghui Jin"
                    },
                    {
                        "@pid": "43/8167",
                        "text": "Wenqi Chen"
                    },
                    {
                        "@pid": "78/2022",
                        "text": "Kai Wang"
                    },
                    {
                        "@pid": "37/5976",
                        "text": "Su Wang"
                    },
                    {
                        "@pid": "62/2814-1",
                        "text": "Jiahai Yang 0001"
                    },
                    {
                        "@pid": "93/5648",
                        "text": "Xingang Shi"
                    },
                    {
                        "@pid": "77/5776",
                        "text": "Xia Yin"
                    },
                    {
                        "@pid": "51/3710-160",
                        "text": "Yang Liu 0160"
                    }
                ]
            },
            "title": "Rules Refine the Riddle: Global Explanation for Deep Learning-Based Anomaly Detection in Security Applications.",
            "venue": "CCS",
            "pages": "4509-4523",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/HanWFJCWW0SYL24",
            "doi": "10.1145/3658644.3670375",
            "ee": "https://doi.org/10.1145/3658644.3670375",
            "url": "https://dblp.org/rec/conf/ccs/HanWFJCWW0SYL24",
            "abstract": "Deep learning (DL) based anomaly detection has shown great promise in the field of security due to its remarkable performance in various tasks. However, the issue of poor interpretability in DL models has significantly impeded their deployment in practical security applications. Despite the progress made in existing studies on DL explanations, the majority of them focus on providing local explanations for individual samples, neglecting the global understanding of the model knowledge. Furthermore, most explanations for supervised models fail to apply to anomaly detection due to their different learning mechanisms.",
            "pdf_url": "",
            "keywords": [
                "Anomaly Detection",
                "Model Interpretability",
                "Global Explanations",
                "Deep Learning Explanations",
                "Security Applications"
            ]
        },
        "url": "URL#256682",
        "sema_paperId": "25ab8d9d9a63b946e24a7708ae79aaf0028417bd"
    },
    {
        "@score": "1",
        "@id": "256683",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "310/0337",
                        "text": "Xingshuo Han"
                    },
                    {
                        "@pid": "224/4500",
                        "text": "Haozhao Wang"
                    },
                    {
                        "@pid": "292/0013",
                        "text": "Kangqiao Zhao"
                    },
                    {
                        "@pid": "236/9144",
                        "text": "Gelei Deng"
                    },
                    {
                        "@pid": "89/3127",
                        "text": "Yuan Xu"
                    },
                    {
                        "@pid": "277/7585",
                        "text": "Hangcheng Liu"
                    },
                    {
                        "@pid": "15/4507-1",
                        "text": "Han Qiu 0001"
                    },
                    {
                        "@pid": "77/7902-4",
                        "text": "Tianwei Zhang 0004"
                    }
                ]
            },
            "title": "VisionGuard: Secure and Robust Visual Perception of Autonomous Vehicles in Practice.",
            "venue": "CCS",
            "pages": "1864-1878",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/HanWZDXL0024",
            "doi": "10.1145/3658644.3670296",
            "ee": "https://doi.org/10.1145/3658644.3670296",
            "url": "https://dblp.org/rec/conf/ccs/HanWZDXL0024",
            "abstract": "Modern Autonomous Vehicles (AVs) implement the Visual Perception Module (VPM) to perceive their surroundings. This VPM adopts various Deep Neural Network (DNN) models to process the data collected from cameras and LiDAR. Prior studies have shown that these models are vulnerable to physical adversarial examples (PAEs), which pose a critical safety risk to the autonomous driving task. While a few defense methods have been proposed to safeguard AVs, most of them only target a limited set of attack types and specific scenarios, making them impractical for real-world protection. In this paper, we introduce VisionGuard , a novel and practical methodology to comprehensively detect and mitigate various types of PAEs to the VPM. The key of VisionGuard is to leverage the spatiotemporal inconsistency property of PAEs to detect anomalies. It predicts the motion states from historical ones and compares them with the current driving states to identify any motion inconsistency caused by physical attacks. We evaluate 9 state-of-the-art PAEs against both camera and camera-LiDAR fusion-based object classification & detection models. Experimental results in both simulation and physical world validate the effectiveness",
            "keywords": [
                "Autonomous Vehicles",
                "Visual Perception Module",
                "Physical Adversarial Examples",
                "Anomaly Detection",
                "Spatiotemporal Inconsistency"
            ]
        },
        "url": "URL#256683",
        "sema_paperId": "b2738838d92acb0ecc2cbccfc1e4904b54a09a95"
    },
    {
        "@score": "1",
        "@id": "256684",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "260/9439",
                        "text": "Yurong Hao"
                    },
                    {
                        "@pid": "49/7565",
                        "text": "Xihui Chen"
                    },
                    {
                        "@pid": "275/9069",
                        "text": "Xiaoting Lyu"
                    },
                    {
                        "@pid": "27/4749",
                        "text": "Jiqiang Liu"
                    },
                    {
                        "@pid": "90/2052",
                        "text": "Yongsheng Zhu"
                    },
                    {
                        "@pid": "82/4194",
                        "text": "Zhiguo Wan"
                    },
                    {
                        "@pid": "m/SjoukeMauw",
                        "text": "Sjouke Mauw"
                    },
                    {
                        "@pid": "w/WeiWang12",
                        "text": "Wei Wang 0012"
                    }
                ]
            },
            "title": "Not One Less: Exploring Interplay between User Profiles and Items in Untargeted Attacks against Federated Recommendation.",
            "venue": "CCS",
            "pages": "2889-2903",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/HaoCLLZWM024",
            "doi": "10.1145/3658644.3670365",
            "ee": "https://doi.org/10.1145/3658644.3670365",
            "url": "https://dblp.org/rec/conf/ccs/HaoCLLZWM024",
            "abstract": "Federated recommendation (FR) is a decentralised approach to training personalised recommender systems, protecting users' privacy by avoiding data collection. Despite its privacy advantages, FR remains vulnerable to poisoning attacks. We focus on untargeted poisoning attacks against FR which degrade the overall performance of recommender services, leading to a detrimental impact on user experience and service quality. In this paper, we propose a general framework to formalise untargeted attacks and identify the vital role played by the interplay between items and user profiles in determining FR's performance. We present an untargeted attack FRecAttack2which exploits this interplay. Specifically, we develop various methods for sampling user profiles, which approximate user distributions with and without collusion among malicious users. Then we leverage a new measurement to identify items that can disrupt the original interplay with user profiles, based on the change velocity of items' recommendation scores during optimisation. Extensive experiments demonstrate the superiority of our attack, outperforming existing methods by up to 27.56%, and its stealthiness in evading mainstream defences. To counteract untargeted attacks, we present a defence GuardCQ to detect malicious users by quantifying their contribution to boost the right interplay between items and user profiles. Empirical results show that GuardCQ effectively mitigates the attack's impact on FR and enhances the robustness of FR against poisoning attacks.",
            "pdf_url": "",
            "keywords": [
                "Federated Recommendation",
                "Untargeted Poisoning Attacks",
                "User Profiles",
                "Item Interplay",
                "Defensive Mechanisms"
            ]
        },
        "url": "URL#256684",
        "sema_paperId": "21ab6426f5adbfcb3804620760ceb1eb806517db"
    },
    {
        "@score": "1",
        "@id": "256685",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "16/3418",
                        "text": "Yu He"
                    },
                    {
                        "@pid": "329/5678",
                        "text": "Boheng Li"
                    },
                    {
                        "@pid": "72/628",
                        "text": "Yao Wang"
                    },
                    {
                        "@pid": "116/8591",
                        "text": "Mengda Yang"
                    },
                    {
                        "@pid": "74/3634-6",
                        "text": "Juan Wang 0006"
                    },
                    {
                        "@pid": "02/2870",
                        "text": "Hongxin Hu"
                    },
                    {
                        "@pid": "83/504-1",
                        "text": "Xingyu Zhao 0001"
                    }
                ]
            },
            "title": "Is Difficulty Calibration All We Need? Towards More Practical Membership Inference Attacks.",
            "venue": "CCS",
            "pages": "1226-1240",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/HeLWYWHZ24",
            "doi": "10.1145/3658644.3690316",
            "ee": "https://doi.org/10.1145/3658644.3690316",
            "url": "https://dblp.org/rec/conf/ccs/HeLWYWHZ24",
            "abstract": "The vulnerability of machine learning models to Membership Inference Attacks (MIAs) has garnered considerable attention in recent years. These attacks determine whether a data sample belongs to the model's training set or not. Recent research has focused on reference-based attacks, which leverage difficulty calibration with independently trained reference models. While empirical studies have demonstrated its effectiveness, there is a notable gap in our understanding of the circumstances under which it succeeds or fails. In this paper, we take a further step towards a deeper understanding of the role of difficulty calibration. Our observations reveal inherent limitations in calibration methods, leading to the misclassification of non-members and suboptimal performance, particularly on high-loss samples. We further identify that these errors stem from an imperfect sampling of the potential distribution and a strong dependence of membership scores on the model parameters. By shedding light on these issues, we propose RAPID: a query-efficient and computation-efficient MIA that directly \\textbf{R}e-lever\\textbf{A}ges the original membershi\\textbf{P} scores to m\\textbf{I}tigate the errors in \\textbf{D}ifficulty calibration. Our experimental results, spanning 9 datasets and 5 model architectures, demonstrate that RAPID outperforms previous state-of-the-art attacks (e.g., LiRA and Canary offline) across different metrics while remaining computationally efficient. Our observations and analysis challenge the current de facto paradigm of difficulty calibration in high-precision inference, encouraging greater attention to the persistent risks posed by MIAs in more practical scenarios.",
            "keywords": [
                "Membership Inference Attacks",
                "Difficulty Calibration",
                "Model Vulnerability",
                "Error Mitigation",
                "RAPID"
            ]
        },
        "url": "URL#256685",
        "sema_paperId": "99784f2814cbab4a9e3fb263843c3fa91b78a370"
    },
    {
        "@score": "1",
        "@id": "256686",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "29/3050",
                        "text": "Jiaxing He"
                    },
                    {
                        "@pid": "86/8501-2",
                        "text": "Kang Yang 0002"
                    },
                    {
                        "@pid": "253/8184",
                        "text": "Guofeng Tang"
                    },
                    {
                        "@pid": "144/6265",
                        "text": "Zhangjie Huang"
                    },
                    {
                        "@pid": "38/4000",
                        "text": "Li Lin"
                    },
                    {
                        "@pid": "195/7421",
                        "text": "Changzheng Wei"
                    },
                    {
                        "@pid": "77/4933-2",
                        "text": "Ying Yan 0002"
                    },
                    {
                        "@pid": "35/7092",
                        "text": "Wei Wang"
                    }
                ]
            },
            "title": "Rhombus: Fast Homomorphic Matrix-Vector Multiplication for Secure Two-Party Inference.",
            "venue": "CCS",
            "pages": "2490-2504",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/HeYTHLWYW24",
            "doi": "10.1145/3658644.3690281",
            "ee": "https://doi.org/10.1145/3658644.3690281",
            "url": "https://dblp.org/rec/conf/ccs/HeYTHLWYW24",
            "abstract": "We presentRhombus, a new secure matrix-vector multiplication (MVM) protocol in the semi-honest two-party setting, which is able to be seamlessly integrated into existing privacy-preserving machine learning (PPML) frameworks and serve as the basis of secure computation in linear layers.Rhombusadopts RLWE-based homomorphic encryption (HE) with coefficient encoding, which allows messages to be chosen from not only a field Fpbut also a ring Z2l, where the latter supports faster computation in non-linear layers. To achieve better efficiency, we develop an input-output packing technique that reduces the communication cost incurred by HE with coefficient encoding by about 21\u00d7, and propose a split-point picking technique that reduces the number of rotations to that sublinear in the matrix dimension. Compared to the recent protocolHELiKsby Balla and Koushanfar (CCS'23), our implementation demonstrates thatRhombusimproves the whole performance of an MVM protocol by a factor of 7.4x ~ 8x, and improves the end-to-end performance of secure two-party inference of ResNet50 by a factor of 4.6x ~ 18x.",
            "pdf_url": "",
            "keywords": [
                "Homomorphic Encryption",
                "Matrix-Vector Multiplication",
                "Secure Two-Party Computation",
                "Privacy-Preserving Machine Learning",
                "Efficiency Optimization"
            ]
        },
        "url": "URL#256686"
    },
    {
        "@score": "1",
        "@id": "256687",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "279/5630",
                        "text": "Elias Heftrig"
                    },
                    {
                        "@pid": "94/7397",
                        "text": "Haya Schulmann"
                    },
                    {
                        "@pid": "332/3113",
                        "text": "Niklas Vogel"
                    },
                    {
                        "@pid": "90/308",
                        "text": "Michael Waidner"
                    }
                ]
            },
            "title": "The Harder You Try, The Harder You Fail: The KeyTrap Denial-of-Service Algorithmic Complexity Attacks on DNSSEC.",
            "venue": "CCS",
            "pages": "497-510",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/HeftrigSVW24",
            "doi": "10.1145/3658644.3670389",
            "ee": "https://doi.org/10.1145/3658644.3670389",
            "url": "https://dblp.org/rec/conf/ccs/HeftrigSVW24",
            "abstract": "Availability is a major concern in the design of DNSSEC. To ensure availability, DNSSEC follows Postel's Law [RFC1123]:\"Be liberal in what you accept, and conservative in what you send.\"Hence, nameservers should send not just one matching key for a record set, but all the relevant cryptographic material, e.g., all the keys for all the ciphers that they support and all the corresponding signatures. This ensures that validation succeeds, and hence availability, even if some of the DNSSEC keys are misconfigured, incorrect or correspond to unsupported ciphers. We show that this design of DNSSEC is flawed. Exploiting vulnerable recommendations in the DNSSEC standards, we develop a new class of DNSSEC-based algorithmic complexity attacks on DNS, we dub KeyTrap attacks. All popular DNS implementations and services are vulnerable. With just a single DNS packet, the KeyTrap attacks lead to a 2.000.000x spike in CPU instruction count in vulnerable DNS resolvers, stalling some for as long as 16 hours. This devastating effect prompted major DNS vendors to refer to KeyTrap as the worst attack on DNS ever discovered. Exploiting KeyTrap, an attacker could effectively disable Internet access in any system utilizing a DNSSEC-validating resolver. We disclosed KeyTrap to vendors and operators on November 2, 2023, confidentially reporting the vulnerabilities to a closed group of DNS experts, operators and developers from the industry. Since then we have been working with all major vendors to mitigate KeyTrap, repeatedly discovering and assisting in closing weaknesses in proposed patches. Following our disclosure, the industry-wide umbrella CVE-2023-50387 has been assigned, covering the DNSSEC protocol vulnerabilities we present in this work.",
            "keywords": [
                "DNSSEC",
                "Denial-of-Service",
                "Algorithmic Complexity Attacks",
                "KeyTrap Attacks",
                "CVE-2023-50387"
            ]
        },
        "url": "URL#256687",
        "sema_paperId": "a6ed4211d8baf1cb192dde6bb9dc15f8766c4744"
    },
    {
        "@score": "1",
        "@id": "256688",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "298/9320",
                        "text": "Julius Hermelink"
                    },
                    {
                        "@pid": "152/9560",
                        "text": "Kai-Chun Ning"
                    },
                    {
                        "@pid": "117/6697",
                        "text": "Richard Petri 0001"
                    },
                    {
                        "@pid": "270/7231",
                        "text": "Emanuele Strieder"
                    }
                ]
            },
            "title": "The Insecurity of Masked Comparisons: SCAs on ML-KEM&apos;s FO-Transform.",
            "venue": "CCS",
            "pages": "2430-2444",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/HermelinkN0S24",
            "doi": "10.1145/3658644.3690339",
            "ee": "https://doi.org/10.1145/3658644.3690339",
            "url": "https://dblp.org/rec/conf/ccs/HermelinkN0S24",
            "abstract": "NIST released the draft standard for ML-KEM, and we can expect its widespread use in the embedded world in the near future. Several side-channel attacks have been proposed, and one line of research has focused on attacks against the comparison step of the FO-transform. A work published at TCHES 2022 stressed the need for secure higher-order masked comparisons beyond thet-probing model and proposed a higher-order masked comparison method. Subsequently, D'Anvers, Van Beirendonck, and Verbauwhede improved upon the performance of several previous proposals; their higher-order masked algorithm currently achieves the highest performance for masked comparisons.",
            "pdf_url": "",
            "keywords": [
                "Side-Channel Attacks",
                "Higher-Order Masking",
                "Masked Comparisons",
                "FO-Transform",
                "ML-KEM"
            ]
        },
        "url": "URL#256688"
    },
    {
        "@score": "1",
        "@id": "256689",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "296/3944",
                        "text": "Jonas Hielscher"
                    },
                    {
                        "@pid": "323/0206",
                        "text": "Markus Sch\u00f6ps"
                    },
                    {
                        "@pid": "392/3274",
                        "text": "Jens Opdenbusch"
                    },
                    {
                        "@pid": "392/3006",
                        "text": "Felix Reichmann"
                    },
                    {
                        "@pid": "308/6435",
                        "text": "Marco Gutfleisch"
                    },
                    {
                        "@pid": "179/7489",
                        "text": "Karola Marky"
                    },
                    {
                        "@pid": "84/3561",
                        "text": "Simon Parkin"
                    }
                ]
            },
            "title": "Selling Satisfaction: A Qualitative Analysis of Cybersecurity Awareness Vendors&apos; Promises.",
            "venue": "CCS",
            "pages": "2666-2680",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/HielscherSORGMP24",
            "doi": "10.1145/3658644.3690196",
            "ee": "https://doi.org/10.1145/3658644.3690196",
            "url": "https://dblp.org/rec/conf/ccs/HielscherSORGMP24",
            "abstract": "Security awareness and training (SAT) vendors operate in a growing multi-billion dollar market. They publish various marketing promises on their websites to their customers -- organizations of all sizes. This paper investigates how these promises align with customers' needs, how they relate to human-centered security challenges highlighted in prior research, and what narrative is presented regarding the role of employees (as SAT recipients). We also investigate the level of transparency in vendor promises, as to whether it constitutes an information asymmetry. We gathered search terms from n=30 awareness professionals to perform an automated Google search and scraping of SAT vendors' websites. We then performed a thematic analysis of 2,476 statements on 156 websites from 59 vendors. We found that the messaging from SAT vendors precisely targets customers' need for easy-to-implement and compliance-fulfilling SAT products; how SAT products are offered also means that some of the impacts of SAT go unmentioned and are transferred to the customer, such as user support. In this vendor-customer relationship, employees are portrayed as a source of weaknesses, needing an indefinite amount of training to be incorporated into the organization's protection. We conclude with suggestions for SAT vendors and regulators, notably toward an SAT ecosystem that directly links SAT solutions to usable security technologies within the organization environment.",
            "pdf_url": "",
            "keywords": [
                "Cybersecurity Awareness Training",
                "Vendor Promises",
                "Human-Centered Security",
                "Information Asymmetry",
                "Employee Training Needs"
            ]
        },
        "url": "URL#256689",
        "sema_paperId": "ebaaea7ed47f429bc488065872e80498a9644949"
    },
    {
        "@score": "1",
        "@id": "256690",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "341/1946",
                        "text": "Florian Hirner"
                    },
                    {
                        "@pid": "356/0485",
                        "text": "Michael Streibl"
                    },
                    {
                        "@pid": "282/8054",
                        "text": "Florian Krieger"
                    },
                    {
                        "@pid": "183/5038",
                        "text": "Ahmet Can Mert"
                    },
                    {
                        "@pid": "31/9547",
                        "text": "Sujoy Sinha Roy"
                    }
                ]
            },
            "title": "Whipping the Multivariate-based MAYO Signature Scheme using Hardware Platforms.",
            "venue": "CCS",
            "pages": "3421-3435",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/HirnerSKMR24",
            "doi": "10.1145/3658644.3690258",
            "ee": "https://doi.org/10.1145/3658644.3690258",
            "url": "https://dblp.org/rec/conf/ccs/HirnerSKMR24",
            "abstract": "NIST issued a new call in 2023 to diversify the portfolio of quantum-resistant digital signature schemes since the current portfolio relies on lattice problems. The MAYO scheme, which builds on the Un-balanced Oil and Vinegar (UOV) problem, is a promising candidate for this new call. MAYO introduces emulsifier maps and a novel \u2018whipping\u2019 technique to significantly reduce the key sizes compared to previous UOV schemes. This paper provides a comprehensive analysis of the implementation aspects of MAYO and proposes several optimization techniques that we use to implement a high-speed hardware accelerator. The first optimization technique is the partial unrolling of the emulsification process to increase parallelization. The second proposed optimization is a novel memory structure enabling the parallelization of significant bottlenecks in the MAYO scheme. In addition to this, we present a flexible transposing technique for the data format used in MAYO that can be expanded to other UOV-based schemes. We use these techniques to design the first high-speed ASIC and FPGA accelerator that supports all operations of the MAYO scheme for different NIST security levels. Compared with state-of-the-art, like HaMAYO [23] and UOV [7], our FPGA design shows a performance benefit of up to three orders of magnitude in both latency and area-time-product. Furthermore, we lower the BRAM consumption by up to 2 . 8 \u00d7 compared to these FPGA implementations. Compared to high-end CPU implementations, our ASIC design allows between 2 . 81 \u00d7 and 60 . 14 \u00d7 higher throughputs. This increases the number of signing operations per second from 483 to 13424, thereby fostering performant deployment of the MAYO scheme in time-critical applications.",
            "keywords": [
                "Quantum-resistant Digital Signatures",
                "MAYO Scheme",
                "Hardware Acceleration",
                "Unbalanced Oil and Vinegar Problem",
                "Key Size Optimization"
            ]
        },
        "url": "URL#256690",
        "sema_paperId": "1135d986fe510d51eb6ee2631dc59f2d32828ee4"
    },
    {
        "@score": "1",
        "@id": "256691",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "246/5631",
                        "text": "Jana Hofmann"
                    },
                    {
                        "@pid": "f/CedricFournet",
                        "text": "C\u00e9dric Fournet"
                    },
                    {
                        "@pid": "10/3908",
                        "text": "Boris K\u00f6pf"
                    },
                    {
                        "@pid": "77/11029",
                        "text": "Stavros Volos"
                    }
                ]
            },
            "title": "Gaussian Elimination of Side-Channels: Linear Algebra for Memory Coloring.",
            "venue": "CCS",
            "pages": "2799-2813",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/HofmannFKV24",
            "doi": "10.1145/3658644.3690263",
            "ee": "https://doi.org/10.1145/3658644.3690263",
            "url": "https://dblp.org/rec/conf/ccs/HofmannFKV24",
            "abstract": "Memory coloring is a software-based technique to ensure microar-chitectural isolation between trust domains sharing a CPU. Prior coloring schemes target individual microarchitectural components and thus provide only partial solutions. In this paper, we provide theoretical foundations and practical algorithms to infer comprehensive coloring schemes for modern cloud CPUs. To this end, we first formulate the requirements for effective memory coloring schemes in a set-theoretic model, including definitions for simultaneous isolation of shared components and uniform utilization of private components. We then algebraically characterize these requirements for microarchitectural components that are indexed by linear functions, which is the prevalent case in today\u2019s CPUs. Based on this, we develop efficient algorithms for computing multi-resource coloring schemes from linear indexing functions, and for reverse-engineering unknown linear indexing functions under minimal assumptions. In a case study, we use our algorithms to compute coloring schemes for recent Intel CPUs, and we show how to design indexing functions that maximize the number of supported trust domains.",
            "keywords": [
                "Memory Coloring",
                "Microarchitectural Isolation",
                "Trust Domains",
                "Linear Indexing Functions",
                "Cloud CPUs"
            ]
        },
        "url": "URL#256691",
        "sema_paperId": "6d74abfb26eaf7804e4e2048bd875156feeff7d2"
    },
    {
        "@score": "1",
        "@id": "256692",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "294/2365",
                        "text": "Jonas Hofmann"
                    },
                    {
                        "@pid": "389/5650",
                        "text": "Kien Tuong Truong"
                    }
                ]
            },
            "title": "End-to-End Encrypted Cloud Storage in the Wild: A Broken Ecosystem.",
            "venue": "CCS",
            "pages": "3988-4001",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/HofmannT24",
            "doi": "10.1145/3658644.3690309",
            "ee": "https://doi.org/10.1145/3658644.3690309",
            "url": "https://dblp.org/rec/conf/ccs/HofmannT24",
            "abstract": "End-to-end encrypted cloud storage offers a way for individuals and organisations to delegate their storage needs to a third-party, while keeping control of their data using cryptographic techniques. We conduct a cryptographic analysis of various products in the ecosystem, showing that many providers fail to provide an adequate level of security. In particular, we provide an in-depth analysis of five end-to-end encrypted cloud storage systems, namely Sync, pCloud, Icedrive, Seafile, and Tresorit, in the setting of a malicious server. These companies cumulatively have over 22 million users and are major providers in the field. We unveil severe cryptographic vulnerabilities in four of them. Our attacks invalidate the marketing claims made by the providers of these systems, showing that a malicious server can, in some cases, inject files in the encrypted storage of users, tamper with file data, and even gain direct access to the content of the files. Many of our attacks affect multiple providers in the same way, revealing common failure patterns in independent cryptographic designs. We conclude by discussing the significance of these patterns beyond the security of the specific providers.",
            "pdf_url": "",
            "keywords": [
                "End-to-End Encryption",
                "Cloud Storage Security",
                "Cryptographic Vulnerabilities",
                "Malicious Server Attacks",
                "Data Integrity"
            ]
        },
        "url": "URL#256692"
    },
    {
        "@score": "1",
        "@id": "256693",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "142/2773",
                        "text": "Naoise Holohan"
                    },
                    {
                        "@pid": "07/4982",
                        "text": "Stefano Braghin"
                    },
                    {
                        "@pid": "315/0860",
                        "text": "Mohamed Suliman 0002"
                    }
                ]
            },
            "title": "Securing Floating-Point Arithmetic for Noise Addition.",
            "venue": "CCS",
            "pages": "1954-1966",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/HolohanB024",
            "doi": "10.1145/3658644.3690347",
            "ee": "https://doi.org/10.1145/3658644.3690347",
            "url": "https://dblp.org/rec/conf/ccs/HolohanB024",
            "abstract": "Floating-point arithmetic is ubiquitous across computing, with its wide range of values, large and small, making it the preferred tool for storing, analysing, and manipulating numerical data. Its flexibility comes at the cost of additional risks in some security/privacy-aware settings. In this paper, we discuss the threat of information leakage caused by floating-point arithmetic when adding noise to sensitive values, which can allow the sensitive information to be recovered (e.g., in differential privacy). We present a solution, Mantissa Bit Manipulation (MBM), that is orders of magnitude faster than the current state-of-the-art, applicable to most continuous probability distributions and to all floating-point number formats.",
            "pdf_url": "",
            "keywords": [
                "Floating-Point Arithmetic",
                "Information Leakage",
                "Noise Addition",
                "Differential Privacy",
                "Mantissa Bit Manipulation (MBM)"
            ]
        },
        "url": "URL#256693",
        "sema_paperId": "7f5e8842adfafab411dade1eacc7999604801bb7"
    },
    {
        "@score": "1",
        "@id": "256694",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "271/7093",
                        "text": "Hanbin Hong"
                    },
                    {
                        "@pid": "58/4582-16",
                        "text": "Xinyu Zhang 0016"
                    },
                    {
                        "@pid": "123/7149",
                        "text": "Binghui Wang"
                    },
                    {
                        "@pid": "139/5759",
                        "text": "Zhongjie Ba"
                    },
                    {
                        "@pid": "79/5433",
                        "text": "Yuan Hong"
                    }
                ]
            },
            "title": "Certifiable Black-Box Attacks with Randomized Adversarial Examples: Breaking Defenses with Provable Confidence.",
            "venue": "CCS",
            "pages": "600-614",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Hong0WBH24",
            "doi": "10.1145/3658644.3690343",
            "ee": "https://doi.org/10.1145/3658644.3690343",
            "url": "https://dblp.org/rec/conf/ccs/Hong0WBH24",
            "abstract": "Black-box adversarial attacks have demonstrated strong potential to compromise machine learning models by iteratively querying the target model or leveraging transferability from a local surrogate model. Recently, such attacks can be effectively mitigated by state-of-the-art (SOTA) defenses, e.g., detection via the pattern of sequential queries, or injecting noise into the model. To our best knowledge, we take the first step to study a new paradigm of black-box attacks with provable guarantees -- certifiable black-box attacks that can guarantee the attack success probability (ASP) of adversarial examples before querying over the target model. This new black-box attack unveils significant vulnerabilities of machine learning models, compared to traditional empirical black-box attacks, e.g., breaking strong SOTA defenses with provable confidence, constructing a space of (infinite) adversarial examples with high ASP, and the ASP of the generated adversarial examples is theoretically guaranteed without verification/queries over the target model. Specifically, we establish a novel theoretical foundation for ensuring the ASP of the black-box attack with randomized adversarial examples (AEs). Then, we propose several novel techniques to craft the randomized AEs while reducing the perturbation size for better imperceptibility. Finally, we have comprehensively evaluated the certifiable black-box attacks on the CIFAR10/100, ImageNet, and LibriSpeech datasets, while benchmarking with 16 SOTA black-box attacks, against various SOTA defenses in the domains of computer vision and speech recognition. Both theoretical and experimental results have validated the significance of the proposed attack. The code and all the benchmarks are available at \\url{https://github.com/datasec-lab/CertifiedAttack}.",
            "keywords": [
                "Black-Box Attacks",
                "Adversarial Examples",
                "Certifiable Attacks",
                "Attack Success Probability",
                "Randomized Adversarial Examples"
            ]
        },
        "url": "URL#256694",
        "sema_paperId": "02fe430921731321c8ff3319e2529ec52af35b08"
    },
    {
        "@score": "1",
        "@id": "256695",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "63/6842",
                        "text": "Seok Min Hong"
                    },
                    {
                        "@pid": "05/10299",
                        "text": "Beom Heyn Kim"
                    },
                    {
                        "@pid": "m/MohammadMannan",
                        "text": "Mohammad Mannan"
                    }
                ]
            },
            "title": "Poster: Detecting Ransomware Attacks by Analyzing Replicated Block Snapshots Using Neural Networks.",
            "venue": "CCS",
            "pages": "5000-5002",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/HongKM24",
            "doi": "10.1145/3658644.3691399",
            "ee": "https://doi.org/10.1145/3658644.3691399",
            "url": "https://dblp.org/rec/conf/ccs/HongKM24",
            "abstract": "Cloud antivirus solutions address limitations of host-based malware detection such as extensive resource consumption. However, they remain vulnerable to sophisticated polymorphic and privileged malware. Also, existing solutions are not suitable to defend against destructive ransomware attacks. We propose an enhancement to existing cloud antivirus solutions that enables deep learning-based block snapshot analysis to detect evasive and privileged ransomware in virtualized environment without requiring any hardware support. Preliminary results validate the proposed approach.",
            "pdf_url": "",
            "keywords": [
                "Ransomware Detection",
                "Cloud Antivirus Solutions",
                "Block Snapshot Analysis",
                "Evasive Malware",
                "Virtualized Environment"
            ]
        },
        "url": "URL#256695",
        "sema_paperId": "674b028dd08a0a075f886895caacca4d8d87ff05"
    },
    {
        "@score": "1",
        "@id": "256696",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "379/2272",
                        "text": "Gal Horowitz"
                    },
                    {
                        "@pid": "180/7297",
                        "text": "Eyal Ronen"
                    },
                    {
                        "@pid": "90/10901",
                        "text": "Yuval Yarom"
                    }
                ]
            },
            "title": "Spec-o-Scope: Cache Probing at Cache Speed.",
            "venue": "CCS",
            "pages": "109-123",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/HorowitzRY24",
            "doi": "10.1145/3658644.3690313",
            "ee": "https://doi.org/10.1145/3658644.3690313",
            "url": "https://dblp.org/rec/conf/ccs/HorowitzRY24",
            "abstract": "Over the last two decades, microarchitectural side channels have been the focus of a large body of research on the development of new attack techniques, exploiting them to attack various classes of targets and designing mitigations. One line of work focuses on increasing the speed of the attacks, achieving higher levels of temporal resolution that can allow attackers to learn finer-grained information. The most recent addition to this line of work is Prime+Scope [CCS '21], which only requires a single access to the L1 cache to confirm the absence of victim activity in a cache set. While significantly faster than prior attacks, Prime+Scope is still an order of magnitude slower than cache access. In this work, we set out to close this gap.",
            "pdf_url": "",
            "keywords": [
                "Microarchitectural Side Channels",
                "Cache Probing",
                "Prime+Scope",
                "Temporal Resolution",
                "Cache Access Speed"
            ]
        },
        "url": "URL#256696"
    },
    {
        "@score": "1",
        "@id": "256697",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "330/4599",
                        "text": "Yuke Hu"
                    },
                    {
                        "@pid": "05/4625-1",
                        "text": "Jian Lou 0001"
                    },
                    {
                        "@pid": "51/2773-3",
                        "text": "Jiaqi Liu 0003"
                    },
                    {
                        "@pid": "260/6910",
                        "text": "Wangze Ni"
                    },
                    {
                        "@pid": "75/2611-4",
                        "text": "Feng Lin 0004"
                    },
                    {
                        "@pid": "148/4477",
                        "text": "Zhan Qin"
                    },
                    {
                        "@pid": "20/6179-1",
                        "text": "Kui Ren 0001"
                    }
                ]
            },
            "title": "ERASER: Machine Unlearning in MLaaS via an Inference Serving-Aware Approach.",
            "venue": "CCS",
            "pages": "3883-3897",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Hu00N0Q024",
            "doi": "10.1145/3658644.3670398",
            "ee": "https://doi.org/10.1145/3658644.3670398",
            "url": "https://dblp.org/rec/conf/ccs/Hu00N0Q024",
            "abstract": "Over the past years, Machine Learning-as-a-Service (MLaaS) has received a surging demand for supporting Machine Learning-driven services to offer revolutionized user experience across diverse application areas. MLaaS provides inference service with low inference latency based on an ML model trained using a dataset collected from numerous individual data owners. Recently, for the sake of data owners' privacy and to comply with the\"right to be forgotten (RTBF)\"as enacted by data protection legislation, many machine unlearning methods have been proposed to remove data owners' data from trained models upon their unlearning requests. However, despite their promising efficiency, almost all existing machine unlearning methods handle unlearning requests independently from inference requests, which unfortunately introduces a new security issue of inference service obsolescence and a privacy vulnerability of undesirable exposure for machine unlearning in MLaaS. In this paper, we propose the ERASER framework for machinE unleaRning in MLaAS via an inferencE seRving-aware approach. ERASER strategically choose appropriate unlearning execution timing to address the inference service obsolescence issue. A novel inference consistency certification mechanism is proposed to avoid the violation of RTBF principle caused by postponed unlearning executions, thereby mitigating the undesirable exposure vulnerability. ERASER offers three groups of design choices to allow for tailor-made variants that best suit the specific environments and preferences of various MLaaS systems. Extensive empirical evaluations across various settings confirm ERASER's effectiveness, e.g., it can effectively save up to 99% of inference latency and 31% of computation overhead over the inference-oblivion baseline.",
            "keywords": [
                "Machine Learning-as-a-Service (MLaaS)",
                "Machine Unlearning",
                "Inference Service",
                "Right to be Forgotten (RTBF)",
                "Inference Consistency Certification"
            ]
        },
        "url": "URL#256697",
        "sema_paperId": "790a49513438c2fa15bda9570ec0ea05ff238403"
    },
    {
        "@score": "1",
        "@id": "256698",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "161/8255",
                        "text": "Yuqi Hu"
                    },
                    {
                        "@pid": "356/3784",
                        "text": "Suood Alroomi"
                    },
                    {
                        "@pid": "306/1347",
                        "text": "Sena Sahin"
                    },
                    {
                        "@pid": "53/10825",
                        "text": "Frank Li 0001"
                    }
                ]
            },
            "title": "Unmasking the Security and Usability of Password Masking.",
            "venue": "CCS",
            "pages": "4241-4255",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/HuAS024",
            "doi": "10.1145/3658644.3690333",
            "ee": "https://doi.org/10.1145/3658644.3690333",
            "url": "https://dblp.org/rec/conf/ccs/HuAS024",
            "abstract": "Password masking, a practice where passwords are obscured during entry, is widely adopted for online authentication. However, its merits have been debated for over a decade, with questions about its security benefits and concerns about its usability impact. Yet to date, masking has received limited prior exploration. In this work, we empirically investigate the security and usability impact of password masking. We first assess the masking practices of popular browsers and websites, demonstrating masking\u2019s ubiquity as well as its design diversity. Guided by our real-world observations, we then conduct a mixed-method evaluation of masking for both mobile and PC devices, combining a survey of over 200 participants on their experiences with and perspectives on masking along with user experiments of 600 participants performing pass-word logins under varying masking conditions. Through our study, we uncover misconceptions about masking, masking\u2019s usability and security impact, and user preferences on masking\u2019s use and its design. Ultimately, our study establishes empirical grounding on how this popular technique manifests in practice, providing recommendations for its use moving forward.",
            "keywords": [
                "Password Masking",
                "Usability",
                "User Experience",
                "Authentication",
                "Security Impact"
            ]
        },
        "url": "URL#256698",
        "sema_paperId": "56d31204d60bf60e16caa0b4f57d99eabaa2457e"
    },
    {
        "@score": "1",
        "@id": "256699",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "139/4106",
                        "text": "Jheng-Jia Huang"
                    },
                    {
                        "@pid": "23/6896",
                        "text": "Guan-Yu Chen"
                    },
                    {
                        "@pid": "76/1704",
                        "text": "Nai-Wei Lo"
                    }
                ]
            },
            "title": "Poster: Post-Quantum Identity-Based Matching Encryption with Revocable Decryption Key.",
            "venue": "CCS",
            "pages": "5006-5008",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/HuangCL24",
            "doi": "10.1145/3658644.3691397",
            "ee": "https://doi.org/10.1145/3658644.3691397",
            "url": "https://dblp.org/rec/conf/ccs/HuangCL24",
            "abstract": "In recent years, scholars have developed Identity-Based Matching Encryption (IB-ME), which enables both the sender and the receiver to specify identities, ensuring ciphertext confidentiality only when these identities match. Building on this concept, our work introduces Revocable Identity-Based Matching Encryption (RIB-ME), which incorporates a revocable mechanism to withdraw decryption rights from unauthorized users. Current RIB-ME schemes rely on a variant of the Diffie-Hellman assumption, rendering it susceptible to quantum computing attacks. To address this vulnerability, we propose a generic construction of RIB-ME inspired by Wang et al. Our approach employs two-level Revocable Hierarchical Identity-Based Encryption (RHIBE) and Identity-Based Signature (IBS) and is compatible with post-quantum encryption schemes. This enables the development of a generic construction of RIB-ME and the creation of the first post-quantum RIB-ME through the use of post-quantum constructions.",
            "pdf_url": "",
            "keywords": [
                "Post-Quantum Cryptography",
                "Identity-Based Matching Encryption",
                "Revocable Encryption",
                "Decryption Key Revocation",
                "Quantum Resistance"
            ]
        },
        "url": "URL#256699",
        "sema_paperId": "57ac216668ca0f0f7e1fa0c8f06023fc29a7e912"
    },
    {
        "@score": "1",
        "@id": "256700",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "62/10077",
                        "text": "Zonghao Huang"
                    },
                    {
                        "@pid": "03/9437",
                        "text": "Neil Zhenqiang Gong"
                    },
                    {
                        "@pid": "r/MichaelKReiter",
                        "text": "Michael K. Reiter"
                    }
                ]
            },
            "title": "A General Framework for Data-Use Auditing of ML Models.",
            "venue": "CCS",
            "pages": "1300-1314",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/HuangGR24",
            "doi": "10.1145/3658644.3690226",
            "ee": "https://doi.org/10.1145/3658644.3690226",
            "url": "https://dblp.org/rec/conf/ccs/HuangGR24",
            "abstract": "Auditing the use of data in training machine-learning (ML) models is an increasingly pressing challenge, as myriad ML practitioners routinely leverage the effort of content creators to train models without their permission. In this paper, we propose a general method to audit an ML model for the use of a data-owner's data in training, without prior knowledge of the ML task for which the data might be used. Our method leverages any existing black-box membership inference method, together with a sequential hypothesis test of our own design, to detect data use with a quantifiable, tunable false-detection rate. We show the effectiveness of our proposed framework by applying it to audit data use in two types of ML models, namely image classifiers and foundation models.",
            "pdf_url": "",
            "keywords": [
                "Data-Use Auditing",
                "Membership Inference",
                "Model Training",
                "Data Ownership",
                "False Detection Rate"
            ]
        },
        "url": "URL#256700"
    },
    {
        "@score": "1",
        "@id": "256701",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "128/9270",
                        "text": "Zhicong Huang"
                    },
                    {
                        "@pid": "231/4234",
                        "text": "Wen-jie Lu"
                    },
                    {
                        "@pid": "82/8599",
                        "text": "Yuchen Wang"
                    },
                    {
                        "@pid": "78/10002",
                        "text": "Cheng Hong"
                    },
                    {
                        "@pid": "64/5099",
                        "text": "Tao Wei"
                    },
                    {
                        "@pid": "60/810",
                        "text": "Wenguang Chen"
                    }
                ]
            },
            "title": "Coral:  Maliciously Secure Computation Framework for Packed and Mixed Circuits.",
            "venue": "CCS",
            "pages": "810-824",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/HuangLWHWC24",
            "doi": "10.1145/3658644.3690223",
            "ee": "https://doi.org/10.1145/3658644.3690223",
            "url": "https://dblp.org/rec/conf/ccs/HuangLWHWC24",
            "abstract": "Achieving malicious security with high efficiency in dishonest-majority secure multiparty computation is a formidable challenge. The milestone works SPDZ and TinyOT have spawn a large family of protocols in this direction. For boolean circuits, state-of-the-art works (Cascudo et. al, TCC 2020 and Escudero et. al, CRYPTO 2022) have proposed schemes based on reverse multiplication-friendly embedding (RMFE) to reduce the amortized cost. However, these protocols are theoretically described and analyzed, resulting in a significant gap between theory and concrete efficiency.",
            "pdf_url": "",
            "keywords": [
                "Malicious Secure Computation",
                "Dishonest Majority",
                "Multiparty Computation",
                "Reverse Multiplication-Friendly Embedding",
                "Concrete Efficiency"
            ]
        },
        "url": "URL#256701"
    },
    {
        "@score": "1",
        "@id": "256702",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "35/5361",
                        "text": "Kaiming Huang"
                    },
                    {
                        "@pid": "31/1273",
                        "text": "Mathias Payer"
                    },
                    {
                        "@pid": "31/8302",
                        "text": "Zhiyun Qian"
                    },
                    {
                        "@pid": "11/2192",
                        "text": "Jack Sampson"
                    },
                    {
                        "@pid": "91/6206",
                        "text": "Gang Tan"
                    },
                    {
                        "@pid": "45/576",
                        "text": "Trent Jaeger"
                    }
                ]
            },
            "title": "Top of the Heap: Efficient Memory Error Protection of Safe Heap Objects.",
            "venue": "CCS",
            "pages": "1330-1344",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/HuangPQSTJ24",
            "doi": "10.1145/3658644.3690310",
            "ee": "https://doi.org/10.1145/3658644.3690310",
            "url": "https://dblp.org/rec/conf/ccs/HuangPQSTJ24",
            "abstract": "Heap memory errors remain a major source of software vulnerabilities. Existing memory safety defenses aim at protecting all objects, resulting in high performance cost and incomplete protection. Instead, we propose an approach that accurately identifies objects that are inexpensive to protect, and design a method to protect such objects comprehensively from all classes of memory errors. Towards this goal, we introduce the Uriah system that (1) statically identifies the heap objects whose accesses satisfy spatial and type safety, and (2) dynamically allocates such\"safe\"heap objects on an isolated safe heap to enforce a form of temporal safety while preserving spatial and type safety, called temporal allocated-type safety. Uriah finds 72.0% of heap allocation sites produce objects whose accesses always satisfy spatial and type safety in the SPEC CPU2006/2017 benchmarks, 5 server programs, and Firefox, which are then isolated on a safe heap using Uriah allocator to enforce temporal allocated-type safety. Uriah incurs only 2.9% and 2.6% runtime overhead, along with 9.3% and 5.4% memory overhead, on the SPEC CPU 2006 and 2017 benchmarks, while preventing exploits on all the heap memory errors in DARPA CGC binaries and 28 recent CVEs. Additionally, using existing defenses to enforce their memory safety guarantees on the unsafe heap objects significantly reduces overhead, enabling the protection of heap objects from all classes of memory errors at more practical costs.",
            "keywords": [
                "Memory Safety",
                "Heap Memory Errors",
                "Temporal Allocated-Type Safety",
                "Safe Heap Objects",
                "Uriah System"
            ]
        },
        "url": "URL#256702",
        "sema_paperId": "6eb59f184443b0737d94dd150a76cbff9111da42"
    },
    {
        "@score": "1",
        "@id": "256703",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "332/6167",
                        "text": "Yongheng Huang"
                    },
                    {
                        "@pid": "360/7695",
                        "text": "Chenghang Shi"
                    },
                    {
                        "@pid": "39/2936-9",
                        "text": "Jie Lu 0009"
                    },
                    {
                        "@pid": "204/1032",
                        "text": "Haofeng Li"
                    },
                    {
                        "@pid": "144/7186",
                        "text": "Haining Meng"
                    },
                    {
                        "@pid": "l/LianLi0002",
                        "text": "Lian Li 0002"
                    }
                ]
            },
            "title": "Detecting Broken Object-Level Authorization Vulnerabilities in Database-Backed Applications.",
            "venue": "CCS",
            "pages": "2934-2948",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/HuangS0LM024",
            "doi": "10.1145/3658644.3690227",
            "ee": "https://doi.org/10.1145/3658644.3690227",
            "url": "https://dblp.org/rec/conf/ccs/HuangS0LM024",
            "abstract": "Broken object-level authorization (BOLA) vulnerabilities are among the most critical security risks facing database-backed applications. However, there is still a significant gap in our systematic understanding of these vulnerabilities. To bridge this gap, we conducted an in-depth study of 101 real-world BOLA vulnerabilities from opensource applications. Our study revealed the four most common object-level authorization models in database-backed application.",
            "pdf_url": "",
            "keywords": [
                "Broken Object-Level Authorization",
                "Database Security",
                "Authorization Models",
                "Vulnerability Detection",
                "Open Source Applications"
            ]
        },
        "url": "URL#256703",
        "sema_paperId": "136d274e50498ba40386e743de3f09ed25dbeff1"
    },
    {
        "@score": "1",
        "@id": "256704",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "392/2924",
                        "text": "Xianglan Huang"
                    },
                    {
                        "@pid": "43/3182",
                        "text": "Qiang Zhou"
                    },
                    {
                        "@pid": "53/10765-1",
                        "text": "Liangmin Wang 0001"
                    },
                    {
                        "@pid": "332/0316",
                        "text": "Weiqi Yu"
                    },
                    {
                        "@pid": "61/4908",
                        "text": "Wenjin Wang"
                    },
                    {
                        "@pid": "51/4912",
                        "text": "Shi Shen"
                    }
                ]
            },
            "title": "Demo: An End-to-End Anonymous Traffic Analysis System.",
            "venue": "CCS",
            "pages": "5084-5086",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/HuangZWYWS24",
            "doi": "10.1145/3658644.3691364",
            "ee": "https://doi.org/10.1145/3658644.3691364",
            "url": "https://dblp.org/rec/conf/ccs/HuangZWYWS24",
            "abstract": "Network crimes committed through anonymous networks pose significant challenges to regulators. Identifying different types of traffic and implementing effective supervision are crucial for maintaining network security. In this demo, we present an end-to-end anonymous traffic analysis system that integrates traffic capturing, protocol parsing, feature extraction, traffic classification, and analysis result presentation, enabling comprehensive analysis of traffic on routers from end to end. Our system can be deployed on the data center network to capture network traffic routed by the routers. It automatically analyzes Tor network traffic, HTTPS encrypted traffic, and Tor network App traffic, identifies the target website or App type associated with the traffic, and displays the identification results via the visual interface.",
            "pdf_url": "",
            "keywords": [
                "Anonymous Traffic Analysis",
                "Network Traffic Classification",
                "Tor Network Traffic",
                "HTTPS Traffic Analysis",
                "Traffic Feature Extraction"
            ]
        },
        "url": "URL#256704",
        "sema_paperId": "1c0ff0592d7e8bd22f36c09af988578dfc170ede"
    },
    {
        "@score": "1",
        "@id": "256705",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "118/9209",
                        "text": "Tomasz Hyla"
                    },
                    {
                        "@pid": "146/8300",
                        "text": "Natalia Wawrzyniak"
                    }
                ]
            },
            "title": "Poster: The Concept of a System for Automatic Detection and Correction of Vulnerabilities in the Source Code.",
            "venue": "CCS",
            "pages": "4943-4945",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/HylaW24",
            "doi": "10.1145/3658644.3691417",
            "ee": "https://doi.org/10.1145/3658644.3691417",
            "url": "https://dblp.org/rec/conf/ccs/HylaW24",
            "abstract": "Defects in the source code that affect security are one of the main elements used to carry out cyber attacks. Examining source code for vulnerabilities is a difficult and expensive process. As a result, specialized software is needed for this. Due to the development of various artificial intelligence methods, improving existing vulnerability detection methods is possible. In particular, it is possible to reduce the number of false positives and enable the detection of complex vulnerabilities that require understanding the broader context of the code. The article presents the concept of a system for automatic analysis of vulnerabilities in source code, along with the challenges and problems related to its design and use.",
            "pdf_url": "",
            "keywords": [
                "Vulnerability Detection",
                "Source Code Analysis",
                "Artificial Intelligence",
                "False Positives",
                "Complex Vulnerabilities"
            ]
        },
        "url": "URL#256705",
        "sema_paperId": "92f5e136148877b53f08c01d6599de130c16ffad"
    },
    {
        "@score": "1",
        "@id": "256706",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "244/2598",
                        "text": "Jacob Imola"
                    },
                    {
                        "@pid": "147/6281",
                        "text": "Amrita Roy Chowdhury 0001"
                    },
                    {
                        "@pid": "56/6435",
                        "text": "Kamalika Chaudhuri"
                    }
                ]
            },
            "title": "Metric Differential Privacy at the User-Level via the Earth-Mover&apos;s Distance.",
            "venue": "CCS",
            "pages": "348-362",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Imola0C24",
            "doi": "10.1145/3658644.3690363",
            "ee": "https://doi.org/10.1145/3658644.3690363",
            "url": "https://dblp.org/rec/conf/ccs/Imola0C24",
            "abstract": "Metric differential privacy (DP) provides heterogeneous privacy guarantees based on a distance between the pair of inputs. It is a widely popular notion of privacy since it captures the natural privacy semantics for many applications (such as, for location data) and results in better utility than standard DP. However, prior work in metric DP has primarily focused on the item-level setting where every user only reports a single data item. A more realistic setting is that of user-level DP where each user contributes multiple items and privacy is then desired at the granularity of the user's entire contribution. In this paper, we initiate the study of one natural definition of metric DP at the user-level. Specifically, we use the earth-mover's distance ($d_\\textsf{EM}$) as our metric to obtain a notion of privacy as it captures both the magnitude and spatial aspects of changes in a user's data. We make three main technical contributions. First, we design two novel mechanisms under $d_\\textsf{EM}$-DP to answer linear queries and item-wise queries. Specifically, our analysis for the latter involves a generalization of the privacy amplification by shuffling result which may be of independent interest. Second, we provide a black-box reduction from the general unbounded to bounded $d_\\textsf{EM}$-DP (size of the dataset is fixed and public) with a novel sampling based mechanism. Third, we show that our proposed mechanisms can provably provide improved utility over user-level DP, for certain types of linear queries and frequency estimation.",
            "keywords": [
                "Metric Differential Privacy",
                "User-Level Privacy",
                "Earth-Mover's Distance",
                "Linear Queries",
                "Privacy Mechanisms"
            ]
        },
        "url": "URL#256706",
        "sema_paperId": "04a47eabb6e42f63eb4e87d64c398a182179228e"
    },
    {
        "@score": "1",
        "@id": "256707",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "372/6077",
                        "text": "Oliver Jacobsen"
                    },
                    {
                        "@pid": "94/7397",
                        "text": "Haya Schulmann"
                    }
                ]
            },
            "title": "Poster: Patching NSEC3-Encloser: The Good, the Bad, and the Ugly.",
            "venue": "CCS",
            "pages": "4937-4939",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/JacobsenS24",
            "doi": "10.1145/3658644.3691395",
            "ee": "https://doi.org/10.1145/3658644.3691395",
            "url": "https://dblp.org/rec/conf/ccs/JacobsenS24",
            "abstract": "This paper evaluates the effectiveness of patches designed to mitigate the NSEC3-encloser attack in DNS resolvers. NSEC3, used in DNSSEC to authenticate non-existence of records, can be exploited to exhaust resolver resources through excessive SHA-1 hashing. Despite recent patches, our study reveals that major DNS resolvers remain vulnerable. We test the NSEC3 exhaustion attacks against pre- and post-patch versions of popular DNS resolvers (Unbound, BIND9, PowerDNS, and Knot Resolver), and observe a 72-fold increase in CPU instructions during attacks. PowerDNS 5.0.5 and Knot Resolver 5.7.3 showed improvements, limiting CPU load with strict hash limits. Conversely, BIND9 exhibited marginal improvement, and Unbound 1.20.0 experienced increased CPU load. At an attack rate of 150 malicious NSEC3 records per second, benign DNS request loss rates ranged from 2.7% to 30%. Our study indicates the need for robust countermeasures to address NSEC3 vulnerabilities.",
            "pdf_url": "",
            "keywords": [
                "DNS Security",
                "NSEC3",
                "Resource Exhaustion",
                "DNS Resolvers",
                "NSEC3-Encloser Attack"
            ]
        },
        "url": "URL#256707",
        "sema_paperId": "0fdd152d806bec8cf85cc61af5a52e2942a06254"
    },
    {
        "@score": "1",
        "@id": "256708",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "372/6077",
                        "text": "Oliver Jacobsen"
                    },
                    {
                        "@pid": "94/7397",
                        "text": "Haya Schulmann"
                    },
                    {
                        "@pid": "332/3113",
                        "text": "Niklas Vogel"
                    },
                    {
                        "@pid": "90/308",
                        "text": "Michael Waidner"
                    }
                ]
            },
            "title": "Poster: From Fort to Foe: The Threat of RCE in RPKI.",
            "venue": "CCS",
            "pages": "5015-5017",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/JacobsenSVW24",
            "doi": "10.1145/3658644.3691387",
            "ee": "https://doi.org/10.1145/3658644.3691387",
            "url": "https://dblp.org/rec/conf/ccs/JacobsenSVW24",
            "abstract": "In this work, we present a novel severe buffer-overflow vulnerability in the RPKI validator Fort, that allows an attacker to achieve Remote Code Execution (RCE) on the machine running the software. We discuss the unique impact of this RCE on networks that use RPKI, illustrating that RCE vulnerabilities are especially severe in the context of RPKI. The design of RPKI makes RCE easy to exploit on a large scale, allows compromise of RPKI validation integrity, and enables a powerful vector for additional attacks on other critical components of the network, like the border routers. We analyze the vulnerability exposing to this RCE and identify indications that the discovered vulnerability could constitute an intentional backdoor to compromise systems running the software over a benign coding mistake. We disclosed the vulnerability, which has been assigned a CVE rated 9.8 critical (CVE-2024-45237).",
            "keywords": [
                "RPKI",
                "Remote Code Execution",
                "Buffer Overflow",
                "Network Security",
                "Vulnerability Disclosure"
            ]
        },
        "url": "URL#256708",
        "sema_paperId": "51ac87ce59856fbdd2692dd2e5f12192432abcaf"
    },
    {
        "@score": "1",
        "@id": "256709",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "267/7352",
                        "text": "Hyerean Jang"
                    },
                    {
                        "@pid": "27/6169",
                        "text": "Taehun Kim"
                    },
                    {
                        "@pid": "33/2332",
                        "text": "Youngjoo Shin"
                    }
                ]
            },
            "title": "SysBumps: Exploiting Speculative Execution in System Calls for Breaking KASLR in macOS for Apple Silicon.",
            "venue": "CCS",
            "pages": "64-78",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/JangKS24",
            "doi": "10.1145/3658644.3690189",
            "ee": "https://doi.org/10.1145/3658644.3690189",
            "url": "https://dblp.org/rec/conf/ccs/JangKS24",
            "abstract": "Apple silicon is the proprietary ARM-based processor that powers the mainstream of Apple devices. The move to this proprietary architecture presents unique challenges in addressing security issues, requiring huge research efforts into the security of Apple silicon-based systems. In this paper, we study the security of KASLR, the randomization-based kernel hardening technique, on the state-of-the-art macOS system equipped with Apple silicon processors. Because KASLR has been subject to many microarchitectural side-channel attacks, the latest operating systems, including macOS, use kernel isolation, which separates the kernel page table from the userspace table. Kernel isolation in macOS provides a barrier to KASLR break attacks. To overcome this, we exploit speculative execution in system calls. By using Spectre-type gadgets in system calls, an unprivileged attacker can cause translations of the attacker's chosen kernel addresses, causing the TLB to change according to the validity of the address. This allows the construction of an attack primitive that breaks KASLR bypassing kernel isolation. Since the TLB is used as a side-channel source, we reverse-engineer the hidden internals of the TLB on various M-series processors using a hardware performance monitoring unit. Based on our attack primitive, we implement SysBumps, the first KASLR break attack on macOS for Apple silicon. Throughout evaluation, we show that SysBumps can effectively break KASLR across different M-series processors and macOS versions. We also discuss possible mitigations against the proposed attack.",
            "pdf_url": "",
            "keywords": [
                "Apple Silicon Security",
                "KASLR",
                "Speculative Execution",
                "Kernel Isolation",
                "SysBumps Attack"
            ]
        },
        "url": "URL#256709",
        "sema_paperId": "86c74efe91deb63f681b62b7dae25f9782d981f1"
    },
    {
        "@score": "1",
        "@id": "256710",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "319/0781",
                        "text": "Yuchen Ji"
                    },
                    {
                        "@pid": "46/7790",
                        "text": "Ting Dai"
                    },
                    {
                        "@pid": "120/1174",
                        "text": "Yutian Tang"
                    },
                    {
                        "@pid": "219/6364",
                        "text": "Jingzhu He"
                    }
                ]
            },
            "title": "Poster: Whether We Are Good Enough to Detect Server-Side Request Forgeries in PHP-native Applications?",
            "venue": "CCS",
            "pages": "4928-4930",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/JiDTH24",
            "doi": "10.1145/3658644.3691419",
            "ee": "https://doi.org/10.1145/3658644.3691419",
            "url": "https://dblp.org/rec/conf/ccs/JiDTH24",
            "abstract": "Server-side request forgeries (SSRFs) are inevitable in PHP web applications. Existing static taint analysis tools for PHP suffer from both high rates of false positives and false negatives in detecting SSRF because they do not incorporate application-specific sources and sinks, account for PHP's dynamic type characteristics, and include SSRF-specific taint analysis rules, leading to over-tainting and under-tainting. In this work, we propose a technique to accurately detect SSRF vulnerabilities in PHP web applications. First, we extract both PHP built-in and application-specific functions as candidate source and sink functions. Second, we extract explicit and implicit function calls to construct applications' call graphs. Third, we perform a taint analysis based on a set of rules that prevent over-tainting and under-tainting. We have implemented a prototype and evaluated it with different types of PHP web applications. Our preliminary experiment shows that we detect 24 SSRF vulnerabilities in 13 different types of applications. 20 of the vulnerabilities are known and 4 of the vulnerabilities are new.",
            "pdf_url": "",
            "keywords": [
                "PHP Web Applications",
                "Server-Side Request Forgery",
                "Static Taint Analysis",
                "Vulnerability Detection",
                "Taint Analysis Rules"
            ]
        },
        "url": "URL#256710",
        "sema_paperId": "1bee9c9af8fd458a9729966c4d9dd1d8b963c90c"
    },
    {
        "@score": "1",
        "@id": "256711",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "231/8643",
                        "text": "Yanxue Jia"
                    },
                    {
                        "@pid": "265/8774",
                        "text": "Varun Madathil"
                    },
                    {
                        "@pid": "12/3394",
                        "text": "Aniket Kate"
                    }
                ]
            },
            "title": "HomeRun: High-efficiency Oblivious Message Retrieval, Unrestricted.",
            "venue": "CCS",
            "pages": "2012-2026",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/JiaMK24",
            "doi": "10.1145/3658644.3670381",
            "ee": "https://doi.org/10.1145/3658644.3670381",
            "url": "https://dblp.org/rec/conf/ccs/JiaMK24",
            "abstract": "In the realm of privacy-preserving blockchain applications such as Zcash, oblivious message retrieval (OMR) enables recipients to privately access messages directed to them on blockchain nodes (or bulletin board servers). OMR prevents servers from linking a message and its corresponding recipient's address, thereby safeguarding recipient privacy. Several OMR schemes have emerged recently to meet the demands of these privacy-centric blockchains; however, we observe that existing solutions exhibit shortcomings in various critical aspects and may only achieve certain objectives inefficiently, sometimes relying on trusted hardware, thereby impacting their practical utility. This work introduces a novel OMR protocol, HomeRun, that leverages two semi-honest, non-colluding servers to excel in both performance and security attributes as compared to the current state-of-the-art.",
            "pdf_url": "",
            "keywords": [
                "Oblivious Message Retrieval",
                "Privacy-Preserving Blockchain",
                "Recipient Privacy",
                "Semi-Honest Servers",
                "HomeRun Protocol"
            ]
        },
        "url": "URL#256711"
    },
    {
        "@score": "1",
        "@id": "256712",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "331/1720",
                        "text": "Chenghan Jiang"
                    },
                    {
                        "@pid": "124/2041",
                        "text": "Jinjiang Yang"
                    },
                    {
                        "@pid": "139/4257",
                        "text": "Xinyi Li"
                    },
                    {
                        "@pid": "181/2688-2",
                        "text": "Qi Li 0002"
                    },
                    {
                        "@pid": "58/4582-3",
                        "text": "Xinyu Zhang 0003"
                    },
                    {
                        "@pid": "00/468-1",
                        "text": "Ju Ren 0001"
                    }
                ]
            },
            "title": "RISiren: Wireless Sensing System Attacks via Metasurface.",
            "venue": "CCS",
            "pages": "3332-3345",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/JiangYLL0024",
            "doi": "10.1145/3658644.3690186",
            "ee": "https://doi.org/10.1145/3658644.3690186",
            "url": "https://dblp.org/rec/conf/ccs/JiangYLL0024",
            "abstract": "After over a decade of intensive research, wireless sensing technology is nearing commercialization. However, the inherent openness of the wireless medium exposes this technology to security flaws and vulnerabilities. In this paper, we introduce RISiren to reveal the risk. RISiren is a pioneering end-to-end black-box attack system leveraging programmable metasurface with a high level of stealthiness. The key insight of RISiren lies in its ability to generate malicious multipath using metasurface, thereby disrupting wireless channel metrics influenced by genuine human activities and facilitating malicious attacks. To ensure the effectiveness of RISiren, we propose a novel metasurface configuration strategy aiming at creating human-like activities that stem from a comprehensive analysis of how human activities impact wireless signal propagation. We have implemented and validated RISiren using commercial Wi-Fi devices. Our evaluation involved testing our attack strategies against five state-of-the-art systems (including five different types of recognition frameworks) representative of the current landscape. The experimental results show that the adversarial wireless signals generated by RISiren achieve over 90% attack success rate on average, and remain robust and effective across different environments and deployment setups, including through wall attack scenarios.",
            "pdf_url": "",
            "keywords": [
                "Wireless Sensing Technology",
                "Programmable Metasurface",
                "Black-box Attack",
                "Multipath Generation",
                "Wireless Channel Disruption"
            ]
        },
        "url": "URL#256712",
        "sema_paperId": "9cac64352a3bee0fde8fa4273400366d63a18ebe"
    },
    {
        "@score": "1",
        "@id": "256713",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "303/7273",
                        "text": "Jiayi Jiang"
                    },
                    {
                        "@pid": "137/9583",
                        "text": "Xiyuan Zhang"
                    },
                    {
                        "@pid": "183/4488",
                        "text": "Chengcheng Wan 0001"
                    },
                    {
                        "@pid": "309/2037",
                        "text": "Haoyi Chen"
                    },
                    {
                        "@pid": "34/6060",
                        "text": "Haiying Sun"
                    },
                    {
                        "@pid": "42/6896-1",
                        "text": "Ting Su 0001"
                    }
                ]
            },
            "title": "BinPRE: Enhancing Field Inference in Binary Analysis Based Protocol Reverse Engineering.",
            "venue": "CCS",
            "pages": "3689-3703",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/JiangZ0CS024",
            "doi": "10.1145/3658644.3690299",
            "ee": "https://doi.org/10.1145/3658644.3690299",
            "url": "https://dblp.org/rec/conf/ccs/JiangZ0CS024",
            "abstract": "Protocol reverse engineering (PRE) aims to infer the specification of network protocols when the source code is not available. Specifically, field inference is one crucial step in PRE to infer the field formats and semantics. To perform field inference, binary analysis based PRE techniques are one major approach category. However, such techniques face two key challenges - (1) the format inference is fragile when the logics of processing input messages may vary among different protocol implementations, and (2) the semantic inference is limited by inadequate and inaccurate inference rules. To tackle these challenges, we present BinPRE, a binary analysis based PRE tool. BinPRE incorporates (1) an instruction-based semantic similarity analysis strategy for format extraction; (2) a novel library composed of atomic semantic detectors for improving semantic inference adequacy; and (3) a cluster-and-refine paradigm to further improve semantic inference accuracy. We have evaluated BinPRE against five existing PRE tools, including Polyglot, AutoFormat, Tupni, BinaryInferno and DynPRE. The evaluation results on eight widely-used protocols show that BinPRE outperforms the prior PRE tools in both format and semantic inference. BinPRE achieves the perfection of 0.73 on format extraction and the F1-score of 0.74 (0.81) on semantic inference of types (functions), respectively. The field inference results of BinPRE have helped improve the effectiveness of protocol fuzzing by achieving 5-29% higher branch coverage, compared to those of the best prior PRE tool. BinPRE has also helped discover one new zero-day vulnerability, which otherwise cannot be found.",
            "keywords": [
                "Protocol Reverse Engineering",
                "Field Inference",
                "Binary Analysis",
                "Semantic Inference",
                "Format Extraction"
            ]
        },
        "url": "URL#256713",
        "sema_paperId": "5cf867068002e95f8fc1bd6102e451802844f206"
    },
    {
        "@score": "1",
        "@id": "256714",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "308/6408",
                        "text": "Jiankai Jin"
                    },
                    {
                        "@pid": "124/1916",
                        "text": "Chitchanok Chuengsatiansup"
                    },
                    {
                        "@pid": "31/6289",
                        "text": "Toby Murray"
                    },
                    {
                        "@pid": "90/1092",
                        "text": "Benjamin I. P. Rubinstein"
                    },
                    {
                        "@pid": "90/10901",
                        "text": "Yuval Yarom"
                    },
                    {
                        "@pid": "70/4765",
                        "text": "Olga Ohrimenko"
                    }
                ]
            },
            "title": "Elephants Do Not Forget: Differential Privacy with State Continuity for Privacy Budget.",
            "venue": "CCS",
            "pages": "1909-1923",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/JinCMRYO24",
            "doi": "10.1145/3658644.3670281",
            "ee": "https://doi.org/10.1145/3658644.3670281",
            "url": "https://dblp.org/rec/conf/ccs/JinCMRYO24",
            "abstract": "Current implementations of differentially-private (DP) systems either lack support to track the global privacy budget consumed on a dataset, or fail to faithfully maintain the state continuity of this budget. We show that failure to maintain a privacy budget enables an adversary to mount replay, rollback and fork attacks - obtaining answers to many more queries than what a secure system would allow. As a result the attacker can reconstruct secret data that DP aims to protect - even if DP code runs in a Trusted Execution Environment (TEE). We propose ElephantDP, a system that aims to provide the same guarantees as a trusted curator in the global DP model would, albeit set in an untrusted environment. Our system relies on a state continuity module to provide protection for the privacy budget and a TEE to faithfully execute DP code and update the budget. To provide security, our protocol makes several design choices including the content of the persistent state and the order between budget updates and query answers. We prove that ElephantDP provides liveness (i.e., the protocol can restart from a correct state and respond to queries as long as the budget is not exceeded) and DP confidentiality (i.e., an attacker learns about a dataset as much as it would from interacting with a trusted curator). Our implementation and evaluation of the protocol use Intel SGX as a TEE to run the DP code and a network of TEEs to maintain state continuity. Compared to an insecure baseline, we observe 1.1-3.2$\\times$ overheads and lower relative overheads for complex DP queries.",
            "keywords": [
                "Differential Privacy",
                "Privacy Budget",
                "State Continuity",
                "Trusted Execution Environment",
                "Replay Attacks"
            ]
        },
        "url": "URL#256714",
        "sema_paperId": "c62e6a525ea108785407a8865a679a0c3a0895a4"
    },
    {
        "@score": "1",
        "@id": "256715",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "148/1500",
                        "text": "Chenglu Jin"
                    },
                    {
                        "@pid": "01/9103",
                        "text": "Chao Yin"
                    },
                    {
                        "@pid": "32/1399",
                        "text": "Marten van Dijk"
                    },
                    {
                        "@pid": "146/0078",
                        "text": "Sisi Duan"
                    },
                    {
                        "@pid": "59/6145",
                        "text": "Fabio Massacci"
                    },
                    {
                        "@pid": "r/MichaelKReiter",
                        "text": "Michael K. Reiter"
                    },
                    {
                        "@pid": "22/1887",
                        "text": "Haibin Zhang"
                    }
                ]
            },
            "title": "PG: Byzantine Fault-Tolerant and Privacy-Preserving Sensor Fusion with Guaranteed Output Delivery.",
            "venue": "CCS",
            "pages": "3272-3286",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/JinYDDMRZ24",
            "doi": "10.1145/3658644.3670343",
            "ee": "https://doi.org/10.1145/3658644.3670343",
            "url": "https://dblp.org/rec/conf/ccs/JinYDDMRZ24",
            "abstract": "Wedesign andimplementPG,aByzantinefault-tolerantandprivacy-preserving multi-sensor fusion system. PG is flexible and extensible, supporting a variety of fusion algorithms and application scenarios. On the theoretical side, PG develops and unifies techniques from dependable distributed systems and modern cryptography. PG can provably protect the privacy of individual sensor inputs and fusion results. In contrast to prior works, PG can provably defend against pollution attacks and guarantee output delivery, even in the presence of malicious sensors that may lie about their inputs, contribute ill-formed inputs, and provide no inputs at all to sway the final result, and in the presence of malicious servers serving as aggregators. On the practical side, we implement PG in the client-server-sensor setting. Moreover, we deploy PG in a cloud-based system",
            "keywords": [
                "Byzantine Fault Tolerance",
                "Sensor Fusion",
                "Privacy Preservation",
                "Pollution Attacks",
                "Guaranteed Output Delivery"
            ]
        },
        "url": "URL#256715",
        "sema_paperId": "0e2b1b774cbaf61ff04e5402bb710dc792236cd8"
    },
    {
        "@score": "1",
        "@id": "256716",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "285/5429",
                        "text": "Tushar M. Jois"
                    },
                    {
                        "@pid": "224/2397",
                        "text": "Gabrielle Beck"
                    },
                    {
                        "@pid": "185/1661",
                        "text": "Gabriel Kaptchuk"
                    }
                ]
            },
            "title": "Pulsar: Secure Steganography for Diffusion Models.",
            "venue": "CCS",
            "pages": "4703-4717",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/JoisBK24",
            "doi": "10.1145/3658644.3690218",
            "ee": "https://doi.org/10.1145/3658644.3690218",
            "url": "https://dblp.org/rec/conf/ccs/JoisBK24",
            "abstract": "Widespread efforts to subvert access to strong cryptography has renewed interest in steganography, the practice of embedding sensitive messages in mundane cover messages. Recent efforts at provably secure steganography have focused on text-based generative models and cannot support other types of models, such as diffusion models, which are used for high-quality image synthesis. In this work, we study securely embedding steganographic messages into the output of image diffusion models. We identify that the use of variance noise during image generation provides a suitable steganographic channel. We develop our construction, Pulsar , by building optimizations to make this channel practical for communication. Our implementation of Pulsar is capable of embedding \u2248 320\u2013613 bytes (on average) into a single image without altering the distribution of the generated image, all in < 3 seconds of online time on a laptop. In addition, we discuss how the results of Pulsar can inform future research into diffusion models. Pulsar shows that diffusion models are a promising medium for steganography and censorship resistance.",
            "keywords": [
                "Steganography",
                "Diffusion Models",
                "Image Synthesis",
                "Secure Communication",
                "Censorship Resistance"
            ]
        },
        "url": "URL#256716",
        "sema_paperId": "befcbef81ca1b6b7be46d292617e2760316e13e7"
    },
    {
        "@score": "1",
        "@id": "256717",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "363/7833",
                        "text": "Jae Hyung Ju"
                    },
                    {
                        "@pid": "279/2397",
                        "text": "Jaiyoung Park"
                    },
                    {
                        "@pid": "38/1733-7",
                        "text": "Jongmin Kim 0007"
                    },
                    {
                        "@pid": "237/1555",
                        "text": "Minsik Kang"
                    },
                    {
                        "@pid": "05/1032",
                        "text": "Donghwan Kim"
                    },
                    {
                        "@pid": "64/5207",
                        "text": "Jung Hee Cheon"
                    },
                    {
                        "@pid": "a/JungHoAhn",
                        "text": "Jung Ho Ahn"
                    }
                ]
            },
            "title": "NeuJeans: Private Neural Network Inference with Joint Optimization of Convolution and FHE Bootstrapping.",
            "venue": "CCS",
            "pages": "4361-4375",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/JuP0KKCA24",
            "doi": "10.1145/3658644.3690375",
            "ee": "https://doi.org/10.1145/3658644.3690375",
            "url": "https://dblp.org/rec/conf/ccs/JuP0KKCA24",
            "abstract": "Fully homomorphic encryption (FHE) is a promising cryptographic primitive for realizing private neural network inference (PI) services by allowing a client to fully offload the inference task to a cloud server while keeping the client data oblivious to the server. This work proposes NeuJeans, an FHE-based solution for the PI of deep convolutional neural networks (CNNs). NeuJeans tackles the critical problem of the enormous computational cost for the FHE evaluation of CNNs. We introduce a novel encoding method called Coefficients-in-Slot (CinS) encoding, which enables multiple convolutions in one HE multiplication without costly slot permutations. We further observe that CinS encoding is obtained by conducting the first several steps of the Discrete Fourier Transform (DFT) on a ciphertext in conventional Slot encoding. This property enables us to save the conversion between CinS and Slot encodings as bootstrapping a ciphertext starts with DFT. Exploiting this, we devise optimized execution flows for various two-dimensional convolution (conv2d) operations and apply them to end-to-end CNN implementations. NeuJeans accelerates the performance of conv2d-activation sequences by up to 5.68 times compared to state-of-the-art FHE-based PI work and performs the PI of a CNN at the scale of ImageNet within a mere few seconds.",
            "keywords": [
                "Fully Homomorphic Encryption",
                "Private Inference",
                "Convolutional Neural Networks",
                "CinS Encoding",
                "Bootstrapping Optimization"
            ]
        },
        "url": "URL#256717",
        "sema_paperId": "b6809e10cb13002abf59e5f2ff35447c90e15a53"
    },
    {
        "@score": "1",
        "@id": "256718",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "159/4614",
                        "text": "Andrew J. Kaizer"
                    },
                    {
                        "@pid": "392/3041",
                        "text": "Will Naciri"
                    },
                    {
                        "@pid": "48/1013",
                        "text": "Swapneel Sheth"
                    }
                ]
            },
            "title": "Poster: Synchronization Concerns of DNS Integrations.",
            "venue": "CCS",
            "pages": "4982-4984",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/KaizerNS24",
            "doi": "10.1145/3658644.3691415",
            "ee": "https://doi.org/10.1145/3658644.3691415",
            "url": "https://dblp.org/rec/conf/ccs/KaizerNS24",
            "abstract": "The widespread use of the Domain Name System (DNS) as a namespace for websites, email addresses, and other applications has led to proposals for integrating domain names into additional applications. An important quality for DNS integrations is synchronization, i.e., there is evidence that a current registrant of a domain name associated with the integration has chosen to participate in the integration. Failure to maintain synchronization may result in avoidable risks to users, however no study has detailed the scope of synchronization concerns across DNS integrations. To that end, this paper presents preliminary results from three novel DNS integrations that show between 1% and 40% of integrated domain name are not clearly synchronized and as such further study is merited to understand the risks and solutions that may be available. Furthermore, feedback on an IETF draft is proposed as one avenue through which researchers could provide input to address this problem space.",
            "pdf_url": "",
            "keywords": [
                "Domain Name System (DNS)",
                "DNS Integration",
                "Synchronization",
                "Domain Registrant Participation",
                "User Risk Management"
            ]
        },
        "url": "URL#256718",
        "sema_paperId": "094ded0676a40e30813dceae5aeda8d3d41bd778"
    },
    {
        "@score": "1",
        "@id": "256719",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "235/5023",
                        "text": "Dimitris Karakostas"
                    },
                    {
                        "@pid": "47/3682",
                        "text": "Aggelos Kiayias"
                    },
                    {
                        "@pid": "76/1308-1",
                        "text": "Thomas Zacharias 0001"
                    }
                ]
            },
            "title": "Blockchain Bribing Attacks and the Efficacy of Counterincentives.",
            "venue": "CCS",
            "pages": "1031-1045",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/KarakostasK024",
            "doi": "10.1145/3658644.3670330",
            "ee": "https://doi.org/10.1145/3658644.3670330",
            "url": "https://dblp.org/rec/conf/ccs/KarakostasK024",
            "abstract": "We analyze bribing attacks in Proof-of-Stake distributed ledgers from a game theoretic perspective. In bribing attacks, an adversary offers participants a reward in exchange for instructing them how to behave, with the goal of attacking the protocol's properties. Specifically, our work focuses on adversaries that target blockchain safety. We consider two types of bribing, depending on how the bribes are awarded: i) guided bribing, where the bribe is given as long as the bribed party behaves as instructed; ii) effective bribing, where bribes are conditional on the attack's success, w.r.t. well-defined metrics. We analyze each type of attack in a game theoretic setting and identify relevant equilibria. In guided bribing, we show that the protocol is not an equilibrium and then describe good equilibria, where the attack is unsuccessful, and a negative one, where all parties are bribed such that the attack succeeds. In effective bribing, we show that both the protocol and the\"all bribed\"setting are equilibria. Using the identified equilibria, we then compute bounds on the Prices of Stability and Anarchy. Our results indicate that additional mitigations are needed for guided bribing, so our analysis concludes with incentive-based mitigation techniques, namely slashing and dilution. Here, we present two positive results, that both render the protocol an equilibrium and achieve maximal welfare for all parties, and a negative result, wherein an attack becomes more plausible if it severely affects the ledger's token's market price.",
            "keywords": [
                "Blockchain Security",
                "Proof-of-Stake",
                "Bribing Attacks",
                "Game Theory",
                "Incentive Mitigation Techniques"
            ]
        },
        "url": "URL#256719",
        "sema_paperId": "e91b11a7833702750191a7af191d377ecd273ad2"
    },
    {
        "@score": "1",
        "@id": "256720",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "232/4571",
                        "text": "Ioanna Karantaidou"
                    },
                    {
                        "@pid": "348/5240",
                        "text": "Omar Renawi"
                    },
                    {
                        "@pid": "46/7643",
                        "text": "Foteini Baldimtsi"
                    },
                    {
                        "@pid": "386/8025",
                        "text": "Nikolaos Kamarinakis"
                    },
                    {
                        "@pid": "k/JonathanKatz",
                        "text": "Jonathan Katz"
                    },
                    {
                        "@pid": "184/3870",
                        "text": "Julian Loss"
                    }
                ]
            },
            "title": "Blind Multisignatures for Anonymous Tokens with Decentralized Issuance.",
            "venue": "CCS",
            "pages": "1508-1522",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/KarantaidouRBKK24",
            "doi": "10.1145/3658644.3690364",
            "ee": "https://doi.org/10.1145/3658644.3690364",
            "url": "https://dblp.org/rec/conf/ccs/KarantaidouRBKK24",
            "abstract": "We propose the first constructions of anonymous tokens with decentralized issuance. Namely, we consider a dynamic set of signers/issuers; a user can obtain a token from any subset of the signers, which is publicly verifiable and unlinkable to the issuance process. To realize this new primitive we formalize the notion of blind multi-signatures (BMS), which allow a user to interact with multiple signers to obtain a (compact) signature; even if all the signers collude they are unable to link a signature to an interaction with any of them. We then present two BMS constructions, one based on BLS signatures and a second based on discrete logarithms without pairings. We prove security of both our constructions in the Algebraic Group Model. We also provide a proof-of-concept implementation and show that it has low-cost verification, which is the most critical operation in blockchain applications.",
            "pdf_url": "",
            "keywords": [
                "Anonymous Tokens",
                "Decentralized Issuance",
                "Blind Multi-signatures",
                "Public Verification",
                "Unlinkability"
            ]
        },
        "url": "URL#256720"
    },
    {
        "@score": "1",
        "@id": "256721",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "229/0090",
                        "text": "Nazmul Karim"
                    },
                    {
                        "@pid": "292/5715",
                        "text": "Abdullah Al Arafat"
                    },
                    {
                        "@pid": "215/3683",
                        "text": "Adnan Siraj Rakin"
                    },
                    {
                        "@pid": "39/4489",
                        "text": "Zhishan Guo"
                    },
                    {
                        "@pid": "71/2488",
                        "text": "Nazanin Rahnavard"
                    }
                ]
            },
            "title": "Fisher Information guided Purification against Backdoor Attacks.",
            "venue": "CCS",
            "pages": "4435-4449",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/KarimARGR24",
            "doi": "10.1145/3658644.3690250",
            "ee": "https://doi.org/10.1145/3658644.3690250",
            "url": "https://dblp.org/rec/conf/ccs/KarimARGR24",
            "abstract": "Studies on backdoor attacks in recent years suggest that an adversary can compromise the integrity of a deep neural network (DNN) by manipulating a small set of training samples. Our analysis shows that such manipulation can make the backdoor model converge to abad local minima,i.e., sharper minima as compared to a benign model. Intuitively, the backdoor can be purified by re-optimizing the model to smoother minima. However, a na\u00efve adoption of any optimization targeting smoother minima can lead to sub-optimal purification techniques hampering the clean test accuracy. Hence, to effectively obtain such re-optimization, inspired by our novel perspective establishing the connection between backdoor removal and loss smoothness, we propose<u>F</u>isher <u>I</u>nformation guided <u>P</u>urification (FIP),a novel backdoor purification framework. Proposed FIP consists of a couple of novel regularizers that aid the model in suppressing the backdoor effects and retaining the acquired knowledge of clean data distribution throughout the backdoor removal procedure through exploiting the knowledge ofFisher Information Matrix (FIM).In addition, we introduce an efficient variant of FIP, dubbed asFast FIP,which reduces the number of tunable parameters significantly and obtains an impressive runtime gain of almost 5\u00d7. Extensive experiments show that the proposed method achieves state-of-the-art (SOTA) performance on a wide range of backdoor defense benchmarks: 5 different tasks---Image Recognition, Object Detection, Video Action Recognition, 3D point Cloud, Language Generation; 11 different datasets includingImageNet, PASCAL VOC, UCF101; diverse model architectures spanning both CNN and vision transformer; 14 different backdoor attacks, e.g.,Dynamic, WaNet, LIRA, ISSBA, etc.Our code is available in this https://github.com/nazmul-karim170/FIP-Fisher-Backdoor-RemovalGitHub Repository.",
            "pdf_url": "",
            "keywords": [
                "Backdoor Attacks",
                "Fisher Information",
                "Model Purification",
                "Loss Smoothness",
                "Deep Neural Network Integrity"
            ]
        },
        "url": "URL#256721"
    },
    {
        "@score": "1",
        "@id": "256722",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "12/3394",
                        "text": "Aniket Kate"
                    },
                    {
                        "@pid": "125/2314",
                        "text": "Easwar Vivek Mangipudi"
                    },
                    {
                        "@pid": "128/5167",
                        "text": "Pratyay Mukherjee"
                    },
                    {
                        "@pid": "208/7290",
                        "text": "Hamza Saleem"
                    },
                    {
                        "@pid": "164/5298",
                        "text": "Sri Aravinda Krishnan Thyagarajan"
                    }
                ]
            },
            "title": "Non-interactive VSS using Class Groups and Application to DKG.",
            "venue": "CCS",
            "pages": "4286-4300",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/KateMMST24",
            "doi": "10.1145/3658644.3670312",
            "ee": "https://doi.org/10.1145/3658644.3670312",
            "url": "https://dblp.org/rec/conf/ccs/KateMMST24",
            "abstract": "We put forward a non-interactive verifiable secret sharing (NI-VSS) scheme using class groups - we call it cgVSS. Our construction follows the standard framework of encrypting the shares to a set of recipients and generating a non-interactiveproof of correct sharing. However, as opposed to prior works, such as Groth's [Eprint 2021], or Gentry et al.'s [Eurocrypt 2022], we do not require any range proof - this is possible due to the unique structure of class groups, that enables efficient encryption/decryption of large field elements in the exponent of an ElGamal-style encryption scheme. Importantly, this is possible without destroying the additive homomorphic structure, which is required to make the proof-of-correctness highly efficient. This approach not onlysubstantially simplifiesthe NI-VSS process, but alsooutperformsthe state-of-art schemes significantly. For example, our implementation shows that for a 150 node system cgVSS outperforms (a simplified implementation of) Groth's protocol in overall communication complexity by 5.6x, about 9.3 -- 9.7x in the dealer time and 2.4 - 2.7x in the receiver time per node.",
            "pdf_url": "",
            "keywords": [
                "Non-Interactive Verifiable Secret Sharing",
                "Class Groups",
                "ElGamal Encryption",
                "Communication Complexity",
                "Distributed Key Generation (DKG)"
            ]
        },
        "url": "URL#256722"
    },
    {
        "@score": "1",
        "@id": "256723",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "218/7156",
                        "text": "Mahimna Kelkar"
                    },
                    {
                        "@pid": "197/6885",
                        "text": "Kushal Babel"
                    },
                    {
                        "@pid": "168/1849",
                        "text": "Philip Daian"
                    },
                    {
                        "@pid": "305/3202",
                        "text": "James Austgen"
                    },
                    {
                        "@pid": "207/8171",
                        "text": "Vitalik Buterin"
                    },
                    {
                        "@pid": "j/AriJuels",
                        "text": "Ari Juels"
                    }
                ]
            },
            "title": "Complete Knowledge: Preventing Encumbrance of Cryptographic Secrets.",
            "venue": "CCS",
            "pages": "2415-2429",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/KelkarBDABJ24",
            "doi": "10.1145/3658644.3690273",
            "ee": "https://doi.org/10.1145/3658644.3690273",
            "url": "https://dblp.org/rec/conf/ccs/KelkarBDABJ24",
            "abstract": "Most cryptographic protocols model a player's knowledge of secrets in a simple way. Informally, the player knows a secret in the sense that she can directly furnish it as a (private) input to a protocol, e.g., to digitally sign a message.",
            "pdf_url": "",
            "keywords": [
                "Cryptographic Protocols",
                "Knowledge Representation",
                "Secret Management",
                "Encumbrance Prevention",
                "Cryptographic Secrets"
            ]
        },
        "url": "URL#256723"
    },
    {
        "@score": "1",
        "@id": "256724",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "378/0982",
                        "text": "Easton Kelso"
                    },
                    {
                        "@pid": "252/4043",
                        "text": "Ananta Soneji"
                    },
                    {
                        "@pid": "208/7323",
                        "text": "Sazzadur Rahaman"
                    },
                    {
                        "@pid": "119/7712",
                        "text": "Yan Shoshitaishvili"
                    },
                    {
                        "@pid": "157/1889-1",
                        "text": "Rakibul Hasan 0001"
                    }
                ]
            },
            "title": "Trust, Because You Can&apos;t Verify: Privacy and Security Hurdles in Education Technology Acquisition Practices.",
            "venue": "CCS",
            "pages": "1656-1670",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/KelsoSRSH24",
            "doi": "10.1145/3658644.3690353",
            "ee": "https://doi.org/10.1145/3658644.3690353",
            "url": "https://dblp.org/rec/conf/ccs/KelsoSRSH24",
            "abstract": "The education technology (EdTech) landscape is expanding rapidly in higher education institutes (HEIs). This growth brings enormous complexity. Protecting the extensive data collected by these tools is crucial for HEIs as data breaches and misuses can have dire security and privacy consequences for the data subjects, particularly students, who are often compelled to use these tools. This urges an in-depth understanding of HEI and EdTech vendor dynamics, which is largely understudied.",
            "pdf_url": "",
            "keywords": [
                "Education Technology",
                "Higher Education Institutions",
                "Data Privacy",
                "Data Security",
                "Vendor Dynamics"
            ]
        },
        "url": "URL#256724"
    },
    {
        "@score": "1",
        "@id": "256725",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "269/7613",
                        "text": "Victor Youdom Kemmoe"
                    },
                    {
                        "@pid": "70/3375",
                        "text": "Anna Lysyanskaya"
                    }
                ]
            },
            "title": "RSA-Based Dynamic Accumulator without Hashing into Primes.",
            "venue": "CCS",
            "pages": "4271-4285",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/KemmoeL24",
            "doi": "10.1145/3658644.3690199",
            "ee": "https://doi.org/10.1145/3658644.3690199",
            "url": "https://dblp.org/rec/conf/ccs/KemmoeL24",
            "abstract": "A cryptographic accumulator is a compact data structure for representing a set of elements coming from some domain. It allows for a compact proof of membership and, in the case of a universal accumulator, non-membership of an element x in the data structure. A dynamic accumulator, furthermore, allows elements to be added to and deleted from the accumulator.",
            "pdf_url": "",
            "keywords": [
                "Cryptographic Accumulator",
                "Dynamic Accumulator",
                "Membership Proof",
                "Non-Membership Proof",
                "RSA-Based Accumulator"
            ]
        },
        "url": "URL#256725"
    },
    {
        "@score": "1",
        "@id": "256726",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "209/8649",
                        "text": "Lucianna Kiffer"
                    },
                    {
                        "@pid": "205/3153",
                        "text": "Joachim Neu"
                    },
                    {
                        "@pid": "254/8997",
                        "text": "Srivatsan Sridhar"
                    },
                    {
                        "@pid": "92/4269",
                        "text": "Aviv Zohar"
                    },
                    {
                        "@pid": "t/DavidNCTse",
                        "text": "David Tse"
                    }
                ]
            },
            "title": "Nakamoto Consensus under Bounded Processing Capacity.",
            "venue": "CCS",
            "pages": "363-377",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/KifferNSZT24",
            "doi": "10.1145/3658644.3670347",
            "ee": "https://doi.org/10.1145/3658644.3670347",
            "url": "https://dblp.org/rec/conf/ccs/KifferNSZT24",
            "abstract": "For Nakamoto's longest-chain consensus protocol, whose proof-of-work (PoW) and proof-of-stake (PoS) variants power major blockchains such as Bitcoin and Cardano, we revisit the classic problem of the security-performance tradeoff: Given a network of nodes with finite communication- and computation-resources, against what fraction of adversary power is Nakamoto consensus (NC) secure for a given block production rate? State-of-the-art analyses of NC fail to answer this question, because their bounded-delay model does not capture the rate limits to nodes' processing of blocks, which cause congestion when blocks are released in quick succession. We develop a new analysis technique to prove a refined security-performance tradeoff for PoW NC in a bounded-capacity model. In this model, we show that, in contrast to the classic bounded-delay model, Nakamoto's private attack is no longer the worst attack, and a new attack we call the teasing strategy, that exploits congestion, is strictly worse. In PoS, equivocating blocks can exacerbate congestion, making traditional PoS NC insecure except at very low block production rates. To counter such equivocation spamming, we present a variant of PoS NC we call Blanking NC (BlaNC), which achieves the same resilience as PoW NC.",
            "keywords": [
                "Nakamoto Consensus",
                "Bounded Processing Capacity",
                "Proof-of-Work",
                "Teasing Strategy",
                "Blanking NC"
            ]
        },
        "url": "URL#256726",
        "sema_paperId": "753de0b3c46b575079e0e839da1a9b3f62331ff0"
    },
    {
        "@score": "1",
        "@id": "256727",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "19/4767",
                        "text": "Donghoon Kim"
                    },
                    {
                        "@pid": "53/3129",
                        "text": "Andrew Booth"
                    },
                    {
                        "@pid": "98/7002",
                        "text": "Euijin Choo"
                    },
                    {
                        "@pid": "39/2379",
                        "text": "Doosung Hwang"
                    }
                ]
            },
            "title": "Poster: Advanced Features for Real-Time Website Fingerprinting Attacks on Tor.",
            "venue": "CCS",
            "pages": "5054-5056",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/KimBCH24",
            "doi": "10.1145/3658644.3691373",
            "ee": "https://doi.org/10.1145/3658644.3691373",
            "url": "https://dblp.org/rec/conf/ccs/KimBCH24",
            "abstract": "The Tor network has been identified as vulnerable to website fingerprinting (WF) attacks. Existing WF attacks have proven effective against the Tor network. However, prior research has mostly been limited to controlled experimental settings, leading to questions about the practicality of WF attacks in real-time environments. Recent advancements in feature engineering and machine learning aim to address this by exploring real-world scenarios, though they often overlook the preprocessing time required to design features from raw network traffic data. To tackle these issues, this research focuses on developing more efficient and high-performing feature vectors for WF attacks in real-time by analyzing previously successful feature vectors. The results indicate that advanced features, particularly those in a compact feature set, deliver competitive performance with reduced training times for real-time WF attacks. This study enhances our understanding of the feasibility of real-time WF attacks on Tor networks in practical settings and may inform future security improvements.",
            "pdf_url": "",
            "keywords": [
                "Website Fingerprinting",
                "Tor Network",
                "Real-Time Attacks",
                "Feature Engineering",
                "Network Traffic Analysis"
            ]
        },
        "url": "URL#256727",
        "sema_paperId": "49b30f611de687ca9466b86133dfcd99946441f6"
    },
    {
        "@score": "1",
        "@id": "256728",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "22/6131",
                        "text": "Juhee Kim"
                    },
                    {
                        "@pid": "231/1918",
                        "text": "Jinbum Park"
                    },
                    {
                        "@pid": "301/5818",
                        "text": "Yoochan Lee"
                    },
                    {
                        "@pid": "69/6818",
                        "text": "Chengyu Song"
                    },
                    {
                        "@pid": "38/8882",
                        "text": "Taesoo Kim"
                    },
                    {
                        "@pid": "45/7986",
                        "text": "Byoungyoung Lee"
                    }
                ]
            },
            "title": "PeTAL: Ensuring Access Control Integrity against Data-only Attacks on Linux.",
            "venue": "CCS",
            "pages": "2919-2933",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/KimPLSKL24",
            "doi": "10.1145/3658644.3690184",
            "ee": "https://doi.org/10.1145/3658644.3690184",
            "url": "https://dblp.org/rec/conf/ccs/KimPLSKL24",
            "abstract": "Data-only attacks are emerging as a new threat to the security of modern operating systems. As a typical data-only attack, memory corruption attacks can compromise the integrity of kernel data, which effectively breaks the premises of access control systems. Unfortunately, the prevalence of memory corruption vulnerabilities allows attackers to exploit them and bypass access control mechanisms. Given the arbitrary memory access capability, attackers can overwrite access control policies or illegally access the kernel resources protected by the access control systems. This paper presents PeTAL, a practical access control integrity solution against data-only attacks on the ARM-based Linux kernel. PeTAL is designed to ensure access control integrity by providing policy integrity and complete enforcement of access control systems. PeTAL first identifies kernel data used as access control policies and kernel data protected by access control policies, based on the user interfaces of the Linux kernel. Then, PeTAL leverages the ARM Pointer Authentication Code (PAC) and Memory Tagging Extension (MTE) to comprehensively protect the integrity of the identified kernel data and pointers. We implemented the prototype of PeTAL and evaluated the performance and the security impact of PeTAL on real AArch64 hardware with PAC and MTE support. Our evaluation results show that PeTAL can effectively thwart memory-corruption-based attacks on access control systems with reasonable performance overheads at most 4% on average in user applications, demonstrating its efficient prospects for kernel security.",
            "keywords": [
                "Kernel Security",
                "Access Control Integrity",
                "Memory Corruption Attacks",
                "ARM Pointer Authentication",
                "Memory Tagging Extension"
            ]
        },
        "url": "URL#256728",
        "sema_paperId": "1a26711c1a15b177ae1022c4460a98990bb33ef2"
    },
    {
        "@score": "1",
        "@id": "256729",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "325/3232",
                        "text": "Jan H. Klemmer"
                    },
                    {
                        "@pid": "287/4547",
                        "text": "Stefan Albert Horstmann"
                    },
                    {
                        "@pid": "248/1690",
                        "text": "Nikhil Patnaik"
                    },
                    {
                        "@pid": "374/8361",
                        "text": "Cordelia Ludden"
                    },
                    {
                        "@pid": "377/8543",
                        "text": "Cordell Burton Jr."
                    },
                    {
                        "@pid": "377/9115",
                        "text": "Carson Powers"
                    },
                    {
                        "@pid": "59/6145",
                        "text": "Fabio Massacci"
                    },
                    {
                        "@pid": "06/10426",
                        "text": "Akond Rahman"
                    },
                    {
                        "@pid": "61/11094",
                        "text": "Daniel Votipka"
                    },
                    {
                        "@pid": "r/HeatherRichter",
                        "text": "Heather Richter Lipford"
                    },
                    {
                        "@pid": "26/3330",
                        "text": "Awais Rashid"
                    },
                    {
                        "@pid": "201/9227",
                        "text": "Alena Naiakshina"
                    },
                    {
                        "@pid": "38/9378",
                        "text": "Sascha Fahl"
                    }
                ]
            },
            "title": "Using AI Assistants in Software Development: A Qualitative Study on Security Practices and Concerns.",
            "venue": "CCS",
            "pages": "2726-2740",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/KlemmerHPLBPMRV24",
            "doi": "10.1145/3658644.3690283",
            "ee": "https://doi.org/10.1145/3658644.3690283",
            "url": "https://dblp.org/rec/conf/ccs/KlemmerHPLBPMRV24",
            "abstract": "Following the recent release of AI assistants, such as OpenAI's ChatGPT and GitHub Copilot, the software industry quickly utilized these tools for software development tasks, e.g., generating code or consulting AI for advice. While recent research has demonstrated that AI-generated code can contain security issues, how software professionals balance AI assistant usage and security remains unclear. This paper investigates how software professionals use AI assistants in secure software development, what security implications and considerations arise, and what impact they foresee on secure software development. We conducted 27 semi-structured interviews with software professionals, including software engineers, team leads, and security testers. We also reviewed 190 relevant Reddit posts and comments to gain insights into the current discourse surrounding AI assistants for software development. Our analysis of the interviews and Reddit posts finds that despite many security and quality concerns, participants widely use AI assistants for security-critical tasks, e.g., code generation, threat modeling, and vulnerability detection. Their overall mistrust leads to checking AI suggestions in similar ways to human code, although they expect improvements and, therefore, a heavier use for security tasks in the future. We conclude with recommendations for software professionals to critically check AI suggestions, AI creators to improve suggestion security and capabilities for ethical security tasks, and academic researchers to consider general-purpose AI in software development.",
            "keywords": [
                "AI Assistants",
                "Software Development",
                "Security Practices",
                "Vulnerability Detection",
                "Code Generation"
            ]
        },
        "url": "URL#256729",
        "sema_paperId": "a78b0eb79ddc4b17ac16b4b599e7ee8aca12036d"
    },
    {
        "@score": "1",
        "@id": "256730",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "301/5893",
                        "text": "Simon Klix"
                    },
                    {
                        "@pid": "228/7702",
                        "text": "Nils Albartus"
                    },
                    {
                        "@pid": "234/1389",
                        "text": "Julian Speith"
                    },
                    {
                        "@pid": "276/5458",
                        "text": "Paul Staat"
                    },
                    {
                        "@pid": "364/0505",
                        "text": "Alice Verstege"
                    },
                    {
                        "@pid": "358/6488",
                        "text": "Annika Wilde"
                    },
                    {
                        "@pid": "338/8066",
                        "text": "Daniel Lammers"
                    },
                    {
                        "@pid": "364/0333",
                        "text": "J\u00f6rn Langheinrich"
                    },
                    {
                        "@pid": "135/0525",
                        "text": "Christian Kison"
                    },
                    {
                        "@pid": "65/11443",
                        "text": "Sebastian Sester-Wehle"
                    },
                    {
                        "@pid": "67/7583",
                        "text": "Daniel E. Holcomb"
                    },
                    {
                        "@pid": "p/ChristofPaar",
                        "text": "Christof Paar"
                    }
                ]
            },
            "title": "Stealing Maggie&apos;s Secrets-On the Challenges of IP Theft Through FPGA Reverse Engineering.",
            "venue": "CCS",
            "pages": "3391-3405",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/KlixASSVWLLKSHP24",
            "doi": "10.1145/3658644.3690235",
            "ee": "https://doi.org/10.1145/3658644.3690235",
            "url": "https://dblp.org/rec/conf/ccs/KlixASSVWLLKSHP24",
            "abstract": "Intellectual Property (IP) theft is a cause of major financial and reputational damage, reportedly in the range of hundreds of billions of dollars annually in the U.S. alone. Field Programmable Gate Arrays (FPGAs) are particularly exposed to IP theft, because their configuration file contains the IP in a proprietary format that can be mapped to a gate-level netlist with moderate effort. Despite this threat, the scientific understanding of this issue lacks behind reality, thereby preventing an in-depth assessment of IP theft from FPGAs in academia. We address this discrepancy through a real-world case study on a Lattice iCE40 FPGA found inside iPhone 7. Apple refers to this FPGA as Maggie. By reverse engineering the proprietary signal-processing algorithm implemented on Maggie, we generate novel insights into the actual efforts required to commit FPGA IP theft and the challenges an attacker faces on the way. Informed by our case study, we then introduce generalized netlist reverse engineering techniques that drastically reduce the required manual effort and are applicable across a diverse spectrum of FPGA implementations and architectures. We evaluate these techniques on six benchmarks that are representative of different FPGA applications and have been synthesized for Xilinx and Lattice FPGAs, as well as in an end-to-end white-box case study. Finally, we provide a comprehensive open-source tool suite of netlist reverse engineering techniques to foster future research, enable the community to perform realistic threat assessments, and facilitate the evaluation of novel countermeasures.",
            "keywords": [
                "FPGA Reverse Engineering",
                "Intellectual Property Theft",
                "Configuration File Analysis",
                "Signal-Processing Algorithm",
                "Netlist Reverse Engineering Techniques"
            ]
        },
        "url": "URL#256730",
        "sema_paperId": "8618597539df1ac9c1cce7f5c1dd6ec57995e3ed"
    },
    {
        "@score": "1",
        "@id": "256731",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "322/5233",
                        "text": "Philip Klostermeyer"
                    },
                    {
                        "@pid": "251/3013",
                        "text": "Sabrina Amft"
                    },
                    {
                        "@pid": "349/7794",
                        "text": "Sandra H\u00f6ltervennhoff"
                    },
                    {
                        "@pid": "40/7792",
                        "text": "Alexander Krause"
                    },
                    {
                        "@pid": "273/7091",
                        "text": "Niklas Busch"
                    },
                    {
                        "@pid": "38/9378",
                        "text": "Sascha Fahl"
                    }
                ]
            },
            "title": "Skipping the Security Side Quests: A Qualitative Study on Security Practices and Challenges in Game Development.",
            "venue": "CCS",
            "pages": "2651-2665",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/KlostermeyerAHK24",
            "doi": "10.1145/3658644.3690190",
            "ee": "https://doi.org/10.1145/3658644.3690190",
            "url": "https://dblp.org/rec/conf/ccs/KlostermeyerAHK24",
            "abstract": "The video game market is one of the biggest for software products. Video game development has progressed in the last decades to complex and multifaceted endeavors. Games-as-a-Service significantly impacted distribution and gameplay, requiring providers and developers to consider factors beyond game functionality, including security and privacy. New security challenges emerged, including authentication, payment security, and user data or asset protection. However, the security community lacks in-depth insights into the security experiences, challenges, and practices of modern video game development. This paper aims to address this gap in research and highlights the criticality of considering security in the process. Therefore, we conducted 20 qualitative, semi-structured inter-views with various roles of professional and skilled video game development experts, investigating awareness, priorities, knowledge, and practices regarding security in the industry through their first-hand experiences. We find that stakeholders are aware of the urgency of security and related issues. However, they often face obstacles, including a lack of money, time, and knowledge, which force them to put security issues lower in priority. We conclude our work by recommending how the game industry can incorporate security into its development processes while balancing other resources and priorities and illustrating ideas for future research.",
            "keywords": [
                "Game Development Security",
                "Games-as-a-Service",
                "Security Challenges",
                "Development Practices",
                "Stakeholder Awareness"
            ]
        },
        "url": "URL#256731",
        "sema_paperId": "9b15338d94d782a43203086cf9d8590c91b57002"
    },
    {
        "@score": "1",
        "@id": "256732",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "386/7872",
                        "text": "Jonathan Knauer"
                    },
                    {
                        "@pid": "283/4641",
                        "text": "Phillip Rieger"
                    },
                    {
                        "@pid": "151/8708",
                        "text": "Hossein Fereidooni"
                    },
                    {
                        "@pid": "s/AhmadRezaSadeghi",
                        "text": "Ahmad-Reza Sadeghi"
                    }
                ]
            },
            "title": "Phantom: Untargeted Poisoning Attacks on Semi-Supervised Learning.",
            "venue": "CCS",
            "pages": "615-629",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/KnauerRFS24",
            "doi": "10.1145/3658644.3690369",
            "ee": "https://doi.org/10.1145/3658644.3690369",
            "url": "https://dblp.org/rec/conf/ccs/KnauerRFS24",
            "abstract": "Deep Neural Networks (DNNs) can handle increasingly complex tasks, albeit they require rapidly expanding training datasets. Collecting data from platforms with user-generated content, such as social networks, has significantly eased the acquisition of large datasets for training DNNs. Despite these advancements, the manual labeling process remains a substantial challenge in terms of both time and cost. In response, Semi-Supervised Learning (SSL) approaches have emerged, where only a small fraction of the dataset needs to be labeled, leaving the majority unlabeled. However, leveraging data from untrusted sources like social networks also creates new security risks, as potential attackers can easily inject manipulated samples. Previous research on the security of SSL primarily focused on injecting backdoors into trained models, while less attention was given to the more challenging untargeted poisoning attacks. In this paper, we introduce Phantom, the first untargeted poisoning attack in SSL that disrupts the training process by injecting a small number of manipulated images into the unlabeled dataset. Unlike existing attacks, our approach only requires adding few manipulated samples, such as posting images on social networks, without the need to control the victim. Phantom causes SSL algorithms to overlook the actual images' pixels and to rely only on maliciously crafted patterns that \\ourname superimposed on the real images. We show Phantom's effectiveness for 6 different datasets and 3 real-world social-media platforms (Facebook, Instagram, Pinterest). Already small fractions of manipulated samples (e.g., 5\\%) reduce the accuracy of the resulting model by 10\\%, with higher percentages leading to a performance comparable to a naive classifier. Our findings demonstrate the threat of poisoning user-generated content platforms, rendering them unsuitable for SSL in specific tasks.",
            "keywords": [
                "Semi-Supervised Learning",
                "Untargeted Poisoning Attacks",
                "Data Manipulation",
                "User-Generated Content",
                "Model Accuracy Reduction"
            ]
        },
        "url": "URL#256732",
        "sema_paperId": "112e376f21300c6c98626afc090057325067b5dc"
    },
    {
        "@score": "1",
        "@id": "256733",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "41/11468",
                        "text": "Jeffrey Knockel"
                    },
                    {
                        "@pid": "319/9769",
                        "text": "Mona Wang"
                    },
                    {
                        "@pid": "392/3300",
                        "text": "Zo\u00eb Reichert"
                    }
                ]
            },
            "title": "The Not-So-Silent Type: Vulnerabilities in Chinese IME Keyboards&apos; Network Security Protocols.",
            "venue": "CCS",
            "pages": "1701-1715",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/KnockelWR24",
            "doi": "10.1145/3658644.3690302",
            "ee": "https://doi.org/10.1145/3658644.3690302",
            "url": "https://dblp.org/rec/conf/ccs/KnockelWR24",
            "abstract": "Popular Chinese Input Method Editor (IME) keyboards almost universally feature \u201ccloud-based\u201d features that improve character prediction when typing. Handling such sensitive data (i.e., keystrokes) in transit demands security in transit. In this work, we perform a comprehensive security measurement of the Chinese IME keyboard ecosystem, investigating the network security of keystrokes sent in transit by popular Chinese IME keyboards from nine vendors. We studied the three most popular third-party keyboards, comprising 95.9% of the third-party keyboard market share in China, as well as the default Chinese IME keyboards pre-installed on six popular Android mobile device manufacturers in China. We found that the vast majority of IME keyboards utilize proprietary, non-TLS network encryption protocols. Our measurement revealed critical vulnerabilities in these encryption protocols from eight out of the nine vendors in which network attackers could completely reveal the contents of users\u2019 keystrokes in transit. We estimate that up to one billion users were affected by these vulnerabilities. Finally, we provide recommendations to various stakeholders to limit the harm from this existing set of vulnerabilities, as well as to prevent future vulnerabilities of this kind.",
            "keywords": [
                "Chinese Input Method Editors",
                "Network Security",
                "Keystroke Vulnerabilities",
                "Cloud-based Features",
                "Encryption Protocols"
            ]
        },
        "url": "URL#256733",
        "sema_paperId": "0da64e4ef4c1bfa50afe86be9f4047cb59403f7f"
    },
    {
        "@score": "1",
        "@id": "256734",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "160/3825",
                        "text": "Nishat Koti"
                    },
                    {
                        "@pid": "177/7910",
                        "text": "Varsha Bhat Kukkala"
                    },
                    {
                        "@pid": "64/3169",
                        "text": "Arpita Patra"
                    },
                    {
                        "@pid": "329/5534",
                        "text": "Bhavish Raj Gopal"
                    }
                ]
            },
            "title": "Graphiti: Secure Graph Computation Made More Scalable.",
            "venue": "CCS",
            "pages": "4017-4031",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/KotiKPG24",
            "doi": "10.1145/3658644.3670393",
            "ee": "https://doi.org/10.1145/3658644.3670393",
            "url": "https://dblp.org/rec/conf/ccs/KotiKPG24",
            "abstract": "Privacy-preserving graph analysis allows performing computations on graphs that store sensitive information while ensuring all the information about the topology of the graph, as well as data associated with the nodes and edges, remains hidden. The current work addresses this problem by designing a highly scalable framework, Graphiti, that allows securely realising any graph algorithm. Graphiti relies on the technique of secure multiparty computation (MPC) to design a generic framework that improves over the state-of-the-art framework of GraphSC by Araki et al. (CCS'21). The key technical contribution is that Graphiti has round complexity independent of the graph size, which in turn allows attaining the desired scalability. Specifically, this is achieved by (i) decoupling the Scatter primitive of GraphSC into separate operations of Propagate and ApplyE, (ii) designing a novel constant-round approach to realise Propagate, as well as (iii) designing a novel constant-round approach to realise the Gather primitive of GraphSC by leveraging the linearity of the aggregation operation. We benchmark the performance of Graphiti for the application of contact tracing via BFS for 10 hops and observe that it takes less than 2 minutes when computing over a graph of size 10^7. Concretely it improves over the state-of-the-art up to a factor of 1034\u00d7 in online run time. Similar to GraphSC by Araki et al., since Graphiti relies on a secure protocol for shuffle, we additionally design a shuffle protocol secure against a semi-honest adversary in the 2-party with a helper setting. Given the versatility of shuffle protocol, the designed solution is of independent interest. Hence, we also benchmark the performance of the designed shuffle where we observe improvements of up to 1.83\u00d7 in online run time when considering an input vector of size 10^7, in comparison to the state-of-the-art in the considered setting.",
            "pdf_url": "",
            "keywords": [
                "Privacy-Preserving Graph Analysis",
                "Secure Multiparty Computation",
                "Graph Algorithms",
                "Scalability",
                "Contact Tracing"
            ]
        },
        "url": "URL#256734"
    },
    {
        "@score": "1",
        "@id": "256735",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "172/0010",
                        "text": "Brian Koziel"
                    },
                    {
                        "@pid": "73/2739",
                        "text": "S. Dov Gordon"
                    },
                    {
                        "@pid": "28/2376",
                        "text": "Craig Gentry"
                    }
                ]
            },
            "title": "Fast Two-party Threshold ECDSA with Proactive Security.",
            "venue": "CCS",
            "pages": "1567-1580",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/KozielGG24",
            "doi": "10.1145/3658644.3670387",
            "ee": "https://doi.org/10.1145/3658644.3670387",
            "url": "https://dblp.org/rec/conf/ccs/KozielGG24",
            "abstract": "We present a new construction of two-party, threshold ECDSA, building on a 2017 scheme of Lindell and improving his scheme in several ways. ECDSA signing is notoriously hard to distribute securely, due to non-linearities in the signing function. Lindell\u2019s scheme uses Paillier encryption to encrypt one party\u2019s key share and handle these non-linearities homomorphically, while elegantly avoiding any expensive zero knowledge proofs over the Paillier group during the signing process. However, the scheme pushes that complexity into key generation. Moreover, avoiding ZK proofs about Paillier ciphertexts during signing comes with a steep price \u2013 namely, the scheme requires a \u201cglobal abort\u201d when a malformed ciphertext is detected, after which an entirely new key must be generated. Weovercome all of these issues with a proactive Refresh procedure. Since the Paillier decryption key is part of the secret that must be proactively refreshed, our first improvement is to radically accelerate key generation by replacing one of Lindell\u2019s ZK proofs \u2013 which requires 80 Paillier ciphertexts for statistical security 2 \u2212 40 \u2013 with a much faster \u201cweak\u201d proof that requires only 2 Paillier ciphertexts, and which proves a weaker statement about a Paillier ciphertext that we show is sufficient in the context of our scheme. Secondly, our more efficient key generation procedure also makes frequent proactive Refreshes practical. Finally, we show that adding noise to one party\u2019s key share suffices to avoid the need to reset the public verification key when certain bad behavior is detected. Instead, we prove that our Refresh procedure, performed after each detection, suffices for addressing the attack, allowing the system to continue functioning without disruption to applications that rely on the verification key. Our scheme is also very efficient, competitive with the best constructions that do not provide proactive security, and state-of-the-art among the few results that do. Our optimizations to ECDSA key generation speed up runtime and improve bandwidth over Lindell\u2019s key generation by factors of 7 and 13, respectively. Our Key Generation protocol requires 20% less bandwidth than existing constructions, completes in only 3 protocol messages, and executes much faster than all but OT-based key generation. For ECDSA signing, our extra Refresh protocol does add a 10X latency and 5X bandwidth overhead compared to Lindell. However, this still fits in 150 ms runtime and about 5.4 KB of messages when run in our AWS cluster benchmark.",
            "keywords": [
                "Threshold ECDSA",
                "Proactive Security",
                "Key Generation",
                "Paillier Encryption",
                "ECDSA Signing"
            ]
        },
        "url": "URL#256735",
        "sema_paperId": "a4ea34387353fbe66d7141ef7e37e611b8b1a0c7"
    },
    {
        "@score": "1",
        "@id": "256736",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "156/3375",
                        "text": "Dmitrii Kuvaiskii"
                    },
                    {
                        "@pid": "317/1689",
                        "text": "Dimitrios Stavrakakis"
                    },
                    {
                        "@pid": "368/7276",
                        "text": "Kailun Qin"
                    },
                    {
                        "@pid": "213/8021",
                        "text": "Cedric Xing"
                    },
                    {
                        "@pid": "35/8319",
                        "text": "Pramod Bhatotia"
                    },
                    {
                        "@pid": "47/9256",
                        "text": "Mona Vij"
                    }
                ]
            },
            "title": "Gramine-TDX: A Lightweight OS Kernel for Confidential VMs.",
            "venue": "CCS",
            "pages": "4598-4612",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/KuvaiskiiSQXBV24",
            "doi": "10.1145/3658644.3690323",
            "ee": "https://doi.org/10.1145/3658644.3690323",
            "url": "https://dblp.org/rec/conf/ccs/KuvaiskiiSQXBV24",
            "abstract": "While Confidential Virtual Machines (CVMs) have emerged as a prominent way for hardware-assisted confidential computing, their primary usage is not suitable for small, specialized, security-critical workloads, i.e., legacy VMs with their conventional OS distributions result in a large trusted computing base. In this paper, we present the Gramine-TDX OS kernel to execute slim, single-purpose, security-first, unmodified Linux workloads with a minimal attack surface. In comparison to a typical Linux kernel, Gramine-TDX\u2019s codebase is \u223c 50 \u00d7 less in binary size and has a significantly smaller attack surface, which makes it a perfect match for emerging cloud-native confidential-computing workloads. Our evaluation on 11 workloads indicates that Gramine-TDX has 1-25% average overhead for CPU-and memory-intensive applications. Performance on network-and FS-intensive applications can drop to 6% of the native application\u2019s, as Gramine-TDX prioritizes security over optimizations in virtual hardware communication. We build our prototype using Intel\u00aeTrust Domain Extensions (TDX).",
            "keywords": [
                "Confidential Virtual Machines",
                "Gramine-TDX",
                "Lightweight OS Kernel",
                "Trusted Computing Base",
                "Security-First Workloads"
            ]
        },
        "url": "URL#256736",
        "sema_paperId": "57a5c8c0260877f449b4151da3f89bd7ac7d6dee"
    },
    {
        "@score": "1",
        "@id": "256737",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "380/6015",
                        "text": "Nada Lahjouji"
                    },
                    {
                        "@pid": "189/4686",
                        "text": "Sameera Ghayyur"
                    },
                    {
                        "@pid": "28/949-1",
                        "text": "Xi He 0001"
                    },
                    {
                        "@pid": "m/SharadMehrotra",
                        "text": "Sharad Mehrotra"
                    }
                ]
            },
            "title": "ProBE: Proportioning Privacy Budget for Complex Exploratory Decision Support.",
            "venue": "CCS",
            "pages": "1924-1938",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/LahjoujiG0M24",
            "doi": "10.1145/3658644.3670394",
            "ee": "https://doi.org/10.1145/3658644.3670394",
            "url": "https://dblp.org/rec/conf/ccs/LahjoujiG0M24",
            "abstract": "This paper studies privacy in the context of complex decision support queries composed of multiple conditions on different aggregate statistics combined using disjunction and conjunction operators. Utility requirements for such queries necessitate the need for private mechanisms that guarantee a bound on the false negative and false positive errors. This paper formally defines complex decision support queries and their accuracy requirements, and provides algorithms that proportion the existing budget to optimally minimize privacy loss while supporting a bounded guarantee on the accuracy. Our experimental results on multiple real-life datasets show that our algorithms successfully maintain such utility guarantees, while also minimizing privacy loss.",
            "keywords": [
                "Privacy Budgeting",
                "Complex Decision Support",
                "Aggregate Statistics",
                "Utility Guarantees",
                "Accuracy Requirements"
            ]
        },
        "url": "URL#256737",
        "sema_paperId": "46095bd4adadbf53ae020106af5884669af48fbe"
    },
    {
        "@score": "1",
        "@id": "256738",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "255/4898",
                        "text": "Yuni Lai"
                    },
                    {
                        "@pid": "82/1512-1",
                        "text": "Kai Zhou 0001"
                    }
                ]
            },
            "title": "Poster: AuditVotes: A Framework towards Deployable Certified Robustness for GNNs.",
            "venue": "CCS",
            "pages": "4949-4951",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Lai024",
            "doi": "10.1145/3658644.3691376",
            "ee": "https://doi.org/10.1145/3658644.3691376",
            "url": "https://dblp.org/rec/conf/ccs/Lai024",
            "abstract": "Graph Neural Networks (GNNs) are powerful but vulnerable to adversarial attacks, necessitating the research on certified robustness that can provide GNNs with robustness guarantees. Existing randomized smoothing methods struggle with a trade-off between utility and robustness due to high noise levels. We introduceAuditVotes,which integrates randomized smoothing with two components, <u>au</u>gmentation and con<u>dit</u>ional smoothing, aiming to improve data and vote quality. We instantiated AuditVotes with simple strategies, and preliminary results demonstrate its significant promise in enhancing certified robustness, representing a substantial step toward deploying certifiably robust GNNs in real-world applications.",
            "pdf_url": "",
            "keywords": [
                "Graph Neural Networks",
                "Certified Robustness",
                "Adversarial Attacks",
                "Randomized Smoothing",
                "AuditVotes Framework"
            ]
        },
        "url": "URL#256738",
        "sema_paperId": "dcb295f8d17cb2046f352cc948d9e94751f6c25c"
    },
    {
        "@score": "1",
        "@id": "256739",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "172/6530",
                        "text": "Daniele Lain"
                    },
                    {
                        "@pid": "386/7543",
                        "text": "Tarek Jost"
                    },
                    {
                        "@pid": "120/1940",
                        "text": "Sinisa Matetic"
                    },
                    {
                        "@pid": "42/2366",
                        "text": "Kari Kostiainen"
                    },
                    {
                        "@pid": "51/1639",
                        "text": "Srdjan Capkun"
                    }
                ]
            },
            "title": "Content, Nudges and Incentives: A Study on the Effectiveness and Perception of Embedded Phishing Training.",
            "venue": "CCS",
            "pages": "4182-4196",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/LainJMKC24",
            "doi": "10.1145/3658644.3690348",
            "ee": "https://doi.org/10.1145/3658644.3690348",
            "url": "https://dblp.org/rec/conf/ccs/LainJMKC24",
            "abstract": "A common form of phishing training in organizations is the use of simulated phishing emails to test employees' susceptibility to phishing attacks, and the immediate delivery of training material to those who fail the test. This widespread practice is dubbed embedded training; however, its effectiveness in decreasing the likelihood of employees falling for phishing again in the future is questioned by the contradictory findings of several recent field studies. We investigate embedded phishing training in three aspects. First, we observe that the practice incorporates different components -- knowledge gains from its content, nudges and reminders from the test itself, and the deterrent effect of potential consequences -- our goal is to study which ones are more effective, if any. Second, we explore two potential improvements to training, namely its timing and the use of incentives. Third, we analyze employees' reception and perception of the practice. For this, we conducted a large-scale mixed-methods (quantitative and qualitative) study on the employees of a partner company. Our study contributes several novel findings on the training practice: in particular, its effectiveness comes from its nudging effect, i.e., the periodic reminder of the threat rather than from its content, which is rarely consumed by employees due to lack of time and perceived usefulness. Further, delaying training to ease time pressure is as effective as currently established practices, while rewards do not improve secure behavior. Finally, some of our results support previous findings with increased ecological validity, e.g., that phishing is an attention problem, rather than a knowledge one, even for the most susceptible employees, and thus enforcing training does not help.",
            "keywords": [
                "Phishing Training",
                "Embedded Training",
                "Employee Behavior",
                "Nudges and Incentives",
                "Training Effectiveness"
            ]
        },
        "url": "URL#256739",
        "sema_paperId": "a9b2c1c5d9460f4d9aa1e4c19a0c413569193c23"
    },
    {
        "@score": "1",
        "@id": "256740",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "244/8329",
                        "text": "Stella Lau"
                    },
                    {
                        "@pid": "145/1652",
                        "text": "Thomas Bourgeat"
                    },
                    {
                        "@pid": "155/8144",
                        "text": "Cl\u00e9ment Pit-Claudel"
                    },
                    {
                        "@pid": "52/796",
                        "text": "Adam Chlipala"
                    }
                ]
            },
            "title": "Specification and Verification of Strong Timing Isolation of Hardware Enclaves.",
            "venue": "CCS",
            "pages": "1121-1135",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/LauBPC24",
            "doi": "10.1145/3658644.3690203",
            "ee": "https://doi.org/10.1145/3658644.3690203",
            "url": "https://dblp.org/rec/conf/ccs/LauBPC24",
            "abstract": "The process isolation enforceable by commodity hardware and operating systems is too weak to protect secrets from malicious code running on the same machine: attacks exploit timing side channels derived from contention on shared microarchitectural resources to extract secrets. With appropriate hardware support, however, we can construct isolated enclaves and safeguard independent processes from interference through timing side channels, a step towards confidentiality and integrity guarantees.",
            "pdf_url": "",
            "keywords": [
                "Hardware Enclaves",
                "Timing Isolation",
                "Microarchitectural Resources",
                "Side Channel Attacks",
                "Process Isolation"
            ]
        },
        "url": "URL#256740",
        "sema_paperId": "fc29417a8f5c18f5158ba9b73c92d167ab169e38"
    },
    {
        "@score": "1",
        "@id": "256741",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "322/4215",
                        "text": "Evan Laufer"
                    },
                    {
                        "@pid": "200/3122",
                        "text": "Alex Ozdemir"
                    },
                    {
                        "@pid": "b/DanBoneh",
                        "text": "Dan Boneh"
                    }
                ]
            },
            "title": "zkPi: Proving Lean Theorems in Zero-Knowledge.",
            "venue": "CCS",
            "pages": "4301-4315",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/LauferOB24",
            "doi": "10.1145/3658644.3670322",
            "ee": "https://doi.org/10.1145/3658644.3670322",
            "url": "https://dblp.org/rec/conf/ccs/LauferOB24",
            "abstract": "Interactive theorem provers (ITPs), such as Lean and Coq, can express formal proofs for a large category of theorems, from abstract math to software correctness. Consider Alice who has a Lean proof for some public statementT. Alice wants to convince the world that she has such a proof, without revealing the actual proof. Perhaps the proof shows that a secret program is correct or safe, but the proof itself might leak information about the program's source code. A natural way for Alice to proceed is to construct a succinct, zero-knowledge, non-interactive argument of knowledge (zkSNARK) to prove that she has a Lean proof for the statementT.",
            "pdf_url": "",
            "keywords": [
                "Zero-Knowledge Proofs",
                "Interactive Theorem Provers",
                "Formal Verification",
                "Succinct Proofs",
                "Lean Theorems"
            ]
        },
        "url": "URL#256741"
    },
    {
        "@score": "1",
        "@id": "256742",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "224/9670",
                        "text": "Seoksu Lee"
                    },
                    {
                        "@pid": "375/0958",
                        "text": "Hyeongchang Jeon"
                    },
                    {
                        "@pid": "83/142",
                        "text": "Eun-Sun Cho"
                    }
                ]
            },
            "title": "Poster: E-Graphs and Equality Saturation for Term-Rewriting in MBA Deobfuscation: An Empirical Study.",
            "venue": "CCS",
            "pages": "4985-4987",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/LeeJC24",
            "doi": "10.1145/3658644.3691382",
            "ee": "https://doi.org/10.1145/3658644.3691382",
            "url": "https://dblp.org/rec/conf/ccs/LeeJC24",
            "abstract": "Obfuscation is a powerful software protection technique. It changes a program into a more complicated one while preserving its semantics. Malware distributors also employ this method, to protect their malware from being understood by malware analysts. Thus, it is crucial to deobfuscate malware in a timely manner, to enable a prompt action to malware.",
            "pdf_url": "",
            "keywords": [
                "Malware Deobfuscation",
                "Software Protection Techniques",
                "Term-Rewriting",
                "E-Graphs",
                "Equality Saturation"
            ]
        },
        "url": "URL#256742",
        "sema_paperId": "a0b46e5816c5c42430dd750dccbf42860468a62e"
    },
    {
        "@score": "1",
        "@id": "256743",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "132/9738",
                        "text": "Wanpeng Li"
                    },
                    {
                        "@pid": "151/4762",
                        "text": "Yuejun Guo 0001"
                    }
                ]
            },
            "title": "Poster: Automated Dependency Mapping for Web API Security Testing Using Large Language Models.",
            "venue": "CCS",
            "pages": "5024-5026",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Li024",
            "doi": "10.1145/3658644.3691377",
            "ee": "https://doi.org/10.1145/3658644.3691377",
            "url": "https://dblp.org/rec/conf/ccs/Li024",
            "abstract": "Dependency extraction is crucial in web API security testing, as it helps identify the required API sequences to exploit a vulnerability. Traditional methods are generally rule-based and require extensive manual analysis of API specification documents by domain experts to formulate appropriate rules. This manual process is not only time-consuming and labor-intensive but also prone to missing dependencies and inaccuracies, which can compromise the effectiveness of security testing. In this paper, we explore the potential of large language models (LLMs) to automate dependency mapping in web APIs. By leveraging the capabilities of advanced LLMs such as GPT-3.5, Mistral-7B-Instruct, and Llama-3-8B-Instruct, which include understanding and generating natural language, we aim to streamline the dependency mapping process, reducing the need for manual analysis and enhancing accuracy. Our preliminary experiments demonstrate that this approach can effectively build dependency mappings, offering a a promising alternative to traditional rule-based approaches.",
            "pdf_url": "",
            "keywords": [
                "Web API Security",
                "Dependency Mapping",
                "Automated Testing",
                "Large Language Models",
                "Vulnerability Exploitation"
            ]
        },
        "url": "URL#256743",
        "sema_paperId": "464978c7e9e3f955f94051395e94ae76efb8a55c"
    },
    {
        "@score": "1",
        "@id": "256744",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "87/6284-10",
                        "text": "Yun Li 0010"
                    },
                    {
                        "@pid": "05/4011-1",
                        "text": "Daniel Escudero 0001"
                    },
                    {
                        "@pid": "151/0274",
                        "text": "Yufei Duan"
                    },
                    {
                        "@pid": "128/9270",
                        "text": "Zhicong Huang"
                    },
                    {
                        "@pid": "78/10002",
                        "text": "Cheng Hong"
                    },
                    {
                        "@pid": "94/3019-8",
                        "text": "Chao Zhang 0008"
                    },
                    {
                        "@pid": "66/7929",
                        "text": "Yifan Song"
                    }
                ]
            },
            "title": "Sublinear Distributed Product Checks on Replicated Secret-Shared Data over Z2k Without Ring Extensions.",
            "venue": "CCS",
            "pages": "825-839",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Li0DHHZS24",
            "doi": "10.1145/3658644.3690260",
            "ee": "https://doi.org/10.1145/3658644.3690260",
            "url": "https://dblp.org/rec/conf/ccs/Li0DHHZS24",
            "abstract": "Multiple works have designed or used maliciously secure honest majority MPC protocols over Z2kusing replicated secret sharing (e.g. Koti et al. USENIX'21). A recent trend in the design of such MPC protocols is to first execute a semi-honest protocol, and then use a check that verifies the correctness of the computation requiring only sublinear amount of communication in terms of the circuit size. The so-called Galois ring extensions are needed in order to execute such checks over Z2k, but these rings incur incredibly high computation overheads, which completely undermine any potential benefits the ring Z2khad to begin with.",
            "pdf_url": "",
            "keywords": [
                "Maliciously Secure MPC",
                "Replicated Secret Sharing",
                "Sublinear Communication",
                "Z2k Computation",
                "Galois Ring Extensions"
            ]
        },
        "url": "URL#256744"
    },
    {
        "@score": "1",
        "@id": "256745",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "202/2279",
                        "text": "Zhaoxuan Li"
                    },
                    {
                        "@pid": "331/8204",
                        "text": "Ziming Zhao 0008"
                    },
                    {
                        "@pid": "11/444",
                        "text": "Wenhao Li"
                    },
                    {
                        "@pid": "60/2536-16",
                        "text": "Rui Zhang 0016"
                    },
                    {
                        "@pid": "30/4367-1",
                        "text": "Rui Xue 0001"
                    },
                    {
                        "@pid": "175/7705",
                        "text": "Siqi Lu"
                    },
                    {
                        "@pid": "21/3626-10",
                        "text": "Fan Zhang 0010"
                    }
                ]
            },
            "title": "Demo: Enhancing Smart Contract Security Comprehensively through Dynamic Symbolic Execution.",
            "venue": "CCS",
            "pages": "5072-5074",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Li0LZ0L024",
            "doi": "10.1145/3658644.3691365",
            "ee": "https://doi.org/10.1145/3658644.3691365",
            "url": "https://dblp.org/rec/conf/ccs/Li0LZ0L024",
            "abstract": "The frequent security incidents of contracts indicate a pressing need to ensure contract security from deployment to running stages, but the state-of-the-art (SOTA) analysis methods cannot work well for three requirements. (i) Identify contract defective code snippets, while generating exploit call sequences to help developers fix them. (ii) Monitor abnormal call behaviors, especially for multiple continuous transactions. (iii) Validate numerous unexploitable detection results automatically because manual verification is labor-intensive. (iv) To tackle these problems, we propose SymX, a symbolic execution-based security analysis art accounting for contract development and running stages. The experiment results demonstrate that it can accurately identify 90.22% of contracts and 98.04% of call transactions, as well as validate misreports as intended, which is superior to SOTAs, thereby protecting contracts better during the contract lifecycle. Currently, SymX is available at https://github.com/Secbrain/SymX.",
            "pdf_url": "",
            "keywords": [
                "Smart Contract Security",
                "Dynamic Symbolic Execution",
                "Contract Vulnerabilities",
                "Exploit Call Sequences",
                "Abnormal Call Behavior Monitoring"
            ]
        },
        "url": "URL#256745",
        "sema_paperId": "265a7aac6f97e1752db61c86b4581a6515fd35ea"
    },
    {
        "@score": "1",
        "@id": "256746",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "17/5705",
                        "text": "Hao Li"
                    },
                    {
                        "@pid": "10/1143-23",
                        "text": "Zheng Li 0023"
                    },
                    {
                        "@pid": "44/3983",
                        "text": "Siyuan Wu"
                    },
                    {
                        "@pid": "383/5407",
                        "text": "Chengrui Hu"
                    },
                    {
                        "@pid": "192/4957",
                        "text": "Yutong Ye"
                    },
                    {
                        "@pid": "83/5342",
                        "text": "Min Zhang"
                    },
                    {
                        "@pid": "79/2089",
                        "text": "Dengguo Feng"
                    },
                    {
                        "@pid": "06/6785-16",
                        "text": "Yang Zhang 0016"
                    }
                ]
            },
            "title": "SeqMIA: Sequential-Metric Based Membership Inference Attack.",
            "venue": "CCS",
            "pages": "3496-3510",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Li0WHYZF024",
            "doi": "10.1145/3658644.3690335",
            "ee": "https://doi.org/10.1145/3658644.3690335",
            "url": "https://dblp.org/rec/conf/ccs/Li0WHYZF024",
            "abstract": "Most existing membership inference attacks (MIAs) utilize metrics (e.g., loss) calculated on the model's final state, while recent advanced attacks leverage metrics computed at various stages, including both intermediate and final stages, throughout the model training. Nevertheless, these attacks often process multiple intermediate states of the metric independently, ignoring their time-dependent patterns. Consequently, they struggle to effectively distinguish between members and non-members who exhibit similar metric values, particularly resulting in a high false-positive rate. In this study, we delve deeper into the new membership signals in the black-box scenario. We identify a new, more integrated membership signal: the Pattern of Metric Sequence, derived from the various stages of model training. We contend that current signals provide only partial perspectives of this new signal: the new one encompasses both the model's multiple intermediate and final states, with a greater emphasis on temporal patterns among them. Building upon this signal, we introduce a novel attack method called Sequential-metric based Membership Inference Attack (SeqMIA). Specifically, we utilize knowledge distillation to obtain a set of distilled models representing various stages of the target model's training. We then assess multiple metrics on these distilled models in chronological order, creating distilled metric sequence. We finally integrate distilled multi-metric sequences as a sequential multiformat and employ an attention-based RNN attack model for inference. Empirical results show SeqMIA outperforms all baselines, especially can achieve an order of magnitude improvement in terms of TPR @ 0.1% FPR. Furthermore, we delve into the reasons why this signal contributes to SeqMIA's high attack performance, and assess various defense mechanisms against SeqMIA.",
            "keywords": [
                "Membership Inference Attack",
                "Sequential Metrics",
                "Temporal Patterns",
                "Knowledge Distillation",
                "False Positive Rate"
            ]
        },
        "url": "URL#256746",
        "sema_paperId": "c154acf1e1518d78cd6df13f5272832b53844ed4"
    },
    {
        "@score": "1",
        "@id": "256747",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "50/3937",
                        "text": "Xiaofan Li"
                    },
                    {
                        "@pid": "180/8186",
                        "text": "Yacong Gu"
                    },
                    {
                        "@pid": "352/6204",
                        "text": "Chu Qiao"
                    },
                    {
                        "@pid": "117/0017",
                        "text": "Zhenkai Zhang"
                    },
                    {
                        "@pid": "150/5465",
                        "text": "Daiping Liu"
                    },
                    {
                        "@pid": "18/7667",
                        "text": "Lingyun Ying"
                    },
                    {
                        "@pid": "36/5143",
                        "text": "Haixin Duan"
                    },
                    {
                        "@pid": "87/4866-1",
                        "text": "Xing Gao 0001"
                    }
                ]
            },
            "title": "Toward Understanding the Security of Plugins in Continuous Integration Services.",
            "venue": "CCS",
            "pages": "482-496",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/LiGQZLYD024",
            "doi": "10.1145/3658644.3670366",
            "ee": "https://doi.org/10.1145/3658644.3670366",
            "url": "https://dblp.org/rec/conf/ccs/LiGQZLYD024",
            "abstract": "Mainstream Continuous Integration (CI) platforms have provided the plugin functionality to accelerate the development of CI pipelines. Unfortunately, CI plugins, which are essentially reusable code snippets, also expose new attack surfaces as plugins might be developed by less trusted users. In this paper, we present an in-depth study to understand potential security risks in existing CI plugins. We conduct a comprehensive analysis of plugin implementations on four mainstream CI platforms (GitHub Actions, GitLab CI, CircleCI, and Azure Pipelines), and investigate several weak links in existing plugin distributions and isolation mechanisms. We investigate seven attack vectors that can enable attackers to hijack plugins and distribute malicious code without plugins users being aware, and further exploit hijacked plugins to manipulate the workflow execution. Additionally, we find that plugin dependency (a plugin references other plugins) might further amplify the attack impact of our disclosed attacks. To evaluate the potential impact, we conduct a large-scale measurement on GitHub and GitLab, covering a total of 1,328,912 repositories using the aforementioned CI platforms. Our measurement results show that a large number of repositories and existing plugins, including many widely used ones, are potentially vulnerable to the proposed attacks. We have duly reported the identified vulnerabilities and received positive responses.",
            "pdf_url": "",
            "keywords": [
                "Continuous Integration Security",
                "CI Plugins",
                "Malicious Code Distribution",
                "Plugin Vulnerabilities",
                "Workflow Manipulation"
            ]
        },
        "url": "URL#256747",
        "sema_paperId": "4c5de2981dad2aab1ebde48cfb885aecf8836dff"
    },
    {
        "@score": "1",
        "@id": "256748",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "80/138",
                        "text": "YongGang Li"
                    },
                    {
                        "@pid": "392/2979",
                        "text": "ShunRong Jiang"
                    },
                    {
                        "@pid": "83/8070",
                        "text": "Yu Bao"
                    },
                    {
                        "@pid": "40/993",
                        "text": "Pengpeng Chen"
                    },
                    {
                        "@pid": "90/5836-3",
                        "text": "Yong Zhou 0003"
                    },
                    {
                        "@pid": "17/3",
                        "text": "Yeh-Ching Chung"
                    }
                ]
            },
            "title": "Isolate and Detect the Untrusted Driver with a Virtual Box.",
            "venue": "CCS",
            "pages": "4584-4597",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/LiJBCZC24",
            "doi": "10.1145/3658644.3670269",
            "ee": "https://doi.org/10.1145/3658644.3670269",
            "url": "https://dblp.org/rec/conf/ccs/LiJBCZC24",
            "abstract": "In kernel, the driver code is much more than the core code, thus having a larger attack surface. Especially for the untrusted drivers without source code, they may come from the hot-plug hardware or the user without security knowledge. Traditional isolation methods require analyzing source code to set checkpoints in the driver for control flow protection, which are not available for closed-source drivers. Even worse, the existing isolation methods can only prevent the hijacked control flows entering/existing drivers, while they cannot discover the illegal control flows inside drivers. Although the kernel address space location randomization (KASLR) can defend against control flow hijacking, it can be bypassed by code probes. In response to these issues, this paper proposes a novel method Dbox to isolate and detect the untrusted drivers whose source code is unavailable. Dbox creates a light hypervisor to monitor and analyze the untrusted driver\u2019s behavior without relying on source code. It isolates the untrusted driver in a private space and dynamically changes its virtual space through a sliding space mechanism. Under the protection of Dbox, all control flows jumping to/from untrusted drivers can be detected. Experiments and analysis show that Dbox has good protection against code probes, kernel rootkits and code reuse attacks, and the overhead introduced to the operating system is less than 3.6% in general scenarios.",
            "keywords": [
                "Driver Isolation",
                "Kernel Security",
                "Untrusted Drivers",
                "Control Flow Detection",
                "Hypervisor Monitoring"
            ]
        },
        "url": "URL#256748",
        "sema_paperId": "8815975ddf335790abaaa56f3d23738615f5d67b"
    },
    {
        "@score": "1",
        "@id": "256749",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "359/9641",
                        "text": "Yueshen Li"
                    },
                    {
                        "@pid": "216/5317",
                        "text": "Jianli Jin"
                    },
                    {
                        "@pid": "l/KirillLevchenko",
                        "text": "Kirill Levchenko"
                    }
                ]
            },
            "title": "CAPSID: A Private Session ID System for Small UAVs.",
            "venue": "CCS",
            "pages": "1791-1805",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/LiJL24",
            "doi": "10.1145/3658644.3690324",
            "ee": "https://doi.org/10.1145/3658644.3690324",
            "url": "https://dblp.org/rec/conf/ccs/LiJL24",
            "abstract": "The US Federal Aviation Administration (FAA) has recently mandated that small unmanned aerial vehicles (UAVs) be equipped with a transmitter that broadcasts the UAV's serial number, location, and altitude. The inclusion of a unique identifier in the form of a UAV serial number has stoked fears that the identifier will be used to track UAV operators and has even led some UAV operators to file a lawsuit against the FAA.",
            "pdf_url": "",
            "keywords": [
                "UAV Identification",
                "Privacy Concerns",
                "Transmitter Regulations",
                "Session ID System",
                "Tracking Risks"
            ]
        },
        "url": "URL#256749",
        "sema_paperId": "225f34ace0ef708f041e91f2374e8215530c778f"
    },
    {
        "@score": "1",
        "@id": "256750",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "234/5954",
                        "text": "Yizhi Li"
                    },
                    {
                        "@pid": "41/3068",
                        "text": "Jiang Li"
                    },
                    {
                        "@pid": "218/8811",
                        "text": "Jiahao Cao"
                    },
                    {
                        "@pid": "191/1022",
                        "text": "Renjie Xie"
                    },
                    {
                        "@pid": "20/8967-1",
                        "text": "Yangyang Wang 0001"
                    },
                    {
                        "@pid": "18/6055",
                        "text": "Mingwei Xu"
                    }
                ]
            },
            "title": "Poster: Few-Shot Inter-Domain Routing Threat Detection with Large-Scale Multi-Modal Pre-Training.",
            "venue": "CCS",
            "pages": "4970-4972",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/LiLCX0X24",
            "doi": "10.1145/3658644.3691402",
            "ee": "https://doi.org/10.1145/3658644.3691402",
            "url": "https://dblp.org/rec/conf/ccs/LiLCX0X24",
            "abstract": "Border Gateway Protocol (BGP) plays a pivotal role as the de facto inter-domain routing protocol on the Internet. However, BGP threats continually emerge and undermine the Internet reliability. Existing BGP threat detection methods based on machine learning require substantial labeled data and expert involvement, making them costly and labor-intensive. Moreover, they fail to learn rich information from massive unlabeled BGP data consistently generated on the Internet. In this paper, we propose FIRE that enables few-shot inter-domain routing threat detection with large-scale multi-modal pre-training. FIRE conducts domain-specific pre-training tasks to acquire rich BGP implicit knowledge from massive unlabeled BGP data for few-shot learning. Our experiments show that FIRE can be fine-tuned to precisely identify BGP threats with only a few labeled samples, e.g., a 93.2% precision in route leak detection with merely 8 events for fine-tuning.",
            "pdf_url": "",
            "keywords": [
                "BGP Threat Detection",
                "Inter-Domain Routing",
                "Few-Shot Learning",
                "Multi-Modal Pre-Training",
                "Route Leak Detection"
            ]
        },
        "url": "URL#256750",
        "sema_paperId": "09729adc843be510386db2b32c0a582b71996b42"
    },
    {
        "@score": "1",
        "@id": "256751",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "253/9727",
                        "text": "Zhuohang Li"
                    },
                    {
                        "@pid": "285/5314",
                        "text": "Andrew Lowy"
                    },
                    {
                        "@pid": "72/2590-9",
                        "text": "Jing Liu 0009"
                    },
                    {
                        "@pid": "98/3964",
                        "text": "Toshiaki Koike-Akino"
                    },
                    {
                        "@pid": "132/8074",
                        "text": "Kieran Parsons"
                    },
                    {
                        "@pid": "m/BradleyMalin",
                        "text": "Bradley A. Malin"
                    },
                    {
                        "@pid": "44/6292-1",
                        "text": "Ye Wang 0001"
                    }
                ]
            },
            "title": "Analyzing Inference Privacy Risks Through Gradients In Machine Learning.",
            "venue": "CCS",
            "pages": "3466-3480",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/LiLLKPM024",
            "doi": "10.1145/3658644.3690304",
            "ee": "https://doi.org/10.1145/3658644.3690304",
            "url": "https://dblp.org/rec/conf/ccs/LiLLKPM024",
            "abstract": "In distributed learning settings, models are iteratively updated with shared gradients computed from potentially sensitive user data. While previous work has studied various privacy risks of sharing gradients, our paper aims to provide a systematic approach to analyze private information leakage from gradients. We present a unified game-based framework that encompasses a broad range of attacks including attribute, property, distributional, and user disclosures. We investigate how different uncertainties of the adversary affect their inferential power via extensive experiments on five datasets across various data modalities. Our results demonstrate the inefficacy of solely relying on data aggregation to achieve privacy against inference attacks in distributed learning. We further evaluate five types of defenses, namely, gradient pruning, signed gradient descent, adversarial perturbations, variational information bottleneck, and differential privacy, under both static and adaptive adversary settings. We provide an information-theoretic view for analyzing the effectiveness of these defenses against inference from gradients. Finally, we introduce a method for auditing attribute inference privacy, improving the empirical estimation of worst-case privacy through crafting adversarial canary records.",
            "keywords": [
                "Inference Privacy",
                "Gradient Leakage",
                "Distributed Learning",
                "Privacy Defenses",
                "Attribute Inference"
            ]
        },
        "url": "URL#256751",
        "sema_paperId": "36f7b140391c41c18f08267bd869ad675bd30f68"
    },
    {
        "@score": "1",
        "@id": "256752",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "04/8388",
                        "text": "Xinfeng Li"
                    },
                    {
                        "@pid": "181/2853",
                        "text": "Kai Li"
                    },
                    {
                        "@pid": "275/7679",
                        "text": "Yifan Zheng"
                    },
                    {
                        "@pid": "46/1162-1",
                        "text": "Chen Yan 0001"
                    },
                    {
                        "@pid": "39/1697-1",
                        "text": "Xiaoyu Ji 0001"
                    },
                    {
                        "@pid": "10/3878-1",
                        "text": "Wenyuan Xu 0001"
                    }
                ]
            },
            "title": "SafeEar: Content Privacy-Preserving Audio Deepfake Detection.",
            "venue": "CCS",
            "pages": "3585-3599",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/LiLZYJX24",
            "doi": "10.1145/3658644.3670285",
            "ee": "https://doi.org/10.1145/3658644.3670285",
            "url": "https://dblp.org/rec/conf/ccs/LiLZYJX24",
            "abstract": "Text-to-Speech (TTS) and Voice Conversion (VC) models have exhibited remarkable performance in generating realistic and natural audio. However, their dark side, audio deepfake poses a significant threat to both society and individuals. Existing countermeasures largely focus on determining the genuineness of speech based on complete original audio recordings, which however often contain private content. This oversight may refrain deepfake detection from many applications, particularly in scenarios involving sensitive information like business secrets. In this paper, we propose SafeEar, a novel framework that aims to detect deepfake audios without relying on accessing the speech content within. Our key idea is to devise a neural audio codec into a novel decoupling model that well separates the semantic and acoustic information from audio samples, and only use the acoustic information (e.g., prosody and timbre) for deepfake detection. In this way, no semantic content will be exposed to the detector. To overcome the challenge of identifying diverse deepfake audio without semantic clues, we enhance our deepfake detector with real-world codec augmentation. Extensive experiments conducted on four benchmark datasets demonstrate SafeEar's effectiveness in detecting various deepfake techniques with an equal error rate (EER) down to 2.02%. Simultaneously, it shields five-language speech content from being deciphered by both machine and human auditory analysis, demonstrated by word error rates (WERs) all above 93.93% and our user study. Furthermore, our benchmark constructed for anti-deepfake and anti-content recovery evaluation helps provide a basis for future research in the realms of audio privacy preservation and deepfake detection.",
            "keywords": [
                "Audio Deepfake Detection",
                "Content Privacy Preservation",
                "Neural Audio Codec",
                "Speech Content Protection",
                "Deepfake Techniques"
            ]
        },
        "url": "URL#256752",
        "sema_paperId": "b510bd9ed8c36d8a8dd9991e6ae8de7812eb3a33"
    },
    {
        "@score": "1",
        "@id": "256753",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "11/444",
                        "text": "Wenhao Li"
                    },
                    {
                        "@pid": "14/1555",
                        "text": "Duohe Ma"
                    },
                    {
                        "@pid": "202/2279",
                        "text": "Zhaoxuan Li"
                    },
                    {
                        "@pid": "294/6531",
                        "text": "Huaifeng Bao"
                    },
                    {
                        "@pid": "42/1503",
                        "text": "Shuai Wang"
                    },
                    {
                        "@pid": "176/1189",
                        "text": "Huamin Jin"
                    },
                    {
                        "@pid": "12/5927",
                        "text": "Xiao-Yu Zhang"
                    }
                ]
            },
            "title": "Poster: Towards Real-Time Intrusion Detection with Explainable AI-Based Detector.",
            "venue": "CCS",
            "pages": "4934-4936",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/LiMLBWJZ24",
            "doi": "10.1145/3658644.3691410",
            "ee": "https://doi.org/10.1145/3658644.3691410",
            "url": "https://dblp.org/rec/conf/ccs/LiMLBWJZ24",
            "abstract": "Identifying malicious traffic is crucial for safeguarding internal networks from privacy breaches. Intrusion Detection Systems (IDS) traditionally rely on inefficient and outdated rule-sets, necessitating a shift towards AI-driven, learning-based algorithms for enhanced detection capabilities. Despite their promise, AI-integrated IDS face deployment challenges due to complex, opaque decision-making processes that can lead to latency and an increased risk of false positives. This paper presents the Explainable AI-based Intrusion Detection System (XAI-IDS), addressing the limitations of both rule-based and AI-driven IDS by integrating interpretable deep learning models. XAI-IDS employs tree regularization to transform complex models into efficient, transparent decision trees, facilitating real-time detection with improved accuracy and explainability. Experiments on two benchmark datasets demonstrate XAI-IDS's superior performance, offering a scalable solution to the challenge of identifying malicious traffic with reduced risk of false positives.",
            "pdf_url": "",
            "keywords": [
                "Intrusion Detection Systems",
                "Explainable AI",
                "Malicious Traffic Identification",
                "Real-Time Detection",
                "False Positives Reduction"
            ]
        },
        "url": "URL#256753",
        "sema_paperId": "716d8adff883a977c199fa922c635f2511e5ea79"
    },
    {
        "@score": "1",
        "@id": "256754",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "08/10177",
                        "text": "Ruiyang Li"
                    },
                    {
                        "@pid": "191/1203",
                        "text": "Yiteng Sun"
                    },
                    {
                        "@pid": "85/10076-2",
                        "text": "Chun Guo 0002"
                    },
                    {
                        "@pid": "38/2138",
                        "text": "Fran\u00e7ois-Xavier Standaert"
                    },
                    {
                        "@pid": "30/6437-3",
                        "text": "Weijia Wang 0003"
                    },
                    {
                        "@pid": "150/9413",
                        "text": "Xiao Wang 0012"
                    }
                ]
            },
            "title": "Leakage-Resilient Circuit Garbling.",
            "venue": "CCS",
            "pages": "780-794",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/LiS0S0024",
            "doi": "10.1145/3658644.3690204",
            "ee": "https://doi.org/10.1145/3658644.3690204",
            "url": "https://dblp.org/rec/conf/ccs/LiS0S0024",
            "abstract": "Due to the ubiquitous requirements and performance leap in the past decade, it has become feasible to execute garbling and secure computations in settings sensitive to side-channel attacks, including smartphones, IoTs and dedicated hardwares, and the possibilities have been demonstrated by recent works. To maintain security in the presence of a moderate amount of leaked information about internal secrets, we investigateleakage-resilient garbling.We augment the classical privacy, obliviousness and authenticity notions with leakages of the garbling function, and define their leakage-resilience analogues. We examine popular garbling schemes and unveil additional side-channel weaknesses due to wire label reuse and XOR leakages. We then incorporate the idea of label refreshing into the GLNP garbling scheme of Gueron et al. and propose a variant GLNPLR that provably satisfies our leakage-resilience definitions. Performance comparison indicates that GLNPLR is 60X (using AES-NI) or 5X (without AES-NI) faster than the HalfGates garbling with second order side-channel masking, for garbling AES circuit when the bandwidth is 2Gbps.",
            "pdf_url": "",
            "keywords": [
                "Leakage-Resilient Garbling",
                "Side-Channel Attacks",
                "Circuit Garbling",
                "Label Refreshing",
                "Wire Label Reuse"
            ]
        },
        "url": "URL#256754",
        "sema_paperId": "77220c12ded1bee9d8c9db58c679f27317eac399"
    },
    {
        "@score": "1",
        "@id": "256755",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "79/8042",
                        "text": "Wenqiang Li"
                    },
                    {
                        "@pid": "215/0123",
                        "text": "Haohuang Wen"
                    },
                    {
                        "@pid": "49/4102-1",
                        "text": "Zhiqiang Lin 0001"
                    }
                ]
            },
            "title": "BaseMirror: Automatic Reverse Engineering of Baseband Commands from Android&apos;s Radio Interface Layer.",
            "venue": "CCS",
            "pages": "2311-2325",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/LiWL24",
            "doi": "10.1145/3658644.3690254",
            "ee": "https://doi.org/10.1145/3658644.3690254",
            "url": "https://dblp.org/rec/conf/ccs/LiWL24",
            "abstract": "In modern mobile devices, baseband is an integral component running on top of cellular processors to handle crucial radio communications. However, recent research reveals significant vulnerabilities in these basebands, posing serious security risks like remote code execution. Yet, effectively scrutinizing basebands remains a daunting task, as they run closed-source and proprietary software on vendor-specific chipsets. Existing analysis methods are limited by their dependence on manual processes and heuristic approaches, reducing their scalability. This paper introduces a novel approach to unveil security issues in basebands from a unique perspective: to uncover vendor-specific baseband commands from theRadio Interface Layer (RIL),a hardware abstraction layer interfacing with basebands. To demonstrate this concept, we have designed and developed BaseMirror, a static binary analysis tool to automatically reverse engineer baseband commands from vendor-specific RIL binaries. It utilizes a bidirectional taint analysis algorithm to adeptly identify baseband commands from an enhanced control flow graph enriched with reconstructed virtual function calls. Our methodology has been applied to 28 vendor RIL libraries, encompassing a wide range of Samsung Exynos smartphone models on the market. Remarkably, BaseMirror has uncovered 873 unique baseband commands undisclosed to the public. Based on these results, we develop an automated attack discovery framework to successfully derive and validate 8 zero-day vulnerabilities that trigger denial of cellular service and arbitrary file access on a Samsung Galaxy A53 device. These findings have been reported and confirmed by Samsung and a bug bounty was awarded to us.",
            "pdf_url": "",
            "keywords": [
                "Baseband Security",
                "Radio Interface Layer",
                "Reverse Engineering",
                "Taint Analysis",
                "Zero-Day Vulnerabilities"
            ]
        },
        "url": "URL#256755"
    },
    {
        "@score": "1",
        "@id": "256756",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "04/8388",
                        "text": "Xinfeng Li"
                    },
                    {
                        "@pid": "06/7124",
                        "text": "Yuchen Yang"
                    },
                    {
                        "@pid": "243/3091",
                        "text": "Jiangyi Deng"
                    },
                    {
                        "@pid": "46/1162-1",
                        "text": "Chen Yan 0001"
                    },
                    {
                        "@pid": "50/10586",
                        "text": "Yanjiao Chen"
                    },
                    {
                        "@pid": "39/1697-1",
                        "text": "Xiaoyu Ji 0001"
                    },
                    {
                        "@pid": "10/3878-1",
                        "text": "Wenyuan Xu 0001"
                    }
                ]
            },
            "title": "SafeGen: Mitigating Sexually Explicit Content Generation in Text-to-Image Models.",
            "venue": "CCS",
            "pages": "4807-4821",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/LiYD0C0024",
            "doi": "10.1145/3658644.3670295",
            "ee": "https://doi.org/10.1145/3658644.3670295",
            "url": "https://dblp.org/rec/conf/ccs/LiYD0C0024",
            "abstract": "Text-to-image (T2I) models, such as Stable Diffusion, have exhibited remarkable performance in generating high-quality images from text descriptions in recent years. However, text-to-image models may be tricked into generating not-safe-for-work (NSFW) content, particularly in sexually explicit scenarios. Existing countermeasures mostly focus on filtering inappropriate inputs and outputs, or suppressing improper text embeddings, which can block sexually explicit content (e.g., naked) but may still be vulnerable to adversarial prompts -- inputs that appear innocent but are ill-intended. In this paper, we present SafeGen, a framework to mitigate sexual content generation by text-to-image models in a text-agnostic manner. The key idea is to eliminate explicit visual representations from the model regardless of the text input. In this way, the text-to-image model is resistant to adversarial prompts since such unsafe visual representations are obstructed from within. Extensive experiments conducted on four datasets and large-scale user studies demonstrate SafeGen's effectiveness in mitigating sexually explicit content generation while preserving the high-fidelity of benign images. SafeGen outperforms eight state-of-the-art baseline methods and achieves 99.4% sexual content removal performance. Furthermore, our constructed benchmark of adversarial prompts provides a basis for future development and evaluation of anti-NSFW-generation methods.",
            "keywords": [
                "Text-to-Image Models",
                "Sexually Explicit Content",
                "Content Moderation",
                "Adversarial Prompts",
                "SafeGen Framework"
            ]
        },
        "url": "URL#256756",
        "sema_paperId": "970111f19cbb20af52a8a1772e8d4b36570b5679"
    },
    {
        "@score": "1",
        "@id": "256757",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "61/500",
                        "text": "Yue Li"
                    },
                    {
                        "@pid": "274/5159",
                        "text": "Zhenxiong Yan"
                    },
                    {
                        "@pid": "196/7070",
                        "text": "Wenqiang Jin"
                    },
                    {
                        "@pid": "47/8535",
                        "text": "Zhenyu Ning"
                    },
                    {
                        "@pid": "141/1957",
                        "text": "Daibo Liu"
                    },
                    {
                        "@pid": "95/6861-1",
                        "text": "Zheng Qin 0001"
                    },
                    {
                        "@pid": "97/2274-21",
                        "text": "Yu Liu 0021"
                    },
                    {
                        "@pid": "282/6169",
                        "text": "Huadi Zhu"
                    },
                    {
                        "@pid": "l/MingLi6",
                        "text": "Ming Li 0006"
                    }
                ]
            },
            "title": "GPSBuster: Busting out Hidden GPS Trackers via MSoC Electromagnetic Radiations.",
            "venue": "CCS",
            "pages": "3302-3316",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/LiYJNL0LZ024",
            "doi": "10.1145/3658644.3690362",
            "ee": "https://doi.org/10.1145/3658644.3690362",
            "url": "https://dblp.org/rec/conf/ccs/LiYJNL0LZ024",
            "abstract": "The escalating threat of hidden GPS tracking devices poses significant risks to personal privacy and security. Featured by their miniaturization and misleading appearances, GPS devices can be easily disguised in their surroundings making their detection extremely challenging. In this paper, we propose a novel side-channel-driven detection system, GPSBuster , leveraging electromagnetic radiation (EMR) emitted by GPS trackers. Our feasibility studies and hardware analysis reveal that unique EMR patterns associated with the tracker\u2019s operation, stemming from the quartz oscillator, local oscillator, and mixer in the Mixed-Signal on Chip (MSoC) system. Never-theless, as a side-channel leakage, EMRs can be extremely weak and suffer from the ambient noise inference, rendering the detections impractical. To address these challenges, we develop the signal processing techniques with noise removals and a dual-dimensional folding mechanism to accumulate the spectrum energy and pro-trude the EMR patterns with high Signal-to-Noise Ratios (SNR). Our detection prototype, built with a portable HackRF One device, allows users to perform a scan-to-detect manner and achieves an overall",
            "keywords": [
                "GPS Tracker Detection",
                "Electromagnetic Radiation",
                "Signal Processing",
                "Noise Removal",
                "Mixed-Signal on Chip (MSoC)"
            ]
        },
        "url": "URL#256757",
        "sema_paperId": "a32bd62625af30c05da760b4bdf9187b5b228dc6"
    },
    {
        "@score": "1",
        "@id": "256758",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "57/2281-6",
                        "text": "Shuai Li 0006"
                    },
                    {
                        "@pid": "55/11040",
                        "text": "Zhemin Yang"
                    },
                    {
                        "@pid": "167/0416",
                        "text": "Yuhong Nan"
                    },
                    {
                        "@pid": "392/2993",
                        "text": "Shutian Yu"
                    },
                    {
                        "@pid": "357/9929",
                        "text": "Qirui Zhu"
                    },
                    {
                        "@pid": "02/1640-2",
                        "text": "Min Yang 0002"
                    }
                ]
            },
            "title": "Are We Getting Well-informed? An In-depth Study of Runtime Privacy Notice Practice in Mobile Apps.",
            "venue": "CCS",
            "pages": "1581-1595",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/LiYNYZ024",
            "doi": "10.1145/3658644.3670377",
            "ee": "https://doi.org/10.1145/3658644.3670377",
            "url": "https://dblp.org/rec/conf/ccs/LiYNYZ024",
            "abstract": "Under the General Data Protection Regulation (GDPR), mobile app developers are required to inform users of necessary information at the time when user data is collected (called users' \"Right-to-be-Informed\"). This is typically done by app developers via providing runtime privacy notices (RPNs for short). However, given the heterogeneous privacy data types and data access patterns in modern apps, it is not clear to what extent apps (app developers) effectively fulfill this compliance requirement in practice.",
            "pdf_url": "",
            "keywords": [
                "Mobile App Privacy",
                "Runtime Privacy Notices",
                "GDPR Compliance",
                "User Data Protection",
                "Right-to-be-Informed"
            ]
        },
        "url": "URL#256758",
        "sema_paperId": "3dc1b2d42c3093ac3330c98a4989e8dca8e5f869"
    },
    {
        "@score": "1",
        "@id": "256759",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "66/7710",
                        "text": "Ruijie Li"
                    },
                    {
                        "@pid": "06/8501",
                        "text": "Chenyang Zhang"
                    },
                    {
                        "@pid": "251/3599",
                        "text": "Huajun Chai"
                    },
                    {
                        "@pid": "18/7667",
                        "text": "Lingyun Ying"
                    },
                    {
                        "@pid": "36/5143",
                        "text": "Haixin Duan"
                    },
                    {
                        "@pid": "35/5170-3",
                        "text": "Jun Tao 0003"
                    }
                ]
            },
            "title": "PowerPeeler: A Precise and General Dynamic Deobfuscation Method for PowerShell Scripts.",
            "venue": "CCS",
            "pages": "4539-4553",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/LiZCYDT24",
            "doi": "10.1145/3658644.3670310",
            "ee": "https://doi.org/10.1145/3658644.3670310",
            "url": "https://dblp.org/rec/conf/ccs/LiZCYDT24",
            "abstract": "PowerShell is a powerful and versatile task automation tool. Unfortunately, it is also widely abused by cyber attackers. To bypass malware detection and hinder threat analysis, attackers often employ diverse techniques to obfuscate malicious PowerShell scripts. Existing deobfuscation tools suffer from the limitation of static analysis, which fails to simulate the real deobfuscation process accurately. In this paper, we propose PowerPeeler. To the best of our knowledge, it is the first dynamic PowerShell script deobfuscation approach at the instruction level. It utilizes expression-related Abstract Syntax Tree (AST) nodes to identify potential obfuscated script pieces. Then, PowerPeeler correlates the AST nodes with their corresponding instructions and monitors the script's entire execution process. Subsequently, PowerPeeler dynamically tracks the execution of these instructions and records their execution results. Finally, PowerPeeler stringifies these results to replace the corresponding obfuscated script pieces and reconstruct the deobfuscated script. To evaluate the effectiveness of PowerPeeler, we collect 1,736,669 real-world malicious PowerShell samples with diversity obfuscation methods. We compare PowerPeeler with five state-of-the-art deobfuscation tools and GPT-4. The evaluation results demonstrate that PowerPeeler can effectively handle all well-known obfuscation methods. Additionally, the deobfuscation correctness rate of PowerPeeler reaches 95%, significantly surpassing that of other tools. PowerPeeler not only recovers the highest amount of sensitive data but also maintains a semantic consistency over 97%, which is also the best. Moreover, PowerPeeler effectively obtains the largest quantity of valid deobfuscated results within a limited time frame. Furthermore, PowerPeeler is extendable and can be used as a helpful tool for other cyber security solutions.",
            "keywords": [
                "PowerShell Deobfuscation",
                "Dynamic Analysis",
                "Malware Detection",
                "Obfuscated Scripts",
                "Abstract Syntax Tree (AST)"
            ]
        },
        "url": "URL#256759",
        "sema_paperId": "08962656d85e751311206f05cb9964a49e6519ba"
    },
    {
        "@score": "1",
        "@id": "256760",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "310/5899",
                        "text": "Shuaishuai Li"
                    },
                    {
                        "@pid": "18/2908",
                        "text": "Cong Zhang"
                    },
                    {
                        "@pid": "44/6488",
                        "text": "Dongdai Lin"
                    }
                ]
            },
            "title": "Secure Multiparty Computation with Lazy Sharing.",
            "venue": "CCS",
            "pages": "795-809",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/LiZL24",
            "doi": "10.1145/3658644.3690207",
            "ee": "https://doi.org/10.1145/3658644.3690207",
            "url": "https://dblp.org/rec/conf/ccs/LiZL24",
            "abstract": "Secure multiparty computation (MPC) protocols enablenparties, each with private inputs, to compute a given function without leaking information beyond the outputs. One of the main approaches to designing efficient MPC protocols is to use secret sharing. In general, secret sharing based MPC contains three phases: input sharing, circuit evaluation, and output recovery. If the adversary corrupts at mosttparties, the protocol typically uses (t,n) threshold secret sharing to share the inputs. In this work, we consider a weaker variant of threshold secret sharing called lazy threshold secret sharing (or simply lazy sharing) and show that: Lazy sharing can serve as a viable alternative to threshold secret sharing in MPC without compromising security. Lazy sharing could be generated more efficiently than threshold secret sharing.",
            "pdf_url": "",
            "keywords": [
                "Secure Multiparty Computation",
                "Lazy Threshold Secret Sharing",
                "Secret Sharing",
                "Input Sharing",
                "Adversarial Corruption"
            ]
        },
        "url": "URL#256760"
    },
    {
        "@score": "1",
        "@id": "256761",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "198/1518",
                        "text": "Yuting Liang"
                    },
                    {
                        "@pid": "43/1219-1",
                        "text": "Ke Yi 0001"
                    }
                ]
            },
            "title": "Smooth Sensitivity for Geo-Privacy.",
            "venue": "CCS",
            "pages": "333-347",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Liang024",
            "doi": "10.1145/3658644.3690365",
            "ee": "https://doi.org/10.1145/3658644.3690365",
            "url": "https://dblp.org/rec/conf/ccs/Liang024",
            "abstract": "Suppose each user $i$ holds a private value $x_i$ in some metric space $(U, \\mathrm{dist})$, and an untrusted data analyst wishes to compute $\\sum_i f(x_i)$ for some function $f : U \\rightarrow \\mathbb{R}$ by asking each user to send in a privatized $f(x_i)$. This is a fundamental problem in privacy-preserving population analytics, and the local model of differential privacy (LDP) is the predominant model under which the problem has been studied. However, LDP requires any two different $x_i, x'_i$ to be $\\varepsilon$-distinguishable, which can be overly strong for geometric/numerical data. On the other hand, Geo-Privacy (GP) stipulates that the level of distinguishability be proportional to $\\mathrm{dist}(x_i, x_i')$, providing an attractive alternative notion of personal data privacy in a metric space. However, existing GP mechanisms for this problem, which add a uniform noise to either $x_i$ or $f(x_i)$, are not satisfactory. In this paper, we generalize the smooth sensitivity framework from Differential Privacy to Geo-Privacy, which allows us to add noise tailored to the hardness of the given instance. We provide definitions, mechanisms, and a generic procedure for computing the smooth sensitivity under GP equipped with a general metric. Then we present three applications: one-way and two-way threshold functions, and Gaussian kernel density estimation, to demonstrate the applicability and utility of our smooth sensitivity framework.",
            "keywords": [
                "Geo-Privacy",
                "Local Differential Privacy",
                "Smooth Sensitivity",
                "Metric Space",
                "Population Analytics"
            ]
        },
        "url": "URL#256761",
        "sema_paperId": "8acd87fb2e98d8c117fa5eefa33f8836db39f332"
    },
    {
        "@score": "1",
        "@id": "256762",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "392/3105",
                        "text": "Yuejia Liang"
                    },
                    {
                        "@pid": "20/1036-5",
                        "text": "Jianjun Chen 0005"
                    },
                    {
                        "@pid": "234/0112",
                        "text": "Run Guo"
                    },
                    {
                        "@pid": "245/2568",
                        "text": "Kaiwen Shen"
                    },
                    {
                        "@pid": "64/3246",
                        "text": "Hui Jiang"
                    },
                    {
                        "@pid": "392/3322",
                        "text": "Man Hou"
                    },
                    {
                        "@pid": "55/2008",
                        "text": "Yue Yu"
                    },
                    {
                        "@pid": "36/5143",
                        "text": "Haixin Duan"
                    }
                ]
            },
            "title": "Internet&apos;s Invisible Enemy: Detecting and Measuring Web Cache Poisoning in the Wild.",
            "venue": "CCS",
            "pages": "452-466",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Liang0GSJHYD24",
            "doi": "10.1145/3658644.3690361",
            "ee": "https://doi.org/10.1145/3658644.3690361",
            "url": "https://dblp.org/rec/conf/ccs/Liang0GSJHYD24",
            "abstract": "Web cache poisoning (WCP) has posed significant threats to Internet security by causing the cache server to deliver malicious responses to innocent users. This results in widespread denial of access to website resources and potential injection of harmful payloads. However, prior works on WCP vulnerability have been fragmented and conducted in a case-by-case form, lacking a systematic analysis of the threat landscape. In this paper, we fill this research gap by conducting a systematic evaluation of WCP vulnerabilities at scale. We propose HCache , a novel testing methodology to facilitates the widespread identification of WCP vulnerabilities. We evaluated our methodology against Tranco Top 1000 domains and their sub-domains, and found that over 1,000 websites across 172 domains, representing 17% of the evaluated domains, are vulnerable to WCP. In particular, we have identified 7 new attack vectors stemming from previously unexplored caching headers. We have responsibly disclosed the vulnerabilities to the affected websites and received ac-knowledgements and bug bounties from world-famous companies, such as Alibaba, Adobe, Huawei, and Microsoft.",
            "keywords": [
                "Web Cache Poisoning",
                "Cache Vulnerabilities",
                "HCache Methodology",
                "Malicious Responses",
                "Attack Vectors"
            ]
        },
        "url": "URL#256762",
        "sema_paperId": "c8e428d78fe8f386c71f5d95eb87ef53b3a56d35"
    },
    {
        "@score": "1",
        "@id": "256763",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "271/4608",
                        "text": "Song Liao"
                    },
                    {
                        "@pid": "49/225-5",
                        "text": "Long Cheng 0005"
                    },
                    {
                        "@pid": "53/1565",
                        "text": "Xiapu Luo"
                    },
                    {
                        "@pid": "29/7459",
                        "text": "Zheng Song 0001"
                    },
                    {
                        "@pid": "117/7062",
                        "text": "Haipeng Cai"
                    },
                    {
                        "@pid": "y/DanfengYao",
                        "text": "Danfeng (Daphne) Yao"
                    },
                    {
                        "@pid": "02/2870",
                        "text": "Hongxin Hu"
                    }
                ]
            },
            "title": "A First Look at Security and Privacy Risks in the RapidAPI Ecosystem.",
            "venue": "CCS",
            "pages": "1626-1640",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Liao0LSCYH24",
            "doi": "10.1145/3658644.3690294",
            "ee": "https://doi.org/10.1145/3658644.3690294",
            "url": "https://dblp.org/rec/conf/ccs/Liao0LSCYH24",
            "abstract": "With the emergence of the open API ecosystem, third-party developers can publish their APIs on the API marketplace, significantly facilitating the development of cutting-edge features and services. The RapidAPI platform is currently the largest API marketplace and it provides over 40,000 APIs, which have been used by more than 4 million developers. However, such open API also raises security and privacy concerns associated with APIs hosted on the platform. In this work, we perform the first large-scale analysis of 32,089 APIs on the RapidAPI platform. By searching in the GitHub code and Android apps, we find that 3,533 RapidAPI keys, which are important and used in API request authorization, have been leaked in the wild. These keys can be exploited to launch various attacks, such as Resource Exhaustion Running, Theft of Service, Data Manipulation, and User Data Breach attacks. We also explore risks in API metadata that can be abused by adversaries. Due to the lack of a strict certification system, adversaries can manipulate the API metadata to perform typosquatting attacks on API URLs, impersonate other developers or renowned companies, and publish spamming APIs on the platform. Lastly, we analyze the privacy non-compliance of APIs and applications,e.g., Android apps, that call these APIs with data collection. We find that 1,709 APIs collect sensitive data and 94% of them dont provide a complete privacy policy. For the Android apps that call these APIs, 50% of them in our study have privacy non-compliance issues.",
            "pdf_url": "",
            "keywords": [
                "API Security",
                "RapidAPI",
                "API Key Leakage",
                "Privacy Compliance",
                "Typosquatting Attacks"
            ]
        },
        "url": "URL#256763",
        "sema_paperId": "85973a1ce1915ca102a2750723cdc14d8f4c9f2e"
    },
    {
        "@score": "1",
        "@id": "256764",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "351/0740",
                        "text": "Johannes Liebenow"
                    },
                    {
                        "@pid": "351/0893",
                        "text": "Yara Sch\u00fctt"
                    },
                    {
                        "@pid": "185/3615",
                        "text": "Tanya Braun"
                    },
                    {
                        "@pid": "220/9776",
                        "text": "Marcel Gehrke"
                    },
                    {
                        "@pid": "217/6974",
                        "text": "Florian Thaeter"
                    },
                    {
                        "@pid": "77/8938",
                        "text": "Esfandiar Mohammadi"
                    }
                ]
            },
            "title": "$DPM: $ Clustering Sensitive Data through Separation.",
            "venue": "CCS",
            "pages": "273-287",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/LiebenowSBGTM24",
            "doi": "10.1145/3658644.3690271",
            "ee": "https://doi.org/10.1145/3658644.3690271",
            "url": "https://dblp.org/rec/conf/ccs/LiebenowSBGTM24",
            "abstract": "Clustering is an important tool for data exploration where the goal is to subdivide a data set into disjoint clusters that fit well into the underlying data structure. When dealing with sensitive data, privacy-preserving algorithms aim to approximate the non-private baseline while minimising the leakage of sensitive information. State-of-the-art privacy-preserving clustering algorithms tend to output clusters that are good in terms of the standard metrics, inertia, silhouette score, and clustering accuracy, however, the clustering result strongly deviates from the non-private KMeans baseline.",
            "pdf_url": "",
            "keywords": [
                "Privacy-Preserving Clustering",
                "Sensitive Data",
                "Data Leakage",
                "Clustering Accuracy",
                "KMeans Baseline"
            ]
        },
        "url": "URL#256764",
        "sema_paperId": "4027c04c7367611db87cd95d88d3ca9da6318fab"
    },
    {
        "@score": "1",
        "@id": "256765",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "381/1590",
                        "text": "Hajeong Lim"
                    },
                    {
                        "@pid": "48/11202",
                        "text": "Jaeyoon Kim"
                    },
                    {
                        "@pid": "119/7678-1",
                        "text": "Hojoon Lee 0001"
                    }
                ]
            },
            "title": "uMMU: Securing Data Confidentiality with Unobservable Memory Subsystem.",
            "venue": "CCS",
            "pages": "2993-3007",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/LimK024",
            "doi": "10.1145/3658644.3690340",
            "ee": "https://doi.org/10.1145/3658644.3690340",
            "url": "https://dblp.org/rec/conf/ccs/LimK024",
            "abstract": "Ensuring data confidentiality in a computing system's memory hierarchy proved to be a formidable challenge with the large attack surface. Diverse and powerful attacks threaten data confidentiality. Memory safety is notoriously hard to achieve with unsafe languages, thereby empowering adversaries with unauthorized memory accesses, as represented by the HeartBleed incident. More recently, microarchitectural side channel attacks reign as a prevalent threat against data confidentiality that affects program execution including the safeguarded ones inside TEEs.",
            "pdf_url": "",
            "keywords": [
                "Data Confidentiality",
                "Memory Hierarchy",
                "Microarchitectural Attacks",
                "Unauthorized Memory Access",
                "Unobservable Memory Subsystem"
            ]
        },
        "url": "URL#256765",
        "sema_paperId": "c2f0aa8eb1c23e78fe81031a7eea36db174c2ca0"
    },
    {
        "@score": "1",
        "@id": "256766",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "272/7059",
                        "text": "Zijin Lin"
                    },
                    {
                        "@pid": "48/76-18",
                        "text": "Yue Zhao 0018"
                    },
                    {
                        "@pid": "c/KaiChen12",
                        "text": "Kai Chen 0012"
                    },
                    {
                        "@pid": "01/10388",
                        "text": "Jinwen He"
                    }
                ]
            },
            "title": "I Don&apos;t Know You, But I Can Catch You: Real-Time Defense against Diverse Adversarial Patches for Object Detectors.",
            "venue": "CCS",
            "pages": "3823-3837",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Lin0CH24",
            "doi": "10.1145/3658644.3670317",
            "ee": "https://doi.org/10.1145/3658644.3670317",
            "url": "https://dblp.org/rec/conf/ccs/Lin0CH24",
            "abstract": "Deep neural networks (DNNs) have revolutionized the field of computer vision like object detection with their unparalleled performance. However, existing research has shown that DNNs are vulnerable to adversarial attacks. In the physical world, an adversary could exploit adversarial patches to implement a Hiding Attack (HA) which patches the target object to make it disappear from the detector, and an Appearing Attack (AA) which fools the detector into misclassifying the patch as a specific object. Recently, many defense methods for detectors have been proposed to mitigate the potential threats of adversarial patches. However, such methods still have limitations in generalization, robustness and efficiency. Most defenses are only effective against the HA, leaving the detector vulnerable to the AA. In this paper, we propose \\textit{NutNet}, an innovative model for detecting adversarial patches, with high generalization, robustness and efficiency. With experiments for six detectors including YOLOv2-v4, SSD, Faster RCNN and DETR on both digital and physical domains, the results show that our proposed method can effectively defend against both the HA and AA, with only 0.4\\% sacrifice of the clean performance. We compare NutNet with four baseline defense methods for detectors, and our method exhibits an average defense performance that is over 2.4 times and 4.7 times higher than existing approaches for HA and AA, respectively. In addition, NutNet only increases the inference time by 8\\%, which can meet the real-time requirements of the detection systems. Demos of NutNet are available at: \\url{https://sites.google.com/view/nutnet}.",
            "keywords": [
                "Adversarial Patches",
                "Object Detection",
                "Hiding Attack",
                "Appearing Attack",
                "Real-Time Defense"
            ]
        },
        "url": "URL#256766",
        "sema_paperId": "feabc8ea9e5d0bf2bca8c586c4c287073db24666"
    },
    {
        "@score": "1",
        "@id": "256767",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "330/5132",
                        "text": "Guopeng Lin"
                    },
                    {
                        "@pid": "42/179",
                        "text": "Weili Han"
                    },
                    {
                        "@pid": "280/3066",
                        "text": "Wenqiang Ruan"
                    },
                    {
                        "@pid": "379/8187",
                        "text": "Ruisheng Zhou"
                    },
                    {
                        "@pid": "280/3038",
                        "text": "Lushan Song"
                    },
                    {
                        "@pid": "269/4522",
                        "text": "Bingshuai Li"
                    },
                    {
                        "@pid": "121/8085-1",
                        "text": "Yunfeng Shao 0001"
                    }
                ]
            },
            "title": "Ents: An Efficient Three-party Training Framework for Decision Trees by Communication Optimization.",
            "venue": "CCS",
            "pages": "4376-4390",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/LinHRZSL024",
            "doi": "10.1145/3658644.3670274",
            "ee": "https://doi.org/10.1145/3658644.3670274",
            "url": "https://dblp.org/rec/conf/ccs/LinHRZSL024",
            "abstract": "Multi-party training frameworks for decision trees based on secure multi-party computation enable multiple parties to train high-performance models on distributed private data with privacy preservation. The training process essentially involves frequent dataset splitting according to the splitting criterion (e.g. Gini impurity). However, existing multi-party training frameworks for decision trees demonstrate communication inefficiency due to the following issues: (1) They suffer from huge communication overhead in securely splitting a dataset with continuous attributes. (2) They suffer from huge communication overhead due to performing almost all the computations on a large ring to accommodate the secure computations for the splitting criterion. In this paper, we are motivated to present an efficient three-party training framework, namely Ents, for decision trees by communication optimization. For the first issue, we present a series of training protocols based on the secure radix sort protocols to efficiently and securely split a dataset with continuous attributes. For the second issue, we propose an efficient share conversion protocol to convert shares between a small ring and a large ring to reduce the communication overhead incurred by performing almost all the computations on a large ring. Experimental results from eight widely used datasets show that Ents outperforms state-of-the-art frameworks by $5.5\\times \\sim 9.3\\times$ in communication sizes and $3.9\\times \\sim 5.3\\times$ in communication rounds. In terms of training time, Ents yields an improvement of $3.5\\times \\sim 6.7\\times$. To demonstrate its practicality, Ents requires less than three hours to securely train a decision tree on a widely used real-world dataset (Skin Segmentation) with more than 245,000 samples in the WAN setting.",
            "keywords": [
                "Decision Trees",
                "Secure Multi-party Computation",
                "Communication Optimization",
                "Dataset Splitting",
                "Three-party Training Framework"
            ]
        },
        "url": "URL#256767",
        "sema_paperId": "f1356caf906f33c4983dfe9426e1fae7d515e9ec"
    },
    {
        "@score": "1",
        "@id": "256768",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "49/4102-1",
                        "text": "Zhiqiang Lin 0001"
                    },
                    {
                        "@pid": "34/8412",
                        "text": "Luyi Xing"
                    }
                ]
            },
            "title": "SaTS &apos;24: The 2nd ACM Workshop on Secure and Trustworthy Superapps.",
            "venue": "CCS",
            "pages": "4886-4887",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/LinX24",
            "doi": "10.1145/3658644.3691542",
            "ee": "https://doi.org/10.1145/3658644.3691542",
            "url": "https://dblp.org/rec/conf/ccs/LinX24",
            "abstract": "Mobile super apps are revolutionizing mobile computing by offering diverse services through integrated \"miniapps'', creating comprehensive ecosystems akin to app stores like Google Play and Apple's App Store. While these platforms, such as WeChat, Alipay, and TikTok, enhance user convenience and functionality, they also raise significant security and privacy concerns due to the vast amounts of user data they handle. In response, the Workshop on Secure and Trustworthy Superapps (SaTS 2024) aims to address these critical issues by fostering collaboration among researchers and practitioners to explore solutions that protect users and enhance security within the super app landscape.",
            "pdf_url": "",
            "keywords": [
                "Mobile Superapps",
                "User Data Privacy",
                "Security Concerns",
                "Integrated Miniapps",
                "Trustworthy Ecosystems"
            ]
        },
        "url": "URL#256768",
        "sema_paperId": "902d71b117640f3d513d7ca4e2683d61927ef26a"
    },
    {
        "@score": "1",
        "@id": "256769",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "287/9961",
                        "text": "Junxu Liu"
                    },
                    {
                        "@pid": "05/4625-1",
                        "text": "Jian Lou 0001"
                    },
                    {
                        "@pid": "39/3530-1",
                        "text": "Li Xiong 0001"
                    },
                    {
                        "@pid": "89/9935",
                        "text": "Jinfei Liu"
                    },
                    {
                        "@pid": "m/XiaofengMeng-1",
                        "text": "Xiaofeng Meng 0001"
                    }
                ]
            },
            "title": "Cross-silo Federated Learning with Record-level Personalized Differential Privacy.",
            "venue": "CCS",
            "pages": "303-317",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Liu00L024",
            "doi": "10.1145/3658644.3670351",
            "ee": "https://doi.org/10.1145/3658644.3670351",
            "url": "https://dblp.org/rec/conf/ccs/Liu00L024",
            "abstract": "Federated learning (FL) enhanced by differential privacy has emerged as a popular approach to better safeguard the privacy of client-side data by protecting clients' contributions during the training process. Existing solutions typically assume a uniform privacy budget for all records and provide one-size-fits-all solutions that may not be adequate to meet each record's privacy requirement. In this paper, we explore the uncharted territory of cross-silo FL with record-level personalized differential privacy. We devise a novel framework named \\textit{rPDP-FL}, employing a two-stage hybrid sampling scheme with both uniform client-level sampling and non-uniform record-level sampling to accommodate varying privacy requirements. A critical and non-trivial problem is how to determine the ideal per-record sampling probability $q$ given the personalized privacy budget $\\varepsilon$. We introduce a versatile solution named \\textit{Simulation-CurveFitting}, allowing us to uncover a significant insight into the nonlinear correlation between $q$ and $\\varepsilon$ and derive an elegant mathematical model to tackle the problem. Our evaluation demonstrates that our solution can provide significant performance gains over the baselines that do not consider personalized privacy preservation.",
            "keywords": [
                "Federated Learning",
                "Differential Privacy",
                "Personalized Privacy",
                "Cross-Silo Learning",
                "Sampling Scheme"
            ]
        },
        "url": "URL#256769",
        "sema_paperId": "58ef4c48b6f45ec3c02df357cef22da4f50b4aee"
    },
    {
        "@score": "1",
        "@id": "256770",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "284/4048",
                        "text": "Zeyan Liu"
                    },
                    {
                        "@pid": "134/4025-1",
                        "text": "Zijun Yao 0001"
                    },
                    {
                        "@pid": "66/6000",
                        "text": "Fengjun Li"
                    },
                    {
                        "@pid": "71/2890",
                        "text": "Bo Luo"
                    }
                ]
            },
            "title": "On the Detectability of ChatGPT Content: Benchmarking, Methodology, and Evaluation through the Lens of Academic Writing.",
            "venue": "CCS",
            "pages": "2236-2250",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Liu0LL24",
            "doi": "10.1145/3658644.3670392",
            "ee": "https://doi.org/10.1145/3658644.3670392",
            "url": "https://dblp.org/rec/conf/ccs/Liu0LL24",
            "abstract": "With ChatGPT under the spotlight, utilizing large language models (LLMs) to assist academic writing has drawn a significant amount of debate in the community. In this paper, we aim to present a comprehensive study of the detectability of ChatGPT-generated content within the academic literature, particularly focusing on the abstracts of scientific papers, to offer holistic support for the future development of LLM applications and policies in academia. Specifically, we first present GPABench2, a benchmarking dataset of over 2.8 million comparative samples of human-written, GPT-written, GPT-completed, and GPT-polished abstracts of scientific writing in computer science, physics, and humanities and social sciences. Second, we explore the methodology for detecting ChatGPT content. We start by examining the unsatisfactory performance of existing ChatGPT detecting tools and the challenges faced by human evaluators (including more than 240 researchers or students). We then test the hand-crafted linguistic features models as a baseline and develop a deep neural framework named CheckGPT to better capture the subtle and deep semantic and linguistic patterns in ChatGPT written literature. Last, we conduct comprehensive experiments to validate the proposed CheckGPT framework in each benchmarking task over different disciplines. To evaluate the detectability of ChatGPT content, we conduct extensive experiments on the transferability, prompt engineering, and robustness of CheckGPT.",
            "keywords": [
                "ChatGPT Detection",
                "Academic Writing",
                "Benchmarking Dataset",
                "Linguistic Features",
                "Deep Neural Framework"
            ]
        },
        "url": "URL#256770",
        "sema_paperId": "1e9dc49aa149b2082b34107483fb92499c58e385"
    },
    {
        "@score": "1",
        "@id": "256771",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "213/0968",
                        "text": "Kaizheng Liu"
                    },
                    {
                        "@pid": "98/2604-1",
                        "text": "Ming Yang 0001"
                    },
                    {
                        "@pid": "79/7563",
                        "text": "Zhen Ling"
                    },
                    {
                        "@pid": "47/722-25",
                        "text": "Yue Zhang 0025"
                    },
                    {
                        "@pid": "284/4365",
                        "text": "Chongqing Lei"
                    },
                    {
                        "@pid": "l/JunzhouLuo",
                        "text": "Junzhou Luo"
                    },
                    {
                        "@pid": "49/2189",
                        "text": "Xinwen Fu"
                    }
                ]
            },
            "title": "RIoTFuzzer: Companion App Assisted Remote Fuzzing for Detecting Vulnerabilities in IoT Devices.",
            "venue": "CCS",
            "pages": "2341-2354",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Liu0LZLLF24",
            "doi": "10.1145/3658644.3670342",
            "ee": "https://doi.org/10.1145/3658644.3670342",
            "url": "https://dblp.org/rec/conf/ccs/Liu0LZLLF24",
            "abstract": "Due to the diversity of architectures and peripherals of Internet of Things (IoT) systems, blackbox fuzzing stands out as a prime option for discovering vulnerabilities of IoT devices. Existing black-box fuzzing tools often rely on companion apps to generate valid fuzzing packets. However, existing methods encounter the challenges of bypassing the cloud server side validation when it comes to fuzz devices that rely on cloud-based communication. Moreover, they tend to concentrate their efforts on Java components within Android companion apps, limiting their effectiveness in assessing non-Java components such as JavaScript-based mini-apps. In this paper, we introduce a novel blackbox fuzzing method, named RIoT-Fuzzer, designed to remotely uncover vulnerabilities of IoT devices with the assistance of companion apps, particularly those powered by All-in-one Apps with the JavaScript-based mini-apps feature enabled. Our approach utilizes document-based control command extraction, hybrid analysis for mutation point identification and side-channel-guided fuzzing to effectively address the challenges of fuzzing IoT devices remotely. We apply RIoTFuzzer to 27 IoT devices on prominent platforms and discovered 11 vulnerabilities. All of them have been acknowledged by the corresponding vendors. 8 have been confirmed by the vendors and have been assigned 4 CVE IDs. Our experiment results also demonstrate that side-channel-guided fuzzing can significantly enhance the efficiency of fuzzing packets sent to IoT devices, with an average increase of 76.62% and a maximum increase of 362.62%.",
            "keywords": [
                "IoT Device Security",
                "Black-box Fuzzing",
                "Companion Apps",
                "Cloud-based Communication",
                "JavaScript Mini-apps"
            ]
        },
        "url": "URL#256771",
        "sema_paperId": "f006e5ed73339c98eb6d5b27ca270f23c59f314e"
    },
    {
        "@score": "1",
        "@id": "256772",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "36/5558",
                        "text": "Tong Liu"
                    },
                    {
                        "@pid": "272/7174",
                        "text": "Zizhuang Deng"
                    },
                    {
                        "@pid": "134/8681",
                        "text": "Guozhu Meng"
                    },
                    {
                        "@pid": "204/3729",
                        "text": "Yuekang Li"
                    },
                    {
                        "@pid": "c/KaiChen12",
                        "text": "Kai Chen 0012"
                    }
                ]
            },
            "title": "Demystifying RCE Vulnerabilities in LLM-Integrated Apps.",
            "venue": "CCS",
            "pages": "1716-1730",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/LiuDML024",
            "doi": "10.1145/3658644.3690338",
            "ee": "https://doi.org/10.1145/3658644.3690338",
            "url": "https://dblp.org/rec/conf/ccs/LiuDML024",
            "abstract": "LLMs show promise in transforming software development, with a growing interest in integrating them into more intelligent apps. Frameworks like LangChain aid LLM-integrated app development, offering code execution utility/APIs for custom actions. However, these capabilities theoretically introduce Remote Code Execution (RCE) vulnerabilities, enabling remote code execution through prompt injections. No prior research systematically investigates these frameworks' RCE vulnerabilities or their impact on applications and exploitation consequences. Therefore, there is a huge research gap in this field. In this study, we propose LLMSmith to detect, validate and exploit the RCE vulnerabilities in LLM-integrated frameworks and apps. To achieve this goal, we develop two novel techniques, including 1) a lightweight static analysis to examine LLM integration mechanisms, and construct call chains to identify RCE vulnerabilities in frameworks; 2) a systematical prompt-based exploitation method to verify and exploit the found vulnerabilities in LLM-integrated apps. This technique involves various strategies to control LLM outputs, trigger RCE vulnerabilities and launch subsequent attacks. Our research has uncovered a total of 20 vulnerabilities in 11 LLM-integrated frameworks, comprising 19 RCE vulnerabilities and 1 arbitrary file read/write vulnerability. Of these, 17 have been confirmed by the framework developers, with 11 vulnerabilities being assigned CVE IDs. For the 51 apps potentially affected by RCE, we successfully executed attacks on 17 apps, 16 of which are vulnerable to RCE and 1 to SQL injection. Furthermore, we conduct a comprehensive analysis of these vulnerabilities and construct practical attacks to demonstrate the hazards in reality. Last, we propose several mitigation measures for both framework and app developers to counteract such attacks.",
            "keywords": [
                "LLM Integration",
                "Remote Code Execution",
                "Vulnerability Detection",
                "Prompt Injection",
                "Exploitation Techniques"
            ]
        },
        "url": "URL#256772",
        "sema_paperId": "9be0dea0d6b892a2162490fb02712efaf10c0c87"
    },
    {
        "@score": "1",
        "@id": "256773",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "93/2654",
                        "text": "Zhaoxiang Liu"
                    },
                    {
                        "@pid": "26/848",
                        "text": "Ning Luo"
                    },
                    {
                        "@pid": "281/0124",
                        "text": "Samuel Judson"
                    },
                    {
                        "@pid": "68/11211",
                        "text": "Raj Gautam Dutta"
                    },
                    {
                        "@pid": "13/10726",
                        "text": "Xiaolong Guo"
                    },
                    {
                        "@pid": "115/9332",
                        "text": "Mark Santolucito"
                    }
                ]
            },
            "title": "Poster: BlindMarket: A Trustworthy Chip Designs Marketplace for IP Vendors and Users.",
            "venue": "CCS",
            "pages": "5048-5050",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/LiuLJDGS24",
            "doi": "10.1145/3658644.3691378",
            "ee": "https://doi.org/10.1145/3658644.3691378",
            "url": "https://dblp.org/rec/conf/ccs/LiuLJDGS24",
            "abstract": "Due to the globalization of the semiconductor supply chain, chip fabrication now involves multiple parties, including intellectual property (IP) vendors and Electronic Design Automation (EDA) tool vendors. Involving multiple entities and valuable IP naturally raises security and privacy concerns. Various frameworks and tools, such as the IEEE 1735 standard for IP protection, have been developed to mitigate the risk of theft. However, existing solutions fail to address all the threats envisioned by the zero-trust model. We propose a novel zero-trust formal verification framework that requires only two essential parties: IP users and IP vendors. This framework leverages secure multiparty computation to ensure the security and privacy of the hardware verification process. Our proposed solution allows IP users and IP vendors to independently convert the hardware design and assertions into conjunctive normal form (CNF), and then apply privacy-preserving SAT solving to verify the conformance of the design to the specification. This paper introduces a domain-specific secure decision procedure, hw-ppSAT, designed to overcome the scalability challenges of using SAT solving in hardware design verification. Our approach also leverages property-based hardware optimizations and domain-specific heuristics to enhance the verification process. We showcase the framework's effectiveness through its application to several open-source benchmarks.",
            "pdf_url": "",
            "keywords": [
                "Chip Design Marketplace",
                "Intellectual Property Protection",
                "Zero-Trust Model",
                "Secure Multiparty Computation",
                "Hardware Verification"
            ]
        },
        "url": "URL#256773",
        "sema_paperId": "340f72555bf396cb7dd4a2d22df53e9f4733f94e"
    },
    {
        "@score": "1",
        "@id": "256774",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "21/5921",
                        "text": "Jianzhong Liu"
                    },
                    {
                        "@pid": "276/1779",
                        "text": "Yuheng Shen"
                    },
                    {
                        "@pid": "330/8070",
                        "text": "Yiru Xu"
                    },
                    {
                        "@pid": "21/4633-1",
                        "text": "Yu Jiang 0001"
                    }
                ]
            },
            "title": "Leveraging Binary Coverage for Effective Generation Guidance in Kernel Fuzzing.",
            "venue": "CCS",
            "pages": "3763-3777",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/LiuSX024",
            "doi": "10.1145/3658644.3690232",
            "ee": "https://doi.org/10.1145/3658644.3690232",
            "url": "https://dblp.org/rec/conf/ccs/LiuSX024",
            "abstract": "State-of-the-art kernel fuzzers useedge-basedcode coverage metrics for novel behavior detection. However, code coverage is not sufficient for operating system kernels, for they contain many untracked but interesting features, such as comparison operands, kernel state identifiers, flags, and executable code, within its data segments, that reflects different execution patterns, and can profoundly increase the granularity and scope of the coverage metrics.",
            "pdf_url": "",
            "keywords": [
                "Kernel Fuzzing",
                "Binary Coverage",
                "Code Coverage Metrics",
                "Operating System Kernels",
                "Execution Patterns"
            ]
        },
        "url": "URL#256774",
        "sema_paperId": "2e4f4fbd654045bc58b2d6975236acb125c7b964"
    },
    {
        "@score": "1",
        "@id": "256775",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "243/0195",
                        "text": "Ruixuan Liu"
                    },
                    {
                        "@pid": "145/3288-1",
                        "text": "Tianhao Wang 0001"
                    },
                    {
                        "@pid": "25/7045-11",
                        "text": "Yang Cao 0011"
                    },
                    {
                        "@pid": "39/3530-1",
                        "text": "Li Xiong 0001"
                    }
                ]
            },
            "title": "PreCurious: How Innocent Pre-Trained Language Models Turn into Privacy Traps.",
            "venue": "CCS",
            "pages": "3511-3524",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/LiuW0024",
            "doi": "10.1145/3658644.3690279",
            "ee": "https://doi.org/10.1145/3658644.3690279",
            "url": "https://dblp.org/rec/conf/ccs/LiuW0024",
            "abstract": "The pre-training and fine-tuning paradigm has demonstrated its effectiveness and has become the standard approach for tailoring language models to various tasks. Currently, community-based platforms offer easy access to various pre-trained models, as anyone can publish without strict validation processes. However, a released pre-trained model can be a privacy trap for fine-tuning datasets if it is carefully designed. In this work, we propose PreCurious framework to reveal the new attack surface where the attacker releases the pre-trained model and gets a black-box access to the final fine-tuned model. PreCurious aims to escalate the general privacy risk of both membership inference and data extraction on the fine-tuning dataset. The key intuition behind PreCurious is to manipulate the memorization stage of the pre-trained model and guide fine-tuning with a seemingly legitimate configuration. While empirical and theoretical evidence suggests that parameter-efficient and differentially private fine-tuning techniques can defend against privacy attacks on a fine-tuned model, PreCurious demonstrates the possibility of breaking up this invulnerability in a stealthy manner compared to fine-tuning on a benign pre-trained model. While DP provides some mitigation for membership inference attack, by further leveraging a sanitized dataset, PreCurious demonstrates potential vulnerabilities for targeted data extraction even under differentially private tuning with a strict privacy budget e.g. $\\epsilon=0.05$. Thus, PreCurious raises warnings for users on the potential risks of downloading pre-trained models from unknown sources, relying solely on tutorials or common-sense defenses, and releasing sanitized datasets even after perfect scrubbing.",
            "keywords": [
                "Pre-trained Language Models",
                "Privacy Risks",
                "Membership Inference",
                "Data Extraction",
                "Differential Privacy"
            ]
        },
        "url": "URL#256775",
        "sema_paperId": "fe247e06d4371a67208a33c27caf0b34c4206829"
    },
    {
        "@score": "1",
        "@id": "256776",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "193/9286",
                        "text": "Zhibo Liu"
                    },
                    {
                        "@pid": "295/5277",
                        "text": "Yuanyuan Yuan"
                    },
                    {
                        "@pid": "292/7423",
                        "text": "Yanzuo Chen"
                    },
                    {
                        "@pid": "248/2303",
                        "text": "Sihang Hu"
                    },
                    {
                        "@pid": "120/6487",
                        "text": "Tianxiang Li"
                    },
                    {
                        "@pid": "42/1503",
                        "text": "Shuai Wang"
                    }
                ]
            },
            "title": "DeepCache: Revisiting Cache Side-Channel Attacks in Deep Neural Networks Executables.",
            "venue": "CCS",
            "pages": "4495-4508",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/LiuYCHLW24",
            "doi": "10.1145/3658644.3690241",
            "ee": "https://doi.org/10.1145/3658644.3690241",
            "url": "https://dblp.org/rec/conf/ccs/LiuYCHLW24",
            "abstract": "Deep neural networks (DNN) are increasingly deployed in heterogeneous hardware, including high-performance devices like GPUs and low-power devices like mobile/IoT CPUs, FPGAs, and accelerators. In order to unlock the full performance potential of various hardware, deep learning (DL) compilers automatically optimize DNN inference computations and compile DNN models into DNN executables for efficient computations across hardware backends. As valuable intellectual properties, DNN architectures are one primary attack target. Since previous works already demonstrate the abuse of cache side channels to steal DNN architectures from DL frameworks (e.g., PyTorch and TensorFlow), we first study using those known side-channel attacks against DNN executables. We find that attacking DNN executables presents unique challenges, and existing works can hardly apply. Particularly, DNN executa-bles exhibit a standalone paradigm that largely reduces cache side channel attack surfaces. Meanwhile, cache side channels capture only limited behaviors of the whole DNN execution while facing daunting technical challenges (e.g., noise and low time resolution). However, we unveil a unique attack vector in DNN executables, such that the cache-aware optimizations, which are extensively employed by contemporary DL compilers to harvest the full potentials of hardware, would result in distinguishable DNN operator cache access patterns, making model architecture recovery possible. We propose DeepCache, an end-to-end side channel attack framework, to infer DNN model architectures from DNN executables. Deep-Cache leverages cache side channels as the attacking primitives and combines contrastive learning and anomaly detection to enable precise inference. Our evaluation using the standard Prime+Probe",
            "keywords": [
                "Cache Side-Channel Attacks",
                "DNN Executables",
                "Model Architecture Recovery",
                "DL Compiler Optimizations",
                "DeepCache Framework"
            ]
        },
        "url": "URL#256776",
        "sema_paperId": "1ed4e363c0d1caa38139b11bfbdf57ff7c3305b4"
    },
    {
        "@score": "1",
        "@id": "256777",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "392/3170",
                        "text": "Sin Tai Liu"
                    },
                    {
                        "@pid": "229/5164",
                        "text": "Jiayuan Yu"
                    },
                    {
                        "@pid": "392/3086",
                        "text": "Jacob Steeves"
                    }
                ]
            },
            "title": "Poster: Solving the Free-rider Problem in Bittensor.",
            "venue": "CCS",
            "pages": "5045-5047",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/LiuYS24",
            "doi": "10.1145/3658644.3691414",
            "ee": "https://doi.org/10.1145/3658644.3691414",
            "url": "https://dblp.org/rec/conf/ccs/LiuYS24",
            "abstract": "The design and operation of https://bittensor.com/Bittensoris a decentralized and anonymous system where actors are incentivized by rewards to provide utilities. To ensure that it is a fair game, utilities obtained by copying other participants should be identified and punished. Our first contribution is to apply a commitment scheme to address this free-rider problem. Under appropriate conditions, we show theoretically and empirically that a commitment scheme dissuades copying by reducing the rewards to the copier. In particular, this dissuasive power is a function of the duration between the commit- and reveal-steps. Our second contribution is to propose the liquid alpha solution to amplify the effect of the commitment scheme.",
            "pdf_url": "",
            "keywords": [
                "Decentralized Systems",
                "Incentive Mechanisms",
                "Free-rider Problem",
                "Commitment Scheme",
                "Liquid Alpha Solution"
            ]
        },
        "url": "URL#256777",
        "sema_paperId": "7c13c0190fc550d65be4a77f783e76647236610b"
    },
    {
        "@score": "1",
        "@id": "256778",
        "info": {
            "authors": {
                "author": {
                    "@pid": "277/7996",
                    "text": "Efr\u00e9n L\u00f3pez-Morales"
                }
            },
            "title": "Securing Cyber-Physical Systems via Advanced Cyber Threat Intelligence Methods.",
            "venue": "CCS",
            "pages": "5119-5121",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Lopez-Morales24",
            "doi": "10.1145/3658644.3690865",
            "ee": "https://doi.org/10.1145/3658644.3690865",
            "url": "https://dblp.org/rec/conf/ccs/Lopez-Morales24",
            "abstract": "Many services that make our modern society work, such as communications and transportation, are only possible thanks to Cyber-Physical Systems (CPS). This makes CPS the target of cyberattacks that aim to disrupt our society. One tool that we can leverage to protect CPS is Cyber Threat Intelligence (CTI). CTI is threat information that helps us understand a threat actor's techniques. However, current CTI on CPS is limited as current methods cannot collect and analyze data on the latest cyberattacks against CPS. In this dissertation research description, we address this problem by developing three new methods that advance the state-of-the-art CTI of three different CPS: Industrial Control Systems (ICS), Satellites, and Connected Autonomous Vehicles (CAV). The first research project involves the development of a novel threat taxonomy for programmable logic controllers (PLCs), which are a key part of ICS. The second project is the development of a satellite honeypot to collect data on adversaries' techniques. The third and final project involves the development of a CAV sandbox that allows us to test cyberattacks on CAVs to collect raw threat intelligence.",
            "pdf_url": "",
            "keywords": [
                "Cyber-Physical Systems",
                "Cyber Threat Intelligence",
                "Industrial Control Systems",
                "Connected Autonomous Vehicles",
                "Satellite Honeypot"
            ]
        },
        "url": "URL#256778",
        "sema_paperId": "6bb740e02bc956f8973bea2f66f5570f2c95c373"
    },
    {
        "@score": "1",
        "@id": "256779",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "38/712",
                        "text": "Yifan Lu"
                    },
                    {
                        "@pid": "168/0792",
                        "text": "Wenxuan Li"
                    },
                    {
                        "@pid": "84/2519-1",
                        "text": "Mi Zhang 0001"
                    },
                    {
                        "@pid": "71/7816",
                        "text": "Xudong Pan"
                    },
                    {
                        "@pid": "02/1640-2",
                        "text": "Min Yang 0002"
                    }
                ]
            },
            "title": "Neural Dehydration: Effective Erasure of Black-box Watermarks from DNNs with Limited Data.",
            "venue": "CCS",
            "pages": "675-689",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/LuL0PY24",
            "doi": "10.1145/3658644.3690334",
            "ee": "https://doi.org/10.1145/3658644.3690334",
            "url": "https://dblp.org/rec/conf/ccs/LuL0PY24",
            "abstract": "To protect the intellectual property of well-trained deep neural networks (DNNs), black-box watermarks, which are embedded into the prediction behavior of DNN models on a set of specially-crafted samples and extracted from suspect models using only API access, have gained increasing popularity in both academy and industry. Watermark robustness is usually implemented against attackers who steal the protected model and obfuscate its parameters for watermark removal. However, current robustness evaluations are primarily performed under moderate attacks or unrealistic settings. Existing removal attacks could only crack a small subset of the mainstream black-box watermarks, and fall short in four key aspects: incomplete removal, reliance on prior knowledge of the watermark, performance degradation, and high dependency on data. In this paper, we propose a watermark-agnostic removal attack called \\textsc{Neural Dehydration} (\\textit{abbrev.} \\textsc{Dehydra}), which effectively erases all ten mainstream black-box watermarks from DNNs, with only limited or even no data dependence. In general, our attack pipeline exploits the internals of the protected model to recover and unlearn the watermark message. We further design target class detection and recovered sample splitting algorithms to reduce the utility loss and achieve data-free watermark removal on five of the watermarking schemes. We conduct comprehensive evaluation of \\textsc{Dehydra} against ten mainstream black-box watermarks on three benchmark datasets and DNN architectures. Compared with existing removal attacks, \\textsc{Dehydra} achieves strong removal effectiveness across all the covered watermarks, preserving at least $90\\%$ of the stolen model utility, under the data-limited settings, i.e., less than $2\\%$ of the training data or even data-free.",
            "keywords": [
                "Black-box Watermarks",
                "Watermark Removal",
                "Intellectual Property Protection",
                "Neural Dehydration",
                "Data-limited Settings"
            ]
        },
        "url": "URL#256779",
        "sema_paperId": "27dfd4db62ae5f17720e57b41ada30d30b86f8cc"
    },
    {
        "@score": "1",
        "@id": "256780",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "250/5769",
                        "text": "Keane Lucas"
                    },
                    {
                        "@pid": "68/4713",
                        "text": "Weiran Lin"
                    },
                    {
                        "@pid": "32/3440",
                        "text": "Lujo Bauer"
                    },
                    {
                        "@pid": "r/MichaelKReiter",
                        "text": "Michael K. Reiter"
                    },
                    {
                        "@pid": "136/8393",
                        "text": "Mahmood Sharif"
                    }
                ]
            },
            "title": "Training Robust ML-based Raw-Binary Malware Detectors in Hours, not Months.",
            "venue": "CCS",
            "pages": "124-138",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/LucasLBRS24",
            "doi": "10.1145/3658644.3690208",
            "ee": "https://doi.org/10.1145/3658644.3690208",
            "url": "https://dblp.org/rec/conf/ccs/LucasLBRS24",
            "abstract": "Machine-learning (ML) classifiers are increasingly used to distinguish malware from benign binaries. Recent work has shown that ML-based detectors can be evaded by adversarial examples, but also that one may defend against such attacks via adversarial training. However, adversarial training, and subsequent robustness evaluation, is computationally expensive in the raw-binary malware-detection domain because it requires producing many adversarial examples for both training and evaluation . Prior work found that Greedy-training , a faster robust training technique that forgoes using adversarial examples, showed some promise in producing robust malware detectors. However, Greedy -training was far less effective in inducing robustness than the more expensive adversarial training, and it also severely hurt natural accuracy (i.e., accuracy on the original data). To faster train models, this work presents GreedyBlock -training, an enhanced version of Greedy -training that we empirically show achieves not only state-of-the-art robustness in malware detectors, exceeding even adversarial training, but also retains natural accuracy better than adversarial training. Furthermore, as it does not require creating adversarial (or functional) examples, GreedyBlock -training is significantly faster than adversarial training. Specifically, we show that GreedyBlock -training can produce more robust (+54% on average), more naturally accurate (+7% on average), and more efficiently trained (-91% average computation) malware detectors than prior work. To faster evaluate models, we also develop methods to faster gauge the robustness of ML-based raw-binary malware detectors by introducing robustness proxies , which can be used either to predict which models are likely to be the most robust, thus helping prioritize which detectors to evaluate with expensive attacks, or aiding in deciding which detectors are worthwhile to continue training. Experimentally, we show these proxy measures can find the most robust detector in a pool of detectors while using only \u223c 20-50% of the computation that would otherwise be required.",
            "keywords": [
                "Malware Detection",
                "Adversarial Training",
                "GreedyBlock-training",
                "Robustness Evaluation",
                "Natural Accuracy"
            ]
        },
        "url": "URL#256780",
        "sema_paperId": "7a92e7d8784d73db4e13a08bc6fcaed1da2afd93"
    },
    {
        "@score": "1",
        "@id": "256781",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "294/1088",
                        "text": "Changhua Luo"
                    },
                    {
                        "@pid": "81/8013-1",
                        "text": "Penghui Li 0001"
                    },
                    {
                        "@pid": "05/3920-1",
                        "text": "Wei Meng 0001"
                    },
                    {
                        "@pid": "94/3019-8",
                        "text": "Chao Zhang 0008"
                    }
                ]
            },
            "title": "Test Suites Guided Vulnerability Validation for Node.js Applications.",
            "venue": "CCS",
            "pages": "570-584",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Luo00Z24",
            "doi": "10.1145/3658644.3690332",
            "ee": "https://doi.org/10.1145/3658644.3690332",
            "url": "https://dblp.org/rec/conf/ccs/Luo00Z24",
            "abstract": "Dynamic methods have shown great promise in validating vulnerabilities and generating Proof-of-Concept (PoC) exploits of Node.js applications. They typically rely on dictionaries or specifications to determine the values of request parameters and their relationships. However, they still struggle to generate complex inputs from the provided dictionaries or specifications.",
            "pdf_url": "",
            "keywords": [
                "Node.js Vulnerability Validation",
                "Dynamic Methods",
                "Proof-of-Concept Exploits",
                "Input Generation",
                "Request Parameter Relationships"
            ]
        },
        "url": "URL#256781",
        "sema_paperId": "25ed59d77f9b63b95a595cdf2110379c37fa82d9"
    },
    {
        "@score": "1",
        "@id": "256782",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "181/2672",
                        "text": "Feng Luo"
                    },
                    {
                        "@pid": "392/3262",
                        "text": "Huangkun Lin"
                    },
                    {
                        "@pid": "175/8858-1",
                        "text": "Zihao Li 0001"
                    },
                    {
                        "@pid": "53/1565",
                        "text": "Xiapu Luo"
                    },
                    {
                        "@pid": "211/7621",
                        "text": "Ruijie Luo"
                    },
                    {
                        "@pid": "270/2519",
                        "text": "Zheyuan He"
                    },
                    {
                        "@pid": "332/4779",
                        "text": "Shuwei Song"
                    },
                    {
                        "@pid": "19/1766-2",
                        "text": "Ting Chen 0002"
                    },
                    {
                        "@pid": "392/2941",
                        "text": "Wenxuan Luo"
                    }
                ]
            },
            "title": "Towards Automatic Discovery of Denial of Service Weaknesses in Blockchain Resource Models.",
            "venue": "CCS",
            "pages": "1016-1030",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/LuoL0LLHS0L24",
            "doi": "10.1145/3658644.3690329",
            "ee": "https://doi.org/10.1145/3658644.3690329",
            "url": "https://dblp.org/rec/conf/ccs/LuoL0LLHS0L24",
            "abstract": "nial-of-Service (DoS) attacks at the execution layer represent one of the most severe threats to blockchain systems, compromising availability by depleting the resources of victims. To counteract these attacks, many blockchains have implemented unique resource models that incorporate transaction fees. Nevertheless, historical incidents of DoS attacks demonstrate that these resource model designs remain inadequate. Although there are studies that manually craft DoS attacks on specific blockchains in isolation, none of them can discover DoS weaknesses in blockchains automatically. In this paper, we provide an insight into DoS weaknesses in blockchain resource models, and present a generic and systematic approach to uncover these weaknesses. In our approach, we first identify DoS weaknesses byDoSVER, a novel tool that reasons feasible DoS weaknesses against blockchain resource models by formal verification. The identified DoS weaknesses will be further validated byDoSDET, a new framework that automates the attack synthesis in exploiting the identified DoS weaknesses. We conduct a comprehensive and systematic evaluation by extensive experiments on nine diverse and widely-used blockchains, and discovered 12 DoS weaknesses with corresponding exploitation across the nine blockchains, 10 of which were unveiled for the first time.",
            "pdf_url": "",
            "keywords": [
                "Blockchain Resource Models",
                "Denial of Service (DoS)",
                "DoS Weaknesses",
                "Formal Verification",
                "Attack Synthesis"
            ]
        },
        "url": "URL#256782",
        "sema_paperId": "42da87b97a15a5ed5832ba1f40a8f368c1587378"
    },
    {
        "@score": "1",
        "@id": "256783",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "73/2249",
                        "text": "Ming Luo"
                    },
                    {
                        "@pid": "53/608",
                        "text": "Feng-Hao Liu"
                    },
                    {
                        "@pid": "67/1771",
                        "text": "Han Wang"
                    }
                ]
            },
            "title": "Faster FHE-Based Single-Server Private Information Retrieval.",
            "venue": "CCS",
            "pages": "1405-1419",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/LuoLW24",
            "doi": "10.1145/3658644.3690233",
            "ee": "https://doi.org/10.1145/3658644.3690233",
            "url": "https://dblp.org/rec/conf/ccs/LuoLW24",
            "abstract": "This work introduces KsPIR, a new practically efficient single-server private information retrieval (PIR) system that outperforms the state-of-the-art Spiral (Menon and Wu, S&P 2022) in terms of server response times. We achieve this by proposing novel dimension folding methods, inspired by recent advancements in fully homomorphic encryption. Our methods offer two significant advantages: firstly, they feature simpler designs that eliminate the need for ciphertext expansion steps in Spiral. Secondly, and more importantly, we propose two types of designs that offer distinct advantages - the first type enables preprocessing of the most resource-intensive computation in the offline stage before receiving the query, thereby optimizing online response time; the second type optimizes overall response time without requiring preprocessing in the offline stage, accomplished through a highly optimized baby-step-giant-step matrix-vector homomorphic multiplication.",
            "pdf_url": "",
            "keywords": [
                "Private Information Retrieval",
                "Fully Homomorphic Encryption",
                "Single-Server PIR",
                "Server Response Time Optimization",
                "Dimension Folding Methods"
            ]
        },
        "url": "URL#256783",
        "sema_paperId": "d7ab01e62416603ac7bb537aa2140b03afb2d128"
    },
    {
        "@score": "1",
        "@id": "256784",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "39/8683",
                        "text": "Mingqi Lv"
                    },
                    {
                        "@pid": "371/2505",
                        "text": "Hongzhe Gao"
                    },
                    {
                        "@pid": "325/4833",
                        "text": "Xuebo Qiu"
                    },
                    {
                        "@pid": "66/6179",
                        "text": "Tieming Chen"
                    },
                    {
                        "@pid": "153/5745",
                        "text": "Tiantian Zhu"
                    },
                    {
                        "@pid": "50/415",
                        "text": "Jinyin Chen"
                    },
                    {
                        "@pid": "07/8388",
                        "text": "Shouling Ji"
                    }
                ]
            },
            "title": "TREC: APT Tactic / Technique Recognition via Few-Shot Provenance Subgraph Learning.",
            "venue": "CCS",
            "pages": "139-152",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/LvGQCZCJ24",
            "doi": "10.1145/3658644.3690221",
            "ee": "https://doi.org/10.1145/3658644.3690221",
            "url": "https://dblp.org/rec/conf/ccs/LvGQCZCJ24",
            "abstract": "APT (Advanced Persistent Threat) with the characteristics of persistence, stealth, and diversity is one of the greatest threats against cyber-infrastructure. As a countermeasure, existing studies leverage provenance graphs to capture the complex relations between system entities in a host for effective APT detection. In addition to detecting single attack events as most existing work does, understanding the tactics / techniques (e.g., Kill-Chain, ATT&CK) applied to organize and accomplish the APT attack campaign is more important for security operations. Existing studies try to manually design a set of rules to map low-level system events to high-level APT tactics / techniques. However, the rule based methods are coarse-grained and lack generalization ability, thus they can only recognize APT tactics and cannot identify fine-grained APT techniques and mutant APT attacks. In this paper, we propose TREC, the first attempt to recognize APT tactics / techniques from provenance graphs by exploiting deep learning techniques. To address the\"needle in a haystack\"problem, TREC segments small and compact subgraphs covering individual APT technique instances from a large provenance graph based on a malicious node detection model and a subgraph sampling algorithm. To address the\"training sample scarcity\"problem, TREC trains the APT tactic / technique recognition model in a few-shot learning manner by adopting a Siamese neural network. We evaluate TREC based on a customized dataset collected and made public by our team. The experiment results show that TREC significantly outperforms state-of-the-art systems in APT tactic recognition and TREC can also effectively identify APT techniques.",
            "keywords": [
                "APT Detection",
                "Provenance Graphs",
                "Tactics and Techniques Recognition",
                "Few-Shot Learning",
                "Malicious Node Detection"
            ]
        },
        "url": "URL#256784",
        "sema_paperId": "25e7d0b5cd962a28c0248e29542395611b0f455d"
    },
    {
        "@score": "1",
        "@id": "256785",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "304/1044",
                        "text": "Yunlong Lyu"
                    },
                    {
                        "@pid": "209/1880",
                        "text": "Yuxuan Xie"
                    },
                    {
                        "@pid": "27/7017",
                        "text": "Peng Chen"
                    },
                    {
                        "@pid": "86/475-3",
                        "text": "Hao Chen 0003"
                    }
                ]
            },
            "title": "Prompt Fuzzing for Fuzz Driver Generation.",
            "venue": "CCS",
            "pages": "3793-3807",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/LyuXCC24",
            "doi": "10.1145/3658644.3670396",
            "ee": "https://doi.org/10.1145/3658644.3670396",
            "url": "https://dblp.org/rec/conf/ccs/LyuXCC24",
            "abstract": "Crafting high-quality fuzz drivers not only is time-consuming but also requires a deep understanding of the library. However, the state-of-the-art automatic fuzz driver generation techniques fall short of expectations. While fuzz drivers derived from consumer code can reach deep states, they have limited coverage. Conversely, interpretative fuzzing can explore most API calls but requires numerous attempts within a large search space. We propose PromptFuzz, a coverage-guided fuzzer for prompt fuzzing that iteratively generates fuzz drivers to explore undiscovered library code. To explore API usage in fuzz drivers during prompt fuzzing, we propose several key techniques: instructive program generation, erroneous program validation, coverage-guided prompt mutation, and constrained fuzzer scheduling. We implemented PromptFuzz and evaluated it on 14 real-world libraries. Compared with OSS-Fuzz and Hopper (the state-of-the-art fuzz driver generation tool), fuzz drivers generated by PromptFuzz achieved 1.61 and 1.63 times higher branch coverage than those by OSS-Fuzz and Hopper, respectively. Moreover, the fuzz drivers generated by PromptFuzz detected 33 genuine, new bugs out of a total of 49 crashes, out of which 30 bugs have been confirmed by their respective communities.",
            "keywords": [
                "Fuzzing",
                "Fuzz Driver Generation",
                "Coverage-Guided Fuzzing",
                "Prompt Fuzzing",
                "Library Code Exploration"
            ]
        },
        "url": "URL#256785",
        "sema_paperId": "239749979eeef500322fd60c2f6970d77dd4bd20"
    },
    {
        "@score": "1",
        "@id": "256786",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "25/2540",
                        "text": "Vadim Lyubashevsky"
                    },
                    {
                        "@pid": "184/3795",
                        "text": "Gregor Seiler"
                    },
                    {
                        "@pid": "392/3414",
                        "text": "Patrick Steuer"
                    }
                ]
            },
            "title": "The LaZer Library: Lattice-Based Zero Knowledge and Succinct Proofs for Quantum-Safe Privacy.",
            "venue": "CCS",
            "pages": "3125-3137",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/LyubashevskySS24",
            "doi": "10.1145/3658644.3690330",
            "ee": "https://doi.org/10.1145/3658644.3690330",
            "url": "https://dblp.org/rec/conf/ccs/LyubashevskySS24",
            "abstract": "The hardness of lattice problems offers one of the most promising security foundations for quantum-safe cryptography. Basic schemes for public key encryption and digital signatures are already close to standardization at NIST and several other standardization bodies, and the research frontier has moved on to building primitives with more advanced privacy features. At the core of many such primitives are zero-knowledge proofs. In recent years, zero-knowledge proofs for (and using) lattice relations have seen a dramatic jump in efficiency and they currently provide arguably the shortest, and most computationally efficient, quantum-safe proofs for many scenarios. The main difficulty in using these proofs by non-experts (and experts!) is that they have a lot of moving parts and a lot of internal parameters depend on the particular instance that one is trying to prove.",
            "pdf_url": "",
            "keywords": [
                "Lattice-Based Cryptography",
                "Zero-Knowledge Proofs",
                "Quantum-Safe Privacy",
                "Efficient Proofs",
                "Privacy Features"
            ]
        },
        "url": "URL#256786",
        "sema_paperId": "08f910c9b2d3f75b7083b1ef3eebfc609c467f4c"
    },
    {
        "@score": "1",
        "@id": "256787",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "215/9898",
                        "text": "Xinyao Ma"
                    },
                    {
                        "@pid": "165/2299-2",
                        "text": "Chaoqi Zhang 0002"
                    },
                    {
                        "@pid": "282/6169",
                        "text": "Huadi Zhu"
                    },
                    {
                        "@pid": "72/4476",
                        "text": "L. Jean Camp"
                    },
                    {
                        "@pid": "l/MingLi6",
                        "text": "Ming Li 0006"
                    },
                    {
                        "@pid": "129/1113",
                        "text": "Xiaojing Liao"
                    }
                ]
            },
            "title": "Avara:  A Uniform Evaluation System for Perceptibility Analysis Against Adversarial Object Evasion Attacks.",
            "venue": "CCS",
            "pages": "4792-4806",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Ma0ZCLL24",
            "doi": "10.1145/3658644.3670291",
            "ee": "https://doi.org/10.1145/3658644.3670291",
            "url": "https://dblp.org/rec/conf/ccs/Ma0ZCLL24",
            "abstract": "Thanks to recent advances in machine learning (ML) techniques, Autonomous Driving (AD) has seen significant breakthroughs with enhanced capabilities. However, the susceptibility of ML models to adversarial evasion attacks poses a critical threat, undermining the reliability of autonomous driving systems. Despite efforts by researchers to mitigate these attacks within the AD context, unfortunately, a significant gap persists in fully understanding such adversarial maneuvers, particularly from a driver's perspective.",
            "pdf_url": "",
            "keywords": [
                "Autonomous Driving",
                "Adversarial Evasion Attacks",
                "Perceptibility Analysis",
                "Reliability of ML Models",
                "Driver's Perspective"
            ]
        },
        "url": "URL#256787",
        "sema_paperId": "3a3e7e6a53afb495e6c6ebf39fec22a6cf9e6317"
    },
    {
        "@score": "1",
        "@id": "256788",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "326/3872",
                        "text": "Oubo Ma"
                    },
                    {
                        "@pid": "220/9652",
                        "text": "Yuwen Pu"
                    },
                    {
                        "@pid": "246/4947",
                        "text": "Linkang Du"
                    },
                    {
                        "@pid": "13/5606",
                        "text": "Yang Dai"
                    },
                    {
                        "@pid": "309/4186",
                        "text": "Ruo Wang"
                    },
                    {
                        "@pid": "34/8893-1",
                        "text": "Xiaolei Liu 0001"
                    },
                    {
                        "@pid": "49/6702",
                        "text": "Yingcai Wu"
                    },
                    {
                        "@pid": "07/8388",
                        "text": "Shouling Ji"
                    }
                ]
            },
            "title": "SUB-PLAY:  Adversarial Policies against Partially Observed Multi-Agent Reinforcement Learning Systems.",
            "venue": "CCS",
            "pages": "645-659",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/MaPDDWLWJ24",
            "doi": "10.1145/3658644.3670293",
            "ee": "https://doi.org/10.1145/3658644.3670293",
            "url": "https://dblp.org/rec/conf/ccs/MaPDDWLWJ24",
            "abstract": "Recent advancements in multi-agent reinforcement learning (MARL) have opened up vast application prospects, such as swarm control of drones, collaborative manipulation by robotic arms, and multi-target encirclement. However, potential security threats during the MARL deployment need more attention and thorough investigation. Recent research reveals that attackers can rapidly exploit the victim's vulnerabilities, generating adversarial policies that result in the failure of specific tasks. For instance, reducing the winning rate of a superhuman-level Go AI to around 20%. Existing studies predominantly focus on two-player competitive environments, assuming attackers possess complete global state observation. In this study, we unveil, for the first time, the capability of attackers to generate adversarial policies even when restricted to partial observations of the victims in multi-agent competitive environments. Specifically, we propose a novel black-box attack (SUB-PLAY) that incorporates the concept of constructing multiple subgames to mitigate the impact of partial observability and suggests sharing transitions among subpolicies to improve attackers' exploitative ability. Extensive evaluations demonstrate the effectiveness of SUB-PLAY under three typical partial observability limitations. Visualization results indicate that adversarial policies induce significantly different activations of the victims' policy networks. Furthermore, we evaluate three potential defenses aimed at exploring ways to mitigate security threats posed by adversarial policies, providing constructive recommendations for deploying MARL in competitive environments.",
            "keywords": [
                "Multi-Agent Reinforcement Learning",
                "Adversarial Policies",
                "Partial Observability",
                "Black-Box Attack",
                "Competitive Environments"
            ]
        },
        "url": "URL#256788",
        "sema_paperId": "6835f649937c76b0be1c326e45b8bc847cdf24b2"
    },
    {
        "@score": "1",
        "@id": "256789",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "60/887",
                        "text": "Hua Ma"
                    },
                    {
                        "@pid": "53/448",
                        "text": "Shang Wang"
                    },
                    {
                        "@pid": "139/1152-1",
                        "text": "Yansong Gao 0001"
                    },
                    {
                        "@pid": "36/5594-1",
                        "text": "Zhi Zhang 0001"
                    },
                    {
                        "@pid": "292/4175",
                        "text": "Huming Qiu"
                    },
                    {
                        "@pid": "166/1912",
                        "text": "Minhui Xue 0001"
                    },
                    {
                        "@pid": "165/0106",
                        "text": "Alsharif Abuadbba"
                    },
                    {
                        "@pid": "88/9558",
                        "text": "Anmin Fu"
                    },
                    {
                        "@pid": "22/3939",
                        "text": "Surya Nepal"
                    },
                    {
                        "@pid": "a/DerekAbbott",
                        "text": "Derek Abbott"
                    }
                ]
            },
            "title": "Watch Out! Simple Horizontal Class Backdoor Can Trivially Evade Defense.",
            "venue": "CCS",
            "pages": "4465-4479",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/MaWGZQ0AFNA24",
            "doi": "10.1145/3658644.3670361",
            "ee": "https://doi.org/10.1145/3658644.3670361",
            "url": "https://dblp.org/rec/conf/ccs/MaWGZQ0AFNA24",
            "abstract": "All current backdoor attacks on deep learning (DL) models fall under the category of a vertical class backdoor (VCB) -- class-dependent. In VCB attacks, any sample from a class activates the implanted backdoor when the secret trigger is present. Existing defense strategies overwhelmingly focus on countering VCB attacks, especially those that are source-class-agnostic. This narrow focus neglects the potential threat of other simpler yet general backdoor types, leading to false security implications. This study introduces a new, simple, and general type of backdoor attack coined as the horizontal class backdoor (HCB) that trivially breaches the class dependence characteristic of the VCB, bringing a fresh perspective to the community. HCB is now activated when the trigger is presented together with an innocuous feature, regardless of class. For example, the facial recognition model misclassifies a person who wears sunglasses with a smiling innocuous feature into the targeted person, such as an administrator, regardless of which person. The key is that these innocuous features are horizontally shared among classes but are only exhibited by partial samples per class. Extensive experiments on attacking performance across various tasks, including MNIST, facial recognition, traffic sign recognition, object detection, and medical diagnosis, confirm the high efficiency and effectiveness of the HCB. We rigorously evaluated the evasiveness of the HCB against a series of eleven representative countermeasures, including Fine-Pruning (RAID 18'), STRIP (ACSAC 19'), Neural Cleanse (Oakland 19'), ABS (CCS 19'), Februus (ACSAC 20'), NAD (ICLR 21'), MNTD (Oakland 21'), SCAn (USENIX SEC 21'), MOTH (Oakland 22'), Beatrix (NDSS 23'), and MM-BD (Oakland 24'). None of these countermeasures prove robustness, even when employing a simplistic trigger, such as a small and static white-square patch.",
            "keywords": [
                "Backdoor Attack",
                "Horizontal Class Backdoor",
                "Vertical Class Backdoor",
                "Model Evasion",
                "Trigger Activation"
            ]
        },
        "url": "URL#256789",
        "sema_paperId": "4c1b2397b6ac259ee80e21ca564e74966bcbc00b"
    },
    {
        "@score": "1",
        "@id": "256790",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "301/9694",
                        "text": "Ahmed Tanvir Mahdad"
                    },
                    {
                        "@pid": "291/3253",
                        "text": "Mohammed Jubur"
                    },
                    {
                        "@pid": "25/1169",
                        "text": "Nitesh Saxena"
                    }
                ]
            },
            "title": "Breaching Security Keys without Root: FIDO2 Deception Attacks via Overlays exploiting Limited Display Authenticators.",
            "venue": "CCS",
            "pages": "1686-1700",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/MahdadJS24",
            "doi": "10.1145/3658644.3690286",
            "ee": "https://doi.org/10.1145/3658644.3690286",
            "url": "https://dblp.org/rec/conf/ccs/MahdadJS24",
            "abstract": "Two-factor authentication (2FA) systems aim to secure user accounts, provided that either the password or the second factor device remains uncompromised. However, in this research, we challenge this perception and analyze the security of FIDO2 hardware security keys, which are increasingly used in 2FA and passwordless systems. Specifically, we develop an attack framework, analyze the underlying protocols of FIDO2, and examine the associated OS-level security. Through practical demonstrations, we illustrate how adversaries can exploit this framework and OS-level security measures to execute our designed attack, known as FIDOLA (<u>FI</u>DO2<u>D</u>eception Attack via<u>O</u>verlays exploiting<u>L</u>imited Display<u>A</u>uthenticators).",
            "pdf_url": "",
            "keywords": [
                "FIDO2",
                "Two-Factor Authentication",
                "Security Keys",
                "Deception Attacks",
                "Limited Display Authenticators"
            ]
        },
        "url": "URL#256790",
        "sema_paperId": "11409400a8c3c3f9f73b1091b941a87e15558e07"
    },
    {
        "@score": "1",
        "@id": "256791",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "87/11152",
                        "text": "Nikolaos Makriyannis"
                    },
                    {
                        "@pid": "356/1794",
                        "text": "Oren Yomtov"
                    },
                    {
                        "@pid": "392/3386",
                        "text": "Arik Galansky"
                    }
                ]
            },
            "title": "Practical Key-Extraction Attacks in Leading MPC Wallets.",
            "venue": "CCS",
            "pages": "3053-3064",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/MakriyannisYG24",
            "doi": "10.1145/3658644.3670359",
            "ee": "https://doi.org/10.1145/3658644.3670359",
            "url": "https://dblp.org/rec/conf/ccs/MakriyannisYG24",
            "abstract": "Multi-Party Computation (MPC) has become a major tool for protecting hundreds of billions of dollars in cryptocurrency wallets. MPC protocols are currently powering the wallets of Coinbase, Binance, Zengo, BitGo, Fireblocks and many other fintech companies servicing thousands of financial institutions and hundreds of millions of end-user consumers.",
            "pdf_url": "",
            "keywords": [
                "Multi-Party Computation (MPC)",
                "Cryptocurrency Wallets",
                "Key-Extraction Attacks",
                "Wallet Security",
                "Fintech Vulnerabilities"
            ]
        },
        "url": "URL#256791"
    },
    {
        "@score": "1",
        "@id": "256792",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "291/4512",
                        "text": "Shubham Malaviya"
                    },
                    {
                        "@pid": "133/7191-1",
                        "text": "Manish Shukla 0001"
                    },
                    {
                        "@pid": "340/7796",
                        "text": "Saurabh Anand"
                    },
                    {
                        "@pid": "14/6843",
                        "text": "Sachin Lodha"
                    }
                ]
            },
            "title": "Poster: Unmasking Label Errors: A need for Robust Cybersecurity Benchmarks.",
            "venue": "CCS",
            "pages": "5018-5020",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Malaviya0AL24",
            "doi": "10.1145/3658644.3691418",
            "ee": "https://doi.org/10.1145/3658644.3691418",
            "url": "https://dblp.org/rec/conf/ccs/Malaviya0AL24",
            "abstract": "Cyber Threat Intelligence (CTI) utilizes information from various sources, necessitating high-quality labeled datasets for effective application of machine learning. Our study addresses the often-overlooked issue of labeling errors in cybersecurity benchmarks, resulting in the creation of D-LADDER++, a curated version of the recently published LADDER dataset. We evaluated the performance of both an open-source model (Microsoft Phi-3) and a closed-source model (Google Gemini) on D-LADDER++. We assessed their zero-shot and few-shot capabilities and fine-tuned the Phi-3 model for enhanced adaptability. Our assessment of the impact of test errors on model performance emphasizes the critical need for robust benchmarks in cybersecurity to ensure accurate model evaluation and selection.",
            "pdf_url": "",
            "keywords": [
                "Cyber Threat Intelligence",
                "Labeling Errors",
                "Cybersecurity Benchmarks",
                "D-LADDER++ Dataset",
                "Model Performance Evaluation"
            ]
        },
        "url": "URL#256792",
        "sema_paperId": "6d9c8d699c9c46b2217e0ae5c489661de08d0323"
    },
    {
        "@score": "1",
        "@id": "256793",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "235/4793",
                        "text": "Deepak Maram"
                    },
                    {
                        "@pid": "218/7156",
                        "text": "Mahimna Kelkar"
                    },
                    {
                        "@pid": "86/8318",
                        "text": "Ittay Eyal"
                    }
                ]
            },
            "title": "Interactive Multi-Credential Authentication.",
            "venue": "CCS",
            "pages": "408-422",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/MaramKE24",
            "doi": "10.1145/3658644.3670378",
            "ee": "https://doi.org/10.1145/3658644.3670378",
            "url": "https://dblp.org/rec/conf/ccs/MaramKE24",
            "abstract": "\u2014Authentication is the first, crucial step in securing digital assets like cryptocurrencies and online services like banking and social networks. It relies on principals maintaining exclusive access to credentials like cryptographic signing keys, passwords, and physical devices. But both individuals and organizations struggle to manage their credentials, resulting in loss of assets and identity theft. Multi-factor authentication improves security, but its analysis and design are mostly limited to one-shot mechanisms , which decide immediately. In this work, we study mechanisms with back-and-forth interaction with the principals. For example, a user receives an email notification about sending money from her bank account and is given a period of time to abort the operation. We formally define the authentication problem , where an authentication mechanism interacts with a user and an attacker and tries to identify the user. A mechanism\u2019s success depends on the scenario \u2013 whether the user / attacker know the different credentials; each credential can be safe, lost, leaked, or stolen. The profile of a mechanism is the set of all scenarios in which it succeeds. Thus, we have a partial order on mechanisms, defined by the subset relation on their profiles. We find an upper bound on the profile size and discover three types of n -credential mechanisms (for any n ) that are maximally secure , meeting this bound. We show these are all the unique maximal mechanisms for n \u2264 3 . We show the efficacy of our model by analyzing existing mechanisms, both theoretical and deployed in widely-used systems, and make concrete improvement proposals. We demonstrate the practicality of our mechanisms by implementing a maximally-secure cryptocurrency wallet.",
            "keywords": [
                "Multi-Credential Authentication",
                "Interactive Mechanisms",
                "User Identification",
                "Credential Management",
                "Maximally Secure Mechanisms"
            ]
        },
        "url": "URL#256793",
        "sema_paperId": "ad489c734db4f79c49cde467c7b7d2ff55973ecc"
    },
    {
        "@score": "1",
        "@id": "256794",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "203/2740",
                        "text": "Evangelia Anna Markatou"
                    },
                    {
                        "@pid": "t/RobertoTamassia",
                        "text": "Roberto Tamassia"
                    }
                ]
            },
            "title": "Reconstructing with Even Less: Amplifying Leakage and Drawing Graphs.",
            "venue": "CCS",
            "pages": "4777-4791",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/MarkatouT24",
            "doi": "10.1145/3658644.3670313",
            "ee": "https://doi.org/10.1145/3658644.3670313",
            "url": "https://dblp.org/rec/conf/ccs/MarkatouT24",
            "abstract": "Leakage-abuse attacks using access pattern leakage from range queries have been shown to reconstruct encrypted databases. However, prior work is either restricted to one-dimensional databases or requires access to all possible responses in two-dimensions. In this paper, we explore what an adversary can achieve with minimal leakage, focusing on denser databases, and present a leakage abuse attack from access pattern of range queries in multiple dimensions. Our attack employs a novel technique to systematically amplify access pattern leakage, inferring a large number of new query responses that have not been requested by the user. Letmbe the size of the database domain. Our attack works ond-dimensional databases and achieves approximate reconstruction. For dense databases and a parameter 0 < \u03bb < 1, our attack fully reconstructs an inner portion of size \u03bbmof the database (referred to as the \u03bb-core) after observingO(mlogm) queries, uniformly at random. These are significant improvements over previous attacks that require the full set of responses, which has sizeO(m2). We are the first to leverage graph drawing techniques for database reconstruction attacks. We implement our attack and evaluate it with experiments on real-world databases, achieving accurate reconstructions after observing a small percentage of the responses.",
            "pdf_url": "",
            "keywords": [
                "Database Reconstruction",
                "Access Pattern Leakage",
                "Range Queries",
                "Multi-dimensional Databases",
                "Graph Drawing Techniques"
            ]
        },
        "url": "URL#256794",
        "sema_paperId": "7b15b1bf8e15d1cf238e4dc0179c2d638deba84f"
    },
    {
        "@score": "1",
        "@id": "256795",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "92/7038",
                        "text": "Long Meng"
                    },
                    {
                        "@pid": "22/150-2",
                        "text": "Liqun Chen 0002"
                    },
                    {
                        "@pid": "188/7576",
                        "text": "Yangguang Tian"
                    },
                    {
                        "@pid": "62/484",
                        "text": "Mark Manulis"
                    }
                ]
            },
            "title": "FABESA: Fast (and Anonymous) Attribute-Based Encryption under Standard Assumption.",
            "venue": "CCS",
            "pages": "4688-4702",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Meng0TM24",
            "doi": "10.1145/3658644.3670321",
            "ee": "https://doi.org/10.1145/3658644.3670321",
            "url": "https://dblp.org/rec/conf/ccs/Meng0TM24",
            "abstract": "Attribute-Based Encryption (ABE) provides fine-grained access control to encrypted data and finds applications in various domains. The practicality of ABE schemes hinges on the balance between security and efficiency. The state-of-the-art adaptive secure ABE scheme, proven to be adaptively secure under standard assumptions (FAME, CCS'17), is less efficient compared to the fastest one (FABEO, CCS'22) which is only proven secure under the Generic Group Model (GGM). These traditional ABE schemes focus solely on message privacy. To address scenarios where attribute value information is also sensitive, Anonymous ABE (A2BE) ensures the privacy of both the message and attributes. However, most A2BE schemes suffer from intricate designs with low efficiency, and the security of the fastest key-policy A2BE (proposed in FEASE, USENIX'24) relies on the GGM.",
            "pdf_url": "",
            "keywords": [
                "Attribute-Based Encryption",
                "Anonymous ABE",
                "Access Control",
                "Efficiency",
                "Standard Assumptions"
            ]
        },
        "url": "URL#256795"
    },
    {
        "@score": "1",
        "@id": "256796",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "246/5331",
                        "text": "Ruijie Meng"
                    },
                    {
                        "@pid": "74/3123",
                        "text": "Gregory J. Duck"
                    },
                    {
                        "@pid": "04/5884",
                        "text": "Abhik Roychoudhury"
                    }
                ]
            },
            "title": "Program Environment Fuzzing.",
            "venue": "CCS",
            "pages": "720-734",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/MengDR24",
            "doi": "10.1145/3658644.3690229",
            "ee": "https://doi.org/10.1145/3658644.3690229",
            "url": "https://dblp.org/rec/conf/ccs/MengDR24",
            "abstract": "Computer programs are not executed in isolation, but rather interact with the execution environment which drives the program behaviors. Software validation methods thus need to capture the effect of possibly complex environmental interactions. Program environments may come from files, databases, configurations, network sockets, human-user interactions, and more. Conventional approaches for environment capture in symbolic execution and model checking employ environment modeling, which involves manual effort. In this paper, we take a different approach based on an extension of greybox fuzzing. Given a program, we first record all observed environmental interactions at the kernel/user-mode boundary in the form of system calls. Next, we replay the program under the original recorded interactions, but this time with selective mutations applied, in order to get the effect of different program environments -- all without environment modeling. Via repeated (feedback-driven) mutations over a fuzzing campaign, we can search for program environments that induce crashing behaviors. Our EnvFuzz tool found 33 previously unknown bugs in well-known real-world protocol implementations and GUI applications. Many of these are security vulnerabilities and 16 CVEs were assigned.",
            "keywords": [
                "Program Environment Fuzzing",
                "Greybox Fuzzing",
                "Environmental Interactions",
                "System Call Monitoring",
                "Bug Detection"
            ]
        },
        "url": "URL#256796",
        "sema_paperId": "f964ab25d258885be3904e6fc8ed29b8d1db3c4f"
    },
    {
        "@score": "1",
        "@id": "256797",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "350/7966",
                        "text": "Qiaoran Meng"
                    },
                    {
                        "@pid": "59/8759",
                        "text": "Nay Oo"
                    },
                    {
                        "@pid": "99/7950",
                        "text": "Yuning Jiang"
                    },
                    {
                        "@pid": "l/HWLim",
                        "text": "Hoon Wei Lim"
                    },
                    {
                        "@pid": "s/BiplabSikdar",
                        "text": "Biplab Sikdar 0001"
                    }
                ]
            },
            "title": "Poster: M2ASK:  A Correlation-Based Multi-Step Attack Scenario Detection Framework Using MITRE ATT&amp;CK Mapping.",
            "venue": "CCS",
            "pages": "4979-4981",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/MengOJL024",
            "doi": "10.1145/3658644.3691392",
            "ee": "https://doi.org/10.1145/3658644.3691392",
            "url": "https://dblp.org/rec/conf/ccs/MengOJL024",
            "abstract": "Traditional Network Intrusion Detection Systems (NIDS) often generate large volumes of alerts with redundancies and false positives, incapable of correlating detected attack actions. This adds difficulty for security analysts to construct a comprehensive understanding of multi-step attacks. To address these limitations, we present a novel MITRE-based Multi-step Attack Scenario Construction (M2ASK) algorithm that enhances cyber threat intelligence (CTI) by integrating MITRE ATT&CK tactic and technique mapping, facilitating the interpretation of multi-step attacks and informing response strategies. Our approach processes alert data from NIDSs, transforming it into a network communication graph. Graph-based correlation techniques are employed, combined with MITRE ATT&CK and Cyber Kill Chain stage profiling to construct comprehensive network attack scenarios. Our key contributions include: (1) the development of a Cyber Kill Chain based model for constructing attack scenarios; (2) the alert correlation approach based on MITRE ATT&CK tagging of attack actions.",
            "pdf_url": "",
            "keywords": [
                "Network Intrusion Detection",
                "Multi-Step Attacks",
                "MITRE ATT&CK",
                "Cyber Kill Chain",
                "Alert Correlation"
            ]
        },
        "url": "URL#256797",
        "sema_paperId": "ac9320bfcdb21b740ae0c6db47f69399fe17d871"
    },
    {
        "@score": "1",
        "@id": "256798",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "354/6457",
                        "text": "Andrea Mengascini"
                    },
                    {
                        "@pid": "392/3381",
                        "text": "Ryan Aurelio"
                    },
                    {
                        "@pid": "35/9056",
                        "text": "Giancarlo Pellegrino"
                    }
                ]
            },
            "title": "The Big Brother&apos;s New Playground: Unmasking the Illusion of Privacy in Web Metaverses from a Malicious User&apos;s Perspective.",
            "venue": "CCS",
            "pages": "2162-2176",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/MengasciniAP24",
            "doi": "10.1145/3658644.3690249",
            "ee": "https://doi.org/10.1145/3658644.3690249",
            "url": "https://dblp.org/rec/conf/ccs/MengasciniAP24",
            "abstract": "Metaverses are virtual worlds where users can engage in social exchanges, collaborate, or play games. Their clients now are JavaScript programs that run inside modern web browsers. They implement functionalities typical of multiplayer video games, like 3D and physics engines, requiring them to maintain complex data structures of objects in the browser\u2019s memory. Unfortunately, these objects can be accessed and manipulated by malicious users, allowing them to learn about events beyond the ones rendered on screen or to hijack the physics of the metaverse to spy on other users. In this paper, we propose one of the first comprehensive security assessments for web clients of metaverse platforms. We begin with a survey and selection of three metaverse platforms and introduce a software-centric threat modeling approach designed to identify the security-relevant entities. Then, we propose a JavaScript global object snapshot diffing technique to identify in-memory objects correlated with the attribute and design 10 attacks, of which eight successfully executed against at least one of the metaverses, enabling a malicious user to perform audio/video surveillance or continuous user position tracking \u2014 to mention a few \u2014 who could exacerbate current threats posed by stalkers and online abusers. Finally, we discuss the implications of our attacks should the metaverse become a business tool and possible solutions.",
            "keywords": [
                "Web Metaverses",
                "Privacy Vulnerabilities",
                "Malicious User Attacks",
                "In-Memory Object Manipulation",
                "User Surveillance"
            ]
        },
        "url": "URL#256798",
        "sema_paperId": "4a7981dd0448da7e6d602a0cd73ad7d393fc6ee3"
    },
    {
        "@score": "1",
        "@id": "256799",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "208/1995",
                        "text": "Samuel Mergendahl"
                    },
                    {
                        "@pid": "f/StephenFickas",
                        "text": "Stephen Fickas"
                    },
                    {
                        "@pid": "26/2418",
                        "text": "Boyana Norris"
                    },
                    {
                        "@pid": "137/3754",
                        "text": "Richard Skowyra"
                    }
                ]
            },
            "title": "Manipulative Interference Attacks.",
            "venue": "CCS",
            "pages": "4569-4583",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/MergendahlFNS24",
            "doi": "10.1145/3658644.3690246",
            "ee": "https://doi.org/10.1145/3658644.3690246",
            "url": "https://dblp.org/rec/conf/ccs/MergendahlFNS24",
            "abstract": "A \u03bc-kernel is an operating system (OS) paradigm that facilitates a strong cybersecurity posture for embedded systems. Unlike a monolithic OS such as Linux, a \u03bc-kernel reduces overall system privilege by deploying most OS functionality within isolated, userspace protection domains. Moreover, a \u03bc-kernel ensures confidentiality and integrity between protection domains (i.e., spatial isolation), and offers timing predictability for real-time tasks in mixed-criticality systems (i.e., temporal isolation). One popular \u03bc-kernel is seL4 which offers extensive formal guarantees of implementation correctness and flexible temporal budgeting mechanisms.",
            "pdf_url": "",
            "keywords": [
                "\u03bc-kernel",
                "Embedded Systems",
                "Cybersecurity Posture",
                "seL4",
                "Manipulative Interference Attacks"
            ]
        },
        "url": "URL#256799",
        "sema_paperId": "86883d3ed3b2bf89f0ba0250565d3ca090fabf68"
    },
    {
        "@score": "1",
        "@id": "256800",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "89/6100",
                        "text": "Jelena Mirkovic"
                    },
                    {
                        "@pid": "57/1201",
                        "text": "David M. Balenson"
                    },
                    {
                        "@pid": "127/9210",
                        "text": "Brian Kocoloski"
                    },
                    {
                        "@pid": "235/0927",
                        "text": "Geoff Lawler"
                    },
                    {
                        "@pid": "392/3321",
                        "text": "Chris Tran"
                    },
                    {
                        "@pid": "392/3405",
                        "text": "Joseph Barnes"
                    },
                    {
                        "@pid": "121/4901",
                        "text": "Yuri Pradkin"
                    },
                    {
                        "@pid": "24/761",
                        "text": "Terry Benzel"
                    },
                    {
                        "@pid": "17/9098",
                        "text": "Srivatsan Ravi"
                    },
                    {
                        "@pid": "175/1595",
                        "text": "Ganesh Sankaran"
                    },
                    {
                        "@pid": "392/3330",
                        "text": "Alba Regalado"
                    },
                    {
                        "@pid": "48/6854",
                        "text": "David R. Choffnes"
                    },
                    {
                        "@pid": "69/7759",
                        "text": "Daniel J. Dubois"
                    },
                    {
                        "@pid": "67/136-1",
                        "text": "Luis Garcia 0001"
                    }
                ]
            },
            "title": "Poster: Security and Privacy Heterogeneous Environment for Reproducible Experimentation (SPHERE).",
            "venue": "CCS",
            "pages": "5051-5053",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/MirkovicBKLTBPB24",
            "doi": "10.1145/3658644.3691409",
            "ee": "https://doi.org/10.1145/3658644.3691409",
            "url": "https://dblp.org/rec/conf/ccs/MirkovicBKLTBPB24",
            "abstract": "\u2014To transform cybersecurity and privacy research into a highly integrated, community-wide effort, researchers need a common, rich, representative research infrastructure that meets the needs across all members of the research community, and facilitates reproducible science. To meet researcher needs, USC Information Sciences Institute and Northeastern University have been funded by the NSF mid-scale research infrastructure program to build Security and Privacy Heterogeneous Environment for Reproducible Experimentation (SPHERE). This research infrastructure will offer access to an unprecedented variety of user-configurable hardware, software, and network resources, it will offer six user portals geared toward different populations of users, and it will support reproducible research via a combination of infrastructure services and community engagement activities.",
            "keywords": [
                "Cybersecurity Research Infrastructure",
                "Reproducible Science",
                "Privacy Research",
                "User-Configurable Resources",
                "Community Engagement"
            ]
        },
        "url": "URL#256800",
        "sema_paperId": "c6f6e2e98eda2b5b514b1e344d8e0de86a8ea673"
    },
    {
        "@score": "1",
        "@id": "256801",
        "info": {
            "authors": {
                "author": {
                    "@pid": "351/6874",
                    "text": "Seyed Mohammad Hadi Mirsadeghi"
                }
            },
            "title": "Poster: In-switch Defense against DNS Amplification DDoS Attacks.",
            "venue": "CCS",
            "pages": "4964-4966",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Mirsadeghi24",
            "doi": "10.1145/3658644.3691404",
            "ee": "https://doi.org/10.1145/3658644.3691404",
            "url": "https://dblp.org/rec/conf/ccs/Mirsadeghi24",
            "abstract": "Amplification Distributed Denial of Service (DDoS) attacks continue to be a high-impact force in the cybersecurity landscape. Programmable switching paves the way for revisiting the measurement of traffic integrity, offering a new opportunity to devise independent defense mechanisms against amplification traffic. A novel method capable of defending against DNS amplification distributed denial-of-service cyberattacks has been developed. The technique enables a programmable switch to independently drop up to 89% of untrusted DNS traffic. The coupling of programmable switching and sequence analysis to detect and drop amplification traffic at line rate appears to be both innovative and practical. A significant aspect of the methodology is that amplification traffic detection and prevention is accomplished in linear time. Another important advantage of this method is the suitability for applications of game theory as utility function. The contributions of this work can be summarized as follows: We present an intermediary algorithm that enables profile-agnostic defense against amplification traffic. The sequence analysis algorithm relies on parts of the packet payload to detect untrusted traffic at line rate. Furthermore, we gauge the potential benefit of in-switch sequence analysis that presents a fundamental step in the direction of more complex applications towards game theoretic trust.",
            "pdf_url": "",
            "keywords": [
                "DDoS Attacks",
                "DNS Amplification",
                "Programmable Switching",
                "Traffic Integrity",
                "Sequence Analysis"
            ]
        },
        "url": "URL#256801",
        "sema_paperId": "bfaaa734b160c2f3496ed871b5f29fe66f637582"
    },
    {
        "@score": "1",
        "@id": "256802",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "356/0904",
                        "text": "Nicolas Mohnblatt"
                    },
                    {
                        "@pid": "170/4315",
                        "text": "Alberto Sonnino"
                    },
                    {
                        "@pid": "284/2574",
                        "text": "Kobi Gurkan"
                    },
                    {
                        "@pid": "14/11314",
                        "text": "Philipp Jovanovic"
                    }
                ]
            },
            "title": "Arke: Scalable and Byzantine Fault Tolerant Privacy-Preserving Contact Discovery.",
            "venue": "CCS",
            "pages": "3212-3226",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/MohnblattSGJ24",
            "doi": "10.1145/3658644.3670289",
            "ee": "https://doi.org/10.1145/3658644.3670289",
            "url": "https://dblp.org/rec/conf/ccs/MohnblattSGJ24",
            "abstract": "Contact discovery is a crucial component of social applications, facilitating interactions between registered contacts. This work introduces Arke, a novel contact discovery scheme that addresses the limitations of existing solutions in terms of privacy, scalability, and reliance on trusted third parties. Arke ensures the unlinkability of user interactions, mitigates enumeration attacks, and operates without single points of failure or trust. Notably, Arke is the first contact discovery system whose performance is independent of the total number of users and the first that can operate in a Byzantine setting. It achieves its privacy goals through an unlinkable handshake mechanism built on top of an identity-based non-interactive key exchange. By leveraging a custom distributed architecture, Arke forgoes the expense of consensus to achieve scalability while maintaining consistency in an adversarial environment. Performance evaluations demonstrate that Arke provides a throughput of over 1,500 user requests per second at a latency of less than 0.5 seconds in a large geo-distributed setting which would allow privacy-preserving contact discovery for all of the popular messaging applications in one system.",
            "pdf_url": "",
            "keywords": [
                "Contact Discovery",
                "Privacy-Preserving",
                "Byzantine Fault Tolerance",
                "Scalability",
                "Unlinkable Handshake"
            ]
        },
        "url": "URL#256802"
    },
    {
        "@score": "1",
        "@id": "256803",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "231/1935",
                        "text": "Marius Momeu"
                    },
                    {
                        "@pid": "379/0311",
                        "text": "Simon Schn\u00fcckel"
                    },
                    {
                        "@pid": "392/3185",
                        "text": "Kai Angnis"
                    },
                    {
                        "@pid": "09/1231",
                        "text": "Michalis Polychronakis"
                    },
                    {
                        "@pid": "87/1029",
                        "text": "Vasileios P. Kemerlis"
                    }
                ]
            },
            "title": "Safeslab: Mitigating Use-After-Free Vulnerabilities via Memory Protection Keys.",
            "venue": "CCS",
            "pages": "1345-1359",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/MomeuSAPK24",
            "doi": "10.1145/3658644.3670279",
            "ee": "https://doi.org/10.1145/3658644.3670279",
            "url": "https://dblp.org/rec/conf/ccs/MomeuSAPK24",
            "abstract": "Restricting dangling pointers from accessing freed memory is a promising technique for mitigating use-after-free vulnerabilities in memory-unsafe programming languages. However, existing solutions suffer from high performance overheads, as they rely on conventional page table manipulation to make dangling pointers inaccessible. In this paper, we present Safeslab : a heap-hardening extension that aims to mitigate use-after-free vulnerabilities via a novel and efficient address aliasing approach. Safeslab assigns multiple virtual aliases to each memory page in the system, and manages their access rights via the recently introduced Memory Protection Keys hardware extension, which is designed to provide a fast alternative to page tables for memory management. This allows Safeslab to drastically reduce the number of page table modifications, while blocking dangling pointers efficiently. We integrated Safeslab into the Linux kernel, replacing its default heap allocator ( SLUB ). The results of our experimental evaluation with real-world benchmarks show that Safeslab incurs a negligible runtime overhead of up to 4% and moderate memory waste.",
            "keywords": [
                "Memory Safety",
                "Use-After-Free",
                "Heap Hardening",
                "Memory Protection Keys",
                "Address Aliasing"
            ]
        },
        "url": "URL#256803",
        "sema_paperId": "5f75e1e5799c580b38c39e756d82e598057c27a5"
    },
    {
        "@score": "1",
        "@id": "256804",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "267/9482",
                        "text": "Kevin Morio"
                    },
                    {
                        "@pid": "89/11274",
                        "text": "Robert K\u00fcnnemann"
                    }
                ]
            },
            "title": "SpecMon: Modular Black-Box Runtime Monitoring of Security Protocols.",
            "venue": "CCS",
            "pages": "2741-2755",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/MorioK24",
            "doi": "10.1145/3658644.3690197",
            "ee": "https://doi.org/10.1145/3658644.3690197",
            "url": "https://dblp.org/rec/conf/ccs/MorioK24",
            "abstract": "This work addresses the verification gap between formal protocol specifications and their real-world implementations by monitoring compliance with formal specifications.",
            "pdf_url": "",
            "keywords": [
                "Runtime Monitoring",
                "Security Protocols",
                "Formal Specifications",
                "Compliance Verification",
                "Black-Box Monitoring"
            ]
        },
        "url": "URL#256804"
    },
    {
        "@score": "1",
        "@id": "256805",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "250/9478",
                        "text": "Marwa Mouallem"
                    },
                    {
                        "@pid": "86/8318",
                        "text": "Ittay Eyal"
                    }
                ]
            },
            "title": "Asynchronous Authentication.",
            "venue": "CCS",
            "pages": "3257-3271",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/MouallemE24",
            "doi": "10.1145/3658644.3670328",
            "ee": "https://doi.org/10.1145/3658644.3670328",
            "url": "https://dblp.org/rec/conf/ccs/MouallemE24",
            "abstract": "A myriad of authentication mechanisms embody a continuous evolution from verbal passwords in ancient times to contemporary multi-factor authentication: Cryptocurrency wallets advanced from a single signing key to using a handful of well-kept credentials, and for online services, the infamous \"security questions'' were all but abandoned. Nevertheless, digital asset heists and numerous identity theft cases illustrate the urgent need to revisit the fundamentals of user authentication.",
            "pdf_url": "",
            "keywords": [
                "Asynchronous Authentication",
                "Digital Asset Security",
                "User Authentication",
                "Identity Theft",
                "Multi-Factor Authentication"
            ]
        },
        "url": "URL#256805"
    },
    {
        "@score": "1",
        "@id": "256806",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "213/2774",
                        "text": "Christian Mouchet"
                    },
                    {
                        "@pid": "245/4979",
                        "text": "Sylvain Chatel"
                    },
                    {
                        "@pid": "341/2109",
                        "text": "Lea N\u00fcrnberger"
                    },
                    {
                        "@pid": "35/9846",
                        "text": "Wouter Lueks"
                    }
                ]
            },
            "title": "Poster: Multiparty Private Set Intersection from Multiparty Homomorphic Encryption.",
            "venue": "CCS",
            "pages": "5003-5005",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/MouchetCNL24",
            "doi": "10.1145/3658644.3691405",
            "ee": "https://doi.org/10.1145/3658644.3691405",
            "url": "https://dblp.org/rec/conf/ccs/MouchetCNL24",
            "abstract": "We revisit the problem of constructing protocols for multiparty private set intersection (MPSI) in light of the recent advances in multiparty homomorphic encryption (MHE). In MPSI, N \u2265 2 parties jointly compute the intersection of their respective private set. Kissner and Song proposed an MHE-based MPSI scheme in 2005, but their approach was limited by the then-available HE schemes. Today, however, MHE schemes have become both more versatile and more efficient. As an early result, we implemented the MPSI approach of Kissner et al. with the recently proposed Helium framework (CCS 2024) for MHE-based MPC. We show that even this simple protocol can outperform the state-of-the-art implementation (in the passive-adversary setting) by Kolesnikov et al. (CCS 2017), both in terms of latency and communication cost.",
            "pdf_url": "",
            "keywords": [
                "Multiparty Private Set Intersection",
                "Multiparty Homomorphic Encryption",
                "Secure Computation",
                "Privacy-Preserving Protocols",
                "Latency and Communication Cost"
            ]
        },
        "url": "URL#256806",
        "sema_paperId": "fd73752ef2f1e561596bc2077fbd1b44f32a8073"
    },
    {
        "@score": "1",
        "@id": "256807",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "213/2774",
                        "text": "Christian Mouchet"
                    },
                    {
                        "@pid": "245/4979",
                        "text": "Sylvain Chatel"
                    },
                    {
                        "@pid": "66/7821",
                        "text": "Apostolos Pyrgelis"
                    },
                    {
                        "@pid": "01/4825",
                        "text": "Carmela Troncoso"
                    }
                ]
            },
            "title": "Helium: Scalable MPC among Lightweight Participants and under Churn.",
            "venue": "CCS",
            "pages": "3038-3052",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/MouchetCPT24",
            "doi": "10.1145/3658644.3670346",
            "ee": "https://doi.org/10.1145/3658644.3670346",
            "url": "https://dblp.org/rec/conf/ccs/MouchetCPT24",
            "abstract": "We introduce Helium, a novel framework that supports scalable secure multiparty computation (MPC) for lightweight participants and tolerates churn. Helium relies on multiparty homomorphic encryption (MHE) as its core building block. While MHE schemes have been well studied in theory, prior works fall short of addressing critical considerations paramount for adoption such as supporting resource-constrained and unstably connected participants. In this work, we systematize the requirements of MHE-based MPC protocols from a practical lens, and we propose a novel execution mechanism that addresses those considerations. We implement this execution mechanism in Helium, which makes it the first implemented framework to support MPC under network churn based solely on cryptographic assumptions. We show that a Helium network of 30 parties connected with 100Mbits/s links and experiencing a system-wide churn rate of 40 failures per minute can compute the product between a fixed 512x512 secret matrix (e.g., a collectively-trained private model) and a fresh secret vector (e.g., a feature vector) 8.3 times per second. This is ~1500 times faster than a state-of-the-art MPC framework operating under no churn.",
            "pdf_url": "",
            "keywords": [
                "Secure Multiparty Computation",
                "Multiparty Homomorphic Encryption",
                "Lightweight Participants",
                "Network Churn",
                "Scalability"
            ]
        },
        "url": "URL#256807"
    },
    {
        "@score": "1",
        "@id": "256808",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "76/5048",
                        "text": "Giovane C. M. Moura"
                    },
                    {
                        "@pid": "00/1175-2",
                        "text": "Thomas Daniels 0002"
                    },
                    {
                        "@pid": "238/7623",
                        "text": "Maarten Bosteels"
                    },
                    {
                        "@pid": "40/7634",
                        "text": "Sebastian Castro"
                    },
                    {
                        "@pid": "12/303",
                        "text": "Moritz M\u00fcller"
                    },
                    {
                        "@pid": "177/5650",
                        "text": "Thymen Wabeke"
                    },
                    {
                        "@pid": "249/7378",
                        "text": "Thijs van Den Hout"
                    },
                    {
                        "@pid": "06/10585",
                        "text": "Maciej Korczynski"
                    },
                    {
                        "@pid": "88/6355",
                        "text": "Georgios Smaragdakis"
                    }
                ]
            },
            "title": "Characterizing and Mitigating Phishing Attacks at ccTLD Scale.",
            "venue": "CCS",
            "pages": "2147-2161",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/MouraDBCMWHKS24",
            "doi": "10.1145/3658644.3690192",
            "ee": "https://doi.org/10.1145/3658644.3690192",
            "url": "https://dblp.org/rec/conf/ccs/MouraDBCMWHKS24",
            "abstract": "Phishing on the web is a model of social engineering and an attack vector for getting access to sensitive and financial data of individuals and corporations. Phishing has been identified as one of the prime cyber threats in recent years. With the goal to effectively identify and mitigate phishing as early as possible, we present in this paper a longitudinal analysis of phishing attacks from the vantage point of three country-code top-level domain (ccTLD) registries that manage more than 8 million active domains \u2013 namely the Netherlands\u2019 .nl , Ireland\u2019s .ie , and Belgium\u2019s .be . We perform a longitudinal analysis on phishing attacks spanning up to 10 years, based on more than 28 thousand phishing domains. Our results show two major attack strategies: national companies and organizations are far more often impersonated using malicious registered domains under their country\u2019s own ccTLD, which enables better mimicry of the impersonated company. In stark contrast, international companies are impersonated using any domains that can be compromised, reducing overall mimicry but bearing no registration and financial costs. Although most research works focus on detecting new domain names, we show that 80% of phishing attacks in the studied ccTLDs employ compromised domain names. We find banks, financial institutions, and high-tech giant companies at the top of the most impersonated targets. We also show the impact of ccTLDs\u2019 registration and abuse handling policies on preventing and mitigating phishing attacks, and that mitigation is complex and performed at both web and DNS level at different intermediaries. Last, our results provide a unique opportunity for ccTLDs to compare and revisit their policies and impacts, with the goal of improving mitigation procedures.",
            "keywords": [
                "Phishing Attacks",
                "ccTLD Analysis",
                "Domain Impersonation",
                "Compromised Domains",
                "Mitigation Strategies"
            ]
        },
        "url": "URL#256808",
        "sema_paperId": "41d09dac28958a5b4f8b6a5da91fbed657388254"
    },
    {
        "@score": "1",
        "@id": "256809",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "221/4551",
                        "text": "Nico Naus"
                    },
                    {
                        "@pid": "01/8190",
                        "text": "Freek Verbeek"
                    },
                    {
                        "@pid": "392/3418",
                        "text": "Sagar Atla"
                    },
                    {
                        "@pid": "61/2985",
                        "text": "Binoy Ravindran"
                    }
                ]
            },
            "title": "Poster: Formally Verified Binary Lifting to P-Code.",
            "venue": "CCS",
            "pages": "4973-4975",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/NausVAR24",
            "doi": "10.1145/3658644.3691386",
            "ee": "https://doi.org/10.1145/3658644.3691386",
            "url": "https://dblp.org/rec/conf/ccs/NausVAR24",
            "abstract": "Analysis of binary software plays a critical role in software security. Reverse engineers analyze binaries to discover vulnerabilities, patch legacy software, and detect malware. Most of the reverse engineering tools have been developed from a practical point of view, and do not provide any guarantees with their results. Recently, formally verified reverse engineering and decompilation have gained traction. These formal tools are for the most part proof-of-concept systems not yet suitable for real-world reverse-engineering tasks. In this poster, we explore the idea of formalizing part of an existing decompilation tool instead. We focus on the lifting from assembly to the IR P-Code in one of the most popular decompilers, Ghidra. This step occurs immediately after disassembly. We are developing a proof system inside the Isabelle theorem prover, to automatically prove semantical equivalence between the assembly and P-Code instructions. We leverage machine-learned x86-64 semantics, to stay as close as possible to actual CPU behavior. This approach has uncovered several shortcomings in Ghidra's P-Code and the lifting it performs. By using a theorem prover, we obtain guarantees that our system of formal semantics and lifting is internally consistent. This work brings the powerful guarantees that formal methods provide in reverse engineering research to the real world.",
            "pdf_url": "",
            "keywords": [
                "Reverse Engineering",
                "Formal Verification",
                "Decompilation",
                "P-Code",
                "Assembly Lifting"
            ]
        },
        "url": "URL#256809",
        "sema_paperId": "9e54fa31d706289db93942c36919abdf9da62c26"
    },
    {
        "@score": "1",
        "@id": "256810",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "158/0425",
                        "text": "Mahmoud Nazzal"
                    },
                    {
                        "@pid": "115/8715",
                        "text": "Issa Khalil"
                    },
                    {
                        "@pid": "39/1037",
                        "text": "Abdallah Khreishah"
                    },
                    {
                        "@pid": "153/5204",
                        "text": "NhatHai Phan"
                    }
                ]
            },
            "title": "PromSec: Prompt Optimization for Secure Generation of Functional Source Code with Large Language Models (LLMs).",
            "venue": "CCS",
            "pages": "2266-2280",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/NazzalKKP24",
            "doi": "10.1145/3658644.3690298",
            "ee": "https://doi.org/10.1145/3658644.3690298",
            "url": "https://dblp.org/rec/conf/ccs/NazzalKKP24",
            "abstract": "The capability of generating high-quality source code using large language models (LLMs) reduces software development time and costs. However, recent literature and our empirical investigation in this work show that while LLMs can generate functioning code, they inherently tend to introduce security vulnerabilities, limiting their potential. This problem is mainly due to their training on massive open-source corpora exhibiting insecure and inefficient programming practices. Therefore, automatic optimization of LLM prompts for generating secure and functioning code is a demanding need. This paper introduces PromSec, an algorithm for <u>prom</u>pt optimization for <u>sec</u>ure and functioning code generation using LLMs. In PromSec, we combine 1) code vulnerability clearing using a generative adversarial graph neural network, dubbed as gGAN, to fix and reduce security vulnerabilities in generated codes and 2) code generation using an LLM into an interactive loop, such that the outcome of the gGAN drives the LLM with enhanced prompts to generate secure codes while preserving their functionality. Introducing a new contrastive learning approach in gGAN, we formulate the code-clearing and generation loop as a dual-objective optimization problem, enabling PromSec to notably reduce the number of LLM inferences. As a result, PromSec becomes a cost-effective and practical solution for generating secure and functioning codes.",
            "pdf_url": "",
            "keywords": [
                "Code Generation",
                "Security Vulnerabilities",
                "Prompt Optimization",
                "Generative Adversarial Networks",
                "Functional Source Code"
            ]
        },
        "url": "URL#256810"
    },
    {
        "@score": "1",
        "@id": "256811",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "336/6239",
                        "text": "Truong Son Nguyen"
                    },
                    {
                        "@pid": "130/1339",
                        "text": "Lun Wang"
                    },
                    {
                        "@pid": "89/10042",
                        "text": "Evgenios M. Kornaropoulos"
                    },
                    {
                        "@pid": "187/5706",
                        "text": "Ni Trieu"
                    }
                ]
            },
            "title": "AITIA: Efficient Secure Computation of Bivariate Causal Discovery.",
            "venue": "CCS",
            "pages": "4420-4434",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/NguyenWKT24",
            "doi": "10.1145/3658644.3670337",
            "ee": "https://doi.org/10.1145/3658644.3670337",
            "url": "https://dblp.org/rec/conf/ccs/NguyenWKT24",
            "abstract": "Researchers across various fields seek to understand causal relationships but often find controlled experiments impractical. To address this, statistical tools for causal discovery from naturally observed data have become crucial. Non-linear regression models, such as Gaussian process regression, are commonly used in causal inference but have limitations due to high costs when adapted for secure computation. Support vector regression (SVR) offers an alternative but remains costly in an Multi-party computation context due to conditional branches and support vector updates.",
            "pdf_url": "",
            "keywords": [
                "Causal Discovery",
                "Bivariate Analysis",
                "Secure Computation",
                "Non-linear Regression",
                "Support Vector Regression (SVR)"
            ]
        },
        "url": "URL#256811"
    },
    {
        "@score": "1",
        "@id": "256812",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "64/7599",
                        "text": "Keiichi Ochiai"
                    },
                    {
                        "@pid": "36/3767",
                        "text": "Masayuki Terada"
                    }
                ]
            },
            "title": "Poster: End-to-End Privacy-Preserving Vertical Federated Learning using Private Cross-Organizational Data Collaboration.",
            "venue": "CCS",
            "pages": "4955-4957",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/OchiaiT24",
            "doi": "10.1145/3658644.3691383",
            "ee": "https://doi.org/10.1145/3658644.3691383",
            "url": "https://dblp.org/rec/conf/ccs/OchiaiT24",
            "abstract": "As data utilization in organizations is advancing in various fields, insights that data brings will be more diverse when it is sourced through collaboration across different organizations. Federated learning, a machine learning method with distributed data across organizations, with local differential privacy protects privacy by sharing only the model parameters and the information necessary for model update, without having to share the data each organization holds. However, there is a problem with local differential privacy, where the amount of noise increases, leading to the degradation in model accuracy. In this paper, we propose a method of reducing the impact of noise compared to conventional federated learning by leveraging private cross-organizational data collaboration, called Private Cross-aggregation Technology (PCT). PCT combines Private Set Intersection Cardinality, Trusted Execution Environment and Differential Privacy, and outputs a cross-tabulation table that is private from input to output. Our method consists of two steps: (1) creating a private cross-tabulation table using PCT, and (2) training a ML using the private cross-tabulation table. The experiment results showed that (1) the classification accuracy of the proposed method was higher than that of the baseline method in situations where the privacy budget is limited, and (2) the computation time of the proposed method was shorter than that of the baseline method.",
            "pdf_url": "",
            "keywords": [
                "Federated Learning",
                "Privacy-Preserving",
                "Cross-Organizational Collaboration",
                "Local Differential Privacy",
                "Private Cross-Aggregation Technology (PCT)"
            ]
        },
        "url": "URL#256812",
        "sema_paperId": "a21d26ec3fdca7e85b299b2edcdc567574aac17d"
    },
    {
        "@score": "1",
        "@id": "256813",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "392/2962",
                        "text": "Joel Osher"
                    },
                    {
                        "@pid": "242/3127",
                        "text": "James K. Holland"
                    },
                    {
                        "@pid": "11/5469",
                        "text": "Nicholas Hopper"
                    }
                ]
            },
            "title": "Poster: Gift or Curse? Safety Slider Settings in Tor Website Fingerprinting.",
            "venue": "CCS",
            "pages": "4997-4999",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/OsherHH24",
            "doi": "10.1145/3658644.3691388",
            "ee": "https://doi.org/10.1145/3658644.3691388",
            "url": "https://dblp.org/rec/conf/ccs/OsherHH24",
            "abstract": "Website Fingerprinting (WF) attacks on the Tor anonymity network identify websites accessed via Tor by recognizing the traffic patterns -- sequences of packet directions and timing -- associated with accessing a particular site. Previous work has shown that modern WF attacks can function when trained and tested against consistent high or low settings of the Tor \"security slider,'' which impacts the traffic pattern produced by a download. In this work we show that training and testing against traces with a mixture of settings can improve the performance of WF attacks in some cases. Thus research seeking to evaluate WF defenses should consider both scenarios to ensure the most consistent evaluations.",
            "pdf_url": "",
            "keywords": [
                "Website Fingerprinting",
                "Tor Network",
                "Traffic Pattern Analysis",
                "Security Slider Settings",
                "Anonymity Attacks"
            ]
        },
        "url": "URL#256813",
        "sema_paperId": "1d276fa986c78d58f65402653389f26d195e5d30"
    },
    {
        "@score": "1",
        "@id": "256814",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "p/CharalamposPapamanthou",
                        "text": "Charalampos Papamanthou"
                    },
                    {
                        "@pid": "165/9469",
                        "text": "Shravan Srinivasan"
                    },
                    {
                        "@pid": "176/5570",
                        "text": "Nicolas Gailly"
                    },
                    {
                        "@pid": "373/6469",
                        "text": "Ismael Hishon-Rezaizadeh"
                    },
                    {
                        "@pid": "373/6129",
                        "text": "Andrus Salumets"
                    },
                    {
                        "@pid": "373/6438",
                        "text": "Stjepan Golemac"
                    }
                ]
            },
            "title": "Reckle Trees: Updatable Merkle Batch Proofs with Applications.",
            "venue": "CCS",
            "pages": "1538-1551",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/PapamanthouSGHS24",
            "doi": "10.1145/3658644.3670354",
            "ee": "https://doi.org/10.1145/3658644.3670354",
            "url": "https://dblp.org/rec/conf/ccs/PapamanthouSGHS24",
            "abstract": "We propose Reckle trees, a new vector commitment based on succinct RECursive arguments and MerKLE trees. Reckle trees' distinguishing feature is their support for succinct batch proofs that are updatable - enabling new applications in the blockchain setting where a proof needs to be computed and efficiently maintained over a moving stream of blocks. Our technical approach is based on embedding the computation of the batch hash inside the recursive Merkle verification via a hash-based accumulator called canonical hashing. Due to this embedding, our batch proofs can be updated in logarithmic time, whenever a Merkle leaf (belonging to the batch or not) changes, by maintaining a data structure that stores previously-computed recursive proofs. Assuming enough parallelism, our batch proofs are also computable in O(log n) parallel time - independent of the size of the batch. As a natural extension of Reckle trees, we also introduce Reckle+ trees. Reckle+ trees provide updatable and succinct proofs for certain types of Map/Reduce computations. In this setting, a prover can commit to a memory M and produce a succinct proof for a Map/Reduce computation over a subsetIof M. The proof can be efficiently updated wheneverIor M changes.",
            "pdf_url": "",
            "keywords": [
                "Reckle Trees",
                "Vector Commitment",
                "Batch Proofs",
                "Updatable Proofs",
                "Map/Reduce Computations"
            ]
        },
        "url": "URL#256814"
    },
    {
        "@score": "1",
        "@id": "256815",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "283/4885",
                        "text": "Christodoulos Pappas"
                    },
                    {
                        "@pid": "18/9002",
                        "text": "Dimitrios Papadopoulos 0001"
                    }
                ]
            },
            "title": "Sparrow: Space-Efficient zkSNARK for Data-Parallel Circuits and Applications to Zero-Knowledge Decision Trees.",
            "venue": "CCS",
            "pages": "3110-3124",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Pappas024",
            "doi": "10.1145/3658644.3690318",
            "ee": "https://doi.org/10.1145/3658644.3690318",
            "url": "https://dblp.org/rec/conf/ccs/Pappas024",
            "abstract": "Space-efficientSNARKs aim to reduce the prover's space overhead which is one the main obstacles for deploying SNARKs in practice, as it can be prohibitively large (e.g., orders of magnitude larger than natively performing the computation). In this work, we propose Sparrow, a novel space-efficient zero-knowledge SNARK for data-parallel arithmetic circuits with two attractive features: (i) it is the first space-efficient scheme where, for a given field, the prover overhead increases with a multiplicativesublogarithmicfactor as the circuit size increases, and (ii) compared to prior space-efficient SNARKs that work for arbitrary arithmetic circuits, it achieves prover spaceasymptotically smallerthan the circuit size itself. Our key building block is a novel space-efficient sumcheck argument with improved prover time which may be of independent interest. Our experimental results for three use cases (arbitrary data parallel circuits, multiplication trees, batch SHA256 hashing) indicate Sparrow outperforms the prior state-of-the-art space-efficient SNARK for arithmetic circuits Gemini (Bootle et al., EUROCRYPT'22) by 3.2-28.7x in total prover space and 3.1-11.3x in prover time. We then use Sparrow to buildzero-knowledge proofs of tree training and prediction, relying on its space efficiency to scale to large datasets and forests of multiple trees. Compared to a (non-space-efficient) optimal-time SNARK based on the GKR protocol, we observe prover space reduction of 16-240x for tree training while maintaining essentially the same prover and verifier times and proof size. Even more interestingly,our prover requires comparable space to natively perform the underlying computation. E.g., for a 400MB dataset, our prover only needs 1.4x more space than the native computation.",
            "pdf_url": "",
            "keywords": [
                "Zero-Knowledge SNARKs",
                "Space Efficiency",
                "Data-Parallel Circuits",
                "Prover Overhead",
                "Decision Trees"
            ]
        },
        "url": "URL#256815"
    },
    {
        "@score": "1",
        "@id": "256816",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "04/773",
                        "text": "Sarvar Patel"
                    },
                    {
                        "@pid": "p/GiuseppePersiano",
                        "text": "Giuseppe Persiano"
                    },
                    {
                        "@pid": "175/1759",
                        "text": "Joon Young Seo"
                    },
                    {
                        "@pid": "176/7649",
                        "text": "Kevin Yeo"
                    }
                ]
            },
            "title": "Efficient Secret Sharing for Large-Scale Applications.",
            "venue": "CCS",
            "pages": "3065-3079",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/PatelPSY24",
            "doi": "10.1145/3658644.3670379",
            "ee": "https://doi.org/10.1145/3658644.3670379",
            "url": "https://dblp.org/rec/conf/ccs/PatelPSY24",
            "abstract": "Threshold secret sharing enables distributing a message tonparties such that no subset of fewer thantparties can learn the message, whereas any subset of at leasttparties can recover the message. Despite being a fundamental primitive, secret sharing still suffers from one significant drawback, where its message reconstruction algorithm is computationally expensive for large privacy thresholdst. In this paper, we aim to address this significant drawback.",
            "pdf_url": "",
            "keywords": [
                "Secret Sharing",
                "Threshold Scheme",
                "Message Reconstruction",
                "Computational Efficiency",
                "Large-Scale Applications"
            ]
        },
        "url": "URL#256816"
    },
    {
        "@score": "1",
        "@id": "256817",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "357/3768",
                        "text": "Thorsten Peinemann"
                    },
                    {
                        "@pid": "332/2354",
                        "text": "Moritz Kirschte"
                    },
                    {
                        "@pid": "319/2658",
                        "text": "Joshua Stock"
                    },
                    {
                        "@pid": "150/0652",
                        "text": "Carlos Cotrini"
                    },
                    {
                        "@pid": "77/8938",
                        "text": "Esfandiar Mohammadi"
                    }
                ]
            },
            "title": "S-BDT: Distributed Differentially Private Boosted Decision Trees.",
            "venue": "CCS",
            "pages": "288-302",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/PeinemannKSCM24",
            "doi": "10.1145/3658644.3690301",
            "ee": "https://doi.org/10.1145/3658644.3690301",
            "url": "https://dblp.org/rec/conf/ccs/PeinemannKSCM24",
            "abstract": "We introduce S-BDT: a novel $(\\varepsilon,\\delta)$-differentially private distributed gradient boosted decision tree (GBDT) learner that improves the protection of single training data points (privacy) while achieving meaningful learning goals, such as accuracy or regression error (utility). S-BDT uses less noise by relying on non-spherical multivariate Gaussian noise, for which we show tight subsampling bounds for privacy amplification and incorporate that into a R\\'enyi filter for individual privacy accounting. We experimentally reach the same utility while saving $50\\%$ in terms of epsilon for $\\varepsilon \\le 0.5$ on the Abalone regression dataset (dataset size $\\approx 4K$), saving $30\\%$ in terms of epsilon for $\\varepsilon \\le 0.08$ for the Adult classification dataset (dataset size $\\approx 50K$), and saving $30\\%$ in terms of epsilon for $\\varepsilon\\leq0.03$ for the Spambase classification dataset (dataset size $\\approx 5K$). Moreover, we show that for situations where a GBDT is learning a stream of data that originates from different subpopulations (non-IID), S-BDT improves the saving of epsilon even further.",
            "keywords": [
                "Differential Privacy",
                "Boosted Decision Trees",
                "Distributed Learning",
                "Privacy Amplification",
                "Non-IID Data"
            ]
        },
        "url": "URL#256817",
        "sema_paperId": "efd1bdf17c10ea37e5ca62d76394a93940840605"
    },
    {
        "@score": "1",
        "@id": "256818",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "392/3004",
                        "text": "Chaoyuan Peng"
                    },
                    {
                        "@pid": "203/0794",
                        "text": "Muhui Jiang"
                    },
                    {
                        "@pid": "68/5597-12",
                        "text": "Lei Wu 0012"
                    },
                    {
                        "@pid": "15/7381",
                        "text": "Yajin Zhou"
                    }
                ]
            },
            "title": "Toss a Fault to BpfChecker: Revealing Implementation Flaws for eBPF runtimes with Differential Fuzzing.",
            "venue": "CCS",
            "pages": "3928-3942",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/PengJ0Z24",
            "doi": "10.1145/3658644.3690237",
            "ee": "https://doi.org/10.1145/3658644.3690237",
            "url": "https://dblp.org/rec/conf/ccs/PengJ0Z24",
            "abstract": "eBPF is a revolutionary technology that can run sandboxed programs in a privileged context and has an extensive range of applications, such as network monitoring on Linux kernel, denial-of-service protection on Windows, and the execution mechanism of smart contracts on blockchain. However, implementation flaws in eBPF have broad-reaching impact and serious consequences. Prior studies primarily focus on the memory safety of the eBPF runtimes, but few can detect implementation flaws (i.e., whether the implementation is correct). Meanwhile, existing implementation flaws detecting methods predominantly address bugs in the verifier, neglecting bugs in other components (i.e., the interpreter and the JIT compiler). In this paper, we present BpfChecker, a differential fuzzing framework to detect implementation flaws in the eBPF runtimes. It utilizes eBPF programs as input, performing differential testing for the critical states across various eBPF runtimes to uncover implementation flaws. To enhance the semantics of generated programs, we devise a lightweight intermediate representation and perform constrained mutations under the guidance of error messages. We have implemented a prototype of BpfChecker and extensively evaluated it on the three eBPF runtimes (i.e., Solana rBPF, vanilla rBPF, Windows eBPF). As a result, we have uncovered 28 new implementation flaws, received 2 CVEs and 800,000 bounty with developers' acknowledgment. More importantly, 2 of the newly found bugs can be used to create divergences in the execution layer of the Solana network.",
            "pdf_url": "",
            "keywords": [
                "eBPF Runtimes",
                "Differential Fuzzing",
                "Implementation Flaws",
                "BpfChecker",
                "Error Message Guidance"
            ]
        },
        "url": "URL#256818",
        "sema_paperId": "a03cffd22790453c7b7aff6fa6a917e7da4d51a3"
    },
    {
        "@score": "1",
        "@id": "256819",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "353/0383",
                        "text": "Ryan Pickren"
                    },
                    {
                        "@pid": "207/6604",
                        "text": "Animesh Chhotaray"
                    },
                    {
                        "@pid": "53/10825",
                        "text": "Frank Li 0001"
                    },
                    {
                        "@pid": "89/4316",
                        "text": "Saman A. Zonouz"
                    },
                    {
                        "@pid": "12/6354",
                        "text": "Raheem Beyah"
                    }
                ]
            },
            "title": "Release the Hounds! Automated Inference and Empirical Security Evaluation of Field-Deployed PLCs Using Active Network Data.",
            "venue": "CCS",
            "pages": "3674-3688",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/PickrenCLZB24",
            "doi": "10.1145/3658644.3690195",
            "ee": "https://doi.org/10.1145/3658644.3690195",
            "url": "https://dblp.org/rec/conf/ccs/PickrenCLZB24",
            "abstract": "Surveying field-deployed Industrial Control System (ICS) equipment has numerous security applications, including attack-surface management and measuring the adoption of vulnerability patches. However, discovering real-world devices using massive Internet-scale scan datasets is tedious and error-prone. We introduce PL-CHound , a novel ICS asset discovery solution designed to automatically reveal elusive ICS devices hiding in network data collected by Internet-scale scanners such as Censys or Shodan. Our solution systematically uncovers indirect evidence of controllers using subtle network-based indicators and temporally-resistant signatures that are often overlooked in prior work. We present PLCHound \u2019s architecture, experimentally verify its accuracy, and explore the security advantages of enhanced device discovery. We also use PL-CHound to perform the largest comprehensive examination of the publicly-reachable population of ICS devices by popular vendors. Our results reveal that the industry-accepted estimations and latest published papers undercount the true number of public devices by up to 37x. We also find that 95.88% of devices expose protocols that cause them to be remotely vulnerable to recent critical CVEs.",
            "keywords": [
                "Industrial Control Systems",
                "Asset Discovery",
                "Network Data Analysis",
                "Vulnerability Exposure",
                "Critical CVEs"
            ]
        },
        "url": "URL#256819",
        "sema_paperId": "ea8917890b4343efeb51817cf91d15642d37e1b6"
    },
    {
        "@score": "1",
        "@id": "256820",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "227/3373",
                        "text": "Maura Pintor"
                    },
                    {
                        "@pid": "218/5156",
                        "text": "Matthew Jagielski"
                    },
                    {
                        "@pid": "03/8495",
                        "text": "Xinyun Chen"
                    }
                ]
            },
            "title": "AISec &apos;24: 17th ACM Workshop on Artificial Intelligence and Security.",
            "venue": "CCS",
            "pages": "4905-4906",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/PintorJC24",
            "doi": "10.1145/3658644.3691545",
            "ee": "https://doi.org/10.1145/3658644.3691545",
            "url": "https://dblp.org/rec/conf/ccs/PintorJC24",
            "abstract": "The use of Artificial Intelligence (AI) and Machine Learning (ML) has been the center of the most outstanding advancements in the last years. The ability to analyze considerable streams of data in real time makes these technologies the most promising tool in many domains, including cybersecurity. As an outstanding example, ML can be used for identifying malware because of its ability to detect patterns otherwise difficult to see for humans and hard-coded rules. However, the use of AI and ML in security-relevant domains raised rightful concerns about their trustworthiness and robustness, espe- cially in front of adaptive attackers. Additionally, privacy threats are now emerging as a crucial aspect and need proper testing and possibly mitigation to prevent data stealing and leakage of sensitive information. AISec provides a venue for presenting and discussing new developments in the intersection of security and privacy with AI and ML. The AISec'24 workshop proceedings are available at: https://dl.acm.org/doi/proceedings/10.1145/3658644.3691545.",
            "pdf_url": "",
            "keywords": [
                "AI in Cybersecurity",
                "Malware Detection",
                "Trustworthiness of AI",
                "Privacy Threats",
                "Data Leakage Mitigation"
            ]
        },
        "url": "URL#256820",
        "sema_paperId": "5dae1d04a6ca86b21ad5d8c67a63865c2813c016"
    },
    {
        "@score": "1",
        "@id": "256821",
        "info": {
            "authors": {
                "author": {
                    "@pid": "263/9673",
                    "text": "Pansilu Pitigalaarachchi"
                }
            },
            "title": "Symbolic Execution for Dynamic Kernel Analysis.",
            "venue": "CCS",
            "pages": "5104-5106",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Pitigalaarachchi24",
            "doi": "10.1145/3658644.3690860",
            "ee": "https://doi.org/10.1145/3658644.3690860",
            "url": "https://dblp.org/rec/conf/ccs/Pitigalaarachchi24",
            "abstract": "Linux kernel-based operating systems have a significant market share in the domains of enterprise/web servers, supercomputers, and mobile devices. Being a large open-source project, the Linux kernel undergoes many changes, with new functionalities (e.g. Support for Rust in the kernel) being added in each release. While the security analysis of the Linux kernel is of critical importance, it is a challenging task. Although symbolic execution based techniques have been used for kernel analysis in the past decade, existing tools have fundamental limitations in kernel thread analysis, such as the need for instrumentation of the target kernel and the lack of user control, command, and access to the target execution. This dissertation aims to address these limitations by proposing a new kernel symbolic execution engine for kernel thread analysis. We then intend to leverage the new engine to conduct a security analysis of Rust drivers written for the Linux kernel. As part of the analysis, we will perform symbolic execution on Rust drivers, detect bugs, and evaluate whether the integration of Rust drivers with the rest of the kernel, written in C, results in any security vulnerabilities.",
            "pdf_url": "",
            "keywords": [
                "Kernel Analysis",
                "Symbolic Execution",
                "Linux Kernel",
                "Rust Drivers",
                "Security Vulnerabilities"
            ]
        },
        "url": "URL#256821",
        "sema_paperId": "895af942f68820a10644a6da68c9d71e94c8986d"
    },
    {
        "@score": "1",
        "@id": "256822",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "241/9467",
                        "text": "Abdullah Qasem"
                    },
                    {
                        "@pid": "d/MDebbabi",
                        "text": "Mourad Debbabi"
                    },
                    {
                        "@pid": "87/2938",
                        "text": "Andrei Soeanu"
                    }
                ]
            },
            "title": "OctopusTaint: Advanced Data Flow Analysis for Detecting Taint-Based Vulnerabilities in IoT/IIoT Firmware.",
            "venue": "CCS",
            "pages": "2355-2369",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/QasemDS24",
            "doi": "10.1145/3658644.3690307",
            "ee": "https://doi.org/10.1145/3658644.3690307",
            "url": "https://dblp.org/rec/conf/ccs/QasemDS24",
            "abstract": "The widespread integration of Internet of Things (IoT) and Industrial IoT (IIoT) devices in respectively home and business environments offers both benefits and perils. While these devices, such as IP cameras and network routers improve operational efficiency with their user-friendly web interfaces, they also broaden the potential for cybersecurity vulnerabilities. Recent studies highlight the vulnerability of these devices to taint-based attacks, demonstrating that even attackers with limited permissions can gain control of a device. Currentstate-of-the-artsolutions for mitigating these risks primarily utilize Dynamic Symbolic Execution (DSE). Although effective, DSE is computationally costly and challenging for large-scale analysis. Besides, during inspection, these approaches typically exhibit over-taint behavior by producing a large number of alerts, many of which are false positives due to ineffective handling of sanitization measures that might be in place. To overcome these limitations, we introduceOctopusTaint,an innovative static-based taint analysis approach that integrates advanced data flow analysis with backtracking techniques.OctopusTaintis distinguished by its integration of a sanitization inspection module and sophisticated post-processing filters. These features are specifically designed to minimize false positives effectively while ensuring the accurate identification of genuine security threats.OctopusTaintalso excels in tracking transformed tainted inputs across NVRAM, identifying new user-defined taint source functions while addressing the challenges associated with indirect calls and aliasing. Through comparative performance evaluations,OctopusTaintdemonstrates superior performance over the currentstate-of-the-artsolutions,SaTC,EmTaint,andMangoDFA.It reports genuine extra tainted sinks in considerable less time (24% faster). Furthermore,OctopusTaintidentifies 82% of tainted sinks withinEmTaint's labeled dataset while exhibiting its advanced capability in sanitization inspection. It correctly flags as sanitized 320 sinks, which were misidentified as genuine alerts byEmTaint.Furthermore,OctopusTaintuncovers additional candidates overlooked byEmTaint,leveraging its enhanced detection mechanisms for new taint sources.OctopusTaintsuccessfully identifies 142n-day vulnerabilities previously reported bySaTCandEmTaint,in addition to discovering dozens of potential 0-day candidates.",
            "pdf_url": "",
            "keywords": [
                "IoT Security",
                "IIoT Firmware",
                "Taint Analysis",
                "False Positives",
                "Vulnerability Detection"
            ]
        },
        "url": "URL#256822",
        "sema_paperId": "6f7411d514501b0050111d6e1d21dbc30edb4cbc"
    },
    {
        "@score": "1",
        "@id": "256823",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "219/5724",
                        "text": "Tamjid Al Rahat"
                    },
                    {
                        "@pid": "30/4550-1",
                        "text": "Yu Feng 0001"
                    },
                    {
                        "@pid": "39/5423-1",
                        "text": "Yuan Tian 0001"
                    }
                ]
            },
            "title": "AuthSaber: Automated Safety Verification of OpenID Connect Programs.",
            "venue": "CCS",
            "pages": "2949-2962",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Rahat0024",
            "doi": "10.1145/3658644.3670318",
            "ee": "https://doi.org/10.1145/3658644.3670318",
            "url": "https://dblp.org/rec/conf/ccs/Rahat0024",
            "abstract": "Single Sign-On (SSO)-based authentication protocols, like OpenID Connect (OIDC), play a crucial role in enhancing security and privacy in today's interconnected digital world, gaining widespread adoption among the majority of prominent authentication service providers. These protocols establish a structured framework for verifying and authenticating the identities of individuals, organizations, and devices, while avoiding the necessity of sharing sensitive credentials (e.g., passwords) with external entities. However, the security guarantees of these protocols rely on their proper implementation, and real-world implementations can, and indeed often do, contain logical programming errors leading to severe attacks, including authentication bypass and user account takeover. In response to this challenge, we presentAuthSaber, an automated verifier designed to assess the real-world OIDC protocol implementations against their standard safety specifications in a scalable manner.AuthSaberaddresses the challenges of expressiveness for OIDC properties, modeling multi-party interactions, and automation by first designing a novel specification language based on linear temporal logic, leveraging an automaton-based approach to constrain the space of possible interactions between OIDC entities, and incorporating several domain-specific transformations to obtain programs and properties that can be directly reasoned about by software model checkers. We evaluateAuthSaberon the 15 most popular and widely used OIDC libraries and discover 16 previously unknown vulnerabilities, all of which are responsively disclosed to the developers. Five categories of these vulnerabilities also led to new CVEs.",
            "pdf_url": "",
            "keywords": [
                "OpenID Connect",
                "Automated Verification",
                "Safety Specifications",
                "Vulnerabilities Detection",
                "Authentication Bypass"
            ]
        },
        "url": "URL#256823",
        "sema_paperId": "9155c62b7e4be6816999b6feb334c0e17c411347"
    },
    {
        "@score": "1",
        "@id": "256824",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "185/3910",
                        "text": "Arvind S. Raj"
                    },
                    {
                        "@pid": "353/7674",
                        "text": "Wil Gibbs"
                    },
                    {
                        "@pid": "296/5462",
                        "text": "Fangzhou Dong"
                    },
                    {
                        "@pid": "224/1548",
                        "text": "Jayakrishna Menon Vadayath"
                    },
                    {
                        "@pid": "224/5428",
                        "text": "Michael Tompkins"
                    },
                    {
                        "@pid": "198/2004",
                        "text": "Steven Wirsz"
                    },
                    {
                        "@pid": "07/8499",
                        "text": "Yibo Liu"
                    },
                    {
                        "@pid": "211/9994",
                        "text": "Zhenghao Hu"
                    },
                    {
                        "@pid": "41/2797",
                        "text": "Chang Zhu"
                    },
                    {
                        "@pid": "331/2470",
                        "text": "Gokulkrishna Praveen Menon"
                    },
                    {
                        "@pid": "94/7563",
                        "text": "Brendan Dolan-Gavitt"
                    },
                    {
                        "@pid": "28/8280",
                        "text": "Adam Doup\u00e9"
                    },
                    {
                        "@pid": "127/9829",
                        "text": "Ruoyu Wang 0001"
                    },
                    {
                        "@pid": "119/7712",
                        "text": "Yan Shoshitaishvili"
                    },
                    {
                        "@pid": "150/5198",
                        "text": "Tiffany Bao"
                    }
                ]
            },
            "title": "Fuzz to the Future: Uncovering Occluded Future Vulnerabilities via Robust Fuzzing.",
            "venue": "CCS",
            "pages": "3719-3733",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/RajGDVTWLHZMDD024",
            "doi": "10.1145/3658644.3690278",
            "ee": "https://doi.org/10.1145/3658644.3690278",
            "url": "https://dblp.org/rec/conf/ccs/RajGDVTWLHZMDD024",
            "abstract": "The security landscape of software systems has witnessed considerable advancements through dynamic testing methodologies, especially fuzzing. Traditionally, fuzzing involves a sequential, cyclic process where software is tested to identify crashes. These crashes are then triaged and patched, leading to subsequent cycles that uncover further vulnerabilities. While effective, this method is not efficient as each cycle potentially reveals new issues previously obscured by earlier crashes, thus resulting in vulnerabilities being discovered sequentially. In this paper, we present a solution to identify occluded future vulnerabilities \u2014 vulnerabilities that are hard or impossible to trigger due to current vulnerabilities occluding the triggering path. We introduce robust fuzzing, a novel technique that enables fuzzers probe beyond the immediate crash location and uncover new vulnerabilities or variants of known ones. We implemented robust fuzzing in FlakJack, a pioneering fuzzing add-on that leverages binary patching to proactively identify occluded future vulnerabilities hidden behind current crashes. By enabling fuzzers to bypass immediate crash points and delve deeper into the software, FlakJack not only accelerates the vulnerability discovery process but also significantly enhances the efficacy of software testing. With the",
            "keywords": [
                "Fuzzing",
                "Vulnerability Discovery",
                "Robust Fuzzing",
                "Occluded Vulnerabilities",
                "Binary Patching"
            ]
        },
        "url": "URL#256824",
        "sema_paperId": "154432971830327fac90a6de0cd12710ef4b73c2"
    },
    {
        "@score": "1",
        "@id": "256825",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "255/5036",
                        "text": "Syed Md. Mukit Rashid"
                    },
                    {
                        "@pid": "261/5092",
                        "text": "Tianwei Wu"
                    },
                    {
                        "@pid": "87/1149",
                        "text": "Kai Tu"
                    },
                    {
                        "@pid": "290/1874",
                        "text": "Abdullah Al Ishtiaq"
                    },
                    {
                        "@pid": "346/0765",
                        "text": "Ridwanul Hasan Tanvir"
                    },
                    {
                        "@pid": "361/1683",
                        "text": "Yilu Dong"
                    },
                    {
                        "@pid": "53/7986",
                        "text": "Omar Chowdhury"
                    },
                    {
                        "@pid": "83/7270",
                        "text": "Syed Rafiul Hussain"
                    }
                ]
            },
            "title": "State Machine Mutation-based Testing Framework for Wireless Communication Protocols.",
            "venue": "CCS",
            "pages": "2102-2116",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/RashidWTITDCH24",
            "doi": "10.1145/3658644.3690312",
            "ee": "https://doi.org/10.1145/3658644.3690312",
            "url": "https://dblp.org/rec/conf/ccs/RashidWTITDCH24",
            "abstract": "This paper proposes Proteus, a protocol state machine, property-guided, and budget-aware automated testing approach for discovering logical vulnerabilities in wireless protocol implementations. Proteus maintains its budget awareness by generating test cases (i.e., each being a sequence of protocol messages) that are not onlymeaningful(i.e., the test case mostly follows the desirable protocol flow except for some controlled deviations) but also have a high probability of violating the desirable properties. To demonstrate its effectiveness, we evaluated Proteus in two different protocol implementations, namely 4G LTE and BLE, across 23 consumer devices (11 for 4G LTE and 12 for BLE). Proteus discovered 25 unique issues, including 112 instances. Affected vendors have positively acknowledged 14 vulnerabilities through 5 CVEs.",
            "pdf_url": "",
            "keywords": [
                "Wireless Communication Protocols",
                "Automated Testing",
                "Logical Vulnerabilities",
                "Protocol State Machine",
                "Budget-aware Testing"
            ]
        },
        "url": "URL#256825"
    },
    {
        "@score": "1",
        "@id": "256826",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "364/9508",
                        "text": "Zachary Ratliff"
                    },
                    {
                        "@pid": "387/1946",
                        "text": "Salil Vadhan"
                    }
                ]
            },
            "title": "A Framework for Differential Privacy Against Timing Attacks.",
            "venue": "CCS",
            "pages": "3615-3629",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/RatliffV24",
            "doi": "10.1145/3658644.3690206",
            "ee": "https://doi.org/10.1145/3658644.3690206",
            "url": "https://dblp.org/rec/conf/ccs/RatliffV24",
            "abstract": "The standard definition of differential privacy (DP) ensures that a mechanism's output distribution on adjacent datasets is indistinguishable. However, real-world implementations of DP can, and often do, reveal information through their runtime distributions, making them susceptible to timing attacks. In this work, we establish a general framework for ensuring differential privacy in the presence of timing side channels. We define a new notion of timing privacy, which captures programs that remain differentially private to an adversary that observes the program's runtime in addition to the output. Our framework enables chaining together component programs that are timing-stable followed by a random delay to obtain DP programs that achieve timing privacy. Importantly, our definitions allow for measuring timing privacy and output privacy using different privacy measures. We illustrate how to instantiate our framework by giving programs for standard DP computations in the RAM and Word RAM models of computation. Furthermore, we show how our framework can be realized in code through a natural extension of the OpenDP Programming Framework.",
            "keywords": [
                "Differential Privacy",
                "Timing Attacks",
                "Timing Privacy",
                "Side Channels",
                "OpenDP Programming Framework"
            ]
        },
        "url": "URL#256826",
        "sema_paperId": "02e52caf74d39457d07fe6e75c8120e4affe2c46"
    },
    {
        "@score": "1",
        "@id": "256827",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "362/2615",
                        "text": "Fabian Rauscher"
                    },
                    {
                        "@pid": "166/1494",
                        "text": "Daniel Gruss"
                    }
                ]
            },
            "title": "Cross-Core Interrupt Detection: Exploiting User and Virtualized IPIs.",
            "venue": "CCS",
            "pages": "94-108",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/RauscherG24",
            "doi": "10.1145/3658644.3690242",
            "ee": "https://doi.org/10.1145/3658644.3690242",
            "url": "https://dblp.org/rec/conf/ccs/RauscherG24",
            "abstract": "Interrupts are fundamental for inter-process and cross-core communication in modern systems. Controlling these communication mechanisms historically requires switches into the kernel or hyper-visor, incurring high-performance costs. To alleviate these costs, Intel introduced new hardware mechanisms to send inter-processor interrupts (IPIs) from user space without switching into the kernel and from virtual machines without switching into the hypervisor. However, it is unclear whether this direct, unsupervised interaction between unprivileged (or virtualized) workloads and the underlying hardware introduces a significant change in the attack surface. In this paper, we present the IPI side channel, a novel side-channel attack exploiting the recently introduced user interrupts and IPI virtualization features on Intel Sapphire Rapids and the upcoming Intel Arrow Lake processors. The IPI side channel is the first cross-core interrupt detection side channel, allowing an attacker to monitor interrupts delivered to any physical core of the same processor. Our attack is based on precise measurements of the hardware delivery time of interrupts from user space and virtual machines. More specifically, we exploit that interrupts are delivered through a cross-core bus, leading to timing variations on the attacker\u2019s local IPIs. We present multiple case studies to compare the IPI side channel with the state of the art: First, we present an unprivileged cross-core covert channel with a native true capacity of 434 . 7kbit/s ( \ud835\udc5b =100, \ud835\udf0e \u00af \ud835\udc65 =0.03) and a cross-VM capacity of 3 . 45kbit/s ( \ud835\udc5b =100, \ud835\udf0e \u00af \ud835\udc65 =0.01). Second, we demonstrate a native inter-keystroke timing attack with an \ud835\udc39 1 score of 97 . 9%. Third, we present an open-world website fingerprinting attack on the top 100 websites, achieving an \ud835\udc39 1 score of 89 . 0% in a native scenario and an \ud835\udc39 1 score of 71 . 0% in a cross-VM (thin client) scenario. Furthermore, we discuss the broader context of the IPI side channels and categorize interrupt side channels and mitigations.",
            "keywords": [
                "Interrupt Handling",
                "Inter-Processor Interrupts (IPIs)",
                "Side-Channel Attacks",
                "Cross-Core Communication",
                "Timing Variations"
            ]
        },
        "url": "URL#256827",
        "sema_paperId": "9a358aa1c44837e1238c908a29f4263a95c2442b"
    },
    {
        "@score": "1",
        "@id": "256828",
        "info": {
            "authors": {
                "author": {
                    "@pid": "238/8867",
                    "text": "Nathan Reitinger"
                }
            },
            "title": "Understanding and Addressing Online Tracking: Online Privacy&apos;s Regulatory Turn.",
            "venue": "CCS",
            "pages": "5095-5097",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Reitinger24",
            "doi": "10.1145/3658644.3690857",
            "ee": "https://doi.org/10.1145/3658644.3690857",
            "url": "https://dblp.org/rec/conf/ccs/Reitinger24",
            "abstract": "Computing and storage breakthroughs over the last few decades have given rise to online tracking abilities that outpace current-day privacy-enhancing tools, social norms, and privacy regulations. Users lack the tools they need to block the types of tracking they cannot see and have very little control over; data stewards (i.e., companies processing user data) lack an understanding of what types of tracking practices users find normatively problematic; and policymakers lack effective feedback on real-world implementations of the data-focused or tracking-adjacent laws they are drafting-at a time when these regulations are in their infancy and feedback is crucial. Users should be able to navigate the web without falling victim to surreptitious tracking technologies; companies should be aware of what types of tracking users find most problematic; and legislators should be able to rely on empirically driven measurement studies to help them understand where the law falls short and where companies need help. My dissertation work focuses on improving online privacy by developing tracker-blocking tools, investigating user perceptions of online tracking, and systematizing knowledge as it relates to the measurement of statutory instruments. I focus here on the last, in-progress piece: a systematization of the measurement of legal compliance-helping researchers produce measurements that are compelling, ethical, and legally robust.",
            "pdf_url": "",
            "keywords": [
                "Online Privacy",
                "Tracking Technologies",
                "User Perceptions",
                "Legal Compliance Measurement",
                "Data Stewardship"
            ]
        },
        "url": "URL#256828",
        "sema_paperId": "b49bc9e0ce59249e1fd466ec0ff51ddde2d65eca"
    },
    {
        "@score": "1",
        "@id": "256829",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "00/8601",
                        "text": "Zhe Ren"
                    },
                    {
                        "@pid": "72/3476-1",
                        "text": "Xinghua Li 0001"
                    },
                    {
                        "@pid": "166/1798",
                        "text": "Yinbin Miao"
                    },
                    {
                        "@pid": "79/4643",
                        "text": "Mengyao Zhu"
                    },
                    {
                        "@pid": "315/2778",
                        "text": "Shunjie Yuan"
                    },
                    {
                        "@pid": "d/RobertHDeng",
                        "text": "Robert H. Deng"
                    }
                ]
            },
            "title": "PIC-BI: Practical and Intelligent Combinatorial Batch Identification for UAV assisted IoT Networks.",
            "venue": "CCS",
            "pages": "3645-3658",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Ren0MZYD24",
            "doi": "10.1145/3658644.3670303",
            "ee": "https://doi.org/10.1145/3658644.3670303",
            "url": "https://dblp.org/rec/conf/ccs/Ren0MZYD24",
            "abstract": "Unmanned Aerial Vehicle (UAV)-assisted IoT networks are receiving a lot of attention in academia and industry. For instance, a UAV can fly and hover over sensors, during which time the sensors simultaneously initiate batch access requests to the UAV. Typically, UAV employs batch authentication to efficiently handle these batch accesses. However, an attacker can initiate illegal requests, causing batch authentication to fail. There are various batch identification algorithms to find illegal requests, enabling legitimate sensors to establish service connections quickly. Existing work wants to choose a suitable one based on the specific attack scenario. However, existing work assumes that the percentage r% of illegal requests is known in advance, which is impractical in real-world scenarios. Besides, existing work only selects a suitable batch identification algorithm based on r%, limiting the performance of batch identification to the capabilities of the alternative algorithms. Drawing inspiration from the Kalman filter, we first propose an adaptive estimation algorithm for the number of illegal requests to address the above problems. Based on the estimated value e%, we design a combinatorial batch identification using reinforcement learning. This approach allows the combination of different algorithms to achieve superior performance. Extensive experiments demonstrate that, for the estimation algorithm, the relative error is less than 20% in 27 out of 40 experiments. Regarding the combinatorial algorithms, the delay can be reduced by approximately 7.15% to 30.86% compared to existing methods.",
            "pdf_url": "",
            "keywords": [
                "UAV-assisted IoT Networks",
                "Batch Authentication",
                "Illegal Requests",
                "Adaptive Estimation Algorithm",
                "Combinatorial Batch Identification"
            ]
        },
        "url": "URL#256829",
        "sema_paperId": "d40cf0f7553fcb1752a47ffffda24d4df55946e0"
    },
    {
        "@score": "1",
        "@id": "256830",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "277/3602",
                        "text": "Doreen Riepel"
                    },
                    {
                        "@pid": "263/6745",
                        "text": "Marloes Venema"
                    },
                    {
                        "@pid": "279/3338",
                        "text": "Tanya Verma"
                    }
                ]
            },
            "title": "ISABELLA: Improving Structures of Attribute-Based Encryption Leveraging Linear Algebra.",
            "venue": "CCS",
            "pages": "4628-4642",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/RiepelVV24",
            "doi": "10.1145/3658644.3690371",
            "ee": "https://doi.org/10.1145/3658644.3690371",
            "url": "https://dblp.org/rec/conf/ccs/RiepelVV24",
            "abstract": "Attribute-based encryption (ABE) is a powerful primitive that has found applications in important real-world settings requiring access control. Compared to traditional public-key encryption, ABE has established itself as a considerably more complex primitive that is additionally less efficient to implement. It is therefore paramount that the we can simplify the design of ABE schemes that are efficient, provide strong security guarantees, minimize the complexity in their descriptions and support all practical features that are desirable for common real-world settings. One of such practical features that is currently still difficult to achieve is multi-authority support. Motivated by NIST's ongoing standardization efforts around multi-authority schemes, we put a specific focus on simplifying the support of multiple authorities in the design of schemes. Abstract: Code to separate paragraphs",
            "pdf_url": "",
            "keywords": [
                "Attribute-Based Encryption",
                "Multi-Authority Support",
                "Access Control",
                "Linear Algebra",
                "Scheme Design"
            ]
        },
        "url": "URL#256830"
    },
    {
        "@score": "1",
        "@id": "256831",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "122/5145",
                        "text": "Michael Rosenberg"
                    },
                    {
                        "@pid": "318/5276",
                        "text": "Tushar Mopuri"
                    },
                    {
                        "@pid": "192/2291",
                        "text": "Hossein Hafezi"
                    },
                    {
                        "@pid": "129/9500",
                        "text": "Ian Miers"
                    },
                    {
                        "@pid": "161/3103",
                        "text": "Pratyush Mishra"
                    }
                ]
            },
            "title": "Hekaton: Horizontally-Scalable zkSNARKs Via Proof Aggregation.",
            "venue": "CCS",
            "pages": "929-940",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/RosenbergMHMM24",
            "doi": "10.1145/3658644.3690282",
            "ee": "https://doi.org/10.1145/3658644.3690282",
            "url": "https://dblp.org/rec/conf/ccs/RosenbergMHMM24",
            "abstract": ",",
            "keywords": [
                "zkSNARKs",
                "Proof Aggregation",
                "Scalability",
                "Zero-Knowledge Proofs",
                "Hekaton"
            ]
        },
        "url": "URL#256831",
        "sema_paperId": "ed204ec664b5f5389c74468df200a6bca142b8af"
    },
    {
        "@score": "1",
        "@id": "256832",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "119/6953",
                        "text": "Mohsen Salehi"
                    },
                    {
                        "@pid": "91/5344",
                        "text": "Karthik Pattabiraman"
                    }
                ]
            },
            "title": "AutoPatch: Automated Generation of Hotpatches for Real-Time Embedded Devices.",
            "venue": "CCS",
            "pages": "2370-2384",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/SalehiP24",
            "doi": "10.1145/3658644.3690255",
            "ee": "https://doi.org/10.1145/3658644.3690255",
            "url": "https://dblp.org/rec/conf/ccs/SalehiP24",
            "abstract": "Real-time embedded devices like medical or industrial devices are increasingly targeted by cyber-attacks. Prompt patching is crucial to mitigate the serious consequences of such attacks on these devices. Hotpatching is an approach to apply a patch to mission-critical embedded devices without rebooting them. However, existing hotpatching approaches require developers to manually write the hotpatch for target systems, which is time-consuming and error-prone. To address these issues, we propose AutoPatch, a new hotpatching technique that automatically generates functionally equivalent hotpatches via static analysis of the official patches. AutoPatch introduces a new software triggering approach that supports diverse embedded devices, and preserves the functionality of the official patch. In contrast to prior work, AutoPatch does not rely on hardware support for triggering patches, or on executing patches in specialized virtual machines. We implemented AutoPatch using the LLVM compiler, and evaluated its efficiency, effectiveness and generality using 62 real CVEs on four embedded devices with different specifications and architectures running popular RTOSes. We found that AutoPatch can fix more than 90% of CVEs, and resolve the vulnerability successfully. The results revealed an average total delay of less than 12.7 $\\mu s$ for fixing the vulnerabilities, representing a performance improvement of 50% over RapidPatch, a state-of-the-art approach. Further, our memory overhead, on average, was slightly lower than theirs (23%). Finally, AutoPatch was able to generate hotpatches for all four devices without any modifications.",
            "keywords": [
                "Embedded Device Security",
                "Hotpatching",
                "Automated Patch Generation",
                "Real-Time Operating Systems",
                "Cyber-Attacks Mitigation"
            ]
        },
        "url": "URL#256832",
        "sema_paperId": "a3a0237e12b13a8d8dfdb02055acf8741dd80392"
    },
    {
        "@score": "1",
        "@id": "256833",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "325/3043",
                        "text": "Katharina Schiller"
                    },
                    {
                        "@pid": "14/9777",
                        "text": "Florian Adamsky"
                    },
                    {
                        "@pid": "345/2198",
                        "text": "Christian Eichenm\u00fcller"
                    },
                    {
                        "@pid": "392/3068",
                        "text": "Matthias Reimert"
                    },
                    {
                        "@pid": "b/ZBenenson",
                        "text": "Zinaida Benenson"
                    }
                ]
            },
            "title": "Employees&apos; Attitudes towards Phishing Simulations: &quot;It&apos;s like when a child reaches onto the hot hob&quot;.",
            "venue": "CCS",
            "pages": "4167-4181",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/SchillerAERB24",
            "doi": "10.1145/3658644.3690212",
            "ee": "https://doi.org/10.1145/3658644.3690212",
            "url": "https://dblp.org/rec/conf/ccs/SchillerAERB24",
            "abstract": "E-mail phishing attacks remain one of the most significant challenges in IT security and are often used for initial access. Many organizations rely on phishing simulations to educate their staff to recognize suspicious e-mails. Previous studies have analyzed the effectiveness of these phishing simulations with mixed findings. However, the perception of and attitudes towards phishing simulations among staff have received little to no attention. This paper presents findings from a study that we carried out in co-operation with a multinational company that conducted phishing simulations over more than 12 months. We first conducted a quantitative survey involving 757 employees and then qualitative interviews with 22 participants to gain deeper insights into the perception of phishing simulations and the corresponding e-learning. We could not find evidence that employees feel attacked by their organization, as previous studies suspected. On the contrary, we found that a majority (86.9%) have a positive or very positive attitude towards phishing simulations. The interviews revealed that some employees developed new routines for e-mail processing, but most describe themselves as having become more vigilant without concrete changes. Furthermore, we found evidence that phishing simulations create a false sense of security, as the employees feel protected by them. Additionally, a lack of communication and feed-back can negatively impact employees\u2019 attitudes and lead to adverse consequences. Finally, we show that only a small portion of the employees who clicked on the phishing website interacted with the interactive e-learning elements, which raises questions about its objective usefulness, although they are perceived as useful",
            "keywords": [
                "Phishing Simulations",
                "Employee Attitudes",
                "IT Security Training",
                "E-mail Security Awareness",
                "False Sense of Security"
            ]
        },
        "url": "URL#256833",
        "sema_paperId": "6263a2c28f7c1dafc0ed14925f28d4f5cab9b653"
    },
    {
        "@score": "1",
        "@id": "256834",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "09/8857",
                        "text": "Sebastian Schrittwieser"
                    },
                    {
                        "@pid": "165/6510",
                        "text": "Michele Ianni"
                    }
                ]
            },
            "title": "CheckMATE &apos;24 - Research on Offensive and Defensive Techniques in the context of Man At The End (MATE) Attacks.",
            "venue": "CCS",
            "pages": "4901-4902",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/SchrittwieserI24",
            "doi": "10.1145/3658644.3691549",
            "ee": "https://doi.org/10.1145/3658644.3691549",
            "url": "https://dblp.org/rec/conf/ccs/SchrittwieserI24",
            "abstract": "MATE (Man-At-The-End) is an attacker model where an adversary has access to the target software and/or hardware environment of his victim and the ability to observe and modify it in order to extract secrets such as cryptographic keys or sensitive information, possibly with the subsequent goal of compromising code integrity or inserting backdoors, among others. A typical example of such a scenario is the case of an attack on a stolen smartphone or against software leveraging protection to offer premium content and/or features such as paid TV channels.",
            "pdf_url": "",
            "keywords": [
                "MATE Attacks",
                "Offensive Techniques",
                "Defensive Techniques",
                "Cryptographic Key Extraction",
                "Code Integrity Compromise"
            ]
        },
        "url": "URL#256834",
        "sema_paperId": "06e5bc3dec189bc668eb14e860a7bdd06488be52"
    },
    {
        "@score": "1",
        "@id": "256835",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "322/1161",
                        "text": "Arnaldo Sgueglia"
                    },
                    {
                        "@pid": "392/3374",
                        "text": "Rocco Addabbo"
                    },
                    {
                        "@pid": "171/5109",
                        "text": "Andrea Di Sorbo"
                    },
                    {
                        "@pid": "150/5429",
                        "text": "Stanislav Dashevskyi"
                    },
                    {
                        "@pid": "201/0224",
                        "text": "Daniel Ricardo dos Santos"
                    },
                    {
                        "@pid": "38/2506",
                        "text": "Corrado Aaron Visaggio"
                    }
                ]
            },
            "title": "Poster: A Multi-step Approach for Classification of Malware Samples.",
            "venue": "CCS",
            "pages": "5009-5011",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/SguegliaASDSV24",
            "doi": "10.1145/3658644.3691370",
            "ee": "https://doi.org/10.1145/3658644.3691370",
            "url": "https://dblp.org/rec/conf/ccs/SguegliaASDSV24",
            "abstract": "The rapid spread of unknown malware has prompted many companies and researchers to improve their detection and classification systems. Cyber security companies must deal with the newest malware samples captured by their honeypots, aiming to analyze and classify them to develop several countermeasures. This process could only be feasible with a strong ground truth baseline; companies could only securely store the samples, waiting for further developments. This paper proposes a multi-step approach to support the classification process of unknown malware samples. Specifically, our approach first leverages well-known classification techniques and third-party services to collect as much information as possible about the samples and combines them with Machine Learning (ML)-based techniques to classify the remaining samples. Our case study, conducted on industrial data, shows how the combination offers superior performance than using each method individually.",
            "pdf_url": "",
            "keywords": [
                "Malware Classification",
                "Cyber Threat Intelligence",
                "Unknown Malware Detection",
                "Machine Learning Techniques",
                "Multi-step Classification Approach"
            ]
        },
        "url": "URL#256835",
        "sema_paperId": "419efa13ae7a59d9b3ecf0473161b9257e155cc7"
    },
    {
        "@score": "1",
        "@id": "256836",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "311/5284",
                        "text": "Zeyang Sha"
                    },
                    {
                        "@pid": "290/7983",
                        "text": "Yicong Tan"
                    },
                    {
                        "@pid": "48/10103",
                        "text": "Mingjie Li"
                    },
                    {
                        "@pid": "b/MichaelBackes1",
                        "text": "Michael Backes 0001"
                    },
                    {
                        "@pid": "06/6785-16",
                        "text": "Yang Zhang 0016"
                    }
                ]
            },
            "title": "ZeroFake: Zero-Shot Detection of Fake Images Generated and Edited by Text-to-Image Generation Models.",
            "venue": "CCS",
            "pages": "4852-4866",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ShaTL0024",
            "doi": "10.1145/3658644.3690297",
            "ee": "https://doi.org/10.1145/3658644.3690297",
            "url": "https://dblp.org/rec/conf/ccs/ShaTL0024",
            "abstract": "The text-to-image generation model has attracted significant interest from both academic and industrial communities. These models can generate the images based on the given prompt descriptions. Their potent capabilities, while beneficial, also present risks. Previous efforts relied on the approach of training binary classifiers to detect the generated fake images, which is inefficient, lacking in generalizability, and non-robust. In this paper, we propose the novel zero-shot detection method, called ZeroFake, to distinguish fake images apart from real ones by utilizing a perturbation-based DDIM inversion technique. ZeroFake is inspired by the findings that fake images are more robust than real images during the process of DDIM inversion and reconstruction. Specifically, for a given image, ZeroFake first generates noise with DDIM inversion guided by adversary prompts. Then, ZeroFake reconstructs the image from the generated noise. Subsequently, it compares the reconstructed image with the original image to determine whether it is fake or real. By exploiting the differential response of fake and real images to the adversary prompts during the inversion and reconstruction process, our model offers a more robust and efficient method to detect fake images without the extensive data and training costs. Extensive results demonstrate that the proposed ZeroFake can achieve great performance in fake image detection, fake artwork detection, and fake edited image detection. We further illustrate the robustness of the proposed ZeroFake by showcasing its resilience against potential adversary attacks. We hope that our solution can better assist the community in achieving the arrival of a more efficient and fair AGI",
            "keywords": [
                "Fake Image Detection",
                "Text-to-Image Generation",
                "Zero-Shot Learning",
                "DDIM Inversion",
                "Adversarial Prompts"
            ]
        },
        "url": "URL#256836",
        "sema_paperId": "cbf1cf177ea6c4be00fa697b39b6f2fccd6ba22e"
    },
    {
        "@score": "1",
        "@id": "256837",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "154/7105",
                        "text": "Filipo Sharevski"
                    },
                    {
                        "@pid": "354/8487",
                        "text": "Aziz Zeidieh"
                    },
                    {
                        "@pid": "337/9859",
                        "text": "Jennifer Vander Loop"
                    },
                    {
                        "@pid": "248/2439",
                        "text": "Peter Jachim"
                    }
                ]
            },
            "title": "Blind and Low-Vision Individuals&apos; Detection of Audio Deepfakes.",
            "venue": "CCS",
            "pages": "4867-4881",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/SharevskiZLJ24",
            "doi": "10.1145/3658644.3690305",
            "ee": "https://doi.org/10.1145/3658644.3690305",
            "url": "https://dblp.org/rec/conf/ccs/SharevskiZLJ24",
            "abstract": "Audio deepfakes are a form of deception where convincing speech sentences are synthesized through machine learning means to give an impression of a human speaker. Audio deepfakes emerge as an attractive vector for targeting users that rely on audio accessibility, such as individuals who are blind or low vision. The critical reliance on speech both as a medium and an affordance puts this population at an undue risk of being deceived as they rely solely on themselves to detect whether a piece of audio is a deepfake or not. To better understand the nature of this risk considering the nuanced reliance on assistive technologies such as screen readers, we conducted a user study with n=16 blind and low vision individuals from the US. Our participants achieved an overall discernment accuracy of 59%, and clips identified as deep fakes were only actually deepfakes in 50.8% of the cases (precision). The participants that self-identified as \"low vision\" performed slightly better (accuracy of 61%, precision of 64%) compared to the ones that self-identified as \"blind\" (accuracy of 55%, precision of 56%). Our qualitative results show that the participants in the \"blind\" group mostly considered a combination of infliction, imperfections in the voice, and the intensity in the speech delivery as discernment factors. The participants in the \"low vision\" group mostly used the speaker's pitch, enunciation, emotion, and the fluency and articulation of the speaker as discernment cues. Overall, participants felt that audio deepfakes have the potential to deceive visually impaired individuals with political disinformation, impersonate their voice in authentication and smart homes, and specifically target them with voice phishing and enhanced scams.",
            "pdf_url": "",
            "keywords": [
                "Audio Deepfakes",
                "Blind and Low Vision Accessibility",
                "Speech Synthesis Deception",
                "User Detection Accuracy",
                "Voice Phishing Risks"
            ]
        },
        "url": "URL#256837",
        "sema_paperId": "45aa206df46e836c182a8255e29b9acd80a0bb8e"
    },
    {
        "@score": "1",
        "@id": "256838",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "307/2373",
                        "text": "Ayushi Sharma"
                    },
                    {
                        "@pid": "123/4533",
                        "text": "Shashank Sharma"
                    },
                    {
                        "@pid": "354/4479",
                        "text": "Sai Ritvik Tanksalkar"
                    },
                    {
                        "@pid": "185/1711",
                        "text": "Santiago Torres-Arias"
                    },
                    {
                        "@pid": "133/8188",
                        "text": "Aravind Machiry"
                    }
                ]
            },
            "title": "Rust for Embedded Systems: Current State and Open Problems.",
            "venue": "CCS",
            "pages": "2296-2310",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/SharmaSTTM24",
            "doi": "10.1145/3658644.3690275",
            "ee": "https://doi.org/10.1145/3658644.3690275",
            "url": "https://dblp.org/rec/conf/ccs/SharmaSTTM24",
            "abstract": "Embedded software is used in safety-critical systems such as medical devices and autonomous vehicles, where software defects, including security vulnerabilities, have severe consequences. Most embedded codebases are developed in unsafe languages, specifically C/C++, and are riddled with memory safety vulnerabilities. To prevent such vulnerabilities, Rust, a performant memory-safe systems language, provides an optimal choice for developing embedded software. Rust interoperability enables developing Rust applications on top of existing C codebases. Despite this, even the most resourceful organizations continue to develop embedded software in C/C++. Thispaper performs the first systematic study to holistically understand the current state and challenges of using Rust for embedded systems. Our study is organized across three research questions. We collected a dataset of 6,408 Rust embedded software spanning various categories and 6 Static Application Security Testing (SAST) tools. We performed a systematic analysis of our dataset and surveys with 225 developers to investigate our research questions. We found that existing Rust software support is inadequate, SAST tools cannot handle certain features of Rust embedded software, resulting in failures, and the prevalence of advanced types in existing Rust software makes it challenging to engineer interoperable code. In addition, we found various challenges faced by developers in using Rust for embedded systems development.",
            "keywords": [
                "Embedded Systems",
                "Rust Programming",
                "Memory Safety",
                "Static Application Security Testing",
                "Interoperability Challenges"
            ]
        },
        "url": "URL#256838",
        "sema_paperId": "71e060576b91646c3cbed8178cb202a85fc11fa5"
    },
    {
        "@score": "1",
        "@id": "256839",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "168/9537",
                        "text": "Dongdong She"
                    },
                    {
                        "@pid": "348/6465",
                        "text": "Adam Storek"
                    },
                    {
                        "@pid": "360/7421",
                        "text": "Yuchong Xie"
                    },
                    {
                        "@pid": "376/0798",
                        "text": "Seoyoung Kweon"
                    },
                    {
                        "@pid": "201/9222",
                        "text": "Prashast Srivastava"
                    },
                    {
                        "@pid": "74/28",
                        "text": "Suman Jana"
                    }
                ]
            },
            "title": "FOX: Coverage-guided Fuzzing as Online Stochastic Control.",
            "venue": "CCS",
            "pages": "765-779",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/SheSXKSJ24",
            "doi": "10.1145/3658644.3670362",
            "ee": "https://doi.org/10.1145/3658644.3670362",
            "url": "https://dblp.org/rec/conf/ccs/SheSXKSJ24",
            "abstract": "Fuzzing is an effective technique for discovering software vulnerabilities by generating random test inputs and executing them against the target program. However, fuzzing large and complex programs remains challenging due to difficulties in uncovering deeply hidden vulnerabilities. This paper addresses the limitations of existing coverage-guided fuzzers, focusing on the scheduler and mutator components. Existing schedulers suffer from information sparsity and the inability to handle fine-grained feedback metrics. The mutators are agnostic of target program branches, leading to wasted computation and slower coverage exploration.",
            "pdf_url": "",
            "keywords": [
                "Fuzzing",
                "Software Vulnerabilities",
                "Coverage-guided Fuzzing",
                "Scheduler and Mutator Components",
                "Fine-grained Feedback Metrics"
            ]
        },
        "url": "URL#256839"
    },
    {
        "@score": "1",
        "@id": "256840",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "148/9731",
                        "text": "Xinyue Shen"
                    },
                    {
                        "@pid": "191/1578",
                        "text": "Zeyuan Chen"
                    },
                    {
                        "@pid": "b/MichaelBackes1",
                        "text": "Michael Backes 0001"
                    },
                    {
                        "@pid": "14/4412",
                        "text": "Yun Shen"
                    },
                    {
                        "@pid": "06/6785-16",
                        "text": "Yang Zhang 0016"
                    }
                ]
            },
            "title": "&quot;Do Anything Now&quot;: Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models.",
            "venue": "CCS",
            "pages": "1671-1685",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ShenC0SZ24",
            "doi": "10.1145/3658644.3670388",
            "ee": "https://doi.org/10.1145/3658644.3670388",
            "url": "https://dblp.org/rec/conf/ccs/ShenC0SZ24",
            "abstract": "The misuse of large language models (LLMs) has drawn significant attention from the general public and LLM vendors. One particular type of adversarial prompt, known as jailbreak prompt, has emerged as the main attack vector to bypass the safeguards and elicit harmful content from LLMs. In this paper, employing our new framework JailbreakHub, we conduct a comprehensive analysis of 1,405 jailbreak prompts spanning from December 2022 to December 2023. We identify 131 jailbreak communities and discover unique characteristics of jailbreak prompts and their major attack strategies, such as prompt injection and privilege escalation. We also observe that jailbreak prompts increasingly shift from online Web communities to prompt-aggregation websites and 28 user accounts have consistently optimized jailbreak prompts over 100 days. To assess the potential harm caused by jailbreak prompts, we create a question set comprising 107,250 samples across 13 forbidden scenarios. Leveraging this dataset, our experiments on six popular LLMs show that their safeguards cannot adequately defend jailbreak prompts in all scenarios. Particularly, we identify five highly effective jailbreak prompts that achieve 0.95 attack success rates on ChatGPT (GPT-3.5) and GPT-4, and the earliest one has persisted online for over 240 days. We hope that our study can facilitate the research community and LLM vendors in promoting safer and regulated LLMs.",
            "keywords": [
                "Jailbreak Prompts",
                "Large Language Models",
                "Adversarial Attacks",
                "Prompt Injection",
                "Privilege Escalation"
            ]
        },
        "url": "URL#256840",
        "sema_paperId": "1104d766527dead44a40532e8a89444d9cef5c65"
    },
    {
        "@score": "1",
        "@id": "256841",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "235/6392",
                        "text": "Jiawen Shi"
                    },
                    {
                        "@pid": "197/5699",
                        "text": "Zenghui Yuan"
                    },
                    {
                        "@pid": "223/3546",
                        "text": "Yinuo Liu"
                    },
                    {
                        "@pid": "48/2209",
                        "text": "Yue Huang"
                    },
                    {
                        "@pid": "84/6614-1",
                        "text": "Pan Zhou 0001"
                    },
                    {
                        "@pid": "121/0780-1",
                        "text": "Lichao Sun 0001"
                    },
                    {
                        "@pid": "03/9437",
                        "text": "Neil Zhenqiang Gong"
                    }
                ]
            },
            "title": "Optimization-based Prompt Injection Attack to LLM-as-a-Judge.",
            "venue": "CCS",
            "pages": "660-674",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ShiYLH00G24",
            "doi": "10.1145/3658644.3690291",
            "ee": "https://doi.org/10.1145/3658644.3690291",
            "url": "https://dblp.org/rec/conf/ccs/ShiYLH00G24",
            "abstract": "LLM-as-a-Judge uses a large language model (LLM) to select the best response from a set of candidates for a given question. LLM-as-a-Judge has many applications such as LLM-powered search, reinforcement learning with AI feedback (RLAIF), and tool selection. In this work, we propose JudgeDeceiver, an optimization-based prompt injection attack to LLM-as-a-Judge. JudgeDeceiver injects a carefully crafted sequence into an attacker-controlled candidate response such that LLM-as-a-Judge selects the candidate response for an attacker-chosen question no matter what other candidate responses are. Specifically, we formulate finding such sequence as an optimization problem and propose a gradient based method to approximately solve it. Our extensive evaluation shows that JudgeDeceive is highly effective, and is much more effective than existing prompt injection attacks that manually craft the injected sequences and jailbreak attacks when extended to our problem. We also show the effectiveness of JudgeDeceiver in three case studies, i.e., LLM-powered search, RLAIF, and tool selection. Moreover, we consider defenses including known-answer detection, perplexity detection, and perplexity windowed detection. Our results show these defenses are insufficient, highlighting the urgent need for developing new defense strategies. Our implementation is available at this repository: https://github.com/ShiJiawenwen/JudgeDeceiver.",
            "keywords": [
                "LLM-as-a-Judge",
                "Prompt Injection Attack",
                "Optimization Problem",
                "JudgeDeceiver",
                "Defense Strategies"
            ]
        },
        "url": "URL#256841",
        "sema_paperId": "e56f14ced9f7ce344ed14bdcb46860ccac72ac83"
    },
    {
        "@score": "1",
        "@id": "256842",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "386/2748",
                        "text": "Sachin Shukla"
                    },
                    {
                        "@pid": "195/4341",
                        "text": "Omid Mirzaei"
                    }
                ]
            },
            "title": "Poster: Different Victims, Same Layout: Email Visual Similarity Detection for Enhanced Email Protection.",
            "venue": "CCS",
            "pages": "4988-4990",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ShuklaM24",
            "doi": "10.1145/3658644.3691381",
            "ee": "https://doi.org/10.1145/3658644.3691381",
            "url": "https://dblp.org/rec/conf/ccs/ShuklaM24",
            "abstract": "In the pursuit of an effective spam detection system, the focus has often been on identifying known spam patterns either through rule-based detection systems or machine learning (ML) solutions that rely on keywords. However, both systems are susceptible to evasion techniques and zero-day attacks that can be achieved at low cost. Therefore, an email that bypassed the defense system once can do it again in the following days, even though rules are updated or the ML models are retrained. The recurrence of failures to detect emails that exhibit layout similarities to previously undetected spam is concerning for customers and can erode their trust in a company. Our observations show that threat actors reuse email kits extensively and can bypass detection with little effort, for example, by making changes to the content of emails. In this work, we propose an email visual similarity detection approach, named Pisco, to improve the detection capabilities of an email threat defense system. We apply our proof of concept to some real-world samples received from different sources. Our results show that email kits are being reused extensively and visually similar emails are sent to our customers at various time intervals. Therefore, this method could be very helpful in situations where detection engines that rely on textual features and keywords are bypassed, an occurrence our observations show happens frequently.",
            "pdf_url": "",
            "keywords": [
                "Email Threat Detection",
                "Visual Similarity Detection",
                "Spam Evasion Techniques",
                "Email Kit Reuse",
                "Detection Bypass"
            ]
        },
        "url": "URL#256842"
    },
    {
        "@score": "1",
        "@id": "256843",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "31/9612",
                        "text": "Lucy Simko"
                    },
                    {
                        "@pid": "374/8992",
                        "text": "Adryana Hutchinson"
                    },
                    {
                        "@pid": "390/4355",
                        "text": "Alvin Isaac"
                    },
                    {
                        "@pid": "392/3196",
                        "text": "Evan Fries"
                    },
                    {
                        "@pid": "57/3752",
                        "text": "Micah Sherr"
                    },
                    {
                        "@pid": "94/1554",
                        "text": "Adam J. Aviv"
                    }
                ]
            },
            "title": "&quot;Modern problems require modern solutions&quot;: Community-Developed Techniques for Online Exam Proctoring Evasion.",
            "venue": "CCS",
            "pages": "2681-2695",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/SimkoHIFSA24",
            "doi": "10.1145/3658644.3691638",
            "ee": "https://doi.org/10.1145/3658644.3691638",
            "url": "https://dblp.org/rec/conf/ccs/SimkoHIFSA24",
            "abstract": "COVID-19 caused an abrupt shift towards remote learning, and along with it, an increased adoption of remote, online proctoring technology to both dissuade and identify academic dishonesty (i.e., cheating). This shift also came with significant discontent from students who took to online platforms to both express their displea-sure with remote proctoring and the methods they used for evading monitoring methods, essentially discussing hacks to subvert the software and cheat on exams. In this paper, we seek to understand both the methods this online community shares for evading online proctoring and why they do so. Through qualitative analysis of social media videos ( \ud835\udc5b = 137 ) and comments ( \ud835\udc5b = 4 , 297 ) on YouTube and TikTok, we find both non-technical (e.g., sticky-notes) and deeply technical (e.g., custom virtual machines) methods of evading proctoring. The online videos, as well as the active comment sections, provide an important window into both an (unethical) desire to cheat but also the development of a security mindset . Many see proctoring software as invasive surveillance technology, and the discussion and sharing of methods to subvert it have similar tones to that of the hacker/tinkerer communities who also seek to share their experiences of subverting technology, for fun and profit. We conclude with lessons for the security and privacy community about evading online exam proctoring, as well as a conversation",
            "keywords": [
                "Online Exam Proctoring",
                "Academic Dishonesty",
                "Cheating Evasion Techniques",
                "Remote Learning Challenges",
                "Surveillance Technology Critique"
            ]
        },
        "url": "URL#256843",
        "sema_paperId": "a7640cc5f0840a2bdfd7c4b7d7f6355ba1112579"
    },
    {
        "@score": "1",
        "@id": "256844",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "283/7990",
                        "text": "Sevval Simsek"
                    },
                    {
                        "@pid": "224/9855",
                        "text": "Zhenpeng Shi"
                    },
                    {
                        "@pid": "392/3065",
                        "text": "Howell Xia"
                    },
                    {
                        "@pid": "392/3059",
                        "text": "David Sastre Medina"
                    },
                    {
                        "@pid": "62/3017",
                        "text": "David Starobinski"
                    }
                ]
            },
            "title": "Poster: Analyzing and Correcting Inaccurate CVE-CWE Mappings in the National Vulnerability Database.",
            "venue": "CCS",
            "pages": "5042-5044",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/SimsekSXMS24",
            "doi": "10.1145/3658644.3691375",
            "ee": "https://doi.org/10.1145/3658644.3691375",
            "url": "https://dblp.org/rec/conf/ccs/SimsekSXMS24",
            "abstract": "We conduct a longitudinal study of the National Vulnerability Database (NVD), focusing on the mappings between vulnerabilities (CVEs) and weaknesses (CWEs). Surprisingly, the study reveals that a significant portion of CVEs, fluctuating between 15% and 30% over the years, lack proper CWE mapping, and that almost 40% of the updates are non-informative. We introduce a methodology, based on knowledge graphs, for automating root cause weakness mapping for CVEs and for fixing existing inaccurate mappings. We showcase promising preliminary results toward this end.",
            "pdf_url": "",
            "keywords": [
                "National Vulnerability Database",
                "CVE-CWE Mappings",
                "Vulnerability Analysis",
                "Knowledge Graphs",
                "Automated Mapping Correction"
            ]
        },
        "url": "URL#256844",
        "sema_paperId": "d6f48086f791c9d53091cb360acfd8d023abeb38"
    },
    {
        "@score": "1",
        "@id": "256845",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "331/8294",
                        "text": "Yongho Song"
                    },
                    {
                        "@pid": "375/6580",
                        "text": "Byeongsu Woo"
                    },
                    {
                        "@pid": "241/4316",
                        "text": "Youngkwang Han"
                    },
                    {
                        "@pid": "17/6702",
                        "text": "Brent ByungHoon Kang"
                    }
                ]
            },
            "title": "Interstellar: Fully Partitioned and Efficient Security Monitoring Hardware Near a Processor Core for Protecting Systems against Attacks on Privileged Software.",
            "venue": "CCS",
            "pages": "198-212",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/SongWHK24",
            "doi": "10.1145/3658644.3690247",
            "ee": "https://doi.org/10.1145/3658644.3690247",
            "url": "https://dblp.org/rec/conf/ccs/SongWHK24",
            "abstract": "The existing approaches to instruction trace-based security monitoring hardware are dependent on the privileged software, which presents a significant challenge in defending against attacks on privileged software itself. To address this challenge, we propose Interstellar, which introduces a partitioned hardware near the CPU's main core and leverages the benefit of hardware-level security monitoring. Interstellar is fully partitioned, parallelized, and simultaneously detecting security monitoring hardware. Interstellar's design makes malicious software hard to reverse-engineer how Interstellar detects the attacks, and Interstellar efficiently protects the system against the attacks on the privileged software(e.g.,Trusted Execution Environment (TEE)). Moreover, Interstellar not only monitors but also blocks various attacks in a timely manner without stalling a CPU core by designing with a finite-state machine.",
            "pdf_url": "",
            "keywords": [
                "Hardware Security Monitoring",
                "Privileged Software Protection",
                "Instruction Trace Analysis",
                "Attack Detection",
                "Trusted Execution Environment (TEE)"
            ]
        },
        "url": "URL#256845",
        "sema_paperId": "0aa07044709f1e4fd5b03fe98fda848b31b3394a"
    },
    {
        "@score": "1",
        "@id": "256846",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "71/625",
                        "text": "Ron Steinfeld"
                    },
                    {
                        "@pid": "76/8037",
                        "text": "Amin Sakzad"
                    },
                    {
                        "@pid": "153/0549",
                        "text": "Muhammed F. Esgin"
                    },
                    {
                        "@pid": "137/5239",
                        "text": "Veronika Kuchta"
                    },
                    {
                        "@pid": "263/6680",
                        "text": "Mert Yassi"
                    },
                    {
                        "@pid": "233/0126",
                        "text": "Raymond K. Zhao"
                    }
                ]
            },
            "title": "LUNA: Quasi-Optimally Succinct Designated-Verifier Zero-Knowledge Arguments from Lattices.",
            "venue": "CCS",
            "pages": "3167-3181",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/SteinfeldSEKYZ24",
            "doi": "10.1145/3658644.3670345",
            "ee": "https://doi.org/10.1145/3658644.3670345",
            "url": "https://dblp.org/rec/conf/ccs/SteinfeldSEKYZ24",
            "abstract": "We introduce the first candidate Lattice-based designated verifier (DV) zero knowledge sUccinct Non-interactive Argument (ZK-SNARG) protocol, named LUNA, with quasi-optimal proof length (quasi-linear in the security/privacy parameter). By simply relying on mildly stronger security assumptions, LUNA is also a candidate ZK-SNARK (i.e. argument of knowledge). LUNA achieves significant improvements in concrete proof sizes, reaching below 6 KB (compared to > 32 KB in prior work) for 128-bit security/privacy level. To achieve our quasi-optimal succinct LUNA, we give a new regularity result for \u2018private\u2019 re-randomization of Module LWE (MLWE) samples using discrete Gaussian randomization vectors, also known as a lattice-based leftover hash lemma with leakage, which applies with a discrete Gaussian re-randomization parameter that is polynomial in the statistical privacy parameter (avoiding exponential smudging), and hides the coset of the re-randomization vector support set. Along the way, we derive bounds on the smoothing parameter of the intersection of short integer solution (SIS), gadget, and Gaussian perp module lattices over the power of 2 cy-clotomic rings. We then introduce a new candidate linear-only homomorphic encryption scheme called Module Half-GSW (HGSW), and apply our regularity theorem to provide smudging-free circuit-private homomorphic linear operations for Module HGSW. Our implementation and experimental performance evaluation show that, for typical instance sizes, Module HGSW provides favourable performance for ZK-SNARG applications involving lightweight verifiers. It enables significantly (around 5 \u00d7 ) shorter proof lengths while speeding up CRS generation and encryption time by 4 \u2212 16 \u00d7 and speeding up decryption time by 4 . 3 \u00d7 , while incurring just 1 . 2 \u2212 2 \u00d7 time overhead in linear homomorphic proof generation operations, compared to a Regev encryption used in prior work in the ZK-SNARG context. We believe our techniques are of independent interest and will find application in other privacy-preserving applications of lattice-based cryptography",
            "keywords": [
                "Lattice-based Cryptography",
                "Zero-Knowledge Arguments",
                "Designated Verifier",
                "Succinct Non-interactive Arguments",
                "Homomorphic Encryption"
            ]
        },
        "url": "URL#256846",
        "sema_paperId": "57dc91537cf1e53d5917b42b5d88a51d2a9d4452"
    },
    {
        "@score": "1",
        "@id": "256847",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "236/9533",
                        "text": "Bozhidar Stevanoski"
                    },
                    {
                        "@pid": "31/2956-2",
                        "text": "Ana-Maria Cretu 0002"
                    },
                    {
                        "@pid": "75/7560",
                        "text": "Yves-Alexandre de Montjoye"
                    }
                ]
            },
            "title": "QueryCheetah: Fast Automated Discovery of Attribute Inference Attacks Against Query-Based Systems.",
            "venue": "CCS",
            "pages": "3451-3465",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Stevanoski0M24",
            "doi": "10.1145/3658644.3690272",
            "ee": "https://doi.org/10.1145/3658644.3690272",
            "url": "https://dblp.org/rec/conf/ccs/Stevanoski0M24",
            "abstract": "Query-based systems (QBSs) are one of the key approaches for sharing data. QBSs allow analysts to request aggregate information from a private protected dataset. Attacks are a crucial part of ensuring QBSs are truly privacy-preserving. The development and testing of attacks is however very labor-intensive and unable to cope with the increasing complexity of systems. Automated approaches have been shown to be promising but are currently extremely computationally intensive, limiting their applicability in practice. We here propose QueryCheetah, a fast and effective method for automated discovery of privacy attacks against QBSs. We instantiate QueryCheetah on attribute inference attacks and show it to discover stronger attacks than previous methods while being 18 times faster than the state-of-the-art automated approach. We then show how QueryCheetah allows system developers to thoroughly evaluate the privacy risk, including for various attacker strengths and target individuals. We finally show how QueryCheetah can be used out-of-the-box to find attacks in larger syntaxes and workarounds around ad-hoc defenses.",
            "keywords": [
                "Query-Based Systems",
                "Privacy Attacks",
                "Attribute Inference",
                "Automated Discovery",
                "Privacy Risk Evaluation"
            ]
        },
        "url": "URL#256847",
        "sema_paperId": "74a4bd34d4cfbd875f18187c674e89dac7ef173d"
    },
    {
        "@score": "1",
        "@id": "256848",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "123/7388",
                        "text": "Ruimin Sun"
                    },
                    {
                        "@pid": "28/3341-1",
                        "text": "Mu Zhang 0001"
                    }
                ]
            },
            "title": "RICSS&apos;24: 2nd International Workshop on Re-design Industrial Control Systems with Security.",
            "venue": "CCS",
            "pages": "4894-4895",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Sun024",
            "doi": "10.1145/3658644.3691337",
            "ee": "https://doi.org/10.1145/3658644.3691337",
            "url": "https://dblp.org/rec/conf/ccs/Sun024",
            "abstract": "Industrial Control System (ICS) and its software touches every aspect of the critical infrastructure used by our industry, academia, and government. Back in the days, these systems and software were not designed with security in mind. With the ever expanding interconnectivity of ICS environments and new threats, practitioners are stuck on a patchwork of security. While certain proprietary ICS software manufacturers have started to provide security solutions, free and open source ICS software is often less known. The goal of the workshop is twofold: we want to collect ideas on redesigning (parts of) the ICS ecosystem so that security is built-in by design; we also invite contributions on designing, incorporating, and maintaining secure open-source ICS software.",
            "pdf_url": "",
            "keywords": [
                "Industrial Control Systems",
                "Security by Design",
                "Open Source Software",
                "ICS Ecosystem Redesign",
                "Cybersecurity Challenges in ICS"
            ]
        },
        "url": "URL#256848",
        "sema_paperId": "8d3aada0eafd72fa294f78747c05ac1fd808bbe3"
    },
    {
        "@score": "1",
        "@id": "256849",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "158/7630",
                        "text": "Zhiyuan Sun"
                    },
                    {
                        "@pid": "175/8858-1",
                        "text": "Zihao Li 0001"
                    },
                    {
                        "@pid": "390/8831",
                        "text": "Xinghao Peng"
                    },
                    {
                        "@pid": "53/1565",
                        "text": "Xiapu Luo"
                    },
                    {
                        "@pid": "203/0794",
                        "text": "Muhui Jiang"
                    },
                    {
                        "@pid": "63/778-9",
                        "text": "Hao Zhou 0009"
                    },
                    {
                        "@pid": "77/3503",
                        "text": "Yinqian Zhang"
                    }
                ]
            },
            "title": "DoubleUp Roll: Double-spending in Arbitrum by Rolling It Back.",
            "venue": "CCS",
            "pages": "2577-2590",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Sun0PLJ0Z24",
            "doi": "10.1145/3658644.3690256",
            "ee": "https://doi.org/10.1145/3658644.3690256",
            "url": "https://dblp.org/rec/conf/ccs/Sun0PLJ0Z24",
            "abstract": "Optimistic rollup protocols are widely adopted as the most popular blockchain scaling solutions. As a dominant implementation, Arbitrum has boasted a total locked value exceeding 18 billion USD, highlighting the significance of optimistic rollups in blockchain ecosystem. Despite their popularity, little research has been done on the security of optimistic rollup protocols, and potential vulnerabilities on them remain unknown.",
            "pdf_url": "",
            "keywords": [
                "Optimistic Rollups",
                "Blockchain Scaling Solutions",
                "Arbitrum",
                "Double-Spending Vulnerability",
                "Rollback Attack"
            ]
        },
        "url": "URL#256849",
        "sema_paperId": "abd8685216b0895d66988ca6888fb0ed0b9d9494"
    },
    {
        "@score": "1",
        "@id": "256850",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "239/2727",
                        "text": "Yunqing Sun"
                    },
                    {
                        "@pid": "k/JonathanKatz",
                        "text": "Jonathan Katz"
                    },
                    {
                        "@pid": "07/5590-1",
                        "text": "Mariana Raykova 0001"
                    },
                    {
                        "@pid": "187/5645",
                        "text": "Phillipp Schoppmann"
                    },
                    {
                        "@pid": "150/9413",
                        "text": "Xiao Wang 0012"
                    }
                ]
            },
            "title": "Actively Secure Private Set Intersection in the Client-Server Setting.",
            "venue": "CCS",
            "pages": "1478-1492",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/SunK0S024",
            "doi": "10.1145/3658644.3690349",
            "ee": "https://doi.org/10.1145/3658644.3690349",
            "url": "https://dblp.org/rec/conf/ccs/SunK0S024",
            "abstract": "Private set intersection (PSI) allows two parties to compute the intersection of their sets without revealing anything else. In some applications of PSI, a server holds a large set and runs a PSI protocol with multiple clients, each with its own smaller set. In this setting, existing protocols fall short: they either achieve only semi-honest security, or else require the server to run the protocol from scratch for each execution. We design an efficient protocol for this setting with simulation-based security against malicious adversaries. In our protocol, the server publishes a one-time, linear-size encoding of its set. Then, multiple clients can independently execute a PSI protocol with the server, with complexity linear in the size of each client\u2019s set. To learn the intersection, a client can download the server\u2019s encoding, which can be accelerated via content-distribution or peer-to-peer networks since the same encoding is used by all clients; alternatively, clients can fetch only the relevant parts of the encoding using verifiable private information retrieval. A key ingredient of our protocol is an efficient instantiation of an oblivious verifiable unpredictable function, which may be of independent interest. Our implementation shows that our protocol is highly efficient. For a server holding 10 8 elements and each client holding 10 3 elements, the size of the server\u2019s encoding is 800MB; an execution of the protocol uses 60MB of communication, runs in under 5s in a WAN network with 120 Mbps bandwidth, and costs only 0.017 USD when utilizing network-caching infrastructures, a 5 \u00d7 saving compared to a state-of-the-art PSI protocol.",
            "keywords": [
                "Private Set Intersection",
                "Client-Server Model",
                "Malicious Security",
                "Oblivious Verifiable Unpredictable Function",
                "Efficient Encoding"
            ]
        },
        "url": "URL#256850",
        "sema_paperId": "8ef27049a97d4cf9cece43cec539158d42fc3fec"
    },
    {
        "@score": "1",
        "@id": "256851",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "238/3163",
                        "text": "Haochen Sun"
                    },
                    {
                        "@pid": "12/975",
                        "text": "Jason Li"
                    },
                    {
                        "@pid": "23/10537-1",
                        "text": "Hongyang Zhang 0001"
                    }
                ]
            },
            "title": "zkLLM: Zero Knowledge Proofs for Large Language Models.",
            "venue": "CCS",
            "pages": "4405-4419",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/SunL024",
            "doi": "10.1145/3658644.3670334",
            "ee": "https://doi.org/10.1145/3658644.3670334",
            "url": "https://dblp.org/rec/conf/ccs/SunL024",
            "abstract": "The recent surge in artificial intelligence (AI), characterized by the prominence of large language models (LLMs), has ushered in fundamental transformations across the globe. However, alongside these advancements, concerns surrounding the legitimacy of LLMs have grown, posing legal challenges to their extensive applications. Compounding these concerns, the parameters of LLMs are often treated as intellectual property, restricting direct investigations. In this study, we address a fundamental challenge within the realm of AI legislation: the need to establish the authenticity of outputs generated by LLMs. To tackle this issue, we present zkLLM, which stands as the inaugural specialized zero-knowledge proof tailored for LLMs to the best of our knowledge. Addressing the persistent challenge of non-arithmetic operations in deep learning, we introduce tlookup, a parallelized lookup argument designed for non-arithmetic tensor operations in deep learning, offering a solution with no asymptotic overhead. Furthermore, leveraging the foundation of tlookup, we introduce zkAttn, a specialized zero-knowledge proof crafted for the attention mechanism, carefully balancing considerations of running time, memory usage, and accuracy. Empowered by our fully parallelized CUDA implementation, zkLLM emerges as a significant stride towards achieving efficient zero-knowledge verifiable computations over LLMs. Remarkably, for LLMs boasting 13 billion parameters, our approach enables the generation of a correctness proof for the entire inference process in under 15 minutes. The resulting proof, compactly sized at less than 200 kB, is designed to uphold the privacy of the model parameters, ensuring no inadvertent information leakage.",
            "keywords": [
                "Zero-Knowledge Proofs",
                "Large Language Models",
                "Model Authenticity",
                "Inference Verification",
                "Privacy of Model Parameters"
            ]
        },
        "url": "URL#256851",
        "sema_paperId": "2b811ec0e19346a5e2654e5189f3f9fe2230cd8d"
    },
    {
        "@score": "1",
        "@id": "256852",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "386/7955",
                        "text": "Thomas Szymkowiak"
                    },
                    {
                        "@pid": "386/7849",
                        "text": "Endrit Isufi"
                    },
                    {
                        "@pid": "86/9795",
                        "text": "Markku-Juhani O. Saarinen"
                    }
                ]
            },
            "title": "Poster: Marian: An Open Source RISC-V Processor with Zvk Vector Cryptography Extensions.",
            "venue": "CCS",
            "pages": "4931-4933",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/SzymkowiakIS24",
            "doi": "10.1145/3658644.3691394",
            "ee": "https://doi.org/10.1145/3658644.3691394",
            "url": "https://dblp.org/rec/conf/ccs/SzymkowiakIS24",
            "abstract": "The RISC-V Vector Cryptography Extensions (Zvk) were ratified in 2023 and integrated into the main ISA manuals in 2024. These extensions support high-speed symmetric cryptography (AES, SHA2, SM3, SM4) operating on the vector register file and offer significant performance improvements over scalar cryptography extensions (Zk) due to data parallelism. As a ratified extension, Zvk is supported by compiler toolchains and is already being integrated into popular cryptographic middleware such as OpenSSL. We report on Marian, the first open-source hardware implementation of a vector processor with the Zvk extensions. The design is based on the PULP \"Ara\" vector unit, which itself is an extension of the popular CVA6 processor. The implementation is in SystemVerilog and has been tested using Virtex Ultrascale+ FPGA prototyping, with a planned tapeout targeting a 22nm process node. We offer an analysis of the architectural requirements that vector cryptography imposes on a processor, as well as the initial estimates of performance and area for our implementation.",
            "pdf_url": "",
            "keywords": [
                "RISC-V Architecture",
                "Vector Cryptography",
                "Open Source Hardware",
                "Performance Optimization",
                "Zvk Extensions"
            ]
        },
        "url": "URL#256852",
        "sema_paperId": "4e4deb8889c8068a43fdbb7dc26f02e0e189f9a0"
    },
    {
        "@score": "1",
        "@id": "256853",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "06/3696",
                        "text": "Kunal Talwar"
                    },
                    {
                        "@pid": "55/1254",
                        "text": "Shan Wang"
                    },
                    {
                        "@pid": "179/2626",
                        "text": "Audra McMillan"
                    },
                    {
                        "@pid": "67/1162",
                        "text": "Vitaly Feldman"
                    },
                    {
                        "@pid": "392/3281",
                        "text": "Pansy Bansal"
                    },
                    {
                        "@pid": "353/2071",
                        "text": "Bailey Basile"
                    },
                    {
                        "@pid": "271/8287",
                        "text": "\u00c1ine Cahill"
                    },
                    {
                        "@pid": "353/1495",
                        "text": "Yi Sheng Chan"
                    },
                    {
                        "@pid": "334/1354",
                        "text": "Mike Chatzidakis"
                    },
                    {
                        "@pid": "233/6535",
                        "text": "Junye Chen"
                    },
                    {
                        "@pid": "164/8089",
                        "text": "Oliver R. A. Chick"
                    },
                    {
                        "@pid": "351/8472",
                        "text": "Mona Chitnis"
                    },
                    {
                        "@pid": "353/2165",
                        "text": "Suman Ganta"
                    },
                    {
                        "@pid": "161/2196",
                        "text": "Yusuf Goren"
                    },
                    {
                        "@pid": "271/8434",
                        "text": "Filip Granqvist"
                    },
                    {
                        "@pid": "353/1514",
                        "text": "Kristine Guo"
                    },
                    {
                        "@pid": "149/2725",
                        "text": "Frederic Jacobs"
                    },
                    {
                        "@pid": "10/11068",
                        "text": "Omid Javidbakht"
                    },
                    {
                        "@pid": "03/2992",
                        "text": "Albert Liu"
                    },
                    {
                        "@pid": "149/5419",
                        "text": "Richard Low"
                    },
                    {
                        "@pid": "353/2170",
                        "text": "Dan Mascenik"
                    },
                    {
                        "@pid": "203/2883",
                        "text": "Steve Myers"
                    },
                    {
                        "@pid": "189/4308",
                        "text": "David Park"
                    },
                    {
                        "@pid": "93/6684",
                        "text": "Wonhee Park"
                    },
                    {
                        "@pid": "334/1300",
                        "text": "Gianni Parsa"
                    },
                    {
                        "@pid": "210/4743",
                        "text": "Tommy Pauly"
                    },
                    {
                        "@pid": "161/6100",
                        "text": "Christian Priebe"
                    },
                    {
                        "@pid": "285/6076",
                        "text": "Rehan Rishi"
                    },
                    {
                        "@pid": "00/6232",
                        "text": "Guy N. Rothblum"
                    },
                    {
                        "@pid": "186/8335",
                        "text": "Congzheng Song"
                    },
                    {
                        "@pid": "160/1268",
                        "text": "Linmao Song"
                    },
                    {
                        "@pid": "353/2055",
                        "text": "Karl Tarbe"
                    },
                    {
                        "@pid": "67/3413-3",
                        "text": "Sebastian Vogt 0003"
                    },
                    {
                        "@pid": "334/1409",
                        "text": "Shundong Zhou"
                    },
                    {
                        "@pid": "334/1770",
                        "text": "Vojta Jina"
                    },
                    {
                        "@pid": "353/2493",
                        "text": "Michael Scaria"
                    },
                    {
                        "@pid": "353/2464",
                        "text": "Luke Winstrom"
                    }
                ]
            },
            "title": "Samplable Anonymous Aggregation for Private Federated Data Analysis.",
            "venue": "CCS",
            "pages": "2859-2873",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/TalwarWMFBBCCCC24",
            "doi": "10.1145/3658644.3690224",
            "ee": "https://doi.org/10.1145/3658644.3690224",
            "url": "https://dblp.org/rec/conf/ccs/TalwarWMFBBCCCC24",
            "abstract": "We revisit the problem of designing scalable protocols for private statistics and private federated learning when each device holds its private data. Locally differentially private algorithms require little trust but are (provably) limited in their utility. Centrally differentially private algorithms can allow significantly better utility but require a trusted curator. This gap has led to significant interest in the design and implementation of simple cryptographic primitives, that can allow central-like utility guarantees without having to trust a central server.",
            "pdf_url": "",
            "keywords": [
                "Private Data Analysis",
                "Federated Learning",
                "Differential Privacy",
                "Cryptographic Primitives",
                "Utility Guarantees"
            ]
        },
        "url": "URL#256853"
    },
    {
        "@score": "1",
        "@id": "256854",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "253/8184",
                        "text": "Guofeng Tang"
                    },
                    {
                        "@pid": "59/9242-1",
                        "text": "Shuai Han 0001"
                    },
                    {
                        "@pid": "38/4000",
                        "text": "Li Lin"
                    },
                    {
                        "@pid": "195/7421",
                        "text": "Changzheng Wei"
                    },
                    {
                        "@pid": "77/4933-2",
                        "text": "Ying Yan 0002"
                    }
                ]
            },
            "title": "Batch Range Proof: How to Make Threshold ECDSA More Efficient.",
            "venue": "CCS",
            "pages": "4256-4270",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/TangHLWY24",
            "doi": "10.1145/3658644.3670287",
            "ee": "https://doi.org/10.1145/3658644.3670287",
            "url": "https://dblp.org/rec/conf/ccs/TangHLWY24",
            "abstract": "With the demand of cryptocurrencies, threshold ECDSA recently regained popularity. So far, several methods have been proposed to construct threshold ECDSA, including the usage of OT and homomorphic encryptions (HE). Due to the mismatch between the plaintext space and the signature space, HE-based threshold ECDSA always requires zero-knowledge range proofs, such as Paillier and Joye-Libert (JL) encryptions. However, the overhead of range proofs constitutes a major portion of the total cost.",
            "pdf_url": "",
            "keywords": [
                "Threshold ECDSA",
                "Cryptography",
                "Homomorphic Encryption",
                "Range Proofs",
                "Efficiency"
            ]
        },
        "url": "URL#256854"
    },
    {
        "@score": "1",
        "@id": "256855",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "392/3152",
                        "text": "Zhaozhou Tang"
                    },
                    {
                        "@pid": "295/0479",
                        "text": "Khaled Serag"
                    },
                    {
                        "@pid": "89/4316",
                        "text": "Saman A. Zonouz"
                    },
                    {
                        "@pid": "143/2298",
                        "text": "Z. Berkay Celik"
                    },
                    {
                        "@pid": "59/5539",
                        "text": "Dongyan Xu"
                    },
                    {
                        "@pid": "12/6354",
                        "text": "Raheem Beyah"
                    }
                ]
            },
            "title": "ERACAN: Defending Against an Emerging CAN Threat Model.",
            "venue": "CCS",
            "pages": "1894-1908",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/TangSZCXB24",
            "doi": "10.1145/3658644.3690267",
            "ee": "https://doi.org/10.1145/3658644.3690267",
            "url": "https://dblp.org/rec/conf/ccs/TangSZCXB24",
            "abstract": "The Controller Area Network (CAN) is a pivotal communication protocol extensively utilized in vehicles, aircraft, factories, and diverse cyber-physical systems (CPSs). The extensive CAN security literature resulting from decades of wide usage may create an impression of thorough scrutiny. However, a closer look reveals its reliance on a specific threat model with a limited range of abilities. Notably, recent works show that this model is outdated and that a more potent and versatile model could soon become the norm, prompting the need for a new defense paradigm. Unfortunately, the security impact of this emerging model on CAN systems has not received sufficient attention, and the defense systems addressing it are almost nonexistent. In this paper, we introduce ERACAN, the first comprehensive defense system against this new threat model. We first begin with a threat analysis to ensure that ERACAN comprehensively understands this model's capabilities, evasion tactics, and propensity to enable new attacks or enhance existing ones. ERACAN offers versatile protection against this spectrum of threats, providing attack detection, classification, and optional prevention abilities. We implement and evaluate ERACAN on a testbed and a real vehicle's CAN bus to demonstrate its low latency, real-time operation, and protective capabilities. ERACAN achieves detection rates of 100% and 99.7%+ for all attacks launched by the conventional and the enhanced threat models, respectively.",
            "pdf_url": "",
            "keywords": [
                "Controller Area Network (CAN)",
                "Cyber-Physical Systems (CPS)",
                "Threat Model",
                "ERACAN Defense System",
                "Attack Detection and Classification"
            ]
        },
        "url": "URL#256855",
        "sema_paperId": "557b001c87f5390d266ac3c6ab81d967c3f2c5db"
    },
    {
        "@score": "1",
        "@id": "256856",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "368/7278",
                        "text": "Wenxu Tang"
                    },
                    {
                        "@pid": "153/3132",
                        "text": "Fangyu Zheng"
                    },
                    {
                        "@pid": "46/2041",
                        "text": "Guang Fan"
                    },
                    {
                        "@pid": "31/4578",
                        "text": "Tian Zhou"
                    },
                    {
                        "@pid": "57/4208",
                        "text": "Jingqiang Lin"
                    },
                    {
                        "@pid": "70/3282",
                        "text": "Jiwu Jing"
                    }
                ]
            },
            "title": "DPad-HE: Towards Hardware-friendly Homomorphic Evaluation using 4-Directional Manipulation.",
            "venue": "CCS",
            "pages": "2475-2489",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/TangZFZLJ24",
            "doi": "10.1145/3658644.3690280",
            "ee": "https://doi.org/10.1145/3658644.3690280",
            "url": "https://dblp.org/rec/conf/ccs/TangZFZLJ24",
            "abstract": "Module Learning with Errors (MLWE) based approaches for Fully Homomorphic Encryption (FHE) have garnered attention due to their potential to enhance hardware-friendliness and implementation efficiency. However, despite these advantages, their overall performance still trails behind traditional schemes based on Ring Learning with Errors (RLWE). This indicates that while MLWE-based constructions hold promise, there remain significant challenges to overcome in bridging the performance gap with RLWE-based FHE schemes. By uncovering the reasons for the unsatisfactory performance of prior schemes and pinpointing the fundamental differences in the design of MLWE-based FHE compared to traditional approaches, the paper introduces DPad-HE with a novel design incorporating manipulation in the module rank dimension. The newly introduced operations, rank-up, and rank-down, effectively regulate the scale of gadget decomposition, reducing the computational workload of key-switching by several times. Taking CKKS as a case study, the evaluation showcases the comprehensive advantages of DPad-HE over the state-of-the-art MLWE-based scheme, resulting in a performance boost of 1.26\u00d7 to 5.71\u00d7, a reduction in key size from 1/3 to 3/4, with enhanced noise control. To test the hardware-friendliness of the solution, DPad-HE is also implemented on GPU. Notably, DPad-HE demonstrates that, for the first time, the execution latency of MLWE-based schemes can achieve comparable performance with traditional RLWE ones, especially on the GPU platform where a speedup up to 1.41\u00d7 is witnessed. Additionally, this paper provides a lightweight conversion method between RLWE and MLWE ciphertexts, allowing for flexible selection of RLWE and MLWE settings during a single complete evaluation process. This opens up new possibilities for both RLWE-based and MLWE-based FHEs.",
            "pdf_url": "",
            "keywords": [
                "Fully Homomorphic Encryption",
                "Module Learning with Errors",
                "Performance Optimization",
                "Key-switching",
                "GPU Implementation"
            ]
        },
        "url": "URL#256856",
        "sema_paperId": "f2407f91cb4e833f31b2c1f90873e98c47cbb950"
    },
    {
        "@score": "1",
        "@id": "256857",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "338/8894",
                        "text": "Kunsheng Tang"
                    },
                    {
                        "@pid": "124/2075",
                        "text": "Wenbo Zhou"
                    },
                    {
                        "@pid": "84/6889-73",
                        "text": "Jie Zhang 0073"
                    },
                    {
                        "@pid": "177/5658",
                        "text": "Aishan Liu"
                    },
                    {
                        "@pid": "236/9144",
                        "text": "Gelei Deng"
                    },
                    {
                        "@pid": "57/2281",
                        "text": "Shuai Li"
                    },
                    {
                        "@pid": "386/2071",
                        "text": "Peigui Qi"
                    },
                    {
                        "@pid": "20/612-1",
                        "text": "Weiming Zhang 0001"
                    },
                    {
                        "@pid": "77/7902-4",
                        "text": "Tianwei Zhang 0004"
                    },
                    {
                        "@pid": "96/5144",
                        "text": "Nenghai Yu"
                    }
                ]
            },
            "title": "GenderCARE: A Comprehensive Framework for Assessing and Reducing Gender Bias in Large Language Models.",
            "venue": "CCS",
            "pages": "1196-1210",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/TangZZLDLQ00Y24",
            "doi": "10.1145/3658644.3670284",
            "ee": "https://doi.org/10.1145/3658644.3670284",
            "url": "https://dblp.org/rec/conf/ccs/TangZZLDLQ00Y24",
            "abstract": "Large language models (LLMs) have exhibited remarkable capabilities in natural language generation, but they have also been observed to magnify societal biases, particularly those related to gender. In response to this issue, several benchmarks have been proposed to assess gender bias in LLMs. However, these benchmarks often lack practical flexibility or inadvertently introduce biases. To address these shortcomings, we introduce GenderCARE, a comprehensive framework that encompasses innovative Criteria, bias Assessment, Reduction techniques, and Evaluation metrics for quantifying and mitigating gender bias in LLMs. To begin, we establish pioneering criteria for gender equality benchmarks, spanning dimensions such as inclusivity, diversity, explainability, objectivity, robustness, and realisticity. Guided by these criteria, we construct GenderPair, a novel pair-based benchmark designed to assess gender bias in LLMs comprehensively. Our benchmark provides standardized and realistic evaluations, including previously overlooked gender groups such as transgender and non-binary individuals. Furthermore, we develop effective debiasing techniques that incorporate counterfactual data augmentation and specialized fine-tuning strategies to reduce gender bias in LLMs without compromising their overall performance. Extensive experiments demonstrate a significant reduction in various gender bias benchmarks, with reductions peaking at over 90% and averaging above 35% across 17 different LLMs. Importantly, these reductions come with minimal variability in mainstream language tasks, remaining below 2%. By offering a realistic assessment and tailored reduction of gender biases, we hope that our GenderCARE can represent a significant step towards achieving fairness and equity in LLMs. More details are available at https://github.com/kstanghere/GenderCARE-ccs24.",
            "keywords": [
                "Gender Bias in Language Models",
                "Bias Assessment",
                "Debiasing Techniques",
                "Inclusivity and Diversity",
                "Gender Equality Benchmarks"
            ]
        },
        "url": "URL#256857",
        "sema_paperId": "be3690748239e85e164a0f9eed3b4db7eb4407b0"
    },
    {
        "@score": "1",
        "@id": "256858",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "265/5746",
                        "text": "Ertem Nusret Tas"
                    },
                    {
                        "@pid": "234/7668",
                        "text": "Istv\u00e1n Andr\u00e1s Seres"
                    },
                    {
                        "@pid": "90/7422",
                        "text": "Yinuo Zhang"
                    },
                    {
                        "@pid": "202/7199",
                        "text": "M\u00e1rk Melczer"
                    },
                    {
                        "@pid": "218/7156",
                        "text": "Mahimna Kelkar"
                    },
                    {
                        "@pid": "27/3087",
                        "text": "Joseph Bonneau"
                    },
                    {
                        "@pid": "24/9744",
                        "text": "Valeria Nikolaenko"
                    }
                ]
            },
            "title": "Atomic and Fair Data Exchange via Blockchain.",
            "venue": "CCS",
            "pages": "3227-3241",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/TasSZMKBN24",
            "doi": "10.1145/3658644.3690248",
            "ee": "https://doi.org/10.1145/3658644.3690248",
            "url": "https://dblp.org/rec/conf/ccs/TasSZMKBN24",
            "abstract": "We introduce a blockchainFair Data Exchange(FDE) protocol, enabling a storage server to transfer a data file to a client atomically: the client receives the file if and only if the server receives an agreed-upon payment. We put forth a new definition for a cryptographic scheme that we name verifiable encryption under committed key (VECK), and we propose two instantiations for this scheme. Our protocol relies on a blockchain to enforce the atomicity of the exchange and uses VECK to ensure that the client receives the correct data (matching an agreed-upon commitment) before releasing the payment for the decrypting key. Our protocol is trust-minimized and requires only constant-sized on-chain communication, concretely 3 signatures, 1 verification key, and 1 secret key, with most of the data stored and communicated off-chain. It also supports exchanging only a subset of the data, can amortize the server's work across multiple clients, and offers a general framework to design alternative FDE protocols using different commitment schemes. A prominent application of our protocol is the Danksharding data availability scheme on Ethereum, which commits to data via KZG polynomial commitments. We also provide an open-source implementation for our protocol with both instantiations for VECK, demonstrating our protocol's efficiency and practicality on Ethereum.",
            "pdf_url": "",
            "keywords": [
                "Blockchain",
                "Fair Data Exchange",
                "Verifiable Encryption",
                "Atomic Transactions",
                "Data Availability"
            ]
        },
        "url": "URL#256858"
    },
    {
        "@score": "1",
        "@id": "256859",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "392/3195",
                        "text": "Kevin Nsieyanji Tchokodeu"
                    },
                    {
                        "@pid": "94/7397",
                        "text": "Haya Schulmann"
                    },
                    {
                        "@pid": "204/8314",
                        "text": "Gil Sobol"
                    },
                    {
                        "@pid": "90/308",
                        "text": "Michael Waidner"
                    }
                ]
            },
            "title": "Poster: Security of Login Interfaces in Modern Organizations.",
            "venue": "CCS",
            "pages": "4925-4927",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/TchokodeuSSW24",
            "doi": "10.1145/3658644.3691413",
            "ee": "https://doi.org/10.1145/3658644.3691413",
            "url": "https://dblp.org/rec/conf/ccs/TchokodeuSSW24",
            "abstract": "Login pages, including those for processes like sign-up, registration, and password recovery are interfaces that implement access control to company services or functionalities. Insufficient security on these pages could allow malicious individuals to gain access to services and network of an organization and launch attacks. In this work, we perform a comprehensive study of the security of 73.4k login interfaces of the 100-top European companies from the Fortune report, which we call EU100. We find over 9 million vulnerabilities, which we analyze from a technical perspective, and categorize them according to the hosting model. Our work provides details on the most commonly observed vulnerabilities on login pages across different sectors and according to the hosting strategy adopted by each company.",
            "pdf_url": "",
            "keywords": [
                "Login Interface Security",
                "Vulnerability Analysis",
                "Access Control Vulnerabilities",
                "Hosting Model",
                "EU100 Companies"
            ]
        },
        "url": "URL#256859",
        "sema_paperId": "ebb22de52c62d2a9b54878a3884eb653e0b7aabd"
    },
    {
        "@score": "1",
        "@id": "256860",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "223/4446",
                        "text": "J\u00e9r\u00e9my Thibault"
                    },
                    {
                        "@pid": "46/7049",
                        "text": "Roberto Blanco"
                    },
                    {
                        "@pid": "97/5095",
                        "text": "Dongjae Lee"
                    },
                    {
                        "@pid": "351/6536",
                        "text": "Sven Argo"
                    },
                    {
                        "@pid": "134/9064",
                        "text": "Arthur Azevedo de Amorim"
                    },
                    {
                        "@pid": "192/1954",
                        "text": "A\u00efna Linn Georges"
                    },
                    {
                        "@pid": "09/2281",
                        "text": "Catalin Hritcu"
                    },
                    {
                        "@pid": "t/AndrewPTolmach",
                        "text": "Andrew Tolmach"
                    }
                ]
            },
            "title": "SECOMP: Formally Secure Compilation of Compartmentalized C Programs.",
            "venue": "CCS",
            "pages": "1061-1075",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ThibaultBLAAGHT24",
            "doi": "10.1145/3658644.3670288",
            "ee": "https://doi.org/10.1145/3658644.3670288",
            "url": "https://dblp.org/rec/conf/ccs/ThibaultBLAAGHT24",
            "abstract": "Undefined behavior in C often causes devastating security vulnerabilities. One practical mitigation is compartmentalization, which allows developers to structure large programs into mutually distrustful compartments with clearly specified privileges and interactions. In this paper we introduce SECOMP, a compiler for compartmentalized C code that comes with machine-checked proofs guaranteeing that the scope of undefined behavior is restricted to the compartments that encounter it and become dynamically compromised. These guarantees are formalized as the preservation of safety properties against adversarial contexts, a secure compilation criterion similar to full abstraction, and this is the first time such a strong criterion is proven for a mainstream programming language. To achieve this we extend the languages of the CompCert verified C compiler with isolated compartments that can only interact via procedure calls and returns, as specified by cross-compartment interfaces. We adapt the passes and optimizations of CompCert as well as their correctness proofs to this compartment-aware setting. We then use compiler correctness as an ingredient in a larger secure compilation proof that involves several proof engineering novelties, needed to scale formally secure compilation up to a C compiler.",
            "keywords": [
                "Compartmentalization",
                "Secure Compilation",
                "Undefined Behavior",
                "C Programming",
                "Formal Verification"
            ]
        },
        "url": "URL#256860",
        "sema_paperId": "654b2dc8d3da193b8912fd9517493723db628ce0"
    },
    {
        "@score": "1",
        "@id": "256861",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "387/3902",
                        "text": "Khiem Ton"
                    },
                    {
                        "@pid": "331/5504",
                        "text": "Nhi Nguyen"
                    },
                    {
                        "@pid": "158/0425",
                        "text": "Mahmoud Nazzal"
                    },
                    {
                        "@pid": "39/1037",
                        "text": "Abdallah Khreishah"
                    },
                    {
                        "@pid": "69/87",
                        "text": "Cristian Borcea"
                    },
                    {
                        "@pid": "153/5204",
                        "text": "NhatHai Phan"
                    },
                    {
                        "@pid": "72/4662",
                        "text": "Ruoming Jin"
                    },
                    {
                        "@pid": "115/8715",
                        "text": "Issa Khalil"
                    },
                    {
                        "@pid": "37/9376",
                        "text": "Yelong Shen"
                    }
                ]
            },
            "title": "Demo: SGCode: A Flexible Prompt-Optimizing System for Secure Generation of Code.",
            "venue": "CCS",
            "pages": "5078-5080",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/TonNNKBPJKS24",
            "doi": "10.1145/3658644.3691367",
            "ee": "https://doi.org/10.1145/3658644.3691367",
            "url": "https://dblp.org/rec/conf/ccs/TonNNKBPJKS24",
            "abstract": "This paper introduces SGCode, a flexible prompt-optimizing system to generate secure code with large language models (LLMs). SGCode integrates recent prompt-optimization approaches with LLMs in a unified system accessible through front-end and back-end APIs, enabling users to 1) generate secure code, which is free of vulnerabilities, 2) review and share security analysis, and 3) easily switch from one prompt optimization approach to another, while providing insights on model and system performance. We populated SGCode on an AWS server with PromSec, an approach that optimizes prompts by combining an LLM and security tools with a lightweight generative adversarial graph neural network to detect and fix security vulnerabilities in the generated code. Extensive experiments show that SGCode is practical as a public tool to gain insights into the trade-offs between model utility, secure code generation, and system cost. SGCode has only a marginal cost compared with prompting LLMs. SGCode is available at: https://sgcode.codes/.",
            "keywords": [
                "Secure Code Generation",
                "Prompt Optimization",
                "Vulnerability Detection",
                "Generative Adversarial Graph Neural Network",
                "Security Analysis"
            ]
        },
        "url": "URL#256861",
        "sema_paperId": "c57b0d884bf26a29316a790daad2764c75aaf634"
    },
    {
        "@score": "1",
        "@id": "256862",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "11/4740",
                        "text": "Wei Tong"
                    },
                    {
                        "@pid": "146/8170",
                        "text": "Haoyu Chen"
                    },
                    {
                        "@pid": "361/4952",
                        "text": "Jiacheng Niu"
                    },
                    {
                        "@pid": "53/4506-2",
                        "text": "Sheng Zhong 0002"
                    }
                ]
            },
            "title": "Data Poisoning Attacks to Locally Differentially Private Frequent Itemset Mining Protocols.",
            "venue": "CCS",
            "pages": "3555-3569",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/TongCN024",
            "doi": "10.1145/3658644.3670298",
            "ee": "https://doi.org/10.1145/3658644.3670298",
            "url": "https://dblp.org/rec/conf/ccs/TongCN024",
            "abstract": "Local differential privacy (LDP) provides a way for an untrusted data collector to aggregate users' data without violating their privacy. Various privacy-preserving data analysis tasks have been studied under the protection of LDP, such as frequency estimation, frequent itemset mining, and machine learning. Despite its privacy-preserving properties, recent research has demonstrated the vulnerability of certain LDP protocols to data poisoning attacks. However, existing data poisoning attacks are focused on basic statistics under LDP, such as frequency estimation and mean/variance estimation. As an important data analysis task, the security of LDP frequent itemset mining has yet to be thoroughly examined. In this paper, we aim to address this issue by presenting novel and practical data poisoning attacks against LDP frequent itemset mining protocols. By introducing a unified attack framework with composable attack operations, our data poisoning attack can successfully manipulate the state-of-the-art LDP frequent itemset mining protocols and has the potential to be adapted to other protocols with similar structures. We conduct extensive experiments on three datasets to compare the proposed attack with four baseline attacks. The results demonstrate the severity of the threat and the effectiveness of the proposed attack.",
            "keywords": [
                "Local Differential Privacy",
                "Frequent Itemset Mining",
                "Data Poisoning Attacks",
                "Privacy-Preserving Protocols",
                "LDP Vulnerabilities"
            ]
        },
        "url": "URL#256862",
        "sema_paperId": "7c28a01ec4a8f3b83aca039d7c5dc99a6f21d24a"
    },
    {
        "@score": "1",
        "@id": "256863",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "185/1711",
                        "text": "Santiago Torres-Arias"
                    },
                    {
                        "@pid": "157/0143",
                        "text": "Marcela S. Melara"
                    }
                ]
            },
            "title": "SCORED &apos;24: Workshop on Software Supply Chain Offensive Research and Ecosystem Defenses.",
            "venue": "CCS",
            "pages": "4917-4918",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Torres-AriasM24",
            "doi": "10.1145/3658644.3691554",
            "ee": "https://doi.org/10.1145/3658644.3691554",
            "url": "https://dblp.org/rec/conf/ccs/Torres-AriasM24",
            "abstract": "Recent attacks on the software supply chain have shed light on the fragility and importance of ensuring the security and integrity of this vital ecosystem. Addressing the technical and social challenges to building trustworthy software for deployment in sensitive and/or large-scale enterprise or governmental settings requires innovative solutions and an interdisciplinary approach. The Workshop on Software Supply Chain Offensive Research and Ecosystem Defenses (SCORED) is the leading venue for bringing together industry practitioners, academics, and policymakers to present and discuss security vulnerabilities, novel defenses against attacks, project demos, adoption requirements and best practices in the software supply chain. The complete SCORED '24 workshop proceedings are available at: https://doi.org/10.1145/3689944",
            "pdf_url": "",
            "keywords": [
                "Software Supply Chain",
                "Security Vulnerabilities",
                "Interdisciplinary Approaches",
                "Ecosystem Defenses",
                "Trustworthy Software"
            ]
        },
        "url": "URL#256863",
        "sema_paperId": "93271a0909c91e1a26a4726af6a73ba0135af22a"
    },
    {
        "@score": "1",
        "@id": "256864",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "169/2279",
                        "text": "Christof Ferreira Torres"
                    },
                    {
                        "@pid": "377/3648",
                        "text": "Albin Mamuti"
                    },
                    {
                        "@pid": "270/8815",
                        "text": "Ben Weintraub"
                    },
                    {
                        "@pid": "n/CristinaNitaRotaru",
                        "text": "Cristina Nita-Rotaru"
                    },
                    {
                        "@pid": "136/8404",
                        "text": "Shweta Shinde"
                    }
                ]
            },
            "title": "Rolling in the Shadows: Analyzing the Extraction of MEV Across Layer-2 Rollups.",
            "venue": "CCS",
            "pages": "2591-2605",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/TorresMWNS24",
            "doi": "10.1145/3658644.3690259",
            "ee": "https://doi.org/10.1145/3658644.3690259",
            "url": "https://dblp.org/rec/conf/ccs/TorresMWNS24",
            "abstract": "The emergence of decentralized finance has transformed asset trading on the blockchain, making traditional financial instruments more accessible while also introducing a series of exploitative economic practices known as Maximal Extractable Value (MEV). Concurrently, decentralized finance has embraced rollup-based Layer-2 solutions to facilitate asset trading at reduced transaction costs compared to Layer-1 solutions such as Ethereum. However, rollups lack a public mempool like Ethereum, making the extraction of MEV more challenging.",
            "pdf_url": "",
            "keywords": [
                "Decentralized Finance",
                "Maximal Extractable Value (MEV)",
                "Layer-2 Rollups",
                "Transaction Costs",
                "MEV Extraction Challenges"
            ]
        },
        "url": "URL#256864"
    },
    {
        "@score": "1",
        "@id": "256865",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "379/2096",
                        "text": "Elkana Tovey"
                    },
                    {
                        "@pid": "84/4293",
                        "text": "Jonathan Weiss"
                    },
                    {
                        "@pid": "84/7357",
                        "text": "Yossi Gilad"
                    }
                ]
            },
            "title": "Distributed PIR: Scaling Private Messaging via the Users&apos; Machines.",
            "venue": "CCS",
            "pages": "1967-1981",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ToveyWG24",
            "doi": "10.1145/3658644.3670350",
            "ee": "https://doi.org/10.1145/3658644.3670350",
            "url": "https://dblp.org/rec/conf/ccs/ToveyWG24",
            "abstract": "This paper presents a new architecture for metadata-private messaging that counters scalability challenges by offloading most computations to the clients. At the core of our design is a distributed private information retrieval (PIR) protocol, where the responder delegates its work to alleviate PIR's computational bottleneck and catches misbehaving delegates by efficiently verifying their results. We introduce DPIR, a messaging system that uses distributed PIR to let a server storing messages delegate the work to the system's clients, such that each client contributes proportional processing to the number of messages it reads. The server removes clients returning invalid results, which DPIR leverages to integrate an incentive mechanism for honest client behavior by conditioning messaging through DPIR on correctly processing PIR requests from other users. The result is a metadata-private messaging system that asymptotically improves scalability over prior work with the same threat model. We show through experiments on a prototype implementation that DPIR concretely improves performance by 3.25\u00d7 and 4.31\u00d7 over prior work [3, 5] and that the performance gap grows with the user base~size.",
            "pdf_url": "",
            "keywords": [
                "Distributed Private Information Retrieval",
                "Metadata-Private Messaging",
                "Scalability Challenges",
                "Client-Server Architecture",
                "Incentive Mechanism"
            ]
        },
        "url": "URL#256865"
    },
    {
        "@score": "1",
        "@id": "256866",
        "info": {
            "authors": {
                "author": {
                    "@pid": "315/5115",
                    "text": "Theodoros Trochatos"
                }
            },
            "title": "Trusted Execution Environments for Quantum Computers.",
            "venue": "CCS",
            "pages": "5089-5091",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Trochatos24",
            "doi": "10.1145/3658644.3690855",
            "ee": "https://doi.org/10.1145/3658644.3690855",
            "url": "https://dblp.org/rec/conf/ccs/Trochatos24",
            "abstract": "The cloud-based environments in which today's and future quantum computers will operate, raise concerns about the security and privacy of user's intellectual property. Quantum circuits submitted to cloud-based quantum computer providers represent sensitive or proprietary algorithms developed by users that need protection. Further, input data is hard-coded into the circuits and leakage of the circuits can expose users' data. Although still in the Noisy Intermediate Scale Quantum regime, quantum computers hold promise to be able to execute novel algorithms and create invaluable data. However, just as with any other type of computing resource, they may be vulnerable to security attacks and should have defenses built into their hardware and software design. % In classical computing, a Trusted Execution Environment (TEE) is an area on the main processor of a device that is separated from the system's main operating system, which ensures data is stored, processed and protected in a secure environment. Similar to the classical computing, by leveraging trusted hardware, we propose Trusted Execution Environments for quantum computers. The proposed thesis will explore the feasibility and the security of the quantum computer Trusted Execution Environment architecture as a novel security primitive. In this prospectus, the challenges and approaches are outlined, current results are presented to show the feasibility of the proposed work and a timeline of future work is given.",
            "pdf_url": "",
            "keywords": [
                "Quantum Computing Security",
                "Trusted Execution Environments",
                "Cloud-based Quantum Computing",
                "Intellectual Property Protection",
                "Data Leakage Prevention"
            ]
        },
        "url": "URL#256866",
        "sema_paperId": "6bf42fe7a2759f2c40c165fbfd1f220bfb8593e3"
    },
    {
        "@score": "1",
        "@id": "256867",
        "info": {
            "authors": {
                "author": {
                    "@pid": "08/1183",
                    "text": "Gene Tsudik"
                }
            },
            "title": "Staving off the IoT Armageddon.",
            "venue": "CCS",
            "pages": "2-3",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Tsudik24",
            "doi": "10.1145/3658644.3690379",
            "ee": "https://doi.org/10.1145/3658644.3690379",
            "url": "https://dblp.org/rec/conf/ccs/Tsudik24",
            "abstract": "IoT devices are increasingly popular and ubiquitous in numerous everyday settings. These specialized gadgets sense and actuate the environment using a wide range of analog peripherals. They are usually deployed in large numbers and often perform safety-and/or mission-critical tasks, in both military and civilian domains. It is no surprise that they represent attractive targets for various attacks. Adversaries range from nation-states to groups (motivated by politics, competition, or greed), to individual malcontents. Their goals vary based on targeted functionality: compromised sensors can exfiltrate sensitive information, while compromised actuators can affect the environment, i.e., physical safety and security. The well-known Stuxnet (2010) is an example of the latter, while numerous hacks into IoT cams exemplify the former. The infamous Mirai botnet (2017) is yet another \"preview of coming attractions\": it successfully zombified a huge number of consumer-grade cameras to form a global botnet later used to mount massive Distributed Denialof- Service (DDoS) attacks.1 Sadly, recent history shows that few, if any, lessons were learned as a result of these attacks. Although not quite malware-relevant, the recent CrowdStrike fiasco underscores the problem. IoT devices are still commonly compromised via both known attack types and zero-day exploits. Realistically speaking, the worst is yet to come. Unfortunately, the current security research limelight is on (both real and imagined) dangers of AI and Machine Learning algorithms, their unfairness, etc. There is thus a real risk of missing the real and present danger posed by the rampant (in)security of the IoT ecosystem.",
            "pdf_url": "",
            "keywords": [
                "IoT Security",
                "Cybersecurity Threats",
                "Device Compromise",
                "DDoS Attacks",
                "Vulnerability Exploitation"
            ]
        },
        "url": "URL#256867",
        "sema_paperId": "8c0448c75338d415f9ae0a218203e3c33dda158b"
    },
    {
        "@score": "1",
        "@id": "256868",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "147/7755",
                        "text": "Rei Ueno"
                    },
                    {
                        "@pid": "305/3597",
                        "text": "Hiromichi Haneda"
                    },
                    {
                        "@pid": "72/699",
                        "text": "Naofumi Homma"
                    },
                    {
                        "@pid": "202/3104",
                        "text": "Akiko Inoue"
                    },
                    {
                        "@pid": "72/3032",
                        "text": "Kazuhiko Minematsu"
                    }
                ]
            },
            "title": "Crystalor: Recoverable Memory Encryption Mechanism with Optimized Metadata Structure.",
            "venue": "CCS",
            "pages": "228-242",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/UenoHHIM24",
            "doi": "10.1145/3658644.3670273",
            "ee": "https://doi.org/10.1145/3658644.3670273",
            "url": "https://dblp.org/rec/conf/ccs/UenoHHIM24",
            "abstract": "This study presents an efficient recoverable memory encryption mechanism, named Crystalor. Existing memory encryption mechanisms, such as Intel SGX integrity tree, offer neither crash consistency nor recoverability, which results in attack surfaces and causes a non-trivial limitation of practical availability. Although the crash consistency of encrypted memory has been studied in the research field of microarchitecture, existing mechanisms lack formal security analysis and cannot incorporate with metadata optimization mechanisms, which are essential to achieve a practical performance. Crystalor efficiently realizes provably-secure recoverable memory encryption with metadata optimization. To establish Crystalor with provable security and practical performance, we develop a dedicated universal hash function PXOR-Hash and a microarchitecture equipped with PXOR-Hash. Crystalor incurs almost no latency overhead under the nominal operations for the recoverability, while it has a simple construction in such a way as to be compatible with existing microarchitectures. We evaluate its practical performance through both algorithmic analyses and system-level simulation in comparison with the state-of-the-art ones, such as SCUE. Crystalor requires 29\u201362% fewer clock cycles per memory read/write operation than SCUE for protecting a 4TB memory. In addition, Crystalor and SCUE require 312GB and 554GB memory overheads for metadata, respectively, which indicates that Crystalor achieves a memory overhead reduction of 44%. The results of the system-level simulation using the gem5 simulator indicate that Crystalor achieves a reduction of up to 11.5% in the workload execution time compared to SCUE. Moreover, Crys-talor achieves a higher availability and memory recovery several thousand times faster than SCUE, as Crystalor offers lazy recovery .",
            "keywords": [
                "Memory Encryption",
                "Recoverable Memory",
                "Crash Consistency",
                "Metadata Optimization",
                "Performance Evaluation"
            ]
        },
        "url": "URL#256868",
        "sema_paperId": "72dbe03a3e74e617362b0cc0c51301c8bd30d104"
    },
    {
        "@score": "1",
        "@id": "256869",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "19/133",
                        "text": "Enriquillo Valdez"
                    },
                    {
                        "@pid": "80/6689-1",
                        "text": "Salman Ahmed 0001"
                    },
                    {
                        "@pid": "76/10471",
                        "text": "Zhongshu Gu"
                    },
                    {
                        "@pid": "54/2629",
                        "text": "Christophe de Dinechin"
                    },
                    {
                        "@pid": "30/1561",
                        "text": "Pau-Chen Cheng"
                    },
                    {
                        "@pid": "45/1350",
                        "text": "Hani Jamjoom"
                    }
                ]
            },
            "title": "Crossing Shifted Moats: Replacing Old Bridges with New Tunnels to Confidential Containers.",
            "venue": "CCS",
            "pages": "1390-1404",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Valdez0GDCJ24",
            "doi": "10.1145/3658644.3670352",
            "ee": "https://doi.org/10.1145/3658644.3670352",
            "url": "https://dblp.org/rec/conf/ccs/Valdez0GDCJ24",
            "abstract": "The Confidential Containers (CoCo) project, as an open-source community initiative, inherits the system architecture of Kata Containers while integrating confidential computing to protect cloud-native container workloads. However, there exists a misalignment in the threat model and trusted computing base (TCB) between Kata Containers and confidential computing. The shifted trust boundaries could potentially expose a range of vulnerabilities, particularly in scenarios where a malicious actor on the host gains access to the CoCo's unprotected control interface. This paper conducts a thorough examination of CoCo's system architecture, exploring the attack surface resulting from the discord in trust boundaries. We have assessed all API endpoints of CoCo's control interface, categorizing them based on their security properties. Drawing from these insights, we have developed a bifurcation approach to splitting CoCo's control interface. This involves establishing an owner-side controller and minimizing the capabilities of the existing host-side controller. Under this framework, the host-side controller is exclusively responsible for allocating and recycling compute resources, while dedicated workload owners can directly manage their containers through alternative secure tunnels. This approach ensures seamless integration with cloud-native orchestration layers and aligns CoCo with the threat model of confidential computing. By doing so, it effectively prevents untrusted hosts from accessing confidential data and interfering with the execution of workloads within protected domains.",
            "pdf_url": "",
            "keywords": [
                "Confidential Computing",
                "Kata Containers",
                "Control Interface Security",
                "Trust Boundaries",
                "Resource Allocation Vulnerabilities"
            ]
        },
        "url": "URL#256869",
        "sema_paperId": "91d5cc17457e6ca4986fafb2515871983875a0cf"
    },
    {
        "@score": "1",
        "@id": "256870",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "392/3132",
                        "text": "Jasmine Vang"
                    },
                    {
                        "@pid": "159/3688",
                        "text": "Matthew Revelle"
                    }
                ]
            },
            "title": "Poster: Formalizing Cognitive Biases for Cybersecurity Defenses.",
            "venue": "CCS",
            "pages": "4991-4993",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/VangR24",
            "doi": "10.1145/3658644.3691403",
            "ee": "https://doi.org/10.1145/3658644.3691403",
            "url": "https://dblp.org/rec/conf/ccs/VangR24",
            "abstract": "As network attacks are becoming increasingly sophisticated, there is a need to develop new defense techniques. Recent work has demonstrated the successful use of cognitive biases to obstruct progress in network attacks by constructing scenarios which exploit biases in attackers. While informal definitions of many cognitive biases are well-established, the lack of definitions in a formal language limits the ability to construct scenarios in an automated fashion. This work proposes formal definitions using first-order logic to encapsulate the complex relationships between actions and biases.",
            "pdf_url": "",
            "keywords": [
                "Cognitive Biases",
                "Cybersecurity Defense",
                "Network Attacks",
                "First-Order Logic",
                "Automated Scenario Construction"
            ]
        },
        "url": "URL#256870",
        "sema_paperId": "898e3138a30dcf4bfe30cbd48541db247b5d67d3"
    },
    {
        "@score": "1",
        "@id": "256871",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "331/5070",
                        "text": "Nikhil Vanjani"
                    },
                    {
                        "@pid": "168/9476",
                        "text": "Pratik Soni"
                    },
                    {
                        "@pid": "164/5298",
                        "text": "Sri Aravinda Krishnan Thyagarajan"
                    }
                ]
            },
            "title": "Functional Adaptor Signatures: Beyond All-or-Nothing Blockchain-based Payments.",
            "venue": "CCS",
            "pages": "1493-1507",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/VanjaniST24",
            "doi": "10.1145/3658644.3690240",
            "ee": "https://doi.org/10.1145/3658644.3690240",
            "url": "https://dblp.org/rec/conf/ccs/VanjaniST24",
            "abstract": "In scenarios where a seller holds sensitive datax, like employee / patient records or ecological data, and a buyer seeks to obtain an evaluation of specific functionfon this data, solutions in trustless digital environments like blockchain-based Web3 systems typically fall into two categories: (1) Smart contract-powered solutions and (2) cryptographic solutions leveraging tools such as adaptor signatures. The former approach offers atomic transactions where the buyer learns the function evaluation f(x) (and notxentirely) upon payment. However, this approach is often inefficient, costly, lacks privacy for the seller's data, and is incompatible with systems that do not support smart contracts with required functionalities. In contrast, the adaptor signature-based approach addresses all of the above issues but comes with an \"all-or-nothing\" guarantee, where the buyer fully extractsxand does not support functional extraction of the sensitive data. In this work, we aim to bridge the gap between these approaches, developing a solution that enables fair functional sales of information while offering improved efficiency, privacy, and compatibility similar to adaptor signatures.",
            "pdf_url": "",
            "keywords": [
                "Blockchain",
                "Functional Data Sales",
                "Adaptor Signatures",
                "Privacy Preservation",
                "Smart Contract Limitations"
            ]
        },
        "url": "URL#256871"
    },
    {
        "@score": "1",
        "@id": "256872",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "01/8190",
                        "text": "Freek Verbeek"
                    },
                    {
                        "@pid": "221/4551",
                        "text": "Nico Naus"
                    },
                    {
                        "@pid": "61/2985",
                        "text": "Binoy Ravindran"
                    }
                ]
            },
            "title": "Verifiably Correct Lifting of Position-Independent x86-64 Binaries to Symbolized Assembly.",
            "venue": "CCS",
            "pages": "2786-2798",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/VerbeekNR24",
            "doi": "10.1145/3658644.3690244",
            "ee": "https://doi.org/10.1145/3658644.3690244",
            "url": "https://dblp.org/rec/conf/ccs/VerbeekNR24",
            "abstract": "We present an approach to lift position-independent x86-64 binaries to symbolized NASM. Symbolization is a decompilation step that enables binary patching: functions can be modified, and instructions can be interspersed. Moreover, it is the first abstraction step in a larger decompilation chain. The produced NASM is recom-pilable, and we extensively test the recompiled binaries to see if they exhibit the same behavior as the original ones. In addition to testing, the produced NASM is accompanied with a certificate, constructed in such a way that if all theorems in the certificate hold, symbolization has occurred correctly. The original and recom-piled binary are lifted again with a third-party decompiler (Ghidra). These representations, as well as the certificate, are loaded into the Isabelle/HOL theorem prover, where proof scripts ensure that correctness can be proven automatically. We have applied sym-bolization to various stripped binaries from various sources, from various compilers, and ranging over various optimization levels. We show how symbolization enables binary-level patching, by tackling challenges originating from industry.",
            "keywords": [
                "Binary Analysis",
                "Decompilation",
                "Position-Independent Binaries",
                "Symbolization",
                "Binary Patching"
            ]
        },
        "url": "URL#256872",
        "sema_paperId": "20ff2f2a84f49e85a2c1c6bcb8133b2e49e8e66a"
    },
    {
        "@score": "1",
        "@id": "256873",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "77/11029",
                        "text": "Stavros Volos"
                    },
                    {
                        "@pid": "f/CedricFournet",
                        "text": "C\u00e9dric Fournet"
                    },
                    {
                        "@pid": "246/5631",
                        "text": "Jana Hofmann"
                    },
                    {
                        "@pid": "10/3908",
                        "text": "Boris K\u00f6pf"
                    },
                    {
                        "@pid": "166/4142",
                        "text": "Oleksii Oleksenko"
                    }
                ]
            },
            "title": "Principled Microarchitectural Isolation on Cloud CPUs.",
            "venue": "CCS",
            "pages": "183-197",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/VolosFHKO24",
            "doi": "10.1145/3658644.3690183",
            "ee": "https://doi.org/10.1145/3658644.3690183",
            "url": "https://dblp.org/rec/conf/ccs/VolosFHKO24",
            "abstract": "We present Marghera, a system design that prevents cross-VM microarchitectural side-channel attacks in the cloud. Marghera is based on isolation contracts which, for a given CPU, describe partitions of physical threads and memory that prevent information leakage through shared microarchitectural resources.",
            "pdf_url": "",
            "keywords": [
                "Microarchitectural Isolation",
                "Cloud Computing",
                "Side-Channel Attacks",
                "Cross-VM Security",
                "Isolation Contracts"
            ]
        },
        "url": "URL#256873",
        "sema_paperId": "6e9f341597c88846b8827626a021256e939327e4"
    },
    {
        "@score": "1",
        "@id": "256874",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "243/2363",
                        "text": "Sarisht Wadhwa"
                    },
                    {
                        "@pid": "265/5787",
                        "text": "Luca Zanolini"
                    },
                    {
                        "@pid": "214/7122",
                        "text": "Aditya Asgaonkar"
                    },
                    {
                        "@pid": "224/4750",
                        "text": "Francesco D&apos;Amato"
                    },
                    {
                        "@pid": "392/3285",
                        "text": "Chengrui Fang"
                    },
                    {
                        "@pid": "21/3626-22",
                        "text": "Fan Zhang 0022"
                    },
                    {
                        "@pid": "143/4459",
                        "text": "Kartik Nayak"
                    }
                ]
            },
            "title": "Data Independent Order Policy Enforcement: Limitations and Solutions.",
            "venue": "CCS",
            "pages": "378-392",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/WadhwaZADF0N24",
            "doi": "10.1145/3658644.3670367",
            "ee": "https://doi.org/10.1145/3658644.3670367",
            "url": "https://dblp.org/rec/conf/ccs/WadhwaZADF0N24",
            "abstract": "Order manipulation attacks such as frontrunning and sandwich-ing have become an increasing concern in blockchain applications such as DeFi. To protect from such attacks, several recent works have designed order policy enforcement (OPE) protocols to order transactions fairly in a data-independent fashion. However, while the manipulation attacks are motivated by monetary profits, the defenses assume honesty among a significantly large set of participants. In existing protocols, if all participants are rational , they may be incentivized to collude and circumvent the order policy without incurring any penalty. Thisworkmakestwokeycontributions. First,weexplorewhether the need for the honesty assumption is fundamental. Indeed, we show that it is impossible to design OPE protocols under some requirements when all parties are rational. Second, we explore the tradeoffs needed to circumvent the impossibility result. In the process, we propose a novel concept of rationally binding transactions that allows us to construct AnimaguSwap 1 , the first content-oblivious Automated Market Makers (AMM) interface that is secure under rationality. We report on a prototype implementation of Ani-maguSwap and performance evaluation results demonstrating its practicality.",
            "keywords": [
                "Blockchain Security",
                "Order Policy Enforcement",
                "Transaction Manipulation",
                "Rationality in Protocols",
                "Automated Market Makers (AMM)"
            ]
        },
        "url": "URL#256874",
        "sema_paperId": "bdfc127cdc4074740d255552d916a3926b3bacff"
    },
    {
        "@score": "1",
        "@id": "256875",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "201/1129",
                        "text": "Yunling Wang"
                    },
                    {
                        "@pid": "117/3128-1",
                        "text": "Shi-Feng Sun 0001"
                    },
                    {
                        "@pid": "65/4872",
                        "text": "Jianfeng Wang"
                    },
                    {
                        "@pid": "c/XiaofengChen1",
                        "text": "Xiaofeng Chen 0001"
                    },
                    {
                        "@pid": "51/5361",
                        "text": "Joseph K. Liu"
                    },
                    {
                        "@pid": "72/1963",
                        "text": "Dawu Gu"
                    }
                ]
            },
            "title": "Practical Non-interactive Encrypted Conjunctive Search with Leakage Suppression.",
            "venue": "CCS",
            "pages": "4658-4672",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Wang0W0LG24",
            "doi": "10.1145/3658644.3670355",
            "ee": "https://doi.org/10.1145/3658644.3670355",
            "url": "https://dblp.org/rec/conf/ccs/Wang0W0LG24",
            "abstract": "Encrypted conjunctive search enables server to perform efficient conjunctive query over encrypted data while guaranteeing data and query privacy. The well-known Oblivious Cross-Tags (OXT) protocol (by Cash et al. in CRYPTO 2013) is the first to realize efficient conjunctive search with some well-defined leakage, such as the keyword pair result pattern (KPRP) leakage and the cross-query intersection result pattern (IP) leakage. To mitigate the potential threats brought by the leakage, much effort has been made to reduce the information leaked by OXT. However, it is still open to achieve encrypted conjunctive search without revealing both KPRP and IP, while preserving high-efficiency.",
            "pdf_url": "",
            "keywords": [
                "Encrypted Conjunctive Search",
                "Data Privacy",
                "Oblivious Cross-Tags (OXT)",
                "Information Leakage",
                "Keyword Pair Result Pattern (KPRP)"
            ]
        },
        "url": "URL#256875",
        "sema_paperId": "3f65ff93be057d6ab1bbc7352a6ab8432ef42b02"
    },
    {
        "@score": "1",
        "@id": "256876",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "01/7214",
                        "text": "Kelin Wang"
                    },
                    {
                        "@pid": "315/5868",
                        "text": "Mengda Chen"
                    },
                    {
                        "@pid": "42/963-11",
                        "text": "Liang He 0011"
                    },
                    {
                        "@pid": "46/3714",
                        "text": "Purui Su"
                    },
                    {
                        "@pid": "60/3060-1",
                        "text": "Yan Cai 0001"
                    },
                    {
                        "@pid": "224/2480",
                        "text": "Jiongyi Chen"
                    },
                    {
                        "@pid": "13/5236",
                        "text": "Bin Zhang"
                    },
                    {
                        "@pid": "97/164",
                        "text": "Chao Feng"
                    },
                    {
                        "@pid": "57/1674",
                        "text": "Chaojing Tang"
                    }
                ]
            },
            "title": "OSmart: Whitebox Program Option Fuzzing.",
            "venue": "CCS",
            "pages": "705-719",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/WangC0S0CZFT24",
            "doi": "10.1145/3658644.3690228",
            "ee": "https://doi.org/10.1145/3658644.3690228",
            "url": "https://dblp.org/rec/conf/ccs/WangC0S0CZFT24",
            "abstract": "Program options are ubiquitous and serve as a fundamental mechanism for configuring and customizing software behaviors. Given their widespread use, testing program options becomes essential to ensure that the software behaves as expected across various configurations. Existing option-aware fuzzers either mutate options as if they were standard program inputs or employ NLP techniques to deduce relationships among options from the documentation. However, there has not been a whitebox approach that generates option combinations by capturing the inherent execution logic of the program.",
            "pdf_url": "",
            "keywords": [
                "Option Fuzzing",
                "Whitebox Testing",
                "Program Configuration",
                "Software Behavior Testing",
                "Execution Logic"
            ]
        },
        "url": "URL#256876",
        "sema_paperId": "523b964b14ca11da0af55dd729c4f8fbb31fb1db"
    },
    {
        "@score": "1",
        "@id": "256877",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "97/8711",
                        "text": "Penghao Wang"
                    },
                    {
                        "@pid": "174/3780",
                        "text": "Jingzhi Hu"
                    },
                    {
                        "@pid": "15/5923-8",
                        "text": "Chao Liu 0008"
                    },
                    {
                        "@pid": "42/2501-1",
                        "text": "Jun Luo 0001"
                    }
                ]
            },
            "title": "RefleXnoop: Passwords Snooping on NLoS Laptops Leveraging Screen-Induced Sound Reflection.",
            "venue": "CCS",
            "pages": "3361-3375",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/WangHL024",
            "doi": "10.1145/3658644.3670341",
            "ee": "https://doi.org/10.1145/3658644.3670341",
            "url": "https://dblp.org/rec/conf/ccs/WangHL024",
            "abstract": "Password inference attacks by covert wireless side-channels jeopardize information safety, even for people with high security awareness and vigilance against snoopers. Yet, with limited spatial resolution, existing attacks cannot accurately infer password input on QWERTY keyboards in distance, creating psychological safety in using laptops publicly. To refute this false belief, we propose RefleXnoop, enabling an attacker to snoop a victim's typing details on anon-line-of-sight(NLoS) laptop. Apart frompassivelyoverhearing keystroke acoustic emanations, RefleXnoopactivelyprobes with ultrasound, whose larger bandwidth and lower noise floor offers a finer resolution. To further maximize its performance, RefleXnoop exploits the laptop'sscreen reflectionto enhance diversity in sound acquisition, and it innovates in neural models to effectively fuse the diversified sound acquisitions and to achieve robust feature-to-key translation. We implement RefleXnoop with commodity hardware and conduct extensive evaluation on it; the results demonstrate that RefleXnoop achieves 85% top-100 accuracy for inferring 8-character passwords on laptop QWERTY-keyboard and in multiple noisy environments.",
            "pdf_url": "",
            "keywords": [
                "Password Inference Attacks",
                "Acoustic Emanations",
                "Non-Line-of-Sight Typing",
                "Ultrasound Probing",
                "Sound Reflection"
            ]
        },
        "url": "URL#256877",
        "sema_paperId": "cd32f03a58551bf23f2d3d8870569faadbcc5dbc"
    },
    {
        "@score": "1",
        "@id": "256878",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "44/6292",
                        "text": "Ye Wang"
                    },
                    {
                        "@pid": "284/4048",
                        "text": "Zeyan Liu"
                    },
                    {
                        "@pid": "71/2890",
                        "text": "Bo Luo"
                    },
                    {
                        "@pid": "54/8707",
                        "text": "Rongqing Hui"
                    },
                    {
                        "@pid": "66/6000",
                        "text": "Fengjun Li"
                    }
                ]
            },
            "title": "The Invisible Polyjuice Potion: an Effective Physical Adversarial Attack against Face Recognition.",
            "venue": "CCS",
            "pages": "3346-3360",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/WangLLHL24",
            "doi": "10.1145/3658644.3670382",
            "ee": "https://doi.org/10.1145/3658644.3670382",
            "url": "https://dblp.org/rec/conf/ccs/WangLLHL24",
            "abstract": "Face recognition systems have been targeted by recent physical adversarial machine learning attacks, which attach or project visible patterns on adversaries\u2019 faces to trick backend FR models. While these attacks have demonstrated effectiveness in the literature, they often rely on visibly suspicious patterns, are susceptible to environmental noise, or exhibit limited success rates in practice. In this paper, we propose a novel physical adversarial attack against deep face recognition systems, namely Agile (adversarial glasses with infrared laser). It generates adjustable, invisible laser perturbations and emits them into the camera CMOS to launch dodging and impersonation attacks against facial biometrics systems. To do so, we first theoretically model physical adversarial perturbations and convert them to the digital domain. The generated synthesized attack signals are utilized to guide real-world laser settings. Our experiments with real-world attackers and a benchmark face database show that Agile is highly effective in DoS, dodging, and imperson-ation attacks. More importantly, the candidate impersonation target and optimal attack settings identified by Agile \u2019s attack synthesis approach are highly consistent with real-world physical attack re-sults. The grey-box and black-box evaluation against commercial FR models also confirms the effectiveness of the Agile attack.",
            "keywords": [
                "Physical Adversarial Attack",
                "Face Recognition Systems",
                "Invisible Perturbations",
                "Impersonation Attacks",
                "Agile Attack"
            ]
        },
        "url": "URL#256878",
        "sema_paperId": "bb634ee00b23a38c9365d100b7b7c9e50cb4317c"
    },
    {
        "@score": "1",
        "@id": "256879",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "308/9920",
                        "text": "Peiran Wang"
                    },
                    {
                        "@pid": "254/4412",
                        "text": "Qiyu Li"
                    },
                    {
                        "@pid": "290/3561",
                        "text": "Longxuan Yu"
                    },
                    {
                        "@pid": "222/8592",
                        "text": "Ziyao Wang"
                    },
                    {
                        "@pid": "33/2805-5",
                        "text": "Ang Li 0005"
                    },
                    {
                        "@pid": "128/9277",
                        "text": "Haojian Jin"
                    }
                ]
            },
            "title": "Moderator: Moderating Text-to-Image Diffusion Models through Fine-grained Context-based Policies.",
            "venue": "CCS",
            "pages": "1181-1195",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/WangLYW0J24",
            "doi": "10.1145/3658644.3690327",
            "ee": "https://doi.org/10.1145/3658644.3690327",
            "url": "https://dblp.org/rec/conf/ccs/WangLYW0J24",
            "abstract": "We present Moderator, a policy-based model management system that allows administrators to specify fine-grained content moderation policies and modify the weights of a text-to-image (TTI) model to make it significantly more challenging for users to produce images that violate the policies. In contrast to existing general-purpose model editing techniques, which unlearn concepts without considering the associated contexts, Moderator allows admins to specify what content should be moderated, under which context, how it should be moderated, and why moderation is necessary. Given a set of policies, Moderator first prompts the original model to generate images that need to be moderated, then uses these self-generated images to reverse fine-tune the model to compute task vectors for moderation and finally negates the original model with the task vectors to decrease its performance in generating moderated content. We evaluated Moderator with 14 participants to play the role of admins and found they could quickly learn and author policies to pass unit tests in approximately 2.29 policy iterations. Our experiment with 32 stable diffusion users suggested that Moderator can prevent 65% of users from generating moderated content under 15 attempts and require the remaining users an average of 8.3 times more attempts to generate undesired content.",
            "pdf_url": "",
            "keywords": [
                "Text-to-Image Generation",
                "Content Moderation",
                "Policy-Based Model Management",
                "Fine-Grained Contextual Policies",
                "Model Fine-Tuning"
            ]
        },
        "url": "URL#256879"
    },
    {
        "@score": "1",
        "@id": "256880",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "32/5536-4",
                        "text": "Shu Wang 0004"
                    },
                    {
                        "@pid": "30/3530-1",
                        "text": "Kun Sun 0001"
                    },
                    {
                        "@pid": "44/6741",
                        "text": "Yan Zhai"
                    }
                ]
            },
            "title": "Dye4AI: Assuring Data Boundary on Generative AI Services.",
            "venue": "CCS",
            "pages": "2281-2295",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/WangSZ24",
            "doi": "10.1145/3658644.3670299",
            "ee": "https://doi.org/10.1145/3658644.3670299",
            "url": "https://dblp.org/rec/conf/ccs/WangSZ24",
            "abstract": "Generative artificial intelligence (AI) is versatile for various applications, but security and privacy concerns with third-party AI vendors hinder its broader adoption in sensitive scenarios. Hence, it is essential for users to validate the AI trustworthiness and ensure the security of data boundaries. In this paper, we present a dye testing system named Dye4AI, which injects crafted trigger data into human-AI dialogue and observes AI responses towards specific prompts to diagnose data flow in AI model evolution. Our dye testing procedure contains 3 stages: trigger generation, trigger insertion, and trigger retrieval. First, to retain both uniqueness and stealthiness, we design a new trigger that transforms a pseudo-random number to a intelligible format. Second, with a custom-designed three-step conversation strategy, we insert each trigger item into dialogue and confirm the model memorizes the new trigger knowledge in the current session. Finally, we routinely try to recover triggers with specific prompts in new sessions, as triggers can present in new sessions only if AI vendors leverage user data for model fine-tuning. Extensive experiments on six LLMs demonstrate our dye testing scheme is effective in ensuring the data boundary, even for models with various architectures and parameter sizes. Also, larger and premier models tend to be more suitable for Dye4AI, e.g., trigger can be retrieved in OpenLLaMa-13B even with only 2 insertions per trigger item. Moreover, we analyze the prompt selection in dye testing, providing insights for future testing systems on generative AI services.",
            "keywords": [
                "Generative AI",
                "Data Boundary Assurance",
                "Dye Testing",
                "Trigger Injection",
                "AI Trustworthiness"
            ]
        },
        "url": "URL#256880",
        "sema_paperId": "711dd9fb30d31ecd6e2da24873de5293910b36d2"
    },
    {
        "@score": "1",
        "@id": "256881",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "122/8715",
                        "text": "Ruizhe Wang"
                    },
                    {
                        "@pid": "75/4287",
                        "text": "Meng Xu"
                    },
                    {
                        "@pid": "39/2508",
                        "text": "N. Asokan"
                    }
                ]
            },
            "title": "SeMalloc: Semantics-Informed Memory Allocator.",
            "venue": "CCS",
            "pages": "1375-1389",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/WangXA24",
            "doi": "10.1145/3658644.3670363",
            "ee": "https://doi.org/10.1145/3658644.3670363",
            "url": "https://dblp.org/rec/conf/ccs/WangXA24",
            "abstract": "Use-after-free (UAF) is a critical and prevalent problem in memory unsafe languages. While many solutions have been proposed, balancing security, run-time cost, and memory overhead (an impossible trinity) is hard. In this paper, we show one way to balance the trinity by passing more semantics about the heap object to the allocator for it to make informed allocation decisions. More specifically, we propose a new notion of thread-, context-, and flow-sensitive\"type\", SemaType, to capture the semantics and prototype a SemaType-based allocator that aims for the best trade-off amongst the impossible trinity. In SeMalloc, only heap objects allocated from the same call site and via the same function call stack can possibly share a virtual memory address, which effectively stops type-confusion attacks and makes UAF vulnerabilities harder to exploit. Through extensive empirical evaluation, we show that SeMalloc is realistic: (a) SeMalloc is effective in thwarting all real-world vulnerabilities we tested; (b) benchmark programs run even slightly faster with SeMalloc than the default heap allocator, at a memory overhead averaged from 41% to 84%; and (c) SeMalloc balances security and overhead strictly better than other closely related works.",
            "keywords": [
                "Memory Allocation",
                "Use-After-Free",
                "SemaType",
                "Type-Confusion Attacks",
                "Memory Safety"
            ]
        },
        "url": "URL#256881",
        "sema_paperId": "b2da3c9f9b8627acafc694af73e2299728379aa3"
    },
    {
        "@score": "1",
        "@id": "256882",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "19/3687",
                        "text": "Shiming Wang"
                    },
                    {
                        "@pid": "115/6308",
                        "text": "Liyao Xiang"
                    },
                    {
                        "@pid": "392/3312",
                        "text": "Bowei Cheng"
                    },
                    {
                        "@pid": "65/4179",
                        "text": "Zhe Ji"
                    },
                    {
                        "@pid": "244/9453",
                        "text": "Tianran Sun"
                    },
                    {
                        "@pid": "96/1149",
                        "text": "Xinbing Wang"
                    }
                ]
            },
            "title": "Curator Attack: When Blackbox Differential Privacy Auditing Loses Its Power.",
            "venue": "CCS",
            "pages": "3540-3554",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/WangXCJSW24",
            "doi": "10.1145/3658644.3690367",
            "ee": "https://doi.org/10.1145/3658644.3690367",
            "url": "https://dblp.org/rec/conf/ccs/WangXCJSW24",
            "abstract": "A surge in data-driven applications enhances everyday life but also raises serious concerns about private information leakage. Hence many privacy auditing tools are emerging for checking if the data sanitization performed meets the privacy standard of the data owner. Blackbox auditing for differential privacy is particularly gaining popularity for its effectiveness and applicability to a wide range of scenarios. Yet, we identified that blackbox auditing is essentially flawed with its setting: small probabilities or densities are ignored due to inaccurate observation. Our argument is based on a solid false positive analysis from a hypothesis testing perspective, which is missed out by prior blackbox auditing tools. This oversight greatly reduces the reliability of these tools, as it allows malicious or incapable data curators to pass the auditing with an overstated privacy guarantee, posing significant risks to data owners. We demonstrate the practical existence of such threats in classical differential privacy mechanisms against four representative blackbox auditors with experimental validations. Our findings aim to reveal the limitations of blackbox auditing tools, empower the data owner with the awareness of risks in using these tools, and encourage the development of more reliable differential privacy auditing methods.",
            "keywords": [
                "Differential Privacy",
                "Blackbox Auditing",
                "Privacy Assurance",
                "Data Sanitization",
                "False Positive Analysis"
            ]
        },
        "url": "URL#256882",
        "sema_paperId": "d944ab1e0c3957a7f3f4be489cf217672b132d77"
    },
    {
        "@score": "1",
        "@id": "256883",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "65/4872",
                        "text": "Jianfeng Wang"
                    },
                    {
                        "@pid": "94/1128",
                        "text": "Huazhong Yang"
                    },
                    {
                        "@pid": "197/1353",
                        "text": "Shuwen Deng"
                    },
                    {
                        "@pid": "01/6993",
                        "text": "Xueqing Li"
                    }
                ]
            },
            "title": "CiMSAT: Exploiting SAT Analysis to Attack Compute-in-Memory Architecture Defenses.",
            "venue": "CCS",
            "pages": "3436-3450",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/WangYDL24",
            "doi": "10.1145/3658644.3690251",
            "ee": "https://doi.org/10.1145/3658644.3690251",
            "url": "https://dblp.org/rec/conf/ccs/WangYDL24",
            "abstract": "Compute-in-memory (CiM) architecture is an emerging energy-efficient processing paradigm that has attracted widespread attention in AI and Internet of Things (IoT) applications. To protect statically stored sensitive data in CiM, designers have implemented various hardware obfuscation techniques in CiM architectures. However, we observe that existing CiM obfuscation defense strategies are based on straightforward static-key deployment strategies, which pose vulnerabilities from the perspective of key-pruning algorithms for de-obfuscation.",
            "pdf_url": "",
            "keywords": [
                "Compute-in-Memory Architecture",
                "Hardware Obfuscation",
                "Data Protection",
                "Key-Pruning Algorithms",
                "De-obfuscation Vulnerabilities"
            ]
        },
        "url": "URL#256883",
        "sema_paperId": "1559d88f4c4c4fe08e4ed0b1dd439420b29b171c"
    },
    {
        "@score": "1",
        "@id": "256884",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "39/2537-21",
                        "text": "Dawei Wang 0021"
                    },
                    {
                        "@pid": "00/2762",
                        "text": "Geng Zhou"
                    },
                    {
                        "@pid": "c/LiChen8",
                        "text": "Li Chen 0008"
                    },
                    {
                        "@pid": "48/4185-1",
                        "text": "Dan Li 0001"
                    },
                    {
                        "@pid": "204/0178",
                        "text": "Yukai Miao"
                    }
                ]
            },
            "title": "ProphetFuzz: Fully Automated Prediction and Fuzzing of High-Risk Option Combinations with Only Documentation via Large Language Model.",
            "venue": "CCS",
            "pages": "735-749",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/WangZ00M24",
            "doi": "10.1145/3658644.3690231",
            "ee": "https://doi.org/10.1145/3658644.3690231",
            "url": "https://dblp.org/rec/conf/ccs/WangZ00M24",
            "abstract": "Vulnerabilities related to option combinations pose a significant challenge in software security testing due to their vast search space. Previous research primarily addressed this challenge through mutation or filtering techniques, which inefficiently treated all option combinations as having equal potential for vulnerabilities, thus wasting considerable time on non-vulnerable targets and resulting in low testing efficiency. In this paper, we utilize carefully designed prompt engineering to drive the large language model (LLM) to predict high-risk option combinations (i.e., more likely to contain vulnerabilities) and perform fuzz testing automatically without human intervention. We developed a tool called ProphetFuzz and evaluated it on a dataset comprising 52 programs collected from three related studies. The entire experiment consumed 10.44 CPU years. ProphetFuzz successfully predicted 1748 high-risk option combinations at an average cost of only \\$8.69 per program. Results show that after 72 hours of fuzzing, ProphetFuzz discovered 364 unique vulnerabilities associated with 12.30\\% of the predicted high-risk option combinations, which was 32.85\\% higher than that found by state-of-the-art in the same timeframe. Additionally, using ProphetFuzz, we conducted persistent fuzzing on the latest versions of these programs, uncovering 140 vulnerabilities, with 93 confirmed by developers and 21 awarded CVE numbers.",
            "keywords": [
                "Software Security Testing",
                "Fuzzing",
                "Option Combinations",
                "Vulnerability Prediction",
                "Large Language Model (LLM)"
            ]
        },
        "url": "URL#256884",
        "sema_paperId": "4f071e6c25cf8e1c46ec35010a09ecc060ffd964"
    },
    {
        "@score": "1",
        "@id": "256885",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "329/3017",
                        "text": "Hanqiu Wang"
                    },
                    {
                        "@pid": "195/9266",
                        "text": "Zihao Zhan"
                    },
                    {
                        "@pid": "211/3822",
                        "text": "Haoqi Shan"
                    },
                    {
                        "@pid": "250/6535",
                        "text": "Siqi Dai"
                    },
                    {
                        "@pid": "284/6797",
                        "text": "Maximillian Panoff"
                    },
                    {
                        "@pid": "63/1591-3",
                        "text": "Shuo Wang 0003"
                    }
                ]
            },
            "title": "GAZEploit: Remote Keystroke Inference Attack by Gaze Estimation from Avatar Views in VR/MR Devices.",
            "venue": "CCS",
            "pages": "1731-1745",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/WangZSDP024",
            "doi": "10.1145/3658644.3690285",
            "ee": "https://doi.org/10.1145/3658644.3690285",
            "url": "https://dblp.org/rec/conf/ccs/WangZSDP024",
            "abstract": "The advent and growing popularity of Virtual Reality (VR) and Mixed Reality (MR) solutions have revolutionized the way we interact with digital platforms. The cutting-edge gaze-controlled typing methods, now prevalent in high-end models of these devices, e.g., Apple Vision Pro, have not only improved user experience but also mitigated traditional keystroke inference attacks that relied on hand gestures, head movements and acoustic side-channels. However, this advancement has paradoxically given birth to a new, potentially more insidious cyber threat,GAZEploit.",
            "pdf_url": "",
            "keywords": [
                "Virtual Reality",
                "Mixed Reality",
                "Gaze Estimation",
                "Keystroke Inference Attack",
                "GAZEploit"
            ]
        },
        "url": "URL#256885"
    },
    {
        "@score": "1",
        "@id": "256886",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "250/9724",
                        "text": "Kevin Warren"
                    },
                    {
                        "@pid": "335/5811",
                        "text": "Tyler Tucker"
                    },
                    {
                        "@pid": "392/3053",
                        "text": "Anna Crowder"
                    },
                    {
                        "@pid": "320/8828",
                        "text": "Daniel Olszewski"
                    },
                    {
                        "@pid": "361/2134",
                        "text": "Allison Lu"
                    },
                    {
                        "@pid": "392/3087",
                        "text": "Caroline Fedele"
                    },
                    {
                        "@pid": "392/3205",
                        "text": "Magdalena Pasternak"
                    },
                    {
                        "@pid": "259/8738",
                        "text": "Seth Layton"
                    },
                    {
                        "@pid": "82/1935",
                        "text": "Kevin R. B. Butler"
                    },
                    {
                        "@pid": "21/1838",
                        "text": "Carrie Gates"
                    },
                    {
                        "@pid": "14/3295",
                        "text": "Patrick Traynor"
                    }
                ]
            },
            "title": "&quot;Better Be Computer or I&apos;m Dumb&quot;: A Large-Scale Evaluation of Humans as Audio Deepfake Detectors.",
            "venue": "CCS",
            "pages": "2696-2710",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/WarrenTCOLFPLBG24",
            "doi": "10.1145/3658644.3670325",
            "ee": "https://doi.org/10.1145/3658644.3670325",
            "url": "https://dblp.org/rec/conf/ccs/WarrenTCOLFPLBG24",
            "abstract": "Audio deepfakes represent a rising threat to trust in our daily communications. In response to this, the research community has developed a wide array of detection techniques aimed at preventing such attacks from deceiving users. Unfortunately, the creation of these defenses has generally overlooked the most important element of the system - the user themselves. As such, it is not clear whether current mechanisms augment, hinder, or simply contradict human classification of deepfakes. In this paper, we perform the first large-scale user study on deepfake detection. We recruit over 1,200 users and present them with samples from the three most widely-cited deepfake datasets. We then quantitatively compare performance and qualitatively conduct thematic analysis to motivate and understand the reasoning behind user decisions and differences from machine classifications. Our results show that users correctly classify human audio at significantly higher rates than machine learning models, and rely on linguistic features and intuition when performing classification. However, users are also regularly mis-led by pre-conceptions about the capabilities of generated audio (e.g",
            "keywords": [
                "Audio Deepfakes",
                "User Detection",
                "Human Classification",
                "Linguistic Features",
                "Detection Mechanisms"
            ]
        },
        "url": "URL#256886",
        "sema_paperId": "8c82b28fa771532f64107ce7ca3b845e25812bf3"
    },
    {
        "@score": "1",
        "@id": "256887",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "270/8815",
                        "text": "Ben Weintraub"
                    },
                    {
                        "@pid": "298/0605",
                        "text": "Satwik Prabhu Kumble"
                    },
                    {
                        "@pid": "n/CristinaNitaRotaru",
                        "text": "Cristina Nita-Rotaru"
                    },
                    {
                        "@pid": "57/8781",
                        "text": "Stefanie Roos"
                    }
                ]
            },
            "title": "Payout Races and Congested Channels: A Formal Analysis of Security in the Lightning Network.",
            "venue": "CCS",
            "pages": "2562-2576",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/WeintraubKNR24",
            "doi": "10.1145/3658644.3670315",
            "ee": "https://doi.org/10.1145/3658644.3670315",
            "url": "https://dblp.org/rec/conf/ccs/WeintraubKNR24",
            "abstract": "The Lightning Network, a payment channel network with a market cap of over 192M USD, is designed to resolve Bitcoin's scalability issues through fast off-chain transactions. There are multiple Lightning Network client implementations, all of which conform to the same textual specifications known as BOLTs. Several vulnerabilities have been manually discovered, but to-date there have been few works systematically analyzing the security of the Lightning Network. In this work, we take a foundational approach to analyzing the security of the Lightning Network with the help of formal methods. Based on the BOLTs' specifications, we build a detailed formal model of the Lightning Network's single-hop payment protocol and verify it using the Spin model checker. Our model captures both concurrency and error semantics of the payment protocol. We then define several security properties which capture the correct intermediate operation of the protocol, ensuring that the outcome is always certain to both channel peers, and using them we re-discover a known attack previously reported in the literature along with a novel attack, referred to as a Payout Race. A Payout Race consists of a particular sequence of events that can lead to an ambiguity in the protocol in which innocent users can unwittingly lose funds. We confirm the practicality of this attack by reproducing it in a local testbed environment.",
            "keywords": [
                "Lightning Network",
                "Payment Channel Network",
                "Formal Methods",
                "Payout Race",
                "Security Vulnerabilities"
            ]
        },
        "url": "URL#256887",
        "sema_paperId": "d01a39ff533dd75aeb24734f3df02b89382dbdcc"
    },
    {
        "@score": "1",
        "@id": "256888",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "270/8815",
                        "text": "Ben Weintraub"
                    },
                    {
                        "@pid": "24/1630",
                        "text": "Jiwon Kim"
                    },
                    {
                        "@pid": "99/955",
                        "text": "Ran Tao"
                    },
                    {
                        "@pid": "n/CristinaNitaRotaru",
                        "text": "Cristina Nita-Rotaru"
                    },
                    {
                        "@pid": "14/5114",
                        "text": "Hamed Okhravi"
                    },
                    {
                        "@pid": "159/0537",
                        "text": "Dave (Jing) Tian"
                    },
                    {
                        "@pid": "205/3765",
                        "text": "Benjamin E. Ujcich"
                    }
                ]
            },
            "title": "Exploiting Temporal Vulnerabilities for Unauthorized Access in Intent-based Networking.",
            "venue": "CCS",
            "pages": "3630-3644",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/WeintraubKTNOTU24",
            "doi": "10.1145/3658644.3670301",
            "ee": "https://doi.org/10.1145/3658644.3670301",
            "url": "https://dblp.org/rec/conf/ccs/WeintraubKTNOTU24",
            "abstract": "Intent-based networking (IBN) enables network administrators to express high-level goals and network policies without needing to specify low-level forwarding configurations, topologies, or protocols. Administrators can define intents that capture the overall behavior they want from the network, and an IBN controller compiles such intents into low-level configurations that get installed in the network and implement the desired behavior. We discovered that current IBN specifications and implementations do not specify that flow rule installation orderings should be enforced, which leads to temporal vulnerabilities where, for a limited time, attackers can exploit indeterminate connectivity behavior to gain unauthorized network access. In this paper, we analyze the causes of such temporal vulnerabilities and their security impacts with a representative case study via the ONOS IBN implementation. We devise the Phantom Link attack and demonstrate a working exploit to highlight the security impacts. To defend against such attacks, we propose Spotlight , a detection method that can alert a system administrator of risky intent updates prone to exploitable temporal vulnerabilities. Spotlight is effective in identifying risky updates using realistic network topologies and policies. We show that Spotlight can detect risky updates in a mean time of 0.65 seconds for topologies of over 1,300 nodes.",
            "keywords": [
                "Intent-based Networking",
                "Temporal Vulnerabilities",
                "Unauthorized Access",
                "Phantom Link Attack",
                "Spotlight Detection Method"
            ]
        },
        "url": "URL#256888",
        "sema_paperId": "92cd49ee776268f1087aa6a4ff47fe4f4f600088"
    },
    {
        "@score": "1",
        "@id": "256889",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "63/10765-2",
                        "text": "Rui Wen 0002"
                    },
                    {
                        "@pid": "10/1143-23",
                        "text": "Zheng Li 0023"
                    },
                    {
                        "@pid": "b/MichaelBackes1",
                        "text": "Michael Backes 0001"
                    },
                    {
                        "@pid": "06/6785-16",
                        "text": "Yang Zhang 0016"
                    }
                ]
            },
            "title": "Membership Inference Attacks Against In-Context Learning.",
            "venue": "CCS",
            "pages": "3481-3495",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/WenL0Z24",
            "doi": "10.1145/3658644.3690306",
            "ee": "https://doi.org/10.1145/3658644.3690306",
            "url": "https://dblp.org/rec/conf/ccs/WenL0Z24",
            "abstract": "Adapting Large Language Models (LLMs) to specific tasks introduces concerns about computational efficiency, prompting an exploration of efficient methods such as In-Context Learning (ICL). However, the vulnerability of ICL to privacy attacks under realistic assumptions remains largely unexplored. In this work, we present the first membership inference attack tailored for ICL, relying solely on generated texts without their associated probabilities. We propose four attack strategies tailored to various constrained scenarios and conduct extensive experiments on four popular large language models. Empirical results show that our attacks can accurately determine membership status in most cases, e.g., 95\\% accuracy advantage against LLaMA, indicating that the associated risks are much higher than those shown by existing probability-based attacks. Additionally, we propose a hybrid attack that synthesizes the strengths of the aforementioned strategies, achieving an accuracy advantage of over 95\\% in most cases. Furthermore, we investigate three potential defenses targeting data, instruction, and output. Results demonstrate combining defenses from orthogonal dimensions significantly reduces privacy leakage and offers enhanced privacy assurances.",
            "keywords": [
                "In-Context Learning",
                "Membership Inference Attack",
                "Large Language Models",
                "Privacy Leakage",
                "Hybrid Attack Strategies"
            ]
        },
        "url": "URL#256889",
        "sema_paperId": "6e8e815f6f0c5370e86651ed959f1c77657d607b"
    },
    {
        "@score": "1",
        "@id": "256890",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "271/1209",
                        "text": "Hongbo Wen"
                    },
                    {
                        "@pid": "348/6074",
                        "text": "Hanzhi Liu"
                    },
                    {
                        "@pid": "204/2488",
                        "text": "Jiaxin Song"
                    },
                    {
                        "@pid": "05/4034",
                        "text": "Yanju Chen"
                    },
                    {
                        "@pid": "144/1238-2",
                        "text": "Wenbo Guo 0002"
                    },
                    {
                        "@pid": "30/4550-1",
                        "text": "Yu Feng 0001"
                    }
                ]
            },
            "title": "FORAY: Towards Effective Attack Synthesis against Deep Logical Vulnerabilities in DeFi Protocols.",
            "venue": "CCS",
            "pages": "1001-1015",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/WenLSC0024",
            "doi": "10.1145/3658644.3690293",
            "ee": "https://doi.org/10.1145/3658644.3690293",
            "url": "https://dblp.org/rec/conf/ccs/WenLSC0024",
            "abstract": "Blockchain adoption has surged with the rise of Decentralized Finance (DeFi) applications. However, the significant value of digital assets managed by DeFi protocols makes them prime targets for attacks. Current smart contract vulnerability detection tools struggle with DeFi protocols due to deep logical bugs arising from complex financial interactions between multiple smart contracts. These tools primarily analyze individual contracts and resort to brute-force methods for DeFi protocols crossing numerous smart contracts, leading to inefficiency. We introduce Foray, a highly effective attack synthesis framework against deep logical bugs in DeFi protocols. Foray proposes a novel attack sketch generation and completion framework. Specifically, instead of treating DeFis as regular programs, we design a domain-specific language (DSL) to lift the low-level smart contracts into their high-level financial operations. Based on our DSL, we first compile a given DeFi protocol into a token flow graph, our graphical representation of DeFi protocols. Then, we design an efficient sketch generation method to synthesize attack sketches for a certain attack goal (e.g., price manipulation, arbitrage, etc.). This algorithm strategically identifies candidate sketches by finding reachable paths in TFG, which is much more efficient than random enumeration. For each candidate sketch written in our DSL, Foray designs a domain-specific symbolic compilation to compile it into SMT constraints. Our compilation simplifies the constraints by removing redundant smart contract semantics. It maintains the usability of symbolic compilation, yet scales to problems orders of magnitude larger. Finally, the candidates are completed via existing solvers and are transformed into concrete attacks via direct syntax transformation.",
            "keywords": [
                "Decentralized Finance (DeFi)",
                "Smart Contract Vulnerabilities",
                "Attack Synthesis",
                "Logical Bugs",
                "Token Flow Graph"
            ]
        },
        "url": "URL#256890",
        "sema_paperId": "e537c4972d1e59665233a6e4e3d9debd8de1424d"
    },
    {
        "@score": "1",
        "@id": "256891",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "263/7337",
                        "text": "Luca Wilke"
                    },
                    {
                        "@pid": "296/1680",
                        "text": "Florian Sieck"
                    },
                    {
                        "@pid": "72/817",
                        "text": "Thomas Eisenbarth 0001"
                    }
                ]
            },
            "title": "TDXdown: Single-Stepping and Instruction Counting Attacks against Intel TDX.",
            "venue": "CCS",
            "pages": "79-93",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/WilkeS024",
            "doi": "10.1145/3658644.3690230",
            "ee": "https://doi.org/10.1145/3658644.3690230",
            "url": "https://dblp.org/rec/conf/ccs/WilkeS024",
            "abstract": "Trusted Execution Environments are a promising solution for solving the data privacy and trust issues introduced by cloud computing. As a result, all major CPU vendors integrated Trusted Execution Environments (TEEs) into their CPUs. The biggest threat to TEE security are side-channel attacks, of which single-stepping attacks turned out to be the most powerful ones. Enabled by the TEE attacker model, single-stepping attacks allow the attacker to execute the TEE one instruction at a time, enabling numerous controlled- and side-channel based security issues. Intel recently launched Intel TDX, its second generation TEE, which protects whole virtual machines (VMs). To minimize the attack surface to side-channels, TDX comes with a dedicated single-stepping attack countermeasure. In this paper, we systematically analyze the single-stepping countermeasure of Intel TDX and show, for the first time, that both, the built-in detection heuristic as well as the prevention mechanism, can be circumvented. We reliably single-step TDX-protected VMs by deluding the TDX security monitor about the elapsed processing time used as part of the detection heuristic. Moreover, our study reveals a design flaw in the single-stepping countermeasure that turns the prevention mechanism against itself: An inherent side-channel within the prevention mechanism leaks the number of instructions executed by the TDX-protected VM, enabling a novel attack we refer to asStumbleStepping.Both attacks, single-stepping andStumbleStepping,work on the most recent Intel TDX enabled Xeon Scalable CPUs. UsingStumbleStepping,we demonstrate a novel end-to-end attack against wolfSSL's ECDSA implementation, exploiting a control flow side-channel in its truncation-based nonce generation algorithm. We provide a systematic study of nonce-truncation implementations, revealing similar leakages in OpenSSL, which we exploit with our single-stepping primitive. Finally, we propose design changes to TDX to mitigate our attacks.",
            "pdf_url": "",
            "keywords": [
                "Trusted Execution Environments",
                "Intel TDX",
                "Single-Stepping Attacks",
                "Side-Channel Attacks",
                "Nonce Generation Vulnerabilities"
            ]
        },
        "url": "URL#256891",
        "sema_paperId": "a81658d54e51c1d2c3dc5cb69f34ddaa8dbe0cfb"
    },
    {
        "@score": "1",
        "@id": "256892",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "305/8372",
                        "text": "Hans Winderix"
                    },
                    {
                        "@pid": "325/3751",
                        "text": "Marton Bognar"
                    },
                    {
                        "@pid": "222/9411",
                        "text": "Lesly-Ann Daniel"
                    },
                    {
                        "@pid": "85/6647",
                        "text": "Frank Piessens"
                    }
                ]
            },
            "title": "Libra: Architectural Support For Principled, Secure And Efficient Balanced Execution On High-End Processors.",
            "venue": "CCS",
            "pages": "19-33",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/WinderixBDP24",
            "doi": "10.1145/3658644.3690319",
            "ee": "https://doi.org/10.1145/3658644.3690319",
            "url": "https://dblp.org/rec/conf/ccs/WinderixBDP24",
            "abstract": "Control-flow leakage (CFL) attacks enable an attacker to expose control-flow decisions of a victim program via side-channel observations.Linearization(i.e. elimination) of secret-dependent control flow is the main countermeasure against these attacks, yet it comes at a non-negligible cost. Conversely,balancingsecret-dependent branches often incurs a smaller overhead, but is notoriously insecure on high-end processors. Hence, linearization has been widely believed to bethe onlyeffective countermeasure against CFL attacks. In this paper, we challenge this belief and investigate an unexplored alternative: how to securely balance secret-dependent branches on higher-end processors?",
            "pdf_url": "",
            "keywords": [
                "Control-Flow Leakage",
                "High-End Processors",
                "Secret-Dependent Control Flow",
                "Balancing Branches",
                "Linearization Countermeasure"
            ]
        },
        "url": "URL#256892"
    },
    {
        "@score": "1",
        "@id": "256893",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "276/5744",
                        "text": "Felix A. Wolf"
                    },
                    {
                        "@pid": "m/PMuller1",
                        "text": "Peter M\u00fcller 0001"
                    }
                ]
            },
            "title": "Verifiable Security Policies for Distributed Systems.",
            "venue": "CCS",
            "pages": "4-18",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Wolf024",
            "doi": "10.1145/3658644.3690303",
            "ee": "https://doi.org/10.1145/3658644.3690303",
            "url": "https://dblp.org/rec/conf/ccs/Wolf024",
            "abstract": "In the context of secure information flow, security policies express the classification and declassification of data. Existing policy frameworks are tightly linked to a programming language, which limits their flexibility and complicates reasoning, for instance, during audits. We present a framework for the specification and verification of security policies for distributed systems, where attackers may observe the I/O performed by a program, but not its memory. Our policies are expressed over the I/O behaviors of programs and, thereby, language-agnostic. We present techniques to reason formally about policies, and to verify that an implementation satisfies a given policy. We formalize these verification techniques in Isabelle/HOL. An evaluation on several case studies, including an implementation of the WireGuard VPN key exchange protocol, demonstrates that our policies are expressive, and that verification is amenable to SMT-based verification.",
            "pdf_url": "",
            "keywords": [
                "Distributed Systems Security",
                "Security Policies",
                "Information Flow",
                "Formal Verification",
                "Language-Agnostic Policies"
            ]
        },
        "url": "URL#256893",
        "sema_paperId": "3e2f0ecf4a86645c644ff40b3b524fb46ad8b9b3"
    },
    {
        "@score": "1",
        "@id": "256894",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "275/3157",
                        "text": "Sara Wr\u00f3tniak"
                    },
                    {
                        "@pid": "181/1557",
                        "text": "Hemi Leibowitz"
                    },
                    {
                        "@pid": "12/7905",
                        "text": "Ewa Syta"
                    },
                    {
                        "@pid": "62/3150",
                        "text": "Amir Herzberg"
                    }
                ]
            },
            "title": "Provable Security for PKI Schemes.",
            "venue": "CCS",
            "pages": "1552-1566",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/WrotniakLSH24",
            "doi": "10.1145/3658644.3670374",
            "ee": "https://doi.org/10.1145/3658644.3670374",
            "url": "https://dblp.org/rec/conf/ccs/WrotniakLSH24",
            "abstract": "PKI schemes provide a critical foundation for applied cryptographic protocols. However, there are no rigorous security specifications for realistic PKI schemes, and therefore, no PKI schemes were proven secure. Cryptographic systems that use PKI are analyzed by adopting overly simplified models of PKI, often simply assuming securely-distributed public keys. This is problematic given the extensive reliance on PKI, the multiple failures of PKI systems, and the complexity of both proposed and deployed systems, which involve complex requirements and models.",
            "pdf_url": "",
            "keywords": [
                "Public Key Infrastructure (PKI)",
                "Cryptographic Protocols",
                "Security Specifications",
                "PKI Security Models",
                "Public Key Distribution"
            ]
        },
        "url": "URL#256894"
    },
    {
        "@score": "1",
        "@id": "256895",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "149/5889",
                        "text": "Jialin Wu"
                    },
                    {
                        "@pid": "243/3091",
                        "text": "Jiangyi Deng"
                    },
                    {
                        "@pid": "375/6492",
                        "text": "Shengyuan Pang"
                    },
                    {
                        "@pid": "50/10586",
                        "text": "Yanjiao Chen"
                    },
                    {
                        "@pid": "228/2968",
                        "text": "Jiayang Xu"
                    },
                    {
                        "@pid": "04/8388",
                        "text": "Xinfeng Li"
                    },
                    {
                        "@pid": "10/3878-1",
                        "text": "Wenyuan Xu 0001"
                    }
                ]
            },
            "title": "Legilimens: Practical and Unified Content Moderation for Large Language Model Services.",
            "venue": "CCS",
            "pages": "1151-1165",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/WuDPCXL024",
            "doi": "10.1145/3658644.3690322",
            "ee": "https://doi.org/10.1145/3658644.3690322",
            "url": "https://dblp.org/rec/conf/ccs/WuDPCXL024",
            "abstract": "Given the societal impact of unsafe content generated by large language models (LLMs), ensuring that LLM services comply with safety standards is a crucial concern for LLM service providers. Common content moderation methods are limited by an effectiveness-and-efficiency dilemma, where simple models are fragile while sophisticated models consume excessive computational resources. In this paper, we reveal for the first time that effective and efficient content moderation can be achieved by extracting conceptual features from chat-oriented LLMs, despite their initial fine-tuning for conversation rather than content moderation. We propose a practical and unified content moderation framework for LLM services, named Legilimens, which features both effectiveness and efficiency. Our red-team model-based data augmentation enhances the robustness of Legilimens against state-of-the-art jailbreaking. Additionally, we develop a framework to theoretically analyze the cost-effectiveness of Legilimens compared to other methods. We have conducted extensive experiments on five host LLMs, seventeen datasets, and nine jailbreaking methods to verify the effectiveness, efficiency, and robustness of Legilimens against normal and adaptive adversaries. A comparison of Legilimens with both commercial and academic baselines demonstrates the superior performance of Legilimens. Furthermore, we confirm that Legilimens can be applied to few-shot scenarios and extended to multi-label classification tasks.",
            "keywords": [
                "Content Moderation",
                "Large Language Models",
                "Safety Standards",
                "Data Augmentation",
                "Jailbreaking Robustness"
            ]
        },
        "url": "URL#256895",
        "sema_paperId": "45af32e2e65d828b28402e1c89546512ac3d1bbe"
    },
    {
        "@score": "1",
        "@id": "256896",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "47/2819",
                        "text": "Yixin Wu"
                    },
                    {
                        "@pid": "14/4412",
                        "text": "Yun Shen"
                    },
                    {
                        "@pid": "b/MichaelBackes1",
                        "text": "Michael Backes 0001"
                    },
                    {
                        "@pid": "06/6785-16",
                        "text": "Yang Zhang 0016"
                    }
                ]
            },
            "title": "Image-Perfect Imperfections: Safety, Bias, and Authenticity in the Shadow of Text-To-Image Model Evolution.",
            "venue": "CCS",
            "pages": "4837-4851",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/WuS0024",
            "doi": "10.1145/3658644.3690288",
            "ee": "https://doi.org/10.1145/3658644.3690288",
            "url": "https://dblp.org/rec/conf/ccs/WuS0024",
            "abstract": "Text-to-image models, such as Stable Diffusion (SD), undergo iterative updates to improve image quality and address concerns such as safety. Improvements in image quality are straightforward to assess. However, how model updates resolve existing concerns and whether they raise new questions remain unexplored. This study takes an initial step in investigating the evolution of text-to-image models from the perspectives of safety, bias, and authenticity. Our findings, centered on Stable Diffusion, indicate that model updates paint a mixed picture. While updates progressively reduce the generation of unsafe images, the bias issue, particularly in gender, intensifies. We also find that negative stereotypes either persist within the same Non-White race group or shift towards other Non-White race groups through SD updates, yet with minimal association of these traits with the White race group. Additionally, our evaluation reveals a new concern stemming from SD updates: State-of-the-art fake image detectors, initially trained for earlier SD versions, struggle to identify fake images generated by updated versions. We show that fine-tuning these detectors on fake images generated by updated versions achieves at least 96.6\\% accuracy across various SD versions, addressing this issue. Our insights highlight the importance of continued efforts to mitigate biases and vulnerabilities in evolving text-to-image models.",
            "keywords": [
                "Text-to-Image Models",
                "Model Updates",
                "Bias in AI",
                "Image Authenticity",
                "Safety in AI Generation"
            ]
        },
        "url": "URL#256896",
        "sema_paperId": "6d9c5cbee7b3388895b47eb0846c29460a9aad7a"
    },
    {
        "@score": "1",
        "@id": "256897",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "392/3340",
                        "text": "Jielun Wu"
                    },
                    {
                        "@pid": "145/3943",
                        "text": "Qingkai Shi"
                    }
                ]
            },
            "title": "Poster: Protecting Source Code Privacy When Hunting Bugs.",
            "venue": "CCS",
            "pages": "5030-5032",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/WuS24",
            "doi": "10.1145/3658644.3691407",
            "ee": "https://doi.org/10.1145/3658644.3691407",
            "url": "https://dblp.org/rec/conf/ccs/WuS24",
            "abstract": "When proving to a third party that a software system is of high quality or bug-free, a software vendor may have to reveal the source code such that the third party can use a public or their own static code analyzer to check the code. However, revealing source code seriously damages the interests of software vendors as the source code often contains core technical details or even secrets. In this work, we propose a win-win solution that can help software vendors protect source code privacy to the greatest extent and, meanwhile, maximize the bug-detection capability of the third party. Our key idea is that a majority of source code information is not useful for bug detection. Thus, a software vendor only needs to reveal a little source code information --- a stripped binary together with minimal debug information (which is the carrier of source code information) --- to prove the software's quality. To realize this win-win solution, we propose an approach that minimizes critical debug information in a non-stripped binary while maintaining its positive impact on static bug detection. Evaluation results demonstrate that our approach can significantly reduce the size of debug information and retain only a minimal amount of source-level private information.",
            "pdf_url": "",
            "keywords": [
                "Source Code Privacy",
                "Static Code Analysis",
                "Debug Information Minimization",
                "Bug Detection",
                "Software Quality Assurance"
            ]
        },
        "url": "URL#256897",
        "sema_paperId": "f76342a5d8296c3146dee3508d7bcec8703d9e83"
    },
    {
        "@score": "1",
        "@id": "256898",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "156/3706",
                        "text": "Hao Xiang"
                    },
                    {
                        "@pid": "392/2917",
                        "text": "Zehui Cheng"
                    },
                    {
                        "@pid": "06/8291",
                        "text": "Jinku Li"
                    },
                    {
                        "@pid": "12/6604-1",
                        "text": "Jianfeng Ma 0001"
                    },
                    {
                        "@pid": "67/10639",
                        "text": "Kangjie Lu"
                    }
                ]
            },
            "title": "Boosting Practical Control-Flow Integrity with Complete Field Sensitivity and Origin Awareness.",
            "venue": "CCS",
            "pages": "4524-4538",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/XiangCL0L24",
            "doi": "10.1145/3658644.3670308",
            "ee": "https://doi.org/10.1145/3658644.3670308",
            "url": "https://dblp.org/rec/conf/ccs/XiangCL0L24",
            "abstract": "Control-flow integrity (CFI) is a strong and efficient defense mechanism against memory-corruption attacks. The practical versions of CFI, which have been integrated into compilers, employ static analysis to collect all possibly valid target functions of indirect calls. They are however less effective because the static analysis is imprecise. While more precise CFI techniques have been proposed, such as dynamic CFI, they are not yet practical due to issues on performance, compatibility, and deployability. We believe that to be practical, CFI based on static analysis is still the promising direction. However, these years have not seen much progress on the effectiveness of such practical CFI.",
            "pdf_url": "",
            "keywords": [
                "Control-Flow Integrity",
                "Memory-Corruption Attacks",
                "Static Analysis",
                "Dynamic CFI",
                "Field Sensitivity and Origin Awareness"
            ]
        },
        "url": "URL#256898",
        "sema_paperId": "cd28f49113b1f38005e1054f5c6cab2e761a7e07"
    },
    {
        "@score": "1",
        "@id": "256899",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "80/6791-7",
                        "text": "Yue Xiao 0007"
                    },
                    {
                        "@pid": "381/1693",
                        "text": "Chaoqi Zhang 0006"
                    },
                    {
                        "@pid": "142/1169",
                        "text": "Yue Qin"
                    },
                    {
                        "@pid": "392/3178",
                        "text": "Fares Fahad S. Alharbi"
                    },
                    {
                        "@pid": "34/8412",
                        "text": "Luyi Xing"
                    },
                    {
                        "@pid": "129/1113",
                        "text": "Xiaojing Liao"
                    }
                ]
            },
            "title": "Measuring Compliance Implications of Third-party Libraries&apos; Privacy Label Disclosure Guidelines.",
            "venue": "CCS",
            "pages": "1641-1655",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Xiao0QAXL24",
            "doi": "10.1145/3658644.3670371",
            "ee": "https://doi.org/10.1145/3658644.3670371",
            "url": "https://dblp.org/rec/conf/ccs/Xiao0QAXL24",
            "abstract": "Privacy label disclosure guideline, which specifies the data usage practices of third-party libraries (TPL), is a valuable resource for iOS app developers to accurately complete their iOS privacy labels. This is particularly important given the mandatory requirement for all apps on the App Store to disclose their data practices via privacy labels. However, it is essential to ensure the accuracy and compliance of these guidelines to ensure that accurate TPL data usage has been provided to app developers. Despite the significance of these guidelines, there is little understanding of how accurate and compliant they are in reflecting the actual data practices of third-party libraries used in iOS apps. To address this issue, our study implements a tool called Colaine to automatically check the compliance of privacy label disclosure guidelines, taking into account the configurable data practices in TPLs. Colaine analyzed 107 TPLs associated with 1,605 different configurations, shedding light on the prevalence and seriousness of privacy label disclosure guideline non-compliance issues.",
            "keywords": [
                "Privacy Label Compliance",
                "Third-party Libraries",
                "Data Usage Practices",
                "iOS App Development",
                "Privacy Disclosure Guidelines"
            ]
        },
        "url": "URL#256899",
        "sema_paperId": "7c4dfd77b6e40719a4c1e2e678ad434550b04953"
    },
    {
        "@score": "1",
        "@id": "256900",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "325/3450",
                        "text": "Haoyu Xiao"
                    },
                    {
                        "@pid": "48/2168-9",
                        "text": "Yuan Zhang 0009"
                    },
                    {
                        "@pid": "332/3133",
                        "text": "Minghang Shen"
                    },
                    {
                        "@pid": "262/2722",
                        "text": "Chaoyang Lin"
                    },
                    {
                        "@pid": "35/1714",
                        "text": "Can Zhang"
                    },
                    {
                        "@pid": "22/2080-3",
                        "text": "Shengli Liu 0003"
                    },
                    {
                        "@pid": "02/1640-2",
                        "text": "Min Yang 0002"
                    }
                ]
            },
            "title": "Accurate and Efficient Recurring Vulnerability Detection for IoT Firmware.",
            "venue": "CCS",
            "pages": "3317-3331",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Xiao0SLZ0024",
            "doi": "10.1145/3658644.3670275",
            "ee": "https://doi.org/10.1145/3658644.3670275",
            "url": "https://dblp.org/rec/conf/ccs/Xiao0SLZ0024",
            "abstract": "IoT firmware faces severe threats to security vulnerabilities. As an important method to detect vulnerabilities, recurring vulnerability detection has not been systematically studied in IoT firmware. In fact, existing methods would meet significant challenges from two aspects. First, firmware vulnerabilities are usually reported in texts without too much code-level information, e.g., security patches. Second, firmware images are released as binaries, making the analysis of known vulnerabilities and the detection of unknown vulnerabilities quite difficult. This paper presents FirmRec, the first recurring vulnerability detection approach for IoT firmware. FirmRec features several new techniques to enable accurate and efficient vulnerability detection. First, it proposes a new exploitation-based vulnerability signature representation for firmware, which does not use syntactic code features but the semantic features along the dynamic vulnerability exploitation procedure (thus is more resilient to binary code changes and fits the context of binary-only firmware). Second, given a vulnerability report, it designs concolic execution-based vulnerability signature extraction to understand the vulnerability exploitation procedure and generate an exploitation-based vulnerability signature. Third, based on known vulnerability signatures, it employs a two-stage pipeline to accurately and efficiently detect recurring vulnerabilities.",
            "keywords": [
                "IoT Firmware Security",
                "Vulnerability Detection",
                "Recurring Vulnerabilities",
                "Exploitation-Based Signatures",
                "Concolic Execution"
            ]
        },
        "url": "URL#256900",
        "sema_paperId": "3af6e2156e5e83ca596076649674fd704a8399a1"
    },
    {
        "@score": "1",
        "@id": "256901",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "184/4766",
                        "text": "Hanshen Xiao"
                    },
                    {
                        "@pid": "09/5657",
                        "text": "G. Edward Suh"
                    },
                    {
                        "@pid": "14/3973",
                        "text": "Srinivas Devadas"
                    }
                ]
            },
            "title": "Formal Privacy Proof of Data Encoding: The Possibility and Impossibility of Learnable Encryption.",
            "venue": "CCS",
            "pages": "1834-1848",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/XiaoSD24",
            "doi": "10.1145/3658644.3670277",
            "ee": "https://doi.org/10.1145/3658644.3670277",
            "url": "https://dblp.org/rec/conf/ccs/XiaoSD24",
            "abstract": "We initiate a formal study on the concept of learnable obfuscation and aim to answer the following question: is there a type of data encoding that maintains the \"learnability\" of encoded samples, thereby enabling direct model training on transformed data, while ensuring the privacy of both plaintext and the secret encoding function? This long-standing open problem has prompted many efforts to design such an encryption function, for example, NeuraCrypt and TransNet. Nonetheless, all existing constructions are heuristic without formal privacy guarantees, and many successful reconstruction attacks are known on these constructions assuming an adversary with substantial prior knowledge.",
            "pdf_url": "",
            "keywords": [
                "Learnable Obfuscation",
                "Data Encoding",
                "Privacy Preservation",
                "Reconstruction Attacks",
                "Formal Privacy Guarantees"
            ]
        },
        "url": "URL#256901",
        "sema_paperId": "ea85b79b3775729df1b207a47ae4d1723fb53740"
    },
    {
        "@score": "1",
        "@id": "256902",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "301/7958",
                        "text": "Danning Xie"
                    },
                    {
                        "@pid": "16/1234-2",
                        "text": "Zhuo Zhang 0002"
                    },
                    {
                        "@pid": "06/4489-12",
                        "text": "Nan Jiang 0012"
                    },
                    {
                        "@pid": "276/3462",
                        "text": "Xiangzhe Xu"
                    },
                    {
                        "@pid": "13/3957-1",
                        "text": "Lin Tan 0001"
                    },
                    {
                        "@pid": "95/3760-1",
                        "text": "Xiangyu Zhang 0001"
                    }
                ]
            },
            "title": "ReSym: Harnessing LLMs to Recover Variable and Data Structure Symbols from Stripped Binaries.",
            "venue": "CCS",
            "pages": "4554-4568",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Xie00X0024",
            "doi": "10.1145/3658644.3670340",
            "ee": "https://doi.org/10.1145/3658644.3670340",
            "url": "https://dblp.org/rec/conf/ccs/Xie00X0024",
            "abstract": "Decompilation aims to recover a binary executable to the source code form and hence has a wide range of applications in cyber security, such as malware analysis and legacy code hardening. A prominent challenge is to recover variable symbols, including both primitive and complex types such as user-defined data structures, along with their symbol information such as names and types. Existing efforts focus on solving parts of the problem, e.g., recovering only types (without names) or only local variables (without user-defined structures). In this paper, we propose ReSym, a novel hybrid technique that combines Large Language Models (LLMs) and program analysis to recover both names and types for local variables and user-defined data structures. Our method encompasses fine-tuning two LLMs to handle local variables and structures, respectively. To overcome the inherent token limitations in current LLMs, we devise a novel Prolog-based algorithm to aggregate and cross-check results from multiple LLM queries, suppressing uncertainty and hallucinations. Our experiments show that ReSym is effective in recovering variable information and user-defined data structures, substantially outperforming the state-of-the-art methods.",
            "keywords": [
                "Binary Analysis",
                "Decompilation",
                "Variable Recovery",
                "User-defined Data Structures",
                "Large Language Models (LLMs)"
            ]
        },
        "url": "URL#256902",
        "sema_paperId": "5d8c1c3857e14f6fdc7d47d9f8b4783e71e90b4c"
    },
    {
        "@score": "1",
        "@id": "256903",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "293/0988",
                        "text": "Zhikang Xie"
                    },
                    {
                        "@pid": "37/10342",
                        "text": "Mengling Liu"
                    },
                    {
                        "@pid": "137/5280",
                        "text": "Haiyang Xue"
                    },
                    {
                        "@pid": "55/24",
                        "text": "Man Ho Au"
                    },
                    {
                        "@pid": "d/RobertHDeng",
                        "text": "Robert H. Deng"
                    },
                    {
                        "@pid": "y/SiuMingYiu",
                        "text": "Siu-Ming Yiu"
                    }
                ]
            },
            "title": "Direct Range Proofs for Paillier Cryptosystem and Their Applications.",
            "venue": "CCS",
            "pages": "899-913",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/XieLXADY24",
            "doi": "10.1145/3658644.3690261",
            "ee": "https://doi.org/10.1145/3658644.3690261",
            "url": "https://dblp.org/rec/conf/ccs/XieLXADY24",
            "abstract": "The Paillier cryptosystem is renowned for its applications in electronic voting, threshold ECDSA, multi-party computation, and more, largely due to its additive homomorphism. In these applications, range proofs for the Paillier cryptosystem are crucial for maintaining security, because of the mismatch between the message space in the Paillier system and the operation space in application scenarios.",
            "pdf_url": "",
            "keywords": [
                "Paillier Cryptosystem",
                "Additive Homomorphism",
                "Range Proofs",
                "Electronic Voting",
                "Multi-Party Computation"
            ]
        },
        "url": "URL#256903"
    },
    {
        "@score": "1",
        "@id": "256904",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "166/9948",
                        "text": "Tong Xin"
                    },
                    {
                        "@pid": "39/2405-4",
                        "text": "Ying He 0004"
                    },
                    {
                        "@pid": "44/10330",
                        "text": "Efpraxia D. Zamani"
                    },
                    {
                        "@pid": "193/7947",
                        "text": "Cunjin Luo"
                    }
                ]
            },
            "title": "Poster: Cyber Security Economics Model (CYSEM).",
            "venue": "CCS",
            "pages": "4946-4948",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Xin0ZL24",
            "doi": "10.1145/3658644.3691398",
            "ee": "https://doi.org/10.1145/3658644.3691398",
            "url": "https://dblp.org/rec/conf/ccs/Xin0ZL24",
            "abstract": "The increasing sophistication of cyberattacks and the evolution of security risks make it challenging for organizations to understand their impact on businesses. The habitual reliance on the judgment of cyber security experts and communication gaps between cyber security team and board members, responsible for making strategic cyber security investment decisions further weaken organization's capability to respond to cyber threats. Existing research lacks a transparent approach to quantify security risks and their impact on businesses. This paper introduces a novel CYSEM that express security risk in financial terms, through integrating Cyber Threat Intelligence (CTI) with the Factor Analysis of Information Risk (FAIR) model, elaborated with cyber security cost typologies. CYSEM facilitates communication among multi-stakeholders and improves transparency and quality of investment decision-making at the strategic level. We evaluate the CYSEM using a case study, which has showed its effectiveness in understanding the impact of cyber threat from an economics perspective.",
            "pdf_url": "",
            "keywords": [
                "Cyber Security Economics",
                "Cyber Threat Intelligence",
                "Risk Quantification",
                "Investment Decision-Making",
                "Factor Analysis of Information Risk (FAIR)"
            ]
        },
        "url": "URL#256904",
        "sema_paperId": "c6bd2a1c04d05fb024b299e78e76ff2cf1b4a8a3"
    },
    {
        "@score": "1",
        "@id": "256905",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "89/3127",
                        "text": "Yuan Xu"
                    },
                    {
                        "@pid": "236/9144",
                        "text": "Gelei Deng"
                    },
                    {
                        "@pid": "310/0337",
                        "text": "Xingshuo Han"
                    },
                    {
                        "@pid": "31/10776",
                        "text": "Guanlin Li"
                    },
                    {
                        "@pid": "15/4507-1",
                        "text": "Han Qiu 0001"
                    },
                    {
                        "@pid": "77/7902-4",
                        "text": "Tianwei Zhang 0004"
                    }
                ]
            },
            "title": "PhyScout: Detecting Sensor Spoofing Attacks via Spatio-temporal Consistency.",
            "venue": "CCS",
            "pages": "1879-1893",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/XuDHL0024",
            "doi": "10.1145/3658644.3670290",
            "ee": "https://doi.org/10.1145/3658644.3670290",
            "url": "https://dblp.org/rec/conf/ccs/XuDHL0024",
            "abstract": "Existing defense approaches against sensor spoofing attacks suffer from the limitations of limited specific attack types, requiring GPU computation, exhibiting considerable detection latency and struggling with the interpretability of corner cases. We developed PhyScout, a holistic sensor spoofing defense framework to overcome the above limitations. Our framework capitalizes on the observation that human drivers can rapidly and accurately identify spoofing attacks by performing spatio-temporal consistency checks of their environment. We commence by defining the generalized conflicts that different sensor spoofing attacks produce regarding the spatio-temporal consistency. These conflicts are subsequently unified and formalized through a least squares problem approach. This process is modeled using image-based feature point extraction and matching techniques, followed by the design of a risk identification method for each conflict.",
            "pdf_url": "",
            "keywords": [
                "Sensor Spoofing Defense",
                "Spatio-temporal Consistency",
                "Sensor Attacks",
                "Risk Identification",
                "Least Squares Problem"
            ]
        },
        "url": "URL#256905",
        "sema_paperId": "fe90b7f2869f6243d63eb32bd6bea52ede317742"
    },
    {
        "@score": "1",
        "@id": "256906",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "140/8357",
                        "text": "Haoran Xu"
                    },
                    {
                        "@pid": "129/1178",
                        "text": "Zhiyuan Jiang"
                    },
                    {
                        "@pid": "74/1097",
                        "text": "Yongjun Wang"
                    },
                    {
                        "@pid": "275/5256",
                        "text": "Shuhui Fan"
                    },
                    {
                        "@pid": "64/10449",
                        "text": "Shenglin Xu"
                    },
                    {
                        "@pid": "128/3562",
                        "text": "Peidai Xie"
                    },
                    {
                        "@pid": "98/902",
                        "text": "Shaojing Fu"
                    },
                    {
                        "@pid": "31/1273",
                        "text": "Mathias Payer"
                    }
                ]
            },
            "title": "Fuzzing JavaScript Engines with a Graph-based IR.",
            "venue": "CCS",
            "pages": "3734-3748",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/XuJWFXXFP24",
            "doi": "10.1145/3658644.3690336",
            "ee": "https://doi.org/10.1145/3658644.3690336",
            "url": "https://dblp.org/rec/conf/ccs/XuJWFXXFP24",
            "abstract": "Mutation-based fuzzing effectively discovers defects in JS engines. High-quality mutations are key for the performance of mutation-based fuzzers. The choice of the underlying representation (e.g., a sequence of tokens, an abstract syntax tree, or an intermediate representation) defines the possible mutation space and subsequently influences the design of mutation operators. Current program representations in JS engine fuzzers center around abstract syntax trees and customized bytecode-level intermediate languages. However, existing efforts struggle to generate semantically valid and meaningful mutations, limiting the discovery of defects in JS engines. Our proposed graph-based intermediate representation, FlowIR, directly represents the JS control flow and data flow as the mutation target. FlowIR is essential for the implementation of powerful semantic mutation. It supports mutation operators at the data flow and control flow level, thereby expanding the granularity of mutation operators. Experimental results show that our method is more effective in discovering new bugs. Our prototype, FuzzFlow, outperforms state-of-the-art fuzzers in generating valid test cases and exploring code coverage. In our evaluation, we detected 37 new defects in thoroughly tested mainstream JS engines.",
            "keywords": [
                "JavaScript Engine Fuzzing",
                "Mutation-based Fuzzing",
                "Graph-based Intermediate Representation",
                "Semantic Mutation",
                "FlowIR"
            ]
        },
        "url": "URL#256906",
        "sema_paperId": "886ae4e3a498c0180956a3a7541e4ad8840a4507"
    },
    {
        "@score": "1",
        "@id": "256907",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "383/4999",
                        "text": "Huiyu Xu"
                    },
                    {
                        "@pid": "282/9311",
                        "text": "Yaopeng Wang"
                    },
                    {
                        "@pid": "31/5772-1",
                        "text": "Zhibo Wang 0001"
                    },
                    {
                        "@pid": "139/5759",
                        "text": "Zhongjie Ba"
                    },
                    {
                        "@pid": "66/300",
                        "text": "Wenxin Liu"
                    },
                    {
                        "@pid": "28/2680",
                        "text": "Lu Jin"
                    },
                    {
                        "@pid": "169/7167",
                        "text": "Haiqin Weng"
                    },
                    {
                        "@pid": "64/5099",
                        "text": "Tao Wei"
                    },
                    {
                        "@pid": "20/6179-1",
                        "text": "Kui Ren 0001"
                    }
                ]
            },
            "title": "ProFake: Detecting Deepfakes in the Wild against Quality Degradation with Progressive Quality-adaptive Learning.",
            "venue": "CCS",
            "pages": "2207-2221",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/XuW0BLJWW024",
            "doi": "10.1145/3658644.3690238",
            "ee": "https://doi.org/10.1145/3658644.3690238",
            "url": "https://dblp.org/rec/conf/ccs/XuW0BLJWW024",
            "abstract": "Despite the promising advances in deepfake detection on current datasets, detecting visual deepfakes in real-world scenarios (e.g., deepfake videos and live streaming on YouTube) remains a challenge due to the inherent quality degradation such as unpredictable compression employed by social media platforms. Such degradation perturbs discernible forgery clues and diminishes the effectiveness of deepfake detection methods, raising a critical safety concern to the misuse of forgery faces in real-world scenarios. In this paper, we aim to understand the impacts of real-world degradation on the robustness of deepfake detection. Particularly, we investigate the risk of degraded deepfakes towards their detection on two real-world scenarios (i.e., deepfake videos and deepfake live streaming on social media platforms). By measuring the effects of real-world degradations on the performance and representation capabilities of detection models, we reveal that real-world deepfakes can be simulated via common degradation operations (e.g., JPEG compression) as they are perceptually similar to deepfake detectors. By analyzing the training dynamics under different sequences of training samples, we observe that the training order of deepfakes progressing from non-degraded (easy) to heavily degraded (hard) enhances the adaptability of detection models to various degradation in real-world scenarios. Drawing from these observations, we present a novel deepfake detection method ProFake to enhance the robustness of deepfake detection against real-world quality degradations. ProFake enables quality-adaptive learning via progressively degrade, detect and assign weights for the training samples driven by the feedback of model performance and image quality, which ensures that our model gradually focuses on more challenging samples to achieve quality-adaptive deepfake detection. Extensive experiments show that compared with existing methods, ProFake improves deepfake detection accuracy by an average of over 10 % in real-world scenarios and by an average of over 30 % in heavily degraded scenarios, while maintaining comparable performance in detecting high-quality deepfakes.",
            "pdf_url": "",
            "keywords": [
                "Deepfake Detection",
                "Quality Degradation",
                "Real-world Scenarios",
                "Progressive Quality-adaptive Learning",
                "Robustness Against Degradation"
            ]
        },
        "url": "URL#256907",
        "sema_paperId": "9accdd96f8f9b1c393aaca0965fc137ecc9c9647"
    },
    {
        "@score": "1",
        "@id": "256908",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "162/1634",
                        "text": "Shuangqing Xu"
                    },
                    {
                        "@pid": "60/3312",
                        "text": "Yifeng Zheng"
                    },
                    {
                        "@pid": "155/4920",
                        "text": "Zhongyun Hua"
                    }
                ]
            },
            "title": "Camel: Communication-Efficient and Maliciously Secure Federated Learning in the Shuffle Model of Differential Privacy.",
            "venue": "CCS",
            "pages": "243-257",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/XuZH24",
            "doi": "10.1145/3658644.3690200",
            "ee": "https://doi.org/10.1145/3658644.3690200",
            "url": "https://dblp.org/rec/conf/ccs/XuZH24",
            "abstract": "Federated learning (FL) has rapidly become a compelling paradigm that enables multiple clients to jointly train a model by sharing only gradient updates for aggregation, without revealing their local private data. In order to protect the gradient updates which could also be privacy-sensitive, there has been a line of work studying local differential privacy (LDP) mechanisms to provide a formal privacy guarantee. With LDP mechanisms, clients locally perturb their gradient updates before sharing them out for aggregation. However, such approaches are known for greatly degrading the model utility, due to heavy noise addition. To enable a better privacy-utility tradeoff, a recently emerging trend is to apply the shuffle model of DP in FL, which relies on an intermediate shuffling operation on the perturbed gradient updates to achieve privacy amplification. Following this trend, in this paper, we present Camel, a new communication-efficient and maliciously secure FL framework in the shuffle model of DP. Camel first departs from existing works by ambitiously supporting integrity check for the shuffle computation, achieving security against malicious adversary. Specifically, Camel builds on the trending cryptographic primitive of secret-shared shuffle, with custom techniques we develop for optimizing system-wide communication efficiency, and for lightweight integrity checks to harden the security of server-side computation. In addition, we also derive a significantly tighter bound on the privacy loss through analyzing the Renyi differential privacy (RDP) of the overall FL process. Extensive experiments demonstrate that Camel achieves better privacy-utility trade-offs than the state-of-the-art work, with promising performance.",
            "keywords": [
                "Federated Learning",
                "Local Differential Privacy",
                "Shuffle Model",
                "Malicious Security",
                "Privacy-Utility Tradeoff"
            ]
        },
        "url": "URL#256908",
        "sema_paperId": "8916d4aa2274d5b033228f83e832cfa8494a3e8b"
    },
    {
        "@score": "1",
        "@id": "256909",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "164/3671",
                        "text": "Di Xue"
                    },
                    {
                        "@pid": "73/860",
                        "text": "Gang Zhao"
                    },
                    {
                        "@pid": "257/0173",
                        "text": "Zhongqi Fan"
                    },
                    {
                        "@pid": "64/6025",
                        "text": "Wei Li"
                    },
                    {
                        "@pid": "168/7353",
                        "text": "Yahong Xu"
                    },
                    {
                        "@pid": "77/35",
                        "text": "Zhen Liu"
                    },
                    {
                        "@pid": "10/3416",
                        "text": "Yin Liu"
                    },
                    {
                        "@pid": "392/3323",
                        "text": "Zhongliang Yuan"
                    }
                ]
            },
            "title": "Poster: An Exploration of Large Language Models in Malicious Source Code Detection.",
            "venue": "CCS",
            "pages": "4940-4942",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/XueZFLXLLY24",
            "doi": "10.1145/3658644.3691374",
            "ee": "https://doi.org/10.1145/3658644.3691374",
            "url": "https://dblp.org/rec/conf/ccs/XueZFLXLLY24",
            "abstract": "Embedding malicious code within the software supply chain has become a significant concern in the information technology field. Current methods for detecting malicious code, based on signatures, behavior analysis, and traditional machine learning models, lack result interpretability. This study proposes a novel malicious code detection framework, Mal-LLM, which leverages the cost advantages of traditional machine learning models and the interpretability of LLMs. Initially, traditional machine learning models filter vast amounts of malicious source code in the software supply chain. Subsequently, LLMs analyze and interpret the filtered malicious source code using a customized prompt template incorporating role-playing and chain-of-thought techniques. The feasibility of the Mal-LLM framework is validated through extensive experimental analyses, examining the ambiguity and redundancy of the LLM in the framework, the significance of ''experience'' and ''malicious'' prompts, and exploring methods to reduce the cost of using LLMs from an enterprise perspective.",
            "pdf_url": "",
            "keywords": [
                "Malicious Code Detection",
                "Software Supply Chain",
                "Large Language Models",
                "Interpretability",
                "Cost Reduction in LLMs"
            ]
        },
        "url": "URL#256909",
        "sema_paperId": "6dce639f0644b5fec9d61d4401087346afc22270"
    },
    {
        "@score": "1",
        "@id": "256910",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "118/0321",
                        "text": "Yihui Yan"
                    },
                    {
                        "@pid": "162/5529",
                        "text": "Zhice Yang"
                    }
                ]
            },
            "title": "MaskPrint: Take the Initiative in Fingerprint Protection to Mitigate the Harm of Data Breach.",
            "venue": "CCS",
            "pages": "1806-1818",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/YanY24",
            "doi": "10.1145/3658644.3670364",
            "ee": "https://doi.org/10.1145/3658644.3670364",
            "url": "https://dblp.org/rec/conf/ccs/YanY24",
            "abstract": "The privacy of fingerprints is a growing concern due to the risk of data breaches and subsequent attacks. A key issue is that the information of the same fingerprint may exist on multiple devices, and device-level protection mechanisms are fundamentally limited in their coverage. Consequently, information leakage from any device potentially affects all enrolled fingerprint recognition devices. In this paper, we introduce a novel fingerprint enrollment method called MaskPrint, which allows users to enroll in various fingerprint recognition systems using distinct information. This approach can largely mitigate the risk of data breaches, providing a user-transparent, device-agnostic fingerprint protection measure. Our method involves collecting the original fingerprint information, selecting a minimum feature set, synthesizing protective fingerprints, and fabricating physical ones for enrollment. Users can complete these procedures on their own. We validate the effectiveness and usability of MaskPrint on commercial fingerprint recognition systems.",
            "pdf_url": "",
            "keywords": [
                "Fingerprint Privacy",
                "Data Breach Mitigation",
                "Fingerprint Recognition Systems",
                "User-Transparent Protection",
                "Distinct Fingerprint Information"
            ]
        },
        "url": "URL#256910",
        "sema_paperId": "1db9082699ef14e9d306dbf27658c568b2fe89f3"
    },
    {
        "@score": "1",
        "@id": "256911",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "341/9518",
                        "text": "Kailun Yan"
                    },
                    {
                        "@pid": "158/4724",
                        "text": "Xiaokuan Zhang"
                    },
                    {
                        "@pid": "149/2350",
                        "text": "Wenrui Diao"
                    }
                ]
            },
            "title": "Stealing Trust: Unraveling Blind Message Attacks in Web3 Authentication.",
            "venue": "CCS",
            "pages": "555-569",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/YanZD24",
            "doi": "10.1145/3658644.3670323",
            "ee": "https://doi.org/10.1145/3658644.3670323",
            "url": "https://dblp.org/rec/conf/ccs/YanZD24",
            "abstract": "As the field of Web3 continues its rapid expansion, the security of Web3 authentication, often the gateway to various Web3 applications, becomes increasingly crucial. Despite its widespread use as a login method by numerous Web3 applications, the security risks of Web3 authentication have not received much attention. This paper investigates the vulnerabilities in the Web3 authentication process and proposes a new type of attack, dubbed blind message attacks. In blind message attacks, attackers trick users into blindly signing messages from target applications by exploiting users' inability to verify the source of messages, thereby achieving unauthorized access to the target application. We have developed Web3AuthChecker, a dynamic detection tool that interacts with Web3 authentication-related APIs to identify vulnerabilities. Our evaluation of real-world Web3 applications shows that a staggering 75.8% (22/29) of Web3 authentication deployments are at risk of blind message attacks. In response to this alarming situation, we implemented Web3AuthGuard on the open-source wallet MetaMask to alert users of potential attacks. Our evaluation results show that Web3AuthGuard can successfully raise alerts in 80% of the tested Web3 authentications. We have responsibly reported our findings to vulnerable websites and have been assigned two CVE IDs.",
            "keywords": [
                "Web3 Authentication",
                "Blind Message Attacks",
                "Security Vulnerabilities",
                "User Exploitation",
                "Web3AuthChecker"
            ]
        },
        "url": "URL#256911",
        "sema_paperId": "36fade8611566feadfa9d1678448a4c5c5b2ed0b"
    },
    {
        "@score": "1",
        "@id": "256912",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "146/9561",
                        "text": "Yuxin Yang"
                    },
                    {
                        "@pid": "72/872-8",
                        "text": "Qiang Li 0008"
                    },
                    {
                        "@pid": "24/5124-1",
                        "text": "Jinyuan Jia 0001"
                    },
                    {
                        "@pid": "79/5433",
                        "text": "Yuan Hong"
                    },
                    {
                        "@pid": "123/7149",
                        "text": "Binghui Wang"
                    }
                ]
            },
            "title": "Distributed Backdoor Attacks on Federated Graph Learning and Certified Defenses.",
            "venue": "CCS",
            "pages": "2829-2843",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/YangLJHW24",
            "doi": "10.1145/3658644.3690187",
            "ee": "https://doi.org/10.1145/3658644.3690187",
            "url": "https://dblp.org/rec/conf/ccs/YangLJHW24",
            "abstract": "Federated graph learning (FedGL) is an emerging federated learning (FL) framework that extends FL to learn graph data from diverse sources. FL for non-graph data has shown to be vulnerable to backdoor attacks, which inject a shared backdoor trigger into the training data such that the trained backdoored FL model can predict the testing data containing the trigger as the attacker desires. However, FedGL against backdoor attacks is largely unexplored, and no effective defense exists. In this paper, we aim to address such significant deficiency. First, we propose an effective, stealthy, and persistent backdoor attack on FedGL. Our attack uses a subgraph as the trigger and designs an adaptive trigger generator that can derive the effective trigger location and shape for each graph. Our attack shows that empirical defenses are hard to detect/remove our generated triggers. To mitigate it, we further develop a certified defense for any backdoored FedGL model against the trigger with any shape at any location. Our defense involves carefully dividing a testing graph into multiple subgraphs and designing a majority vote-based ensemble classifier on these subgraphs. We then derive the deterministic certified robustness based on the ensemble classifier and prove its tightness. We extensively evaluate our attack and defense on six graph datasets. Our attack results show our attack can obtain>90% backdoor accuracy in almost all datasets. Our defense results show, in certain cases, the certified accuracy for clean testing graphs against an arbitrary trigger with size 20 can be close to the normal accuracy under no attack, while there is a moderate gap in other cases. Moreover, the certified backdoor accuracy is always 0 for backdoored testing graphs generated by our attack, implying our defense can fully mitigate the attack. Source code is available at: https://github.com/Yuxin104/Opt-GDBA.",
            "keywords": [
                "Federated Graph Learning",
                "Backdoor Attacks",
                "Trigger Generation",
                "Certified Defense",
                "Subgraph Ensemble Classifier"
            ]
        },
        "url": "URL#256912",
        "sema_paperId": "42bb47f5d06dd4e659de1eeaba4a04e1cd224634"
    },
    {
        "@score": "1",
        "@id": "256913",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "130/6977",
                        "text": "Ronghai Yang"
                    },
                    {
                        "@pid": "231/6763",
                        "text": "Xianbo Wang"
                    },
                    {
                        "@pid": "164/0299",
                        "text": "Kaixuan Luo"
                    },
                    {
                        "@pid": "75/2856",
                        "text": "Xin Lei"
                    },
                    {
                        "@pid": "75/6627",
                        "text": "Ke Li"
                    },
                    {
                        "@pid": "392/3387",
                        "text": "Jiayuan Xin"
                    },
                    {
                        "@pid": "l/WingCheongLau",
                        "text": "Wing Cheong Lau"
                    }
                ]
            },
            "title": "SWIDE: A Semantic-aware Detection Engine for Successful Web Injection Attacks.",
            "venue": "CCS",
            "pages": "540-554",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/YangWLLLXL24",
            "doi": "10.1145/3658644.3670304",
            "ee": "https://doi.org/10.1145/3658644.3670304",
            "url": "https://dblp.org/rec/conf/ccs/YangWLLLXL24",
            "abstract": "Web attacks, a primary vector for system breaches, pose a significant challenge within the cybersecurity landscape. The growing intensity of web attack attempts has led to \"alert fatigue\" where enterprises are inundated by excessive alerts. Although extensive research is being conducted on automated methods for detecting web attacks, it remains an open problem to identify whether the attacks are successful. Towards this end, we present SWIDE (Successful Web Injection Detection Engine), an engine to pinpoint successful web injection attacks (e.g., PHP command injection, SQL injection). This enables enterprises to focus exclusively on those crucial threats. Our methodology builds on two insights: Firstly, while attackers tend to apply payload obfuscation techniques to evade detection, all successful web injection attacks must comply with the programming language syntax to be executable; Secondly, these attacks inevitably produce observable effects, such as returning execution result or creating backdoors for future access by the attacker. Consequently, we leverage advanced syntactic and semantic analysis to 1) detect malicious syntax features in obfuscated payloads and 2) perform semantic analysis of the payload to recover the intention of the attack. With a two-stage design, namely, attack identification and confirmation mechanisms, SWIDE can accurately identify successful attacks, even amidst intricate obfuscations. Unlike proof-of-concept studies, SWIDE has been deployed and validated in real-world environments through collaborations with a cybersecurity firm. Serving 5,045 enterprise users, our system identifies that roughly 15% of enterprises have suffered from successful attacks on a weekly basis - an alarmingly high rate. Moreover, we perform a detailed analysis of six months' data and discover 60 zero-day vulnerabilities exploited in the wild, including 12 high-risk ones acknowledged by relevant authorities. These findings underscore the practical effectiveness of SWIDE.",
            "pdf_url": "",
            "keywords": [
                "Web Injection Attacks",
                "Semantic Analysis",
                "Payload Obfuscation",
                "Successful Attack Detection",
                "Zero-day Vulnerabilities"
            ]
        },
        "url": "URL#256913",
        "sema_paperId": "d66a94413793467dac7fd6aa2706ee62302fd5a9"
    },
    {
        "@score": "1",
        "@id": "256914",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "203/0673",
                        "text": "Yuqiao Yang"
                    },
                    {
                        "@pid": "187/5035",
                        "text": "Zhongjie Wu"
                    },
                    {
                        "@pid": "235/0642",
                        "text": "Yongzhao Zhang"
                    },
                    {
                        "@pid": "19/1766-2",
                        "text": "Ting Chen 0002"
                    },
                    {
                        "@pid": "116/1011",
                        "text": "Jun Li"
                    },
                    {
                        "@pid": "12/1198-3",
                        "text": "Jie Yang 0003"
                    },
                    {
                        "@pid": "86/8117",
                        "text": "Wenhao Liu"
                    },
                    {
                        "@pid": "26/3075-1",
                        "text": "Xiaosong Zhang 0001"
                    },
                    {
                        "@pid": "272/8111",
                        "text": "Ruicong Shi"
                    },
                    {
                        "@pid": "92/7728-1",
                        "text": "Jingwei Li 0001"
                    },
                    {
                        "@pid": "21/4633-1",
                        "text": "Yu Jiang 0001"
                    },
                    {
                        "@pid": "02/10578-5",
                        "text": "Zhuo Su 0005"
                    }
                ]
            },
            "title": "UWBAD: Towards Effective and Imperceptible Jamming Attacks Against UWB Ranging Systems with COTS Chips.",
            "venue": "CCS",
            "pages": "3376-3390",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/YangWZ0LYL0S00024",
            "doi": "10.1145/3658644.3670349",
            "ee": "https://doi.org/10.1145/3658644.3670349",
            "url": "https://dblp.org/rec/conf/ccs/YangWZ0LYL0S00024",
            "abstract": "UWB ranging systems have been adopted in many critical and security sensitive applications due to its precise positioning and secure ranging capabilities. We present a practical jamming attack, namely UWBAD, against commercial UWB ranging systems, which exploits the vulnerability of the adoption of the normalized cross-correlation process in UWB ranging and can selectively and quickly block ranging sessions without prior knowledge of the configurations of the victim devices, potentially leading to severe consequences such as property loss, unauthorized access, or vehicle theft. UWBAD achieves more effective and less imperceptible jamming due to: (i) it efficiently blocks every ranging session by leveraging the field-level jamming, thereby exerting a tangible impact on commercial UWB ranging systems, and (ii) the compact, reactive, and selective system design based on COTS UWB chips, making it affordable and less imperceptible. We successfully conducted real attacks against commercial UWB ranging systems from the three largest UWB chip vendors on the market, e.g., Apple, NXP, and Qorvo. We reported our findings to Apple, related Original Equipment Manufacturers (OEM), and the Automotive Security Research Group, triggering internal security incident response procedures at Volkswagen, Audi, Bosch, and NXP. As of the writing of this paper, the related OEM has acknowledged this vulnerability in their automotive systems and has offered a $5,000 reward as a bounty.",
            "keywords": [
                "UWB Ranging Systems",
                "Jamming Attacks",
                "Cross-Correlation Vulnerability",
                "COTS Chips",
                "Selective Blocking"
            ]
        },
        "url": "URL#256914",
        "sema_paperId": "90e93a5a648e4e5d17639c44992c67ac3c930735"
    },
    {
        "@score": "1",
        "@id": "256915",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "33/6363",
                        "text": "Qingsong Yao"
                    },
                    {
                        "@pid": "24/545",
                        "text": "Yuming Liu"
                    },
                    {
                        "@pid": "392/3054",
                        "text": "Xiongjia Sun"
                    },
                    {
                        "@pid": "49/7488",
                        "text": "Xuewen Dong"
                    },
                    {
                        "@pid": "39/1697-1",
                        "text": "Xiaoyu Ji 0001"
                    },
                    {
                        "@pid": "12/6604-1",
                        "text": "Jianfeng Ma 0001"
                    }
                ]
            },
            "title": "Watch the Rhythm: Breaking Privacy with Accelerometer at the Extremely-Low Sampling Rate of 5Hz.",
            "venue": "CCS",
            "pages": "1776-1790",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/YaoLSDJ024",
            "doi": "10.1145/3658644.3690370",
            "ee": "https://doi.org/10.1145/3658644.3690370",
            "url": "https://dblp.org/rec/conf/ccs/YaoLSDJ024",
            "abstract": "Considering the threat from on-board eavesdropping with smartphone motion sensors, Android 12 has limited the maximum sampling rate of motion sensors to 200Hz for zero-privilege access to prevent potential wiretapping. Unfortunately, there have been some attacks targeting 200Hz, making it not a safe sampling rate any more. Smartphone manufacturers may further reduce the maximum sampling rate of the accelerometer in response to this privacy concern. It can be expected that, the maximum sampling rate will gradually decrease to a very low level, as the battle between manufacturers and adversaries continues. Existing on-board eavesdropping approaches, utilizing spectral features, cannot provide acceptable accuracy at very low sampling rates, not even at 50Hz.",
            "pdf_url": "",
            "keywords": [
                "Smartphone Motion Sensors",
                "On-board Eavesdropping",
                "Privacy Threats",
                "Accelerometer Sampling Rate",
                "Low Sampling Rate Attacks"
            ]
        },
        "url": "URL#256915",
        "sema_paperId": "8f3409dd745cea3a0b0a68ad832c8b4baa050c3c"
    },
    {
        "@score": "1",
        "@id": "256916",
        "info": {
            "authors": {
                "author": {
                    "@pid": "392/3056",
                    "text": "Jiayuan Ye"
                }
            },
            "title": "Privacy Analyses in Machine Learning.",
            "venue": "CCS",
            "pages": "5110-5112",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Ye24",
            "doi": "10.1145/3658644.3690862",
            "ee": "https://doi.org/10.1145/3658644.3690862",
            "url": "https://dblp.org/rec/conf/ccs/Ye24",
            "abstract": "Machine learning models sometimes memorize sensitive training data features, posing privacy risks. To control such privacy risks, Dwork et al. proposed the definition of differential privacy (DP) to measure the privacy risks of an algorithm. However, existing DP models either have significantly lower accuracy than their non-private variants or are computationally expensive to train by requiring to incorporate a large amount of public prior knowledge in terms of data or a large pre-trained model. Thus, the fundamental problem of efficiently training an accurate model while preserving DP is not fully addressed. To tackle this problem, we investigate the potential of improving privacy analysis of machine learning algorithms, thus subsequently allowing improved privacy-utility trade-off. First, we observe that the standard DP bound is not tight for large, overparameterized models. Specifically, the DP bound worsens with the number of iterations, and the privacy-accuracy trade-off worsens with the model dimension. This is despite the algorithm converging during training and the finite dimension of training data space. Such potential untightness is more severe for a realistic adversary that does not observe all model parameters, where prior works suggest empirical privacy amplification, and we investigate theoretically. Finally, we take a close look at the privacy risk of each model prediction about individual training data and analyze how to attribute privacy risk to the properties of the data and the choice of model (e.g., architectures). If successful, our research would enable tighter and more informative privacy bounds for differentially private learning, thus in turn allowing improved privacy-utility trade-offs.",
            "pdf_url": "",
            "keywords": [
                "Differential Privacy",
                "Privacy Risks",
                "Privacy-Utility Trade-off",
                "Overparameterized Models",
                "Privacy Analysis"
            ]
        },
        "url": "URL#256916",
        "sema_paperId": "0f9e1c799fbf2e328acf56e25c630e31970c414d"
    },
    {
        "@score": "1",
        "@id": "256917",
        "info": {
            "authors": {
                "author": {
                    "@pid": "172/4550-1",
                    "text": "Zhiyuan Yu 0001"
                }
            },
            "title": "Towards Proactive Protection against Unauthorized Speech Synthesis.",
            "venue": "CCS",
            "pages": "5128-5130",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Yu24",
            "doi": "10.1145/3658644.3690868",
            "ee": "https://doi.org/10.1145/3658644.3690868",
            "url": "https://dblp.org/rec/conf/ccs/Yu24",
            "abstract": "The rapid advancement of artificial speech synthesis technologies, fueled by generative AI (GenAI), presents both opportunities and potential threats to society. While offering unprecedented opportunities, these technologies have been exploited to create \"DeepFake\" speech for fraud, impersonation, and spreading disinformation, as evidenced by recent real-world incidents. Our research aims to address such emerging threats by exploring a novel, proactive approach to disrupt unauthorized speech synthesis.",
            "pdf_url": "",
            "keywords": [
                "Speech Synthesis",
                "DeepFake Technology",
                "Unauthorized Speech",
                "Fraud Prevention",
                "Disinformation Mitigation"
            ]
        },
        "url": "URL#256917",
        "sema_paperId": "cd59615dab68dddcc6d0df2de119bddd567745e5"
    },
    {
        "@score": "1",
        "@id": "256918",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "220/7449",
                        "text": "Lingjing Yu"
                    },
                    {
                        "@pid": "303/5465",
                        "text": "Jingli Hao"
                    },
                    {
                        "@pid": "91/4845",
                        "text": "Jun Ma"
                    },
                    {
                        "@pid": "64/3333",
                        "text": "Yong Sun"
                    },
                    {
                        "@pid": "147/2217",
                        "text": "Yijun Zhao"
                    },
                    {
                        "@pid": "71/2890",
                        "text": "Bo Luo"
                    }
                ]
            },
            "title": "A Comprehensive Analysis of Security Vulnerabilities and Attacks in Satellite Modems.",
            "venue": "CCS",
            "pages": "3287-3301",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/YuHMSZL24",
            "doi": "10.1145/3658644.3670390",
            "ee": "https://doi.org/10.1145/3658644.3670390",
            "url": "https://dblp.org/rec/conf/ccs/YuHMSZL24",
            "abstract": "Satellite modems are critical components in satellite communication networks. Especially, they determine the entire communication regime in traditional systems where the satellites only act as transparent relays. However, unlike satellites that are usually more isolated and better protected, satellite modems are accessible and susceptible to lower-cost attacks, potentially serving as a weak link in the chain of satellite communication security. We make the first attempt to shed light on satellite modem security. We first physically disassemble commodity satellite modems and systematically examine hardware and software modules. We perform a measurement study on the satellite modems that are exposed to the Internet. We identify 16 security vulnerabilities across three attack surfaces: satellite communication interface, ground network interface, and hardware. We further introduce AirSecAnalyzer, an automated security analyzer/fuzzer for the modems\u2019 satellite communication interface. Through comprehensive analysis and extensive experiments on 9 real-world satellite modems, we report 18 novel attacks that exploit the identified vulnerabilities. Our findings are expected to contribute as a valuable foundation for future research on the security of satellite modems and satellite communication networks.",
            "keywords": [
                "Satellite Communication Security",
                "Satellite Modems",
                "Security Vulnerabilities",
                "Automated Security Analysis",
                "Attack Surfaces"
            ]
        },
        "url": "URL#256918",
        "sema_paperId": "d841bdef88879e9fc627ff1d5af307a6f9fe2b76"
    },
    {
        "@score": "1",
        "@id": "256919",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "295/5277",
                        "text": "Yuanyuan Yuan"
                    },
                    {
                        "@pid": "193/9286",
                        "text": "Zhibo Liu"
                    },
                    {
                        "@pid": "195/2914",
                        "text": "Sen Deng"
                    },
                    {
                        "@pid": "292/7423",
                        "text": "Yanzuo Chen"
                    },
                    {
                        "@pid": "42/1503-11",
                        "text": "Shuai Wang 0011"
                    },
                    {
                        "@pid": "77/3503",
                        "text": "Yinqian Zhang"
                    },
                    {
                        "@pid": "s/ZhendongSu",
                        "text": "Zhendong Su 0001"
                    }
                ]
            },
            "title": "HyperTheft: Thieving Model Weights from TEE-Shielded Neural Networks via Ciphertext Side Channels.",
            "venue": "CCS",
            "pages": "4346-4360",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/YuanLDCWZ024",
            "doi": "10.1145/3658644.3690317",
            "ee": "https://doi.org/10.1145/3658644.3690317",
            "url": "https://dblp.org/rec/conf/ccs/YuanLDCWZ024",
            "abstract": "Trusted execution environments (TEEs) are widely employed to protect deep neural networks (DNNs) from untrusted hosts (e.g., hypervisors). By shielding DNNs as fully black-box via encryption, TEEs mitigate model weight leakage and its follow-up white-box attacks. However, this paper uncovers that the confidentiality of TEE-shielded DNNs can be violated due to an emerging threat towards TEEs: ciphertext side channels of TEEs create weight-dependent observations during a DNN\u2019s execution. Despite the potential of inferring DNN weights from ciphertext side channels, existing techniques are inapplicable due to their over-strong requirements and the high precision required by DNN weights. A DNN can have millions of weight elements, and even a few incorrectly recovered weight elements may make the DNN non-functional. We propose a novel viewpoint that focuses on the functionality of DNN weights, rather than each weight element\u2019s exact value. Accordingly, we design HyperTheft to directly generate weights that are functionality-equivalent to the victim DNN using ciphertext side channels. HyperTheft is established for highly practical settings; it exhibits the weakest requirement compared to prior methods. When only knowing a victim DNN\u2019s input type and task type (which are public and denote the minimal information required to use a DNN), HyperTheft can recover its weight using ciphertext side channels logged during the victim DNN\u2019s one execution. The whole procedure does not require attackers to 1) query the",
            "keywords": [
                "Trusted Execution Environments",
                "Ciphertext Side Channels",
                "Model Weight Leakage",
                "Functionality-Equivalent Weights",
                "HyperTheft"
            ]
        },
        "url": "URL#256919",
        "sema_paperId": "aeb5c8a09395e39b2cea92d48e98db3da6c388b7"
    },
    {
        "@score": "1",
        "@id": "256920",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "y/WilliamYurcik",
                        "text": "William Yurcik"
                    },
                    {
                        "@pid": "77/3274",
                        "text": "Gregory Pluta"
                    },
                    {
                        "@pid": "392/2947",
                        "text": "Toan Luong"
                    },
                    {
                        "@pid": "67/136-1",
                        "text": "Luis Garcia 0001"
                    }
                ]
            },
            "title": "HealthSec &apos;24: First ACM CCS Workshop on Cybersecurity in Healthcare.",
            "venue": "CCS",
            "pages": "4882-4883",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/YurcikPLG24",
            "doi": "10.1145/3658644.3691334",
            "ee": "https://doi.org/10.1145/3658644.3691334",
            "url": "https://dblp.org/rec/conf/ccs/YurcikPLG24",
            "abstract": "Our motivation is to create new research forum bringing together diverse researchers from academia, government, and the healthcare industry to report on latest research efforts on cybersecurity in healthcare. As this is the inaugural workshop, our immediate goal for HealthSec'24 is to encourage, jumpstart, grow, and support an interdisciplinary community of researchers focused on cybersecurity in healthcare. To our knowledge this is the first cybersecurity research forum of any kind to have participation from credentialed medical doctors with backgrounds and/or responsibilities related to cybersecurity in healthcare.",
            "pdf_url": "",
            "keywords": [
                "Cybersecurity in Healthcare",
                "Interdisciplinary Research",
                "Healthcare Data Protection",
                "Medical Cybersecurity",
                "Healthcare Vulnerabilities"
            ]
        },
        "url": "URL#256920",
        "sema_paperId": "9a5893e8498bd8996edee6a1f14e340ca95b4c95"
    },
    {
        "@score": "1",
        "@id": "256921",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "205/3769",
                        "text": "Mingming Zha"
                    },
                    {
                        "@pid": "227/2961-1",
                        "text": "Zilong Lin 0001"
                    },
                    {
                        "@pid": "44/10369",
                        "text": "Siyuan Tang"
                    },
                    {
                        "@pid": "129/1113",
                        "text": "Xiaojing Liao"
                    },
                    {
                        "@pid": "167/0416",
                        "text": "Yuhong Nan"
                    },
                    {
                        "@pid": "06/6268",
                        "text": "XiaoFeng Wang 0001"
                    }
                ]
            },
            "title": "Understanding Cross-Platform Referral Traffic for Illicit Drug Promotion.",
            "venue": "CCS",
            "pages": "2132-2146",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Zha0TLN024",
            "doi": "10.1145/3658644.3670383",
            "ee": "https://doi.org/10.1145/3658644.3670383",
            "url": "https://dblp.org/rec/conf/ccs/Zha0TLN024",
            "abstract": "The promotion of illegal drugs has become increasingly prevalent on popular social media platforms such as TikTok, Instagram, and YouTube. Within this ecosystem, miscreants utilize cross-platform referral traffic to advertise and promote illicit drugs. They start by posting illicit drug-promoting comments on upstream social media platforms, attracting potential drug buyers, and then redi-recting these buyers to downstream platforms where the actual drug sales take place. To the best of our knowledge, little has been done so far to understand this cross-platform referral traffic for illicit drug promotion and selling on social media platforms, not to mention any effort to systematically identify such referral traffic on social media platforms. In this paper, we designed an automated pipeline for detecting illicit referral traffic and identified 154,753 drug-referral comments and 3,253 drug sellers. Based upon the dataset, we presented the first systematic study on the ecosystem of such cross-platform illicit drug promotion and selling businesses, which sheds light on the strategies and campaigns of illicit drug promotion. These findings provide valuable insights into the broader impact of illicit drug trading activities and highlight the need for increased attention to addressing the associated security concerns in social media platforms.",
            "keywords": [
                "Illicit Drug Promotion",
                "Social Media Platforms",
                "Cross-Platform Referral Traffic",
                "Automated Detection",
                "Drug Selling Ecosystem"
            ]
        },
        "url": "URL#256921",
        "sema_paperId": "73ed995161cd9c9f2183733e0be6958db87f77c2"
    },
    {
        "@score": "1",
        "@id": "256922",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "306/1688",
                        "text": "Yuxia Zhan"
                    },
                    {
                        "@pid": "43/1032-1",
                        "text": "Yan Meng 0001"
                    },
                    {
                        "@pid": "56/6786",
                        "text": "Lu Zhou"
                    },
                    {
                        "@pid": "301/5880",
                        "text": "Yichang Xiong"
                    },
                    {
                        "@pid": "158/4724",
                        "text": "Xiaokuan Zhang"
                    },
                    {
                        "@pid": "138/5183",
                        "text": "Lichuan Ma"
                    },
                    {
                        "@pid": "05/1884",
                        "text": "Guoxing Chen"
                    },
                    {
                        "@pid": "06/4559",
                        "text": "Qingqi Pei"
                    },
                    {
                        "@pid": "22/5702",
                        "text": "Haojin Zhu"
                    }
                ]
            },
            "title": "VPVet: Vetting Privacy Policies of Virtual Reality Apps.",
            "venue": "CCS",
            "pages": "1746-1760",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Zhan0ZXZMCPZ24",
            "doi": "10.1145/3658644.3690321",
            "ee": "https://doi.org/10.1145/3658644.3690321",
            "url": "https://dblp.org/rec/conf/ccs/Zhan0ZXZMCPZ24",
            "abstract": "Virtual reality (VR) apps can harvest a wider range of user data than web/mobile apps running on personal computers or smartphones. Existing law and privacy regulations emphasize that VR developers should inform users of what data are collected/used/shared (CUS) through privacy policies. However, privacy policies in the VR ecosystem are still in their early stages, and many developers fail to write appropriate privacy policies that comply with regulations and meet user expectations. In this paper, we propose VPVet to automatically vet privacy policy compliance issues for VR apps. VPVet first analyzes the availability and completeness of a VR privacy policy and then refines its analysis based on three key criteria: granularity, minimization, and consistency of CUS statements. Our study establishes the first and currently largest VR privacy policy dataset named VRPP, consisting of privacy policies of 11,923 different VR apps from 10 mainstream platforms. Our vetting results reveal severe privacy issues within the VR ecosystem, including the limited availability and poor quality of privacy policies, along with their coarse granularity, lack of adaptation to VR traits and the inconsistency between CUS statements in privacy policies and their actual behaviors. We open-source VPVet system along with our findings at repository https://github.com/kalamoo/PPAudit, aiming to raise awareness within the VR community and pave the way for further research in this field.",
            "keywords": [
                "Virtual Reality Privacy",
                "Privacy Policy Compliance",
                "User Data Harvesting",
                "Granularity and Consistency",
                "VR Privacy Issues"
            ]
        },
        "url": "URL#256922",
        "sema_paperId": "8e4bb6133646b0aaad3a14e99c24b41f85218614"
    },
    {
        "@score": "1",
        "@id": "256923",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "180/9777",
                        "text": "Jiahe Zhang"
                    },
                    {
                        "@pid": "20/1036-5",
                        "text": "Jianjun Chen 0005"
                    },
                    {
                        "@pid": "19/1924",
                        "text": "Qi Wang"
                    },
                    {
                        "@pid": "239/9956",
                        "text": "Hangyu Zhang"
                    },
                    {
                        "@pid": "210/1379",
                        "text": "Chuhan Wang"
                    },
                    {
                        "@pid": "15/3840",
                        "text": "Jianwei Zhuge"
                    },
                    {
                        "@pid": "36/5143",
                        "text": "Haixin Duan"
                    }
                ]
            },
            "title": "Inbox Invasion: Exploiting MIME Ambiguities to Evade Email Attachment Detectors.",
            "venue": "CCS",
            "pages": "467-481",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Zhang0WZWZD24",
            "doi": "10.1145/3658644.3670386",
            "ee": "https://doi.org/10.1145/3658644.3670386",
            "url": "https://dblp.org/rec/conf/ccs/Zhang0WZWZD24",
            "abstract": "Email attachments have become a favored delivery vector for malware campaigns. In response, email attachment detectors are widely deployed to safeguard email security. However, an emerging threat arises when adversaries exploit parsing discrepancies between email detectors and clients to evade detection. Currently, uncovering these vulnerabilities still depends on manual, ad hoc methods. In this paper, we perform the first systematic evaluation of email attachment detection against parsing ambiguity vulnerabilities. We propose a novel testing methodology, MIMEminer, to systematically discover evasion vulnerabilities in email systems. We evaluated our methodology against 16 content detectors of popular email services like Gmail and iCloud, and 7 popular email clients like Outlook and Thunderbird. In total, we discovered 19 new evasion methods affecting all tested email services and clients. We further analyzed these vulnerabilities and identified three primary categories of malware evasions. We have responsibly reported those identified vulnerabilities to the affected providers to help with the remediation of such vulnerabilities and received acknowledgments from Google Gmail,",
            "keywords": [
                "Email Security",
                "MIME Parsing",
                "Attachment Detection",
                "Evasion Techniques",
                "Malware Delivery"
            ]
        },
        "url": "URL#256923",
        "sema_paperId": "b0ef7103dc23ce45587762f53c048a75e32dd374"
    },
    {
        "@score": "1",
        "@id": "256924",
        "info": {
            "authors": {
                "author": {
                    "@pid": "169/4905",
                    "text": "Jialun Zhang"
                }
            },
            "title": "Language-based Sandboxing.",
            "venue": "CCS",
            "pages": "5122-5124",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Zhang24",
            "doi": "10.1145/3658644.3690866",
            "ee": "https://doi.org/10.1145/3658644.3690866",
            "url": "https://dblp.org/rec/conf/ccs/Zhang24",
            "abstract": "Existing sandboxing techniques require a lot of manual efforts in retrofitting legacy programs and do not provide a unified framework for reasoning about whole-program properties. To address these issues, we propose a language-based approach that makes sandbox a first-class concept in the language. The composability of sandboxes with other language features can enable programmers to do faster compartmentalization and end-to-end reasoning of safety properties.",
            "pdf_url": "",
            "keywords": [
                "Language-based Sandboxing",
                "Compartmentalization",
                "Whole-program Properties",
                "Safety Properties",
                "Legacy Programs"
            ]
        },
        "url": "URL#256924",
        "sema_paperId": "48a18068849dcb10b6e855d3a69cdf333cd85f4c"
    },
    {
        "@score": "1",
        "@id": "256925",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "251/8581",
                        "text": "Jinghuai Zhang"
                    },
                    {
                        "@pid": "231/6028",
                        "text": "Jianfeng Chi"
                    },
                    {
                        "@pid": "10/1143-23",
                        "text": "Zheng Li 0023"
                    },
                    {
                        "@pid": "329/3620",
                        "text": "Kunlin Cai"
                    },
                    {
                        "@pid": "06/6785-16",
                        "text": "Yang Zhang 0016"
                    },
                    {
                        "@pid": "39/5423-1",
                        "text": "Yuan Tian 0001"
                    }
                ]
            },
            "title": "BadMerging: Backdoor Attacks Against Model Merging.",
            "venue": "CCS",
            "pages": "4450-4464",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ZhangCLCZT24",
            "doi": "10.1145/3658644.3690284",
            "ee": "https://doi.org/10.1145/3658644.3690284",
            "url": "https://dblp.org/rec/conf/ccs/ZhangCLCZT24",
            "abstract": "Fine-tuning pre-trained models for downstream tasks has led to a proliferation of open-sourced task-specific models. Recently, Model Merging (MM) has emerged as an effective approach to facilitate knowledge transfer among these independently fine-tuned models. MM directly combines multiple fine-tuned task-specific models into a merged model without additional training, and the resulting model shows enhanced capabilities in multiple tasks. Although MM provides great utility, it may come with security risks because an adversary can exploit MM to affect multiple downstream tasks. However, the security risks of MM have barely been studied. In this paper, we first find that MM, as a new learning paradigm, introduces unique challenges for existing backdoor attacks due to the merging process. To address these challenges, we introduce BadMerging, the first backdoor attack specifically designed for MM. Notably, BadMergingallows an adversary to compromise the entire merged model by contributing as few as one backdoored task-specific model. BadMergingcomprises a two-stage attack mechanism and a novel feature-interpolation-based loss to enhance the robustness of embedded backdoors against the changes of different merging parameters. Considering that a merged model may incorporate tasks from different domains, BadMergingcan jointly compromise the tasks provided by the adversary (on-task attack) and other contributors (off-task attack) and solve the corresponding unique challenges with novel attack designs. Extensive experiments show that BadMergingachieves remarkable attacks against various MM algorithms. Our ablation study demonstrates that the proposed attack designs can progressively contribute to the attack performance. Finally, we show that prior defense mechanisms fail to defend against our attacks, highlighting the need for more advanced defense. Our code is available at: https://github.com/jzhang538/BadMerging.",
            "pdf_url": "",
            "keywords": [
                "Model Merging",
                "Backdoor Attack",
                "Task-Specific Models",
                "Knowledge Transfer",
                "Adversarial Compromise"
            ]
        },
        "url": "URL#256925"
    },
    {
        "@score": "1",
        "@id": "256926",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "18/2908",
                        "text": "Cong Zhang"
                    },
                    {
                        "@pid": "87/1254-3",
                        "text": "Yu Chen 0003"
                    },
                    {
                        "@pid": "71/10355",
                        "text": "Weiran Liu"
                    },
                    {
                        "@pid": "144/6285",
                        "text": "Liqiang Peng"
                    },
                    {
                        "@pid": "184/7209",
                        "text": "Meng Hao"
                    },
                    {
                        "@pid": "116/4536",
                        "text": "Anyu Wang 0001"
                    },
                    {
                        "@pid": "w/XiaoyunWang",
                        "text": "Xiaoyun Wang 0001"
                    }
                ]
            },
            "title": "Unbalanced Private Set Union with Reduced Computation and Communication.",
            "venue": "CCS",
            "pages": "1434-1447",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ZhangCLPHWW24",
            "doi": "10.1145/3658644.3690308",
            "ee": "https://doi.org/10.1145/3658644.3690308",
            "url": "https://dblp.org/rec/conf/ccs/ZhangCLPHWW24",
            "abstract": "Private set union (PSU) is a cryptographic protocol that allows two parties to compute the union of their sets without revealing anything else. Despite some efficient PSU protocols that have been proposed, they mainly focus on the balanced setting, where the sets held by the parties are of similar size. Recently, Tu et al. (CCS 2023) proposed the first unbalanced PSU protocol which achieves sublinear communication complexity in the size of the larger set.",
            "pdf_url": "",
            "keywords": [
                "Private Set Union",
                "Cryptographic Protocols",
                "Unbalanced Setting",
                "Communication Complexity",
                "Sublinear Complexity"
            ]
        },
        "url": "URL#256926"
    },
    {
        "@score": "1",
        "@id": "256927",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "227/6698",
                        "text": "Dongjia Zhang"
                    },
                    {
                        "@pid": "252/5052",
                        "text": "Andrea Fioraldi"
                    },
                    {
                        "@pid": "56/490",
                        "text": "Davide Balzarotti"
                    }
                ]
            },
            "title": "On Understanding and Forecasting Fuzzers Performance with Static Analysis.",
            "venue": "CCS",
            "pages": "3973-3987",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ZhangFB24",
            "doi": "10.1145/3658644.3670348",
            "ee": "https://doi.org/10.1145/3658644.3670348",
            "url": "https://dblp.org/rec/conf/ccs/ZhangFB24",
            "abstract": "Fuzz testing, a technique for detecting critical software vulnerabilities, combines various methodologies from previous research to improve its effectiveness. For fuzzing practitioners, it is imperative to comprehend the effects of distinct techniques and select the ideal configuration customized to the program they need to test. However, evaluating the individual contributions of these techniques is often very difficult. Prior research compared assembled fuzzers and studied their affinity with different programs. Nevertheless, assembled fuzzers cannot be easily broken down into independent components, and therefore, the evaluation does not clarify which technique explains the performance of the fuzzer. Without understanding the potential impact of integrating different fuzzing techniques, it becomes even more challenging to adjust the fuzzer configuration for different programs under test. Our research tackles this challenge by introducing a novel approach that correlates static analysis features extracted at compile time with the performance results of various fuzzing techniques. Our method uses diverse metrics to uncover the relationship be-tween the static attributes of a program and the dynamic runtime performance of fuzzers. The correlation analysis performed on 23 target applications reveals interesting relationships, such as power schedulers performing better with larger programs and context-sensitive feedback struggling with a large number of inputs. This approach not only enhances our analytical understanding of fuzzing techniques, but also enables predictive capabilities. We show how a simple machine learning model can propose a fuzzer configuration customized for a particular program using information collected through static analysis. In 11 of our benchmark programs, fuzzers using the suggested configuration achieved the best improvement over the baseline compared to AFLplusplus, LibFuzzer and Honggfuzz.",
            "keywords": [
                "Fuzz Testing",
                "Static Analysis",
                "Fuzzer Performance",
                "Configuration Optimization",
                "Correlation Analysis"
            ]
        },
        "url": "URL#256927",
        "sema_paperId": "a69e3611e3f31a1c0d7cd32d85d6da7f451a10eb"
    },
    {
        "@score": "1",
        "@id": "256928",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "72/8471",
                        "text": "Zidong Zhang"
                    },
                    {
                        "@pid": "276/0713",
                        "text": "Qinsheng Hou"
                    },
                    {
                        "@pid": "18/7667",
                        "text": "Lingyun Ying"
                    },
                    {
                        "@pid": "149/2350",
                        "text": "Wenrui Diao"
                    },
                    {
                        "@pid": "180/8186",
                        "text": "Yacong Gu"
                    },
                    {
                        "@pid": "96/4282",
                        "text": "Rui Li"
                    },
                    {
                        "@pid": "47/401",
                        "text": "Shanqing Guo"
                    },
                    {
                        "@pid": "36/5143",
                        "text": "Haixin Duan"
                    }
                ]
            },
            "title": "MiniCAT: Understanding and Detecting Cross-Page Request Forgery Vulnerabilities in Mini-Programs.",
            "venue": "CCS",
            "pages": "525-539",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ZhangHYDGLGD24",
            "doi": "10.1145/3658644.3670294",
            "ee": "https://doi.org/10.1145/3658644.3670294",
            "url": "https://dblp.org/rec/conf/ccs/ZhangHYDGLGD24",
            "abstract": "Mini-programs are lightweight apps running in super apps (such as WeChat, Baidu, Alipay, and TikTok), an emerging paradigm in the era of mobile computing. With the growing popularity of mini-programs, there is an increasing concern for their security and privacy. In essence, mini-programs are WebView-based apps. This means that they may be vulnerable to the same security risks associated with web apps. In this work, we discovered a new mini-program vulnerability called MiniCPRF (Cross-Page Request Forgery in Mini-Programs). The exploit of this vulnerability is easy, and the attack consequences are severe, leading to unauthorized operations, such as free shopping, and the exposure of confidential information, such as credit card numbers. The root causes of MiniCPRF can be attributed to multiple design flaws in both mini-programs and their super apps, including the insecure routing mechanism, lack of message integrity check, and plain-text storage. To evaluate the impacts of MiniCPRF, we designed an automated analysis framework called MiniCAT. It can automatically crawl mini-programs, perform static analysis on them",
            "keywords": [
                "Mini-Program Security",
                "Cross-Page Request Forgery",
                "Vulnerability Detection",
                "Automated Analysis Framework",
                "MiniCPRF"
            ]
        },
        "url": "URL#256928",
        "sema_paperId": "43d6b0997ab6312def9b7267b4e68d65d40406ed"
    },
    {
        "@score": "1",
        "@id": "256929",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "231/7517",
                        "text": "Tianfang Zhang"
                    },
                    {
                        "@pid": "353/2243",
                        "text": "Qiufan Ji"
                    },
                    {
                        "@pid": "322/6627",
                        "text": "Zhengkun Ye"
                    },
                    {
                        "@pid": "358/2744",
                        "text": "Md Mojibur Rahman Redoy Akanda"
                    },
                    {
                        "@pid": "301/9694",
                        "text": "Ahmed Tanvir Mahdad"
                    },
                    {
                        "@pid": "07/6946-4",
                        "text": "Cong Shi 0004"
                    },
                    {
                        "@pid": "59/2227-3",
                        "text": "Yan Wang 0003"
                    },
                    {
                        "@pid": "25/1169",
                        "text": "Nitesh Saxena"
                    },
                    {
                        "@pid": "18/2343-1",
                        "text": "Yingying Chen 0001"
                    }
                ]
            },
            "title": "SAFARI: Speech-Associated Facial Authentication for AR/VR Settings via Robust VIbration Signatures.",
            "venue": "CCS",
            "pages": "153-167",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ZhangJYAM00S024",
            "doi": "10.1145/3658644.3670358",
            "ee": "https://doi.org/10.1145/3658644.3670358",
            "url": "https://dblp.org/rec/conf/ccs/ZhangJYAM00S024",
            "abstract": "In AR/VR devices, the voice interface, serving as one of the primary AR/VR control mechanisms, enables users to interact naturally using speeches (voice commands) for accessing data, controlling applications, and engaging in remote communication/meetings. Voice authentication can be adopted to protect against unauthorized speech inputs. However, existing voice authentication mechanisms are usually susceptible to voice spoofing attacks and are unreliable under the variations of phonetic content. In this work, we propose SAFARI, a spoofing-resistant and text-independent speech authentication system that can be seamlessly integrated into AR/VR voice interfaces. The key idea is to elicit phonetic-invariant biometrics from the facial muscle vibrations upon the headset. During speech production, a user\u2019s facial muscles are de-formed for articulating phoneme sounds. The facial deformations associated with the phonemes are referred to as visemes. They carry rich biometrics of the wearer\u2019s muscles, tissue, and bones, which can propagate through the head and vibrate the headset. SAFARI aims to derive reliable facial biometrics from the viseme-associated facial vibrations captured by the AR/VR motion sensors. Particularly, it identifies the vibration data segments that contain rich viseme patterns (prominent visemes) less susceptible to phonetic variations. Based on the prominent visemes, SAFARI learns on the correlations among facial vibrations of different frequencies to extract biometric representations invariant to the phonetic context. The key advantages of",
            "keywords": [
                "AR/VR Interfaces",
                "Voice Authentication",
                "Facial Biometrics",
                "Spoofing Resistance",
                "Viseme Patterns"
            ]
        },
        "url": "URL#256929",
        "sema_paperId": "d49774f09f99327a3a23961bc80cf15493b75d31"
    },
    {
        "@score": "1",
        "@id": "256930",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "227/5659",
                        "text": "Yuexi Zhang"
                    },
                    {
                        "@pid": "49/1389",
                        "text": "Bingyu Li"
                    },
                    {
                        "@pid": "57/4208",
                        "text": "Jingqiang Lin"
                    },
                    {
                        "@pid": "19/10136",
                        "text": "Linghui Li"
                    },
                    {
                        "@pid": "392/3198",
                        "text": "Jiaju Bai"
                    },
                    {
                        "@pid": "51/10138-1",
                        "text": "Shijie Jia 0001"
                    },
                    {
                        "@pid": "54/7015",
                        "text": "Qianhong Wu"
                    }
                ]
            },
            "title": "Gopher: High-Precision and Deep-Dive Detection of Cryptographic API Misuse in the Go Ecosystem.",
            "venue": "CCS",
            "pages": "2978-2992",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ZhangLLLB0W24",
            "doi": "10.1145/3658644.3690276",
            "ee": "https://doi.org/10.1145/3658644.3690276",
            "url": "https://dblp.org/rec/conf/ccs/ZhangLLLB0W24",
            "abstract": "The complexity of cryptographic APIs and developers' expertise gaps often leads to their improper use, seriously threatening information security. Existing cryptographic API misuse detection tools that rely on black/white-list methods require experts to manually establish detection rules. They struggle to dynamically update rules and scale to cover numerous unofficial cryptographic libraries. Furthermore, as these tools are primarily aimed at non-Go languages, they have limited applicability and accuracy in the Go ecosystem, which is extensively used for security-centric applications. To mitigate these challenges, we presentGopher,a novel cryptographic misuse detection framework, that excels in encapsulated API and cross-library detection. In this framework, we have designedCryDictto convert rules into unified and standardized constraints, capable of deriving new usage rules and elucidating implicit knowledge during scanning.GopherleveragesCryDictto create a logical separation between rule formulation andDetectordetection, enabling dynamic updating of constraints and enhancing detection capabilities. This significantly improves theGopher's compatibility and scalability. UtilizingGopher,we have conducted an extensive analysis of the Go ecosystem, examining 19,313 Go projects. In our rigorous testing,Gopherdemonstrated a remarkable 98.9% accuracy rate and identified 64.1% of previously undetected misuses. This scrutiny has surfaced numerous hidden security vulnerabilities, and highlighted misuse tendencies across diverse project categories.",
            "pdf_url": "",
            "keywords": [
                "Cryptographic API Misuse",
                "Go Ecosystem",
                "Detection Framework",
                "Rule Formulation",
                "Security Vulnerabilities"
            ]
        },
        "url": "URL#256930",
        "sema_paperId": "c1571428f9314ebd11e825e08833b064edc67355"
    },
    {
        "@score": "1",
        "@id": "256931",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "214/9494",
                        "text": "Zhenda Zhang"
                    },
                    {
                        "@pid": "24/3255",
                        "text": "Svetla Petkova-Nikova"
                    },
                    {
                        "@pid": "84/5358",
                        "text": "Ventzislav Nikov"
                    }
                ]
            },
            "title": "Glitch-Stopping Circuits: Hardware Secure Masking without Registers.",
            "venue": "CCS",
            "pages": "3406-3420",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ZhangPN24",
            "doi": "10.1145/3658644.3670335",
            "ee": "https://doi.org/10.1145/3658644.3670335",
            "url": "https://dblp.org/rec/conf/ccs/ZhangPN24",
            "abstract": "Masking is one of the most popular countermeasures to protect implementations against power and electromagnetic side-channel attacks because it offers provable security. Masking has been shown secure against d-threshold probing adversaries by Ishai et al. at CRYPTO'03, but this adversary's model doesn't consider any physical hardware defaults and thus such masking schemes were shown to be still vulnerable when implemented as hardware circuits. To address these limitations glitch-extended probing adversaries and correspondingly glitch-immune masking schemes have been introduced. This paper introduces glitch-stopping circuits, which coincide with circuits protected via glitch-immune masking when instantiated with registers. Then we show that one can instantiate glitch-stopping circuits without registers by using clocked logic gates or latches. This is illustrated for both ASIC and FPGA, offering a promising alternative to conventional register-based masked implementations. Compared to the traditional register-based approach, these register-free solutions can reduce the latency to a single cycle and achieve a lower area cost. We prove and experimentally confirm that the proposed solution is as secure as the register-based one. In summary, this paper proposes a novel method to address the latency of register-based hardware masking without jeopardizing their security. This method not only reduces the latency down to one clock cycle but also improves the area costs of the implementations.",
            "pdf_url": "",
            "keywords": [
                "Hardware Security",
                "Side-Channel Attacks",
                "Masking Techniques",
                "Glitch-Immune Circuits",
                "Register-Free Implementations"
            ]
        },
        "url": "URL#256931"
    },
    {
        "@score": "1",
        "@id": "256932",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "15/4228",
                        "text": "Xiangyang Zhang"
                    },
                    {
                        "@pid": "220/2593",
                        "text": "Yaobin Shen"
                    },
                    {
                        "@pid": "w/LeiWang31",
                        "text": "Lei Wang 0031"
                    }
                ]
            },
            "title": "Multi-User Security of CCM Authenticated Encryption Mode.",
            "venue": "CCS",
            "pages": "4331-4345",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ZhangSW24",
            "doi": "10.1145/3658644.3670385",
            "ee": "https://doi.org/10.1145/3658644.3670385",
            "url": "https://dblp.org/rec/conf/ccs/ZhangSW24",
            "abstract": "The CCM authenticated encryption mode has gained widespread usage and standardization. Notably, in conjunction with GCM and ChaCha20-Poly1305, CCM is recommended to be used in TLS 1.3 that underlies in https. Since TLS 1.3 is currently utilized by a large number of users, it is imperative to assess the security of these schemes in the multi-user model. Concrete multi-user security analysis for GCM and ChaCha20-Poly1305 have been scrutinized in literature. However, the formal multi-user security analysis for CCM falls behind that for GCM and ChaCha20-Poly1305. Furthermore, in the associated IETF document, the multi-user security bound for CCM is derived by naive generic reduction and falls considerably short of our expectations. In this paper, we bridge the gap by establishing a concrete multi-user security bound for CCM. Our new bound surpasses that derived from generic reduction and it indicates that CCM maintains birthday-bound security in the multi-user model as in the single-user model.",
            "pdf_url": "",
            "keywords": [
                "Authenticated Encryption",
                "CCM Mode",
                "Multi-User Security",
                "Security Bound",
                "Birthday-Bound Security"
            ]
        },
        "url": "URL#256932",
        "sema_paperId": "c09d79a54dbf7228e0545de044c576f91c56d6a2"
    },
    {
        "@score": "1",
        "@id": "256933",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "353/0783",
                        "text": "Elisa Zhang"
                    },
                    {
                        "@pid": "244/4445",
                        "text": "Shiyu Sun"
                    },
                    {
                        "@pid": "300/5803",
                        "text": "Yunlong Xing"
                    },
                    {
                        "@pid": "30/3530-1",
                        "text": "Kun Sun 0001"
                    }
                ]
            },
            "title": "Poster: Repairing Bugs with the Introduction of New Variables: A Multi-Agent Large Language Model.",
            "venue": "CCS",
            "pages": "4961-4963",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ZhangSX024",
            "doi": "10.1145/3658644.3691412",
            "ee": "https://doi.org/10.1145/3658644.3691412",
            "url": "https://dblp.org/rec/conf/ccs/ZhangSX024",
            "abstract": "Trained on billions of tokens, large language models (LLMs) have a broad range of empirical knowledge which enables them to generate software patches with complex repair patterns. We leverage the powerful code-fixing capabilities of LLMs and propose VarPatch, a multi-agent conversational automated program repair (APR) technique that iteratively queries the LLM to generate software patches by providing various prompts and context information. VarPatch focuses on the variable addition repair pattern, as previous APR tools struggle to introduce and use new variables to fix buggy code. Additionally, we summarize commonly used APIs and identify four repair patterns involving new variable addition. Our evaluation on the Defects4J 1.2 dataset shows that VarPatch can repair 69% more bugs than baseline tools and over 8 times more bugs than GPT-4.",
            "pdf_url": "",
            "keywords": [
                "Automated Program Repair",
                "Large Language Models",
                "Variable Addition",
                "Software Patching",
                "Defects4J Dataset"
            ]
        },
        "url": "URL#256933",
        "sema_paperId": "a34f073bda8dee2c3a7aa8ae6ba87da4d3346c5f"
    },
    {
        "@score": "1",
        "@id": "256934",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "177/7467",
                        "text": "Qiankun Zhang"
                    },
                    {
                        "@pid": "09/5856",
                        "text": "Di Yuan"
                    },
                    {
                        "@pid": "10/10956",
                        "text": "Boyu Zhang"
                    },
                    {
                        "@pid": "64/1812",
                        "text": "Bin Yuan"
                    },
                    {
                        "@pid": "245/3556",
                        "text": "Bingqian Du"
                    }
                ]
            },
            "title": "Membership Inference Attacks against Vision Transformers: Mosaic MixUp Training to the Defense.",
            "venue": "CCS",
            "pages": "1256-1270",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ZhangYZYD24",
            "doi": "10.1145/3658644.3690268",
            "ee": "https://doi.org/10.1145/3658644.3690268",
            "url": "https://dblp.org/rec/conf/ccs/ZhangYZYD24",
            "abstract": "Vision transformers (ViTs) have demonstrated great success in various fundamental CV tasks, mainly benefiting from their self-attention-based transformer architectures, and the paradigm of pre-training followed by fine-tuning. However, such advantages may lead to significant data privacy risks, such as membership inference attacks (MIAs), which remain unclear. This paper presents the first comprehensive study on MIAs and corresponding defenses against ViTs. Our first contribution is a rollout-attention-based MIA method (RAMIA), based on an experimental observation that the attention, more precisely the rollout attention, behaves disproportionately for members and non-members. We evaluate RAMIA on the standard ViT architecture proposed by Google (ICLR 2021), achieving high accuracy, precision, and recall performance. Further, inspired by another experimental observation on a strong connection between positional embeddings (PEs) and attentions, we propose a novel framework for training ViTs, named Mosaic MixUp Training (MMUT), as a defense against RAMIA. Intuitively, MMUT mixes up private images and public ones at a patch level, and mosaics the corresponding PEs with a global learnable mosaic embedding. Our empirical results show MMUT achieves a much better accuracy-privacy trade-off than some common defense mechanisms. Extensive experiments are conducted to rigorously evaluate both RAMIA and MMUT.",
            "pdf_url": "",
            "keywords": [
                "Vision Transformers",
                "Membership Inference Attacks",
                "Data Privacy",
                "Mosaic MixUp Training",
                "Rollout Attention"
            ]
        },
        "url": "URL#256934",
        "sema_paperId": "f99f72e4998cd932db27f0ad7df4f5a1444e1bde"
    },
    {
        "@score": "1",
        "@id": "256935",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "332/2906",
                        "text": "Chuqi Zhang"
                    },
                    {
                        "@pid": "04/1346",
                        "text": "Jun Zeng"
                    },
                    {
                        "@pid": "76/5416",
                        "text": "Yiming Zhang"
                    },
                    {
                        "@pid": "205/3202",
                        "text": "Adil Ahmad"
                    },
                    {
                        "@pid": "20/11242",
                        "text": "Fengwei Zhang"
                    },
                    {
                        "@pid": "98/4156",
                        "text": "Hai Jin 0001"
                    },
                    {
                        "@pid": "99/4951",
                        "text": "Zhenkai Liang"
                    }
                ]
            },
            "title": "The HitchHiker&apos;s Guide to High-Assurance System Observability Protection with Efficient Permission Switches.",
            "venue": "CCS",
            "pages": "3898-3912",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ZhangZZAZ0L24",
            "doi": "10.1145/3658644.3690188",
            "ee": "https://doi.org/10.1145/3658644.3690188",
            "url": "https://dblp.org/rec/conf/ccs/ZhangZZAZ0L24",
            "abstract": "Protecting system observability records (logs) from compromised OSs has gained significant traction in recent times, with several note-worthy approaches proposed. Unfortunately, none of the proposed approaches achieve high performance with tiny log protection delays. They also leverage risky environments for protection (e.g., many use general-purpose hypervisors or TrustZone, which have large TCB and attack surfaces). HitchHiker is an attempt to rectify this problem. The system is designed to ensure (a) in-memory protection of batched logs within a short and configurable real-time deadline by efficient hardware permission switching, and (b) an end-to-end high-assurance environment built upon hardware protection primitives with debloating strategies for secure log protection, persistence, and management. Security evaluations and validations show that HitchHiker reduces log protection delay by 93.3--99.3% compared to the state-of-the-art, while reducing TCB by 9.4--26.9X. Performance evaluations show HitchHiker incurs a geometric mean of less than 6% overhead on diverse real-world programs, improving on the state-of-the-art approach by 61.9--77.5%.",
            "pdf_url": "",
            "keywords": [
                "System Observability",
                "Log Protection",
                "Hardware Permission Switching",
                "High-Assurance Environment",
                "Trusted Computing Base (TCB)"
            ]
        },
        "url": "URL#256935"
    },
    {
        "@score": "1",
        "@id": "256936",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "386/7683",
                        "text": "Bokang Zhang"
                    },
                    {
                        "@pid": "286/3197",
                        "text": "Yanglin Zhang"
                    },
                    {
                        "@pid": "90/545-1",
                        "text": "Zhikun Zhang 0001"
                    },
                    {
                        "@pid": "244/6287",
                        "text": "Jinglan Yang"
                    },
                    {
                        "@pid": "238/1248",
                        "text": "Lingying Huang"
                    },
                    {
                        "@pid": "06/5271-1",
                        "text": "Junfeng Wu 0001"
                    }
                ]
            },
            "title": "S2NeRF: Privacy-preserving Training Framework for NeRF.",
            "venue": "CCS",
            "pages": "258-272",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ZhangZZYH024",
            "doi": "10.1145/3658644.3690185",
            "ee": "https://doi.org/10.1145/3658644.3690185",
            "url": "https://dblp.org/rec/conf/ccs/ZhangZZYH024",
            "abstract": "Neural Radiance Fields (NeRF) have revolutionized 3D computer vision and graphics, facilitating novel view synthesis and influencing sectors like extended reality and e-commerce. However, NeRF's dependence on extensive data collection, including sensitive scene image data, introduces significant privacy risks when users upload this data for model training. To address this concern, we first propose SplitNeRF, a training framework that incorporates split learning (SL) techniques to enable privacy-preserving collaborative model training between clients and servers without sharing local data. Despite its benefits, we identify vulnerabilities in SplitNeRF by developing two attack methods, Surrogate Model Attack and Scene-aided Surrogate Model Attack, which exploit the shared gradient data and a few leaked scene images to reconstruct private scene information. To counter these threats, we introduce $S^2$NeRF, secure SplitNeRF that integrates effective defense mechanisms. By introducing decaying noise related to the gradient norm into the shared gradient information, $S^2$NeRF preserves privacy while maintaining a high utility of the NeRF model. Our extensive evaluations across multiple datasets demonstrate the effectiveness of $S^2$NeRF against privacy breaches, confirming its viability for secure NeRF training in sensitive applications.",
            "keywords": [
                "Neural Radiance Fields",
                "Privacy-Preserving Training",
                "Split Learning",
                "Gradient Privacy",
                "Secure Model Training"
            ]
        },
        "url": "URL#256936",
        "sema_paperId": "0ce273faa81649cd632922ac8326c301e7c0d20a"
    },
    {
        "@score": "1",
        "@id": "256937",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "323/7849",
                        "text": "Xiyuan Zhao"
                    },
                    {
                        "@pid": "247/1165",
                        "text": "Xinhao Deng"
                    },
                    {
                        "@pid": "181/2688-2",
                        "text": "Qi Li 0002"
                    },
                    {
                        "@pid": "02/8137",
                        "text": "Yunpeng Liu"
                    },
                    {
                        "@pid": "69/11514",
                        "text": "Zhuotao Liu"
                    },
                    {
                        "@pid": "30/3530-1",
                        "text": "Kun Sun 0001"
                    },
                    {
                        "@pid": "181/2626-2",
                        "text": "Ke Xu 0002"
                    }
                ]
            },
            "title": "Towards Fine-Grained Webpage Fingerprinting at Scale.",
            "venue": "CCS",
            "pages": "423-436",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ZhaoD0LL0024",
            "doi": "10.1145/3658644.3690211",
            "ee": "https://doi.org/10.1145/3658644.3690211",
            "url": "https://dblp.org/rec/conf/ccs/ZhaoD0LL0024",
            "abstract": "Website Fingerprinting (WF) attacks can effectively identify the websites visited by Tor clients via analyzing encrypted traffic patterns. Existing attacks focus on identifying different websites, but their accuracy dramatically decreases when applied to identify fine-grained webpages, especially when distinguishing among different subpages of the same website. WebPage Fingerprinting (WPF) attacks face the challenges of highly similar traffic patterns and a much larger scale of webpages. Furthermore, clients often visit multiple webpages concurrently, increasing the difficulty of extracting the traffic patterns of each webpage from the obfuscated traffic. In this paper, we propose Oscar, a WPF attack based on multi-label metric learning that identifies different webpages from obfuscated traffic by transforming the feature space. Oscar can extract the subtle differences among various webpages, even those with similar traffic patterns. In particular, Oscar combines proxy-based and sample-based metric learning losses to extract webpage features from obfuscated traffic and identify multiple webpages. We prototype Oscar and evaluate its performance using traffic collected from 1,000 monitored webpages and over 9,000 unmonitored webpages in the real world. Oscar demonstrates an 88.6% improvement in the multi-label metric Recall@5 compared to the state-of-the-art attacks.",
            "pdf_url": "",
            "keywords": [
                "Webpage Fingerprinting",
                "Traffic Analysis",
                "Obfuscated Traffic",
                "Multi-label Metric Learning",
                "Fine-Grained Webpage Identification"
            ]
        },
        "url": "URL#256937"
    },
    {
        "@score": "1",
        "@id": "256938",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "392/3201",
                        "text": "Faqi Zhao"
                    },
                    {
                        "@pid": "14/1555",
                        "text": "Duohe Ma"
                    },
                    {
                        "@pid": "11/444",
                        "text": "Wenhao Li"
                    },
                    {
                        "@pid": "77/1318-1",
                        "text": "Feng Liu 0001"
                    },
                    {
                        "@pid": "29/4680-8",
                        "text": "Wen Wang 0008"
                    }
                ]
            },
            "title": "Poster: Enhancing Network Traffic Analysis with Pre-trained Side-channel Feature Imputation.",
            "venue": "CCS",
            "pages": "5033-5035",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ZhaoML0W24",
            "doi": "10.1145/3658644.3691401",
            "ee": "https://doi.org/10.1145/3658644.3691401",
            "url": "https://dblp.org/rec/conf/ccs/ZhaoML0W24",
            "abstract": "The recent advances in learning-based methodologies has underscored their efficacy in deducing patterns from the side-channel features of encrypted network traffic. Nonetheless, the distribution of these features has been identified as susceptible, particularly in the expansive and intricate network topologies characteristic of the modern Internet. The unpredictability of traffic bursts can result in packet loss during retransmission, thereby generating fragmented feature patterns. Unfortunately, current approaches struggle to adapt to such fragmented features, often leading to a substantial decline in performance. To surmount this challenge, this paper introduces a pre-training-based augmentation framework, denoted as N\u00fcwa, which imputes the side-channel features of encrypted network traffic. The crux of N\u00fcwa lies in its ability to reconstruct the side-channel features, with a particular focus on the temporal attributes of the missing packets within a traffic session. N\u00fcwa is comprised of a word-level Sequence2Embedding module, a Traffic Noise-based Self-supervised Pre-trained Masking Strategy, and a Traffic Side-Channel Feature Imputation Module. Experiments across four diverse real-world scenarios substantiate N\u00fcwa's capacity to restore the performance of prevalent temporal models while maintaining the integrity of the imputed features.",
            "pdf_url": "",
            "keywords": [
                "Network Traffic Analysis",
                "Side-channel Features",
                "Feature Imputation",
                "Temporal Attributes",
                "Traffic Fragmentation"
            ]
        },
        "url": "URL#256938",
        "sema_paperId": "7dd13109f10ab6dec5964f8b2b3782d5393f3ded"
    },
    {
        "@score": "1",
        "@id": "256939",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "281/9219",
                        "text": "Qiyuan Zhao"
                    },
                    {
                        "@pid": "211/4403",
                        "text": "George P\u00eerlea"
                    },
                    {
                        "@pid": "392/3407",
                        "text": "Karolina Grzeszkiewicz"
                    },
                    {
                        "@pid": "84/3601",
                        "text": "Seth Gilbert"
                    },
                    {
                        "@pid": "77/9770",
                        "text": "Ilya Sergey"
                    }
                ]
            },
            "title": "Compositional Verification of Composite Byzantine Protocols.",
            "venue": "CCS",
            "pages": "34-48",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ZhaoPGGS24",
            "doi": "10.1145/3658644.3690355",
            "ee": "https://doi.org/10.1145/3658644.3690355",
            "url": "https://dblp.org/rec/conf/ccs/ZhaoPGGS24",
            "abstract": "Byzantine Fault-Tolerant (BFT) protocols are known to be difficult to design and to reason about. To address this challenge, on one hand, several approaches have been developed recently for computer-aided formal verification of the desired correctness properties, both safety and liveness, of standalone BFT protocols. On the other hand, the distributed computing community has made attempts to reduce the conceptual complexity of constructing new such protocols by showing how to assemble them from simpler \u201cbuilding blocks\u201d. No methodology to date combines these two approaches for foundational verification of arbitrary BFT protocols. We present Bythos, the first foundational framework for compositional mechanised verification of both safety and liveness of composite BFT protocols. Bythos is implemented on top of the Coq proof assistant and uses Coq\u2019s higher-order logic to reuse proofs of common facts about knowledge and trust in BFT protocols. It allows for compact liveness specifications in the style of TLA+, and for their proofs using an embedding of TLA into Coq. Most importantly, Bythos provides a family of higher-order definitions that allow building composite BFT protocols from simpler ones, with their correctness proofs derived. We showcase Bythos by verifying in it safety and liveness properties of three basic BFT protocols: Reliable Broadcast, Provable Broadcast, and the recently proposed Accountable Byzantine Confirmer, as well as their compositions.",
            "keywords": [
                "Byzantine Fault Tolerance",
                "Formal Verification",
                "Compositional Verification",
                "Safety and Liveness",
                "Composite BFT Protocols"
            ]
        },
        "url": "URL#256939",
        "sema_paperId": "869f19567399ae38ebad0ea13f42071a2708d943"
    },
    {
        "@score": "1",
        "@id": "256940",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "209/0123",
                        "text": "Yingquan Zhao"
                    },
                    {
                        "@pid": "71/7089",
                        "text": "Zan Wang"
                    },
                    {
                        "@pid": "04/4498-3",
                        "text": "Junjie Chen 0003"
                    },
                    {
                        "@pid": "351/7091",
                        "text": "Ruifeng Fu"
                    },
                    {
                        "@pid": "392/3160",
                        "text": "Yanzhou Lu"
                    },
                    {
                        "@pid": "292/1669",
                        "text": "Tianchang Gao"
                    },
                    {
                        "@pid": "274/0611",
                        "text": "Haojie Ye"
                    }
                ]
            },
            "title": "Program Ingredients Abstraction and Instantiation for Synthesis-based JVM Testing.",
            "venue": "CCS",
            "pages": "3943-3957",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ZhaoW0FLGY24",
            "doi": "10.1145/3658644.3690366",
            "ee": "https://doi.org/10.1145/3658644.3690366",
            "url": "https://dblp.org/rec/conf/ccs/ZhaoW0FLGY24",
            "abstract": "Java Virtual Machine (JVM) holds a crucial position in executing various Java programs, thereby necessitating rigorous testing to ensure software reliability and security. Regarding existing JVM testing techniques, synthesis-based techniques have proven to be state-of-the-art, which construct a test program by synthesizing various program ingredients extracted from historical bug-revealing test programs into a seed program. However, existing synthesis-based techniques directly use the program ingredients specific to historical bugs, which limits the test scope without the ability of covering more JVM features and negatively affects the diversity of synthesized test programs.",
            "pdf_url": "",
            "keywords": [
                "Java Virtual Machine Testing",
                "Synthesis-based Techniques",
                "Program Ingredients",
                "Test Program Diversity",
                "Bug-revealing Test Programs"
            ]
        },
        "url": "URL#256940",
        "sema_paperId": "66efcfac51dfcc76005b3dbdb44e5b9304ced641"
    },
    {
        "@score": "1",
        "@id": "256941",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "277/1357",
                        "text": "Yihao Zheng"
                    },
                    {
                        "@pid": "349/2976",
                        "text": "Haocheng Xia"
                    },
                    {
                        "@pid": "374/6863",
                        "text": "Junyuan Pang"
                    },
                    {
                        "@pid": "89/9935",
                        "text": "Jinfei Liu"
                    },
                    {
                        "@pid": "20/6179-1",
                        "text": "Kui Ren 0001"
                    },
                    {
                        "@pid": "21/10575",
                        "text": "Lingyang Chu"
                    },
                    {
                        "@pid": "25/7045-11",
                        "text": "Yang Cao 0011"
                    },
                    {
                        "@pid": "39/3530-1",
                        "text": "Li Xiong 0001"
                    }
                ]
            },
            "title": "TabularMark: Watermarking Tabular Datasets for Machine Learning.",
            "venue": "CCS",
            "pages": "3570-3584",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ZhengXPL0C0024",
            "doi": "10.1145/3658644.3690373",
            "ee": "https://doi.org/10.1145/3658644.3690373",
            "url": "https://dblp.org/rec/conf/ccs/ZhengXPL0C0024",
            "abstract": "Watermarking is broadly utilized to protect ownership of shared data while preserving data utility. However, existing watermarking methods for tabular datasets fall short on the desired properties (detectability, non-intrusiveness, and robustness) and only preserve data utility from the perspective of data statistics, ignoring the performance of downstream ML models trained on the datasets. Can we watermark tabular datasets without significantly compromising their utility for training ML models while preventing attackers from training usable ML models on attacked datasets?",
            "pdf_url": "",
            "keywords": [
                "Tabular Data Watermarking",
                "Data Utility Preservation",
                "Machine Learning Model Robustness",
                "Watermark Detectability",
                "Non-Intrusive Watermarking"
            ]
        },
        "url": "URL#256941"
    },
    {
        "@score": "1",
        "@id": "256942",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "323/8662",
                        "text": "Peizhao Zhou"
                    },
                    {
                        "@pid": "43/8066-4",
                        "text": "Xiaojie Guo 0004"
                    },
                    {
                        "@pid": "386/7954",
                        "text": "Pinzhi Chen"
                    },
                    {
                        "@pid": "29/3826-11",
                        "text": "Tong Li 0011"
                    },
                    {
                        "@pid": "216/6271",
                        "text": "Siyi Lv"
                    },
                    {
                        "@pid": "22/8078",
                        "text": "Zheli Liu"
                    }
                ]
            },
            "title": "Shortcut: Making MPC-based Collaborative Analytics Efficient on Dynamic Databases.",
            "venue": "CCS",
            "pages": "854-868",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/Zhou0C0LL24",
            "doi": "10.1145/3658644.3690314",
            "ee": "https://doi.org/10.1145/3658644.3690314",
            "url": "https://dblp.org/rec/conf/ccs/Zhou0C0LL24",
            "abstract": "Secure Multi-party Computation (MPC) provides a promising solution for privacy-preserving multi-source data analytics. However, existing MPC-based collaborative analytics systems (MCASs) have unsatisfying performance for scenarios with dynamic databases. Naively running an MCAS on a dynamic database would lead to significant redundant costs and raise performance concerns, due to the substantial duplicate contents between the pre-updating and post-updating databases.",
            "pdf_url": "",
            "keywords": [
                "Secure Multi-party Computation",
                "Collaborative Analytics",
                "Dynamic Databases",
                "Performance Optimization",
                "Redundant Costs"
            ]
        },
        "url": "URL#256942"
    },
    {
        "@score": "1",
        "@id": "256943",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "306/1011",
                        "text": "Xin&apos;an Zhou"
                    },
                    {
                        "@pid": "119/5192",
                        "text": "Qing Deng"
                    },
                    {
                        "@pid": "385/8658",
                        "text": "Juefei Pu"
                    },
                    {
                        "@pid": "267/1308",
                        "text": "Keyu Man"
                    },
                    {
                        "@pid": "31/8302",
                        "text": "Zhiyun Qian"
                    },
                    {
                        "@pid": "k/SrikanthVKrishnamurthy",
                        "text": "Srikanth V. Krishnamurthy"
                    }
                ]
            },
            "title": "Untangling the Knot: Breaking Access Control in Home Wireless Mesh Networks.",
            "venue": "CCS",
            "pages": "2072-2086",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ZhouDPMQK24",
            "doi": "10.1145/3658644.3670380",
            "ee": "https://doi.org/10.1145/3658644.3670380",
            "url": "https://dblp.org/rec/conf/ccs/ZhouDPMQK24",
            "abstract": "Home wireless mesh networks (WMNs) are increasingly gaining popularity for their superior extensibility and signal coverage compared to traditional single-AP wireless networks. In particular, there is a single gateway node and multiple extender nodes that cooperate to provide wireless coverage. We observe that there is no comprehensive research conducted on the security aspects of the control plane of such networks. For example, this decentralized architecture enables each extender node to independently authenticate wireless clients by synchronizing access control policies from the gateway node. However, this synchronization unexpectedly opens an attack surface which has not been scrutinized. In our research, we conduct an empirical study investigating devices and protocols of six popular home wireless mesh network vendors, focusing on the attack surface introduced by the access policy synchronization. Interestingly, we find that the exact protocols used to support such functionalities vary by vendors, despite the existence of the EasyMesh standard that vendors could opt-in. Furthermore, we find a number of serious security flaws, including but not limited to malicious clients retaining their network access indefinitely and direct compromises of gateway and extender nodes in some cases. These issues arise due to the lack of coordination across different layers of protocols that work together to support the control plane. We reported all of our findings to the affected vendors and they have acknowledged the issues and are working towards fixes (most of the vendors have released patches). Finally, we discuss trade-offs in different existing designs, suggest alternative solutions, and summarize lessons learned from the research.",
            "keywords": [
                "Wireless Mesh Networks",
                "Access Control Policies",
                "Security Flaws",
                "Policy Synchronization",
                "Home Network Security"
            ]
        },
        "url": "URL#256943",
        "sema_paperId": "27a7f0483dd36782aa5517545b9292fa753687c7"
    },
    {
        "@score": "1",
        "@id": "256944",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "251/5365",
                        "text": "Mingxun Zhou"
                    },
                    {
                        "@pid": "141/9910",
                        "text": "Giulia Fanti"
                    },
                    {
                        "@pid": "80/4580",
                        "text": "Elaine Shi"
                    }
                ]
            },
            "title": "Conan: Distributed Proofs of Compliance for Anonymous Data Collection.",
            "venue": "CCS",
            "pages": "914-928",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ZhouFS24",
            "doi": "10.1145/3658644.3690264",
            "ee": "https://doi.org/10.1145/3658644.3690264",
            "url": "https://dblp.org/rec/conf/ccs/ZhouFS24",
            "abstract": "We consider how to design an anonymous data collection protocol that enforces compliance rules. Imagine that each client contributes multiple data items (e.g., votes, location crumbs, or secret shares of its input) to an anonymous network, which mixes all clients\u2019 data items so that the receiver cannot determine which data items belong to the same user. Now, each user must prove to an auditor that the set it contributed satis\ufb01es a compliance predicate, without identifying which items it contributed. For example, the auditor may want to ensure that no voter voted for the same candidate twice, or that a user\u2019s location crumbs are not too far apart in a given time interval. Our main contribution is a novel anonymous, compliant data collection protocol that realizes the above goal. In comparison with na\u00a8\u0131ve approaches such as generic multi-party computation or earlier constructions of collaborative zero-knowledge proofs, the most compelling advantage of our approach is that each client\u2019s communication and computation overhead do not grow with respect to the number of clients n . In this sense, we save a factor of at least n over prior work, which allows our technique to scale to applications with a large number of clients, such as anonymous voting and privacy-preserving federated learning. We \ufb01rst describe our protocol using generic cryptographic primitives that can be realized from standard assumptions. We then suggest a concrete instantiation called Conan which we implement and evaluate. In this concrete instantiation, we are willing to employ SNARKs and the random oracle model for better practical e\ufb03ciency. Notably, in this practical instantiation, each client\u2019s additional communication overhead (not counting the overhead of sending its data items over the anonymous network) is only (cid:101) O (1). We evaluated our technique in various application settings, including secure voting, and secure aggregation protocols for histogram, summation, and vector summation. Our evaluation results show that in all scenarios, each client\u2019s additional communication overhead is only 2.2KB or 2.6KB, depending on which SNARK implementation we use. Further, each client\u2019s computation only 0.2s - 0.5s for almost all cases, except for the vector summation application where the data items are high-dimensional and each client\u2019s computation is 8.5-10.6s.",
            "keywords": [
                "Anonymous Data Collection",
                "Compliance Protocols",
                "Zero-Knowledge Proofs",
                "Client Overhead",
                "SNARKs"
            ]
        },
        "url": "URL#256944",
        "sema_paperId": "78c7311f130ef10ce66ef71a1f2bbc46d5375ad3"
    },
    {
        "@score": "1",
        "@id": "256945",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "246/6069",
                        "text": "Liyi Zhou"
                    },
                    {
                        "@pid": "246/5857",
                        "text": "Kaihua Qin"
                    }
                ]
            },
            "title": "DeFi &apos;24: Workshop on Decentralized Finance and Security.",
            "venue": "CCS",
            "pages": "4907-4908",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ZhouQ24",
            "doi": "10.1145/3658644.3691552",
            "ee": "https://doi.org/10.1145/3658644.3691552",
            "url": "https://dblp.org/rec/conf/ccs/ZhouQ24",
            "abstract": "Decentralized Finance (DeFi) has undergone significant expansion, evolving from a niche market into a complex alternative financial ecosystem. This burgeoning landscape now encompasses a diverse array of financial services, including decentralized exchanges, lending and borrowing platforms, stablecoins, derivatives, yield optimization services, prediction markets, and privacy-enhancing technologies such as token mixers. While the total value locked in DeFi protocols-estimated at approximately 77 billion USD-underscores its increasing significance, it simultaneously highlights the critical necessity for robust security measures.",
            "pdf_url": "",
            "keywords": [
                "Decentralized Finance",
                "DeFi Protocols",
                "Financial Ecosystem",
                "Security Measures",
                "Total Value Locked"
            ]
        },
        "url": "URL#256945",
        "sema_paperId": "38f4aa5b01186c5e882955bdd420fdf94994d920"
    },
    {
        "@score": "1",
        "@id": "256946",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "162/2075",
                        "text": "Andy Zhou"
                    },
                    {
                        "@pid": "47/8617",
                        "text": "Xiaojun Xu"
                    },
                    {
                        "@pid": "321/0994",
                        "text": "Ramesh Raghunathan"
                    },
                    {
                        "@pid": "63/3067",
                        "text": "Alok Lal"
                    },
                    {
                        "@pid": "133/1883",
                        "text": "Xinze Guan"
                    },
                    {
                        "@pid": "27/116-1",
                        "text": "Bin Yu 0001"
                    },
                    {
                        "@pid": "50/3402-26",
                        "text": "Bo Li 0026"
                    }
                ]
            },
            "title": "KnowGraph: Knowledge-Enabled Anomaly Detection via Logical Reasoning on Graph Data.",
            "venue": "CCS",
            "pages": "168-182",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ZhouXRLGY024",
            "doi": "10.1145/3658644.3690354",
            "ee": "https://doi.org/10.1145/3658644.3690354",
            "url": "https://dblp.org/rec/conf/ccs/ZhouXRLGY024",
            "abstract": "Graph-based anomaly detection is pivotal in diverse security applications, such as fraud detection in transaction networks and intrusion detection for network traffic. Standard approaches, including Graph Neural Networks (GNNs), often struggle to generalize across shifting data distributions. Meanwhile, real-world domain knowledge is more stable and a common existing component of real-world detection strategies. To explicitly integrate such knowledge into data-driven models such as GCNs, we propose KnowGraph, which integrates domain knowledge with data-driven learning for enhanced graph-based anomaly detection. KnowGraph comprises two principal components: (1) a statistical learning component that utilizes a main model for the overarching detection task, augmented by multiple specialized knowledge models that predict domain-specific semantic entities; (2) a reasoning component that employs probabilistic graphical models to execute logical inferences based on model outputs, encoding domain knowledge through weighted first-order logic formulas. Extensive experiments on these large-scale real-world datasets show that KnowGraph consistently outperforms state-of-the-art baselines in both transductive and inductive settings, achieving substantial gains in average precision when generalizing to completely unseen test graphs. Further ablation studies demonstrate the effectiveness of the proposed reasoning component in improving detection performance, especially under extreme class imbalance. These results highlight the potential of integrating domain knowledge into data-driven models for high-stakes, graph-based security applications.",
            "keywords": [
                "Graph-based Anomaly Detection",
                "Domain Knowledge Integration",
                "Logical Reasoning",
                "Graph Neural Networks",
                "Extreme Class Imbalance"
            ]
        },
        "url": "URL#256946",
        "sema_paperId": "c2ff98386bf000dae920f6104a8b3134d2256f83"
    },
    {
        "@score": "1",
        "@id": "256947",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "196/6977",
                        "text": "Yutong Zhou"
                    },
                    {
                        "@pid": "29/3081",
                        "text": "Fan Yang"
                    },
                    {
                        "@pid": "331/4574",
                        "text": "Zirui Song"
                    },
                    {
                        "@pid": "20/4152",
                        "text": "Ke Zhang"
                    },
                    {
                        "@pid": "224/2480",
                        "text": "Jiongyi Chen"
                    },
                    {
                        "@pid": "66/6560",
                        "text": "Kehuan Zhang"
                    }
                ]
            },
            "title": "LiftFuzz: Validating Binary Lifters through Context-aware Fuzzing with GPT.",
            "venue": "CCS",
            "pages": "3778-3792",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ZhouYSZCZ24",
            "doi": "10.1145/3658644.3670276",
            "ee": "https://doi.org/10.1145/3658644.3670276",
            "url": "https://dblp.org/rec/conf/ccs/ZhouYSZCZ24",
            "abstract": "Analyzing binary code is vital for software engineering and security research, particularly when the source code is unavailable. However, understanding, modifying, and retargeting binary code can be complex tasks. To counter these difficulties, binary lifters have been introduced. These tools translate binary code into Intermediate Representations (IRs), providing several advantages, such as enabling modifications to executables without source code and facilitating code retargetability. So far, accurately developing binary lifters for modern ISAs is universally acknowledged as challenging and error-prone. Existing validation methods mainly concentrate on isolated instructions, overlooking interactions among instructions. In this paper, we introduceLiftFuzz, a novel framework that leverages instruction context-aware fuzzing to validate binary lifters.LiftFuzzharnesses an assembly language model to learn interactions among instructions and generates test cases with the knowledge.LiftFuzzgreatly outperforms the baseline, requiring only 1/1000 of the test cases used by the baseline to identify 26 inconsistencies, including a previously uncovered category.LiftFuzzsignificantly contributes to enhancing the performance of binary lifters, which are frequently employed in binary security applications.",
            "pdf_url": "",
            "keywords": [
                "Binary Code Analysis",
                "Binary Lifters",
                "Intermediate Representations",
                "Context-aware Fuzzing",
                "Validation of Binary Lifters"
            ]
        },
        "url": "URL#256947",
        "sema_paperId": "f86e549ba53de289fcca849a68a94a639234e204"
    },
    {
        "@score": "1",
        "@id": "256948",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "67/94",
                        "text": "Yufei Zhou"
                    },
                    {
                        "@pid": "33/10575",
                        "text": "Peijia Zheng"
                    },
                    {
                        "@pid": "39/3695",
                        "text": "Xiaochun Cao"
                    },
                    {
                        "@pid": "90/6446",
                        "text": "Jiwu Huang"
                    }
                ]
            },
            "title": "Two-Tier Data Packing in RLWE-based Homomorphic Encryption for Secure Federated Learning.",
            "venue": "CCS",
            "pages": "2844-2858",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ZhouZCH24",
            "doi": "10.1145/3658644.3690191",
            "ee": "https://doi.org/10.1145/3658644.3690191",
            "url": "https://dblp.org/rec/conf/ccs/ZhouZCH24",
            "abstract": "Homomorphic Encryption (HE) facilitates the preservation of privacy in federated learning (FL) aggregation. However, HE imposes significant computational and communication overhead. To address this problem, data encoding methods have been introduced that enable batch processing to improving the efficiency of ciphertext usage. The existing methods simply concatenate integer or coefficients assignment in polynomials, which do not fully make use of HE based on ring learning with errors (RLWE). We present a novel two-tier data encoding approach tailored for RLWE-based HE, effectively utilizing RLWE's polynomial structure. Our method involves a dual-level data packing strategy for batch processing at both integer and polynomial levels. At the first tier (integer level), we amalgamate those quantized model data into larger integers. Beyond existing concatenation-based encoding, we introduce a new encoding method derived from the Chinese Remainder Theorem (CRT). This CRT-based method effectively mitigates overflow and error propagation concerns. At the second tier (polynomial level), we transmute the large integers into a polynomial form. Additionally, we propose a new subring decomposition method, i.e., employing ring isomorphism mappings to project multiple large integers into varied sub-polynomial rings. Our dual-tier encoding strategy offers a more flexible and effective batch HE solution. We rigorously analyze the correctness, efficiency, and security of our approach. Our extensive experimental evaluations reveal that secure FL, empowered by our dual-tier encoding technique, markedly enhances computational and communication efficiencies over prevailing batch HE methods.",
            "pdf_url": "",
            "keywords": [
                "Homomorphic Encryption",
                "Federated Learning",
                "RLWE",
                "Data Encoding",
                "Chinese Remainder Theorem (CRT)"
            ]
        },
        "url": "URL#256948",
        "sema_paperId": "bd1b07c7ca293f4b5867bc31cd55d03c6ee191cd"
    },
    {
        "@score": "1",
        "@id": "256949",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "353/7626",
                        "text": "Jiaxun Zhu"
                    },
                    {
                        "@pid": "191/6849",
                        "text": "Minghao Lin"
                    },
                    {
                        "@pid": "40/4177",
                        "text": "Tingting Yin"
                    },
                    {
                        "@pid": "353/7550",
                        "text": "Zechao Cai"
                    },
                    {
                        "@pid": "02/5889",
                        "text": "Yu Wang"
                    },
                    {
                        "@pid": "61/1290",
                        "text": "Rui Chang"
                    },
                    {
                        "@pid": "18/5040",
                        "text": "Wenbo Shen"
                    }
                ]
            },
            "title": "CrossFire: Fuzzing macOS Cross-XPU Memory on Apple Silicon.",
            "venue": "CCS",
            "pages": "3749-3762",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ZhuLYCWCS24",
            "doi": "10.1145/3658644.3690376",
            "ee": "https://doi.org/10.1145/3658644.3690376",
            "url": "https://dblp.org/rec/conf/ccs/ZhuLYCWCS24",
            "abstract": "Modern computing systems increasingly utilize XPUs, such as GPUs and NPUs, for specialized computation tasks. While these XPUs provide critical functionalities, their security protections are generally weaker than those of CPUs, making them attractive attack targets. In particular, Apple silicon optimizes memory usage by adopting a unified memory architecture (UMA), which employs shared memory regions (termed cross-XPU memory) to facilitate communication between CPUs and XPUs. Although the cross-XPU memory enhances performance, it also introduces a new attack surface. Unfortunately, the difficulty in identifying effective shared memory regions and generating valid payloads makes fuzzing cross-XPU memory a challenging problem that cannot be resolved effectively by existing fuzzing techniques.",
            "pdf_url": "",
            "keywords": [
                "Cross-XPU Memory",
                "Unified Memory Architecture",
                "Fuzzing",
                "Apple Silicon",
                "Memory Vulnerabilities"
            ]
        },
        "url": "URL#256949",
        "sema_paperId": "b494ba587f37960e1ee4daaee7f4e5c291d05110"
    },
    {
        "@score": "1",
        "@id": "256950",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "36/1469",
                        "text": "Tong Zhu"
                    },
                    {
                        "@pid": "299/8770",
                        "text": "Chaofan Shou"
                    },
                    {
                        "@pid": "22/3870",
                        "text": "Zhen Huang"
                    },
                    {
                        "@pid": "05/1884",
                        "text": "Guoxing Chen"
                    },
                    {
                        "@pid": "158/4724",
                        "text": "Xiaokuan Zhang"
                    },
                    {
                        "@pid": "43/1032-1",
                        "text": "Yan Meng 0001"
                    },
                    {
                        "@pid": "07/6713-1",
                        "text": "Shuang Hao 0001"
                    },
                    {
                        "@pid": "22/5702",
                        "text": "Haojin Zhu"
                    }
                ]
            },
            "title": "Unveiling Collusion-Based Ad Attribution Laundering Fraud: Detection, Analysis, and Security Implications.",
            "venue": "CCS",
            "pages": "2963-2977",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ZhuSHCZ00Z24",
            "doi": "10.1145/3658644.3670314",
            "ee": "https://doi.org/10.1145/3658644.3670314",
            "url": "https://dblp.org/rec/conf/ccs/ZhuSHCZ00Z24",
            "abstract": "In recent years, the growth of mobile advertising has been driven by in-app programmatic advertising and technologies like Real-Time Bidding (RTB). However, this growth has also led to an increase in ad fraud, such as click injection, background ad activity, etc. While existing studies have primarily concentrated on ad fraud within individual apps or devices, this paper introduces a new form of collusion-based ad fraud, named ad attribution laundering fraud ( ALF ). ALF involves multiple apps collaborating to deceive advertisers by misrepresenting the app where ads are displayed. The collusion-based approach allows lower-quality apps to exploit the reputable identities of seemingly legitimate apps. This deceives ad-vertisers or ad networks into believing that the advertisements they place are reaching potentially valid end-users on the legitimate app. The seemingly legitimate ad events and ad attribution procedures employed by individual apps in such attacks can evade detection by existing tools. To detect ALF , we design and implement the first detection framework, AlfScan. It overcomes two challenges to extract apps\u2019 identities from diverse and obfuscated apps using both static and dynamic analysis techniques, then cross-check the identities to identify ALF . We evaluate AlfScan on a 200-app ground truth dataset, and it achieves 92% precision and 92% recall. We use AlfS-can to conduct a large-scale analysis on 91 , 006 apps and identify 4 , 515 unique fraudulent apps and 1 , 483 fraudulent clusters, exposing patterns among fraudulent developers and revealing reliability",
            "keywords": [
                "Mobile Advertising",
                "Ad Fraud",
                "Collusion-Based Fraud",
                "Ad Attribution Laundering Fraud (ALF)",
                "Fraud Detection Framework"
            ]
        },
        "url": "URL#256950",
        "sema_paperId": "b97affe3cfd0f082563f0de88af7cb60dd9684e4"
    },
    {
        "@score": "1",
        "@id": "256951",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "55/5471",
                        "text": "Jie Zhu"
                    },
                    {
                        "@pid": "374/9277",
                        "text": "Jirong Zha"
                    },
                    {
                        "@pid": "95/7132-1",
                        "text": "Ding Li 0001"
                    },
                    {
                        "@pid": "07/8764",
                        "text": "Leye Wang"
                    }
                ]
            },
            "title": "A Unified Membership Inference Method for Visual Self-supervised Encoder via Part-aware Capability.",
            "venue": "CCS",
            "pages": "1241-1255",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ZhuZ0W24",
            "doi": "10.1145/3658644.3690202",
            "ee": "https://doi.org/10.1145/3658644.3690202",
            "url": "https://dblp.org/rec/conf/ccs/ZhuZ0W24",
            "abstract": "Self-supervised learning shows promise in harnessing extensive unlabeled data, but it also confronts significant privacy concerns, especially in vision. In this paper, we aim to perform membership inference on visual self-supervised models in a more realistic setting: self-supervised training method and details are unknown for an adversary when attacking as he usually faces a black-box system in practice. In this setting, considering that self-supervised model could be trained by completely different self-supervised paradigms, e.g., masked image modeling and contrastive learning, with complex training details, we propose a unified membership inference method called PartCrop. It is motivated by the shared part-aware capability among models and stronger part response on the training data. Specifically, PartCrop crops parts of objects in an image to query responses with the image in representation space. We conduct extensive attacks on self-supervised models with different training protocols and structures using three widely used image datasets. The results verify the effectiveness and generalization of PartCrop. Moreover, to defend against PartCrop, we evaluate two common approaches, i.e., early stop and differential privacy, and propose a tailored method called shrinking crop scale range. The defense experiments indicate that all of them are effective. Our code is available at https://github.com/JiePKU/PartCrop.",
            "keywords": [
                "Self-supervised Learning",
                "Membership Inference",
                "Visual Models",
                "Part-aware Capability",
                "Privacy Concerns"
            ]
        },
        "url": "URL#256951",
        "sema_paperId": "71622c5fb66d949e6b8c0610d321c1b310946d29"
    },
    {
        "@score": "1",
        "@id": "256952",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "88/8969",
                        "text": "Zhenhua Zou"
                    },
                    {
                        "@pid": "69/11514",
                        "text": "Zhuotao Liu"
                    },
                    {
                        "@pid": "05/7998",
                        "text": "Jinyong Shan"
                    },
                    {
                        "@pid": "181/2688-2",
                        "text": "Qi Li 0002"
                    },
                    {
                        "@pid": "181/2626-2",
                        "text": "Ke Xu 0002"
                    },
                    {
                        "@pid": "18/6055",
                        "text": "Mingwei Xu"
                    }
                ]
            },
            "title": "CoGNN: Towards Secure and Efficient Collaborative Graph Learning.",
            "venue": "CCS",
            "pages": "4032-4046",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ZouLSLXX24",
            "doi": "10.1145/3658644.3670300",
            "ee": "https://doi.org/10.1145/3658644.3670300",
            "url": "https://dblp.org/rec/conf/ccs/ZouLSLXX24",
            "abstract": "Collaborative graph learning represents a learning paradigm where multiple parties jointly train a graph neural network (GNN) using their own proprietary graph data. To honor the data privacy of all parties, existing solutions for collaborative graph learning are either based on federated learning (FL) or secure machine learning (SML). Although promising in terms of efficiency and scalability due to their distributed training scheme, FL-based approaches fall short in providing provable security guarantees and achieving good model performance. Conversely, SML-based solutions, while offering provable privacy guarantees, are hindered by their high computational and communication overhead, as well as poor scalability as more parties participate.",
            "pdf_url": "",
            "keywords": [
                "Collaborative Graph Learning",
                "Graph Neural Networks",
                "Data Privacy",
                "Federated Learning",
                "Secure Machine Learning"
            ]
        },
        "url": "URL#256952"
    },
    {
        "@score": "1",
        "@id": "256953",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "164/6064",
                        "text": "Guy Zyskind"
                    },
                    {
                        "@pid": "164/3366",
                        "text": "Avishay Yanai"
                    },
                    {
                        "@pid": "p/AlexPentland",
                        "text": "Alex &apos;Sandy&apos; Pentland"
                    }
                ]
            },
            "title": "High-Throughput Three-Party DPFs with Applications to ORAM and Digital Currencies.",
            "venue": "CCS",
            "pages": "4152-4166",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/ccs/ZyskindYP24",
            "doi": "10.1145/3658644.3670292",
            "ee": "https://doi.org/10.1145/3658644.3670292",
            "url": "https://dblp.org/rec/conf/ccs/ZyskindYP24",
            "abstract": "Distributed point functions (DPF) are increasingly becoming a foundational tool with applications for application-specific and general secure computation. While two-party DPF constructions are readily available for those applications with satisfiable performance, the three-party ones are left behind in both security and efficiency. In this paper we close this gap and propose the first three-party DPF construction that matches the state-of-the-art two-party DPF on all metrics. Namely, it is secure against a malicious adversary corrupting both the dealer and one out of the three evaluators, its function's shares are of the same size and evaluation takes the same time as in the best two-party DPF. Compared to the state-of-the-art three-party DPF, our construction enjoys 40-120\u00d7 smaller function's share size and shorter evaluation time, for function domains of 216-240, respectively.",
            "pdf_url": "",
            "keywords": [
                "Distributed Point Functions",
                "Three-Party DPF",
                "Secure Computation",
                "Malicious Adversary",
                "Function Share Size"
            ]
        },
        "url": "URL#256953"
    },
    {
        "@score": "1",
        "@id": "389329",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "71/2890",
                        "text": "Bo Luo"
                    },
                    {
                        "@pid": "129/1113",
                        "text": "Xiaojing Liao"
                    },
                    {
                        "@pid": "90/514-24",
                        "text": "Jun Xu 0024"
                    },
                    {
                        "@pid": "k/EnginKirda",
                        "text": "Engin Kirda"
                    },
                    {
                        "@pid": "l/DavidLie",
                        "text": "David Lie"
                    }
                ]
            },
            "title": "Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security, CCS 2024, Salt Lake City, UT, USA, October 14-18, 2024",
            "venue": "CCS",
            "publisher": "ACM",
            "year": "2024",
            "type": "Editorship",
            "key": "conf/ccs/2024",
            "doi": "10.1145/3658644",
            "ee": "https://doi.org/10.1145/3658644",
            "url": "https://dblp.org/rec/conf/ccs/2024",
            "abstract": null
        },
        "url": "URL#389329",
        "sema_paperId": "179aa4266e5d13b89560e051b7cc4a893ffd0215"
    }
]