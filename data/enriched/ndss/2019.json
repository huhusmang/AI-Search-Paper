[
    {
        "@score": "1",
        "@id": "2737630",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "08/1117-1",
                        "text": "Michael Schwarz 0001"
                    },
                    {
                        "@pid": "239/8996",
                        "text": "Florian Lackner"
                    },
                    {
                        "@pid": "166/1494",
                        "text": "Daniel Gruss"
                    }
                ]
            },
            "title": "JavaScript Template Attacks: Automatically Inferring Host Information for Targeted Exploits.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/0001LG19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/javascript-template-attacks-automatically-inferring-host-information-for-targeted-exploits/",
            "url": "https://dblp.org/rec/conf/ndss/0001LG19",
            "abstract": "Today, more and more web browsers and extensions provide anonymity features to hide user details. Primarily used to evade tracking by websites and advertisements, these features are also used by criminals to prevent identification. Thus, not only tracking companies but also law-enforcement agencies have an interest in finding flaws which break these anonymity features. For instance, for targeted exploitation using zero days, it is essential to have as much information about the target as possible. A failed exploitation attempt, e.g., due to a wrongly guessed operating system, can burn the zero-day, effectively costing the attacker money. Also for side-channel attacks, it is of the utmost importance to know certain aspects of the victim\u2019s hardware configuration, e.g., the instruction-set architecture. Moreover, knowledge about specific environmental properties, such as the operating system, allows crafting more plausible dialogues for phishing attacks. In this paper, we present a fully automated approach to find subtle differences in browser engines caused by the environment. Furthermore, we present two new side-channel attacks on browser engines to detect the instruction-set architecture and the used memory allocator. Using these differences, we can deduce information about the system, both about the software as well as the hardware. As a result, we cannot only ease the creation of fingerprints, but we gain the advantage of having a more precise picture for targeted exploitation. Our approach allows automating the cumbersome manual search for such differences. We collect all data available to the JavaScript engine and build templates from these properties. If a property of such a template stays the same on one system but differs on a different system, we found an environment-dependent property. We found environment-dependent properties in Firefox, Chrome, Edge, and mobile Tor, allowing us to reveal the underlying operating system, CPU architecture, used privacy-enhancing plugins, as well as exact browser version. We stress that our method should be used in the development of browsers and privacy extensions to automatically find flaws in the implementation.",
            "keywords": [
                "Browser Anonymity",
                "Template Attacks",
                "Side-Channel Attacks",
                "Fingerprinting",
                "Environment-Dependent Properties"
            ]
        },
        "url": "URL#2737630",
        "sema_paperId": "0c58daa05c323110d1ef50cc88a9be3786fdf3b6"
    },
    {
        "@score": "1",
        "@id": "2737631",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "76/3473-4",
                        "text": "Cheng Feng 0004"
                    },
                    {
                        "@pid": "176/9981",
                        "text": "Venkata Reddy Palleti"
                    },
                    {
                        "@pid": "m/AdityaPMathur",
                        "text": "Aditya Mathur"
                    },
                    {
                        "@pid": "205/3763",
                        "text": "Deeph Chana"
                    }
                ]
            },
            "title": "A Systematic Framework to Generate Invariants for Anomaly Detection in Industrial Control Systems.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/0004PMC19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/a-systematic-framework-to-generate-invariants-for-anomaly-detection-in-industrial-control-systems/",
            "url": "https://dblp.org/rec/conf/ndss/0004PMC19",
            "abstract": "Industrial Control Systems (ICS) consisting of integrated hardware and software components designed to monitor and control a variety of industrial processes, are typically deployed in critical infrastructures such as water treatment plants, power grids and gas pipelines. Unlike conventional IT systems, the consequences of deviations from normal operation in ICS have the potential to cause significant physical damage to equipment, the environment and even human life. The active monitoring of invariant rules that define the physical conditions that must be maintained for the normal operation of ICS provides a means to improve the security and dependability of such systems by which early detection of anomalous system states may be achieved, allowing for timely mitigating actions \u2013 such as fault checking, system shutdown \u2013 to be taken. Generally, invariant rules are predefined by system engineers during the design phase of a given ICS build. However, this manually intensive process is costly, error-prone and, in typically complex systems, sub-optimal. In this paper we propose a novel framework that is designed to systematically generate invariant rules from information contained within ICS operational data logs, using a combination of several machine learning and data mining techniques. The effectiveness of our approach is demonstrated by experiments on two real world ICS testbeds: a water distribution system and a water treatment plant. We show that sets of invariant rules, far larger than those defined manually, can be successfully derived by our framework and that they may be used to deliver significant improvements in anomaly detection compared with the invariant rules defined by system engineers as well as the commonly used residual errorbased anomaly detection model for ICS. Keywords\u2014industrial control systems, anomaly detection, invariant rules, machine learning.",
            "keywords": [
                "Industrial Control Systems",
                "Anomaly Detection",
                "Invariant Rules",
                "Operational Data Logs",
                "Fault Detection"
            ]
        },
        "url": "URL#2737631",
        "sema_paperId": "de39d8209e4848bdb9e7268080c87d7384525d11"
    },
    {
        "@score": "1",
        "@id": "2737632",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "205/2013",
                        "text": "Hadi Abdullah"
                    },
                    {
                        "@pid": "192/6857",
                        "text": "Washington Garcia"
                    },
                    {
                        "@pid": "224/2404",
                        "text": "Christian Peeters"
                    },
                    {
                        "@pid": "14/3295",
                        "text": "Patrick Traynor"
                    },
                    {
                        "@pid": "82/1935",
                        "text": "Kevin R. B. Butler"
                    },
                    {
                        "@pid": "41/4560",
                        "text": "Joseph Wilson"
                    }
                ]
            },
            "title": "Practical Hidden Voice Attacks against Speech and Speaker Recognition Systems.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/AbdullahGPTBW19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/practical-hidden-voice-attacks-against-speech-and-speaker-recognition-systems/",
            "url": "https://dblp.org/rec/conf/ndss/AbdullahGPTBW19",
            "abstract": "Voice Processing Systems (VPSes), now widely deployed, have been made significantly more accurate through the application of recent advances in machine learning. However, adversarial machine learning has similarly advanced and has been used to demonstrate that VPSes are vulnerable to the injection of hidden commands - audio obscured by noise that is correctly recognized by a VPS but not by human beings. Such attacks, though, are often highly dependent on white-box knowledge of a specific machine learning model and limited to specific microphones and speakers, making their use across different acoustic hardware platforms (and thus their practicality) limited. In this paper, we break these dependencies and make hidden command attacks more practical through model-agnostic (blackbox) attacks, which exploit knowledge of the signal processing algorithms commonly used by VPSes to generate the data fed into machine learning systems. Specifically, we exploit the fact that multiple source audio samples have similar feature vectors when transformed by acoustic feature extraction algorithms (e.g., FFTs). We develop four classes of perturbations that create unintelligible audio and test them against 12 machine learning models, including 7 proprietary models (e.g., Google Speech API, Bing Speech API, IBM Speech API, Azure Speaker API, etc), and demonstrate successful attacks against all targets. Moreover, we successfully use our maliciously generated audio samples in multiple hardware configurations, demonstrating effectiveness across both models and real systems. In so doing, we demonstrate that domain-specific knowledge of audio signal processing represents a practical means of generating successful hidden voice command attacks.",
            "keywords": [
                "Voice Processing Systems",
                "Hidden Voice Attacks",
                "Adversarial Audio",
                "Signal Processing Vulnerabilities",
                "Model-Agnostic Attacks"
            ]
        },
        "url": "URL#2737632",
        "sema_paperId": "b6b483e0ff8d39ab5d5fada757b7ab43995e65bc"
    },
    {
        "@score": "1",
        "@id": "2737633",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "180/3674",
                        "text": "Tigist Abera"
                    },
                    {
                        "@pid": "191/5905",
                        "text": "Raad Bahmani"
                    },
                    {
                        "@pid": "117/5967",
                        "text": "Ferdinand Brasser"
                    },
                    {
                        "@pid": "23/5695-2",
                        "text": "Ahmad Ibrahim 0002"
                    },
                    {
                        "@pid": "s/AhmadRezaSadeghi",
                        "text": "Ahmad-Reza Sadeghi"
                    },
                    {
                        "@pid": "86/1764",
                        "text": "Matthias Schunter"
                    }
                ]
            },
            "title": "DIAT: Data Integrity Attestation for Resilient Collaboration of Autonomous Systems.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/AberaBB0SS19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/diat-data-integrity-attestation-for-resilient-collaboration-of-autonomous-systems/",
            "url": "https://dblp.org/rec/conf/ndss/AberaBB0SS19",
            "abstract": "Networks of autonomous collaborative embedded systems are emerging in many application domains such as vehicular ad-hoc networks, robotic factory workers, search/rescue robots, delivery and search drones. To perform their collaborative tasks the involved devices exchange various types of information such as sensor data, status information, and commands. For the correct operation of these complex systems each device must be able to verify that the data coming from other devices is correct and has not been maliciously altered. In this paper, we present DIAT \u2013 a novel approach that allows to verify the correctness of data by attesting the correct generation as well as processing of data using control-flow attestation. DIAT enables devices in autonomous collaborative networks to securely and efficiently interact, relying on a minimal TCB. It ensures that the data sent from one device to another device is not maliciously changed, neither during transport nor during generation or processing on the originating device. Data exchanged between devices in the network is therefore authenticated along with a proof of integrity of all software involved in its generation and processing. To enable this, the embedded devices\u2019 software is decomposed into simple interacting modules reducing the amount and complexity of software that needs to be attested, i.e., only those modules that process the data are relevant. As a proof of concept we implemented and evaluated our scheme DIAT on a state-of-the-art flight controller for drones. Furthermore, we evaluated our scheme in a simulation environment to demonstrate its scalability for large-scale systems.",
            "keywords": [
                "Autonomous Systems",
                "Data Integrity",
                "Control-Flow Attestation",
                "Collaborative Networks",
                "Embedded Systems"
            ]
        },
        "url": "URL#2737633",
        "sema_paperId": "2c625bbe472db3765ef3a2406bd2f61f6230be36"
    },
    {
        "@score": "1",
        "@id": "2737634",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "205/3202",
                        "text": "Adil Ahmad"
                    },
                    {
                        "@pid": "183/1504",
                        "text": "Byunggill Joe"
                    },
                    {
                        "@pid": "152/3962-1",
                        "text": "Yuan Xiao 0001"
                    },
                    {
                        "@pid": "77/3503",
                        "text": "Yinqian Zhang"
                    },
                    {
                        "@pid": "45/4154",
                        "text": "Insik Shin"
                    },
                    {
                        "@pid": "45/7986",
                        "text": "Byoungyoung Lee"
                    }
                ]
            },
            "title": "OBFUSCURO: A Commodity Obfuscation Engine on Intel SGX.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/AhmadJXZSL19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/obfuscuro-a-commodity-obfuscation-engine-on-intel-sgx/",
            "url": "https://dblp.org/rec/conf/ndss/AhmadJXZSL19",
            "abstract": "\u2014Program obfuscation is a popular cryptographic construct with a wide range of uses such as IP theft prevention. Although cryptographic solutions for program obfuscation impose impractically high overheads, a recent breakthrough leveraging trusted hardware has shown promise. However, the existing solution is based on special-purpose trusted hardware, restricting its use-cases to a limited few. In this paper, we first study if such obfuscation is feasible based on commodity trusted hardware, Intel SGX, and we observe that certain important security considerations are not afforded by commodity hardware. In particular, we found that existing obfuscation/obliviousness schemes are insecure if directly applied to Intel SGX primarily due to side-channel limitations. To this end, we present O BFUSCURO , the first system providing program obfuscation using commodity trusted hardware, Intel SGX. The key idea is to leverage ORAM operations to perform secure code execution and data access. Initially, O BFUSCURO transforms the regular program layout into a side-channel-secure and ORAM-compatible layout. Then, O BFUSCURO ensures that its ORAM controller performs data oblivious accesses in order to protect itself from all memory-based side-channels. Furthermore, O BFUSCURO ensures that the program is secure from timing attacks by ensuring that the program always runs for a pre-configured time interval. Along the way, O BFUSCURO also introduces a systematic optimization such as register-based ORAM stash. We provide a thorough security analysis of O BFUSCURO along with empirical attack evaluations showing that O BFUSCURO can protect the SGX program execution from being leaked by access pattern-based and timing-based",
            "keywords": [
                "Program Obfuscation",
                "Intel SGX",
                "Commodity Trusted Hardware",
                "Side-Channel Attacks",
                "Data Oblivious Accesses"
            ]
        },
        "url": "URL#2737634",
        "sema_paperId": "e5cdf0993a894e3a16af8602c4b0dcf3232e538d"
    },
    {
        "@score": "1",
        "@id": "2737635",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "150/5254",
                        "text": "Eihal Alowaisheq"
                    },
                    {
                        "@pid": "95/4442-88",
                        "text": "Peng Wang 0088"
                    },
                    {
                        "@pid": "123/3274",
                        "text": "Sumayah A. Alrwais"
                    },
                    {
                        "@pid": "129/1113",
                        "text": "Xiaojing Liao"
                    },
                    {
                        "@pid": "06/6268",
                        "text": "XiaoFeng Wang 0001"
                    },
                    {
                        "@pid": "239/8962",
                        "text": "Tasneem Alowaisheq"
                    },
                    {
                        "@pid": "192/2270",
                        "text": "Xianghang Mi"
                    },
                    {
                        "@pid": "44/10369",
                        "text": "Siyuan Tang"
                    },
                    {
                        "@pid": "89/10754",
                        "text": "Baojun Liu"
                    }
                ]
            },
            "title": "Cracking the Wall of Confinement: Understanding and Analyzing Malicious Domain Take-downs.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/AlowaisheqWAL0A19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/cracking-the-wall-of-confinement-understanding-and-analyzing-malicious-domain-take-downs/",
            "url": "https://dblp.org/rec/conf/ndss/AlowaisheqWAL0A19",
            "abstract": "Take-down operations aim to disrupt cybercrime involving malicious domains. In the past decade, many successful take-down operations have been reported, including those against the Conficker worm, and most recently, against VPNFilter. Although it plays an important role in fighting cybercrime, the domain take-down procedure is still surprisingly opaque. There seems to be no in-depth understanding about how the take-down operation works and whether there is due diligence to ensure its security and reliability. In this paper, we report the first systematic study on domain takedown. Our study was made possible via a large collection of data, including various sinkhole feeds and blacklists, passive DNS data spanning six years, and historical WHOIS information. Over these datasets, we built a unique methodology that extensively used various reverse lookups and other data analysis techniques to address the challenges in identifying taken-down domains, sinkhole operators, and take-down durations. Applying the methodology on the data, we discovered over 620K takendown domains and conducted a longitudinal analysis on the take-down process, thus facilitating a better understanding of the operation and its weaknesses. We found that more than 14% of domains taken-down over the past ten months have been released back to the domain market and that some of the released domains have been repurchased by the malicious actor again before being captured and seized, either by the same or different sinkholes. In addition, we showed that the misconfiguration of DNS records corresponding to the sinkholed domains allowed us to hijack a domain that was seized by the FBI. Further, we found that expired sinkholes have caused the transfer of around 30K takendown domains whose traffic is now under the control of new owners.",
            "keywords": [
                "Malicious Domain Take-down",
                "Cybercrime Disruption",
                "Domain Seizure",
                "Sinkhole Operations",
                "Domain Reacquisition"
            ]
        },
        "url": "URL#2737635",
        "sema_paperId": "cd45b19c0148c666dcaf85578dc5c4b2eb5c008a"
    },
    {
        "@score": "1",
        "@id": "2737636",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "135/0878",
                        "text": "Athanasios Andreou"
                    },
                    {
                        "@pid": "65/2466",
                        "text": "M\u00e1rcio Silva"
                    },
                    {
                        "@pid": "90/2878",
                        "text": "Fabr\u00edcio Benevenuto"
                    },
                    {
                        "@pid": "88/10325",
                        "text": "Oana Goga"
                    },
                    {
                        "@pid": "10/7062",
                        "text": "Patrick Loiseau"
                    },
                    {
                        "@pid": "31/3833",
                        "text": "Alan Mislove"
                    }
                ]
            },
            "title": "Measuring the Facebook Advertising Ecosystem.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/AndreouSBGLM19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/measuring-the-facebook-advertising-ecosystem/",
            "url": "https://dblp.org/rec/conf/ndss/AndreouSBGLM19",
            "abstract": "The Facebook advertising platform has been subject to a number of controversies in the past years regarding privacy violations, lack of transparency, as well as its capacity to be used by dishonest actors for discrimination or propaganda. In this study, we aim to provide a better understanding of the Facebook advertising ecosystem, focusing on how it is being used by advertisers. We first analyze the set of advertisers and then investigate how those advertisers are targeting users and customizing ads via the platform. Our analysis is based on the data we collected from over 600 real-world users via a browser extension that collects the ads our users receive when they browse their Facebook timeline, as well as the explanations for why users received these ads. Our results reveal that users are targeted by a wide range of advertisers (e.g., from popular to niche advertisers); that a non-negligible fraction of advertisers are part of potentially sensitive categories such as news and politics, health or religion; that a significant number of advertisers employ targeting strategies that could be either invasive or opaque; and that many advertisers use a variety of targeting parameters and ad texts. Overall, our work emphasizes the need for better mechanisms to audit ads and advertisers in social media and provides an overview of the platform usage that can help move towards such mechanisms.",
            "keywords": [
                "Facebook Advertising",
                "Advertising Ecosystem",
                "User Targeting",
                "Ad Transparency",
                "Sensitive Categories"
            ]
        },
        "url": "URL#2737636",
        "sema_paperId": "054d87ef2d1aeb715a68a0fe929e5ffa2bbb2932"
    },
    {
        "@score": "1",
        "@id": "2737637",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "133/5077",
                        "text": "Daniele Antonioli"
                    },
                    {
                        "@pid": "32/7125",
                        "text": "Nils Ole Tippenhauer"
                    },
                    {
                        "@pid": "01/4779",
                        "text": "Kasper Bonne Rasmussen"
                    }
                ]
            },
            "title": "Nearby Threats: Reversing, Analyzing, and Attacking Google&apos;s &apos;Nearby Connections&apos; on Android.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/AntonioliTR19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/nearby-threats-reversing-analyzing-and-attacking-googles-nearby-connections-on-android/",
            "url": "https://dblp.org/rec/conf/ndss/AntonioliTR19",
            "abstract": "Google\u2019s Nearby Connections API enables any An-droid (and Android Things) application to provide proximity-based services to its users, regardless of their network connectivity.The API uses Bluetooth BR/EDR, Bluetooth LE and Wi-Fi to let\u201cnearby\u201d clients (discoverers) and servers (advertisers) connectand exchange different types of payloads. The implementation ofthe API is proprietary, closed-source and obfuscated. The updatesof the API are automatically installed by Google across differentversions of Android, without user interaction. Little is knownpublicly about the security guarantees offered by the API, eventhough it presents a significant attack surface.In this work we present the first security analysis of theGoogle\u2019s Nearby Connections API, based on reverse-engineeringof its Android implementation. We discover and implement sev-eral attacks grouped into two families: connection manipulation(CMA) and range extension attacks (REA). CMA-attacks allow anattacker to insert himself as a man-in-the-middle and manipulateconnections (even unrelated to nearby), and to tamper withthe victim\u2019s interface and network configuration. REA-attacksallow an attacker to tunnel any nearby connection to remotelocations, even between two honest devices. Our attacks areenabled by REArby, a toolkit we developed while reversingthe API implementation. REArby includes a dynamic binaryinstrumenter, a packet dissector, and the implementations ofcustom Nearby Connections client and server. We plan to open-source REArby after a responsible disclosure period.",
            "keywords": [
                "Nearby Connections API",
                "Android Security",
                "Connection Manipulation Attacks",
                "Range Extension Attacks",
                "Reverse Engineering"
            ]
        },
        "url": "URL#2737637",
        "sema_paperId": "0523ed2117815ad673a89a618eb22c719f2c1b6e"
    },
    {
        "@score": "1",
        "@id": "2737638",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "180/5502",
                        "text": "Maria Apostolaki"
                    },
                    {
                        "@pid": "225/5525",
                        "text": "Gian Marti"
                    },
                    {
                        "@pid": "220/5929",
                        "text": "Jan M\u00fcller"
                    },
                    {
                        "@pid": "51/7546",
                        "text": "Laurent Vanbever"
                    }
                ]
            },
            "title": "SABRE: Protecting Bitcoin against Routing Attacks.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ApostolakiMMV19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/sabre-protecting-bitcoin-against-routing-attacks/",
            "url": "https://dblp.org/rec/conf/ndss/ApostolakiMMV19",
            "abstract": "Routing attacks remain practically effective in the Internet today as existing countermeasures either fail to provide protection guarantees or are not easily deployable. Blockchain systems are particularly vulnerable to such attacks as they rely on Internet-wide communication to reach consensus. In particular, Bitcoin -the most widely-used cryptocurrency- can be split in half by any AS-level adversary using BGP hijacking. In this paper, we present SABRE, a secure and scalable Bitcoin relay network which relays blocks worldwide through a set of connections that are resilient to routing attacks. SABRE runs alongside the existing peer-to-peer network and is easily deployable. As a critical system, SABRE design is highly resilient and can efficiently handle high bandwidth loads, including Denial of Service attacks. We built SABRE around two key technical insights. First, we leverage fundamental properties of inter-domain routing (BGP) policies to host relay nodes: (i) in locations that are inherently protected against routing attacks; and (ii) on paths that are economically preferred by the majority of Bitcoin clients. These properties are generic and can be used to protect other Blockchain-based systems. Second, we leverage the fact that relaying blocks is communication-heavy, not computation-heavy. This enables us to offload most of the relay operations to programmable network hardware (using the P4 programming language). Thanks to this hardware/software co-design, SABRE nodes operate seamlessly under high load while mitigating the effects of malicious clients. We present a complete implementation of SABRE together with an extensive evaluation. Our results demonstrate that SABRE is effective at securing Bitcoin against routing attacks, even with deployments as small as 6 nodes.",
            "keywords": [
                "Blockchain Security",
                "Bitcoin Relay Network",
                "Routing Attacks",
                "BGP Hijacking",
                "Denial of Service Mitigation"
            ]
        },
        "url": "URL#2737638",
        "sema_paperId": "16775e1f1a8d8fe90221bf9f8eadbc1ecb822d36"
    },
    {
        "@score": "1",
        "@id": "2737639",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "160/7844",
                        "text": "Cornelius Aschermann"
                    },
                    {
                        "@pid": "189/1758",
                        "text": "Tommaso Frassetto"
                    },
                    {
                        "@pid": "h/ThorstenHolz",
                        "text": "Thorsten Holz"
                    },
                    {
                        "@pid": "224/9363",
                        "text": "Patrick Jauernig"
                    },
                    {
                        "@pid": "s/AhmadRezaSadeghi",
                        "text": "Ahmad-Reza Sadeghi"
                    },
                    {
                        "@pid": "239/8837",
                        "text": "Daniel Teuchert"
                    }
                ]
            },
            "title": "NAUTILUS: Fishing for Deep Bugs with Grammars.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/AschermannFHJST19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/nautilus-fishing-for-deep-bugs-with-grammars/",
            "url": "https://dblp.org/rec/conf/ndss/AschermannFHJST19",
            "abstract": "Fuzz testing is a well-known method for efficiently identifying bugs in programs. Unfortunately, when programs that require highly-structured inputs such as interpreters are fuzzed, many fuzzing methods struggle to pass the syntax checks: interpreters often process inputs in multiple stages, first syntactic and then semantic correctness is checked. Only if both checks are passed, the interpreted code gets executed. This prevents fuzzers from executing \u201cdeeper\u201d \u2014 and hence potentially more interesting \u2014 code. Typically, two valid inputs that lead to the execution of different features in the target program require too many mutations for simple mutation-based fuzzers to discover: making small changes like bit flips usually only leads to the execution of error paths in the parsing engine. So-called grammar fuzzers are able to pass the syntax checks by using ContextFree Grammars. Feedback can significantly increase the efficiency of fuzzing engines and is commonly used in state-of-the-art mutational fuzzers which do not use grammars. Yet, current grammar fuzzers do not make use of code coverage, i.e., they do not know whether any input triggers new functionality. In this paper, we propose NAUTILUS, a method to efficiently fuzz programs that require highly-structured inputs by combining the use of grammars with the use of code coverage feedback. This allows us to recombine aspects of interesting inputs, and to increase the probability that any generated input will be syntactically and semantically correct. We implemented a proofof-concept fuzzer that we tested on multiple targets, including ChakraCore (the JavaScript engine of Microsoft Edge), PHP, mruby, and Lua. NAUTILUS identified multiple bugs in all of the targets: Seven in mruby, three in PHP, two in ChakraCore, and one in Lua. Reporting these bugs was awarded with a sum of 2600 USD and 6 CVEs were assigned. Our experiments show that combining context-free grammars and feedback-driven fuzzing significantly outperforms state-of-the-art approaches like AFL by an order of magnitude and grammar fuzzers by more than a factor of two when measuring code coverage.",
            "keywords": [
                "Fuzz Testing",
                "Grammar-Based Fuzzing",
                "Code Coverage Feedback",
                "Deep Bugs",
                "Context-Free Grammars"
            ]
        },
        "url": "URL#2737639",
        "sema_paperId": "d610be355072e52b72cddd9f8e2f9f188007d550"
    },
    {
        "@score": "1",
        "@id": "2737640",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "160/7844",
                        "text": "Cornelius Aschermann"
                    },
                    {
                        "@pid": "205/2072",
                        "text": "Sergej Schumilo"
                    },
                    {
                        "@pid": "205/2079",
                        "text": "Tim Blazytko"
                    },
                    {
                        "@pid": "150/5154",
                        "text": "Robert Gawlik"
                    },
                    {
                        "@pid": "h/ThorstenHolz",
                        "text": "Thorsten Holz"
                    }
                ]
            },
            "title": "REDQUEEN: Fuzzing with Input-to-State Correspondence.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/AschermannSBGH19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/redqueen-fuzzing-with-input-to-state-correspondence/",
            "url": "https://dblp.org/rec/conf/ndss/AschermannSBGH19",
            "abstract": "\u2014Automated software testing based on fuzzing has experienced a revival in recent years. Especially feedback-driven fuzzing has become well-known for its ability to ef\ufb01ciently perform randomized testing with limited input corpora. Despite a lot of progress, two common problems are magic numbers and (nested) checksums. Computationally expensive methods such as taint tracking and symbolic execution are typically used to overcome such roadblocks. Unfortunately, such methods often require access to source code, a rather precise description of the environment (e.g., behavior of library calls or the underlying OS), or the exact semantics of the platform\u2019s instruction set. In this paper, we introduce a lightweight, yet very effective alternative to taint tracking and symbolic execution to facilitate and optimize state-of-the-art feedback fuzzing that easily scales to large binary applications and unknown environments. We observe that during the execution of a given program, parts of the input often end up directly (i.e., nearly unmodi\ufb01ed) in the program state. This input-to-state correspondence can be exploited to create a robust method to overcome common fuzzing roadblocks in a highly effective and ef\ufb01cient manner. Our prototype implementation, called R EDQUEEN , is able to solve magic bytes and (nested) checksum tests automatically for a given binary executable. Additionally, we show that our techniques outperform various state-of-the-art tools on a wide variety of targets across different privilege levels (kernel-space and userland) with no platform-speci\ufb01c code. R EDQUEEN is the \ufb01rst method to \ufb01nd more than 100% of the bugs planted in L AVA -M across all targets. Furthermore, we were able to discover 65 new bugs and obtained 16 CVEs in multiple programs and OS kernel drivers. Finally, our evaluation demonstrates that R EDQUEEN is fast, widely applicable and outperforms concurrent approaches by up to three orders of magnitude.",
            "keywords": [
                "Fuzzing",
                "Input-to-State Correspondence",
                "Automated Software Testing",
                "Magic Numbers",
                "Checksum Validation"
            ]
        },
        "url": "URL#2737640",
        "sema_paperId": "f51ee4f4cb3b3d28b8ff3bbcc2628c3e94352726"
    },
    {
        "@score": "1",
        "@id": "2737641",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "239/9034",
                        "text": "Xiaofei Bai"
                    },
                    {
                        "@pid": "02/563",
                        "text": "Jian Gao"
                    },
                    {
                        "@pid": "239/8985",
                        "text": "Chenglong Hu"
                    },
                    {
                        "@pid": "50/6759-19",
                        "text": "Liang Zhang 0019"
                    }
                ]
            },
            "title": "Constructing an Adversary Solver for Equihash.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/BaiGHZ19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/constructing-an-adversary-solver-for-equihash/",
            "url": "https://dblp.org/rec/conf/ndss/BaiGHZ19",
            "abstract": "Blockchain networks, especially cryptocurrencies, rely heavily on proof-of-work (PoW) systems, often as a basis to distribute rewards. These systems require solving specific puzzles, where Application Specific Integrated Circuits (ASICs) can be designed for performance or efficiency. Either way, ASICs surpass CPUs and GPUs by orders of magnitude, and may harm blockchain networks. Recently, Equihash is developed to resist ASIC solving with heavy memory usage. Although commercial ASIC solvers exist for its most popular parameter set, such solvers do not work under better ones, and are considered impossible under optimal parameters. In this paper, we inspect the ASIC resistance of Equihash by constructing a parameterindependent adversary solver design. We evaluate the product, and project at least 10x efficiency advantage for resourceful adversaries. We contribute to the security community in two ways: (1) by revealing the limitation of Equihash and raising awareness about its algorithmic factors, and (2) by demonstrating that security inspection is practical and useful on PoW systems, serving as a start point for future research and development.",
            "keywords": [
                "Blockchain Technology",
                "Proof-of-Work",
                "Equihash",
                "ASIC Resistance",
                "Adversary Solver"
            ]
        },
        "url": "URL#2737641",
        "sema_paperId": "c174498c6e0498612d8fe1f43784552288bd0fda"
    },
    {
        "@score": "1",
        "@id": "2737642",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "150/5353",
                        "text": "Muhammad Ahmad Bashir"
                    },
                    {
                        "@pid": "68/1727",
                        "text": "Umar Farooq"
                    },
                    {
                        "@pid": "142/5450",
                        "text": "Maryam Shahid"
                    },
                    {
                        "@pid": "59/3605",
                        "text": "Muhammad Fareed Zaffar"
                    },
                    {
                        "@pid": "79/5135",
                        "text": "Christo Wilson"
                    }
                ]
            },
            "title": "Quantity vs. Quality: Evaluating User Interest Profiles Using Ad Preference Managers.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/BashirFSZW19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/quantity-vs-quality-evaluating-user-interest-profiles-using-ad-preference-managers/",
            "url": "https://dblp.org/rec/conf/ndss/BashirFSZW19",
            "abstract": "\u2014Widely reported privacy issues concerning major online advertising platforms (e.g., Facebook) have heightened concerns among users about the data that is collected about them. However, while we have a comprehensive understanding who collects data on users, as well as how tracking is implemented, there is still a signi\ufb01cant gap in our understanding: what information do advertisers actually infer about users, and is this information accurate? In this study, we leverage Ad Preference Managers ( APMs ) as a lens through which to address this gap. APMs are transparency tools offered by some advertising platforms that allow users to see the interest pro\ufb01les that are constructed about them. We recruited 220 participants to install an IRB approved browser extension that collected their interest pro\ufb01les from four APMs (Google, Facebook, Oracle BlueKai, and Neilsen eXelate), as well as behavioral and survey data. We use this data to analyze the size and correctness of interest pro\ufb01les, compare their composition across the four platforms, and investigate the origins of the data underlying these pro\ufb01les.",
            "keywords": [
                "Online Advertising",
                "User Privacy",
                "Interest Profiles",
                "Ad Preference Managers",
                "Data Accuracy"
            ]
        },
        "url": "URL#2737642",
        "sema_paperId": "85f28d9df6dd89e6915adc11f3262c43b9d3c5db"
    },
    {
        "@score": "1",
        "@id": "2737643",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "117/5967",
                        "text": "Ferdinand Brasser"
                    },
                    {
                        "@pid": "164/2771",
                        "text": "David Gens"
                    },
                    {
                        "@pid": "224/9363",
                        "text": "Patrick Jauernig"
                    },
                    {
                        "@pid": "s/AhmadRezaSadeghi",
                        "text": "Ahmad-Reza Sadeghi"
                    },
                    {
                        "@pid": "32/4934",
                        "text": "Emmanuel Stapf"
                    }
                ]
            },
            "title": "SANCTUARY: ARMing TrustZone with User-space Enclaves.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/BrasserGJSS19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/sanctuary-arming-trustzone-with-user-space-enclaves/",
            "url": "https://dblp.org/rec/conf/ndss/BrasserGJSS19",
            "abstract": "ARM TrustZone is one of the most widely deployed security architecture providing Trusted Execution Environments (TEEs). Unfortunately, its usage and potential benefits for application developers and end users are largely limited due to restricted deployment policies imposed by device vendors. Restriction is enforced since every Trusted App (TA) increases the TEE\u2019s attack surface: any vulnerable or malicious TA can compromise the system\u2019s security. Hence, deploying a TA requires mutual trust between device vendor and application developer, incurring high costs for both. Vendors work around this by offering interfaces to selected TEE functionalities, however, these are not sufficient to securely implement advanced mobile services like banking. Extensive discussion of Intel\u2019s SGX technology in academia and industry has unveiled the demand for an unrestricted use of TEEs, yet no comparable security architecture for mobile devices exists to this day. We propose SANCTUARY, the first security architecture which allows unconstrained use of TEEs in the TrustZone ecosystem without relying on virtualization. SANCTUARY enables execution of security-sensitive apps within strongly isolated compartments in TrustZone\u2019s normal world comparable to SGX\u2019s user-space enclaves. In particular, we leverage TrustZone\u2019s versatile AddressSpace Controller available in current ARM System-on-Chip reference designs, to enforce two-way hardware-level isolation: (i) security-sensitive apps are shielded against a compromised normal-world OS, while (ii) the system is also protected from potentially malicious apps in isolated compartments. Moreover, moving security-sensitive apps from the TrustZone\u2019s secure world to isolated compartments minimizes the TEE\u2019s attack surface. Thus, mutual trust relationships between device vendors and developers become obsolete: the full potential of TEEs can be leveraged. We demonstrate practicality and real-world benefits of SANCTUARY by thoroughly evaluating our prototype on a HiKey 960 development board with microbenchmarks and a use case for one-time password generation in two-factor authentication.",
            "keywords": [
                "ARM TrustZone",
                "Trusted Execution Environments",
                "User-space Enclaves",
                "Security-sensitive Applications",
                "Mutual Trust Relationships"
            ]
        },
        "url": "URL#2737643",
        "sema_paperId": "5d6f6eebbdc1c35ab1aa23b4992632c6ff2b2bda"
    },
    {
        "@score": "1",
        "@id": "2737644",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "143/2298",
                        "text": "Z. Berkay Celik"
                    },
                    {
                        "@pid": "91/6206",
                        "text": "Gang Tan"
                    },
                    {
                        "@pid": "m/PatrickDrewMcDaniel",
                        "text": "Patrick D. McDaniel"
                    }
                ]
            },
            "title": "IoTGuard: Dynamic Enforcement of Security and Safety Policy in Commodity IoT.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/CelikTM19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/iotguard-dynamic-enforcement-of-security-and-safety-policy-in-commodity-iot/",
            "url": "https://dblp.org/rec/conf/ndss/CelikTM19",
            "abstract": "\u2014Broadly de\ufb01ned as the Internet of Things (IoT), the growth of commodity devices that integrate physical processes with digital connectivity has changed the way we live, play, and work. To date, the traditional approach to securing IoT has treated devices individually. However, in practice, it has been recently shown that the interactions among devices are often the real cause of safety and security violations. In this paper, we present I O TG UARD , a dynamic, policy-based enforcement system for IoT, which protects users from unsafe and insecure device states by monitoring the behavior of IoT and trigger-action platform apps. I O TG UARD operates in three phases: (a) implementation of a code instrumentor that adds extra logic to an app\u2019s source code to collect app\u2019s information at runtime, (b) storing the apps\u2019 information in a dynamic model that represents the runtime execution behavior of apps, and (c) identifying IoT safety and security policies, and enforcing relevant policies on the dynamic model of individual apps or sets of interacting apps. We demonstrate I O TG UARD on 20 \ufb02awed apps and \ufb01nd that I O TG UARD correctly enforces 12 of the 12 policy violations. In addition, we evaluate I O TG UARD on 35 SmartThings IoT and 30 IFTTT trigger-action platform market apps executed in a simulated smart home. I O TG UARD enforces 11 unique policies and blocks 16 states in six (17.1%) SmartThings and \ufb01ve (16.6%) IFTTT apps. I O TG UARD imposes only 17.3% runtime overhead on an app and 19.8% for \ufb01ve interacting apps. Through this effort, we introduce a rigorously grounded system for enforcing correct operation of IoT devices through systematically identi\ufb01ed IoT policies, demonstrating the effectiveness and value of monitoring IoT apps with tools such as I O TG UARD .",
            "keywords": [
                "IoT Security",
                "Dynamic Policy Enforcement",
                "Safety Violations",
                "Trigger-Action Platforms",
                "Runtime Monitoring"
            ]
        },
        "url": "URL#2737644",
        "sema_paperId": "4e0e35fb300d5cd256aa5211f0cfc559eedd9957"
    },
    {
        "@score": "1",
        "@id": "2737645",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "162/1897",
                        "text": "Or\u00e7un \u00c7etin"
                    },
                    {
                        "@pid": "22/7256",
                        "text": "Carlos Ga\u00f1\u00e1n"
                    },
                    {
                        "@pid": "224/9124",
                        "text": "Lisette Altena"
                    },
                    {
                        "@pid": "119/1132",
                        "text": "Takahiro Kasama"
                    },
                    {
                        "@pid": "62/5563",
                        "text": "Daisuke Inoue"
                    },
                    {
                        "@pid": "227/4089",
                        "text": "Kazuki Tamiya"
                    },
                    {
                        "@pid": "226/0141",
                        "text": "Ying Tie"
                    },
                    {
                        "@pid": "66/3013",
                        "text": "Katsunari Yoshioka"
                    },
                    {
                        "@pid": "17/7444",
                        "text": "Michel van Eeten"
                    }
                ]
            },
            "title": "Cleaning Up the Internet of Evil Things: Real-World Evidence on ISP and Consumer Efforts to Remove Mirai.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/CetinGAKITTYE19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/cleaning-up-the-internet-of-evil-things-real-world-evidence-on-isp-and-consumer-efforts-to-remove-mirai/",
            "url": "https://dblp.org/rec/conf/ndss/CetinGAKITTYE19",
            "abstract": "With the rise of IoT botnets, the remediation of infected devices has become a critical task. As over 87% of these devices reside in broadband networks, this task will fall primarily to consumers and the Internet Service Providers. We present the first empirical study of IoT malware cleanup in the wild -- more specifically, of removing Mirai infections in the network of a medium-sized ISP. To measure remediation rates, we combine data from an observational study and a randomized controlled trial involving 220 consumers who suffered a Mirai infection together with data from honeypots and darknets. We find that quarantining and notifying infected customers via a walled garden, a best practice from ISP botnet mitigation for conventional malware, remediates 92% of the infections within 14 days. Email-only notifications have no observable impact compared to a control group where no notifications were sent. We also measure surprisingly high natural remediation rates of 58-74% for this control group and for two reference networks where users were also not notified. Even more surprising, reinfection rates are low. Only 5% of the customers who remediated suffered another infection in the five months after our first study. This stands in contrast to our lab tests, which observed reinfection of real IoT devices within minutes -- a discrepancy for which we explore various different possible explanations, but find no satisfactory answer. We gather data on customer experiences and actions via 76 phone interviews and the communications logs of the ISP. Remediation succeeds even though many users are operating from the wrong mental model -- e.g., they run anti-virus software on their PC to solve the infection of an IoT device. While quarantining infected devices is clearly highly effective, future work will have to resolve several remaining mysteries. Furthermore, it will be hard to scale up the walled garden solution because of the weak incentives of the ISPs.",
            "keywords": [
                "IoT Botnets",
                "Malware Remediation",
                "Mirai Infections",
                "Internet Service Providers",
                "Consumer Efforts"
            ]
        },
        "url": "URL#2737645",
        "sema_paperId": "3e2eb4f05af794fc0b2bc634f1b94ab762c83d44"
    },
    {
        "@score": "1",
        "@id": "2737646",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "157/8155",
                        "text": "Anrin Chakraborti"
                    },
                    {
                        "@pid": "94/1554",
                        "text": "Adam J. Aviv"
                    },
                    {
                        "@pid": "83/5841",
                        "text": "Seung Geol Choi"
                    },
                    {
                        "@pid": "74/8292",
                        "text": "Travis Mayberry"
                    },
                    {
                        "@pid": "09/5926",
                        "text": "Daniel S. Roche"
                    },
                    {
                        "@pid": "s/RaduSion",
                        "text": "Radu Sion"
                    }
                ]
            },
            "title": "rORAM: Efficient Range ORAM with O(log2 N) Locality.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ChakrabortiACMR19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/roram-efficient-range-oram-with-olog2-n-locality/",
            "url": "https://dblp.org/rec/conf/ndss/ChakrabortiACMR19",
            "abstract": "Oblivious RAM protocols (ORAMs) allow a client to access data from an untrusted storage device without revealing to that device any information about their access pattern. Typically this is accomplished through random shuffling of the data such that the storage device cannot determine where individual blocks are located, resulting in a highly randomized access pattern. Storage devices however, are typically optimized for sequential access. A large number of random disk seeks during standard ORAM operation induce a substantial overhead. In this paper, we introduce rORAM, an ORAM specifically suited for accessing ranges of sequentially logical blocks while minimizing the number of random physical disk seeks. rORAM obtains significantly better asymptotic efficiency than prior designs (Asharov et al., ePrint 2017, Demertzis et al., CRYPTO 2018) reducing both the number of seeks and communication complexity by a multiplicative factor of O(logN). An rORAM prototype is 30-50x times faster than Path ORAM for similar range-query workloads on local HDDs, 30x faster for local SSDs, and 10x faster for network block devices. rORAM\u2019s novel disk layout can also speed up standard ORAM constructions, e.g., resulting in a 2x faster Path ORAM variant. Importantly, experiments demonstrate suitability for real world applications \u2013 rORAM is up to 5x faster running a file server and up to 11x faster running a range-query intensive video server workloads compared to standard Path ORAM.",
            "keywords": [
                "Oblivious RAM",
                "Range ORAM",
                "Data Access Patterns",
                "Disk Seek Optimization",
                "Communication Complexity"
            ]
        },
        "url": "URL#2737646",
        "sema_paperId": "fcafffc58133048d3bcaa036373e50dd56a3f652"
    },
    {
        "@score": "1",
        "@id": "2737647",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "157/8155",
                        "text": "Anrin Chakraborti"
                    },
                    {
                        "@pid": "s/RaduSion",
                        "text": "Radu Sion"
                    }
                ]
            },
            "title": "ConcurORAM: High-Throughput Stateless Parallel Multi-Client ORAM.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ChakrabortiS19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/concuroram-high-throughput-stateless-parallel-multi-client-oram/",
            "url": "https://dblp.org/rec/conf/ndss/ChakrabortiS19",
            "abstract": "ConcurORAM is a parallel, multi-client oblivious RAM (ORAM) that eliminates waiting for concurrent stateless clients and allows over-all throughput to scale gracefully, without requiring trusted third party components (proxies) or direct inter-client coordination. A key insight behind ConcurORAM is the fact that, during multi-client data access, only a subset of the concurrently-accessed server-hosted data structures require access privacy guarantees. Everything else can be safely implemented as oblivious data structures that are later synced securely and efficiently during an ORAM \u201ceviction\u201d.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2019/02/ndss2019_07B-2_Chakraborti_paper.pdf",
            "keywords": [
                "Oblivious RAM",
                "Multi-Client Systems",
                "Data Access Privacy",
                "Concurrency",
                "Stateless Clients"
            ]
        },
        "url": "URL#2737647"
    },
    {
        "@score": "1",
        "@id": "2737648",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "201/9242",
                        "text": "Sze Yiu Chau"
                    },
                    {
                        "@pid": "162/6489",
                        "text": "Moosa Yahyazadeh"
                    },
                    {
                        "@pid": "53/7986",
                        "text": "Omar Chowdhury"
                    },
                    {
                        "@pid": "12/3394",
                        "text": "Aniket Kate"
                    },
                    {
                        "@pid": "l/NinghuiLi",
                        "text": "Ninghui Li"
                    }
                ]
            },
            "title": "Analyzing Semantic Correctness with Symbolic Execution: A Case Study on PKCS#1 v1.5 Signature Verification.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ChauYCKL19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/analyzing-semantic-correctness-with-symbolic-execution-a-case-study-on-pkcs1-v1-5-signature-verification/",
            "url": "https://dblp.org/rec/conf/ndss/ChauYCKL19",
            "abstract": "\u2014 We discuss how symbolic execution can be used to not only \ufb01nd low-level errors but also analyze the semantic correctness of protocol implementations. To avoid manually crafting test cases, we propose a strategy of meta-level search, which leverages constraints stemmed from the input formats to automatically generate concolic test cases. Additionally, to aid root-cause analysis, we develop constraint provenance tracking (CPT), a mechanism that associates atomic sub-formulas of path constraints with their corresponding source level origins. We demonstrate the power of symbolic analysis with a case study on PKCS#1 v1.5 signature veri\ufb01cation. Leveraging meta-level search and CPT, we analyzed 15 recent open-source implementations using symbolic execution and found semantic \ufb02aws in 6 of them. Further analysis of these \ufb02aws showed that 4 implementations are susceptible to new variants of the Bleichenbacher low-exponent RSA signature forgery. One implementation suffers from potential denial of service attacks with purposefully crafted signatures. All our \ufb01ndings have been responsibly shared with the affected vendors. Among the \ufb02aws discovered, 6 new CVEs have been assigned to the immediately exploitable ones.",
            "keywords": [
                "Symbolic Execution",
                "Semantic Correctness",
                "PKCS#1 v1.5",
                "Signature Verification",
                "Bleichenbacher Attack"
            ]
        },
        "url": "URL#2737648",
        "sema_paperId": "ba1e1af274581801a11921377decc39490a8ea07"
    },
    {
        "@score": "1",
        "@id": "2737649",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "150/5333",
                        "text": "Zheng Leong Chua"
                    },
                    {
                        "@pid": "123/2365",
                        "text": "Yanhao Wang"
                    },
                    {
                        "@pid": "212/5599",
                        "text": "Teodora Baluta"
                    },
                    {
                        "@pid": "90/105",
                        "text": "Prateek Saxena"
                    },
                    {
                        "@pid": "99/4951",
                        "text": "Zhenkai Liang"
                    },
                    {
                        "@pid": "46/3714",
                        "text": "Purui Su"
                    }
                ]
            },
            "title": "One Engine To Serve &apos;em All: Inferring Taint Rules Without Architectural Semantics.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ChuaWBSLS19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/one-engine-to-serve-em-all-inferring-taint-rules-without-architectural-semantics/",
            "url": "https://dblp.org/rec/conf/ndss/ChuaWBSLS19",
            "abstract": "Dynamic binary taint analysis has wide applications in the security analysis of commercial-off-the-shelf (COTS) binaries. One of the key challenges in dynamic binary analysis is to specify the taint rules that capture how taint information propagates for each instruction on an architecture. Most of the existing solutions specify taint rules using a deductive approach by summarizing the rules manually after analyzing the instruction semantics. Intuitively, taint propagation reflects on how an instruction input affects its output, and thus can be observed from instruction executions. In this work, we propose an inductive method for taint propagation and develop a universal taint tracking engine that is architecture-agnostic. Our taint engine, TAINTINDUCE, can learn taint rules with minimal architectural knowledge by observing the execution behavior of instructions. To measure its correctness and guide taint rule generation, we define the precise notion of soundness for bit-level taint tracking in this novel setup. In our evaluation, we show that TAINTINDUCE automatically learns rules for 4 widely used architectures: x86, x64, AArch64, and MIPS-I. It can detect vulnerabilities for 24 CVEs in 15 applications on both Linux and Windows over millions of instructions and is comparable with other mature existing tools (TEMU [51], libdft [32], Triton [42]). TAINTINDUCE can be used as a stand-alone taint engine or be used to complement existing taint engines for unhandled instructions. Further, it can be used as a cross-referencing tool to uncover bugs in taint engines, emulation implementations and ISA documentations.",
            "keywords": [
                "Dynamic Binary Taint Analysis",
                "Taint Propagation",
                "Architecture-Agnostic",
                "Vulnerability Detection",
                "TAINTINDUCE"
            ]
        },
        "url": "URL#2737649",
        "sema_paperId": "909f5472713158613f97e10357c69a24cd7e428d"
    },
    {
        "@score": "1",
        "@id": "2737650",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "17/2282",
                        "text": "Cas Cremers"
                    },
                    {
                        "@pid": "205/2144",
                        "text": "Martin Dehnel-Wild"
                    }
                ]
            },
            "title": "Component-Based Formal Analysis of 5G-AKA: Channel Assumptions and Session Confusion.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/CremersD19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/component-based-formal-analysis-of-5g-aka-channel-assumptions-and-session-confusion/",
            "url": "https://dblp.org/rec/conf/ndss/CremersD19",
            "abstract": "\u2014The 5G mobile telephony standards are nearing completion; upon adoption these will be used by billions across the globe. Ensuring the security of 5G communication is of the utmost importance, building trust in a critical component of everyday life and national infrastructure. We perform \ufb01ne-grained formal analysis of 5G\u2019s main authentication and key agreement protocol (AKA), and provide the \ufb01rst models to explicitly consider all parties de\ufb01ned by the protocol speci\ufb01cation. Our analysis reveals that the security of 5G-AKA critically relies on unstated assumptions on the inner workings of the underlying channels. In practice this means that following the 5G-AKA speci\ufb01cation, a provider can easily and \u2018correctly\u2019 implement the standard insecurely, leaving the protocol vulnerable to a security-critical race condition. We provide the \ufb01rst models and analysis considering component and channel compromise in 5G, whose results further demonstrate the fragility and subtle trust assumptions of the 5G-AKA protocol. We propose formally veri\ufb01ed \ufb01xes to the encountered issues, and have worked with 3GPP to ensure these \ufb01xes are adopted.",
            "keywords": [
                "5G Security",
                "Authentication and Key Agreement (AKA)",
                "Formal Analysis",
                "Channel Compromise",
                "Session Confusion"
            ]
        },
        "url": "URL#2737650",
        "sema_paperId": "39c8e1b590a408872ce7a63c4eb01d03cd184529"
    },
    {
        "@score": "1",
        "@id": "2737651",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "31/6808-1",
                        "text": "Sourav Das 0001"
                    },
                    {
                        "@pid": "91/44",
                        "text": "Vinay Joseph Ribeiro"
                    },
                    {
                        "@pid": "230/3651",
                        "text": "Abhijeet Anand"
                    }
                ]
            },
            "title": "YODA: Enabling computationally intensive contracts on blockchains with Byzantine and Selfish nodes.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/DasRA19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/yoda-enabling-computationally-intensive-contracts-on-blockchains-with-byzantine-and-selfish-nodes/",
            "url": "https://dblp.org/rec/conf/ndss/DasRA19",
            "abstract": "One major shortcoming of permissionless blockchains such as Bitcoin and Ethereum is that they are unsuitable for running Computationally Intensive smart Contracts (CICs). This prevents such blockchains from running Machine Learning algorithms, Zero-Knowledge proofs, etc. which may need non-trivial computation. In this paper, we present YODA, which is to the best of our knowledge the first solution for efficient computation of CICs in permissionless blockchains with guarantees for a threat model with both Byzantine and selfish nodes. YODA selects one or more execution sets (ES) via Sortition to execute a particular CIC off-chain. One key innovation is the MultI-Round Adaptive Consensus using Likelihood Estimation (MIRACLE) algorithm based on sequential hypothesis testing. M I RACLE allows the execution sets to be small thus making YODA efficient while ensuring correct CIC execution with high probability. It adapts the number of ES sets automatically depending on the concentration of Byzantine nodes in the system and is optimal in terms of the expected number of ES sets used in certain scenarios. Through a suite of economic incentives and technical mechanisms such as the novel Randomness Inserted Contract Execution (RICE) algorithm, we force selfish nodes to behave honestly. We also prove that the honest behavior of selfish nodes is an approximate Nash Equilibrium. We present the system design and details of YODA and prove the security properties of MIRACLE and RICE. Our prototype implementation built on top of Ethereum demonstrates the ability of YODA to run CICs with orders of magnitude higher gas per unit time as well as total gas requirements than Ethereum currently supports. It also demonstrates the low overheads of RICE.",
            "keywords": [
                "Computationally Intensive Contracts",
                "Blockchain Technology",
                "Byzantine Nodes",
                "Selfish Nodes",
                "Off-chain Execution"
            ]
        },
        "url": "URL#2737651",
        "sema_paperId": "5cac801d2a1b7ab481e3974cf5b8cbb986d9b3cb"
    },
    {
        "@score": "1",
        "@id": "2737652",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "239/8919",
                        "text": "Abdallah Dawoud"
                    },
                    {
                        "@pid": "31/7561",
                        "text": "Sven Bugiel"
                    }
                ]
            },
            "title": "DroidCap: OS Support for Capability-based Permissions in Android.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/DawoudB19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/droidcap-os-support-for-capability-based-permissions-in-android/",
            "url": "https://dblp.org/rec/conf/ndss/DawoudB19",
            "abstract": "We present DroidCap, a retrofitting of Android\u2019s central Binder IPC mechanism to change the way how permissions are being represented and managed in the system. In DroidCap, permissions are per-process Binder object capabilities. DroidCap's design removes Android\u2019s UID-based ambient authority and allows the delegation of capabilities between processes to create least-privileged protection domains efficiently. With DroidCap, we show that object capabilities as underlying access control model integrates naturally and backward-compatible into Android\u2019s stock permission model and application management. Thus, our Binder capabilities provide app developers with a new path to gradually adopting app compartmentalization, which we showcase at two favorite examples from the literature, privilege separated advertisement libraries and least privileged app components.",
            "keywords": [
                "Capability-based Permissions",
                "Android Security",
                "Binder IPC",
                "Least Privileged Protection",
                "App Compartmentalization"
            ]
        },
        "url": "URL#2737652",
        "sema_paperId": "00a7f1e8b3c4ff147bf8f1eaa3a401fdce6b861b"
    },
    {
        "@score": "1",
        "@id": "2737653",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "120/5815",
                        "text": "Martin Degeling"
                    },
                    {
                        "@pid": "129/4413",
                        "text": "Christine Utz"
                    },
                    {
                        "@pid": "193/1473",
                        "text": "Christopher Lentzsch"
                    },
                    {
                        "@pid": "181/5389",
                        "text": "Henry Hosseini"
                    },
                    {
                        "@pid": "08/7562",
                        "text": "Florian Schaub"
                    },
                    {
                        "@pid": "h/ThorstenHolz",
                        "text": "Thorsten Holz"
                    }
                ]
            },
            "title": "We Value Your Privacy ... Now Take Some Cookies: Measuring the GDPR&apos;s Impact on Web Privacy.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/DegelingULHSH19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/we-value-your-privacy-now-take-some-cookies-measuring-the-gdprs-impact-on-web-privacy/",
            "url": "https://dblp.org/rec/conf/ndss/DegelingULHSH19",
            "abstract": "The European Union\u2019s General Data Protection Regulation (GDPR) went into effect on May 25, 2018. Its privacy regulations apply to any service and company collecting or processing personal data in Europe. Many companies had to adjust their data handling processes, consent forms, and privacy policies to comply with the GDPR\u2019s transparency requirements. We monitored this rare event by analyzing changes on popular websites in all 28 member states of the European Union. For each country, we periodically examined its 500 most popular websites \u2013 6,579 in total \u2013 for the presence of and updates to their privacy policy between December 2017 and October 2018. While many websites already had privacy policies, we find that in some countries up to 15.7 % of websites added new privacy policies by May 25, 2018, resulting in 84.5 % of websites having privacy policies. 72.6 % of websites with existing privacy policies updated them close to the date. After May this positive development slowed down noticeably. Most visibly, 62.1 % of websites in Europe now display cookie consent notices, 16 % more than in January 2018. These notices inform users about a site\u2019s cookie use and user tracking practices. We categorized all observed cookie consent notices and evaluated 28 common implementations with respect to their technical realization of cookie consent. Our analysis shows that core web security mechanisms such as the same-origin policy pose problems for the implementation of consent according to GDPR rules, and opting out of third-party cookies requires the third party to cooperate. Overall, we conclude that the web became more transparent at the time GDPR came into force, but there is still a lack of both functional and usable mechanisms for users to consent to or deny processing of their personal data on the Internet.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2019/02/ndss2019_04B-2_Degeling_paper.pdf",
            "keywords": [
                "Web Privacy",
                "GDPR Compliance",
                "Cookie Consent",
                "Privacy Policy Updates",
                "User Data Protection"
            ]
        },
        "url": "URL#2737653"
    },
    {
        "@score": "1",
        "@id": "2737654",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "117/1764",
                        "text": "David Derler"
                    },
                    {
                        "@pid": "55/9778",
                        "text": "Kai Samelin"
                    },
                    {
                        "@pid": "72/5883",
                        "text": "Daniel Slamanig"
                    },
                    {
                        "@pid": "128/5113",
                        "text": "Christoph Striecks"
                    }
                ]
            },
            "title": "Fine-Grained and Controlled Rewriting in Blockchains: Chameleon-Hashing Gone Attribute-Based.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/DerlerSSS19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/fine-grained-and-controlled-rewriting-in-blockchains-chameleon-hashing-gone-attribute-based/",
            "url": "https://dblp.org/rec/conf/ndss/DerlerSSS19",
            "abstract": "Blockchain technologies recently received a considerable amount of attention. While the initial focus was mainly on the use of blockchains in the context of cryptocurrencies such as Bitcoin, application scenarios now go far beyond this. Most blockchains have the property that once some object, e.g., a block or a transaction, has been registered to be included into the blockchain, it is persisted and there are no means to modify it again. While this is an essential feature of most blockchain scenarios, it is still often desirable---at times it may be even legally required--to allow for breaking this immutability in a controlled way.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2019/02/ndss2019_02A-3_Derler_paper.pdf",
            "keywords": [
                "Blockchain Technology",
                "Immutability",
                "Controlled Rewriting",
                "Chameleon-Hashing",
                "Attribute-Based"
            ]
        },
        "url": "URL#2737654"
    },
    {
        "@score": "1",
        "@id": "2737655",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "234/6067",
                        "text": "Kostas Drakonakis"
                    },
                    {
                        "@pid": "129/9582",
                        "text": "Panagiotis Ilia"
                    },
                    {
                        "@pid": "33/2939",
                        "text": "Sotiris Ioannidis"
                    },
                    {
                        "@pid": "47/8412",
                        "text": "Jason Polakis"
                    }
                ]
            },
            "title": "Please Forget Where I Was Last Summer: The Privacy Risks of Public Location (Meta)Data.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/DrakonakisIIP19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/please-forget-where-i-was-last-summer-the-privacy-risks-of-public-location-metadata/",
            "url": "https://dblp.org/rec/conf/ndss/DrakonakisIIP19",
            "abstract": "The exposure of location data constitutes a significant privacy risk to users as it can lead to de-anonymization, the inference of sensitive information, and even physical threats. In this paper we present LPAuditor, a tool that conducts a comprehensive evaluation of the privacy loss caused by public location metadata. First, we demonstrate how our system can pinpoint users\u2019 key locations at an unprecedented granularity by identifying their actual postal addresses. Our evaluation on Twitter data highlights the effectiveness of our techniques which outperform prior approaches by 18.9%-91.6% for homes and 8.7%-21.8% for workplaces. Next we present a novel exploration of automated private information inference that uncovers \u201csensitive\u201d locations that users have visited (pertaining to health, religion, and sex/nightlife). We find that location metadata can provide additional context to tweets and thus lead to the exposure of private information that might not match the users\u2019 intentions.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2019/02/ndss2019_01A-6_Drakonakis_paper.pdf",
            "keywords": [
                "Location Privacy",
                "Public Metadata",
                "De-anonymization",
                "Sensitive Information Inference",
                "Location Data Exposure"
            ]
        },
        "url": "URL#2737655"
    },
    {
        "@score": "1",
        "@id": "2737656",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "117/4491",
                        "text": "Ruian Duan"
                    },
                    {
                        "@pid": "21/7434",
                        "text": "Ashish Bijlani"
                    },
                    {
                        "@pid": "72/1056-2",
                        "text": "Yang Ji 0002"
                    },
                    {
                        "@pid": "127/7110",
                        "text": "Omar Alrawi"
                    },
                    {
                        "@pid": "129/6327",
                        "text": "Yiyuan Xiong"
                    },
                    {
                        "@pid": "239/8948",
                        "text": "Moses Ike"
                    },
                    {
                        "@pid": "150/5240",
                        "text": "Brendan Saltaformaggio"
                    },
                    {
                        "@pid": "29/5976",
                        "text": "Wenke Lee"
                    }
                ]
            },
            "title": "Automating Patching of Vulnerable Open-Source Software Versions in Application Binaries.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/DuanBJAXISL19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/automating-patching-of-vulnerable-open-source-software-versions-in-application-binaries/",
            "url": "https://dblp.org/rec/conf/ndss/DuanBJAXISL19",
            "abstract": "Mobile application developers rely heavily on opensource software (OSS) to offload common functionalities such as the implementation of protocols and media format playback. Over the past years, several vulnerabilities have been found in popular open-source libraries like OpenSSL and FFmpeg. Mobile applications that include such libraries inherit these flaws, which make them vulnerable. Fortunately, the open-source community is responsive and patches are made available within days. However, mobile application developers are often left unaware of these flaws. The App Security Improvement Program (ASIP) is a commendable effort by Google to notify application developers of these flaws, but recent work has shown that many developers do not act on this information. Our work addresses vulnerable mobile applications through automatic binary patching from source patches provided by the OSS maintainers and without involving the developers. We propose novel techniques to overcome difficult challenges like patching feasibility analysis, source-code-to-binary-code matching, and in-memory patching. Our technique uses a novel variabilityaware approach, which we implement as OSSPATCHER. We evaluated OSSPATCHER with 39 OSS and a collection of 1,000 Android applications using their vulnerable versions. OSSPATCHER generated 675 function-level patches that fixed the affected mobile applications without breaking their binary code. Further, we evaluated 10 vulnerabilities in popular apps such as Chrome with public exploits, which OSSPATCHER was able to mitigate and thwart their exploitation.",
            "keywords": [
                "Open-Source Software",
                "Mobile Application Security",
                "Binary Patching",
                "Vulnerability Mitigation",
                "OSSPATCHER"
            ]
        },
        "url": "URL#2737656",
        "sema_paperId": "9dddb7eb2d83ee094be3eebd9903df08b743aad7"
    },
    {
        "@score": "1",
        "@id": "2737657",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "180/7145",
                        "text": "Sina Faezi"
                    },
                    {
                        "@pid": "180/7182",
                        "text": "Sujit Rokka Chhetri"
                    },
                    {
                        "@pid": "239/9018",
                        "text": "Arnav Vaibhav Malawade"
                    },
                    {
                        "@pid": "239/9006",
                        "text": "John Charles Chaput"
                    },
                    {
                        "@pid": "170/6539",
                        "text": "William H. Grover"
                    },
                    {
                        "@pid": "12/2711",
                        "text": "Philip Brisk"
                    },
                    {
                        "@pid": "06/1521",
                        "text": "Mohammad Abdullah Al Faruque"
                    }
                ]
            },
            "title": "Oligo-Snoop: A Non-Invasive Side Channel Attack Against DNA Synthesis Machines.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/FaeziCMCGBF19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/oligo-snoop-a-non-invasive-side-channel-attack-against-dna-synthesis-machines/",
            "url": "https://dblp.org/rec/conf/ndss/FaeziCMCGBF19",
            "abstract": "\u2014Synthetic biology is developing into a promising science and engineering \ufb01eld. One of the enabling technologies for this \ufb01eld is the DNA synthesizer. It allows researchers to custom-build sequences of oligonucleotides (short DNA strands) using the nucleobases: Adenine (A), Guanine (G), Cytosine (C), and Thymine (T). Incorporating these sequences into organisms can result in improved disease resistance and lifespan for plants, animals, and humans. Hence, many laboratories spend large amounts of capital researching and developing unique sequences of oligonucleotides. However, these DNA synthesizers are fully automated systems with cyber-domain processes and physical domain components. Hence, they may be prone to security breaches like any other computing system. In our work, we present a novel acoustic side-channel attack methodology which can be used on DNA synthesizers to breach their con\ufb01dential-ity and steal valuable oligonucleotide sequences. Our proposed attack methodology achieves an average accuracy of 88.07% in predicting each base and is able to reconstruct short sequences with 100% accuracy by making less than 21 guesses out of 4 15 possibilities. We evaluate our attack against the effects of the microphone\u2019s distance from the DNA synthesizer and show that our attack methodology can achieve over 80% accuracy when the microphone is placed as far as 0.7 meters from the DNA synthesizer despite the presence of common room noise. In addition, we reconstruct DNA sequences to show how effectively an attacker with biomedical-domain knowledge would be able to derive the intended functionality of the sequence using the proposed attack methodology. To the best of our knowledge, this is the \ufb01rst methodology that highlights the possibility of such an",
            "keywords": [
                "Synthetic Biology",
                "DNA Synthesis",
                "Acoustic Side-Channel Attack",
                "Oligonucleotide Sequences",
                "Security Breach"
            ]
        },
        "url": "URL#2737657",
        "sema_paperId": "12c57abea8999327e34361567e5a82d8f98ca368"
    },
    {
        "@score": "1",
        "@id": "2737658",
        "info": {
            "authors": {
                "author": {
                    "@pid": "01/2316",
                    "text": "Deborah A. Frincke"
                }
            },
            "title": "Keynote: Modern Challenges for Cyber Defense.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Other",
            "access": "open",
            "key": "conf/ndss/Frincke19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/auto-draft-49/",
            "url": "https://dblp.org/rec/conf/ndss/Frincke19",
            "abstract": null,
            "keywords": [
                "Cyber Defense",
                "Threat Landscape",
                "Incident Response",
                "Security Challenges",
                "Emerging Threats"
            ]
        },
        "url": "URL#2737658",
        "sema_paperId": "66fc299c54688bc080b4b8a7052bf730fc51db60"
    },
    {
        "@score": "1",
        "@id": "2737659",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "69/711",
                        "text": "Sergey Frolov"
                    },
                    {
                        "@pid": "60/8733",
                        "text": "Eric Wustrow"
                    }
                ]
            },
            "title": "The use of TLS in Censorship Circumvention.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/FrolovW19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/the-use-of-tls-in-censorship-circumvention/",
            "url": "https://dblp.org/rec/conf/ndss/FrolovW19",
            "abstract": "\u2014TLS, the Transport Layer Security protocol, has quickly become the most popular protocol on the Internet, already used to load over 70% of web pages in Mozilla Firefox. Due to its ubiquity, TLS is also a popular protocol for censorship circumvention tools, including Tor and Signal, among others. However, the wide range of features supported in TLS makes it possible to distinguish implementations from one another by what set of cipher suites, elliptic curves, signature algorithms, and other extensions they support. Already, censors have used deep packet inspection (DPI) to identify and block popular circumvention tools based on the \ufb01ngerprint of their TLS implementation. In response, many circumvention tools have attempted to mimic popular TLS implementations such as browsers, but this technique has several challenges. First, it is burdensome to keep up with the rapidly-changing browser TLS implementations, and know what \ufb01ngerprints would be good candidates to mimic. Second, TLS implementations can be dif\ufb01cult to mimic correctly, as they offer many features that may not be supported by the relatively lightweight libraries used in typical circumvention tools. Finally, dependency changes and updates to the underlying libraries can silently impact what an application\u2019s TLS \ufb01ngerprint looks like, making it dif\ufb01cult for tool maintainers to keep up. In this paper, we collect and analyze real-world TLS traf\ufb01c from over 11.8 billion TLS connections over 9 months to identify a wide range of TLS client implementations actually used on the Internet. We use our data to analyze TLS implementations of several popular censorship circumvention tools, including Lantern, Psiphon, Signal, Outline, TapDance, and Tor (Snow\ufb02ake and meek pluggable transports). We \ufb01nd that the many of these tools use TLS con\ufb01gurations that are easily distinguishable from the real-world traf\ufb01c they attempt to mimic, even when these tools have put effort into parroting popular TLS implementations.",
            "keywords": [
                "TLS Protocol",
                "Censorship Circumvention",
                "Deep Packet Inspection",
                "TLS Fingerprinting",
                "Implementation Distinguishability"
            ]
        },
        "url": "URL#2737659",
        "sema_paperId": "f71c171036b29dc13c4b2ae93d3209df02bcee3a"
    },
    {
        "@score": "1",
        "@id": "2737660",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "20/2659",
                        "text": "Virgil D. Gligor"
                    },
                    {
                        "@pid": "11/814",
                        "text": "Shan Leung Maverick Woo"
                    }
                ]
            },
            "title": "Establishing Software Root of Trust Unconditionally.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/GligorW19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/establishing-software-root-of-trust-unconditionally/",
            "url": "https://dblp.org/rec/conf/ndss/GligorW19",
            "abstract": "Root-of-Trust (RoT) establishment ensures either that the state of an untrusted system contains all and only content chosen by a trusted local verifier and the system code begins execution in that state, or that the verifier discovers the existence of unaccounted for content. This ensures program booting into system states that are free of persistent malware. An adversary can no longer retain undetected control of one\u2019s local system. We establish RoT unconditionally; i.e., without secrets, trusted hardware modules and instructions, or bounds on the adversary\u2019s computational power. The specification of a system\u2019s chipset and device controllers, and an external source of true random numbers, such as a commercially available quantum RNG, is all that is needed. Our system specifications are those of a concrete Word Random Access Machine (cWRAM) model \u2013 the closest computation model to a real system with a large instruction set. We define the requirements for RoT establishment and explain their differences from past attestation protocols. Then we introduce a RoT establishment protocol based on a new computation primitive with concrete (non-asymptotic) optimal space-time bounds in adversarial evaluation on the cWRAM. The new primitive is a randomized polynomial, which has kindependent uniform coefficients in a prime order field. Its collision properties are stronger than those of a k-independent (almost) universal hash function in cWRAM evaluations, and are sufficient to prove existence of malware-free states before RoT is established. Preliminary measurements show that randomizedpolynomial performance is practical on commodity hardware even for very large k. To prove the concrete optimality of randomized polynomials, we present a result of independent complexity interest: a Hornerrule program is uniquely optimal whenever the cWRAM execution space and time are simultaneously minimized.",
            "keywords": [
                "Root of Trust",
                "Malware Detection",
                "Randomized Polynomials",
                "cWRAM Model",
                "True Random Number Generation"
            ]
        },
        "url": "URL#2737660",
        "sema_paperId": "1a68062a17596f7bca8a2d9c78fc51b091315d8f"
    },
    {
        "@score": "1",
        "@id": "2737661",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "232/3003",
                        "text": "Inken Hagestedt"
                    },
                    {
                        "@pid": "06/6785-16",
                        "text": "Yang Zhang 0016"
                    },
                    {
                        "@pid": "83/8816",
                        "text": "Mathias Humbert"
                    },
                    {
                        "@pid": "124/6255",
                        "text": "Pascal Berrang"
                    },
                    {
                        "@pid": "90/3951",
                        "text": "Haixu Tang"
                    },
                    {
                        "@pid": "06/6268",
                        "text": "XiaoFeng Wang 0001"
                    },
                    {
                        "@pid": "b/MichaelBackes1",
                        "text": "Michael Backes 0001"
                    }
                ]
            },
            "title": "MBeacon: Privacy-Preserving Beacons for DNA Methylation Data.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/Hagestedt0HBT0019",
            "ee": "https://www.ndss-symposium.org/ndss-paper/mbeacon-privacy-preserving-beacons-for-dna-methylation-data/",
            "url": "https://dblp.org/rec/conf/ndss/Hagestedt0HBT0019",
            "abstract": "The advancement of molecular profiling techniques \nfuels biomedical research with a deluge of data. To facilitate \ndata sharing, the Global Alliance for Genomics and Health \nestablished the Beacon system, a search engine designed to help \nresearchers find datasets of interest. While the current Beacon \nsystem only supports genomic data, other types of biomedical \ndata, such as DNA methylation, are also essential for advancing \nour understanding in the field. In this paper, we propose the first \nBeacon system for DNA methylation data sharing: MBeacon. As \nthe current genomic Beacon is vulnerable to privacy attacks, such \nas membership inference, and DNA methylation data is highly \nsensitive, we take a privacy-by-design approach to construct \nMBeacon. \nFirst, we demonstrate the privacy threat, by proposing a \nmembership inference attack tailored specifically to unprotected \nmethylation Beacons. Our experimental results show that 100 \nqueries are sufficient to achieve a successful attack with AUC \n(area under the ROC curve) above 0.9. To remedy this situation, \nwe propose a novel differential privacy mechanism, namely SVT2 \n, \nwhich is the core component of MBeacon. Extensive experiments \nover multiple datasets show that SVT2 \ncan successfully mitigate \nmembership privacy risks without significantly harming utility. \nWe further implement a fully functional prototype of MBeacon \nwhich we make available to the research community",
            "keywords": [
                "DNA Methylation",
                "Data Sharing",
                "Privacy Preservation",
                "Membership Inference Attack",
                "Differential Privacy"
            ]
        },
        "url": "URL#2737661",
        "sema_paperId": "6010b9137d6af08de16a3768b9ca5bd690fb4222"
    },
    {
        "@score": "1",
        "@id": "2737662",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "207/6588",
                        "text": "HyungSeok Han"
                    },
                    {
                        "@pid": "239/9051",
                        "text": "DongHyeon Oh"
                    },
                    {
                        "@pid": "49/8463",
                        "text": "Sang Kil Cha"
                    }
                ]
            },
            "title": "CodeAlchemist: Semantics-Aware Code Generation to Find Vulnerabilities in JavaScript Engines.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/HanOC19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/codealchemist-semantics-aware-code-generation-to-find-vulnerabilities-in-javascript-engines/",
            "url": "https://dblp.org/rec/conf/ndss/HanOC19",
            "abstract": "JavaScript engines are an attractive target for attackers due to their popularity and flexibility in building exploits. Current state-of-the-art fuzzers for finding JavaScript engine vulnerabilities focus mainly on generating syntactically correct test cases based on either a predefined context-free grammar or a trained probabilistic language model. Unfortunately, syntactically correct JavaScript sentences are often semantically invalid at runtime. Furthermore, statically analyzing the semantics of JavaScript code is challenging due to its dynamic nature: JavaScript code is generated at runtime, and JavaScript expressions are dynamically-typed. To address this challenge, we propose a novel test case generation algorithm that we call semantics-aware assembly, and implement it in a fuzz testing tool termed CodeAlchemist. Our tool can generate arbitrary JavaScript code snippets that are both semantically and syntactically correct, and it effectively yields test cases that can crash JavaScript engines. We found numerous vulnerabilities of the latest JavaScript engines with CodeAlchemist and reported them to the vendors.",
            "keywords": [
                "JavaScript Engine Vulnerabilities",
                "Fuzz Testing",
                "Semantics-Aware Code Generation",
                "Dynamic Typing",
                "Test Case Generation"
            ]
        },
        "url": "URL#2737662",
        "sema_paperId": "c2a6a4b6be2dabfcae7e17f2b02b6b29e03a8277"
    },
    {
        "@score": "1",
        "@id": "2737663",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "184/8086",
                        "text": "Wajih Ul Hassan"
                    },
                    {
                        "@pid": "162/3606",
                        "text": "Shengjian Guo"
                    },
                    {
                        "@pid": "95/7132-1",
                        "text": "Ding Li 0001"
                    },
                    {
                        "@pid": "14/3744",
                        "text": "Zhengzhang Chen"
                    },
                    {
                        "@pid": "36/10085",
                        "text": "Kangkook Jee"
                    },
                    {
                        "@pid": "55/4022",
                        "text": "Zhichun Li"
                    },
                    {
                        "@pid": "126/3601",
                        "text": "Adam Bates 0001"
                    }
                ]
            },
            "title": "NoDoze: Combatting Threat Alert Fatigue with Automated Provenance Triage.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/HassanGLCJL019",
            "ee": "https://www.ndss-symposium.org/ndss-paper/nodoze-combatting-threat-alert-fatigue-with-automated-provenance-triage/",
            "url": "https://dblp.org/rec/conf/ndss/HassanGLCJL019",
            "abstract": "\u2014Large enterprises are increasingly relying on threat detection softwares (e.g., Intrusion Detection Systems) to allow them to spot suspicious activities. These softwares generate alerts which must be investigated by cyber analysts to \ufb01gure out if they are true attacks. Unfortunately, in practice, there are more alerts than cyber analysts can properly investigate. This leads to a \u201cthreat alert fatigue\u201d or information overload problem where cyber analysts miss true attack alerts in the noise of false alarms. In this paper, we present N O D OZE to combat this challenge using contextual and historical information of generated threat alert. N O D OZE \ufb01rst generates a causal dependency graph of an alert event. Then, it assigns an anomaly score to each edge in the dependency graph based on the frequency with which related events have happened before in the enterprise. N O D OZE then propagates those scores along the neighboring edges of the graph using a novel network diffusion algorithm and generates an aggregate anomaly score which is used for triaging. We deployed and evaluated N O D OZE at NEC Labs America. Evaluation on our dataset of 364 threat alerts shows that N O D OZE consistently ranked the true alerts higher than the false alerts based on aggregate anomaly scores. Further, through the introduction of a cutoff threshold for anomaly scores, we estimate that our system decreases the volume of false alarms by 84%, saving analysts\u2019 more than 90 hours of investigation time per week. N O D OZE generates alert dependency graphs that are two orders of magnitude smaller than those generated by traditional tools without sacri\ufb01cing the vital information needed for the investigation. Our system has a low average runtime overhead and can be deployed with any threat detection software.",
            "keywords": [
                "Threat Detection",
                "Alert Fatigue",
                "Anomaly Scoring",
                "Causal Dependency Graph",
                "Automated Triage"
            ]
        },
        "url": "URL#2737663",
        "sema_paperId": "dfe5a726609c318baf509af7cf41bf3840884c0b"
    },
    {
        "@score": "1",
        "@id": "2737664",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "45/1437",
                        "text": "Cormac Herley"
                    },
                    {
                        "@pid": "s/SESchechter",
                        "text": "Stuart E. Schechter"
                    }
                ]
            },
            "title": "Distinguishing Attacks from Legitimate Authentication Traffic at Scale.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/HerleyS19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/distinguishing-attacks-from-legitimate-authentication-traffic-at-scale/",
            "url": "https://dblp.org/rec/conf/ndss/HerleyS19",
            "abstract": "Online guessing attacks against password servers can be hard to address. Approaches that throttle or block repeated guesses on an account (e.g., three strikes type lockout rules) can be effective against depth-first attacks, but are of little help against breadth-first attacks that spread guesses very widely. At large providers with tens, or hundreds, of millions of accounts breadth-first attacks offer a way to send millions or even billions of guesses without ever triggering the depth-first defenses. The absence of labels and non-stationarity of attack traffic make it challenging to apply machine learning techniques. We show how to accurately estimate the odds that an observation x indicates that a request is malicious. Our main assumptions are that successful malicious logins are a small fraction of the total, and that the distribution of x in the legitimate traffic is stationary, or very-slowly varying. From these we show how we can estimate the ratio of bad-to-good traffic among any set of requests; how we can then identify subsets of the request data that contain least (or even no) attack traffic; how these leastattacked subsets allow us to estimate the distribution of values of x over the legitimate data, and hence calculate the odds ratio. A sensitivity analysis shows that even when we fail to identify a subset with little attack traffic our odds ratio estimates are very robust.",
            "keywords": [
                "Authentication Traffic Analysis",
                "Online Guessing Attacks",
                "Breadth-First Attacks",
                "Malicious Login Detection",
                "Odds Ratio Estimation"
            ]
        },
        "url": "URL#2737664",
        "sema_paperId": "df83171fa17fde9d151443ebbab97d91a3637b3b"
    },
    {
        "@score": "1",
        "@id": "2737665",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "205/2182",
                        "text": "Stephen Herwig"
                    },
                    {
                        "@pid": "205/2133",
                        "text": "Katura Harvey"
                    },
                    {
                        "@pid": "205/2195",
                        "text": "George Hughey"
                    },
                    {
                        "@pid": "140/7944",
                        "text": "Richard Roberts"
                    },
                    {
                        "@pid": "03/6428",
                        "text": "Dave Levin"
                    }
                ]
            },
            "title": "Measurement and Analysis of Hajime, a Peer-to-peer IoT Botnet.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/HerwigHHRL19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/measurement-and-analysis-of-hajime-a-peer-to-peer-iot-botnet/",
            "url": "https://dblp.org/rec/conf/ndss/HerwigHHRL19",
            "abstract": "The Internet of Things (IoT) introduces an unprecedented diversity and ubiquity to networked computing. It also introduces new attack surfaces that are a boon to attackers. The recent Mirai botnet showed the potential and power of a collection of compromised IoT devices. A new botnet, known as Hajime, targets many of the same devices as Mirai, but differs considerably in its design and operation. Hajime uses a public peer-to-peer system as its command and control infrastructure, and regularly introduces new exploits, thereby increasing its resilience. We show that Hajime\u2019s distributed design makes it a valuable tool for better understanding IoT botnets. For instance, Hajime cleanly separates its bots into different peer groups depending on their underlying hardware architecture. Through detailed measurement\u2014active scanning of Hajime\u2019s peer-to-peer infrastructure and passive, longitudinal collection of root DNS backscatter traffic\u2014we show that Hajime can be used as a lens into how IoT botnets operate, what kinds of devices they compromise, and what countries are more (or less) susceptible. Our results show that there are more compromised IoT devices than previously reported; that these devices use an assortment of CPU architectures, the popularity of which varies widely by country; that churn is high among IoT devices; and that new exploits can quickly and drastically increase the size and power of IoT botnets. Our code and data are available to assist future efforts to measure and mitigate the growing threat of IoT botnets.",
            "keywords": [
                "IoT Botnets",
                "Peer-to-Peer Networks",
                "Hajime",
                "Device Compromise",
                "Exploit Resilience"
            ]
        },
        "url": "URL#2737665",
        "sema_paperId": "0da2cf33a83b342e93f3e7e20ca281a6e9018d83"
    },
    {
        "@score": "1",
        "@id": "2737666",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "83/7270",
                        "text": "Syed Rafiul Hussain"
                    },
                    {
                        "@pid": "239/8831",
                        "text": "Mitziu Echeverria"
                    },
                    {
                        "@pid": "53/7986",
                        "text": "Omar Chowdhury"
                    },
                    {
                        "@pid": "l/NinghuiLi",
                        "text": "Ninghui Li"
                    },
                    {
                        "@pid": "b/ElisaBertino",
                        "text": "Elisa Bertino"
                    }
                ]
            },
            "title": "Privacy Attacks to the 4G and 5G Cellular Paging Protocols Using Side Channel Information.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/HussainECLB19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/privacy-attacks-to-the-4g-and-5g-cellular-paging-protocols-using-side-channel-information/",
            "url": "https://dblp.org/rec/conf/ndss/HussainECLB19",
            "abstract": "\u2014The cellular paging (broadcast) protocol strives to balance between a cellular device\u2019s energy consumption and quality-of-service by allowing the device to only periodically poll for pending services in its idle, low-power state. For a given cellular device and serving network, the exact time periods when the device polls for services (called the paging occasion ) are \ufb01xed by design in the 4G/5G cellular protocol. In this paper, we show that the \ufb01xed nature of paging occasions can be exploited by an adversary in the vicinity of a victim to associate the victim\u2019s soft- identity (e.g., phone number, Twitter handle) with its paging occasion, with only a modest cost, through an attack dubbed ToRPEDO . Consequently, ToRPEDO can enable an adversary to verify a victim\u2019s coarse-grained location information, inject fabricated paging messages, and mount denial-of-service attacks. We also demonstrate that, in 4G and 5G, it is plausible for an adversary to retrieve a victim device\u2019s persistent identity (i.e., IMSI) with a brute-force IMSI-Cracking attack while using ToRPEDO as an attack sub-step. Our further investigation on 4G paging protocol deployments also identi\ufb01ed an implementation oversight of several network providers which enables the adversary to launch an attack, named PIERCER , for associating a victim\u2019s phone number with its IMSI; subsequently allowing targeted user location tracking. All of our attacks have been validated and evaluated in the wild using commodity hardware and software. We \ufb01nally discuss potential countermeasures against the presented attacks.",
            "keywords": [
                "Cellular Paging Protocol",
                "Privacy Attacks",
                "ToRPEDO",
                "IMSI-Cracking",
                "Location Tracking"
            ]
        },
        "url": "URL#2737666",
        "sema_paperId": "f6eacd8b4b275d839137d30282fb89dd86da4709"
    },
    {
        "@score": "1",
        "@id": "2737667",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "185/1661",
                        "text": "Gabriel Kaptchuk"
                    },
                    {
                        "@pid": "74/4531-1",
                        "text": "Matthew Green 0001"
                    },
                    {
                        "@pid": "129/9500",
                        "text": "Ian Miers"
                    }
                ]
            },
            "title": "Giving State to the Stateless: Augmenting Trustworthy Computation with Ledgers.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/Kaptchuk0M19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/giving-state-to-the-stateless-augmenting-trustworthy-computation-with-ledgers/",
            "url": "https://dblp.org/rec/conf/ndss/Kaptchuk0M19",
            "abstract": "In this work we investigate new computational properties that can be achieved by combining stateless trusted devices with public ledgers. We consider a hybrid paradigm in which a client-side device (such as a co-processor or trusted enclave) performs secure computation, while interacting with a public ledger via a possibly malicious host computer. We explore both the constructive and potentially destructive implications of such systems. We first show that this combination allows for the construction of stateful interactive functionalities (including general computation) even when the device has no persistent storage; this allows us to build sophisticated applications using inexpensive trusted hardware or even pure cryptographic obfuscation techniques. We further show how to use this paradigm to achieve censorship-resistant communication with a network, even when network communications are mediated by a potentially malicious host. Finally we describe a number of practical applications that can be achieved today. These include the synchronization of private smart contracts; rate limited mandatory logging; strong encrypted backups from weak passwords; enforcing fairness in multi-party computation; and destructive applications such as autonomous ransomware, which allows for payments without an online party.",
            "keywords": [
                "Trusted Computation",
                "Public Ledgers",
                "Stateless Devices",
                "Censorship-Resistant Communication",
                "Stateful Interactive Functionalities"
            ]
        },
        "url": "URL#2737667",
        "sema_paperId": "9976dbd5b66e2bd166526a7a2905963cc2b0f614"
    },
    {
        "@score": "1",
        "@id": "2737668",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "149/9887",
                        "text": "Anastasis Keliris"
                    },
                    {
                        "@pid": "56/1494",
                        "text": "Michail Maniatakos"
                    }
                ]
            },
            "title": "ICSREF: A Framework for Automated Reverse Engineering of Industrial Control Systems Binaries.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/KelirisM19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/icsref-a-framework-for-automated-reverse-engineering-of-industrial-control-systems-binaries/",
            "url": "https://dblp.org/rec/conf/ndss/KelirisM19",
            "abstract": "The security of Industrial Control Systems (ICS) has been attracting increased attention over the past years, following the discovery of real threats targeting industrial environments. Despite this attention, automation of the reverse engineering process of ICS binaries for programmable logic controllers remains an open problem, mainly due to the use of proprietary compilers by ICS vendors. Such automation could be a double-edged sword; on the one hand it could accelerate digital forensic investigations and incident response actions, while on the other hand it could enable dynamic generation of malicious ICS payloads. In this work, we propose a structured methodology that automates the reverse engineering process for ICS binaries taking into account their unique domain-specific characteristics. We apply this methodology to develop the modular Industrial Control Systems Reverse Engineering Framework (ICSREF), and instantiate ICSREF modules for reversing binaries compiled with CODESYS, a widely used software stack and compiler for PLCs. To evaluate our framework we create a database of samples by collecting real PLC binaries from public code repositories, as well as developing binaries in-house. Our results demonstrate that ICSREF can successfully handle diverse PLC binaries from varied industry sectors, irrespective of the programming language used. Furthermore, we deploy ICSREF on a commercial smartphone which orchestrates and launches a completely automated process-aware attack against a chemical process testbed. This example of dynamic payload generation showcases how ICSREF can enable sophisticated attacks without any prior knowledge.",
            "keywords": [
                "Industrial Control Systems",
                "Reverse Engineering",
                "PLC Binaries",
                "Automated Analysis",
                "Dynamic Payload Generation"
            ]
        },
        "url": "URL#2737668",
        "sema_paperId": "8b6a1067e9698a603edc45e06a23f10ff86d707b"
    },
    {
        "@score": "1",
        "@id": "2737669",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "98/3396",
                        "text": "Amit Klein 0001"
                    },
                    {
                        "@pid": "31/1735",
                        "text": "Benny Pinkas"
                    }
                ]
            },
            "title": "DNS Cache-Based User Tracking.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/KleinP19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/dns-cache-based-user-tracking/",
            "url": "https://dblp.org/rec/conf/ndss/KleinP19",
            "abstract": "We describe a novel user tracking technique that is based on assigning statistically unique DNS records per user. This new tracking technique is unique in being able to distinguish between machines that have identical hardware and software, and track users even if they use \u201cprivacy mode\u201d browsing, or use multiple browsers (on the same machine).\nThe technique overcomes issues related to the caching of DNS answers in resolvers, and utilizes per-device caching of DNS answers at the client. We experimentally demonstrate that it covers the technologies used by a very large fraction of Internet users (in terms of browsers, operating systems, and DNS resolution platforms).\nOur technique can track users for up to a day (typically), and therefore works best when combined with other, narrower yet longer-lived techniques such as regular cookies - we briefly\nexplain how to combine such techniques.\nWe suggest mitigations to this tracking technique but note that it is not easily mitigated. There are possible workarounds, yet these are not without setup overhead, performance overhead or convenience overhead. A complete mitigation requires software modifications in both browsers and resolver software.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2019/02/ndss2019_04B-4_Klein_paper.pdf",
            "keywords": [
                "DNS Cache Tracking",
                "User Tracking Techniques",
                "Privacy Mode Browsing",
                "Statistically Unique DNS Records",
                "Mitigation Strategies"
            ]
        },
        "url": "URL#2737669",
        "sema_paperId": "63ac36de7f805076bf538c0c4690784fd4637ef2"
    },
    {
        "@score": "1",
        "@id": "2737670",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "155/5132",
                        "text": "Katharina Kohls"
                    },
                    {
                        "@pid": "185/1682",
                        "text": "Kai Jansen"
                    },
                    {
                        "@pid": "77/2192",
                        "text": "David Rupprecht"
                    },
                    {
                        "@pid": "h/ThorstenHolz",
                        "text": "Thorsten Holz"
                    },
                    {
                        "@pid": "11/3019",
                        "text": "Christina P\u00f6pper"
                    }
                ]
            },
            "title": "On the Challenges of Geographical Avoidance for Tor.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/KohlsJRHP19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/on-the-challenges-of-geographical-avoidance-for-tor/",
            "url": "https://dblp.org/rec/conf/ndss/KohlsJRHP19",
            "abstract": "Traffic-analysis attacks are a persisting threat for Tor users. When censors or law enforcement agencies try to identify users, they conduct traffic-confirmation attacks and monitor encrypted transmissions to extract metadata\u2014in combination with routing attacks, these attacks become sufficiently powerful to de-anonymize users. While traffic-analysis attacks are hard to detect and expensive to counter in practice, geographical avoidance provides an option to reject circuits that might be routed through an untrusted area. Unfortunately, recently proposed solutions introduce severe security issues by imprudent design decisions. In this paper, we approach geographical avoidance starting from a thorough assessment of its challenges. These challenges serve as the foundation for the design of an empirical avoidance concept that considers actual transmission characteristics for justified decisions. Furthermore, we address the problems of untrusted or intransparent ground truth information that hinder a reliable assessment of circuits. Taking these features into account, we conduct an empirical simulation study and compare the performance of our novel avoidance concept with existing approaches. Our results show that we outperform existing systems by 22% fewer rejected circuits, which reduces the collateral damage of overly restrictive avoidance decisions. In a second evaluation step, we extend our initial system concept and implement the prototype TrilateraTor. This prototype is the first to satisfy the requirements of a practical deployment, as it maintains Tor\u2019s original level of security, provides reasonable performance, and overcomes the fundamental security flaws of existing systems.",
            "keywords": [
                "Tor Network",
                "Traffic-Analysis Attacks",
                "Geographical Avoidance",
                "Circuit Routing",
                "TrilateraTor Prototype"
            ]
        },
        "url": "URL#2737670",
        "sema_paperId": "d77a25a1f465ada0ed8207db697a94c97fcb8d78"
    },
    {
        "@score": "1",
        "@id": "2737671",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "44/10958",
                        "text": "Platon Kotzias"
                    },
                    {
                        "@pid": "15/6037",
                        "text": "Leyla Bilge"
                    },
                    {
                        "@pid": "122/8629",
                        "text": "Pierre-Antoine Vervier"
                    },
                    {
                        "@pid": "35/3587",
                        "text": "Juan Caballero"
                    }
                ]
            },
            "title": "Mind Your Own Business: A Longitudinal Study of Threats and Vulnerabilities in Enterprises.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/KotziasBVC19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/mind-your-own-business-a-longitudinal-study-of-threats-and-vulnerabilities-in-enterprises/",
            "url": "https://dblp.org/rec/conf/ndss/KotziasBVC19",
            "abstract": "\u2014Enterprises own a signi\ufb01cant fraction of the hosts connected to the Internet and possess valuable assets, such as \ufb01nancial data and intellectual property, which may be targeted by attackers. They suffer attacks that exploit unpatched hosts and install malware, resulting in breaches that may cost millions in damages. Despite the scale of this phenomenon, the threat and vulnerability landscape of enterprises remains under-studied. The security posture of enterprises remains unclear, and it\u2019s unknown whether enterprises are indeed more secure than consumer hosts. To address these questions, we perform the largest and longest enterprise security study up to date. Our data covers nearly 3 years and is collected from 28K enterprises, belonging to 67 industries, which own 82M hosts and 73M public-facing servers. Our measurements comprise of two parts: an analysis of the threat landscape and an analysis of the enterprise vulnerability patching behavior. The threat landscape analysis \ufb01rst classi\ufb01es low reputation \ufb01les observed in enterprise hosts into families. Then, it measures, among others, that 91%\u201397% of the enterprises, 13%\u201341% of the enterprise hosts, encountered at least one malware or PUP \ufb01le over the length of our study; that enterprises encounter malware much more often than PUP; and that some industries like banks and consumer \ufb01nances are doing notoriously better, achieving signi\ufb01cantly lower malware and PUP encounter rates than the most-affected industries. The vulnerability analysis examines the patching of 12 client-side and 112 server-side applications in enterprise hosts and servers. It measures, among others, that it takes over 6 months on average to patch 90% of the population across all vulnerabilities in the 12 client-side applications; that enterprise computers are faster to patch vulnerabilities compared to consumer hosts; and that the patching of server applications is much worse than the patching of client-side applications.",
            "keywords": [
                "Enterprise Security",
                "Threat Landscape",
                "Vulnerability Patching",
                "Malware Encounter Rates",
                "Enterprise Hosts"
            ]
        },
        "url": "URL#2737671",
        "sema_paperId": "6c1c79acc5587f7265bb33a39a22ce13fe69a399"
    },
    {
        "@score": "1",
        "@id": "2737672",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "78/6080",
                        "text": "Jaeho Lee"
                    },
                    {
                        "@pid": "59/146-1",
                        "text": "Ang Chen 0001"
                    },
                    {
                        "@pid": "w/DanSWallach",
                        "text": "Dan S. Wallach"
                    }
                ]
            },
            "title": "Total Recall: Persistence of Passwords in Android.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/LeeCW19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/total-recall-persistence-of-passwords-in-android/",
            "url": "https://dblp.org/rec/conf/ndss/LeeCW19",
            "abstract": "A good security practice for handling sensitive data, such as passwords, is to overwrite the data buffers with zeros once the data is no longer in use. This protects against attackers who gain a snapshot of a device\u2019s physical memory, whether by inperson physical attacks, or by remote attacks like Meltdown and Spectre. This paper looks at unnecessary password retention in Android phones by popular apps, secure password management apps, and even the lockscreen system process. We have performed a comprehensive analysis of the Android framework and a variety of apps, and discovered that passwords can survive in a variety of locations, including UI widgets where users enter their passwords, apps that retain passwords rather than exchange them for tokens, old copies not yet reused by garbage collectors, and buffers in keyboard apps. We have developed solutions that successfully fix these problems with modest code changes.",
            "keywords": [
                "Android Security",
                "Password Management",
                "Data Persistence",
                "Memory Safety",
                "Sensitive Data Handling"
            ]
        },
        "url": "URL#2737672",
        "sema_paperId": "60c5e8e3cbd4f79296094e6479538ab83c0386c4"
    },
    {
        "@score": "1",
        "@id": "2737673",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "55/8846-1",
                        "text": "Hyunwoo Lee 0001"
                    },
                    {
                        "@pid": "224/2399",
                        "text": "Zach Smith"
                    },
                    {
                        "@pid": "239/8917",
                        "text": "Junghwan Lim"
                    },
                    {
                        "@pid": "239/9042",
                        "text": "Gyeongjae Choi"
                    },
                    {
                        "@pid": "217/4431",
                        "text": "Selin Chun"
                    },
                    {
                        "@pid": "90/8396",
                        "text": "Taejoong Chung"
                    },
                    {
                        "@pid": "14/2293-1",
                        "text": "Ted Taekyoung Kwon"
                    }
                ]
            },
            "title": "maTLS: How to Make TLS middlebox-aware?",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/LeeSLCCCK19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/matls-how-to-make-tls-middlebox-aware/",
            "url": "https://dblp.org/rec/conf/ndss/LeeSLCCCK19",
            "abstract": "\u2014Middleboxes are widely deployed in order to enhance security and performance in networking. As communication over TLS becomes increasingly common, however, the end-to-end channel model of TLS undermines the ef\ufb01cacy of middleboxes. Existing solutions, such as \u2018SplitTLS\u2019, which in-tercepts TLS sessions, often introduce signi\ufb01cant security risks by installing a custom root certi\ufb01cate or sharing a private key. Many studies have con\ufb01rmed security vulnerabilities when combining TLS with middleboxes, which include certi\ufb01cate validation failures, use of obsolete ciphersuites, and unwanted content modi\ufb01cation. To address the above issues, we introduce a middlebox-aware TLS protocol, dubbed maTLS, which allows middleboxes to participate in the TLS session in a visible and auditable fashion. Every participating middlebox now splits a session into two segments with their own security parameters in collaboration with the two endpoints. The maTLS protocol is designed to authenticate the middleboxes to verify the security parameters of segments, and to audit the middleboxes\u2019 write operations. Thus, security of the session is ensured. We prove the security model of maTLS by using Tamarin, a state-of-the-art security veri\ufb01cation tool. We also carry out testbed-based experiments to show that maTLS achieves the above security goals with marginal overhead.",
            "keywords": [
                "Middlebox-aware TLS",
                "TLS Protocol",
                "Security Parameters",
                "Session Segmentation",
                "Auditable Middleboxes"
            ]
        },
        "url": "URL#2737673",
        "sema_paperId": "447d0561ae8d7b5f8c96ead94d4ac18acc27a349"
    },
    {
        "@score": "1",
        "@id": "2737674",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "163/3449",
                        "text": "Seunghyeon Lee"
                    },
                    {
                        "@pid": "164/1673",
                        "text": "Changhoon Yoon"
                    },
                    {
                        "@pid": "164/1777",
                        "text": "Heedo Kang"
                    },
                    {
                        "@pid": "177/3037",
                        "text": "Yeonkeun Kim"
                    },
                    {
                        "@pid": "20/6892",
                        "text": "Yongdae Kim"
                    },
                    {
                        "@pid": "12/5388",
                        "text": "Dongsu Han"
                    },
                    {
                        "@pid": "09/3668",
                        "text": "Sooel Son"
                    },
                    {
                        "@pid": "84/3319-1",
                        "text": "Seungwon Shin 0001"
                    }
                ]
            },
            "title": "Cybercriminal Minds: An investigative study of cryptocurrency abuses in the Dark Web.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/LeeYKKKHSS19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/cybercriminal-minds-an-investigative-study-of-cryptocurrency-abuses-in-the-dark-web/",
            "url": "https://dblp.org/rec/conf/ndss/LeeYKKKHSS19",
            "abstract": "The Dark Web is notorious for being a major distribution channel of harmful content as well as unlawful goods. Perpetrators have also used cryptocurrencies to conduct illicit financial transactions while hiding their identities. The limited coverage and outdated data of the Dark Web in previous studies motivated us to conduct an in-depth investigative study to understand how perpetrators abuse cryptocurrencies in the Dark Web. We designed and implemented MFScope, a new framework which collects Dark Web data, extracts cryptocurrency information, and analyzes their usage characteristics on the Dark Web. Specifically, MFScope collected more than 27 million dark webpages and extracted around 10 million unique cryptocurrency addresses for Bitcoin, Ethereum, and Monero. It then classified their usages to identify trades of illicit goods and traced cryptocurrency money flows, to reveal black money operations on the Dark Web. In total, using MFScope we discovered that more than 80% of Bitcoin addresses on the Dark Web were used with malicious intent; their monetary volume was around 180 million USD, and they sent a large sum of their money to several popular cryptocurrency services (e.g., exchange services). Furthermore, we present two real-world unlawful services and demonstrate their Bitcoin transaction traces, which helps in understanding their marketing strategy as well as black money operations.",
            "keywords": [
                "Dark Web",
                "Cryptocurrency Abuse",
                "Illicit Transactions",
                "Money Laundering",
                "Malicious Intent"
            ]
        },
        "url": "URL#2737674",
        "sema_paperId": "45b7ecc4f3ac21b02ebe64c5f9ec103e7ceae2c0"
    },
    {
        "@score": "1",
        "@id": "2737675",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "20/6946",
                        "text": "Derek Leung"
                    },
                    {
                        "@pid": "216/6745",
                        "text": "Adam Suhl"
                    },
                    {
                        "@pid": "84/7357",
                        "text": "Yossi Gilad"
                    },
                    {
                        "@pid": "99/5780",
                        "text": "Nickolai Zeldovich"
                    }
                ]
            },
            "title": "Vault: Fast Bootstrapping for the Algorand Cryptocurrency.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/LeungSGZ19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/vault-fast-bootstrapping-for-the-algorand-cryptocurrency/",
            "url": "https://dblp.org/rec/conf/ndss/LeungSGZ19",
            "abstract": "Decentralized cryptocurrencies rely on participants to keep track of the state of the system in order to verify new transactions. As the number of users and transactions grows, this requirement becomes a significant burden, requiring users to download, verify, and store a large amount of data to participate. Vault is a new cryptocurrency design based on Algorand that minimizes these storage and bootstrapping costs for participants. Vault\u2019s design is based on Algorand\u2019s proof-of-stake consensus protocol and uses several techniques to achieve its goals. First, Vault decouples the storage of recent transactions from the storage of account balances, which enables Vault to delete old account state. Second, Vault allows sharding state across participants in a way that preserves strong security guarantees. Finally, Vault introduces the notion of stamping certificates, which allow a new client to catch up securely and efficiently in a proofof-stake system without having to verify every single block. Experiments with a prototype implementation of Vault\u2019s data structures show that Vault\u2019s design reduces the bandwidth cost of joining the network as a full client by 99.7% compared to Bitcoin and 90.5% compared to Ethereum when downloading a ledger containing 500 million transactions.",
            "keywords": [
                "Cryptocurrency Design",
                "Algorand",
                "Bootstrapping Costs",
                "Transaction Storage",
                "Proof-of-Stake Consensus"
            ]
        },
        "url": "URL#2737675",
        "sema_paperId": "4c158535a4ab37ac50cac32820d459b04becef02"
    },
    {
        "@score": "1",
        "@id": "2737676",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "76/7842",
                        "text": "Jinfeng Li"
                    },
                    {
                        "@pid": "07/8388",
                        "text": "Shouling Ji"
                    },
                    {
                        "@pid": "128/2982",
                        "text": "Tianyu Du"
                    },
                    {
                        "@pid": "50/3402-26",
                        "text": "Bo Li 0026"
                    },
                    {
                        "@pid": "12/2633-6",
                        "text": "Ting Wang 0006"
                    }
                ]
            },
            "title": "TextBugger: Generating Adversarial Text Against Real-world Applications.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/LiJDLW19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/textbugger-generating-adversarial-text-against-real-world-applications/",
            "url": "https://dblp.org/rec/conf/ndss/LiJDLW19",
            "abstract": "Deep Learning-based Text Understanding (DLTU) is the backbone technique behind various applications, including question answering, machine translation, and text classification. Despite its tremendous popularity, the security vulnerabilities of DLTU are still largely unknown, which is highly concerning given its increasing use in security-sensitive applications such as user sentiment analysis and toxic content detection. In this paper, we show that DLTU is inherently vulnerable to adversarial text attacks, in which maliciously crafted text triggers target DLTU systems and services to misbehave. Specifically, we present TextBugger, a general attack framework for generating adversarial text. In contrast of prior work, TextBugger differs in significant ways: (i) effective -- it outperforms state-of-the-art attacks in terms of attack success rate; (ii) evasive -- it preserves the utility of benign text, with 94.9% of the adversarial text correctly recognized by human readers; and (iii) efficient -- it generates adversarial text with computational complexity sub-linear to the text length. We empirically evaluate TextBugger on a set of real-world DLTU systems and services used for sentiment analysis and toxic content detection, demonstrating its effectiveness, evasiveness, and efficiency. For instance, TextBugger achieves 100% success rate on the IMDB dataset based on Amazon AWS Comprehend within 4.61 seconds and preserves 97% semantic similarity. We further discuss possible defense mechanisms to mitigate such attack and the adversary's potential countermeasures, which leads to promising directions for further research.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2019/02/ndss2019_03A-5_Li_paper.pdf",
            "keywords": [
                "Adversarial Text Generation",
                "Deep Learning Text Understanding",
                "Text Classification Vulnerabilities",
                "Sentiment Analysis Attacks",
                "TextBugger Framework"
            ]
        },
        "url": "URL#2737676"
    },
    {
        "@score": "1",
        "@id": "2737677",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "34/8146-1",
                        "text": "Shasha Li 0001"
                    },
                    {
                        "@pid": "154/7852",
                        "text": "Ajaya Neupane"
                    },
                    {
                        "@pid": "138/6200",
                        "text": "Sujoy Paul"
                    },
                    {
                        "@pid": "69/6818",
                        "text": "Chengyu Song"
                    },
                    {
                        "@pid": "k/SrikanthVKrishnamurthy",
                        "text": "Srikanth V. Krishnamurthy"
                    },
                    {
                        "@pid": "c/AmitKRoyChowdhury",
                        "text": "Amit K. Roy-Chowdhury"
                    },
                    {
                        "@pid": "89/5072",
                        "text": "Ananthram Swami"
                    }
                ]
            },
            "title": "Stealthy Adversarial Perturbations Against Real-Time Video Classification Systems.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/LiNPSKRS19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/stealthy-adversarial-perturbations-against-real-time-video-classification-systems/",
            "url": "https://dblp.org/rec/conf/ndss/LiNPSKRS19",
            "abstract": "Recent research has demonstrated the brittleness of machine learning systems to adversarial perturbations. However, the studies have been mostly limited to perturbations on images and more generally, classification that does not deal with temporally varying inputs. In this paper we ask \"Are adversarial perturbations possible in real-time video classification systems and if so, what properties must they satisfy?\" Such systems find application in surveillance applications, smart vehicles, and smart elderly care and thus, misclassification could be particularly harmful (e.g., a mishap at an elderly care facility may be missed). We show that accounting for temporal structure is key to generating adversarial examples in such systems. We exploit recent advances in generative adversarial network (GAN) architectures to account for temporal correlations and generate adversarial samples that can cause misclassification rates of over 80% for targeted activities. More importantly, the samples also leave other activities largely unaffected making them extremely stealthy. Finally, we also surprisingly find that in many scenarios, the same perturbation can be applied to every frame in a video clip that makes the adversary's ability to achieve misclassification relatively easy.",
            "keywords": [
                "Adversarial Perturbations",
                "Video Classification",
                "Temporal Structure",
                "Generative Adversarial Networks",
                "Stealthy Misclassification"
            ]
        },
        "url": "URL#2737677",
        "sema_paperId": "119a62a685aed7e94234a2ac4b16636c744b04a6"
    },
    {
        "@score": "1",
        "@id": "2737678",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "16/3121-2",
                        "text": "Meng Luo 0002"
                    },
                    {
                        "@pid": "167/2160",
                        "text": "Pierre Laperdrix"
                    },
                    {
                        "@pid": "15/3991",
                        "text": "Nima Honarmand"
                    },
                    {
                        "@pid": "04/8280",
                        "text": "Nick Nikiforakis"
                    }
                ]
            },
            "title": "Time Does Not Heal All Wounds: A Longitudinal Analysis of Security-Mechanism Support in Mobile Browsers.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/LuoLHN19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/time-does-not-heal-all-wounds-a-longitudinal-analysis-of-security-mechanism-support-in-mobile-browsers/",
            "url": "https://dblp.org/rec/conf/ndss/LuoLHN19",
            "abstract": "\u2014Recent market share statistics show that mobile device traf\ufb01c has overtaken that of traditional desktop computers. Users spend an increasing amount of time on their smartphones and tablets, while the web continues to be the platform of choice for delivering new applications to users. In this environment, it is necessary for web applications to utilize all the tools at their disposal to protect mobile users against popular web application attacks. In this paper, we perform the \ufb01rst study of the support of popular web-application security mechanisms (such as the Content-Security Policy, HTTP Strict Transport Security, and Referrer Policy) across mobile browsers. We design 395 individual tests covering 8 different security mechanisms, and utilize them to evaluate the security-mechanism support in the 20 most popular browser families on Android. Moreover, by collecting and testing browser versions from the last seven years, we evaluate a total of 351 unique browser versions against the aforementioned tests, collecting more than 138K test results. By analyzing these results, we \ufb01nd that, although mobile browsers generally support more security mechanisms over time, not all browsers evolve in the same way. We discover popular browsers, with millions of downloads, which do not support the majority of the tested mechanisms, and identify design choices, followed by the majority of browsers, which leave hundreds of popular websites open to clickjacking attacks. Moreover, we discover the presence of multi-year vulnerability windows between the time when popular websites start utilizing a security mechanism and when mobile browsers enforce it. Our \ufb01ndings highlight the need for continuous security testing of mobile web browsers, as well as server-side frameworks which can adapt to the level of security that each browser can guarantee.",
            "keywords": [
                "Mobile Web Security",
                "Browser Security Mechanisms",
                "Content-Security Policy",
                "HTTP Strict Transport Security",
                "Clickjacking Vulnerabilities"
            ]
        },
        "url": "URL#2737678",
        "sema_paperId": "72f2531e4ff40051a8e2de3dd618d3165770aff3"
    },
    {
        "@score": "1",
        "@id": "2737679",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "172/8745",
                        "text": "Shiqing Ma"
                    },
                    {
                        "@pid": "92/10048",
                        "text": "Yingqi Liu"
                    },
                    {
                        "@pid": "88/10370-1",
                        "text": "Guanhong Tao 0001"
                    },
                    {
                        "@pid": "09/4057",
                        "text": "Wen-Chuan Lee"
                    },
                    {
                        "@pid": "95/3760-1",
                        "text": "Xiangyu Zhang 0001"
                    }
                ]
            },
            "title": "NIC: Detecting Adversarial Samples with Neural Network Invariant Checking.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/MaLTL019",
            "ee": "https://www.ndss-symposium.org/ndss-paper/nic-detecting-adversarial-samples-with-neural-network-invariant-checking/",
            "url": "https://dblp.org/rec/conf/ndss/MaLTL019",
            "abstract": "\u2014Deep Neural Networks (DNN) are vulnerable to adversarial samples that are generated by perturbing correctly classi\ufb01ed inputs to cause DNN models to misbehave (e.g., misclas-si\ufb01cation). This can potentially lead to disastrous consequences especially in security-sensitive applications. Existing defense and detection techniques work well for speci\ufb01c attacks under various assumptions (e.g., the set of possible attacks are known beforehand). However, they are not suf\ufb01ciently general to protect against a broader range of attacks. In this paper, we analyze the internals of DNN models under various attacks and identify two common exploitation channels: the provenance channel and the activation value distribution channel. We then propose a novel technique to extract DNN invariants and use them to perform runtime adversarial sample detection. Our experimental results of 11 different kinds of attacks on popular datasets including ImageNet and 13 models show that our technique can effectively detect all these attacks (over 90% accuracy) with limited false positives. We also compare it with three state-of-the-art techniques including the Local Intrinsic Dimensionality (LID) based method, denoiser based methods (i.e., MagNet and HGD), and the prediction inconsistency based approach (i.e., feature squeezing). Our experiments show promising results.",
            "keywords": [
                "Adversarial Sample Detection",
                "Deep Neural Network Invariants",
                "Provenance Channel",
                "Activation Value Distribution",
                "Runtime Detection Techniques"
            ]
        },
        "url": "URL#2737679",
        "sema_paperId": "76b7b8c96971c8a4960936255a1f67fe742b04ff"
    },
    {
        "@score": "1",
        "@id": "2737680",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "148/1304",
                        "text": "Giulio Malavolta"
                    },
                    {
                        "@pid": "128/4640",
                        "text": "Pedro Moreno-Sanchez"
                    },
                    {
                        "@pid": "215/5466",
                        "text": "Clara Schneidewind"
                    },
                    {
                        "@pid": "12/3394",
                        "text": "Aniket Kate"
                    },
                    {
                        "@pid": "25/3571",
                        "text": "Matteo Maffei"
                    }
                ]
            },
            "title": "Anonymous Multi-Hop Locks for Blockchain Scalability and Interoperability.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/MalavoltaMSKM19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/anonymous-multi-hop-locks-for-blockchain-scalability-and-interoperability/",
            "url": "https://dblp.org/rec/conf/ndss/MalavoltaMSKM19",
            "abstract": "\u2014Tremendous growth in cryptocurrency usage is exposing the inherent scalability issues with permis-sionless blockchain technology. Payment-channel networks (PCNs) have emerged as the most widely deployed solution to mitigate the scalability issues, allowing the bulk of payments between two users to be carried out off-chain. Unfortunately, as reported in the literature and further demonstrated in this paper, current PCNs do not provide meaningful security and privacy guarantees [30], [40]. In this work, we study and design secure and privacy-preserving PCNs. We start with a security analysis of existing PCNs, reporting a new attack that applies to all major PCNs, including the Lightning Network, and allows an attacker to steal the fees from honest intermediaries in the same payment path. We then formally de\ufb01ne anonymous multi-hop locks (AMHLs), a novel cryptographic primitive that serves as a cornerstone for the design of secure and privacy-preserving PCNs. We present several provably secure cryptographic instantiations that make AMHLs compatible with the vast majority of cryptocurrencies. In particular, we show that (linear) homomorphic one-way functions suf\ufb01ce to construct AMHLs for PCNs supporting a script language (e.g., Ethereum). We also propose a construction based on ECDSA signatures that does not require scripts , thus solving a prominent open problem in the \ufb01eld.",
            "keywords": [
                "Blockchain Scalability",
                "Payment-Channel Networks",
                "Privacy-Preserving Protocols",
                "Anonymous Multi-Hop Locks",
                "Cryptographic Security"
            ]
        },
        "url": "URL#2737680",
        "sema_paperId": "6b8ef0bb719a23575978251dc048ef90a6e1fbd6"
    },
    {
        "@score": "1",
        "@id": "2737681",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "20/4458",
                        "text": "A. Theodore Markettos"
                    },
                    {
                        "@pid": "159/0070",
                        "text": "Colin Rothwell"
                    },
                    {
                        "@pid": "239/8902",
                        "text": "Brett F. Gutstein"
                    },
                    {
                        "@pid": "145/4019",
                        "text": "Allison Pearce"
                    },
                    {
                        "@pid": "n/PeterGNeumann",
                        "text": "Peter G. Neumann"
                    },
                    {
                        "@pid": "m/SimonWMoore",
                        "text": "Simon W. Moore"
                    },
                    {
                        "@pid": "70/2118",
                        "text": "Robert N. M. Watson"
                    }
                ]
            },
            "title": "Thunderclap: Exploring Vulnerabilities in Operating System IOMMU Protection via DMA from Untrustworthy Peripherals.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/MarkettosRGPNMW19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/thunderclap-exploring-vulnerabilities-in-operating-system-iommu-protection-via-dma-from-untrustworthy-peripherals/",
            "url": "https://dblp.org/rec/conf/ndss/MarkettosRGPNMW19",
            "abstract": "DARPA I2O FA8750-10-C-0237 (\"CTSRD\")\nDARPA MTO HR0011- 18-C-0016 (\"ECATS\")\nArm Ltd\nGoogle Inc\nThis work was also supported by EPSRC EP/R012458/1 (\u201cIOSEC\u201d).",
            "keywords": [
                "IOMMU Protection",
                "DMA Attacks",
                "Untrustworthy Peripherals",
                "Operating System Vulnerabilities",
                "Thunderclap"
            ]
        },
        "url": "URL#2737681",
        "sema_paperId": "10622c4d8319409f55c08a114446e46fb2a365be"
    },
    {
        "@score": "1",
        "@id": "2737682",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "209/8703",
                        "text": "Michael Meli"
                    },
                    {
                        "@pid": "170/7852",
                        "text": "Matthew R. McNiece"
                    },
                    {
                        "@pid": "117/3983",
                        "text": "Bradley Reaves"
                    }
                ]
            },
            "title": "How Bad Can It Git? Characterizing Secret Leakage in Public GitHub Repositories.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/MeliMR19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/how-bad-can-it-git-characterizing-secret-leakage-in-public-github-repositories/",
            "url": "https://dblp.org/rec/conf/ndss/MeliMR19",
            "abstract": "\u2014GitHub and similar platforms have made public collaborative development of software commonplace. However, a problem arises when this public code must manage authentication secrets, such as API keys or cryptographic secrets. These secrets must be kept private for security, yet common development practices like adding these secrets to code make accidental leakage frequent. In this paper, we present the \ufb01rst large-scale and longitudinal analysis of secret leakage on GitHub. We examine billions of \ufb01les collected using two complementary approaches: a nearly six-month scan of real-time public GitHub commits and a public snapshot covering 13% of open-source repositories. We focus on private key \ufb01les and 11 high-impact platforms with distinctive API key formats. This focus allows us to develop conservative detection techniques that we manually and automatically evaluate to ensure accurate results. We \ufb01nd that not only is secret leakage pervasive \u2014 affecting over 100,000 repositories \u2014 but that thousands of new, unique secrets are leaked every day. We also use our data to explore possible root causes of leakage and to evaluate potential mitigation strategies. This work shows that secret leakage on public repository platforms is rampant and far from a solved problem, placing developers and services at persistent risk of compromise and abuse.",
            "keywords": [
                "Secret Leakage",
                "GitHub Repositories",
                "API Keys",
                "Public Code Security",
                "Mitigation Strategies"
            ]
        },
        "url": "URL#2737682",
        "sema_paperId": "e43b9221f62b9075357dc53ec3d1edf4d856a38c"
    },
    {
        "@score": "1",
        "@id": "2737683",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "187/8997",
                        "text": "Milad Nasr"
                    },
                    {
                        "@pid": "151/8595",
                        "text": "Sadegh Farhang"
                    },
                    {
                        "@pid": "22/1797",
                        "text": "Amir Houmansadr"
                    },
                    {
                        "@pid": "28/3855",
                        "text": "Jens Grossklags"
                    }
                ]
            },
            "title": "Enemy At the Gateways: Censorship-Resilient Proxy Distribution Using Game Theory.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/NasrFHG19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/enemy-at-the-gateways-censorship-resilient-proxy-distribution-using-game-theory/",
            "url": "https://dblp.org/rec/conf/ndss/NasrFHG19",
            "abstract": "A core technique used by popular proxy-based circumvention systems like Tor is to privately and selectively distribute the IP addresses of circumvention proxies among censored clients to keep them unknown to the censors. In Tor, for instance, such privately shared proxies are known as bridges. A key challenge to this mechanism is the insider attack problem: censoring agents can impersonate benign censored clients in order to learn (and then block) the privately shared circumvention proxies. To minimize the risks of the insider attack threat, in-thewild circumvention systems like Tor use various proxy assignment mechanisms in order to minimize the risk of proxy enumeration by the censors, while providing access to a large fraction of censored clients. Unfortunately, existing proxy assignment mechanisms (like the one used by Tor) are based on ad hoc heuristics that offer no theoretical guarantees and are easily evaded in practice. In this paper, we take a systematic approach to the problem of proxy distribution in circumvention systems by establishing a gametheoretic framework. We model the proxy assignment problem as a game between circumvention system operators and the censors, and use game theory to derive the optimal strategies of each of the parties. Using our framework, we derive the best (optimal) proxy assignment mechanism of a circumvention system like Tor in the presence of the strongest censorship adversary who takes her best censorship actions. We perform extensive simulations to evaluate our optimal proxy assignment algorithm under various adversarial and network settings. We show that the algorithm has superior performance compared to the state of the art, i.e., provides stronger resistance to censorship even against the strongest censorship adversary. Our study establishes a generic framework for optimal proxy assignment that can be applied to various types of circumvention systems and under various threat models. We conclude with lessons and recommendations for the design of proxy-based circumvention systems.",
            "keywords": [
                "Proxy Distribution",
                "Censorship Resistance",
                "Game Theory",
                "Insider Attack",
                "Proxy Assignment Mechanism"
            ]
        },
        "url": "URL#2737683",
        "sema_paperId": "4d2a05489282ecce3c11822815b2d9860a4c5a98"
    },
    {
        "@score": "1",
        "@id": "2737684",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "154/7852",
                        "text": "Ajaya Neupane"
                    },
                    {
                        "@pid": "25/1169",
                        "text": "Nitesh Saxena"
                    },
                    {
                        "@pid": "61/4143",
                        "text": "Leanne M. Hirshfield"
                    },
                    {
                        "@pid": "164/9614",
                        "text": "Sarah E. Bratt"
                    }
                ]
            },
            "title": "The Crux of Voice (In)Security: A Brain Study of Speaker Legitimacy Detection.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/NeupaneSHB19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/the-crux-of-voice-insecurity-a-brain-study-of-speaker-legitimacy-detection/",
            "url": "https://dblp.org/rec/conf/ndss/NeupaneSHB19",
            "abstract": "A new generation of scams has emerged that uses voice impersonation to obtain sensitive information, eavesdrop over voice calls and extort money from unsuspecting human users. Research demonstrates that users are fallible to voice impersonation attacks that exploit the current advancement in speech synthesis. In this paper, we set out to elicit a deeper understanding of such human-centered \u201cvoice hacking\u201d based on a neuro-scientific methodology (thereby corroborating and expanding the traditional behavioral-only approach in significant ways). Specifically, we investigate the neural underpinnings of voice security through functional near-infrared spectroscopy (fNIRS), a cutting-edge neuroimaging technique, that captures neural signals in both temporal and spatial domains. We design and conduct an fNIRS study to pursue a thorough investigation of users\u2019 mental processing related to speaker legitimacy detection \u2013 whether a voice sample is rendered by a target speaker, a different other human speaker or a synthesizer mimicking the speaker. We analyze the neural activity associated within this task as well as the brain areas that may control such activity. Our key insight is that there may be no statistically significant differences in the way the human brain processes the legitimate speakers vs. synthesized speakers, whereas clear differences are visible when encountering legitimate vs. different other human speakers. This finding may help to explain users\u2019 susceptibility to synthesized attacks, as seen from the behavioral self-reported analysis. That is, the impersonated synthesized voices may seem indistinguishable from the real voices in terms of both behavioral and neural perspectives. In sharp contrast, prior studies showed subconscious neural differences in other real vs. fake artifacts (e.g., paintings and websites), despite users failing to note these differences behaviorally. Overall, our work dissects the fundamental neural patterns underlying voice-based insecurity and reveals users\u2019 susceptibility to voice synthesis attacks at a biological level. We believe that this could be a significant insight for the security community suggesting that the human detection of voice synthesis attacks may not improve over time, especially given that voice synthesis techniques will likely continue to improve, calling for the design of careful machine-assisted techniques to help humans counter these attacks. *Work done while being a student at UAB",
            "keywords": [
                "Voice Impersonation",
                "Speaker Legitimacy Detection",
                "Voice Synthesis Attacks",
                "Neuroimaging",
                "Functional Near-Infrared Spectroscopy (fNIRS)"
            ]
        },
        "url": "URL#2737684",
        "sema_paperId": "dcd463b9f533a6edee85e6a974365e44a4defe2c"
    },
    {
        "@score": "1",
        "@id": "2737685",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "130/2934",
                        "text": "Panagiotis Papadopoulos"
                    },
                    {
                        "@pid": "129/9582",
                        "text": "Panagiotis Ilia"
                    },
                    {
                        "@pid": "09/1231",
                        "text": "Michalis Polychronakis"
                    },
                    {
                        "@pid": "m/EvangelosPMarkatos",
                        "text": "Evangelos P. Markatos"
                    },
                    {
                        "@pid": "33/2939",
                        "text": "Sotiris Ioannidis"
                    },
                    {
                        "@pid": "41/2735",
                        "text": "Giorgos Vasiliadis"
                    }
                ]
            },
            "title": "Master of Web Puppets: Abusing Web Browsers for Persistent and Stealthy Computation.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/PapadopoulosIPM19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/master-of-web-puppets-abusing-web-browsers-for-persistent-and-stealthy-computation/",
            "url": "https://dblp.org/rec/conf/ndss/PapadopoulosIPM19",
            "abstract": "The proliferation of web applications has essentially transformed modern browsers into small but powerful operating systems. Upon visiting a website, user devices run implicitly trusted script code, the execution of which is confined within the browser to prevent any interference with the user's system. Recent JavaScript APIs, however, provide advanced capabilities that not only enable feature-rich web applications, but also allow attackers to perform malicious operations despite the confined nature of JavaScript code execution. In this paper, we demonstrate the powerful capabilities that modern browser APIs provide to attackers by presenting MarioNet: a framework that allows a remote malicious entity to control a visitor's browser and abuse its resources for unwanted computation or harmful operations, such as cryptocurrency mining, password-cracking, and DDoS. MarioNet relies solely on already available HTML5 APIs, without requiring the installation of any additional software. In contrast to previous browser-based botnets, the persistence and stealthiness characteristics of MarioNet allow the malicious computations to continue in the background of the browser even after the user closes the window or tab of the initial malicious website. We present the design, implementation, and evaluation of a prototype system, MarioNet, that is compatible with all major browsers, and discuss potential defense strategies to counter the threat of such persistent in-browser attacks. Our main goal is to raise awareness regarding this new class of attacks, and inform the design of future browser APIs so that they provide a more secure client-side environment for web applications.",
            "keywords": [
                "Web Browser Security",
                "JavaScript APIs",
                "In-browser Attacks",
                "Persistent Computation",
                "MarioNet Framework"
            ]
        },
        "url": "URL#2737685",
        "sema_paperId": "38b547fa6e001ce1351458f600b7afeea27b4695"
    },
    {
        "@score": "1",
        "@id": "2737686",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "222/3183",
                        "text": "Victor Perrier"
                    },
                    {
                        "@pid": "70/7706",
                        "text": "Hassan Jameel Asghar"
                    },
                    {
                        "@pid": "71/5612",
                        "text": "Dali Kaafar"
                    }
                ]
            },
            "title": "Private Continual Release of Real-Valued Data Streams.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/PerrierAK19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/private-continual-release-of-real-valued-data-streams/",
            "url": "https://dblp.org/rec/conf/ndss/PerrierAK19",
            "abstract": "We present a differentially private mechanism to display statistics (e.g., the moving average) of a stream of real valued observations where the bound on each observation is either too conservative or unknown in advance. This is particularly relevant to scenarios of real-time data monitoring and reporting, e.g., energy data through smart meters. Our focus is on real-world data streams whose distribution is light-tailed, meaning that the tail approaches zero at least as fast as the exponential distribution. For such data streams, individual observations are expected to be concentrated below an unknown threshold. Estimating this threshold from the data can potentially violate privacy as it would reveal particular events tied to individuals [1]. On the other hand an overly conservative threshold may impact accuracy by adding more noise than necessary. We construct a utility optimizing differentially private mechanism to release this threshold based on the input stream. Our main advantage over the state-of-the-art algorithms is that the resulting noise added to each observation of the stream is scaled to the threshold instead of a possibly much larger bound; resulting in considerable gain in utility when the difference is significant. Using two real-world datasets, we demonstrate that our mechanism, on average, improves the utility by a factor of 3.5 on the first dataset, and 9 on the other. While our main focus is on continual release of statistics, our mechanism for releasing the threshold can be used in various other applications where a (privacy-preserving) measure of the scale of the input distribution is required.",
            "keywords": [
                "Differential Privacy",
                "Real-Valued Data Streams",
                "Moving Average",
                "Threshold Estimation",
                "Utility Optimization"
            ]
        },
        "url": "URL#2737686",
        "sema_paperId": "c4729c9b8a8d72c00840201e6b9c542f2c0b8f7e"
    },
    {
        "@score": "1",
        "@id": "2737687",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "221/3626",
                        "text": "Victor Le Pochat"
                    },
                    {
                        "@pid": "147/2244",
                        "text": "Tom van Goethem"
                    },
                    {
                        "@pid": "182/6692",
                        "text": "Samaneh Tajalizadehkhoob"
                    },
                    {
                        "@pid": "06/10585",
                        "text": "Maciej Korczynski"
                    },
                    {
                        "@pid": "13/86",
                        "text": "Wouter Joosen"
                    }
                ]
            },
            "title": "Tranco: A Research-Oriented Top Sites Ranking Hardened Against Manipulation.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/PochatGTKJ19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/tranco-a-research-oriented-top-sites-ranking-hardened-against-manipulation/",
            "url": "https://dblp.org/rec/conf/ndss/PochatGTKJ19",
            "abstract": "In order to evaluate the prevalence of security and privacy practices on a representative sample of the Web, researchers rely on website popularity rankings such as the Alexa list. While the validity and representativeness of these rankings are rarely questioned, our findings show the contrary: we show for four main rankings how their inherent properties (similarity, stability, representativeness, responsiveness and benignness) affect their composition and therefore potentially skew the conclusions made in studies. Moreover, we find that it is trivial for an adversary to manipulate the composition of these lists. We are the first to empirically validate that the ranks of domains in each of the lists are easily altered, in the case of Alexa through as little as a single HTTP request. This allows adversaries to manipulate rankings on a large scale and insert malicious domains into whitelists or bend the outcome of research studies to their will. To overcome the limitations of such rankings, we propose improvements to reduce the fluctuations in list composition and guarantee better defenses against manipulation. To allow the research community to work with reliable and reproducible rankings, we provide Tranco, an improved ranking that we offer through an online service available at this https URL.",
            "keywords": [
                "Website Popularity Rankings",
                "Ranking Manipulation",
                "Tranco",
                "Security Research",
                "Privacy Practices"
            ]
        },
        "url": "URL#2737687",
        "sema_paperId": "de49216211dc0ababaaf338ce88983cc7031ee61"
    },
    {
        "@score": "1",
        "@id": "2737688",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "132/9407",
                        "text": "Michael Rodler"
                    },
                    {
                        "@pid": "29/4801-1",
                        "text": "Wenting Li 0001"
                    },
                    {
                        "@pid": "36/1531",
                        "text": "Ghassan O. Karame"
                    },
                    {
                        "@pid": "73/7564",
                        "text": "Lucas Davi"
                    }
                ]
            },
            "title": "Sereum: Protecting Existing Smart Contracts Against Re-Entrancy Attacks.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/RodlerLKD19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/sereum-protecting-existing-smart-contracts-against-re-entrancy-attacks/",
            "url": "https://dblp.org/rec/conf/ndss/RodlerLKD19",
            "abstract": "Recently, a number of existing blockchain systems have witnessed major bugs and vulnerabilities within smart contracts. Although the literature features a number of proposals for securing smart contracts, these proposals mostly focus on proving the correctness or absence of a certain type of vulnerability within a contract, but cannot protect deployed (legacy) contracts from being exploited.\nIn this paper, we address this problem in the context of re-entrancy exploits and propose a novel smart contract security technology, dubbed Sereum  (Secure Ethereum), which protects existing, deployed contracts against re-entrancy attacks in a backwards compatible way based on run-time monitoring and validation. Sereum does neither require any modification nor any semantic knowledge of existing contracts. By means of implementation and evaluation using the Ethereum blockchain, we show that Sereum covers the actual execution flow of a smart contract to accurately detect and prevent\nattacks with a false positive rate as small as 0.06% and with negligible\nrun-time overhead. As a by-product, we develop three advanced re-entrancy attacks to demonstrate the limitations of existing offline vulnerability analysis tools.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2019/02/ndss2019_09-3_Rodler_paper.pdf",
            "keywords": [
                "Smart Contract Security",
                "Re-Entrancy Attacks",
                "Legacy Contracts",
                "Run-Time Monitoring",
                "Vulnerability Detection"
            ]
        },
        "url": "URL#2737688"
    },
    {
        "@score": "1",
        "@id": "2737689",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "94/7855",
                        "text": "Nicol\u00e1s Rosner"
                    },
                    {
                        "@pid": "233/6851",
                        "text": "Ismet Burak Kadron"
                    },
                    {
                        "@pid": "130/1704",
                        "text": "Lucas Bang"
                    },
                    {
                        "@pid": "07/3368",
                        "text": "Tevfik Bultan"
                    }
                ]
            },
            "title": "Profit: Detecting and Quantifying Side Channels in Networked Applications.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/RosnerKBB19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/profit-detecting-and-quantifying-side-channels-in-networked-applications/",
            "url": "https://dblp.org/rec/conf/ndss/RosnerKBB19",
            "abstract": "We present a black-box, dynamic technique to detect and quantify side-channel information leaks in networked applications that communicate through a TLS-encrypted stream. Given a user-supplied profiling-input suite in which some aspect of the inputs is marked as secret, we run the application over the inputs and capture a collection of variable-length network packet traces. The captured traces give rise to a vast side-channel feature space, including the size and timestamp of each individual packet as well as their aggregations (such as total time, median size, etc.) over every possible subset of packets. Finding the features that leak the most information is a difficult problem. Our approach addresses this problem in three steps: 1) Global analysis of traces for their alignment and identification of phases across traces; 2) Feature extraction using the identified phases; 3) Information leakage quantification and ranking of features via estimation of probability distribution. We embody this approach in a tool called Profit and experimentally evaluate it on a benchmark of applications from the DARPA STAC program, which were developed to assess the effectiveness of side-channel analysis techniques. Our experimental results demonstrate that, given suitable profiling-input suites, Profit is successful in automatically detecting information-leaking features in applications, and correctly ordering the strength of the leakage for differently-leaking variants of the same application.",
            "keywords": [
                "Side-Channel Analysis",
                "Networked Applications",
                "Information Leakage",
                "TLS Encryption",
                "Feature Extraction"
            ]
        },
        "url": "URL#2737689",
        "sema_paperId": "f39d000563f195672efc9cb954118bc0b876351f"
    },
    {
        "@score": "1",
        "@id": "2737690",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "41/506-1",
                        "text": "Ahmed Salem 0001"
                    },
                    {
                        "@pid": "06/6785-16",
                        "text": "Yang Zhang 0016"
                    },
                    {
                        "@pid": "83/8816",
                        "text": "Mathias Humbert"
                    },
                    {
                        "@pid": "124/6255",
                        "text": "Pascal Berrang"
                    },
                    {
                        "@pid": "07/5701",
                        "text": "Mario Fritz"
                    },
                    {
                        "@pid": "b/MichaelBackes1",
                        "text": "Michael Backes 0001"
                    }
                ]
            },
            "title": "ML-Leaks: Model and Data Independent Membership Inference Attacks and Defenses on Machine Learning Models.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/Salem0HBF019",
            "ee": "https://www.ndss-symposium.org/ndss-paper/ml-leaks-model-and-data-independent-membership-inference-attacks-and-defenses-on-machine-learning-models/",
            "url": "https://dblp.org/rec/conf/ndss/Salem0HBF019",
            "abstract": "Machine learning (ML) has become a core component of many real-world applications and training data is a key factor that drives current progress. This huge success has led Internet companies to deploy machine learning as a service (MLaaS). Recently, the first membership inference attack has shown that extraction of information on the training set is possible in such MLaaS settings, which has severe security and privacy implications.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2019/02/ndss2019_03A-1_Salem_paper.pdf",
            "keywords": [
                "Membership Inference Attacks",
                "Privacy Implications",
                "Machine Learning as a Service (MLaaS)",
                "Data Leakage",
                "Model Independence"
            ]
        },
        "url": "URL#2737690"
    },
    {
        "@score": "1",
        "@id": "2737691",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "195/0263",
                        "text": "Lea Sch\u00f6nherr"
                    },
                    {
                        "@pid": "155/5132",
                        "text": "Katharina Kohls"
                    },
                    {
                        "@pid": "43/8156",
                        "text": "Steffen Zeiler"
                    },
                    {
                        "@pid": "h/ThorstenHolz",
                        "text": "Thorsten Holz"
                    },
                    {
                        "@pid": "44/3463",
                        "text": "Dorothea Kolossa"
                    }
                ]
            },
            "title": "Adversarial Attacks Against Automatic Speech Recognition Systems via Psychoacoustic Hiding.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/SchonherrKZHK19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/adversarial-attacks-against-automatic-speech-recognition-systems-via-psychoacoustic-hiding/",
            "url": "https://dblp.org/rec/conf/ndss/SchonherrKZHK19",
            "abstract": "Voice interfaces are becoming accepted widely as input methods for a diverse set of devices. This development is driven by rapid improvements in automatic speech recognition (ASR), which now performs on par with human listening in many tasks. These improvements base on an ongoing evolution of DNNs as the computational core of ASR. However, recent research results show that DNNs are vulnerable to adversarial perturbations, which allow attackers to force the transcription into a malicious output. \nIn this paper, we introduce a new type of adversarial examples based on psychoacoustic hiding. Our attack exploits the characteristics of DNN-based ASR systems, where we extend the original analysis procedure by an additional backpropagation step. We use this backpropagation to learn the degrees of freedom for the adversarial perturbation of the input signal, i.e., we apply a psychoacoustic model and manipulate the acoustic signal below the thresholds of human perception. To further minimize the perceptibility of the perturbations, we use forced alignment to find the best fitting temporal alignment between the original audio sample and the malicious target transcription. These extensions allow us to embed an arbitrary audio input with a malicious voice command that is then transcribed by the ASR system, with the audio signal remaining barely distinguishable from the original signal. In an experimental evaluation, we attack the state-of-the-art speech recognition system Kaldi and determine the best performing parameter and analysis setup for different types of input. Our results show that we are successful in up to 98% of cases with a computational effort of fewer than two minutes for a ten-second audio file. Based on user studies, we found that none of our target transcriptions were audible to human listeners, who still understand the original speech content with unchanged accuracy.",
            "keywords": [
                "Automatic Speech Recognition",
                "Adversarial Attacks",
                "Psychoacoustic Hiding",
                "DNN Vulnerabilities",
                "Malicious Voice Commands"
            ]
        },
        "url": "URL#2737691",
        "sema_paperId": "a43763e4e0e928bd2fdd7a3164b0383a38d28fab"
    },
    {
        "@score": "1",
        "@id": "2737692",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "187/9868",
                        "text": "Tohid Shekari"
                    },
                    {
                        "@pid": "205/2026",
                        "text": "Christian Bayens"
                    },
                    {
                        "@pid": "43/2967",
                        "text": "Morris Cohen"
                    },
                    {
                        "@pid": "233/2579",
                        "text": "Lukas Graber"
                    },
                    {
                        "@pid": "12/6354",
                        "text": "Raheem Beyah"
                    }
                ]
            },
            "title": "RFDIDS: Radio Frequency-based Distributed Intrusion Detection System for the Power Grid.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ShekariBCGB19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/rfdids-radio-frequency-based-distributed-intrusion-detection-system-for-the-power-grid/",
            "url": "https://dblp.org/rec/conf/ndss/ShekariBCGB19",
            "abstract": "Recently, the number of cyber threats on power systems has increased at an unprecedented rate. For instance, the widespread blackout in Ukrainian power grid on December 2015 was a wakeup call that modern power systems have numerous vulnerabilities, especially in power substations which form the backbone of electricity networks. There have been significant efforts among researchers to develop effective intrusion detection systems (IDSs) in order to prevent such attacks or at least reduce their damaging consequences. However, all of the existing techniques require some level of trust from components on the supervisory control and data acquisition (SCADA) network; hence, they are still vulnerable to sophisticated attacks that can compromise the SCADA system completely. This paper presents a radio frequency-based distributed intrusion detection system (RFDIDS) which remains reliable even when the entire SCADA system is considered untrusted. The proposed system uses radio frequency (RF) emissions to monitor the power grid substation activities. Indeed, it utilizes a radio receiver as a diagnostic tool to provide air-gapped, independent, and verifiable information about the radio emissions from substation components, particularly at low frequencies (LF, 0.05$-$50~kHz, or $>$20~$mu$s period). The simulation and experimental results verified that four types of diagnostic information can be extracted from radio emissions of power system substation circuits: i)~harmonic content of the circuit current, ii)~fundamental frequency of the circuit current, iii)~impulsive signals from rapid circuit current changes, and iv)~sferics from global lightning strokes. Each or a combination of the first three diagnostics can be effectively leveraged to directly detect specific types of power grid attacks. Meanwhile, the last diagnostic is utilized to check the integrity of the receiver's signal as it is encoded with the quasi-random distribution of the global lightning strokes. The simulation and real-world experimental results verified the effectiveness of RFDIDS in protecting the power grid against sophisticated attacks.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2019/02/ndss2019_07A-2_Shekari_paper.pdf",
            "keywords": [
                "Intrusion Detection System",
                "Power Grid Security",
                "Radio Frequency Monitoring",
                "Cyber Threats",
                "SCADA Vulnerabilities"
            ]
        },
        "url": "URL#2737692",
        "sema_paperId": "fb4571c63172e09eca69bab8b45304880745ecc4"
    },
    {
        "@score": "1",
        "@id": "2737693",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "169/3386",
                        "text": "Shiqi Shen"
                    },
                    {
                        "@pid": "136/8404",
                        "text": "Shweta Shinde"
                    },
                    {
                        "@pid": "223/4052",
                        "text": "Soundarya Ramesh"
                    },
                    {
                        "@pid": "04/5884",
                        "text": "Abhik Roychoudhury"
                    },
                    {
                        "@pid": "90/105",
                        "text": "Prateek Saxena"
                    }
                ]
            },
            "title": "Neuro-Symbolic Execution: Augmenting Symbolic Execution with Neural Constraints.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ShenSRRS19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/neuro-symbolic-execution-augmenting-symbolic-execution-with-neural-constraints/",
            "url": "https://dblp.org/rec/conf/ndss/ShenSRRS19",
            "abstract": "Symbolic execution is a powerful technique for program analysis. However, it has many limitations in practical applicability: the path explosion problem encumbers scalability, the need for language-specific implementation, the inability to handle complex dependencies, and the limited expressiveness of theories supported by underlying satisfiability checkers. Often, relationships between variables of interest are not expressible directly as purely symbolic constraints. To this end, we present a new approach\u2014neuro-symbolic execution\u2014which learns an approximation of the relationship between program values of interest, as a neural network. We develop a procedure for checking satisfiability of mixed constraints, involving both symbolic expressions and neural representations. We implement our new approach in a tool called NEUEX as an extension of KLEE, a state-of-the-art dynamic symbolic execution engine. NEUEX finds 33 exploits in a benchmark of 7 programs within 12 hours. This is an improvement in the bug finding efficacy of 94% over vanilla KLEE. We show that this new approach drives execution down difficult paths on which KLEE and other DSE extensions get stuck, eliminating limitations of purely SMT-based techniques.",
            "keywords": [
                "Neuro-Symbolic Execution",
                "Symbolic Execution",
                "Program Analysis",
                "Path Explosion Problem",
                "Mixed Constraints"
            ]
        },
        "url": "URL#2737693",
        "sema_paperId": "814c5434265f0bdf9196746e08f03f406679f2cd"
    },
    {
        "@score": "1",
        "@id": "2737694",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "187/8338",
                        "text": "Jangseop Shin"
                    },
                    {
                        "@pid": "130/9723",
                        "text": "Donghyun Kwon"
                    },
                    {
                        "@pid": "27/229",
                        "text": "Jiwon Seo"
                    },
                    {
                        "@pid": "130/9710",
                        "text": "Yeongpil Cho"
                    },
                    {
                        "@pid": "65/3751",
                        "text": "Yunheung Paek"
                    }
                ]
            },
            "title": "CRCount: Pointer Invalidation with Reference Counting to Mitigate Use-after-free in Legacy C/C++.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ShinKSCP19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/crcount-pointer-invalidation-with-reference-counting-to-mitigate-use-after-free-in-legacy-c-c/",
            "url": "https://dblp.org/rec/conf/ndss/ShinKSCP19",
            "abstract": "Pointer invalidation has been a popular approach adopted in many recent studies to mitigate use-after-free errors. The approach can be divided largely into two different schemes: explicit invalidation and implicit invalidation. The former aims to eradicate the root cause of use-after-free errors by explicitly invalidating every dangling pointer. In contrast, the latter aims to prevent dangling pointers by freeing an object only if there is no pointer referring to it. A downside of the explicit scheme is that it is expensive, as it demands high-cost algorithms or a large amount of space to maintain up-to-date lists of pointer locations linking to each object. Implicit invalidation is more efficient in that even without any explicit effort, it can eliminate dangling pointers by leaving objects undeleted until all the links between the objects and their referring pointers vanish by themselves during program execution. However, such an argument only holds if the scheme knows exactly when each link is created and deleted. Reference counting is a traditional method to determine the existence of reference links between objects and pointers. Unfortunately, impeccable reference counting for legacy C/C++ code is very difficult and expensive to achieve in practice, mainly because of the type unsafe operations in the code. In this paper, we present a solution, called CRCount, to the use-after-free problem in legacy C/C++. For effective and efficient problem solving, CRCount is armed with the pointer footprinting technique that enables us to compute, with high accuracy, the reference count of every object referred to by the pointers in the legacy code. Our experiments demonstrate that CRCount mitigates the useafter-free errors with a lower performance-wise and space-wise overhead than the existing pointer invalidation solutions.",
            "keywords": [
                "Pointer Invalidation",
                "Use-after-free",
                "Reference Counting",
                "Legacy C/C++",
                "Pointer Footprinting"
            ]
        },
        "url": "URL#2737694",
        "sema_paperId": "6ef4bc3251c7e506f45ce3575fd47666b4c125ba"
    },
    {
        "@score": "1",
        "@id": "2737695",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "157/2295",
                        "text": "Mridula Singh"
                    },
                    {
                        "@pid": "183/1273",
                        "text": "Patrick Leu"
                    },
                    {
                        "@pid": "51/1639",
                        "text": "Srdjan Capkun"
                    }
                ]
            },
            "title": "UWB with Pulse Reordering: Securing Ranging against Relay and Physical-Layer Attacks.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/SinghLC19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/uwb-with-pulse-reordering-securing-ranging-against-relay-and-physical-layer-attacks/",
            "url": "https://dblp.org/rec/conf/ndss/SinghLC19",
            "abstract": "Physical-layer attacks allow attackers to manipulate (spoof) ranging and positioning. These attacks had real-world impact and allowed car thefts, executions of unauthorized payments and manipulation of navigation. UWB impulse radio, standardized within 802.15.4a,f, has emerged as a prominent technique for precise ranging that allows high operating distances despite power constraints by transmitting multi-pulse symbols. Security of UWB ranging (in terms of the attacker's ability to manipulate the measured distance) has been discussed in the literature and is, since recently also being addressed as a part of the emerging 802.15.4z standard. However, all research so far, as well as security enhancements proposed within this emerging standard face one main limitation: they achieve security through short symbol lengths and sacrifice performance (i.e., limit the maximum distance of measurement), or use longer symbol lengths, therefore sacrificing security. We present UWB with pulse reordering (UWB-PR), the first modulation scheme that secures distance measurement between two mutually trusted devices against all physical-layer distance shortening attacks without sacrificing performance, therefore simultaneously enabling extended range and security. We analyze the security of UWB-PR under the attacker that fully controls the communication channel and show that UWB-PR resists such strong attackers. We evaluate UWB-PR within a UWB system built on top of the IEEE 802.15.4 device and show that it achieves distances of up to 93m with 10cm precision (LoS). UWB-PR is, therefore, a good candidate for the extended mode of the new 802.15.4z Low Rate Pulse standard. Finally, UWB-PR shows that secure distance measurement can be built on top of modulation schemes with longer symbol lengths - so far, this was considered insecure.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2019/02/ndss2019_06B-2_Singh_paper.pdf",
            "keywords": [
                "UWB Ranging",
                "Pulse Reordering",
                "Physical-Layer Attacks",
                "Distance Measurement Security",
                "802.15.4z Standard"
            ]
        },
        "url": "URL#2737695"
    },
    {
        "@score": "1",
        "@id": "2737696",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "168/9531",
                        "text": "Suphannee Sivakorn"
                    },
                    {
                        "@pid": "36/10085",
                        "text": "Kangkook Jee"
                    },
                    {
                        "@pid": "139/9789",
                        "text": "Yixin Sun"
                    },
                    {
                        "@pid": "266/8091",
                        "text": "Lauri Korts-P\u00e4rn"
                    },
                    {
                        "@pid": "55/4022",
                        "text": "Zhichun Li"
                    },
                    {
                        "@pid": "23/3990",
                        "text": "Cristian Lumezanu"
                    },
                    {
                        "@pid": "87/6581-3",
                        "text": "Zhenyu Wu 0003"
                    },
                    {
                        "@pid": "67/7788",
                        "text": "Lu-An Tang"
                    },
                    {
                        "@pid": "95/7132-1",
                        "text": "Ding Li 0001"
                    }
                ]
            },
            "title": "Countering Malicious Processes with Process-DNS Association.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/SivakornJSKLLWT19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/countering-malicious-processes-with-process-dns-association/",
            "url": "https://dblp.org/rec/conf/ndss/SivakornJSKLLWT19",
            "abstract": "Modern malware and cyber attacks depend heavily on DNS services to make their campaigns reliable and difficult to track. Monitoring network DNS activities and blocking suspicious domains have been proven an effective technique in countering such attacks. However, recent successful campaigns reveal that at- tackers adapt by using seemingly benign domains and public web storage services to hide malicious activity. Also, the recent support for encrypted DNS queries provides attacker easier means to hide malicious traffic from network-based DNS monitoring.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2019/02/ndss2019_02B-4_Sivakorn_paper.pdf",
            "keywords": [
                "DNS Security",
                "Malware Detection",
                "Network Monitoring",
                "Encrypted DNS",
                "Malicious Domain Identification"
            ]
        },
        "url": "URL#2737696",
        "sema_paperId": "30a3f6235011d12d9e11220ae279d003a741133e"
    },
    {
        "@score": "1",
        "@id": "2737697",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "196/8836",
                        "text": "Alexander Sj\u00f6sten"
                    },
                    {
                        "@pid": "28/8877",
                        "text": "Steven Van Acker"
                    },
                    {
                        "@pid": "131/9757",
                        "text": "Pablo Picazo-Sanchez"
                    },
                    {
                        "@pid": "s/AndreiSabelfeld",
                        "text": "Andrei Sabelfeld"
                    }
                ]
            },
            "title": "Latex Gloves: Protecting Browser Extensions from Probing and Revelation Attacks.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/SjostenAPS19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/latex-gloves-protecting-browser-extensions-from-probing-and-revelation-attacks/",
            "url": "https://dblp.org/rec/conf/ndss/SjostenAPS19",
            "abstract": "Browser extensions enable rich experience for the users of today's web. Being deployed with elevated privileges, extensions are given the power to overrule web pages. As a result, web pages often seek to detect the installed extensions, sometimes for benign adoption of their behavior but sometimes as part of privacy-violating user fingerprinting. Researchers have studied a class of attacks that allow detecting extensions by probing for Web Accessible Resources (WARs) via URLs that include public extension IDs. Realizing privacy risks associated with WARs, Firefox has recently moved to randomize a browser extension's ID, prompting the Chrome team to plan for following the same path. However, rather than mitigating the issue, the randomized IDs can in fact exacerbate the extension detection problem, enabling attackers to use a randomized ID as a reliable fingerprint of a user. We study a class of extension revelation attacks, where extensions reveal themselves by injecting their code on web pages. We demonstrate how a combination of revelation and probing can uniquely identify 90% out of all extensions injecting content, in spite of a randomization scheme. We perform a series of large-scale studies to estimate possible implications of both classes of attacks. As a countermeasure, we propose a browser-based mechanism that enables control over which extensions are loaded on which web pages and present a proof of concept implementation which blocks both classes of attacks.",
            "keywords": [
                "Browser Extensions",
                "Privacy Violations",
                "Extension Detection",
                "Revelation Attacks",
                "Web Accessible Resources (WARs)"
            ]
        },
        "url": "URL#2737697",
        "sema_paperId": "d5a658695b5424ff8c3f4c0ed43f33f9b06eb730"
    },
    {
        "@score": "1",
        "@id": "2737698",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "210/0976",
                        "text": "Dokyung Song"
                    },
                    {
                        "@pid": "188/6046",
                        "text": "Felicitas Hetzelt"
                    },
                    {
                        "@pid": "90/3182-2",
                        "text": "Dipanjan Das 0002"
                    },
                    {
                        "@pid": "30/7555",
                        "text": "Chad Spensky"
                    },
                    {
                        "@pid": "37/9431",
                        "text": "Yeoul Na"
                    },
                    {
                        "@pid": "127/6103",
                        "text": "Stijn Volckaert"
                    },
                    {
                        "@pid": "v/GiovanniVigna",
                        "text": "Giovanni Vigna"
                    },
                    {
                        "@pid": "k/ChristopherKruegel",
                        "text": "Christopher Kruegel"
                    },
                    {
                        "@pid": "98/117",
                        "text": "Jean-Pierre Seifert"
                    },
                    {
                        "@pid": "f/MichaelFranz",
                        "text": "Michael Franz"
                    }
                ]
            },
            "title": "PeriScope: An Effective Probing and Fuzzing Framework for the Hardware-OS Boundary.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/SongH0SNVVKSF19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/periscope-an-effective-probing-and-fuzzing-framework-for-the-hardware-os-boundary/",
            "url": "https://dblp.org/rec/conf/ndss/SongH0SNVVKSF19",
            "abstract": "Author(s): Song, Dokyung; Hetzelt, Felicitas; Das, Dipanjan; Spensky, Chad; Na, Yeoul; Volckaert, Stijn; Vigna, Giovanni; Kruegel, Christopher; Seifert, Jean-Pierre; Franz, Michael",
            "keywords": [
                "Hardware-OS Boundary",
                "Probing Framework",
                "Fuzzing Techniques",
                "Vulnerability Detection",
                "Security Testing"
            ]
        },
        "url": "URL#2737698",
        "sema_paperId": "648148eaab8f38d0e2ea3fca29c615672cbad26f"
    },
    {
        "@score": "1",
        "@id": "2737699",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "170/4315",
                        "text": "Alberto Sonnino"
                    },
                    {
                        "@pid": "184/4757",
                        "text": "Mustafa Al-Bassam"
                    },
                    {
                        "@pid": "03/10812",
                        "text": "Shehar Bano"
                    },
                    {
                        "@pid": "94/8813",
                        "text": "Sarah Meiklejohn"
                    },
                    {
                        "@pid": "11/1148",
                        "text": "George Danezis"
                    }
                ]
            },
            "title": "Coconut: Threshold Issuance Selective Disclosure Credentials with Applications to Distributed Ledgers.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/SonninoABMD19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/coconut-threshold-issuance-selective-disclosure-credentials-with-applications-to-distributed-ledgers/",
            "url": "https://dblp.org/rec/conf/ndss/SonninoABMD19",
            "abstract": "We present Coconut, a novel selective disclosure credential scheme supporting distributed threshold issuance, public and private attributes, re-randomization, and multiple unlinkable selective attribute revelations. Coconut can be used by modern blockchains to ensure confidentiality, authenticity and availability even when a subset of credential issuing authorities are malicious or offline. We implement and evaluate a generic Coconut smart contract library for Chainspace and Ethereum; and present three applications related to anonymous payments, electronic petitions, and distribution of proxies for censorship resistance. Coconut uses short and computationally efficient credentials, and our evaluation shows that most Coconut cryptographic primitives take just a few milliseconds on average, with verification taking the longest time (10 milliseconds).",
            "keywords": [
                "Selective Disclosure Credentials",
                "Threshold Issuance",
                "Distributed Ledgers",
                "Confidentiality and Authenticity",
                "Unlinkable Attribute Revelations"
            ]
        },
        "url": "URL#2737699",
        "sema_paperId": "935d5845cbbf5dd76f7539529e14c41929418896"
    },
    {
        "@score": "1",
        "@id": "2737700",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "205/2051",
                        "text": "Marius Steffens"
                    },
                    {
                        "@pid": "08/6024",
                        "text": "Christian Rossow"
                    },
                    {
                        "@pid": "82/359",
                        "text": "Martin Johns"
                    },
                    {
                        "@pid": "136/8343",
                        "text": "Ben Stock"
                    }
                ]
            },
            "title": "Don&apos;t Trust The Locals: Investigating the Prevalence of Persistent Client-Side Cross-Site Scripting in the Wild.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/SteffensRJS19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/dont-trust-the-locals-investigating-the-prevalence-of-persistent-client-side-cross-site-scripting-in-the-wild/",
            "url": "https://dblp.org/rec/conf/ndss/SteffensRJS19",
            "abstract": "The Web has become highly interactive and an \nimportant driver for modern life, enabling information retrieval, \nsocial exchange, and online shopping. From the security perspective, Cross-Site Scripting (XSS) is one of the most nefarious \nattacks against Web clients. Research has long since focused \non three categories of XSS: Reflected, Persistent, and DOMbased XSS. In this paper, we argue that our community must \nconsider at least four important classes of XSS, and present \nthe first systematic study of the threat of Persistent Client-Side \nXSS, caused by the insecure use of client-side storage. While \nthe existence of this class has been acknowledged, especially by \nthe non-academic community like OWASP, prior works have \neither only found such flaws as side effects of other analyses or \nfocused on a limited set of applications to analyze. Therefore, the \ncommunity lacks in-depth knowledge about the actual prevalence \nof Persistent Client-Side XSS in the wild. \nTo close this research gap, we leverage taint tracking to \nidentify suspicious flows from client-side persistent storage (Web \nStorage, cookies) to dangerous sinks (HTML, JavaScript, and \nscript.src). We discuss two attacker models capable of \ninjecting malicious payloads into storage, i.e., a Network Attacker \ncapable of temporarily hijacking HTTP communication (e.g., in \na public WiFi), and a Web Attacker who can leverage flows into \nstorage or an existing reflected XSS flaw to persist their payload. \nWith our taint-aware browser and these models in mind, we \nstudy the prevalence of Persistent Client-Side XSS in the Alexa \nTop 5,000 domains. We find that more than 8% of them have \nunfiltered data flows from persistent storage to a dangerous sink, \nwhich showcases the developers\u2019 inherent trust in the integrity \nof storage content. Even worse, if we only consider sites that \nmake use of data originating from storage, 21% of the sites are \nvulnerable. For those sites with vulnerable flows from storage \nto sink, we find that at least 70% are directly exploitable by \nour attacker models. Finally, investigating the vulnerable flows \noriginating from storage allows us to categorize them into four \ndisjoint categories and propose appropriate mitigations.",
            "keywords": [
                "Cross-Site Scripting (XSS)",
                "Client-Side Storage",
                "Persistent XSS",
                "Web Security Vulnerabilities",
                "Taint Tracking"
            ]
        },
        "url": "URL#2737700",
        "sema_paperId": "560c2924e4d3c584507b42894d0040d3b8b4fbc5"
    },
    {
        "@score": "1",
        "@id": "2737701",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "41/10099",
                        "text": "Shridatt Sugrim"
                    },
                    {
                        "@pid": "18/5099-1",
                        "text": "Can Liu 0001"
                    },
                    {
                        "@pid": "239/8872",
                        "text": "Meghan McLean"
                    },
                    {
                        "@pid": "65/1182",
                        "text": "Janne Lindqvist"
                    }
                ]
            },
            "title": "Robust Performance Metrics for Authentication Systems.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/SugrimLML19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/robust-performance-metrics-for-authentication-systems/",
            "url": "https://dblp.org/rec/conf/ndss/SugrimLML19",
            "abstract": "Research has produced many types of authentication systems that use machine learning. However, there is no consistent approach for reporting performance metrics and the reported metrics are inadequate. In this work, we show that several of the common metrics used for reporting performance, such as maximum accuracy (ACC), equal error rate (EER) and area under the ROC curve (AUROC), are inherently flawed. These common metrics hide the details of the inherent tradeoffs a system must make when implemented. Our findings show that current metrics give no insight into how system performance degrades outside the ideal conditions in which they were designed. We argue that adequate performance reporting must be provided to enable meaningful evaluation and that current, commonly used approaches fail in this regard. We present the unnormalized frequency count of scores (FCS) to demonstrate the mathematical underpinnings that lead to these failures and show how they can be avoided. The FCS can be used to augment the performance reporting to enable comparison across systems in a visual way. When reported with the Receiver Operating Characteristics curve (ROC), these two metrics provide a solution to the limitations of currently reported metrics. Finally, we show how to use the FCS and ROC metrics to evaluate and compare different authentication systems.",
            "keywords": [
                "Authentication Systems",
                "Performance Metrics",
                "Evaluation Methods",
                "Frequency Count of Scores (FCS)",
                "Receiver Operating Characteristics (ROC)"
            ]
        },
        "url": "URL#2737701",
        "sema_paperId": "6a9059b3dc1f670e669a6e73194dea9681a4891a"
    },
    {
        "@score": "1",
        "@id": "2737702",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "238/9909",
                        "text": "Kimia Tajik"
                    },
                    {
                        "@pid": "238/0157",
                        "text": "Akshith Gunasekaran"
                    },
                    {
                        "@pid": "239/0126",
                        "text": "Rhea Dutta"
                    },
                    {
                        "@pid": "239/0168",
                        "text": "Brandon Ellis"
                    },
                    {
                        "@pid": "115/7959",
                        "text": "Rakesh B. Bobba"
                    },
                    {
                        "@pid": "r/MikeRosulek",
                        "text": "Mike Rosulek"
                    },
                    {
                        "@pid": "82/4065",
                        "text": "Charles V. Wright"
                    },
                    {
                        "@pid": "04/329",
                        "text": "Wu-chi Feng"
                    }
                ]
            },
            "title": "Balancing Image Privacy and Usability with Thumbnail-Preserving Encryption.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/TajikGDEBRWF19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/balancing-image-privacy-and-usability-with-thumbnail-preserving-encryption/",
            "url": "https://dblp.org/rec/conf/ndss/TajikGDEBRWF19",
            "abstract": "In this paper, we motivate the need for image encryption techniques that preserve certain visual features in images and hide all other information, to balance privacy and usability in the context of cloud-based image storage services. In particular, we introduce the concept of ideal or exact Thumbnail-Preserving Encryption (TPE), a special case of format-preserving encryption, and present a concrete construction. In TPE, a ciphertext is itself an image that has the same thumbnail as the plaintext (unecrypted) image, but that provably leaks nothing about the plaintext beyond its thumbnail. We provide a formal security analysis for the construction, and a prototype implementation to demonstrate compatibility with existing services. We also study the ability of users to distinguish between thumbnail images preserved by TPE. Our findings indicate that TPE is an efficient and promising approach to balance usability and privacy concerns for images. Our code and a demo are available at: http://photoencryption.org.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2019/02/ndss2019_07B-1_Tajik_paper.pdf",
            "keywords": [
                "Thumbnail-Preserving Encryption",
                "Image Privacy",
                "Cloud Storage",
                "Usability",
                "Visual Feature Preservation"
            ]
        },
        "url": "URL#2737702"
    },
    {
        "@score": "1",
        "@id": "2737703",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "68/5101",
                        "text": "Luis Vargas"
                    },
                    {
                        "@pid": "183/1275",
                        "text": "Logan Blue"
                    },
                    {
                        "@pid": "224/9362",
                        "text": "Vanessa Frost"
                    },
                    {
                        "@pid": "201/6456",
                        "text": "Christopher Patton"
                    },
                    {
                        "@pid": "167/0436",
                        "text": "Nolen Scaife"
                    },
                    {
                        "@pid": "82/1935",
                        "text": "Kevin R. B. Butler"
                    },
                    {
                        "@pid": "14/3295",
                        "text": "Patrick Traynor"
                    }
                ]
            },
            "title": "Digital Healthcare-Associated Infection: A Case Study on the Security of a Major Multi-Campus Hospital System.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/VargasBFPSBT19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/digital-healthcare-associated-infection-a-case-study-on-the-security-of-a-major-multi-campus-hospital-system/",
            "url": "https://dblp.org/rec/conf/ndss/VargasBFPSBT19",
            "abstract": "Modern hospital systems are complex environments that rely on high interconnectivity with the larger Internet. With this connectivity comes a vast attack surface. Security researchers have expended considerable effort to characterize the risks posed to medical devices (e.g., pacemakers and insulin pumps). However, there has been no systematic, ecosystem-wide analyses of a modern hospital system to date, perhaps due to the challenges of collecting and analyzing sensitive healthcare data. Hospital traffic requires special considerations because healthcare data may contain private information or may come from safety-critical devices in charge of patient care. We describe the process of obtaining the network data in a safe and ethical manner in order to help expand future research in this field. We present an analysis of network-enabled devices connected to the hospital used for its daily operations without posing any harm to the hospital\u2019s environment. We perform a Digital Healthcare- Associated Infection (D-HAI) analysis of the hospital ecosystem, assessing a major multi-campus healthcare system over a period of six months. As part of the D-HAI analysis, we characterize DNS requests and TLS/SSL communications to better understand the threats faced within the hospital environment without disturbing the operational network. Contrary to past assumptions, we find that medical devices have minimal exposure to the external Internet, but that medical support devices (e.g., servers, computer terminals) essential for daily hospital operations are much more exposed. While much of this communication appears to be benign, we discover evidence of insecure and broken cryptography and misconfigured devices, and potential botnet activity. Analyzing the network ecosystem in which they operate gives us an insight into the weaknesses and misconfigurations hospitals need to address to ensure the safety and privacy of patients.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2019/02/ndss2019_03B-1-1_Vargas_paper.pdf",
            "keywords": [
                "Digital Healthcare Security",
                "Network Analysis",
                "Medical Device Vulnerabilities",
                "D-HAI",
                "Cryptography Misconfigurations"
            ]
        },
        "url": "URL#2737703",
        "sema_paperId": "c771bd59b958ecfb5fecc6cbca53b688839fb830"
    },
    {
        "@score": "1",
        "@id": "2737704",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "236/6947",
                        "text": "Jack Wampler"
                    },
                    {
                        "@pid": "239/8918",
                        "text": "Ian Martiny"
                    },
                    {
                        "@pid": "60/8733",
                        "text": "Eric Wustrow"
                    }
                ]
            },
            "title": "ExSpectre: Hiding Malware in Speculative Execution.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/WamplerMW19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/exspectre-hiding-malware-in-speculative-execution/",
            "url": "https://dblp.org/rec/conf/ndss/WamplerMW19",
            "abstract": "\u2014Recently, the Spectre and Meltdown attacks revealed serious vulnerabilities in modern CPU designs, allowing an attacker to ex\ufb01ltrate data from sensitive programs. These vulnerabilities take advantage of speculative execution to coerce a processor to perform computation that would otherwise not occur, leaking the resulting information via side channels to an attacker. In this paper, we extend these ideas in a different direction, and leverage speculative execution in order to hide malware from both static and dynamic analysis. Using this technique, critical portions of a malicious program\u2019s computation can be shielded from view, such that even a debugger following an instruction-level trace of the program cannot tell how its results were computed. We introduce ExSpectre , which compiles arbitrary malicious code into a seemingly-benign payload binary. When a separate trigger program runs on the same machine, it mistrains the CPU\u2019s branch predictor, causing the payload program to speculatively execute its malicious payload, which communicates speculative results back to the rest of the payload program to change its real-world behavior.",
            "keywords": [
                "Speculative Execution",
                "Malware Hiding",
                "Side Channel Attacks",
                "Branch Prediction",
                "ExSpectre"
            ]
        },
        "url": "URL#2737704",
        "sema_paperId": "25eab72f0ae87d6a7f5d025a08f847bd06b5c035"
    },
    {
        "@score": "1",
        "@id": "2737705",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "123/7149",
                        "text": "Binghui Wang"
                    },
                    {
                        "@pid": "24/5124-1",
                        "text": "Jinyuan Jia 0001"
                    },
                    {
                        "@pid": "03/9437",
                        "text": "Neil Zhenqiang Gong"
                    }
                ]
            },
            "title": "Graph-based Security and Privacy Analytics via Collective Classification with Joint Weight Learning and Propagation.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/WangJG19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/graph-based-security-and-privacy-analytics-via-collective-classification-with-joint-weight-learning-and-propagation/",
            "url": "https://dblp.org/rec/conf/ndss/WangJG19",
            "abstract": "Many security and privacy problems can be modeled as a graph classification problem, where nodes in the graph are classified by collective classification simultaneously. State- of-the-art collective classification methods for such graph-based security and privacy analytics follow the following paradigm: assign weights to edges of the graph, iteratively propagate reputation scores of nodes among the weighted graph, and use the final reputation scores to classify nodes in the graph. The key challenge is to assign edge weights such that an edge has a large weight if the two corresponding nodes have the same label, and a small weight otherwise. Although collective classification has been studied and applied for security and privacy problems for more than a decade, how to address this challenge is still an open question. For instance, most existing methods simply set a constant weight to all edges.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2019/02/ndss2019_11-1_Wang_paper.pdf",
            "keywords": [
                "Graph-based Security Analytics",
                "Collective Classification",
                "Edge Weight Assignment",
                "Reputation Score Propagation",
                "Node Classification"
            ]
        },
        "url": "URL#2737705"
    },
    {
        "@score": "1",
        "@id": "2737706",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "04/10838",
                        "text": "Daimeng Wang"
                    },
                    {
                        "@pid": "154/7852",
                        "text": "Ajaya Neupane"
                    },
                    {
                        "@pid": "31/8302",
                        "text": "Zhiyun Qian"
                    },
                    {
                        "@pid": "86/2654",
                        "text": "Nael B. Abu-Ghazaleh"
                    },
                    {
                        "@pid": "k/SrikanthVKrishnamurthy",
                        "text": "Srikanth V. Krishnamurthy"
                    },
                    {
                        "@pid": "87/2240",
                        "text": "Edward J. M. Colbert"
                    },
                    {
                        "@pid": "12/6699",
                        "text": "Paul L. Yu"
                    }
                ]
            },
            "title": "Unveiling your keystrokes: A Cache-based Side-channel Attack on Graphics Libraries.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/WangNQAKCY19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/unveiling-your-keystrokes-a-cache-based-side-channel-attack-on-graphics-libraries/",
            "url": "https://dblp.org/rec/conf/ndss/WangNQAKCY19",
            "abstract": "Operating systems use shared memory to improve performance. However, as shown in recent studies, attackers can exploit CPU cache side-channels associated with shared memory to extract sensitive information. The attacks that were previously attempted typically only detect the presence of a certain operation and require significant manual analysis to identify and evaluate their effectiveness. Moreover, very few of them target graphics libraries which are commonly used, but difficult to attack. In this paper, we consider the execution time of shared libraries as the side-channel, and showcase a completely automated technique to discover and select exploitable side-channels on shared graphics libraries. In essence, we first collect the cache lines accessed by a victim process during different key presses offline, and then use machine learning to infer the best cache lines (e.g., easily measurable, robust to noise, high information leakage) for a flush and reload attack. We are able to discover effective strategies to classify what keys have been pressed. Using this approach, we not only preclude the need for manual analyses of code and traces \u2014 the automated system discovered many previously unknown sidechannels of the type we are interested in, but also achieve high precision in terms of inferring the sensitive information entered on desktop and Android platforms. We show that our approach infers the passwords with lowercase letters and numbers 10,000 1,000,000 times faster than random guessing. For a large fraction of PINs consisting of 4 to 6 digits, we are able to infer them within 20 and 80 guesses respectively. Finally, we suggest ways to mitigate these attacks.",
            "keywords": [
                "Cache-based Side-channel Attack",
                "Graphics Libraries",
                "Shared Memory",
                "Automated Side-channel Discovery",
                "Keystroke Inference"
            ]
        },
        "url": "URL#2737706",
        "sema_paperId": "8e0881c11a1a66366a1077ceb127a61308ed2518"
    },
    {
        "@score": "1",
        "@id": "2737707",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "220/3081",
                        "text": "Ke Coby Wang"
                    },
                    {
                        "@pid": "r/MichaelKReiter",
                        "text": "Michael K. Reiter"
                    }
                ]
            },
            "title": "How to End Password Reuse on the Web.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/WangR19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/how-to-end-password-reuse-on-the-web/",
            "url": "https://dblp.org/rec/conf/ndss/WangR19",
            "abstract": "We present a framework by which websites can coordinate to make it difficult for users to set similar passwords at these websites, in an effort to break the culture of password reuse on the web today. Though the design of such a framework is fraught with risks to users' security and privacy, we show that these risks can be effectively mitigated through careful scoping of the goals for such a framework and through principled design. At the core of our framework is a private set-membership-test protocol that enables one website to determine, upon a user setting a password for use at it, whether that user has already set a similar password at another website, but with neither side disclosing to the other the password(s) it employs in the protocol. Our framework then layers over this protocol a collection of techniques to mitigate the leakage necessitated by such a test. These mechanisms are consistent with common user experience today, and so our framework should be unobtrusive to users who do not reuse similar passwords across websites (e.g., due to having adopted a password manager). Through a working implementation of our framework and optimization of its parameters based on insights of how passwords tend to be reused, we show that our design can meet the scalability challenges facing such a service.",
            "keywords": [
                "Password Management",
                "Password Reuse",
                "Privacy-preserving Protocols",
                "Set-membership Testing",
                "User Experience"
            ]
        },
        "url": "URL#2737707",
        "sema_paperId": "4c51c1764eadc6e1b9db707500a5eb1c23288d5d"
    },
    {
        "@score": "1",
        "@id": "2737708",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "145/2706",
                        "text": "Samuel Weiser"
                    },
                    {
                        "@pid": "59/8645",
                        "text": "Mario Werner"
                    },
                    {
                        "@pid": "117/5967",
                        "text": "Ferdinand Brasser"
                    },
                    {
                        "@pid": "197/5046",
                        "text": "Maja Malenko"
                    },
                    {
                        "@pid": "91/4831",
                        "text": "Stefan Mangard"
                    },
                    {
                        "@pid": "s/AhmadRezaSadeghi",
                        "text": "Ahmad-Reza Sadeghi"
                    }
                ]
            },
            "title": "TIMBER-V: Tag-Isolated Memory Bringing Fine-grained Enclaves to RISC-V.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/WeiserWBMMS19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/timber-v-tag-isolated-memory-bringing-fine-grained-enclaves-to-risc-v/",
            "url": "https://dblp.org/rec/conf/ndss/WeiserWBMMS19",
            "abstract": "Embedded computing devices are used on a large scale in the emerging internet of things (IoT). However, their wide deployment raises the incentive for attackers to target these devices, as demonstrated by several recent attacks. As IoT devices are built for long service life, means are required to protect sensitive code in the presence of potential vulnerabilities, which might be discovered long after deployment. Tagged memory has been proposed as a mechanism to enforce various fine-grained security policies at runtime. However, none of the existing tagged memory schemes provides efficient and flexible compartmentalization in terms of isolated execution environments. We present TIMBER-V, a new tagged memory architecture featuring flexible and efficient isolation of code and data on small embedded systems. We overcome several limitations of previous schemes. We augment tag isolation with a memory protection unit to isolate individual processes, while maintaining low memory overhead. TIMBER-V significantly reduces the problem of memory fragmentation, and improves dynamic reuse of untrusted memory across security boundaries. TIMBER-V enables novel sharing of execution stacks across different security domains, in addition to interleaved heaps. TIMBER-V is compatible to existing code, supports real-time constraints and is open source. We show the efficiency of TIMBER-V by evaluating our proofof-concept implementation on the RISC-V simulator.",
            "keywords": [
                "Embedded Computing",
                "Tagged Memory Architecture",
                "Isolation Mechanisms",
                "IoT Security",
                "Memory Protection Unit"
            ]
        },
        "url": "URL#2737708",
        "sema_paperId": "35f74f95501207a000fd09426a5a9099d38d4827"
    },
    {
        "@score": "1",
        "@id": "2737709",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "144/7556",
                        "text": "Daoyuan Wu"
                    },
                    {
                        "@pid": "60/206",
                        "text": "Debin Gao"
                    },
                    {
                        "@pid": "87/4986",
                        "text": "Rocky K. C. Chang"
                    },
                    {
                        "@pid": "209/6119",
                        "text": "En He"
                    },
                    {
                        "@pid": "198/0911",
                        "text": "Eric K. T. Cheng"
                    },
                    {
                        "@pid": "d/RobertHDeng",
                        "text": "Robert H. Deng"
                    }
                ]
            },
            "title": "Understanding Open Ports in Android Applications: Discovery, Diagnosis, and Security Assessment.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/WuGCHCD19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/understanding-open-ports-in-android-applications-discovery-diagnosis-and-security-assessment/",
            "url": "https://dblp.org/rec/conf/ndss/WuGCHCD19",
            "abstract": "\u2014Open TCP/UDP ports are traditionally used by servers to provide application services, but they are also found in many Android apps. In this paper, we present the \ufb01rst open-port analysis pipeline, covering the discovery, diagnosis, and security assessment, to systematically understand open ports in Android apps and their threats. We design and deploy a novel on-device crowdsourcing app and its server-side analytic engine to continuously monitor open ports in the wild. Over a period of ten months, we have collected over 40 million port monitoring records from 3,293 users in 136 countries worldwide, which allow us to observe the actual execution of open ports in 925 popular apps and 725 built-in system apps. The crowdsourcing also provides us a more accurate view of the pervasiveness of open ports in Android apps at 15.3%, much higher than the previous estimation of 6.8%. We also develop a new static diagnostic tool to reveal that 61.8% of the open-port apps are solely due to embedded SDKs, and 20.7% suffer from insecure API usages. Finally, we perform three security assessments of open ports: (i) vulnerability analysis revealing \ufb01ve vulnerability patterns in open ports of popular apps, e.g., Instagram, Samsung Gear, Skype, and the widely-embedded Facebook SDK, (ii) inter-device connectivity measurement in 224 cellular networks and 2,181 WiFi networks through crowdsourced network scans, and (iii) experimental demonstration of effective denial-of-service attacks against mobile open ports.",
            "keywords": [
                "Open Ports",
                "Android Applications",
                "Security Assessment",
                "Crowdsourcing Analysis",
                "Vulnerability Patterns"
            ]
        },
        "url": "URL#2737709",
        "sema_paperId": "0e4b5b3567c989525a72992177e23295f10a955d"
    },
    {
        "@score": "1",
        "@id": "2737710",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "213/7633",
                        "text": "Fenghao Xu"
                    },
                    {
                        "@pid": "149/2350",
                        "text": "Wenrui Diao"
                    },
                    {
                        "@pid": "62/4119-1",
                        "text": "Zhou Li 0001"
                    },
                    {
                        "@pid": "224/2480",
                        "text": "Jiongyi Chen"
                    },
                    {
                        "@pid": "66/6560",
                        "text": "Kehuan Zhang"
                    }
                ]
            },
            "title": "BadBluetooth: Breaking Android Security Mechanisms via Malicious Bluetooth Peripherals.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/XuDLCZ19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/badbluetooth-breaking-android-security-mechanisms-via-malicious-bluetooth-peripherals/",
            "url": "https://dblp.org/rec/conf/ndss/XuDLCZ19",
            "abstract": "\u2014Bluetooth is a widely used communication tech- nology, especially under the scenarios of mobile computing and Internet of Things. Once paired with a host device, a Bluetooth device then can exchange commands and data, such as voice, keyboard/mouse inputs, network, blood pressure data, and so on, with the host. Due to the sensitivity of such data and commands, some security measures have already been built into the Bluetooth protocol, like authentication, encryption, authorization, etc. However, according to our studies on the Bluetooth protocol as well as its implementation on Android system, we \ufb01nd that there are still some design \ufb02aws which could lead to serious security consequences. For example, it is found that the authentication process on Bluetooth pro\ufb01les is quite inconsistent and coarse- grained: if a paired device changes its pro\ufb01le, it automatically gets trust and users would not be noti\ufb01ed. Also, there is no strict veri\ufb01cation on the information provided by the Bluetooth device itself, so that a malicious device can deceive a user by changing its name, pro\ufb01le information, and icon to be displayed on the screen. To better understand the problem, we performed a systematic study over the Bluetooth pro\ufb01les and presented three attacks to demonstrate the feasibility and potential damages of such Bluetooth design \ufb02aws. The attacks were implemented on a Raspberry Pi 2 device and evaluated with different Android OS versions ranging from 5.1 to the latest 8.1. The results showed adversaries could bypass existing protections of Android (e.g., permissions, isolations, etc.), launch Man-in-the-Middle attack, control the victim apps and system, steal sensitive information, etc. To mitigate such threats, a new Bluetooth validation mechanism was proposed. We implemented the prototype system based on the AOSP project and deployed it on a Google Pixel 2 phone for evaluation. The experiment showed our solution could effectively prevent the attacks.",
            "keywords": [
                "Bluetooth Security",
                "Android Vulnerabilities",
                "Malicious Bluetooth Devices",
                "Authentication Flaws",
                "Man-in-the-Middle Attack"
            ]
        },
        "url": "URL#2737710",
        "sema_paperId": "1789602c0f1da5cd591defa0606a409aa91a3a5f"
    },
    {
        "@score": "1",
        "@id": "2737711",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "218/6153",
                        "text": "Jiyong Yu"
                    },
                    {
                        "@pid": "227/7907",
                        "text": "Lucas Hsiung"
                    },
                    {
                        "@pid": "227/7804",
                        "text": "Mohamad El Hajj"
                    },
                    {
                        "@pid": "25/8166",
                        "text": "Christopher W. Fletcher"
                    }
                ]
            },
            "title": "Data Oblivious ISA Extensions for Side Channel-Resistant and High Performance Computing.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/YuHHF19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/data-oblivious-isa-extensions-for-side-channel-resistant-and-high-performance-computing/",
            "url": "https://dblp.org/rec/conf/ndss/YuHHF19",
            "abstract": "Blocking microarchitectural (digital) side channels is one of the most pressing challenges in hardware security today.  Recently, there has been a surge of effort that attempts to block these leakages by writing programs data obliviously.  In this model, programs are written to avoid placing sensitive data-dependent pressure on shared resources.  Despite recent efforts, however, running data oblivious programs on modern machines today is insecure and low performance.  First, writing programs obliviously assumes certain instructions in today's ISAs will not leak privacy, whereas today's ISAs and hardware provide no such guarantees.  Second, writing programs to avoid data-dependent behavior is inherently high performance overhead.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2019/02/ndss2019_05B-4_Yu_paper.pdf",
            "keywords": [
                "Hardware Security",
                "Data Oblivious Programming",
                "Microarchitectural Side Channels",
                "Performance Overhead",
                "Instruction Set Architecture (ISA)"
            ]
        },
        "url": "URL#2737711"
    },
    {
        "@score": "1",
        "@id": "2737712",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "139/0702",
                        "text": "Min Hong Yun"
                    },
                    {
                        "@pid": "27/2552-1",
                        "text": "Lin Zhong 0001"
                    }
                ]
            },
            "title": "Ginseng: Keeping Secrets in Registers When You Distrust the Operating System.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/Yun019",
            "ee": "https://www.ndss-symposium.org/ndss-paper/ginseng-keeping-secrets-in-registers-when-you-distrust-the-operating-system/",
            "url": "https://dblp.org/rec/conf/ndss/Yun019",
            "abstract": "Many mobile and embedded apps possess sensitive data, or secrets. Trusting the operating system (OS), they often keep their secrets in the memory. Recent incidents have shown that the memory is not necessarily secure because the OS can be compromised due to inevitable vulnerabilities resulting from its sheer size and complexity. Existing solutions protect sensitive data against an untrusted OS by running app logic in the Secure world, a Trusted Execution Environment (TEE) supported by the ARM TrustZone technology. Because app logic increases the attack surface of their TEE, these solutions do not work for third-party apps. This work aims to support third-party apps without growing the attack surface, significant development effort, or performance overhead. Our solution, called Ginseng, protects sensitive data by allocating them to registers at compile time and encrypting them at runtime before they enter the memory, due to function calls, exceptions or lack of physical registers. Ginseng does not run any app logic in the TEE and only requires minor markups to support existing apps. We report a prototype implementation based on LLVM, ARM Trusted Firmware (ATF), and the HiKey board. We evaluate it with both microbenchmarks and real-world secret-holding apps. Our evaluation shows Ginseng efficiently protects sensitive data with low engineering effort. For example, a Ginsengenabled web server, Nginx, protects the TLS master key with no measurable overhead. We find Ginseng\u2019s overhead is proportional to how often sensitive data in registers have to be encrypted and decrypted, i.e., spilling and restoring sensitive data on a function call or under high register pressure. As a result, Ginseng is most suited to protecting small sensitive data, like a password or social security number.",
            "keywords": [
                "Trusted Execution Environment",
                "Sensitive Data Protection",
                "Operating System Vulnerabilities",
                "Register Allocation",
                "Data Encryption"
            ]
        },
        "url": "URL#2737712",
        "sema_paperId": "0e92e56e9110040dfa0a8a8e3281a5546fb6ab8e"
    },
    {
        "@score": "1",
        "@id": "2737713",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "158/4724",
                        "text": "Xiaokuan Zhang"
                    },
                    {
                        "@pid": "69/7426",
                        "text": "Jihun Hamm"
                    },
                    {
                        "@pid": "r/MichaelKReiter",
                        "text": "Michael K. Reiter"
                    },
                    {
                        "@pid": "77/3503",
                        "text": "Yinqian Zhang"
                    }
                ]
            },
            "title": "Statistical Privacy for Streaming Traffic.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ZhangHRZ19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/statistical-privacy-for-streaming-traffic/",
            "url": "https://dblp.org/rec/conf/ndss/ZhangHRZ19",
            "abstract": "\u2014Machine learning empowers traf\ufb01c-analysis attacks that breach users\u2019 privacy from their encrypted traf\ufb01c. Recent advances in deep learning drastically escalate such threats. One prominent example demonstrated recently is a traf\ufb01c-analysis attack against video streaming by using convolutional neural networks. In this paper, we explore the adaption of techniques previously used in the domains of adversarial machine learning and differential privacy to mitigate the machine-learning-powered analysis of streaming traf\ufb01c. Our \ufb01ndings are twofold. First, constructing adversarial samples effectively confounds an adversary with a predetermined classi\ufb01er but is less effective when the adversary can adapt to the defense by using alternative classi\ufb01ers or training the classi\ufb01er with adversarial samples. Second, differential-privacy guarantees are very effective against such statistical-inference-based traf\ufb01c analysis, while remaining agnostic to the machine learning clas-si\ufb01ers used by the adversary. We propose two mechanisms for enforcing differential privacy for encrypted streaming traf\ufb01c, and evaluate their security and utility. Our empirical implementation and evaluation suggest that the proposed statistical privacy approaches are promising solutions in the underlying scenarios.",
            "keywords": [
                "Traffic Analysis",
                "Statistical Privacy",
                "Adversarial Samples",
                "Differential Privacy",
                "Streaming Traffic"
            ]
        },
        "url": "URL#2737713",
        "sema_paperId": "ec1ce15fed4dc46726e6c418b75fa87c87d26a12"
    },
    {
        "@score": "1",
        "@id": "2737714",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "65/7564",
                        "text": "Bingsheng Zhang"
                    },
                    {
                        "@pid": "95/10478",
                        "text": "Roman Oliynykov"
                    },
                    {
                        "@pid": "190/5268",
                        "text": "Hamed Balogun"
                    }
                ]
            },
            "title": "A Treasury System for Cryptocurrencies: Enabling Better Collaborative Intelligence.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ZhangOB19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/a-treasury-system-for-cryptocurrencies-enabling-better-collaborative-intelligence/",
            "url": "https://dblp.org/rec/conf/ndss/ZhangOB19",
            "abstract": "A treasury system is a community-controlled and decentralized collaborative decision-making mechanism for sustainable funding of blockchain development and maintenance. During each treasury period, project proposals are submitted, discussed, and voted for; top-ranked projects are funded from the treasury. The Dash governance system is a real-world example of such kind of systems. In this work, we, for the first time, provide a rigorous study of the treasury system. We modelled, designed, and implemented a provably secure treasury system that is compatible with most existing blockchain infrastructures, such as Bitcoin, Ethereum, etc. More specifically, the proposed treasury system supports liquid democracy/delegative voting for better collaborative intelligence. Namely, the stake holders can either vote directly on the proposed projects or delegate their votes to experts. Its core component is a distributed universally composable secure end-to-end verifiable voting protocol. The integrity of the treasury voting decisions is guaranteed even when all the voting committee members are corrupted. To further improve efficiency, we proposed the world\u2019s first honest verifier zero-knowledge proof for unit vector encryption with logarithmic size communication. This partial result may be of independent interest to other cryptographic protocols. A pilot system is implemented in Scala over the Scorex 2.0 framework, and its benchmark results indicate that the proposed system can support tens of thousands of treasury participants with high efficiency.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2019/02/ndss2019_02A-2_Zhang_paper.pdf",
            "keywords": [
                "Treasury System",
                "Decentralized Governance",
                "Collaborative Decision-Making",
                "Liquid Democracy",
                "Voting Protocols"
            ]
        },
        "url": "URL#2737714"
    },
    {
        "@score": "1",
        "@id": "2737715",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "164/2196",
                        "text": "Yangyong Zhang"
                    },
                    {
                        "@pid": "19/360-24",
                        "text": "Lei Xu 0024"
                    },
                    {
                        "@pid": "167/4353",
                        "text": "Abner Mendoza"
                    },
                    {
                        "@pid": "153/5855",
                        "text": "Guangliang Yang 0001"
                    },
                    {
                        "@pid": "183/4920",
                        "text": "Phakpoom Chinprutthiwong"
                    },
                    {
                        "@pid": "64/1147",
                        "text": "Guofei Gu"
                    }
                ]
            },
            "title": "Life after Speech Recognition: Fuzzing Semantic Misinterpretation for Voice Assistant Applications.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ZhangXMYCG19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/life-after-speech-recognition-fuzzing-semantic-misinterpretation-for-voice-assistant-applications/",
            "url": "https://dblp.org/rec/conf/ndss/ZhangXMYCG19",
            "abstract": "\u2014Popular Voice Assistant (VA) services such as Amazon Alexa and Google Assistant are now rapidly appifying their platforms to allow more \ufb02exible and diverse voice-controlled service experience. However, the ubiquitous deployment of VA devices and the increasing number of third-party applications have raised security and privacy concerns. While previous works such as hidden voice attacks mostly examine the problems of VA services\u2019 default Automatic Speech Recognition (ASR) component, our work analyzes and evaluates the security of the succeeding component after ASR, i.e., Natural Language Understanding (NLU), which performs semantic interpretation (i.e., text-to-intent) after ASR\u2019s acoustic-to-text processing. In particular, we focus on NLU\u2019s Intent Classi\ufb01er which is used in customizing machine understanding for third-party VA Applications (or vApps). We \ufb01nd that the semantic inconsistency caused by the improper semantic interpretation of an Intent Classi\ufb01er can create the opportunity of breaching the integrity of vApp processing when attackers delicately leverage some common spoken errors. In this paper, we design the \ufb01rst linguistic-model-guided fuzzing tool, named LipFuzzer, to assess the security of Intent Classi\ufb01er and systematically discover potential misinterpretation-prone spoken errors based on vApps\u2019 voice command templates. To guide the fuzzing, we construct adversarial linguistic models with the help of Statistical Relational Learning (SRL) and emerging Natural Language Processing (NLP) techniques. In evaluation, we have successfully veri\ufb01ed the effectiveness and accuracy of LipFuzzer. We also use LipFuzzer to evaluate both Amazon Alexa and Google Assistant vApp platforms. We have identi\ufb01ed that a large portion of real-world",
            "keywords": [
                "Voice Assistant Security",
                "Natural Language Understanding",
                "Intent Classifier",
                "Semantic Misinterpretation",
                "Fuzzing Tool"
            ]
        },
        "url": "URL#2737715",
        "sema_paperId": "082b66534929a7fbb431d4e847b178bbc3cf9352"
    },
    {
        "@score": "1",
        "@id": "2737716",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "87/734-12",
                        "text": "Lei Zhao 0012"
                    },
                    {
                        "@pid": "10/9994",
                        "text": "Yue Duan"
                    },
                    {
                        "@pid": "77/6178-1",
                        "text": "Heng Yin 0001"
                    },
                    {
                        "@pid": "86/4142",
                        "text": "Jifeng Xuan"
                    }
                ]
            },
            "title": "Send Hardest Problems My Way: Probabilistic Path Prioritization for Hybrid Fuzzing.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ZhaoDYX19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/send-hardest-problems-my-way-probabilistic-path-prioritization-for-hybrid-fuzzing/",
            "url": "https://dblp.org/rec/conf/ndss/ZhaoDYX19",
            "abstract": "Hybrid fuzzing which combines fuzzing and concolic execution has become an advanced technique for software vulnerability detection. Based on the observation that fuzzing and concolic execution are complementary in nature, the stateof-the-art hybrid fuzzing systems deploy \u201cdemand launch\u201d and \u201coptimal switch\u201d strategies. Although these ideas sound intriguing, we point out several fundamental limitations in them, due to oversimplified assumptions. We then propose a novel \u201cdiscriminative dispatch\u201d strategy to better utilize the capability of concolic execution. We design a novel Monte Carlo based probabilistic path prioritization model to quantify each path\u2019s difficulty and prioritize them for concolic execution. This model treats fuzzing as a random sampling process. It calculates each path\u2019s probability based on the sampling information. Finally, our model prioritizes and assigns the most difficult paths to concolic execution. We implement a prototype system DigFuzz and evaluate our system with two representative datasets. Results show that the concolic execution in DigFuzz outperforms than those in state-of-the-art hybrid fuzzing systems in every major aspect. In particular, the concolic execution in DigFuzz contributes to discovering more vulnerabilities (12 vs. 5) and producing more code coverage (18.9% vs. 3.8%) on the CQE dataset than the concolic execution in Driller.",
            "keywords": [
                "Hybrid Fuzzing",
                "Concolic Execution",
                "Path Prioritization",
                "Vulnerability Detection",
                "Probabilistic Model"
            ]
        },
        "url": "URL#2737716",
        "sema_paperId": "8ba39103cf0833fa3e37d7c442bc2f21e6d5ce46"
    },
    {
        "@score": "1",
        "@id": "2737717",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "140/6495",
                        "text": "Lianying Zhao"
                    },
                    {
                        "@pid": "m/MohammadMannan",
                        "text": "Mohammad Mannan"
                    }
                ]
            },
            "title": "TEE-aided Write Protection Against Privileged Data Tampering.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ZhaoM19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/tee-aided-write-protection-against-privileged-data-tampering/",
            "url": "https://dblp.org/rec/conf/ndss/ZhaoM19",
            "abstract": "Unauthorized data alteration has been a long-standing threat since the emergence of malware. System and application software can be reinstalled and hardware can be replaced, but user data is priceless in many cases. Especially in recent years, ransomware has become high-impact due to its direct monetization model. State-of-the-art defenses are mostly based on known signature or behavior analysis, and more importantly, require an uncompromised OS kernel. However, malware with the highest software privileges has shown its obvious existence.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2019/02/ndss2019_10-2_Zhao_paper.pdf",
            "keywords": [
                "Trusted Execution Environment",
                "Data Integrity",
                "Write Protection",
                "Malware Defense",
                "Ransomware Prevention"
            ]
        },
        "url": "URL#2737717"
    },
    {
        "@score": "1",
        "@id": "2737718",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "156/1033",
                        "text": "Qingchuan Zhao"
                    },
                    {
                        "@pid": "149/8302",
                        "text": "Chaoshun Zuo"
                    },
                    {
                        "@pid": "35/9056",
                        "text": "Giancarlo Pellegrino"
                    },
                    {
                        "@pid": "49/4102-1",
                        "text": "Zhiqiang Lin 0001"
                    }
                ]
            },
            "title": "Geo-locating Drivers: A Study of Sensitive Data Leakage in Ride-Hailing Services.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ZhaoZPL19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/geo-locating-drivers-a-study-of-sensitive-data-leakage-in-ride-hailing-services/",
            "url": "https://dblp.org/rec/conf/ndss/ZhaoZPL19",
            "abstract": "Increasingly, mobile application-based ride-hailing \nservices have become a very popular means of transportation. \nDue to the handling of business logic, these services also contain \na wealth of privacy-sensitive information such as GPS locations, \ncar plates, driver licenses, and payment data. Unlike many of \nthe mobile applications in which there is only one type of users, \nride-hailing services face two types of users: riders and drivers. \nWhile most of the efforts had focused on the rider\u2019s privacy, \nunfortunately, we notice little has been done to protect drivers. \nTo raise the awareness of the privacy issues with drivers, in \nthis paper we perform the first systematic study of the drivers\u2019 \nsensitive data leakage in ride-hailing services. More specifically, \nwe select 20 popular ride-hailing apps including Uber and Lyft \nand focus on one particular feature, namely the nearby cars \nfeature. Surprisingly, our experimental results show that largescale \ndata harvesting of drivers is possible for all of the ridehailing \nservices we studied. In particular, attackers can determine \nwith high-precision the driver\u2019s privacy-sensitive information \nincluding mostly visited address (e.g., home) and daily driving behaviors. \nMeanwhile, attackers can also infer sensitive information \nabout the business operations and performances of ride-hailing \nservices such as the number of rides, utilization of cars, and \npresence on the territory. In addition to presenting the attacks, \nwe also shed light on the countermeasures the service providers \ncould take to protect the driver\u2019s sensitive information.",
            "keywords": [
                "Ride-Hailing Services",
                "Driver Privacy",
                "Sensitive Data Leakage",
                "GPS Location Tracking",
                "Data Harvesting"
            ]
        },
        "url": "URL#2737718",
        "sema_paperId": "d5cea0a3ee1fe9553519d1c37a92638937baa307"
    },
    {
        "@score": "1",
        "@id": "2737719",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "08/2047",
                        "text": "Fei Zuo"
                    },
                    {
                        "@pid": "45/1827-1",
                        "text": "Xiaopeng Li 0001"
                    },
                    {
                        "@pid": "225/5250",
                        "text": "Patrick Young"
                    },
                    {
                        "@pid": "153/5297",
                        "text": "Lannan Luo"
                    },
                    {
                        "@pid": "81/583-1",
                        "text": "Qiang Zeng 0001"
                    },
                    {
                        "@pid": "225/5264",
                        "text": "Zhexin Zhang"
                    }
                ]
            },
            "title": "Neural Machine Translation Inspired Binary Code Similarity Comparison beyond Function Pairs.",
            "venue": "NDSS",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ZuoLYL0Z19",
            "ee": "https://www.ndss-symposium.org/ndss-paper/neural-machine-translation-inspired-binary-code-similarity-comparison-beyond-function-pairs/",
            "url": "https://dblp.org/rec/conf/ndss/ZuoLYL0Z19",
            "abstract": "Binary code analysis allows analyzing binary code without having access to the corresponding source code. It is widely used for vulnerability discovery, malware dissection, attack investigation, etc. A binary, after disassembly, is expressed in an assembly language. This inspires us to approach binary analysis by leveraging ideas and techniques from Natural Language Processing (NLP), a rich area focused on processing text of various natural languages. We notice that binary code analysis and NLP share a lot of analogical topics, such as semantics extraction, summarization, and classification. This work utilizes these ideas to address two important code similarity comparison problems. (I) Given a pair of basic blocks for different\ninstruction set architectures, determining whether their semantics is similar or not; and (II) given a piece of code of interest, determining if it is contained in another piece of assembly code from a different architecture. The solutions to these two problems have many applications, such as cross-architecture code plagiarism detection, malware identification, and vulnerability discovery.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2019/02/ndss2019_11-4_Zuo_paper.pdf",
            "keywords": [
                "Binary Code Analysis",
                "Natural Language Processing",
                "Code Similarity Comparison",
                "Cross-Architecture Detection",
                "Malware Identification"
            ]
        },
        "url": "URL#2737719"
    },
    {
        "@score": "1",
        "@id": "2781652",
        "info": {
            "title": "26th Annual Network and Distributed System Security Symposium, NDSS 2019, San Diego, California, USA, February 24-27, 2019",
            "venue": "NDSS",
            "publisher": "The Internet Society",
            "year": "2019",
            "type": "Editorship",
            "access": "open",
            "key": "conf/ndss/2019",
            "ee": "https://www.ndss-symposium.org/ndss2019/",
            "url": "https://dblp.org/rec/conf/ndss/2019",
            "abstract": null
        },
        "url": "URL#2781652",
        "sema_paperId": "96ff486cc064e26b4c47d84386f7ca3cc35e2ae3"
    }
]