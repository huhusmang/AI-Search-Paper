[
    {
        "@score": "1",
        "@id": "2305474",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "08/1117-1",
                        "text": "Michael Schwarz 0001"
                    },
                    {
                        "@pid": "172/1127",
                        "text": "Moritz Lipp"
                    },
                    {
                        "@pid": "230/4065",
                        "text": "Claudio Canella"
                    },
                    {
                        "@pid": "153/6192",
                        "text": "Robert Schilling"
                    },
                    {
                        "@pid": "241/7066",
                        "text": "Florian Kargl"
                    },
                    {
                        "@pid": "166/1494",
                        "text": "Daniel Gruss"
                    }
                ]
            },
            "title": "ConTExT: A Generic Approach for Mitigating Spectre.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/0001LCSKG20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/context-a-generic-approach-for-mitigating-spectre/",
            "url": "https://dblp.org/rec/conf/ndss/0001LCSKG20",
            "abstract": "Out-of-order execution and speculative execution are among the biggest contributors to performance and efficiency of modern processors. However, they are inconsiderate, leaking secret data during the transient execution of instructions. Many solutions and hardware fixes have been proposed for mitigating transient-execution attacks. However, they either do not eliminate the leakage entirely or introduce unacceptable performance penalties. In this paper, we propose ConTExT, a Considerate Transient Execution Technique. ConTExT is a minimal and fully backward compatible architecture change. The basic idea of ConTExT is that secrets can enter registers but not transiently leave them. ConTExT transforms Spectre from a problem that cannot be solved purely in software [65], to a problem that is not easy to solve, but solvable in software. For this, ConTExT requires minimal, fully backward-compatible modifications of applications, compilers, operating systems, and the hardware. ConTExT offers full protection for secrets in memory and secrets in registers. With ConTExT-light, we propose a software-only solution of ConTExT for existing commodity CPUs protecting secrets in memory. We evaluate the security and performance of ConTExT. Even when over-approximating with ConTExT-light, we observe no performance overhead for unprotected code and data, and an overhead between 0% and 338% for security-critical applications while protecting against all Spectre variants.",
            "keywords": [
                "Transient Execution",
                "Spectre Mitigation",
                "Out-of-Order Execution",
                "Security in Processors",
                "ConTExT Technique"
            ]
        },
        "url": "URL#2305474",
        "sema_paperId": "86c8ee6d13160b721ad9934f46a3dcf47a2706e2"
    },
    {
        "@score": "1",
        "@id": "2305475",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "145/3288-1",
                        "text": "Tianhao Wang 0001"
                    },
                    {
                        "@pid": "241/5891",
                        "text": "Milan Lopuha\u00e4-Zwakenberg"
                    },
                    {
                        "@pid": "220/3927",
                        "text": "Zitao Li"
                    },
                    {
                        "@pid": "s/BorisSkoric",
                        "text": "Boris Skoric"
                    },
                    {
                        "@pid": "l/NinghuiLi",
                        "text": "Ninghui Li"
                    }
                ]
            },
            "title": "Locally Differentially Private Frequency Estimation with Consistency.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/0001LLSL20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/locally-differentially-private-frequency-estimation-with-consistency/",
            "url": "https://dblp.org/rec/conf/ndss/0001LLSL20",
            "abstract": "Local Differential Privacy (LDP) protects user privacy from the data collector. LDP protocols have been increasingly deployed in the industry. A basic building block is frequency oracle (FO) protocols, which estimate frequencies of values. While several FO protocols have been proposed, the design goal does not lead to optimal results for answering many queries. In this paper, we show that adding post-processing steps to FO protocols by exploiting the knowledge that all individual frequencies should be non-negative and they sum up to one can lead to significantly better accuracy for a wide range of tasks, including frequencies of individual values, frequencies of the most frequent values, and frequencies of subsets of values. We consider 10 different methods that exploit this knowledge differently. We establish theoretical relationships between some of them and conducted extensive experimental evaluations to understand which methods should be used for different query tasks.",
            "keywords": [
                "Local Differential Privacy",
                "Frequency Estimation",
                "Frequency Oracle Protocols",
                "Post-Processing Steps",
                "Non-Negative Frequencies"
            ]
        },
        "url": "URL#2305475",
        "sema_paperId": "b27acac335a0e38c975a455c501342b7349b7f55"
    },
    {
        "@score": "1",
        "@id": "2305476",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "84/4318-1",
                        "text": "Takuya Watanabe 0001"
                    },
                    {
                        "@pid": "20/7998",
                        "text": "Eitaro Shioji"
                    },
                    {
                        "@pid": "26/3158",
                        "text": "Mitsuaki Akiyama"
                    },
                    {
                        "@pid": "62/6630",
                        "text": "Tatsuya Mori"
                    }
                ]
            },
            "title": "Melting Pot of Origins: Compromising the Intermediary Web Services that Rehost Websites.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/0001SAM20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/melting-pot-of-origins-compromising-the-intermediary-web-services-that-rehost-websites/",
            "url": "https://dblp.org/rec/conf/ndss/0001SAM20",
            "abstract": "\u2014Intermediary web services such as web proxies, web translators, and web archives have become pervasive as a means to enhance the openness of the web. These services aim to remove the intrinsic obstacles to web access; i.e., access blocking, language barriers, and missing web pages. In this study, we refer to these services as web rehosting services and make the \ufb01rst exploration of their security \ufb02aws. The web rehosting services use a single domain name to rehost several websites that have distinct domain names; this characteristic makes web rehosting services intrinsically vulnerable to violating the same origin policy if not operated carefully. Based on the intrinsic vulnerability of web rehosting services, we demonstrate that an attacker can perform \ufb01ve different types of attacks that target users who make use of web rehosting services: persistent man-in-the-middle attack, abusing privileges to access various resources, stealing credentials, stealing browser history, and session hijacking/injection. Our extensive analysis of 21 popular web rehosting services, which have more than 200 million accesses per day, revealed that these attacks are feasible. In response to this observation, we provide effective countermeasures against each type of attack.",
            "keywords": [
                "Web Rehosting Services",
                "Web Security",
                "Same Origin Policy",
                "Man-in-the-Middle Attacks",
                "Session Hijacking"
            ]
        },
        "url": "URL#2305476",
        "sema_paperId": "9939bcc68c8750177ebc4ee7a1175334e822dc14"
    },
    {
        "@score": "1",
        "@id": "2305477",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "19/1766-2",
                        "text": "Ting Chen 0002"
                    },
                    {
                        "@pid": "153/9102",
                        "text": "Rong Cao"
                    },
                    {
                        "@pid": "63/1303",
                        "text": "Ting Li"
                    },
                    {
                        "@pid": "53/1565",
                        "text": "Xiapu Luo"
                    },
                    {
                        "@pid": "64/1147",
                        "text": "Guofei Gu"
                    },
                    {
                        "@pid": "32/1720-2",
                        "text": "Yufei Zhang 0002"
                    },
                    {
                        "@pid": "270/2453",
                        "text": "Zhou Liao"
                    },
                    {
                        "@pid": "127/6289",
                        "text": "Hang Zhu"
                    },
                    {
                        "@pid": "67/6383",
                        "text": "Gang Chen"
                    },
                    {
                        "@pid": "270/2519",
                        "text": "Zheyuan He"
                    },
                    {
                        "@pid": "03/7238",
                        "text": "Yuxing Tang"
                    },
                    {
                        "@pid": "59/554",
                        "text": "Xiaodong Lin 0001"
                    },
                    {
                        "@pid": "26/3075-1",
                        "text": "Xiaosong Zhang 0001"
                    }
                ]
            },
            "title": "SODA: A Generic Online Detection Framework for Smart Contracts.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/0002CLLGZLZCHTL20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/soda-a-generic-online-detection-framework-for-smart-contracts/",
            "url": "https://dblp.org/rec/conf/ndss/0002CLLGZLZCHTL20",
            "abstract": "\u2014Smart contracts have become lucrative and profitable targets for attackers because they can hold a great amount of money. Unfortunately, existing of\ufb02ine approaches for discovering the vulnerabilities in smart contracts or checking the correctness of smart contracts cannot conduct online detection of attacking transactions. Besides, existing online approaches only focus on speci\ufb01c attacks and cannot be easily extended to detect other attacks. Moreover, developing a new online detection system for smart contracts from scratch is time-consuming and requires deep understanding of blockchain internals, thus making it dif\ufb01cult to quickly implement and deploy mechanisms to detect new attacks. In this paper, we propose a novel generic online detection framework named SODA for smart contracts on any blockchains that support Ethereum virtual machine (EVM). SODA distinguishes itself from existing online approaches through its capability, ef\ufb01ciency, and compatibility. First, SODA empowers users to easily develop apps for detecting various attacks online (i.e., when attacks happen) by separating information collection and attack detection with layered design. At the higher layer, SODA provides uni\ufb01ed interfaces to develop detection apps against various attacks. At the lower layer, SODA instruments EVM to collect all primitive information necessary to detect various attacks and constructs 11 kinds of structural information for the ease of developing apps. Based on SODA , users can develop new apps in a few",
            "keywords": [
                "Smart Contracts",
                "Online Detection",
                "Attack Detection",
                "Blockchain Security",
                "Ethereum Virtual Machine (EVM)"
            ]
        },
        "url": "URL#2305477",
        "sema_paperId": "2eb518535b03de02c332028063f34bd045dc2ab4"
    },
    {
        "@score": "1",
        "@id": "2305478",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "243/2583-1",
                        "text": "Daniel Perez 0001"
                    },
                    {
                        "@pid": "46/2924",
                        "text": "Benjamin Livshits"
                    }
                ]
            },
            "title": "Broken Metre: Attacking Resource Metering in EVM.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/0002L20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/broken-metre-attacking-resource-metering-in-evm/",
            "url": "https://dblp.org/rec/conf/ndss/0002L20",
            "abstract": "Blockchain systems, such as Ethereum, use an approach called \"metering\" to assign a cost to smart contract execution, an approach which is designed to incentivise miners to operate the network and protect it against DoS attacks. In the past, the imperfections of Ethereum metering allowed several DoS attacks which were countered through modification of the metering mechanism. \nThis paper presents a new DoS attack on Ethereum which systematically exploits its metering mechanism. We first replay and analyse several months of transactions, during which we discover a number of discrepancies in the metering model, such as significant inconsistencies in the pricing of the instructions. We further demonstrate that there is very little correlation between the execution cost and the utilised resources, such as CPU and memory. Based on these observations, we present a new type of DoS attack we call Resource Exhaustion Attack, which uses these imperfections to generate low-throughput contracts. To do this, we design a genetic algorithm that generates contracts with a throughput on average 200 times slower than typical contracts. We then show that all major Ethereum client implementations are vulnerable and, if running on commodity hardware, would be unable to stay in sync with the network when under attack. We argue that such an attack could be financially attractive not only for Ethereum competitors and speculators, but also for Ethereum miners. Finally, we discuss short-term and potential long-term fixes against such attacks. Our attack has been responsibly disclosed to the Ethereum Foundation and awarded a bug bounty reward of 5,000 USD.",
            "keywords": [
                "Ethereum",
                "Smart Contract Execution",
                "DoS Attacks",
                "Resource Exhaustion Attack",
                "Metering Mechanism"
            ]
        },
        "url": "URL#2305478",
        "sema_paperId": "a7c2b74d47e5c24681d681b3b0e3f62a25fa2101"
    },
    {
        "@score": "1",
        "@id": "2305479",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "88/845-2",
                        "text": "Zhongjie Wang 0002"
                    },
                    {
                        "@pid": "155/8420",
                        "text": "Shitong Zhu"
                    },
                    {
                        "@pid": "74/5570-3",
                        "text": "Yue Cao 0003"
                    },
                    {
                        "@pid": "31/8302",
                        "text": "Zhiyun Qian"
                    },
                    {
                        "@pid": "69/6818",
                        "text": "Chengyu Song"
                    },
                    {
                        "@pid": "k/SrikanthVKrishnamurthy",
                        "text": "Srikanth V. Krishnamurthy"
                    },
                    {
                        "@pid": "129/2261",
                        "text": "Kevin S. Chan"
                    },
                    {
                        "@pid": "11/317",
                        "text": "Tracy D. Braun"
                    }
                ]
            },
            "title": "SymTCP: Eluding Stateful Deep Packet Inspection with Automated Discrepancy Discovery.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/0002Z0QSKCB20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/symtcp-eluding-stateful-deep-packet-inspection-with-automated-discrepancy-discovery/",
            "url": "https://dblp.org/rec/conf/ndss/0002Z0QSKCB20",
            "abstract": "A key characteristic of commonly deployed deep packet inspection (DPI) systems is that they implement a simplified state machine of the network stack that often differs from that of endhosts. The discrepancies between the two state machines have been exploited to bypass such DPI based middleboxes. However, most prior approaches to do so rely on manually crafted adversarial packets, which not only are labor-intensive but may not work well across a plurality of DPI-based middleboxes. Our goal in this work is to develop an automated way to craft candidate adversarial packets, targeting TCP implementations in particular. Our approach to achieving this goal hinges on the key insight that while the TCP state machines of DPI implementations are obscure, those of the endhosts are well established. Thus, in our system SYMTCP, using symbolic execution, we systematically explore the TCP implementation of an endhost, identifying candidate packets that can reach critical points in the code (e.g., which causes the packets to be accepted or dropped/ignored); such automatically identified packets are then fed through the DPI middlebox to determine if a discrepancy is induced and the middlebox can be eluded. We find that our approach is extremely effective. It can generate tens of thousands of candidate adversarial packets in less than an hour. When evaluating against multiple state-of-the-art DPI systems such as Zeek and Snort, as well as a state-level censorship system, viz. the Great Firewall of China, we identify not only previously known evasion strategies, but also novel ones that were never previously reported (e.g., involving the urgent pointer). The system can be extended easily towards other combinations of operating systems and DPI middleboxes, and serves as a valuable tool for testing future DPIs\u2019 robustness against evasion attempts.",
            "keywords": [
                "Deep Packet Inspection",
                "TCP State Machine",
                "Adversarial Packet Generation",
                "Evasion Techniques",
                "Symbolic Execution"
            ]
        },
        "url": "URL#2305479",
        "sema_paperId": "872fd280b3080005ac157c7a9a56c24b1701b9cf"
    },
    {
        "@score": "1",
        "@id": "2305480",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "88/5808-6",
                        "text": "Matthew Smith 0006"
                    },
                    {
                        "@pid": "117/8959",
                        "text": "Martin Strohmeier"
                    },
                    {
                        "@pid": "241/6018",
                        "text": "Jon Harman"
                    },
                    {
                        "@pid": "75/5939",
                        "text": "Vincent Lenders"
                    },
                    {
                        "@pid": "87/2623",
                        "text": "Ivan Martinovic"
                    }
                ]
            },
            "title": "A View from the Cockpit: Exploring Pilot Reactions to Attacks on Avionic Systems.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/0006SHLM20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/a-view-from-the-cockpit-exploring-pilot-reactions-to-attacks-on-avionic-systems/",
            "url": "https://dblp.org/rec/conf/ndss/0006SHLM20",
            "abstract": "\u2014Many wireless communications systems found in aircraft lack standard security mechanisms, leaving them vulnerable to attack. With affordable software-de\ufb01ned radios readily available, a novel threat has emerged which allows a wide range of attackers to easily interfere with wireless avionic systems. Whilst these vulnerabilities are known, predicting their ultimate effect is dif\ufb01cult. A major factor in this effect is how \ufb02ight crew respond, especially whether their extensive training in fault handling helps them to manage attacks. To investigate this we conducted a user study, inviting 30 Airbus A320 type-rated pilots to \ufb02y simulator scenarios in which they were subjected to attacks on their avionics. We use wireless attacks on three safety-related systems, based on existing literature: Traf\ufb01c Collision Avoidance System (TCAS), Ground Proximity Warning System (GPWS) and the Instrument Landing System (ILS). To analyze their response, we collected control input data coupled with closed and open interview responses. We found that all three attack scenarios created signi\ufb01cant control impact and disruption through missed approaches, avoidance maneuvers and diversions. They further increased workload, distrust in the affected system, and for each attack, at least a third of our participants switched off the system entirely\u2014even if they were important safety systems. All pilots felt the scenarios were useful, with 93.3% feeling that simulator training for wireless attacks could be valuable.",
            "keywords": [
                "Avionic Systems Security",
                "Wireless Attacks",
                "Pilot Response",
                "Simulator Training",
                "Safety System Disruption"
            ]
        },
        "url": "URL#2305480",
        "sema_paperId": "beef879ee4cbe9c123f219991603f5fe9a701bb8"
    },
    {
        "@score": "1",
        "@id": "2305481",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "06/6785-16",
                        "text": "Yang Zhang 0016"
                    },
                    {
                        "@pid": "83/8816",
                        "text": "Mathias Humbert"
                    },
                    {
                        "@pid": "206/8592",
                        "text": "Bartlomiej Surma"
                    },
                    {
                        "@pid": "134/8943",
                        "text": "Praveen Manoharan 0001"
                    },
                    {
                        "@pid": "94/6462",
                        "text": "Jilles Vreeken"
                    },
                    {
                        "@pid": "b/MichaelBackes1",
                        "text": "Michael Backes 0001"
                    }
                ]
            },
            "title": "Towards Plausible Graph Anonymization.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/0016HSMV020",
            "ee": "https://www.ndss-symposium.org/ndss-paper/towards-plausible-graph-anonymization/",
            "url": "https://dblp.org/rec/conf/ndss/0016HSMV020",
            "abstract": "Social graphs derived from online social interactions contain a wealth of information that is nowadays extensively used by both industry and academia. However, as social graphs contain sensitive information, they need to be properly anonymized before release. Most of the existing graph anonymization mechanisms rely on the perturbation of the original graph's edge set. In this paper, we identify a fundamental weakness of these mechanisms: They neglect the strong structural proximity between friends in social graphs, thus add implausible fake edges for anonymization. \n \nTo exploit this weakness, we first propose a metric to quantify an edge's plausibility by relying on graph embedding. Extensive experiments on three real-life social network datasets demonstrate that our plausibility metric can very effectively differentiate fake edges from original edges with AUC (area under the ROC curve) values above 0.95 in most of the cases. We then rely on a Gaussian mixture model to automatically derive the threshold on the edge plausibility values to determine whether an edge is fake, which enables us to recover to a large extent the original graph from the anonymized graph. We further demonstrate that our graph recovery attack jeopardizes the privacy guarantees provided by the considered graph anonymization mechanisms. \n \nTo mitigate this vulnerability, we propose a method to generate fake yet plausible edges given the graph structure and incorporate it into the existing anonymization mechanisms. Our evaluation demonstrates that the enhanced mechanisms decrease the chances of graph recovery, reduce the success of graph de-anonymization (up to 30\\%), and provide even better utility than the existing anonymization mechanisms.",
            "keywords": [
                "Graph Anonymization",
                "Social Network Analysis",
                "Edge Plausibility",
                "Graph Recovery Attack",
                "De-anonymization"
            ]
        },
        "url": "URL#2305481",
        "sema_paperId": "656d1304b59b676e1d8bb39b3971c5f0e9918a32"
    },
    {
        "@score": "1",
        "@id": "2305482",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "187/3595",
                        "text": "Hojjat Aghakhani"
                    },
                    {
                        "@pid": "201/9325",
                        "text": "Fabio Gritti"
                    },
                    {
                        "@pid": "270/2347",
                        "text": "Francesco Mecca"
                    },
                    {
                        "@pid": "81/10928",
                        "text": "Martina Lindorfer"
                    },
                    {
                        "@pid": "32/8412",
                        "text": "Stefano Ortolani"
                    },
                    {
                        "@pid": "56/490",
                        "text": "Davide Balzarotti"
                    },
                    {
                        "@pid": "v/GiovanniVigna",
                        "text": "Giovanni Vigna"
                    },
                    {
                        "@pid": "k/ChristopherKruegel",
                        "text": "Christopher Kruegel"
                    }
                ]
            },
            "title": "When Malware is Packin&apos; Heat; Limits of Machine Learning Classifiers Based on Static Analysis Features.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/AghakhaniGMLOBV20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/when-malware-is-packin-heat-limits-of-machine-learning-classifiers-based-on-static-analysis-features/",
            "url": "https://dblp.org/rec/conf/ndss/AghakhaniGMLOBV20",
            "abstract": ".",
            "keywords": [
                "Malware Detection",
                "Static Analysis",
                "Machine Learning Classifiers",
                "Feature Limitations",
                "Malware Analysis"
            ]
        },
        "url": "URL#2305482",
        "sema_paperId": "1fe696eebdfdfc629fd662eb61da173d7e676be1"
    },
    {
        "@score": "1",
        "@id": "2305483",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "175/4787",
                        "text": "Naif Saleh Almakhdhub"
                    },
                    {
                        "@pid": "187/9046",
                        "text": "Abraham A. Clements"
                    },
                    {
                        "@pid": "57/95",
                        "text": "Saurabh Bagchi"
                    },
                    {
                        "@pid": "31/1273",
                        "text": "Mathias Payer"
                    }
                ]
            },
            "title": "\u00b5RAI: Securing Embedded Systems with Return Address Integrity.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/AlmakhdhubCBP20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/murai-securing-embedded-systems-with-return-address-integrity/",
            "url": "https://dblp.org/rec/conf/ndss/AlmakhdhubCBP20",
            "abstract": "Embedded systems are deployed in security critical environments and have become a prominent target for remote attacks. Microcontroller-based systems (MCUS) are particularly vulnerable due to a combination of limited resources and low level programming which leads to bugs. Since MCUS are often a part of larger systems, vulnerabilities may jeopardize not just the security of the device itself but that of other systems as well. For example, exploiting a WiFi System on Chip (SoC) allows an attacker to hijack the smart phone\u2019s application processor. Control-flow hijacking targeting the backward edge (e.g., Return-Oriented Programming\u2013ROP) remains a threat for MCUS. Current defenses are either susceptible to ROP-style attacks or require special hardware such as a Trusted Execution Environment (TEE) that is not commonly available on MCUS. We present \u03bcRAI , a compiler-based mitigation to prevent control-flow hijacking attacks targeting backward edges by enforcing the Return Address Integrity (RAI) property on MCUS. \u03bcRAI does not require any additional hardware such as TEE, making it applicable to the wide majority of MCUS. To achieve this, \u03bcRAI introduces a technique that moves return addresses from writable memory, to readable and executable memory. It repurposes a single general purpose register that is never spilled, and uses it to resolve the correct return location. We evaluate against the different control-flow hijacking attacks scenarios targeting return addresses (e.g., arbitrary write), and demonstrate how \u03bcRAI prevents them all. Moreover, our evaluation shows that \u03bcRAI enforces its protection with negligible overhead.",
            "keywords": [
                "Embedded Systems Security",
                "Control-Flow Hijacking",
                "Return Address Integrity",
                "Microcontroller Vulnerabilities",
                "Return-Oriented Programming (ROP)"
            ]
        },
        "url": "URL#2305483",
        "sema_paperId": "5f6331feba4c5da40015593389ae33a4b9af17b7"
    },
    {
        "@score": "1",
        "@id": "2305484",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "204/3448",
                        "text": "Venkat Arun"
                    },
                    {
                        "@pid": "12/3394",
                        "text": "Aniket Kate"
                    },
                    {
                        "@pid": "45/6786-1",
                        "text": "Deepak Garg 0001"
                    },
                    {
                        "@pid": "d/PDruschel",
                        "text": "Peter Druschel"
                    },
                    {
                        "@pid": "b/BobbyBhattacharjee",
                        "text": "Bobby Bhattacharjee"
                    }
                ]
            },
            "title": "Finding Safety in Numbers with Secure Allegation Escrows.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ArunK0DB20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/finding-safety-in-numbers-with-secure-allegation-escrows/",
            "url": "https://dblp.org/rec/conf/ndss/ArunK0DB20",
            "abstract": "For fear of retribution, the victim of a crime may be willing to report it only if other victims of the same perpetrator also step forward. Common examples include 1) identifying oneself as the victim of sexual harassment, especially by a person in a position of authority or 2) accusing an influential politician, an authoritarian government, or ones own employer of corruption. To handle such situations, legal literature has proposed the concept of an allegation escrow: a neutral third-party that collects allegations anonymously, matches them against each other, and de-anonymizes allegers only after de-anonymity thresholds (in terms of number of co-allegers), pre-specified by the allegers, are reached. \nAn allegation escrow can be realized as a single trusted third party; however, this party must be trusted to keep the identity of the alleger and content of the allegation private. To address this problem, this paper introduces Secure Allegation Escrows (SAE, pronounced \"say\"). A SAE is a group of parties with independent interests and motives, acting jointly as an escrow for collecting allegations from individuals, matching the allegations, and de-anonymizing the allegations when designated thresholds are reached. By design, SAEs provide a very strong property: No less than a majority of parties constituting a SAE can de-anonymize or disclose the content of an allegation without a sufficient number of matching allegations (even in collusion with any number of other allegers). Once a sufficient number of matching allegations exist, the join escrow discloses the allegation with the allegers' identities. We describe how SAEs can be constructed using a novel authentication protocol and a novel allegation matching and bucketing algorithm, provide formal proofs of the security of our constructions, and evaluate a prototype implementation, demonstrating feasibility in practice.",
            "keywords": [
                "Secure Allegation Escrows",
                "Allegation Matching",
                "De-anonymization",
                "Victim Reporting",
                "Collective Allegations"
            ]
        },
        "url": "URL#2305484",
        "sema_paperId": "1d8a65ea34a6790965742a6b824b5123c7d0dd3b"
    },
    {
        "@score": "1",
        "@id": "2305485",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "66/3575",
                        "text": "Giuseppe Ateniese"
                    },
                    {
                        "@pid": "64/5725-18",
                        "text": "Long Chen 0018"
                    },
                    {
                        "@pid": "129/5172",
                        "text": "Mohammad Etemad"
                    },
                    {
                        "@pid": "17/2212-5",
                        "text": "Qiang Tang 0005"
                    }
                ]
            },
            "title": "Proof of Storage-Time: Efficiently Checking Continuous Data Availability.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/AtenieseCET20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/proof-of-storage-time-efficiently-checking-continuous-data-availability/",
            "url": "https://dblp.org/rec/conf/ndss/AtenieseCET20",
            "abstract": "A high-quality outsourced storage service is crucial for  many  existing  applications.  For  example,  hospitals  and  data centers  need  to  guarantee  the  availability  of  their  systems  to perform  routine  daily  activities.  Such  a  system  should  protect users  against  downtime  and  ensure  data  availability  over  time. Continuous  data  availability  is  a  critical  property  to  measure the   quality   of   an   outsourced   storage   service,   which   implies that   outsourced   data   is   continuously   available   to   the   server during the entire storage period. We formally study the Proof of Storage-Time (PoSt), the notion initially proposed in the Filecoin whitepaper, which enables a verifier to audit the continuous data availability of an outsourced storage service. We provide a formal security model of PoSt and generic constructions that are proven secure under our definition. Moreover, our concrete instantiation can yield a PoSt protocol with an extremely efficient verification: a  single  hash  computation  to  verify  a  proof  of  size  around  200 bits. This makes our scheme applicable even in the decentralized storage  marketplace  enabled  by  blockchain.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2020/02/24427-paper.pdf",
            "keywords": [
                "Outsourced Storage",
                "Data Availability",
                "Proof of Storage-Time",
                "Continuous Data Availability",
                "Decentralized Storage Marketplace"
            ]
        },
        "url": "URL#2305485"
    },
    {
        "@score": "1",
        "@id": "2305486",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "139/5759",
                        "text": "Zhongjie Ba"
                    },
                    {
                        "@pid": "212/1269",
                        "text": "Tianhang Zheng"
                    },
                    {
                        "@pid": "58/4582-16",
                        "text": "Xinyu Zhang 0016"
                    },
                    {
                        "@pid": "148/4477",
                        "text": "Zhan Qin"
                    },
                    {
                        "@pid": "l/BaochunLi",
                        "text": "Baochun Li"
                    },
                    {
                        "@pid": "l/XueLiu",
                        "text": "Xue Liu 0001"
                    },
                    {
                        "@pid": "20/6179-1",
                        "text": "Kui Ren 0001"
                    }
                ]
            },
            "title": "Learning-based Practical Smartphone Eavesdropping with Built-in Accelerometer.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/BaZZQLL020",
            "ee": "https://www.ndss-symposium.org/ndss-paper/learning-based-practical-smartphone-eavesdropping-with-built-in-accelerometer/",
            "url": "https://dblp.org/rec/conf/ndss/BaZZQLL020",
            "abstract": "\u2014Motion sensors on current smartphones have been exploited for audio eavesdropping due to their sensitivity to vibrations. However, this threat is considered low-risk because of two widely acknowledged limitations: First, unlike microphones, motion sensors can only pick up speech signals traveling through a solid medium. Thus, the only feasible setup reported previously is to use a smartphone gyroscope to eavesdrop on a loudspeaker placed on the same table. The second limitation comes from a common sense that these sensors can only pick up a narrow band (85-100Hz) of speech signals due to a sampling ceiling of 200Hz. In this paper, we revisit the threat of motion sensors to speech privacy and propose AccelEve, a new side-channel attack that employs a smartphone\u2019s accelerometer to eavesdrop on the speaker in the same smartphone. Speci\ufb01cally, it utilizes the accelerometer measurements to recognize the speech emitted by the speaker and to reconstruct the corresponding audio signals. In contrast to previous works, our setup allows the speech signals to always produce strong responses in accelerometer measurements through the shared motherboard, which successfully addresses the \ufb01rst limitation and allows this kind of attacks to penetrate into real-life scenarios. Regarding the sampling rate limitation, contrary to the widely-held belief, we observe up to 500Hz sampling rates in recent smartphones, which almost covers the entire fundamental frequency band (85-255Hz) of adult speech. On top of these pivotal observations, we propose a novel deep learning based system that learns to recognize and reconstruct speech information from the spectrogram representation of acceleration signals. This system employs adaptive optimization on deep neural networks with skip connections using robust and generalizable losses to achieve robust recognition and reconstruction performance. Extensive evaluations demonstrate the effectiveness and high accuracy of our attack under various settings.",
            "keywords": [
                "Smartphone Eavesdropping",
                "Motion Sensors",
                "Accelerometer",
                "Speech Reconstruction",
                "Side-Channel Attack"
            ]
        },
        "url": "URL#2305486",
        "sema_paperId": "23479b9d9941ecf34fb2e261098aee8d12f8a0b9"
    },
    {
        "@score": "1",
        "@id": "2305487",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "225/5499",
                        "text": "Alireza Bahramali"
                    },
                    {
                        "@pid": "22/1797",
                        "text": "Amir Houmansadr"
                    },
                    {
                        "@pid": "178/5177",
                        "text": "Ramin Soltani"
                    },
                    {
                        "@pid": "77/910",
                        "text": "Dennis Goeckel"
                    },
                    {
                        "@pid": "t/DonaldFTowsley",
                        "text": "Don Towsley"
                    }
                ]
            },
            "title": "Practical Traffic Analysis Attacks on Secure Messaging Applications.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/BahramaliHSGT20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/practical-traffic-analysis-attacks-on-secure-messaging-applications/",
            "url": "https://dblp.org/rec/conf/ndss/BahramaliHSGT20",
            "abstract": "Instant Messaging (IM) applications like Telegram, Signal, and WhatsApp have become extremely  popular in recent years. Unfortunately, such IM services have been the  target of continuous  governmental surveillance and censorship, as these services are home to public and private communication channels on socially and politically sensitive topics. To protect their clients,  popular IM services deploy state-of-the-art encryption mechanisms. In this paper, we show that despite the use of advanced encryption, popular IM applications leak sensitive information about their clients to adversaries who merely monitor their encrypted IM traffic, with no need for leveraging any software vulnerabilities of IM applications. Specifically, we devise traffic analysis attacks that enable an adversary to identify  administrators as well as  members of target IM channels (e.g., forums) with  high accuracies. We believe that our study demonstrates  a significant, real-world threat to the users of such services given the increasing attempts by oppressive governments at cracking down controversial IM channels.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2020/02/24347-paper.pdf",
            "keywords": [
                "Traffic Analysis",
                "Secure Messaging",
                "Information Leakage",
                "Government Surveillance",
                "User Privacy Threats"
            ]
        },
        "url": "URL#2305487"
    },
    {
        "@score": "1",
        "@id": "2305488",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "94/7837",
                        "text": "Shivam Bhasin"
                    },
                    {
                        "@pid": "99/4535",
                        "text": "Anupam Chattopadhyay"
                    },
                    {
                        "@pid": "68/10491",
                        "text": "Annelie Heuser"
                    },
                    {
                        "@pid": "163/8627",
                        "text": "Dirmanto Jap"
                    },
                    {
                        "@pid": "50/10230",
                        "text": "Stjepan Picek"
                    },
                    {
                        "@pid": "224/5698",
                        "text": "Ritu Ranjan Shrivastwa"
                    }
                ]
            },
            "title": "Mind the Portability: A Warriors Guide through Realistic Profiled Side-channel Analysis.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/BhasinCHJPS20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/mind-the-portability-a-warriors-guide-through-realistic-profiled-side-channel-analysis/",
            "url": "https://dblp.org/rec/conf/ndss/BhasinCHJPS20",
            "abstract": "Profiled side-channel attacks represent a practical threat to digital devices, thereby having the potential to disrupt the foundation of e-commerce, Internet-of-Things (IoT), and smart cities. In the profiled side-channel attack, adversary gains knowledge about the target device by getting access to a cloned device. Though these two devices are different in real-world scenarios, yet, unfortunately, a large part of research works simplifies the setting by using only a single device for both profiling and attacking. There, the portability issue is conveniently ignored to ease the experimental procedure. In parallel to the above developments, machine learning techniques are used in recent literature demonstrating excellent performance in profiled side-channel attacks. Again, unfortunately, the portability is neglected.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2020/02/24390-paper.pdf",
            "keywords": [
                "Profiled Side-Channel Attacks",
                "Portability Issues",
                "Digital Device Security",
                "Adversarial Profiling",
                "Machine Learning in Side-Channel Analysis"
            ]
        },
        "url": "URL#2305488"
    },
    {
        "@score": "1",
        "@id": "2305489",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "83/3459",
                        "text": "George Bissias"
                    },
                    {
                        "@pid": "l/BrianNeilLevine",
                        "text": "Brian Neil Levine"
                    }
                ]
            },
            "title": "Bobtail: Improved Blockchain Security with Low-Variance Mining.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/BissiasL20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/bobtail-improved-blockchain-security-with-low-variance-mining/",
            "url": "https://dblp.org/rec/conf/ndss/BissiasL20",
            "abstract": "Blockchain systems are designed to produce blocks at a constant average rate. The most popular systems currently employ a Proof of Work (PoW) algorithm as a means of creating these blocks. An unfortunate limitation of all deployed PoW blockchain systems is that the time between blocks has high variance. For example, Bitcoin produces, on average, one block every 10 minutes. However, 5% of the time, Bitcoin\u2019s inter-block time is at least 40 minutes. In this paper, we show that high variance is at the root of several fundamental attacks on PoW blockchains. We propose an alternative process for PoW-based block discovery that results in an inter-block time with significantly lower variance. Our algorithm, called Bobtail , generalizes the current algorithm by comparing the mean of the k -lowest order statistics to a target. We show that the variance of inter-block times decreases as k increases. Bobtail significantly thwarts doublespend and selfish mining attacks, and makes detection of eclipse attacks trivial and quick. For example, for Bitcoin and Ethereum, a doublespending attacker with 40% of the mining power will succeed with 53% probability when the merchant sets up an embargo of 1 block; however, when k \u2265 40 , the probability of success for the same attacker falls to less than 1%. Similarly, for Bitcoin and Ethereum currently, a selfish miner with 49% of the mining power will claim about 95% of blocks; however, when k \u2265 20 , the same miner will find that selfish mining is less successful than honest mining. We also investigate attacks newly made possible by Bobtail and show how they can be defeated. The primary costs of our approach are larger blocks and increased network traffic.",
            "keywords": [
                "Blockchain Security",
                "Proof of Work",
                "Low-Variance Mining",
                "Double-Spend Attacks",
                "Selfish Mining"
            ]
        },
        "url": "URL#2305489",
        "sema_paperId": "00d409fc82fba4e7d95bdb48d1c4bff00a7dccb6"
    },
    {
        "@score": "1",
        "@id": "2305490",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "251/1474",
                        "text": "Laura Blackstone"
                    },
                    {
                        "@pid": "66/664",
                        "text": "Seny Kamara"
                    },
                    {
                        "@pid": "77/11487",
                        "text": "Tarik Moataz"
                    }
                ]
            },
            "title": "Revisiting Leakage Abuse Attacks.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/BlackstoneKM20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/revisiting-leakage-abuse-attacks/",
            "url": "https://dblp.org/rec/conf/ndss/BlackstoneKM20",
            "abstract": "Encrypted search algorithms (ESA) are cryptographic algorithms that support search over encrypted data. ESAs can be designed with various primitives including searchable/structured symmetric encryption (SSE/STE) and oblivious RAM (ORAM).  Leakage abuse attacks attempt to recover client queries using knowledge of the client's data. An important parameter for any leakage-abuse attack is its known-data rate; that is, the fraction of client data that must be known to the adversary.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2020/02/23103-paper.pdf",
            "keywords": [
                "Encrypted Search Algorithms",
                "Leakage Abuse Attacks",
                "Searchable Symmetric Encryption",
                "Client Data Recovery",
                "Known-Data Rate"
            ]
        },
        "url": "URL#2305490"
    },
    {
        "@score": "1",
        "@id": "2305491",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "177/9298",
                        "text": "William Blair"
                    },
                    {
                        "@pid": "184/6002",
                        "text": "Andrea Mambretti"
                    },
                    {
                        "@pid": "93/7474",
                        "text": "Sajjad Arshad"
                    },
                    {
                        "@pid": "150/8120",
                        "text": "Michael Weissbacher"
                    },
                    {
                        "@pid": "r/WilliamKRobertson",
                        "text": "William Robertson 0002"
                    },
                    {
                        "@pid": "k/EnginKirda",
                        "text": "Engin Kirda"
                    },
                    {
                        "@pid": "27/3108",
                        "text": "Manuel Egele"
                    }
                ]
            },
            "title": "HotFuzz: Discovering Algorithmic Denial-of-Service Vulnerabilities Through Guided Micro-Fuzzing.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/BlairMAW0KE20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/hotfuzz-discovering-algorithmic-denial-of-service-vulnerabilities-through-guided-micro-fuzzing/",
            "url": "https://dblp.org/rec/conf/ndss/BlairMAW0KE20",
            "abstract": "Contemporary fuzz testing techniques focus on identifying memory corruption vulnerabilities that allow adversaries to achieve either remote code execution or information disclosure. Meanwhile, Algorithmic Complexity (AC)vulnerabilities, which are a common attack vector for denial-of-service attacks, remain an understudied threat. In this paper, we present HotFuzz, a framework for automatically discovering AC vulnerabilities in Java libraries. HotFuzz uses micro-fuzzing, a genetic algorithm that evolves arbitrary Java objects in order to trigger the worst-case performance for a method under test. We define Small Recursive Instantiation (SRI) as a technique to derive seed inputs represented as Java objects to micro-fuzzing. After micro-fuzzing, HotFuzz synthesizes test cases that triggered AC vulnerabilities into Java programs and monitors their execution in order to reproduce vulnerabilities outside the fuzzing framework. HotFuzz outputs those programs that exhibit high CPU utilization as witnesses for AC vulnerabilities in a Java library. We evaluate HotFuzz over the Java Runtime Environment (JRE), the 100 most popular Java libraries on Maven, and challenges contained in the DARPA Space and Time Analysis for Cybersecurity (STAC) program. We evaluate SRI's effectiveness by comparing the performance of micro-fuzzing with SRI, measured by the number of AC vulnerabilities detected, to simply using empty values as seed inputs. In this evaluation, we verified known AC vulnerabilities, discovered previously unknown AC vulnerabilities that we responsibly reported to vendors, and received confirmation from both IBM and Oracle. Our results demonstrate that micro-fuzzing finds AC vulnerabilities in real-world software, and that micro-fuzzing with SRI-derived seed inputs outperforms using empty values.",
            "keywords": [
                "Algorithmic Complexity Vulnerabilities",
                "Micro-Fuzzing",
                "Denial-of-Service Attacks",
                "Java Libraries",
                "Small Recursive Instantiation (SRI)"
            ]
        },
        "url": "URL#2305491",
        "sema_paperId": "79927a9592a6a7c7a411d84e67d94af8a2adc1ca"
    },
    {
        "@score": "1",
        "@id": "2305492",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "202/6734",
                        "text": "Jonas B\u00f6hler"
                    },
                    {
                        "@pid": "26/5304",
                        "text": "Florian Kerschbaum"
                    }
                ]
            },
            "title": "Secure Sublinear Time Differentially Private Median Computation.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/BohlerK20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/secure-sublinear-time-differentially-private-median-computation/",
            "url": "https://dblp.org/rec/conf/ndss/BohlerK20",
            "abstract": "\u2014In distributed private learning, e.g., data analysis, machine learning, and enterprise benchmarking, it is common-place for two parties with con\ufb01dential data sets to compute statistics over their combined data. The median is an important robust statistical method used in enterprise benchmarking, e.g., companies compare typical employee salaries, insurance companies use median life expectancy to adjust insurance premiums, banks compare credit scores of their customers, and \ufb01nancial regulators estimate risks based on loan exposures. The exact median can be computed securely, however, it leaks information about the private data. To protect the data sets, we securely compute a differentially private median over the joint data set via the exponential mechanism. The exponential mechanism has a runtime linear in the data universe size and ef\ufb01ciently sampling it is non-trivial. Local differential privacy, where each user shares locally perturbed data with an untrusted server, is often used in private learning but does not provide the same utility as the central model, where noise is only applied once by a trusted server. We present an ef\ufb01cient secure computation of a differentially private median of the union of two large, con\ufb01dential data sets. Our protocol has a runtime sublinear in the size of the data universe and utility like the central model without a trusted third party. We provide differential privacy for small data sets (sublinear in the size of the data universe) and prune large data sets with a relaxed notion of differential privacy providing limited group privacy. We use dynamic programming with a static, i.e., data-independent, access pattern, achieving low complexity of the secure computation circuit. We provide a comprehensive evaluation over multiple AWS regions (from Ohio to N. Virgina, Canada and Frankfurt) with a large real-world data set with a practical runtime of less than 7 seconds for millions of records.",
            "keywords": [
                "Differential Privacy",
                "Secure Computation",
                "Median Computation",
                "Sublinear Time",
                "Data Privacy"
            ]
        },
        "url": "URL#2305492",
        "sema_paperId": "6f78ed487dc6dca2e62cc983f29a740515b9f62e"
    },
    {
        "@score": "1",
        "@id": "2305493",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "218/8811",
                        "text": "Jiahao Cao"
                    },
                    {
                        "@pid": "191/1022",
                        "text": "Renjie Xie"
                    },
                    {
                        "@pid": "30/3530-1",
                        "text": "Kun Sun 0001"
                    },
                    {
                        "@pid": "181/2688-2",
                        "text": "Qi Li 0002"
                    },
                    {
                        "@pid": "64/1147",
                        "text": "Guofei Gu"
                    },
                    {
                        "@pid": "18/6055",
                        "text": "Mingwei Xu"
                    }
                ]
            },
            "title": "When Match Fields Do Not Need to Match: Buffered Packets Hijacking in SDN.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/CaoXS0GX20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/when-match-fields-do-not-need-to-match-buffered-packets-hijacking-in-sdn/",
            "url": "https://dblp.org/rec/conf/ndss/CaoXS0GX20",
            "abstract": "\u2014Software-De\ufb01ned Networking (SDN) greatly meets the need in industry for programmable, agile, and dynamic networks by deploying diversi\ufb01ed SDN applications on a centralized controller. However, SDN application ecosystem inevitably introduces new security threats since compromised or malicious applications can signi\ufb01cantly disrupt network operations. Thus, a number of effective security enhancement systems have been developed to defend against potential attacks from SDN applications. In this paper, we identify a new vulnerability on \ufb02ow rule installation in SDN, namely, buffered packet hijacking , which can be exploited by malicious applications to launch effective attacks bypassing all existing defense systems. The root cause of this vulnerability lies in that SDN systems do not check the inconsistency between buffer IDs and match \ufb01elds when an application attempts to install \ufb02ow rules. Thus, a malicious application can manipulate buffer IDs to hijack buffered packets even though they do not match any installed \ufb02ow rules. We design effective attacks exploiting this vulnerability to disrupt all three SDN layers, i.e., application layer, data plane layer, and control layer. First, by modifying buffered packets and resending them to controllers, a malicious application can poison other applications. Second, by manipulating forwarding behaviors of buffered packets, a malicious application can not only disrupt TCP connections of \ufb02ows but also make \ufb02ows bypass network security policies. Third, by copying massive buffered packets to controllers, a malicious application can saturate the bandwidth of SDN control channels and their computing resources. We demonstrate the feasibility and effectiveness of these attacks with both theoretical analysis and experiments in a real SDN testbed. Finally, we develop a lightweight defense system that can be readily deployed in existing SDN controllers as a patch",
            "keywords": [
                "Software-Defined Networking",
                "Buffered Packet Hijacking",
                "Flow Rule Installation",
                "Security Vulnerability",
                "Malicious Applications"
            ]
        },
        "url": "URL#2305493",
        "sema_paperId": "c8b9812cbdc08252c3f48706dbb03702c776c2a7"
    },
    {
        "@score": "1",
        "@id": "2305494",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "240/8222",
                        "text": "Harsh Chaudhari"
                    },
                    {
                        "@pid": "234/1089",
                        "text": "Rahul Rachuri"
                    },
                    {
                        "@pid": "187/5691",
                        "text": "Ajith Suresh"
                    }
                ]
            },
            "title": "Trident: Efficient 4PC Framework for Privacy Preserving Machine Learning.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ChaudhariRS20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/trident-efficient-4pc-framework-for-privacy-preserving-machine-learning/",
            "url": "https://dblp.org/rec/conf/ndss/ChaudhariRS20",
            "abstract": "Machine learning has started to be deployed in fields such as healthcare and finance, which involves dealing with a lot of sensitive data. This propelled the need for and growth of privacy-preserving machine learning. We propose an efficient four-party protocol (4PC) that outperforms the state-of-the-art of Gordon et al. (ASIACRYPT 2018) and showcase its applications on three of the most widely-known machine learning algorithms -- Linear Regression, Logistic Regression, and Neural Networks.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2020/02/23005-paper.pdf",
            "keywords": [
                "Privacy-Preserving Machine Learning",
                "Four-Party Computation",
                "Secure Multi-Party Computation",
                "Sensitive Data Protection",
                "Efficient Protocols"
            ]
        },
        "url": "URL#2305494"
    },
    {
        "@score": "1",
        "@id": "2305495",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "160/1002",
                        "text": "Weikeng Chen"
                    },
                    {
                        "@pid": "91/275",
                        "text": "Raluca Ada Popa"
                    }
                ]
            },
            "title": "Metal: A Metadata-Hiding File-Sharing System.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ChenP20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/metal-a-metadata-hiding-file-sharing-system/",
            "url": "https://dblp.org/rec/conf/ndss/ChenP20",
            "abstract": "File-sharing systems like Dropbox offer insufficient privacy because a compromised server can see the file contents in the clear.  Although encryption can hide such contents from the servers, metadata leakage remains significant. The goal of our work is to develop a file-sharing system that hides metadata---including user identities and file access patterns.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2020/02/24095-paper.pdf",
            "keywords": [
                "Metadata Hiding",
                "File Sharing Systems",
                "Privacy Preservation",
                "User Identity Protection",
                "Metadata Leakage"
            ]
        },
        "url": "URL#2305495"
    },
    {
        "@score": "1",
        "@id": "2305496",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "69/510-33",
                        "text": "Tao Chen 0033"
                    },
                    {
                        "@pid": "91/10470",
                        "text": "Longfei Shangguan"
                    },
                    {
                        "@pid": "35/203",
                        "text": "Zhenjiang Li"
                    },
                    {
                        "@pid": "j/KyleJamieson",
                        "text": "Kyle Jamieson"
                    }
                ]
            },
            "title": "Metamorph: Injecting Inaudible Commands into Over-the-air Voice Controlled Systems.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ChenSLJ20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/metamorph-injecting-inaudible-commands-into-over-the-air-voice-controlled-systems/",
            "url": "https://dblp.org/rec/conf/ndss/ChenSLJ20",
            "abstract": "\u2014This paper presents Metamorph, a system that generates imperceptible audio that can survive over-the-air transmission to attack the neural network of a speech recognition system. The key challenge stems from how to ensure the added perturbation of the original audio in advance at the sender side is immune to unknown signal distortions during the transmission process. Our empirical study reveals that signal distortion is mainly due to device and channel frequency selectivity but with different characteristics. This brings a chance to capture and further pre-code this impact to generate adversarial examples that are robust to the over-the-air transmission. We leverage this opportunity in Metamorph and obtain an initial perturbation that captures the core distortion\u2019s impact from only a small set of prior measurements, and then take advantage of a domain adaptation algorithm to re\ufb01ne the perturbation to further improve the attack distance and reliability. Moreover, we consider also reducing human perceptibility of the added perturbation. Evaluation achieves a high attack success rate (90%) over the attack distance of up to 6 m. Within a moderate distance, e.g. , 3 m, Metamorph maintains this high success rate, yet can be further adapted to largely improve the audio quality, con\ufb01rmed by a human perceptibility study.",
            "keywords": [
                "Inaudible Commands",
                "Over-the-air Transmission",
                "Speech Recognition Attack",
                "Adversarial Audio Perturbation",
                "Human Perceptibility"
            ]
        },
        "url": "URL#2305496",
        "sema_paperId": "c1a093c6d3aafeac58557edfd39c0c8d1737420e"
    },
    {
        "@score": "1",
        "@id": "2305497",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "181/5758",
                        "text": "Ioannis Demertzis"
                    },
                    {
                        "@pid": "227/9110",
                        "text": "Javad Ghareh Chamani"
                    },
                    {
                        "@pid": "18/9002",
                        "text": "Dimitrios Papadopoulos 0001"
                    },
                    {
                        "@pid": "p/CharalamposPapamanthou",
                        "text": "Charalampos Papamanthou"
                    }
                ]
            },
            "title": "Dynamic Searchable Encryption with Small Client Storage.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/DemertzisCPP20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/dynamic-searchable-encryption-with-small-client-storage/",
            "url": "https://dblp.org/rec/conf/ndss/DemertzisCPP20",
            "abstract": "We study the problem of dynamic searchable encryption (DSE) with forward-and-backward privacy. Many DSE schemes have been proposed recently but the most efficient ones have one limitation: they require maintaining an operation counter for each unique keyword, either stored locally at the client or accessed obliviously (e.g., with an oblivious map) at the server, during  every operation. We propose three new schemes that overcome the above limitation and achieve constant permanent client storage with improved performance, both asymptotically and  experimentally, compared to prior state-of-the-art works. In particular, our first two schemes  adopt a \"static-to-dynamic\" transformation which eliminates the need for oblivious  accesses during searches. Due to this, they are the first practical schemes with minimal client storage and non-interactive search. Our third scheme is the first quasi-optimal forward-and-backward  DSE scheme with only a logarithmic overhead for retrieving the query result (independently of previous deletions). While it does require an oblivious access during search in order to keep  permanent client storage minimal, its practical performance is up to four orders of magnitude  better than the best existing scheme with quasi-optimal search.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2020/02/24423-paper.pdf",
            "keywords": [
                "Dynamic Searchable Encryption",
                "Client Storage",
                "Forward-and-Backward Privacy",
                "Oblivious Access",
                "Non-Interactive Search"
            ]
        },
        "url": "URL#2305497"
    },
    {
        "@score": "1",
        "@id": "2305498",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "118/3376",
                        "text": "Aritra Dhar"
                    },
                    {
                        "@pid": "190/7677",
                        "text": "Enis Ulqinaku"
                    },
                    {
                        "@pid": "42/2366",
                        "text": "Kari Kostiainen"
                    },
                    {
                        "@pid": "51/1639",
                        "text": "Srdjan Capkun"
                    }
                ]
            },
            "title": "ProtectIOn: Root-of-Trust for IO in Compromised Platforms.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/DharUKC20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/protection-root-of-trust-for-io-in-compromised-platforms/",
            "url": "https://dblp.org/rec/conf/ndss/DharUKC20",
            "abstract": "Security and safety-critical remote applications such as e-voting, online banking, industrial control systems and medical devices rely upon user interaction that is typically performed through web applications. Trusted path to such remote systems is critical in the presence of an attacker that controls the computer that the user operates. Such an attacker can observe and modify any IO data without being detected by the user or the server. We investigate the security of previous research proposals and observe several drawbacks that make them vulnerable to attacks. Based on these observations we identify novel requirements for secure IO operation in the presence of a compromised host.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2020/02/24112-paper.pdf",
            "keywords": [
                "Secure Input/Output",
                "Compromised Platforms",
                "Trusted Path",
                "User Interaction Security",
                "Remote Application Safety"
            ]
        },
        "url": "URL#2305498"
    },
    {
        "@score": "1",
        "@id": "2305499",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "19/2685-1",
                        "text": "Ren Ding 0001"
                    },
                    {
                        "@pid": "70/2543-4",
                        "text": "Hong Hu 0004"
                    },
                    {
                        "@pid": "42/1870-2",
                        "text": "Wen Xu 0002"
                    },
                    {
                        "@pid": "38/8882",
                        "text": "Taesoo Kim"
                    }
                ]
            },
            "title": "DESENSITIZATION: Privacy-Aware and Attack-Preserving Crash Report.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/DingHXK20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/desensitization-privacy-aware-and-attack-preserving-crash-report/",
            "url": "https://dblp.org/rec/conf/ndss/DingHXK20",
            "abstract": "\u2014Software vendors collect crash reports from end-users to assist in the debugging and testing of their products. However, crash reports may contain users\u2019 private information, like names and passwords, rendering the user hesitant to share the reports with developers. We need a mechanism to protect users\u2019 privacy in crash reports on the client side while keeping sufficient information to support server-side debugging and analysis. In this paper, we propose the D ESENSITIZATION technique, which generates privacy-aware and attack-preserving crash reports from crashed executions. Our tool adopts lightweight methods to identify bug-related and attack-related data from the memory, and removes other data to protect users\u2019 privacy. Since a large portion of the desensitized memory contains null bytes, we store crash reports in spare files to save the network bandwidth and the server-side storage. We prototype D ESENSITIZATION and apply it to a large number of crashes of real-world programs, like browsers and the JavaScript engine. The result shows that our D ESENSITIZATION technique can eliminate 80.9% of non-zero bytes from coredumps, and 49.0% from minidumps. The desensitized crash report can be 50.5% smaller than the original one, which significantly saves resources for report submission and storage. Our D ESENSITIZATION technique is a push-button solution for the privacy-aware crash report.",
            "keywords": [
                "Crash Report Analysis",
                "User Privacy",
                "Desensitization Technique",
                "Memory Data Protection",
                "Debugging Support"
            ]
        },
        "url": "URL#2305499",
        "sema_paperId": "299ce46faab5969996f9dc00c66ab1dc23243310"
    },
    {
        "@score": "1",
        "@id": "2305500",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "10/9994",
                        "text": "Yue Duan"
                    },
                    {
                        "@pid": "243/2006",
                        "text": "Xuezixiang Li"
                    },
                    {
                        "@pid": "56/10449",
                        "text": "Jinghan Wang"
                    },
                    {
                        "@pid": "77/6178-1",
                        "text": "Heng Yin 0001"
                    }
                ]
            },
            "title": "DeepBinDiff: Learning Program-Wide Code Representations for Binary Diffing.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/DuanLWY20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/deepbindiff-learning-program-wide-code-representations-for-binary-diffing/",
            "url": "https://dblp.org/rec/conf/ndss/DuanLWY20",
            "abstract": "\u2014Binary dif\ufb01ng analysis quantitatively measures the differences between two given binaries and produces \ufb01ne-grained basic block level matching. It has been widely used to enable different kinds of critical security analysis. However, all existing program analysis and machine learning based techniques suffer from low accuracy, poor scalability, coarse granularity, or require extensive labeled training data to function. In this paper, we pro-pose an unsupervised program-wide code representation learning technique to solve the problem. We rely on both the code semantic information and the program-wide control \ufb02ow information to generate basic block embeddings. Furthermore, we propose a k - hop greedy matching algorithm to \ufb01nd the optimal dif\ufb01ng results using the generated block embeddings. We implement a prototype called D EEP B IN D IFF and evaluate its effectiveness and ef\ufb01ciency with a large number of binaries. The results show that our tool outperforms the state-of-the-art binary dif\ufb01ng tools by a large margin for both cross-version and cross-optimization-level dif\ufb01ng. A case study for OpenSSL using real-world vulnerabilities further demonstrates the usefulness of our system.",
            "keywords": [
                "Binary Diffing",
                "Code Representation Learning",
                "Basic Block Matching",
                "Control Flow Information",
                "Unsupervised Learning"
            ]
        },
        "url": "URL#2305500",
        "sema_paperId": "20c59907cf81469b0ab9cc12cc33a4ba0917324e"
    },
    {
        "@score": "1",
        "@id": "2305501",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "210/4047",
                        "text": "Thijs van Ede"
                    },
                    {
                        "@pid": "171/4007",
                        "text": "Riccardo Bortolameotti"
                    },
                    {
                        "@pid": "190/9885",
                        "text": "Andrea Continella"
                    },
                    {
                        "@pid": "60/10581",
                        "text": "Jingjing Ren"
                    },
                    {
                        "@pid": "69/7759",
                        "text": "Daniel J. Dubois"
                    },
                    {
                        "@pid": "81/10928",
                        "text": "Martina Lindorfer"
                    },
                    {
                        "@pid": "48/6854",
                        "text": "David R. Choffnes"
                    },
                    {
                        "@pid": "s/MaartenvanSteen",
                        "text": "Maarten van Steen"
                    },
                    {
                        "@pid": "43/8243",
                        "text": "Andreas Peter"
                    }
                ]
            },
            "title": "FlowPrint: Semi-Supervised Mobile-App Fingerprinting on Encrypted Network Traffic.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/EdeBCRDLCSP20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/flowprint-semi-supervised-mobile-app-fingerprinting-on-encrypted-network-traffic/",
            "url": "https://dblp.org/rec/conf/ndss/EdeBCRDLCSP20",
            "abstract": "Mobile-application fingerprinting of network traffic is valuable for many security solutions as it provides insights into the apps active on a network. Unfortunately, existing techniques require prior knowledge of apps to be able to recognize them. However, mobile environments are constantly evolving, i.e., apps are regularly installed, updated, and uninstalled. Therefore, it is infeasible for existing fingerprinting approaches to cover all apps that may appear on a network. Moreover, most mobile traffic is encrypted, shows similarities with other apps, e.g., due to common libraries or the use of content delivery networks, and depends on user input, further complicating the fingerprinting process. As a solution, we propose FlowPrint, a semi-supervised approach for fingerprinting mobile apps from (encrypted) network traffic. We automatically find temporal correlations among destination-related features of network traffic and use these correlations to generate app fingerprints. Our approach is able to fingerprint previously unseen apps, something that existing techniques fail to achieve. We evaluate our approach for both Android and iOS in the setting of app recognition, where we achieve an accuracy of 89.2%, significantly outperforming state-of-the-art solutions. In addition, we show that our approach can detect previously unseen apps with a precision of 93.5%, detecting 72.3% of apps within the first five minutes of communication.",
            "keywords": [
                "Mobile App Fingerprinting",
                "Encrypted Network Traffic",
                "Semi-Supervised Learning",
                "App Recognition",
                "Unseen App Detection"
            ]
        },
        "url": "URL#2305501",
        "sema_paperId": "f9296d55d45c2ce271155f5aa818058fc24dea0b"
    },
    {
        "@score": "1",
        "@id": "2305502",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "209/2300",
                        "text": "Parinya Ekparinya"
                    },
                    {
                        "@pid": "11/171",
                        "text": "Vincent Gramoli"
                    },
                    {
                        "@pid": "51/2666",
                        "text": "Guillaume Jourjon"
                    }
                ]
            },
            "title": "The Attack of the Clones Against Proof-of-Authority.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/EkparinyaGJ20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/the-attack-of-the-clones-against-proof-of-authority/",
            "url": "https://dblp.org/rec/conf/ndss/EkparinyaGJ20",
            "abstract": "In this paper, we explore vulnerabilities and countermeasures of the recently proposed blockchain consensus based on proof-of-authority. The proof-of-work blockchains, like Bitcoin and Ethereum, have been shown both theoretically and empirically vulnerable to double spending attacks. This is why Byzantine fault tolerant consensus algorithms have gained popularity in the blockchain context for their ability to tolerate a limited number t of attackers among n participants. We formalize the recently proposed proof-of-authority consensus algorithms that are Byzantine fault tolerant by describing the Aura and Clique protocols present in the two mainstream implementations of Ethereum. We then introduce the Cloning Attack and show how to apply it to double spend in each of these protocols with a single malicious node. Our results show that the Cloning Attack against Aura is always successful while the same attack against Clique is about twice as fast and succeeds in most cases.",
            "keywords": [
                "Blockchain Consensus",
                "Proof-of-Authority",
                "Byzantine Fault Tolerance",
                "Cloning Attack",
                "Double Spending"
            ]
        },
        "url": "URL#2305502",
        "sema_paperId": "9329e150170534e99d169a345aa68aeb004279ca"
    },
    {
        "@score": "1",
        "@id": "2305503",
        "info": {
            "authors": {
                "author": {
                    "@pid": "270/2392",
                    "text": "Paul Forney"
                }
            },
            "title": "Overcoming the &quot;Evil Twins&quot; Attack: Lessons Learned from the Industrial Battlefield.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Other",
            "access": "open",
            "key": "conf/ndss/Forney20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/6126/",
            "url": "https://dblp.org/rec/conf/ndss/Forney20",
            "abstract": null,
            "keywords": [
                "Industrial Cybersecurity",
                "Evil Twins Attack",
                "Threat Mitigation",
                "Attack Vectors",
                "Lessons Learned"
            ]
        },
        "url": "URL#2305503",
        "sema_paperId": "728a4670d445db5721b45b426e91a6583d2c688c"
    },
    {
        "@score": "1",
        "@id": "2305504",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "69/711",
                        "text": "Sergey Frolov"
                    },
                    {
                        "@pid": "236/6947",
                        "text": "Jack Wampler"
                    },
                    {
                        "@pid": "60/8733",
                        "text": "Eric Wustrow"
                    }
                ]
            },
            "title": "Detecting Probe-resistant Proxies.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/FrolovWW20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/detecting-probe-resistant-proxies/",
            "url": "https://dblp.org/rec/conf/ndss/FrolovWW20",
            "abstract": "hosts on the Internet, despite their design. We discover unique TCP behaviors of \ufb01ve probe-resistant protocols used in popular circumvention software that could allow censors to effectively con\ufb01rm suspected proxies with minimal false positives. We evaluate and analyze our attacks on hundreds of thousands of servers collected from a 10 Gbps university ISP vantage point over several days as well as active scanning using ZMap. We \ufb01nd that our attacks are able to ef\ufb01ciently identify proxy servers with only a handful of probing connections, with negligible false positives. Using our datasets, we also suggest defenses to these attacks that make it harder for censors to distinguish proxies from other common servers, and we work with proxy developers to implement these changes in several popular circumvention tools.",
            "keywords": [
                "Probe-resistant Protocols",
                "Circumvention Software",
                "TCP Behavior Analysis",
                "Censorship Resistance",
                "Proxy Detection"
            ]
        },
        "url": "URL#2305504",
        "sema_paperId": "17c7106bf6343f2b9f1821b4cec6449ae4c8307c"
    },
    {
        "@score": "1",
        "@id": "2305505",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "47/10540",
                        "text": "Jairo Giraldo"
                    },
                    {
                        "@pid": "48/6119",
                        "text": "Alvaro A. C\u00e1rdenas"
                    },
                    {
                        "@pid": "36/195",
                        "text": "Murat Kantarcioglu"
                    },
                    {
                        "@pid": "k/JonathanKatz",
                        "text": "Jonathan Katz"
                    }
                ]
            },
            "title": "Adversarial Classification Under Differential Privacy.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/GiraldoCKK20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/adversarial-classification-under-differential-privacy/",
            "url": "https://dblp.org/rec/conf/ndss/GiraldoCKK20",
            "abstract": "\u2014The last decade has seen a growing interest in adversarial classi\ufb01cation , where an attacker tries to mislead a classi\ufb01er meant to detect anomalies. We study this problem in a setting where anomaly detection is being used in conjunction with differential privacy to protect personal information. We show that a strategic attacker can leverage the additional noise (introduced to ensure differential privacy) to mislead the classi\ufb01er beyond what the attacker could do otherwise; we also propose countermeasures against such attacks. We then evaluate the impact of our attacks and defenses in road traf\ufb01c congestion and smart metering examples",
            "keywords": [
                "Adversarial Classification",
                "Differential Privacy",
                "Anomaly Detection",
                "Strategic Attacker",
                "Countermeasures"
            ]
        },
        "url": "URL#2305505",
        "sema_paperId": "1c1f55154378ffa32b7c8c10b1ada84ed3b06277"
    },
    {
        "@score": "1",
        "@id": "2305506",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "68/86",
                        "text": "Ben Gras"
                    },
                    {
                        "@pid": "75/8194",
                        "text": "Cristiano Giuffrida"
                    },
                    {
                        "@pid": "55/9843",
                        "text": "Michael Kurth"
                    },
                    {
                        "@pid": "91/800",
                        "text": "Herbert Bos"
                    },
                    {
                        "@pid": "121/2685",
                        "text": "Kaveh Razavi"
                    }
                ]
            },
            "title": "ABSynthe: Automatic Blackbox Side-channel Synthesis on Commodity Microarchitectures.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/GrasGKBR20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/absynthe-automatic-blackbox-side-channel-synthesis-on-commodity-microarchitectures/",
            "url": "https://dblp.org/rec/conf/ndss/GrasGKBR20",
            "abstract": "\u2014The past decade has seen a plethora of side-channel attacks on various CPU components. Each new attack typically follows a whitebox analysis approach, which involves (i) identifying a speci\ufb01c shared CPU component, (ii) reversing its behavior on a speci\ufb01c microarchitecture, and (iii) surgically exploiting such knowledge to leak information (e.g., by actively evicting shared entries to monitor victim accesses). This approach requires lengthy reverse engineering, repeated for every component and microarchitecture, and does not allow for attacking unknown shared resources. In this paper, we present ABSynthe, a system that takes a target program and a microarchitecture as inputs and automatically synthesizes new side channels. The key insight is that by limiting ourselves to (typically on-core) contention-based side channels, we can treat the target CPU microarchitecture as a black box, enabling automation. To make ABSynthe possible, we have automatically generated leakage maps for a variety of x86_64 microarchitectures. These leakage maps show a complex picture of interaction between different x86_64 instructions and justify a black box approach to \ufb01nding the best sequence of instructions that cause information to leak from a given software target, which we also treat as a black box. To recover the secret information using the optimized sequence of instructions, ABSynthe relies on a recurrent neural network to craft practical side-channel attacks that recover a secret bit stream. Our evaluation shows that ABSynthe can synthesize better attacks by exploiting contention on multiple components at the same time compared to state of the art contention-based attacks that focus on a single component. Furthermore, the automation made possible by ABSynthe allows us to synthesize cross-thread attacks for a variety of microarchitectures (from Intel, AMD and ARM) on four different cryptographic software targets, in both native and virtualized environments. The results show that ABSynthe can",
            "keywords": [
                "Side-channel Attacks",
                "Microarchitecture",
                "Contention-based Side Channels",
                "Information Leakage",
                "Cross-thread Attacks"
            ]
        },
        "url": "URL#2305506",
        "sema_paperId": "ab170c28a942781b07c5c77f8be87686db04e573"
    },
    {
        "@score": "1",
        "@id": "2305507",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "234/0112",
                        "text": "Run Guo"
                    },
                    {
                        "@pid": "32/3885",
                        "text": "Weizhong Li"
                    },
                    {
                        "@pid": "89/10754",
                        "text": "Baojun Liu"
                    },
                    {
                        "@pid": "07/6713-1",
                        "text": "Shuang Hao 0001"
                    },
                    {
                        "@pid": "80/2266-4",
                        "text": "Jia Zhang 0004"
                    },
                    {
                        "@pid": "36/5143",
                        "text": "Haixin Duan"
                    },
                    {
                        "@pid": "260/5375",
                        "text": "Kaiwen Sheng"
                    },
                    {
                        "@pid": "20/1036-5",
                        "text": "Jianjun Chen 0005"
                    },
                    {
                        "@pid": "91/112-24",
                        "text": "Ying Liu 0024"
                    }
                ]
            },
            "title": "CDN Judo: Breaking the CDN DoS Protection with Itself.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/GuoLLHZDSCL20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/cdn-judo-breaking-the-cdn-dos-protection-with-itself/",
            "url": "https://dblp.org/rec/conf/ndss/GuoLLHZDSCL20",
            "abstract": "A content delivery network (CDN) improves the accessing performance and availability of websites via its globally distributed network infrastructures, which contributes to the thriving of CDN-powered websites on the Internet. Because CDNpowered websites normally operate important businesses or critical services, attackers are mostly interested in taking down these high-value websites, to achieve severe damage with maximum influence. Because the CDN absorbs distributed attacking traffic with its massive bandwidth resources, it is commonly believed that CDN vendors provide effective DoS protection for the CDNpowered websites. However, we reveal that implementation or protocol weaknesses in the forwarding mechanisms of the CDN can be exploited to break this CDN protection. By sending crafted but legal requests, an attacker can launch an efficient DoS attack against the website origin behind it. In particular, we present three CDN threats in this study. By abusing the HTTP/2 requestconverting behavior and HTTP pre-POST behavior of a CDN, an attacker can saturate the CDN\u2013origin bandwidth and exhaust the connection limits of the origin. What is more concerning is that some CDN vendors use only a small set of traffic forwarding IPs with lower IP-churning rates to establish connections with the origin. This characteristic provides a great opportunity for an attacker to effectively degrade the global availability of a website just by cutting off specific CDN\u2013origin connections. In this work, we examine the CDN request-forwarding behaviors across six well-known CDN vendors and perform real-world experiments to evaluate the severity of the threats. Because the threats are caused by flawed trade-offs made by the CDN vendors between usability and security, we discuss possible mitigation and received positive feedback after responsible disclosure to the aforementioned CDN vendors.",
            "keywords": [
                "Content Delivery Networks",
                "Denial of Service",
                "HTTP/2 Exploits",
                "Traffic Forwarding Vulnerabilities",
                "DoS Attack Mitigation"
            ]
        },
        "url": "URL#2305507",
        "sema_paperId": "d7408d675be9d3d72be5ed9f59634929b11085ec"
    },
    {
        "@score": "1",
        "@id": "2305508",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "182/6753",
                        "text": "Xueyuan Han"
                    },
                    {
                        "@pid": "144/4204",
                        "text": "Thomas F. J.-M. Pasquier"
                    },
                    {
                        "@pid": "126/3601",
                        "text": "Adam Bates 0001"
                    },
                    {
                        "@pid": "90/1843",
                        "text": "James Mickens"
                    },
                    {
                        "@pid": "s/MargoISeltzer",
                        "text": "Margo I. Seltzer"
                    }
                ]
            },
            "title": "Unicorn: Runtime Provenance-Based Detector for Advanced Persistent Threats.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/HanP0MS20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/unicorn-runtime-provenance-based-detector-for-advanced-persistent-threats/",
            "url": "https://dblp.org/rec/conf/ndss/HanP0MS20",
            "abstract": "Advanced Persistent Threats (APTs) are difficult to detect due to their \u201clow-and-slow\u201d attack patterns and frequent use of zero-day exploits. We present UNICORN, an anomaly-based APT detector that effectively leverages data provenance analysis. From modeling to detection, UNICORN tailors its design specifically for the unique characteristics of APTs. Through extensive yet time-efficient graph analysis, UNICORN explores provenance graphs that provide rich contextual and historical information to identify stealthy anomalous activities without pre-defined attack signatures. Using a graph sketching technique, it summarizes long-running system execution with space efficiency to combat slow-acting attacks that take place over a long time span. UNICORN further improves its detection capability using a novel modeling approach to understand long-term behavior as the system evolves. Our evaluation shows that UNICORN outperforms an existing state-of-the-art APT detection system and detects real-life APT scenarios with high accuracy.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2020/02/24046-paper.pdf",
            "keywords": [
                "Advanced Persistent Threats",
                "Anomaly Detection",
                "Data Provenance",
                "Graph Analysis",
                "Stealthy Anomalous Activities"
            ]
        },
        "url": "URL#2305508"
    },
    {
        "@score": "1",
        "@id": "2305509",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "184/8086",
                        "text": "Wajih Ul Hassan"
                    },
                    {
                        "@pid": "184/3896",
                        "text": "Mohammad A. Noureddine"
                    },
                    {
                        "@pid": "154/4512",
                        "text": "Pubali Datta"
                    },
                    {
                        "@pid": "126/3601",
                        "text": "Adam Bates 0001"
                    }
                ]
            },
            "title": "OmegaLog: High-Fidelity Attack Investigation via Transparent Multi-layer Log Analysis.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/HassanND020",
            "ee": "https://www.ndss-symposium.org/ndss-paper/omegalog-high-fidelity-attack-investigation-via-transparent-multi-layer-log-analysis/",
            "url": "https://dblp.org/rec/conf/ndss/HassanND020",
            "abstract": "\u2014Recent advances in causality analysis have en- abled investigators to trace multi-stage attacks using provenance graphs. Based on system-layer audit logs (e.g., syscalls), these approaches omit vital sources of application context (e.g., email addresses, HTTP response codes) that can be found in higher layers of the system. Although such information is often essential to understanding attack behaviors, it is dif\ufb01cult to incorporate this evidence into causal analysis engines because of the semantic gap that exists between system layers. To address that short- coming, we propose the notion of universal provenance , which encodes all forensically relevant causal dependencies regardless of their layer of origin. To transparently realize that vision on commodity systems, we present OmegaLog, a provenance tracker that bridges the semantic gap between system and application logging contexts. OmegaLog analyzes program binaries to identify and model application-layer logging behaviors, enabling accurate reconciliation of application events with system-layer accesses. OmegaLog then intercepts applications\u2019 runtime logging activities and grafts those events onto the system-layer provenance graph, allowing investigators to reason more precisely about the nature of attacks. We demonstrate that our system is widely applicable to existing software projects and can transparently facilitate execution partitioning of provenance graphs without any training or developer intervention. Evaluation on real-world attack scenarios shows that our technique generates concise provenance graphs with rich semantic information relative to the state-of-the-art, with an average runtime overhead of 4%.",
            "keywords": [
                "Provenance Analysis",
                "Log Analysis",
                "Multi-layer Attacks",
                "Causal Dependencies",
                "Application Context"
            ]
        },
        "url": "URL#2305509",
        "sema_paperId": "36eb598c9cb9975dd4626f241822919f5fc67dfe"
    },
    {
        "@score": "1",
        "@id": "2305510",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "223/6748",
                        "text": "Tomas Hlavacek"
                    },
                    {
                        "@pid": "80/186",
                        "text": "\u00cdtalo Cunha"
                    },
                    {
                        "@pid": "84/7357",
                        "text": "Yossi Gilad"
                    },
                    {
                        "@pid": "62/3150",
                        "text": "Amir Herzberg"
                    },
                    {
                        "@pid": "66/2080",
                        "text": "Ethan Katz-Bassett"
                    },
                    {
                        "@pid": "15/5634",
                        "text": "Michael Schapira"
                    },
                    {
                        "@pid": "94/7397",
                        "text": "Haya Schulmann"
                    }
                ]
            },
            "title": "DISCO: Sidestepping RPKI&apos;s Deployment Barriers.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/HlavacekCGHKSS20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/disco-sidestepping-rpkis-deployment-barriers/",
            "url": "https://dblp.org/rec/conf/ndss/HlavacekCGHKSS20",
            "abstract": "\u2014BGP is a gaping security hole in today\u2019s Internet, as evidenced by numerous Internet outages and blackouts, repeated traffic hijacking, and surveillance incidents. To protect against prefix hijacking, the Resource Public Key Infrastructure (RPKI) has been standardized. Yet, despite Herculean efforts, ubiquitous deployment of the RPKI remains distant, due to RPKI\u2019s manual and error-prone certification process. We argue that deploying origin authentication at scale requires substituting the standard requirement of certifying legal ownership of IP address blocks with the goal of certifying de facto ownership. We show that settling for de facto ownership is sufficient for protecting against hazardous prefix hijacking and can be accomplished without requiring any changes to today\u2019s routing infrastructure. We present DISCO, a readily deployable system that automatically certifies de facto ownership and generates the appropriate BGP-path-filtering rules at routers. We evaluate DISCO\u2019s security and deployability via live experiments on the Internet using a prototype implementation of DISCO and through simulations on empirically-derived datasets. To facilitate the reproducibility of our results, we open source our prototype, simulator, and measurement analysis code [30].",
            "keywords": [
                "BGP Security",
                "RPKI Deployment",
                "Prefix Hijacking",
                "De Facto Ownership",
                "DISCO System"
            ]
        },
        "url": "URL#2305510",
        "sema_paperId": "38cc3f62eb7ea7d3ceb8cd24ab964447ddabf1c3"
    },
    {
        "@score": "1",
        "@id": "2305511",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "132/2690",
                        "text": "Thang Hoang"
                    },
                    {
                        "@pid": "51/3023",
                        "text": "Jorge Guajardo"
                    },
                    {
                        "@pid": "73/4897",
                        "text": "Attila A. Yavuz"
                    }
                ]
            },
            "title": "MACAO: A Maliciously-Secure and Client-Efficient Active ORAM Framework.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/HoangGY20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/macao-a-maliciously-secure-and-client-efficient-active-oram-framework/",
            "url": "https://dblp.org/rec/conf/ndss/HoangGY20",
            "abstract": "Oblivious Random Access Machine (ORAM) allows a client to hide the access pattern and thus, offers a strong level of privacy for data outsourcing. An ideal ORAM scheme is expected to offer desirable properties such as low client bandwidth, low server computation overhead and the ability to compute over encrypted data. S3ORAM (CCS\u201917), is a very efficient active ORAM scheme, which takes advantage of secret sharing to provide ideal properties for data outsourcing such as low client bandwidth, low server computation and low delay. Despite its merits, S3ORAM only offers security in the semi-honest setting.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2020/02/24313-paper.pdf",
            "keywords": [
                "Oblivious Random Access Machine (ORAM)",
                "Data Outsourcing",
                "Active ORAM",
                "Client Efficiency",
                "Malicious Security"
            ]
        },
        "url": "URL#2305511"
    },
    {
        "@score": "1",
        "@id": "2305512",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "218/7966",
                        "text": "Kyungho Joo"
                    },
                    {
                        "@pid": "09/6032",
                        "text": "Wonsuk Choi"
                    },
                    {
                        "@pid": "l/DongHoonLee",
                        "text": "Dong Hoon Lee 0001"
                    }
                ]
            },
            "title": "Hold the Door! Fingerprinting Your Car Key to Prevent Keyless Entry Car Theft.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/JooC020",
            "ee": "https://www.ndss-symposium.org/ndss-paper/hold-the-door-fingerprinting-your-car-key-to-prevent-keyless-entry-car-theft/",
            "url": "https://dblp.org/rec/conf/ndss/JooC020",
            "abstract": "Recently, the traditional way to unlock car doors has been replaced with a keyless entry system which proves more convenient for automobile owners. When a driver with a key fob is in vicinity of the vehicle, doors automatically unlock on user command. However, unfortunately, it has been known that these keyless entry systems are vulnerable to signal-relaying attacks. While it is evident that automobile manufacturers incorporate preventative methods to secure these keyless entry systems, a range of attacks continue to occur. Relayed signals fit into the valid packets that are verified as legitimate, and this makes it is difficult to distinguish a legitimate request for doors to be unlocked from malicious signals. In response to this vulnerability, this paper presents an RF-fingerprinting method (coined \u201cHOld the DOoR\u201d, HODOR) to detect attacks on keyless entry systems, which is the first attempt to exploit RF-fingerprint technique in automotive domain. HODOR is designed as a sub-authentication system that supports existing authentication systems for keyless entry systems and does not require any modification of the main system to perform. Through a series of experiments, the results demonstrate that HODOR competently and reliably detects attacks on keyless entry systems. HODOR achieves both an average false positive rate (FPR) of 0.27% with a false negative rate (FNR) of 0% for the detection of simulated attacks corresponding to the current issue on keyless entry car theft. Furthermore, HODOR was also observed under environmental factors: temperature variation, non-line-of-sight (NLoS) conditions and battery aging. HODOR yields a false positive rate of 1.32% for the identification of a legitimated key fob which is even under NLoS condition. Based on the experimental results, it is expected that HODOR will provide a secure service for keyless entry systems, while remaining convenient.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2020/02/23107-paper.pdf",
            "keywords": [
                "Keyless Entry Systems",
                "RF Fingerprinting",
                "Signal-Relaying Attacks",
                "Automotive Security",
                "HODOR"
            ]
        },
        "url": "URL#2305512"
    },
    {
        "@score": "1",
        "@id": "2305513",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "270/2346",
                        "text": "Soroush Karami"
                    },
                    {
                        "@pid": "129/9582",
                        "text": "Panagiotis Ilia"
                    },
                    {
                        "@pid": "232/2988",
                        "text": "Konstantinos Solomos"
                    },
                    {
                        "@pid": "47/8412",
                        "text": "Jason Polakis"
                    }
                ]
            },
            "title": "Carnus: Exploring the Privacy Threats of Browser Extension Fingerprinting.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/KaramiISP20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/carnus-exploring-the-privacy-threats-of-browser-extension-fingerprinting/",
            "url": "https://dblp.org/rec/conf/ndss/KaramiISP20",
            "abstract": "\u2014With users becoming increasingly privacy-aware and browser vendors incorporating anti-tracking mechanisms, browser \ufb01ngerprinting has garnered signi\ufb01cant attention. Accord-ingly, prior work has proposed techniques for identifying browser extensions and using them as part of a device\u2019s \ufb01ngerprint. While previous studies have demonstrated how extensions can be detected through their web accessible resources, there exists a signi\ufb01cant gap regarding techniques that indirectly detect extensions through behavioral artifacts. In fact, no prior study has demonstrated that this can be done in an automated fashion. In this paper, we bridge this gap by presenting the \ufb01rst fully automated creation and detection of behavior-based extension \ufb01ngerprints. We also introduce two novel \ufb01ngerprinting techniques that monitor extensions\u2019 communication patterns, namely outgoing HTTP requests and intra-browser message exchanges. These techniques comprise the core of Carnus, a modular system for the static and dynamic analysis of extensions, which we use to create the largest set of extension \ufb01ngerprints to date. We leverage our dataset of 29,428 detectable extensions to conduct a comprehensive investigation of extension \ufb01ngerprinting in realistic settings and demonstrate the practicality of our attack. Our in-depth analysis con\ufb01rms the robustness of our techniques, as 83.6% - 87.92% of our behavior-based \ufb01ngerprints remain effective against a state-of-the-art countermeasure. Subsequently, we aim to explore the true extent of the privacy threat that extension \ufb01ngerprinting poses to users, and present a novel study on the feasibility of inference attacks that reveal private and sensitive user information based on the functionality and nature of their extensions. We \ufb01rst collect over 1.44 million public user reviews of our detectable extensions, which provide a unique macroscopic view of the browser extension ecosystem and enable a more precise evaluation of the discriminatory power of extensions as well as a new deanonymization vector. We also automatically categorize extensions based on the developers\u2019 descriptions and identify those that can lead to",
            "keywords": [
                "Browser Fingerprinting",
                "Privacy Threats",
                "Browser Extensions",
                "Behavioral Artifacts",
                "Inference Attacks"
            ]
        },
        "url": "URL#2305513",
        "sema_paperId": "096459bb1ad69b89ad73e08b880c344d7995139d"
    },
    {
        "@score": "1",
        "@id": "2305514",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "78/5052",
                        "text": "Kyungtae Kim"
                    },
                    {
                        "@pid": "201/5448",
                        "text": "Dae R. Jeong"
                    },
                    {
                        "@pid": "122/2010",
                        "text": "Chung Hwan Kim"
                    },
                    {
                        "@pid": "150/5222",
                        "text": "Yeongjin Jang"
                    },
                    {
                        "@pid": "45/4154",
                        "text": "Insik Shin"
                    },
                    {
                        "@pid": "45/7986",
                        "text": "Byoungyoung Lee"
                    }
                ]
            },
            "title": "HFL: Hybrid Fuzzing on the Linux Kernel.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/KimJKJSL20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/hfl-hybrid-fuzzing-on-the-linux-kernel/",
            "url": "https://dblp.org/rec/conf/ndss/KimJKJSL20",
            "abstract": "Hybrid fuzzing, combining symbolic execution and fuzzing, is a promising approach for vulnerability discovery because each approach can complement the other. However, we observe that applying hybrid fuzzing to kernel testing is challenging because the following unique characteristics of the kernel make a naive adoption of hybrid fuzzing inefficient: 1) having indirect control transfers determined by system call arguments, 2) controlling and matching internal system state via system calls, and 3) inferring nested argument type for invoking system calls. Failure to handling such challenges will render both fuzzing and symbolic execution inefficient, and thereby, will result in an inefficient hybrid fuzzing. Although these challenges are essential to both fuzzing and symbolic execution, to the best of our knowledge, existing kernel testing approaches either naively use each technique separately without handling such challenges or imprecisely handle a part of challenges only by static analysis. To this end, this paper proposes HFL, which not only combines fuzzing with symbolic execution for hybrid fuzzing but also addresses kernel-specific fuzzing challenges via three distinct features: 1) converting indirect control transfers to direct transfers, 2) inferring system call sequence to build a consistent system state, and 3) identifying nested arguments types of system calls. As a result, HFL found 24 previously unknown vulnerabilities in recent Linux kernels. Additionally, HFL achieves 15% and 26% higher code coverage than Moonshine and Syzkaller, respectively, and over kAFL/S2E/TriforceAFL, achieving even four times better coverage, using the same amount of resources (CPU, time, etc.). Regarding vulnerability discovery performance, HFL found 13 known vulnerabilities more than three times faster than Syzkaller.",
            "keywords": [
                "Hybrid Fuzzing",
                "Linux Kernel Testing",
                "Vulnerability Discovery",
                "Symbolic Execution",
                "System Call Analysis"
            ]
        },
        "url": "URL#2305514",
        "sema_paperId": "5b37f758a3f891fcb5dbec1abf82b998b58aec1c"
    },
    {
        "@score": "1",
        "@id": "2305515",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "208/7179",
                        "text": "Marcel Kneib"
                    },
                    {
                        "@pid": "254/2104",
                        "text": "Oleg Schell"
                    },
                    {
                        "@pid": "177/2248",
                        "text": "Christopher Huth"
                    }
                ]
            },
            "title": "EASI: Edge-Based Sender Identification on Resource-Constrained Platforms for Automotive Networks.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/KneibSH20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/easi-edge-based-sender-identification-on-resource-constrained-platforms-for-automotive-networks/",
            "url": "https://dblp.org/rec/conf/ndss/KneibSH20",
            "abstract": "In vehicles, internal Electronic Control Units (ECUs) are increasingly prone to adversarial exploitation over wireless connections due to ongoing digitalization. Controlling an ECU allows an adversary to send messages to the internal vehicle bus and thereby to control various vehicle functions. Access to the Controller Area Network (CAN), the most widely used bus technology, is especially severe as it controls brakes and steering. However, state of the art receivers are not able to identify the sender of a frame. Retrofitting frame authenticity, e.g. through Message Authentication Codes (MACs), is only possible to a limited extent due to reduced bandwidth, low payload and limited computational resources. To address this problem, observation in analog differences of the CAN signal was proposed to determine the actual sender. Some of the prior approaches exhibit good identification and detection rates, however require high sampling rates and a high computing effort. With EASI we significantly reduce the required resources and at the same time show increased identification rates of 99.98% by having no false positives in a prototype structure and two series production vehicles. In comparison to the most lightweight approach so far, we have reduced the memory footprint and the computational requirements by a factor of 168 and 142, respectively. In addition, we show the feasibility of EASI and thus demonstrate for the first time that voltage-based sender identification is realizable using comprehensive signal characteristics on resource-constrained platforms. Due to the lightweight design, we achieved a classification in under 100\u03bcs with a training time of 2.61 seconds. We also showed the ability to adapt the system to incremental signal changes during operation. Since cost effectiveness is of utmost importance in the automotive industry due to high production volumes, the achieved improvements are significant and necessary to realize sender identification.",
            "keywords": [
                "Automotive Networks",
                "Sender Identification",
                "Electronic Control Units (ECUs)",
                "Controller Area Network (CAN)",
                "Voltage-Based Identification"
            ]
        },
        "url": "URL#2305515",
        "sema_paperId": "1a6d8723d3df5dfdddf8862ff8de79dd00f331db"
    },
    {
        "@score": "1",
        "@id": "2305516",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "46/4109",
                        "text": "Jonghoon Kwon"
                    },
                    {
                        "@pid": "140/7873-3",
                        "text": "Taeho Lee 0003"
                    },
                    {
                        "@pid": "270/2377",
                        "text": "Claude H\u00e4hni"
                    },
                    {
                        "@pid": "16/6873",
                        "text": "Adrian Perrig"
                    }
                ]
            },
            "title": "SVLAN: Secure &amp; Scalable Network Virtualization.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/KwonLHP20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/svlan-secure-scalable-network-virtualization/",
            "url": "https://dblp.org/rec/conf/ndss/KwonLHP20",
            "abstract": "Network isolation is a critical modern Internet service. To date, network operators have created a logical network of distributed systems to provide communication isolation between different parties. However, the current network isolation is limited in scalability and flexibility. It limits the number of virtual networks and it only supports isolation at host (or virtualmachine) granularity. In this paper, we introduce Scalable Virtual Local Area Networking (SVLAN) that scales to a large number of distributed systems and offers improved flexibility in providing secure network isolation. With the notion of destination-driven reachability and packet-carrying forwarding state, SVLAN not only offers communication isolation but isolation can be specified at different granularities, e.g., per-application or per-process. Our proof-of-concept SVLAN implementation demonstrates its feasibility and practicality for real-world applications.",
            "keywords": [
                "Network Virtualization",
                "Scalable Network Isolation",
                "Distributed Systems",
                "Communication Isolation",
                "Granularity of Isolation"
            ]
        },
        "url": "URL#2305516",
        "sema_paperId": "213de2f2ca8c8abfa36f705154bac3a139f8a7c4"
    },
    {
        "@score": "1",
        "@id": "2305517",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "67/587",
                        "text": "Taekjin Lee"
                    },
                    {
                        "@pid": "257/1291",
                        "text": "Seongil Wi"
                    },
                    {
                        "@pid": "256/5167",
                        "text": "Suyoung Lee"
                    },
                    {
                        "@pid": "09/3668",
                        "text": "Sooel Son"
                    }
                ]
            },
            "title": "FUSE: Finding File Upload Bugs via Penetration Testing.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/LeeWLS20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/fuse-finding-file-upload-bugs-via-penetration-testing/",
            "url": "https://dblp.org/rec/conf/ndss/LeeWLS20",
            "abstract": "\u2014An Unrestricted File Upload (UFU) vulnerability is a critical security threat that enables an adversary to upload her choice of a forged \ufb01le to a target web server. This bug evolves into an Unrestricted Executable File Upload (UEFU) vulnerability when the adversary is able to conduct remote code execution of the uploaded \ufb01le via triggering its URL. We design and implement FUSE, a penetration testing tool designed to discover UFU and UEFU vulnerabilities in server-side PHP web applications. The goal of FUSE is to generate upload requests; each request becomes an exploit payload that triggers a UFU or UEFU vulnerability. However, this approach entails two technical challenges: (1) it should generate an upload request that bypasses all content-\ufb01ltering checks present in a target web application; and (2) it should preserve the execution semantic of the resulting uploaded \ufb01le. We address these technical challenges by mutating standard upload requests with carefully designed mutations that enable the bypassing of content-\ufb01ltering checks and do not tamper with the execution of uploaded \ufb01les. FUSE discovered 30 previously unreported UEFU vulnerabilities, including 15 CVEs from 33 real-world web applications, thereby demonstrating its ef\ufb01cacy in \ufb01nding code execution bugs via \ufb01le uploads.",
            "keywords": [
                "File Upload Vulnerabilities",
                "Unrestricted File Upload",
                "Remote Code Execution",
                "Penetration Testing",
                "FUSE Tool"
            ]
        },
        "url": "URL#2305517",
        "sema_paperId": "d77ab0f957d1b114989a4e22bc4cd30c10daf61e"
    },
    {
        "@score": "1",
        "@id": "2305518",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "37/3545",
                        "text": "Hui Lin"
                    },
                    {
                        "@pid": "270/2376",
                        "text": "Jianing Zhuang"
                    },
                    {
                        "@pid": "51/6805",
                        "text": "Yih-Chun Hu"
                    },
                    {
                        "@pid": "151/9102",
                        "text": "Huayu Zhou"
                    }
                ]
            },
            "title": "DefRec: Establishing Physical Function Virtualization to Disrupt Reconnaissance of Power Grids&apos; Cyber-Physical Infrastructures.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/LinZHZ20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/defrec-establishing-physical-function-virtualization-to-disrupt-reconnaissance-of-power-grids-cyber-physical-infrastructures/",
            "url": "https://dblp.org/rec/conf/ndss/LinZHZ20",
            "abstract": "\u2014Reconnaissance is critical for adversaries to prepare attacks causing physical damage in industrial control systems (ICS) like smart power grids. Disrupting reconnaissance is challenging. The state-of-the-art moving target defense (MTD) techniques based on mimicking and simulating system behaviors do not consider the physical infrastructure of power grids and can be easily identi\ufb01ed. To overcome these challenges, we propose physical function virtualization (PFV) that \u201chooks\u201d network interactions with real physical devices and uses these real devices to build lightweight virtual nodes that follow the actual implementation of network stacks, system invariants, and physical state variations in the real devices. On top of PFV, we propose DefRec, a defense mechanism that signi\ufb01cantly increases the effort required for an adversary to infer the knowledge of power grids\u2019 cyber-physical infrastructures. By randomizing communications and crafting decoy data for virtual nodes, DefRec can mislead adversaries into designing damage-free attacks. We implement PFV and DefRec in the ONOS network operating system and evaluate them in a cyber-physical testbed, using real devices from different vendors and HP physical switches to simulate six power grids. The experimental results show that with negligible overhead, PFV can accurately follow the behavior of real devices. DefRec can delay adversaries\u2019 reconnaissance for more than 100 years by adding a number of virtual nodes less than or equal to 20% of the number of real devices.",
            "keywords": [
                "Cyber-Physical Systems",
                "Power Grid Security",
                "Reconnaissance Disruption",
                "Physical Function Virtualization",
                "Moving Target Defense"
            ]
        },
        "url": "URL#2305518",
        "sema_paperId": "f365d0a3bdeb17c97c040468e8198e958a3b7319"
    },
    {
        "@score": "1",
        "@id": "2305519",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "243/3648",
                        "text": "Shiqing Luo"
                    },
                    {
                        "@pid": "52/5285",
                        "text": "Anh Nguyen"
                    },
                    {
                        "@pid": "14/5979-1",
                        "text": "Chen Song 0001"
                    },
                    {
                        "@pid": "75/2611-4",
                        "text": "Feng Lin 0004"
                    },
                    {
                        "@pid": "11/6689",
                        "text": "Wenyao Xu"
                    },
                    {
                        "@pid": "28/10126",
                        "text": "Zhisheng Yan"
                    }
                ]
            },
            "title": "OcuLock: Exploring Human Visual System for Authentication in Virtual Reality Head-mounted Display.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/LuoN00XY20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/oculock-exploring-human-visual-system-for-authentication-in-virtual-reality-head-mounted-display/",
            "url": "https://dblp.org/rec/conf/ndss/LuoN00XY20",
            "abstract": "The increasing popularity of virtual reality (VR) in a wide spectrum of applications has generated sensitive personal data such as medical records and credit card information. While protecting such data from unauthorized access is critical, directly applying traditional authentication methods (e.g., PIN) through new VR input modalities such as remote controllers and head navigation would cause security issues. The authentication action can be purposefully observed by attackers to infer the authentication input. Unlike any other mobile devices, VR presents immersive experience via a head-mounted display (HMD) that fully covers users\u2019 eye area without public exposure. Leveraging this feature, we explore human visual system (HVS) as a novel biometric authentication tailored for VR platforms. While previous works used eye globe movement (gaze) to authenticate smartphones or PCs, they suffer from a high error rate and low stability since eye gaze is highly dependent on cognitive states. In this paper, we explore the HVS as a whole to consider not just the eye globe movement but also the eyelid, extraocular muscles, cells, and surrounding nerves in the HVS. Exploring HVS biostructure and unique HVS features triggered by immersive VR content can enhance authentication stability. To this end, we present OcuLock, an HVS-based system for reliable and unobservable VR HMD authentication. OcuLock is empowered by an electrooculography (EOG) based HVS sensing framework and a record-comparison driven authentication scheme. Experiments through 70 subjects show that OcuLock is resistant against common types of attacks such as impersonation attack and statistical attack with Equal Error Rates as low as 3.55% and 4.97% respectively. More importantly, OcuLock maintains a stable performance over a 2month period and is preferred by users when compared to other potential approaches.",
            "keywords": [
                "Virtual Reality Authentication",
                "Human Visual System",
                "Biometric Authentication",
                "Electrooculography",
                "OcuLock"
            ]
        },
        "url": "URL#2305519",
        "sema_paperId": "305a39ce73c29d8460c5e36590e7c5c64c3a790b"
    },
    {
        "@score": "1",
        "@id": "2305520",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "270/2295",
                        "text": "Alessandro Mantovani"
                    },
                    {
                        "@pid": "204/5152",
                        "text": "Simone Aonzo"
                    },
                    {
                        "@pid": "86/9728",
                        "text": "Xabier Ugarte-Pedrero"
                    },
                    {
                        "@pid": "54/3464",
                        "text": "Alessio Merlo"
                    },
                    {
                        "@pid": "56/490",
                        "text": "Davide Balzarotti"
                    }
                ]
            },
            "title": "Prevalence and Impact of Low-Entropy Packing Schemes in the Malware Ecosystem.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/MantovaniAUMB20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/prevalence-and-impact-of-low-entropy-packing-schemes-in-the-malware-ecosystem/",
            "url": "https://dblp.org/rec/conf/ndss/MantovaniAUMB20",
            "abstract": "\u2014An open research problem on malware analysis is how to statically distinguish between packed and non-packed executables. This has an impact on antivirus software and malware analysis systems, which may need to apply different heuristics or to resort to more costly code emulation solutions to deal with the presence of potential packing routines. It can also affect the results of many research studies in which the authors adopt algorithms that are speci\ufb01cally designed for packed or non-packed binaries. Therefore, a wrong answer to the question \u201cis this executable packed?\u201d can make the difference between malware evasion and detection. It has long been known that packing and entropy are strongly correlated, often leading to the wrong assumption that a low entropy score implies that an executable is NOT packed. Exceptions to this rule exist, but they have always been considered as one-off cases, with a negligible impact on any large scale experiment. However, if such an assumption might have been acceptable in the past, our experiments show that this is not the case anymore as an increasing and remarkable number of packed malware samples implement proper schemes to keep their entropy low. In this paper, we empirically investigate and measure this problem by analyzing a dataset of 50K low-entropy Windows malware samples. Our tests show that, despite all samples have a low entropy value, over 30% of them adopt some form of runtime packing. We then extended our analysis beyond the pure entropy, by considering all static features that have been proposed so far to identify packed code. Again, our tests show that even a state of the art machine learning classi\ufb01er is unable to conclude whether a",
            "keywords": [
                "Malware Analysis",
                "Low-Entropy Packing",
                "Executable Packing",
                "Static Feature Analysis",
                "Runtime Packing Detection"
            ]
        },
        "url": "URL#2305520",
        "sema_paperId": "05462beae637fcbca3211174622f0cefc4623b85"
    },
    {
        "@score": "1",
        "@id": "2305521",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "154/8074",
                        "text": "Vasilios Mavroudis"
                    },
                    {
                        "@pid": "181/1565",
                        "text": "Karl W\u00fcst"
                    },
                    {
                        "@pid": "118/3376",
                        "text": "Aritra Dhar"
                    },
                    {
                        "@pid": "42/2366",
                        "text": "Kari Kostiainen"
                    },
                    {
                        "@pid": "51/1639",
                        "text": "Srdjan Capkun"
                    }
                ]
            },
            "title": "Snappy: Fast On-chain Payments with Practical Collaterals.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/MavroudisWDKC20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/snappy-fast-on-chain-payments-with-practical-collaterals/",
            "url": "https://dblp.org/rec/conf/ndss/MavroudisWDKC20",
            "abstract": "Permissionless blockchains offer many advantages but also have significant limitations including high latency. This prevents their use in important scenarios such as retail payments, where merchants should approve payments fast. Prior works have attempted to mitigate this problem by moving transactions off the chain. However, such Layer-2 solutions have their own problems: payment channels require a separate deposit towards each merchant and thus significant locked-in funds from customers; payment hubs require very large operator deposits that depend on the number of customers; and side-chains require trusted validators. \nIn this paper, we propose Snappy, a novel solution that enables recipients, like merchants, to safely accept fast payments. In Snappy, all payments are on the chain, while small customer collaterals and moderate merchant collaterals act as payment guarantees. Besides receiving payments, merchants also act as statekeepers who collectively track and approve incoming payments using majority voting. In case of a double-spending attack, the victim merchant can recover lost funds either from the collateral of the malicious customer or a colluding statekeeper (merchant). Snappy overcomes the main problems of previous solutions: a single customer collateral can be used to shop with many merchants; merchant collaterals are independent of the number of customers; and validators do not have to be trusted. Our Ethereum prototype shows that safe, fast (<2 seconds) and cheap payments are possible on existing blockchains.",
            "keywords": [
                "On-chain Payments",
                "Blockchain Scalability",
                "Payment Collaterals",
                "Double-Spending Attack",
                "Fast Transaction Processing"
            ]
        },
        "url": "URL#2305521",
        "sema_paperId": "20a4b3a3b80cd90d57a4437f5c5b9672b11aa8fa"
    },
    {
        "@score": "1",
        "@id": "2305522",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "260/3169",
                        "text": "Hamid Mozaffari"
                    },
                    {
                        "@pid": "22/1797",
                        "text": "Amir Houmansadr"
                    }
                ]
            },
            "title": "Heterogeneous Private Information Retrieval.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/MozaffariH20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/heterogeneous-private-information-retrieval/",
            "url": "https://dblp.org/rec/conf/ndss/MozaffariH20",
            "abstract": "\u2014Private information retrieval (PIR) enables clients to query and retrieve data from untrusted servers without the untrusted servers learning which data was retrieved. In this paper, we present a new class of multi-server PIR protocols, which we call heterogeneous PIR (HPIR) . In such multi-server PIR protocols, the computation and communication overheads imposed on the PIR servers are non-uniform, i.e., some servers handle higher computation/communication burdens than the others. This enables heterogeneous PIR protocols to be suitable for a range of new PIR applications. What enables us to enforce such heterogeneity is a unique PIR-tailored secret sharing algorithm that we leverage in building our PIR protocol. We have implemented our HPIR protocol and evaluated its performance in comparison with regular (i.e., homogenous) PIR protocols. Our evaluations demonstrate that a querying client can trade off the computation and communication loads of the (heterogeneous) PIR servers by adjusting some parameters. For example in a two server scenario with a heterogeneity degree of 4 / 1 , to retrieve a 456 KB \ufb01le from a 0 . 2 GB database, the rich (i.e., resourceful) PIR server will do 1 . 1 seconds worth of computation compared to 0 . 3 seconds by the poor (resource-constrained) PIR server; this is while each of the servers would do the same 1 seconds of computation in a homogeneous settings. Also, for this given example, our HPIR protocol will impose a 912 KB communication bandwidth on the rich server compared to 228 KB on the poor server (by contrast to 456 KB overheads on each of the servers for a traditional homogeneous design).",
            "keywords": [
                "Private Information Retrieval",
                "Heterogeneous PIR",
                "Multi-server Protocols",
                "Secret Sharing",
                "Resource Allocation"
            ]
        },
        "url": "URL#2305522",
        "sema_paperId": "c33cf66550e33afd991fadbbae5ffeeb7ea09642"
    },
    {
        "@score": "1",
        "@id": "2305523",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "187/8997",
                        "text": "Milad Nasr"
                    },
                    {
                        "@pid": "187/8999",
                        "text": "Hadi Zolfaghari"
                    },
                    {
                        "@pid": "22/1797",
                        "text": "Amir Houmansadr"
                    },
                    {
                        "@pid": "248/1723",
                        "text": "Amirhossein Ghafari"
                    }
                ]
            },
            "title": "MassBrowser: Unblocking the Censored Web for the Masses, by the Masses.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/NasrZHG20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/massbrowser-unblocking-the-censored-web-for-the-masses-by-the-masses/",
            "url": "https://dblp.org/rec/conf/ndss/NasrZHG20",
            "abstract": "Existing censorship circumvention systems fail to offer reliable circumvention without sacrificing their users\u2019 QoS and privacy, or undertaking high costs of operation. We have designed and implemented a censorship circumvention system, MassBrowser, whose goal is to offer effective censorship circumvention to a large mass of censored users, with a high quality of service (QoS), low cost of operation, and adjustable privacy protection. Towards this, we have made several key decisions in designing our system. First, we argue that circumvention systems should not bundle strong privacy protections (like anonymity) with censorship circumvention. Additional privacy properties should be offered to the users of circumvention systems as optional features which can be enabled by specific users or on specific connections (perhaps by trading off some QoS). Second, we have engineered MassBrowser by combining various state-of-the-art circumvention techniques to ensure strong censorship resilience at a very low cost of operation (i.e., $0.0001 per censored client per month when deployed at a large scale). In particular, MassBrowser aims at increasing the collateral damage of censorship by employing a \u201cmass\u201d of normal Internet users, from both censored and non-censored areas, to serve as circumvention proxies. Also, MassBrowser uses various techniques, like CDNBrowsing, to optimize the loads on circumvention proxies. We have built and deployed MassBrowser as a fully operational system with end-user GUI software for major operating systems. Our system has been in the beta release mode for over a year with hundreds of invited users from major censored countries testing it on a daily basis.",
            "keywords": [
                "Censorship Circumvention",
                "Privacy Protection",
                "Quality of Service (QoS)",
                "Mass Proxy Network",
                "Censorship Resilience"
            ]
        },
        "url": "URL#2305523",
        "sema_paperId": "7853969619f255dca5125e8bed6dc86f45694016"
    },
    {
        "@score": "1",
        "@id": "2305524",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "203/1926",
                        "text": "Peter Ney"
                    },
                    {
                        "@pid": "95/5263",
                        "text": "Luis Ceze"
                    },
                    {
                        "@pid": "k/TadayoshiKohno",
                        "text": "Tadayoshi Kohno"
                    }
                ]
            },
            "title": "Genotype Extraction and False Relative Attacks: Security Risks to Third-Party Genetic Genealogy Services Beyond Identity Inference.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/NeyCK20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/genotype-extraction-and-false-relative-attacks-security-risks-to-third-party-genetic-genealogy-services-beyond-identity-inference/",
            "url": "https://dblp.org/rec/conf/ndss/NeyCK20",
            "abstract": "\u2014Customers of direct-to-consumer (DTC) genetic testing services routinely download their raw genetic data and give it to third-party companies that support additional features. One type of analysis, called genetic genealogy, uses genetic data and genealogical methods to \ufb01nd new relatives. While genetic genealogy is quite popular, it has raised new privacy concerns. Genetic genealogy services can be leveraged to \ufb01nd the person corresponding to anonymous genetic data and have been used dozens of times by law enforcement to solve crimes. We hypothesized that the open design and broad API offered by some genetic genealogy services raise other signi\ufb01cant security and privacy issues. To test this hypothesis, we analyzed the security practices of GEDmatch, the largest third-party genetic genealogy service. Here, we experimentally show how the GEDmatch API is vulnerable to a number of attacks from an adversary that only uploads normally formatted genetic data \ufb01les and runs standard queries. Using a small number of speci\ufb01cally designed \ufb01les and queries, an attacker can extract a large percentage of the genetic markers from other users; 92% of markers can be extracted with 98% accuracy, including hundreds of medically sensitive markers. We also \ufb01nd that an adversary can construct genetic data \ufb01les that falsely appear like relatives to other samples in the database; in certain situations, these false relatives can be used to make the re-identi\ufb01cation of genetic data more dif\ufb01cult. These attacks are possible because of the rich set of features supported by the API, including detailed visualizations, that are meant to enhance usability. We conclude with security recommendations for genetic genealogy services.",
            "keywords": [
                "Genetic Genealogy",
                "Privacy Concerns",
                "Genotype Extraction",
                "False Relatives",
                "Security Vulnerabilities"
            ]
        },
        "url": "URL#2305524",
        "sema_paperId": "33e2a03420a7deabe4024a505fddcfbac015fb73"
    },
    {
        "@score": "1",
        "@id": "2305525",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "224/9301",
                        "text": "Riccardo Paccagnella"
                    },
                    {
                        "@pid": "154/4512",
                        "text": "Pubali Datta"
                    },
                    {
                        "@pid": "184/8086",
                        "text": "Wajih Ul Hassan"
                    },
                    {
                        "@pid": "126/3601",
                        "text": "Adam Bates 0001"
                    },
                    {
                        "@pid": "25/8166",
                        "text": "Christopher W. Fletcher"
                    },
                    {
                        "@pid": "39/1855",
                        "text": "Andrew Miller"
                    },
                    {
                        "@pid": "159/0537",
                        "text": "Dave Tian"
                    }
                ]
            },
            "title": "Custos: Practical Tamper-Evident Auditing of Operating Systems Using Trusted Execution.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/PaccagnellaDH0F20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/custos-practical-tamper-evident-auditing-of-operating-systems-using-trusted-execution/",
            "url": "https://dblp.org/rec/conf/ndss/PaccagnellaDH0F20",
            "abstract": "\u2014System auditing is a central concern when investigating and responding to security incidents. Unfortunately, attackers regularly engage in anti-forensic activities after a break-in, covering their tracks from the system logs in order to frustrate the efforts of investigators. While a variety of tamper-evident logging solutions have appeared throughout the industry and the literature, these techniques do not meet the operational and scalability requirements of system-layer audit frameworks. In this work, we introduce C USTOS , a practical framework for the detection of tampering in system logs. C USTOS consists of a tamper-evident logging layer and a decentralized auditing protocol. The former enables the veri\ufb01cation of log integrity with minimal changes to the underlying logging framework, while the latter enables near real-time detection of log integrity violations within an enterprise-class network. C USTOS is made practical by the observation that we can decouple the costs of cryptographic log commitments from the act of creating and storing log events, without trading off security, leveraging features of off-the-shelf trusted execution environments. Supporting over one million events per second, we show that C USTOS \u2019 tamper-evident logging protocol is three orders of magnitude (1000 \u00d7 ) faster than prior solutions and incurs only between 2% and 7% runtime overhead over insecure logging on intensive workloads. Further, we show that C USTOS \u2019 auditing protocol can detect violations in near real-time even in the presence of a powerful distributed adversary and with minimal (3%) network overhead. Our case study on a real-world APT attack scenario demonstrates that C USTOS forces anti-forensic attackers into a \u201close-lose\u201d situation, where they can either be covert and not tamper with logs (which can be used for forensics), or erase logs but then",
            "keywords": [
                "Tamper-Evident Logging",
                "System Auditing",
                "Trusted Execution Environments",
                "Log Integrity",
                "Anti-Forensic Activities"
            ]
        },
        "url": "URL#2305525",
        "sema_paperId": "34ab3f31f842a6f06996da8fb7ca83d563e95812"
    },
    {
        "@score": "1",
        "@id": "2305526",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "119/7177",
                        "text": "Taemin Park"
                    },
                    {
                        "@pid": "270/2424",
                        "text": "Karel Dhondt"
                    },
                    {
                        "@pid": "164/2771",
                        "text": "David Gens"
                    },
                    {
                        "@pid": "37/9431",
                        "text": "Yeoul Na"
                    },
                    {
                        "@pid": "127/6103",
                        "text": "Stijn Volckaert"
                    },
                    {
                        "@pid": "f/MichaelFranz",
                        "text": "Michael Franz"
                    }
                ]
            },
            "title": "NoJITsu: Locking Down JavaScript Engines.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ParkDGNVF20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/nojitsu-locking-down-javascript-engines/",
            "url": "https://dblp.org/rec/conf/ndss/ParkDGNVF20",
            "abstract": "\u2014Data-only attacks against dynamic scripting environments have become common. Web browsers and other modern applications embed scripting engines to support interactive content. The scripting engines optimize performance via just-in-time compilation. Since applications are increasingly hardened against code-reuse attacks, adversaries are looking to achieve code execution or elevate privileges by corrupting sensitive data like the intermediate representation of optimizing JIT compilers. This has inspired numerous defenses for just-in-time compilers. Our paper demonstrates that securing JIT compilation is not suf\ufb01cient. First, we present a proof-of-concept data-only attack against a recent version of Mozilla\u2019s SpiderMonkey JIT in which the attacker only corrupts heap objects to successfully issue a system call from within bytecode execution at run time. Previous work assumed that bytecode execution is safe by construction since interpreters only allow a narrow set of benign instructions and bytecode is always checked for validity before execution. We show that this does not prevent malicious code execution in practice. Second, we design a novel defense, dubbed N O JIT SU to protect complex, real-world scripting engines from data-only attacks against interpreted code. The key idea behind our defense is to enable \ufb01ne-grained memory access control for individual memory regions based on their roles throughout the JavaScript lifecycle. For this we combine automated analysis, instrumentation, compartmentalization, and Intel\u2019s Memory-Protection Keys to secure SpiderMonkey against existing and newly synthesized attacks. We implement and thoroughly test our implementation using a number of real-world scenarios as well as standard benchmarks. We show that N O JIT SU successfully thwarts code-reuse as well as data-only attacks against any part of the scripting engine while offering a modest run-time overhead of only 5%.",
            "keywords": [
                "JavaScript Security",
                "Just-in-Time Compilation",
                "Data-only Attacks",
                "Memory Access Control",
                "SpiderMonkey"
            ]
        },
        "url": "URL#2305526",
        "sema_paperId": "86c8e79894811f40f1f4bffc779a7748b8e5f123"
    },
    {
        "@score": "1",
        "@id": "2305527",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "64/3169",
                        "text": "Arpita Patra"
                    },
                    {
                        "@pid": "187/5691",
                        "text": "Ajith Suresh"
                    }
                ]
            },
            "title": "BLAZE: Blazing Fast Privacy-Preserving Machine Learning.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/PatraS20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/blaze-blazing-fast-privacy-preserving-machine-learning/",
            "url": "https://dblp.org/rec/conf/ndss/PatraS20",
            "abstract": "Machine learning tools have illustrated their potential in many significant sectors such as healthcare and finance, to aide in deriving useful inferences. The sensitive and confidential nature of the data, in such sectors, raise natural concerns for the privacy of data. This motivated the area of Privacy-preserving Machine Learning (PPML) where privacy of the data is guaranteed. Typically, ML techniques require large computing power, which leads clients with limited infrastructure to rely on the method of Secure Outsourced Computation (SOC). In SOC setting, the computation is outsourced to a set of specialized and powerful cloud servers and the service is availed on a pay-per-use basis. In this work, we explore PPML techniques in the SOC setting for widely used ML algorithms-- Linear Regression, Logistic Regression, and Neural Networks.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2020/02/24202-paper.pdf",
            "keywords": [
                "Privacy-Preserving Machine Learning",
                "Secure Outsourced Computation",
                "Data Privacy",
                "Computational Efficiency",
                "Linear Regression and Logistic Regression"
            ]
        },
        "url": "URL#2305527"
    },
    {
        "@score": "1",
        "@id": "2305528",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "221/3626",
                        "text": "Victor Le Pochat"
                    },
                    {
                        "@pid": "202/6739",
                        "text": "Tim Van hamme"
                    },
                    {
                        "@pid": "216/8573",
                        "text": "Sourena Maroofi"
                    },
                    {
                        "@pid": "147/2244",
                        "text": "Tom van Goethem"
                    },
                    {
                        "@pid": "12/603",
                        "text": "Davy Preuveneers"
                    },
                    {
                        "@pid": "d/AndrzejDuda",
                        "text": "Andrzej Duda"
                    },
                    {
                        "@pid": "13/86",
                        "text": "Wouter Joosen"
                    },
                    {
                        "@pid": "06/10585",
                        "text": "Maciej Korczynski"
                    }
                ]
            },
            "title": "A Practical Approach for Taking Down Avalanche Botnets Under Real-World Constraints.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/PochathMGPDJK20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/a-practical-approach-for-taking-down-avalanche-botnets-under-real-world-constraints/",
            "url": "https://dblp.org/rec/conf/ndss/PochathMGPDJK20",
            "abstract": "In 2016, law enforcement dismantled the infrastructure of the Avalanche bulletproof hosting service, the largest takedown of a cybercrime operation so far. The malware families supported by Avalanche use Domain Generation Algorithms (DGAs) to generate random domain names for controlling their botnets. The takedown proactively targets these presumably malicious domains; however, as coincidental collisions with legitimate domains are possible, investigators must first classify domains to prevent undesirable harm to website owners and botnet victims. The constraints of this real-world takedown (proactive decisions without access to malware activity, no bulk patterns and no active connections) mean that approaches from the state of the art cannot be applied. The problem of classifying thousands of registered DGA domain names therefore required an extensive, painstaking manual effort by law enforcement investigators. To significantly reduce this effort without compromising correctness, we develop a model that automates the classification. Through a synergetic approach, we achieve an accuracy of 97.6% with ground truth from the 2017 and 2018 Avalanche takedowns; for the 2019 takedown, this translates into a reduction of 76.9% in manual investigation effort. Furthermore, we interpret the model to provide investigators with insights into how benign and malicious domains differ in behavior, which features and data sources are most important, and how the model can be applied according to the practical requirements of a real-world takedown.",
            "keywords": [
                "Avalanche Botnet",
                "Domain Generation Algorithms",
                "Malicious Domain Classification",
                "Cybercrime Takedown",
                "Automated Investigation Effort"
            ]
        },
        "url": "URL#2305528",
        "sema_paperId": "976e25d26b8d86e22a5e44e3a964187d8938e073"
    },
    {
        "@score": "1",
        "@id": "2305529",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "270/2488",
                        "text": "Ram Sundara Raman"
                    },
                    {
                        "@pid": "270/2365",
                        "text": "Adrian Stoll"
                    },
                    {
                        "@pid": "143/5671",
                        "text": "Jakub Dalek"
                    },
                    {
                        "@pid": "270/2465",
                        "text": "Reethika Ramesh"
                    },
                    {
                        "@pid": "121/4072",
                        "text": "Will Scott"
                    },
                    {
                        "@pid": "24/973",
                        "text": "Roya Ensafi"
                    }
                ]
            },
            "title": "Measuring the Deployment of Network Censorship Filters at Global Scale.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/RamanSDRSE20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/measuring-the-deployment-of-network-censorship-filters-at-global-scale/",
            "url": "https://dblp.org/rec/conf/ndss/RamanSDRSE20",
            "abstract": "\u2014Content \ufb01ltering technologies are often used for Internet censorship, but even as these technologies have become cheaper and easier to deploy, the censorship measurement community lacks a systematic approach to monitor their proliferation. Past research has focused on a handful of speci\ufb01c \ufb01ltering technologies, each of which required cumbersome manual detective work to identify. Researchers and policymakers require a more comprehensive picture of the state and evolution of censorship based on content \ufb01ltering in order to establish effective policies that protect Internet freedom. In this work, we present FilterMap, a novel framework that can scalably monitor content \ufb01ltering technologies based on their blockpages. FilterMap \ufb01rst compiles in-network and new remote censorship measurement techniques to gather blockpages from \ufb01lter deployments. We then show how the observed blockpages can be clustered, generating signatures for longitudinal tracking. FilterMap outputs a map of regions of address space in which the same blockpages appear (corresponding to \ufb01lter deployments), and each unique blockpage is manually veri\ufb01ed to avoid false positives. By collecting and analyzing more than 379 million measurements from 45,000 vantage points against more than 18,000 sensitive test domains, we are able to identify \ufb01lter deployments associated with 90 vendors and actors and observe \ufb01ltering in 103 countries. We detect the use of commercial \ufb01ltering technologies for censorship in 36 out of 48 countries labeled as \u2018Not Free\u2019 or \u2018Partly Free\u2019 by the Freedom House \u201cFreedom on the Net\u201d report. The unrestricted transfer of content \ufb01ltering technologies have led to high availability, low cost, and highly effective \ufb01ltering techniques becoming easier to deploy and harder to circumvent. Identifying these \ufb01ltering deployments highlights policy and corporate social responsibility issues, and adds accountability to \ufb01lter manufacturers. Our continued publication of FilterMap data will help the international community track the scope, scale and evolution of content-based censorship.",
            "keywords": [
                "Internet Censorship",
                "Content Filtering",
                "Censorship Measurement",
                "Filter Deployments",
                "Blockpage Analysis"
            ]
        },
        "url": "URL#2305529",
        "sema_paperId": "bbd7ceb7f4673b273949b496857d53960f478036"
    },
    {
        "@score": "1",
        "@id": "2305530",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "217/1012",
                        "text": "Sivaramakrishnan Ramanathan"
                    },
                    {
                        "@pid": "89/6100",
                        "text": "Jelena Mirkovic"
                    },
                    {
                        "@pid": "89/6345",
                        "text": "Minlan Yu"
                    }
                ]
            },
            "title": "BLAG: Improving the Accuracy of Blacklists.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/RamanathanMY20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/blag-improving-the-accuracy-of-blacklists/",
            "url": "https://dblp.org/rec/conf/ndss/RamanathanMY20",
            "abstract": "\u2014IP address blacklists are a useful source of information about repeat attackers. Such information can be used to prioritize which traf\ufb01c to divert for deeper inspection (e.g., repeat offender traf\ufb01c), or which traf\ufb01c to serve \ufb01rst (e.g., traf\ufb01c from sources that are not blacklisted). But blacklists also suffer from overspecialization \u2013 each list is geared towards a speci\ufb01c purpose \u2013 and they may be inaccurate due to misclassi\ufb01cation or stale information. We propose BLAG, a system that evaluates and aggregates multiple blacklists feeds, producing a more useful, accurate and timely master blacklist , tailored to the speci\ufb01c customer network. BLAG uses a sample of the legitimate sources of the customer network\u2019s inbound traf\ufb01c to evaluate the accuracy of each blacklist over regions of address space. It then leverages recommendation systems to select the most accurate information to aggregate into its master blacklist. Finally, BLAG identi\ufb01es portions of the master blacklist that can be expanded into larger address regions (e.g. /24 pre\ufb01xes) to uncover more malicious addresses with minimum collateral damage. Our evaluation of 157 blacklists of various attack types and three ground-truth datasets shows that BLAG achieves high speci\ufb01city up to 99%, improves recall by up to 114 times compared to competing approaches, and detects attacks up to 13.7 days faster, which makes it a promising approach for blacklist generation.",
            "keywords": [
                "IP Address Blacklists",
                "Malicious Traffic Detection",
                "Blacklist Aggregation",
                "Accuracy Improvement",
                "Recommendation Systems"
            ]
        },
        "url": "URL#2305530",
        "sema_paperId": "082041a377899e500d7fdad30424314315f2e364"
    },
    {
        "@score": "1",
        "@id": "2305531",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "270/2465",
                        "text": "Reethika Ramesh"
                    },
                    {
                        "@pid": "270/2488",
                        "text": "Ram Sundara Raman"
                    },
                    {
                        "@pid": "189/5540",
                        "text": "Matthew Bernhard"
                    },
                    {
                        "@pid": "270/2402",
                        "text": "Victor Ongkowijaya"
                    },
                    {
                        "@pid": "270/2407",
                        "text": "Leonid Evdokimov"
                    },
                    {
                        "@pid": "126/2313",
                        "text": "Anne Edmundson"
                    },
                    {
                        "@pid": "270/2324",
                        "text": "Steven Sprecher"
                    },
                    {
                        "@pid": "72/7208-1",
                        "text": "Muhammad Ikram 0001"
                    },
                    {
                        "@pid": "24/973",
                        "text": "Roya Ensafi"
                    }
                ]
            },
            "title": "Decentralized Control: A Case Study of Russia.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/RameshRBOEESIE20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/decentralized-control-a-case-study-of-russia/",
            "url": "https://dblp.org/rec/conf/ndss/RameshRBOEESIE20",
            "abstract": "\u2014Until now, censorship research has largely focused on highly centralized networks that rely on government-run technical choke-points, such as the Great Firewall of China. Although it was previously thought to be prohibitively dif\ufb01cult, large-scale censorship in decentralized networks are on the rise. Our in-depth investigation of the mechanisms underlying decentralized information control in Russia shows that such large-scale censorship can be achieved in decentralized networks through inexpensive commodity equipment. This new form of information control presents a host of problems for censorship measurement, including dif\ufb01culty identifying censored content, requiring measurements from diverse perspectives, and variegated censorship mechanisms that require signi\ufb01cant effort to identify in a robust manner. By working with activists on the ground in Russia, we obtained \ufb01ve leaked blocklists signed by Roskomnadzor, the Russian government\u2019s federal service for mass communications, along with seven years of historical blocklist data. This authoritative list contains domains, IPs, and subnets that ISPs have been required to block since November 1st, 2012. We used the blocklist from April 24 2019, that contains 132,798 domains, 324,695 IPs, and 39 subnets, to collect active measurement data from residential, data center and infrastructural vantage points. Our vantage points span 408 unique ASes that control \u2248 65% of Russian IP address space. Our \ufb01ndings suggest that data centers block differently from the residential ISPs both in quantity and in method of blocking, resulting in different experiences of the Internet for residential network perspectives and data center perspectives. As expected, residential vantage points experience high levels of censorship. While we observe a range of blocking techniques, such as TCP/IP blocking, DNS manipulation",
            "keywords": [
                "Decentralized Censorship",
                "Information Control",
                "Russia",
                "Censorship Measurement",
                "Blocking Techniques"
            ]
        },
        "url": "URL#2305531",
        "sema_paperId": "0824e2b61154749e1976b693e919b54d8cb6dfa2"
    },
    {
        "@score": "1",
        "@id": "2305532",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "244/5274",
                        "text": "Sebastian Roth"
                    },
                    {
                        "@pid": "207/6562",
                        "text": "Timothy Barron"
                    },
                    {
                        "@pid": "89/9526",
                        "text": "Stefano Calzavara"
                    },
                    {
                        "@pid": "04/8280",
                        "text": "Nick Nikiforakis"
                    },
                    {
                        "@pid": "136/8343",
                        "text": "Ben Stock"
                    }
                ]
            },
            "title": "Complex Security Policy? A Longitudinal Analysis of Deployed Content Security Policies.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/RothBCNS20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/complex-security-policy-a-longitudinal-analysis-of-deployed-content-security-policies/",
            "url": "https://dblp.org/rec/conf/ndss/RothBCNS20",
            "abstract": "The Content Security Policy (CSP) mechanism was developed as a mitigation against script injection attacks in 2010. In this paper, we leverage the unique vantage point of the Internet Archive to conduct a historical and longitudinal analysis of how CSP deployment has evolved for a set of 10,000 highly ranked domains. In doing so, we document the long-term struggle site operators face when trying to roll out CSP for content restriction and highlight that even seemingly secure whitelists can be bypassed through expired or typo domains. Next to these new insights, we also shed light on the usage of CSP for other use cases, in particular, TLS enforcement and framing control. Here, we find that CSP can be easily deployed to fit those security scenarios, but both lack wide-spread adoption. Specifically, while the underspecified and thus inconsistently implemented X-Frame-Options header is increasingly used on the Web, CSP\u2019s well-specified and secure alternative cannot keep up. To understand the reasons behind this, we run a notification campaign and subsequent survey, concluding that operators have often experienced the complexity of CSP (and given up), utterly unaware of the easy-to-deploy components of CSP. Hence, we find the complexity of secure, yet functional content restriction gives CSP a bad reputation, resulting in operators not leveraging its potential to secure a site against the non-original attack vectors.",
            "keywords": [
                "Content Security Policy",
                "Web Security",
                "CSP Deployment",
                "Script Injection Mitigation",
                "Security Complexity"
            ]
        },
        "url": "URL#2305532",
        "sema_paperId": "6f2cbf99687942412b36ffea1771c40dafaf904e"
    },
    {
        "@score": "1",
        "@id": "2305533",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "77/2192",
                        "text": "David Rupprecht"
                    },
                    {
                        "@pid": "155/5132",
                        "text": "Katharina Kohls"
                    },
                    {
                        "@pid": "h/ThorstenHolz",
                        "text": "Thorsten Holz"
                    },
                    {
                        "@pid": "11/3019",
                        "text": "Christina P\u00f6pper"
                    }
                ]
            },
            "title": "IMP4GT: IMPersonation Attacks in 4G NeTworks.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/RupprechtKHP20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/imp4gt-impersonation-attacks-in-4g-networks/",
            "url": "https://dblp.org/rec/conf/ndss/RupprechtKHP20",
            "abstract": "\u2014Long Term Evolution (LTE/4G) establishes mutual authentication with a provably secure Authentication and Key Agreement (AKA) protocol on layer three of the network stack. Permanent integrity protection of the control plane safeguards the traf\ufb01c against manipulations. However, missing integrity protection of the user plane still allows an adversary to manipulate and redirect IP packets, as recently demonstrated. In this work, we introduce a novel cross-layer attack that exploits the existing vulnerability on layer two and extends it with an attack mechanism on layer three. More precisely, we take advantage of the default IP stack behavior of operating systems and show that this combination allows an active attacker to impersonate a user towards the network and vice versa; we name these attacks IMP 4G T (IMPersonation attacks in 4G neTworks). In contrast to a simple redirection attack as demonstrated in prior work, our attack dramatically extends the possible attack scenarios and thus emphasizes the need for user plane integrity protection in mobile communication standards. The results of our work imply that providers can no longer rely on mutual authentication for billing, access control, and legal prosecution. On the other side, users are exposed to any incoming IP connection as an adversary can bypass the provider\u2019s \ufb01rewall. To demonstrate the practical impact of our attack, we conduct two IMP 4G T attack variants in a commercial network, which\u2014 for the \ufb01rst time\u2014completely break the mutual authentication aim of LTE on the user plane in a real-world setting.",
            "keywords": [
                "4G Networks",
                "Mutual Authentication",
                "Impersonation Attacks",
                "User Plane Integrity",
                "Cross-Layer Attack"
            ]
        },
        "url": "URL#2305533",
        "sema_paperId": "9ed449156a774018de47a1cfec9a0a63e0ed2273"
    },
    {
        "@score": "1",
        "@id": "2305534",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "177/2910",
                        "text": "Teemu Rytilahti"
                    },
                    {
                        "@pid": "h/ThorstenHolz",
                        "text": "Thorsten Holz"
                    }
                ]
            },
            "title": "On Using Application-Layer Middlebox Protocols for Peeking Behind NAT Gateways.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/RytilahtiH20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/on-using-application-layer-middlebox-protocols-for-peeking-behind-nat-gateways/",
            "url": "https://dblp.org/rec/conf/ndss/RytilahtiH20",
            "abstract": "\u2014Typical port scanning approaches do not achieve a full coverage of all devices connected to the Internet as not all devices are directly reachable via a public (IPv4) address: due to IP address space exhaustion, \ufb01rewalls, and many other reasons, an end-to-end connectivity is not achieved in today\u2019s Internet anymore. Especially Network Address Translation (NAT) is widely deployed in practice and it has the side effect of \u201chiding\u201d devices from being scanned. Some protocols, however, require end-to-end connectivity to function properly and hence several methods were developed in the past to enable crossing network borders. In this paper, we explore how an attacker can take advantage of such application-layer middlebox protocols to access devices located behind these gateways. More speci\ufb01cally, we investigate different methods for identifying such devices by using only legitimate protocol features. We categorize the available protocols into two classes: First, there are persistent protocols that are typically port-forwarding based. Such protocols are used to allow local network devices to open and forward external ports to them. Second, there are non-persistent protocols that are typically proxy-based to route packets between network edges, such as HTTP and SOCKS proxies. We perform a comprehensive, Internet-wide analysis to obtain an accurate overview of how prevalent and widespread such protocols are in practice. Our results indicate that hundreds of thousands of hosts are vulnerable for different types of attacks, e.g., we detect over 400,000 hosts that are likely vulnerable for attacks involving the UPnP IGD protocol. More worrisome, we \ufb01nd empirical evidence that attackers are already actively exploiting such protocols in the wild to access devices located behind NAT gateways. Amongst other \ufb01ndings, we discover that at least 24% of all open Internet proxies are miscon\ufb01gured to allow accessing hosts on non-routable addresses.",
            "keywords": [
                "Application-Layer Middlebox Protocols",
                "Network Address Translation (NAT)",
                "Port Scanning",
                "Device Discovery",
                "Vulnerability Exploitation"
            ]
        },
        "url": "URL#2305534",
        "sema_paperId": "e1f75f9cc324ea459c386b5b6a5aa57b0dc8dbcd"
    },
    {
        "@score": "1",
        "@id": "2305535",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "205/2072",
                        "text": "Sergej Schumilo"
                    },
                    {
                        "@pid": "160/7844",
                        "text": "Cornelius Aschermann"
                    },
                    {
                        "@pid": "73/2297-2",
                        "text": "Ali Abbasi 0002"
                    },
                    {
                        "@pid": "248/1623",
                        "text": "Simon W\u00f6rner"
                    },
                    {
                        "@pid": "h/ThorstenHolz",
                        "text": "Thorsten Holz"
                    }
                ]
            },
            "title": "HYPER-CUBE: High-Dimensional Hypervisor Fuzzing.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/SchumiloAAWH20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/hyper-cube-high-dimensional-hypervisor-fuzzing/",
            "url": "https://dblp.org/rec/conf/ndss/SchumiloAAWH20",
            "abstract": "\u2014Virtual machine monitors (VMMs, also called hy-pervisors ) represent a very critical part of a modern software stack: compromising them could allow an attacker to take full control of the whole cloud infrastructure of any cloud provider. Hence their security is critical for many applications, especially in the context of Infrastructure-as-a-Service. In this paper, we present the design and implementation of H YPER -C UBE , a novel fuzzer that aims explicitly at testing hypervisors in an ef\ufb01cient, effective, and precise way. Our approach is based on a custom operating system that implements a custom bytecode interpreter. This high-throughput design for long-running, interactive targets allows us to fuzz a large number of both open source and proprietary hypervisors. In contrast to one-dimensional fuzzers such as AFL, H YPER -C UBE can interact with any number of interfaces in any order. Our evaluation results show that we can \ufb01nd more bugs (over 2 \u00d7 ) and coverage (as much as 2 \u00d7 ) than state-of-the-art hypervisor fuzzers. In most cases, we were even able to do so using multiple orders of magnitude less time than comparable fuzzers. H YPER -C UBE was also able to rediscover a set of well-known hypervisor vulnerabilities, such as VENOM, in less than \ufb01ve minutes. In total, we found 54 novel bugs, and so far obtained 43 CVEs. Our evaluation results demonstrate that next-generation coverage-guided fuzzers should incorporate a higher-throughput design for long-running targets such as hypervisors.",
            "keywords": [
                "Hypervisor Fuzzing",
                "Virtual Machine Monitors",
                "Security Testing",
                "Bug Discovery",
                "Coverage-Guided Fuzzing"
            ]
        },
        "url": "URL#2305535",
        "sema_paperId": "4e490b9e04c1b9db27582f0eb672611ed61a22b0"
    },
    {
        "@score": "1",
        "@id": "2305536",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "320/8568",
                        "text": "Imani N. Sherman"
                    },
                    {
                        "@pid": "192/6415",
                        "text": "Jasmine D. Bowers"
                    },
                    {
                        "@pid": "270/2514",
                        "text": "Keith McNamara Jr."
                    },
                    {
                        "@pid": "01/6747",
                        "text": "Juan E. Gilbert"
                    },
                    {
                        "@pid": "41/2122",
                        "text": "Jaime Ruiz"
                    },
                    {
                        "@pid": "14/3295",
                        "text": "Patrick Traynor"
                    }
                ]
            },
            "title": "Are You Going to Answer That? Measuring User Responses to Anti-Robocall Application Indicators.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ShermanBMGRT20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/are-you-going-to-answer-that-measuring-user-responses-to-anti-robocall-application-indicators/",
            "url": "https://dblp.org/rec/conf/ndss/ShermanBMGRT20",
            "abstract": "Robocalls are inundating phone users. These automated calls allow for attackers to reach massive audiences with scams ranging from credential hijacking to unnecessary IT support in a largely untraceable fashion. In response, many applications have been developed to alert mobile phone users of incoming robocalls. However, how well these applications communicate risk with their users is not well understood. In this paper, we identify common real-time security indicators used in the most popular anti-robocall applications. Using focus groups and user testing, we first identify which of these indicators most effectively alert users of danger. We then demonstrate that the most powerful indicators can reduce the likelihood that users will answer such calls by as much as 43%. Unfortunately, our evaluation also shows that attackers can eliminate the gains provided by such indicators using a small amount of targetspecific information (e.g., a known phone number). In so doing, we demonstrate that anti-robocall indicators could benefit from significantly increased attention from the research community.",
            "keywords": [
                "Anti-Robocall Applications",
                "User Risk Communication",
                "Security Indicators",
                "User Response Behavior",
                "Robocall Mitigation"
            ]
        },
        "url": "URL#2305536",
        "sema_paperId": "66fb5ce03075c5279ba8d03d1f708eb195a1bec3"
    },
    {
        "@score": "1",
        "@id": "2305537",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "180/3862",
                        "text": "Faysal Hossain Shezan"
                    },
                    {
                        "@pid": "259/8951",
                        "text": "Kaiming Cheng"
                    },
                    {
                        "@pid": "19/5112",
                        "text": "Zhen Zhang"
                    },
                    {
                        "@pid": "28/8733",
                        "text": "Yinzhi Cao"
                    },
                    {
                        "@pid": "39/5423-1",
                        "text": "Yuan Tian 0001"
                    }
                ]
            },
            "title": "TKPERM: Cross-platform Permission Knowledge Transfer to Detect Overprivileged Third-party Applications.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ShezanCZC020",
            "ee": "https://www.ndss-symposium.org/ndss-paper/tkperm-cross-platform-permission-knowledge-transfer-to-detect-overprivileged-third-party-applications/",
            "url": "https://dblp.org/rec/conf/ndss/ShezanCZC020",
            "abstract": "Permission-based access control enables users to manage and control their sensitive data for third-party applications. In an ideal scenario, third-party application includes enough details to illustrate the usage of such data, while the reality is that many descriptions of third-party applications are vague about their security or privacy activities. As a result, users are left with insufficient details when granting sensitive data to these applications. Prior works, such as WHYPER and AutoCog, have addressed the aforementioned problem via a so-called permission correlation system. Such a system correlates thirdparty applications\u2019 description with their requested permissions and determines an application as overprivileged, if a mismatch between the requested permission and the description is found. However, although prior works are successful on their own platforms, such as Android eco-system, they are not directly applicable to new platforms, such as Chrome extensions and IFTTT, without extensive data labeling and parameter tuning. In this paper, we design, implement, and evaluate a novel system, called TKPERM, which transfers knowledges of permission correlation systems across platforms. Our key idea is that these varied platforms with different use cases\u2014like smartphones, IoTs, and desktop browsers\u2014are all user-facing and thus allow the knowledges to be transferrable across platforms. Particularly, we adopt a greedy selection algorithm that picks the best source domains to transfer to the target permission on a new platform. TKPERM achieves 90.02% overall F1 score after transfer, which is 12.62% higher than the one of a model trained directly on the target domain without transfer. Particularly, TKPERM has 91.83% F1 score on IFTTT, 89.13% F1 score on Chrome-Extension, and 89.1% F1 score on SmartThings. TKPERM also successfully identified many real-world overprivileged applications, such as a gaming hub requesting location permissions without legitimate use.",
            "keywords": [
                "Permission Correlation",
                "Cross-platform Transfer",
                "Overprivileged Applications",
                "Third-party Application Privacy",
                "Permission Management"
            ]
        },
        "url": "URL#2305537",
        "sema_paperId": "c7c7be69f98f919f638892a8712ef14febbd36ff"
    },
    {
        "@score": "1",
        "@id": "2305538",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "156/5453",
                        "text": "Sandra Siby"
                    },
                    {
                        "@pid": "129/8347",
                        "text": "Marc Juarez"
                    },
                    {
                        "@pid": "d/ClaudiaDiaz",
                        "text": "Claudia D\u00edaz"
                    },
                    {
                        "@pid": "50/7563",
                        "text": "Narseo Vallina-Rodriguez"
                    },
                    {
                        "@pid": "01/4825",
                        "text": "Carmela Troncoso"
                    }
                ]
            },
            "title": "Encrypted DNS -&gt; Privacy? A Traffic Analysis Perspective.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/SibyJDVT20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/encrypted-dns-privacy-a-traffic-analysis-perspective/",
            "url": "https://dblp.org/rec/conf/ndss/SibyJDVT20",
            "abstract": "Virtually every connection to an Internet service is preceded by a DNS lookup which is performed without any traffic-level protection, thus enabling manipulation, redirection, surveillance, and censorship. To address these issues, large organizations such as Google and Cloudflare are deploying recently standardized protocols that encrypt DNS traffic between end users and recursive resolvers such as DNS-over-TLS (DoT) and DNS-over-HTTPS (DoH). In this paper, we examine whether encrypting DNS traffic can protect users from traffic analysis-based monitoring and censoring. We propose a novel feature set to perform the attacks, as those used to attack HTTPS or Tor traffic are not suitable for DNS\u2019 characteristics. We show that traffic analysis enables the identification of domains with high accuracy in closed and open world settings, using 124 times less data than attacks on HTTPS flows. We find that factors such as location, resolver, platform, or client do mitigate the attacks performance but they are far from completely stopping them. Our results indicate that DNS-based censorship is still possible on encrypted DNS traffic. In fact, we demonstrate that the standardized padding schemes are not effective. Yet, Tor \u2014 which does not effectively mitigate traffic analysis attacks on web traffic\u2014 is a good defense against DoH traffic analysis.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2020/02/24301-paper.pdf",
            "keywords": [
                "Encrypted DNS",
                "Traffic Analysis",
                "Censorship",
                "Domain Identification",
                "DoH/DoT Vulnerabilities"
            ]
        },
        "url": "URL#2305538"
    },
    {
        "@score": "1",
        "@id": "2305539",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "207/7977",
                        "text": "Dimitrios Sikeridis"
                    },
                    {
                        "@pid": "154/0807",
                        "text": "Panos Kampanakis"
                    },
                    {
                        "@pid": "61/3564",
                        "text": "Michael Devetsikiotis"
                    }
                ]
            },
            "title": "Post-Quantum Authentication in TLS 1.3: A Performance Study.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/SikeridisKD20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/post-quantum-authentication-in-tls-1-3-a-performance-study/",
            "url": "https://dblp.org/rec/conf/ndss/SikeridisKD20",
            "abstract": "The potential development of large-scale quantum computers is raising concerns among IT and security research professionals due to their ability to solve (elliptic curve) discrete logarithm and integer factorization problems in polynomial time. There is, therefore, a threat to public-key cryptography as all the currently used algorithms would be deemed insecure in a post-quantum (PQ) setting. In response, the National Institute of Standards and Technology (NIST) has initiated a process to standardize quantum-resistant crypto algorithms, focusing primarily on their security guarantees. Since PQ algorithms present significant differences over classical ones, their overall assessment should not be performed out-of-context. This work presents a detailed performance evaluation of the NIST signature algorithm candidates and investigates the imposed latency on TLS 1.3 connection establishment under realistic network conditions. In addition, we investigate their impact on the achievable TLS session throughput of a server and analyze the trade-off between lengthier PQ signatures, and computationally heavier PQ cryptographic operations for idle and heavily loaded servers. Our results demonstrate that the adoption of at least two PQ signature algorithms would indeed be viable for time-sensitive applications over TLS with little additional overhead over current signature algorithms. Also, we argue that more of the NIST PQ candidates can effectively be used for less time-sensitive applications, and provide an in-depth discussion on the integration of PQ authentication in encrypted tunneling protocols, along with the related challenges, and alternatives. Finally, we propose and evaluate the combination of different PQ signature algorithms across the same certificate chain in TLS. Results show a reduction of the TLS handshake time and a significant increase of a server's TLS tunnel connection rate over the alternative of the chain using a single PQ signature scheme.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2020/02/24203-paper.pdf",
            "keywords": [
                "Post-Quantum Cryptography",
                "TLS 1.3",
                "Signature Algorithms",
                "Performance Evaluation",
                "Quantum-Resistant Authentication"
            ]
        },
        "url": "URL#2305539"
    },
    {
        "@score": "1",
        "@id": "2305540",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "180/3218",
                        "text": "Jared M. Smith"
                    },
                    {
                        "@pid": "230/3896",
                        "text": "Kyle Birkeland"
                    },
                    {
                        "@pid": "185/1211",
                        "text": "Tyler McDaniel"
                    },
                    {
                        "@pid": "54/8732",
                        "text": "Max Schuchard"
                    }
                ]
            },
            "title": "Withdrawing the BGP Re-Routing Curtain: Understanding the Security Impact of BGP Poisoning through Real-World Measurements.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/SmithBMS20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/withdrawing-the-bgp-re-routing-curtain-understanding-the-security-impact-of-bgp-poisoning-through-real-world-measurements/",
            "url": "https://dblp.org/rec/conf/ndss/SmithBMS20",
            "abstract": "The security of the Internet's routing infrastructure has underpinned much of the past two decades of distributed systems security research. However, the converse is increasingly true. Routing and path decisions are now important for the security properties of systems built on top of the Internet. In particular, BGP poisoning leverages the de facto routing protocol between Autonomous Systems (ASes) to maneuver the return paths of upstream networks onto previously unusable, new paths. These new paths can be used to avoid congestion, censors, geo-political boundaries, or any feature of the topology which can be expressed at an AS-level. Given the increase in BGP poisoning usage as a security primitive, we set out to evaluate poisoning feasibility in practice beyond simulation. \nTo that end, using an Internet-scale measurement infrastructure, we capture and analyze over 1,400 instances of BGP poisoning across thousands of ASes as a mechanism to maneuver return paths of traffic. We analyze in detail the performance of steering paths, the graph-theoretic aspects of available paths, and re-evaluate simulated systems with this data. We find that the real-world evidence does not completely support the findings from simulated systems published in the literature. We also analyze filtering of BGP poisoning across types of ASes and ISP working groups. We explore the connectivity concerns when poisoning by reproducing a decade old experiment to uncover the current state of an Internet triple the size. We build predictive models for understanding an ASes' vulnerability to poisoning. Finally, an exhaustive measurement of an upper bound on the maximum path length of the Internet is presented, detailing how security research should react to ASes leveraging poisoned long paths. In total, our results and analysis expose the real-world impact of BGP poisoning on past and future security research.",
            "keywords": [
                "BGP Poisoning",
                "Internet Routing Security",
                "Autonomous Systems",
                "Path Manipulation",
                "Network Congestion Avoidance"
            ]
        },
        "url": "URL#2305540",
        "sema_paperId": "cbf16973d328c1671f940324cb4c724e2bd8c742"
    },
    {
        "@score": "1",
        "@id": "2305541",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "42/8668",
                        "text": "Trevor Smith"
                    },
                    {
                        "@pid": "270/2308",
                        "text": "Luke Dickenson"
                    },
                    {
                        "@pid": "s/KentESeamons",
                        "text": "Kent E. Seamons"
                    }
                ]
            },
            "title": "Let&apos;s Revoke: Scalable Global Certificate Revocation.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/SmithDS20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/lets-revoke-scalable-global-certificate-revocation/",
            "url": "https://dblp.org/rec/conf/ndss/SmithDS20",
            "abstract": "\u2014Current revocation strategies have numerous issues that prevent their widespread adoption and use, including scalability, privacy, and new infrastructure requirements. Consequently, revocation is often ignored, leaving clients vulnerable to man-in-the-middle attacks. This paper presents Let\u2019s Revoke, a scalable global revocation strategy that addresses the concerns of current revocation checking. Let\u2019s Revoke introduces a new unique identi\ufb01er to each certi\ufb01cate that serves as an index to a dynamically-sized bit vector containing revocation status information. The bit vector approach enables signi\ufb01cantly more ef\ufb01cient revocation checking for both clients and certi\ufb01cate authorities. We compare Let\u2019s Revoke to existing revocation schemes and show that it requires less storage and network bandwidth than other systems, including those that cover only a fraction of the global certi\ufb01cate space. We further demonstrate through simulations that Let\u2019s Revoke scales linearly up to ten billion certi\ufb01cates, even during mass revocation events.",
            "keywords": [
                "Certificate Revocation",
                "Scalability",
                "Revocation Checking",
                "Bit Vector",
                "Man-in-the-Middle Attacks"
            ]
        },
        "url": "URL#2305541",
        "sema_paperId": "0662826b896c56b702b3f67ba8e6d4e7365e3028"
    },
    {
        "@score": "1",
        "@id": "2305542",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "79/512",
                        "text": "Rock Stevens"
                    },
                    {
                        "@pid": "214/8818",
                        "text": "Josiah Dykstra"
                    },
                    {
                        "@pid": "270/2360",
                        "text": "Wendy Knox Everette"
                    },
                    {
                        "@pid": "270/2485",
                        "text": "James Chapman 0003"
                    },
                    {
                        "@pid": "270/2440",
                        "text": "Garrett Bladow"
                    },
                    {
                        "@pid": "177/2697",
                        "text": "Alexander Farmer"
                    },
                    {
                        "@pid": "270/2520",
                        "text": "Kevin Halliday"
                    },
                    {
                        "@pid": "20/7983",
                        "text": "Michelle L. Mazurek"
                    }
                ]
            },
            "title": "Compliance Cautions: Investigating Security Issues Associated with U.S. Digital-Security Standards.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/StevensDECBFHM20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/compliance-cautions-investigating-security-issues-associated-with-u-s-digital-security-standards/",
            "url": "https://dblp.org/rec/conf/ndss/StevensDECBFHM20",
            "abstract": ",",
            "keywords": [
                "Digital Security Standards",
                "Compliance Issues",
                "Security Investigations",
                "U.S. Regulations",
                "Security Risks"
            ]
        },
        "url": "URL#2305542",
        "sema_paperId": "63f3cf1caed8ff29afca7133211b22fb1657d3fb"
    },
    {
        "@score": "1",
        "@id": "2305543",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "270/2509",
                        "text": "Giada Stivala"
                    },
                    {
                        "@pid": "35/9056",
                        "text": "Giancarlo Pellegrino"
                    }
                ]
            },
            "title": "Deceptive Previews: A Study of the Link Preview Trustworthiness in Social Platforms.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/StivalaP20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/deceptive-previews-a-study-of-the-link-preview-trustworthiness-in-social-platforms/",
            "url": "https://dblp.org/rec/conf/ndss/StivalaP20",
            "abstract": "Social media has become a primary mean of content and information sharing, thanks to its speed and simplicity. In this scenario, link previews play the important role of giving a meaningful first glance to users, summarizing the content of the shared webpage within their title, description and image. In our work, we analyzed the preview-rendering process, observing how it is possible to misuse it to obtain benign-looking previews for malicious links. Concrete use-case of this research field is phishing and spam spread, considering targeted attacks in addition to large-scale campaigns. \n \nWe designed a set of experiments for 20 social media platforms including social networks and instant messenger applications and found out how most of the platforms follow their own preview design and format, sometimes providing partial information. Four of these platforms allow preview crafting so as to hide the malicious target even to a tech-savvy user, and we found that it is possible to create misleading previews for the remaining 16 platforms when an attacker can register their own domain. We also observe how 18 social media platforms do not employ active nor passive countermeasures against the spread of known malicious links or software, and that existing cross-checks on malicious URLs can be bypassed through client and server-side redirections. To conclude, we suggest seven recommendations covering the spectrum of our findings, to improve the overall preview-rendering mechanism and increase users\u2019 overall trust in social media platforms.",
            "keywords": [
                "Link Previews",
                "Social Media Trustworthiness",
                "Phishing Attacks",
                "Malicious Links",
                "Preview Rendering Mechanism"
            ]
        },
        "url": "URL#2305543",
        "sema_paperId": "9585fe3026df9de1e3fc5ef7106c30a5ed4a1e9b"
    },
    {
        "@score": "1",
        "@id": "2305544",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "182/4673",
                        "text": "Avinash Sudhodanan"
                    },
                    {
                        "@pid": "246/4771",
                        "text": "Soheil Khodayari"
                    },
                    {
                        "@pid": "35/3587",
                        "text": "Juan Caballero"
                    }
                ]
            },
            "title": "Cross-Origin State Inference (COSI) Attacks: Leaking Web Site States through XS-Leaks.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/SudhodananKC20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/cross-origin-state-inference-cosi-attacks-leaking-web-site-states-through-xs-leaks/",
            "url": "https://dblp.org/rec/conf/ndss/SudhodananKC20",
            "abstract": "In a Cross-Origin State Inference (COSI) attack, an attacker convinces a victim into visiting an attack web page, which leverages the cross-origin interaction features of the victim\u2019s web browser to infer the victim\u2019s state at a target web site. Multiple instances of COSI attacks have been found in the past under different names such as login detection or access detection attacks. But, those attacks only consider two states (e.g., logged in or not) and focus on a specific browser leak method (or XS-Leak).",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2020/02/24278-paper.pdf",
            "keywords": [
                "Cross-Origin State Inference",
                "XS-Leaks",
                "Web Privacy",
                "State Leakage",
                "Login Detection"
            ]
        },
        "url": "URL#2305544"
    },
    {
        "@score": "1",
        "@id": "2305545",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "266/1534",
                        "text": "Qinhan Tan"
                    },
                    {
                        "@pid": "270/2510",
                        "text": "Zhihua Zeng"
                    },
                    {
                        "@pid": "14/3799",
                        "text": "Kai Bu"
                    },
                    {
                        "@pid": "20/6179-1",
                        "text": "Kui Ren 0001"
                    }
                ]
            },
            "title": "PhantomCache: Obfuscating Cache Conflicts with Localized Randomization.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/TanZB020",
            "ee": "https://www.ndss-symposium.org/ndss-paper/phantomcache-obfuscating-cache-conflicts-with-localized-randomization/",
            "url": "https://dblp.org/rec/conf/ndss/TanZB020",
            "abstract": "Cache conflicts due to deterministic memory-to-cache mapping have long been exploited to leak sensitive information such as secret keys. While randomized mapping is fully investigated for L1 caches, it still remains unresolved about how to secure a much larger last-level cache (LLC). Recent solutions periodically change the mapping strategy to disrupt the crafting of conflicted addresses, which is a critical attack procedure to exploit cache conflicts. Remapping, however, increases both miss rate and access latency. We present PhantomCache for securing an LLC with remapping-free randomized mapping. We propose a localized randomization technique to bound randomized mapping of a memory address within only a limited number of cache sets. The small randomization space offers fast set search over an LLC in a memory access. The intrinsic randomness still suffices to obfuscate conflicts and disrupt efficient exploitation of conflicted addresses. We evaluate PhantomCache against an attacker exploring the state-of-the-art attack with linear-complexity. To secure an 8-bank 16~MB 16-way LLC, PhantomCache confines randomization space of an address within 8 sets and brings only 0.5% performance degradation and 0.5% storage overhead per cache line, which are 3x and 9x more efficient than the state-of-the-art solutions. Moreover, PhantomCache is solely an architectural solution and requires no software change.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2020/02/24086-paper.pdf",
            "keywords": [
                "Cache Security",
                "Randomized Mapping",
                "Last-Level Cache (LLC)",
                "Cache Conflicts",
                "Localized Randomization"
            ]
        },
        "url": "URL#2305545"
    },
    {
        "@score": "1",
        "@id": "2305546",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "195/5725",
                        "text": "Saeid Tizpaz-Niari"
                    },
                    {
                        "@pid": "34/6556",
                        "text": "Pavol Cern\u00fd"
                    },
                    {
                        "@pid": "06/5756",
                        "text": "Ashutosh Trivedi 0001"
                    }
                ]
            },
            "title": "Data-Driven Debugging for Functional Side Channels.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/Tizpaz-NiariC020",
            "ee": "https://www.ndss-symposium.org/ndss-paper/data-driven-debugging-for-functional-side-channels/",
            "url": "https://dblp.org/rec/conf/ndss/Tizpaz-NiariC020",
            "abstract": "Information leaks through side channels are a pervasive problem, even in security-critical applications. Functional side channels arise when an attacker knows that a secret value of a server stays fixed for a certain time. Then, the attacker can observe the server executions on a sequence of different public inputs, each paired with the same secret input. Thus for each secret, the attacker observes a function from public inputs to execution time, for instance, and she can compare these functions for different secrets. First, we introduce a notion of noninterference for functional side channels. We focus on the case of noisy observations, where we demonstrate with examples that there is a practical functional side channel in programs that would be deemed information-leak-free or be underestimated using the standard definition. Second, we develop a framework and techniques for debugging programs for functional side channels. We extend evolutionary fuzzing techniques to generate inputs that exploit functional dependencies of response times on public inputs. We adapt existing results and algorithms in functional data analysis to model the functions and discover the existence of side channels. We use a functional extension of standard decision tree learning to pinpoint the code fragments causing a side channel if there is one. We empirically evaluate the performance of our tool FUCHSIA on a series of micro-benchmarks and realistic Java programs. On the set of benchmarks, we show that FUCHSIA outperforms the state-of-the-art techniques in detecting side channel classes. On the realistic programs, we show the scalability of FUCHSIA in analyzing functional side channels in Java programs with thousands of methods. Also, we show the usefulness of FUCHSIA in finding side channels including a zero-day vulnerability in OpenJDK and another vulnerability in Jetty that was since fixed by the developers.",
            "keywords": [
                "Functional Side Channels",
                "Information Leakage",
                "Noninterference",
                "Debugging Techniques",
                "FUCHSIA Tool"
            ]
        },
        "url": "URL#2305546",
        "sema_paperId": "b8be13f9a6db03bd1116a8ad01a5a72784a335fe"
    },
    {
        "@score": "1",
        "@id": "2305547",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "117/6580",
                        "text": "Rahmadi Trimananda"
                    },
                    {
                        "@pid": "167/5871",
                        "text": "Janus Varmarken"
                    },
                    {
                        "@pid": "82/5866",
                        "text": "Athina Markopoulou"
                    },
                    {
                        "@pid": "47/3381",
                        "text": "Brian Demsky"
                    }
                ]
            },
            "title": "Packet-Level Signatures for Smart Home Devices.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/TrimanandaVMD20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/packet-level-signatures-for-smart-home-devices/",
            "url": "https://dblp.org/rec/conf/ndss/TrimanandaVMD20",
            "abstract": "\u2014Smart home devices are vulnerable to passive inference attacks based on network traf\ufb01c, even in the presence of encryption. In this paper, we present P ING P ONG , a tool that can automatically extract packet-level signatures for device events ( e.g., light bulb turning ON/OFF) from network traf\ufb01c. We evaluated P ING P ONG on popular smart home devices ranging from smart plugs and thermostats to cameras, voice-activated devices, and smart TVs. We were able to: (1) automatically extract previously unknown signatures that consist of simple sequences of packet lengths and directions; (2) use those signatures to detect the devices or speci\ufb01c events with an average recall of more than 97%; (3) show that the signatures are unique among hundreds of millions of packets of real world network traf\ufb01c; (4) show that our methodology is also applicable to publicly available datasets; and (5) demonstrate its robustness in different settings: events triggered by local and remote smartphones, as well as by home-automation systems.",
            "keywords": [
                "Smart Home Security",
                "Packet-Level Signatures",
                "Passive Inference Attacks",
                "Network Traffic Analysis",
                "Device Event Detection"
            ]
        },
        "url": "URL#2305547",
        "sema_paperId": "e676f55a190c11c1d5264722a9c39813641a3850"
    },
    {
        "@score": "1",
        "@id": "2305548",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "205/3765",
                        "text": "Benjamin E. Ujcich"
                    },
                    {
                        "@pid": "164/3347",
                        "text": "Samuel Jero"
                    },
                    {
                        "@pid": "137/3754",
                        "text": "Richard Skowyra"
                    },
                    {
                        "@pid": "48/8738",
                        "text": "Steven R. Gomez"
                    },
                    {
                        "@pid": "126/3601",
                        "text": "Adam Bates 0001"
                    },
                    {
                        "@pid": "s/WilliamHSanders",
                        "text": "William H. Sanders"
                    },
                    {
                        "@pid": "14/5114",
                        "text": "Hamed Okhravi"
                    }
                ]
            },
            "title": "Automated Discovery of Cross-Plane Event-Based Vulnerabilities in Software-Defined Networking.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/UjcichJSG0SO20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/automated-discovery-of-cross-plane-event-based-vulnerabilities-in-software-defined-networking/",
            "url": "https://dblp.org/rec/conf/ndss/UjcichJSG0SO20",
            "abstract": "\u2014Software-de\ufb01ned networking (SDN) achieves a programmable control plane through the use of logically centralized, event-driven controllers and through network applications (apps) that extend the controllers\u2019 functionality. As control plane decisions are often based on the data plane, it is possible for carefully crafted malicious data plane inputs to direct the control plane towards unwanted states that bypass network security restrictions ( i.e., cross-plane attacks ). Unfortunately, because of the complex interplay among controllers, apps, and data plane inputs, at present it is dif\ufb01cult to systematically identify and analyze these cross-plane vulnerabilities. We present E VENT S COPE , a vulnerability detection tool that automatically analyzes SDN control plane event usage, discovers candidate vulnerabilities based on missing event-handling routines, and validates vulnerabilities based on data plane effects. To accurately detect missing event handlers without ground truth or developer aid, we cluster apps according to similar event usage and mark inconsistencies as candidates. We create an event \ufb02ow graph to observe a global view of events and control \ufb02ows within the control plane and use it to validate vulnerabilities that affect the data plane. We applied E VENT S COPE to the ONOS SDN controller and uncovered 14 new vulnerabilities.",
            "keywords": [
                "Software-Defined Networking",
                "Control Plane",
                "Cross-Plane Vulnerabilities",
                "Event-Driven Controllers",
                "Vulnerability Detection Tool"
            ]
        },
        "url": "URL#2305548",
        "sema_paperId": "d4c74b7634ea7db1fabb17f1407357592cdb2969"
    },
    {
        "@score": "1",
        "@id": "2305549",
        "info": {
            "authors": {
                "author": {
                    "@pid": "12/5838-12",
                    "text": "Tao Wang 0012"
                }
            },
            "title": "Designing a Better Browser for Tor with BLAST.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/Wang20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/designing-a-better-browser-for-tor-with-blast/",
            "url": "https://dblp.org/rec/conf/ndss/Wang20",
            "abstract": "\u2014Tor is an anonymity network that allows clients to browse web pages privately, but loading web pages with Tor is slow. To analyze how the browser loads web pages, we examine their resource trees using our new browser logging and simulation tool, BLAST. We \ufb01nd that the time it takes to load a web page with Tor is almost entirely determined by the number of round trips incurred, not its bandwidth, and Tor Browser incurs unnecessary round trips. Resources sit in the browser queue excessively waiting for the TCP and TLS handshakes, each of which takes a separate round trip. We show that increasing resource loading capacity with larger pipelines and even HTTP/2 do not decrease load time because they do not save round trips. We set out to minimize round trips with a number of protocol and browser improvements, including TCP Fast Open, optimistic data and 0-RTT TLS. We also recommend the use of databases to assist the client with redirection, identifying HTTP/2 servers, and prefetching. All of these features are designed to cut down on the number of round trips incurred in loading web pages. To evaluate these proposed improvements, we create a simulation tool and validate that it is highly accurate in predicting mean page load times. We use the simulator to analyze these features and it predicts that they will decrease the mean page load time by 61% over HTTP/2. Our large improvement to user experience comes at trivial cost to the Tor network.",
            "keywords": [
                "Tor Network",
                "Web Page Loading",
                "Round Trips",
                "Browser Performance",
                "TCP Fast Open"
            ]
        },
        "url": "URL#2305549",
        "sema_paperId": "2a68e1b17bb4202ff3b8a675ca62eef46aaa929e"
    },
    {
        "@score": "1",
        "@id": "2305550",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "19/1924-17",
                        "text": "Qi Wang 0017"
                    },
                    {
                        "@pid": "184/8086",
                        "text": "Wajih Ul Hassan"
                    },
                    {
                        "@pid": "95/7132-1",
                        "text": "Ding Li 0001"
                    },
                    {
                        "@pid": "36/10085",
                        "text": "Kangkook Jee"
                    },
                    {
                        "@pid": "89/2407-7",
                        "text": "Xiao Yu 0007"
                    },
                    {
                        "@pid": "270/2472",
                        "text": "Kexuan Zou"
                    },
                    {
                        "@pid": "27/5932",
                        "text": "Junghwan Rhee"
                    },
                    {
                        "@pid": "14/3744",
                        "text": "Zhengzhang Chen"
                    },
                    {
                        "@pid": "89/2506-2",
                        "text": "Wei Cheng 0002"
                    },
                    {
                        "@pid": "g/CarlAGunter",
                        "text": "Carl A. Gunter"
                    },
                    {
                        "@pid": "08/57",
                        "text": "Haifeng Chen"
                    }
                ]
            },
            "title": "You Are What You Do: Hunting Stealthy Malware via Data Provenance Analysis.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/WangHLJYZRCCGC20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/you-are-what-you-do-hunting-stealthy-malware-via-data-provenance-analysis/",
            "url": "https://dblp.org/rec/conf/ndss/WangHLJYZRCCGC20",
            "abstract": "\u2014To subvert recent advances in perimeter and host security, the attacker community has developed and employed various attack vectors to make a malware much stealthier than before to penetrate the target system and prolong its presence. Such advanced malware or \u201cstealthy malware\u201d makes use of various techniques to impersonate or abuse benign applications and legitimate system tools to minimize its footprints in the target system. It is thus dif\ufb01cult for traditional detection tools, such as malware scanners, to detect it, as the malware normally does not expose its malicious payload in a \ufb01le and hides its malicious behaviors among the benign behaviors of the processes. In this paper, we present P ROV D ETECTOR , a provenance-based approach for detecting stealthy malware. Our insight behind the P ROV D ETECTOR approach is that although a stealthy malware attempts to blend into benign processes, its malicious behaviors inevitably interact with the underlying operating system (OS), which will be exposed to and captured by provenance monitoring. Based on this intuition, P ROV D ETECTOR \ufb01rst employs a novel selection algorithm to identify possibly malicious parts in the OS-level provenance data of a process. It then applies a neural embedding and machine learning pipeline to automatically detect any behavior that deviates signi\ufb01cantly from normal behaviors. We evaluate our approach on a large provenance dataset from an enterprise network and demonstrate that it achieves very high detection performance of stealthy malware (an average F1 score of 0.974). Further, we conduct thorough interpretability studies to understand the internals of the learned machine learning models",
            "keywords": [
                "Stealthy Malware Detection",
                "Data Provenance Analysis",
                "Malicious Behavior Identification",
                "Operating System Interaction",
                "Machine Learning for Malware Detection"
            ]
        },
        "url": "URL#2305550",
        "sema_paperId": "1b12fbe7d9f7cd251a40e099e66e65f635b873ff"
    },
    {
        "@score": "1",
        "@id": "2305551",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "123/2365",
                        "text": "Yanhao Wang"
                    },
                    {
                        "@pid": "205/2209",
                        "text": "Xiangkun Jia"
                    },
                    {
                        "@pid": "158/7566",
                        "text": "Yuwei Liu"
                    },
                    {
                        "@pid": "270/2413",
                        "text": "Kyle Zeng"
                    },
                    {
                        "@pid": "150/5198",
                        "text": "Tiffany Bao"
                    },
                    {
                        "@pid": "54/2696",
                        "text": "Dinghao Wu"
                    },
                    {
                        "@pid": "46/3714",
                        "text": "Purui Su"
                    }
                ]
            },
            "title": "Not All Coverage Measurements Are Equal: Fuzzing by Coverage Accounting for Input Prioritization.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/WangJLZBWS20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/not-all-coverage-measurements-are-equal-fuzzing-by-coverage-accounting-for-input-prioritization/",
            "url": "https://dblp.org/rec/conf/ndss/WangJLZBWS20",
            "abstract": "\u2014Coverage-based fuzzing has been actively studied and widely adopted for \ufb01nding vulnerabilities in real-world software applications. With coverage information, such as statement coverage and transition coverage, as the guidance of input mutation, coverage-based fuzzing can generate inputs that cover more code and thus \ufb01nd more vulnerabilities without prerequisite information such as input format. Current coverage-based fuzzing tools treat covered code equally. All inputs that contribute to new statements or transitions are kept for future mutation no matter what the statements or transitions are and how much they impact security. Although this design is reasonable from the perspective of software testing that aims at full code coverage, it is inef\ufb01cient for vulnerability discovery since that 1) current techniques are still inadequate to reach full coverage within a reasonable amount of time, and that 2) we always want to discover vulnerabilities early so that it can be \ufb01xed promptly. Even worse, due to the non-discriminative code coverage treatment, current fuzzing tools suffer from recent anti-fuzzing techniques and become much less effective in \ufb01nding vulnerabilities from programs enabled with anti-fuzzing schemes. To address the limitation caused by equal coverage, we propose coverage accounting , a novel approach that evaluates coverage by security impacts. Coverage accounting attributes edges by three metrics based on three different levels: function, loop and basic block. Based on the proposed metrics, we",
            "keywords": [
                "Coverage-based Fuzzing",
                "Vulnerability Discovery",
                "Coverage Accounting",
                "Anti-fuzzing Techniques",
                "Input Prioritization"
            ]
        },
        "url": "URL#2305551",
        "sema_paperId": "13b99f35ebbe21e1d721b41c28e99c680e0998b6"
    },
    {
        "@score": "1",
        "@id": "2305552",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "95/4442-88",
                        "text": "Peng Wang 0088"
                    },
                    {
                        "@pid": "129/1113",
                        "text": "Xiaojing Liao"
                    },
                    {
                        "@pid": "142/1169",
                        "text": "Yue Qin"
                    },
                    {
                        "@pid": "06/6268",
                        "text": "XiaoFeng Wang 0001"
                    }
                ]
            },
            "title": "Into the Deep Web: Understanding E-commerce Fraud from Autonomous Chat with Cybercriminals.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/WangLQ020",
            "ee": "https://www.ndss-symposium.org/ndss-paper/into-the-deep-web-understanding-e-commerce-fraud-from-autonomous-chat-with-cybercriminals/",
            "url": "https://dblp.org/rec/conf/ndss/WangLQ020",
            "abstract": "\u2014E-commerce miscreants heavily rely on instant messaging (IM) to promote their illicit businesses and coordinate their operations. The threat intelligence provided by IM communication, therefore, becomes invaluable for understanding and mitigating the threats of e-commerce frauds. However, such information is hard to obtain since it is usually shared only through one-on-one conversations with the criminals. In this paper, we present the \ufb01rst chatbot, called Aubrey , to actively collect such intelligence through autonomous chats with real-world e-commerce miscreants. Our approach leverages the question-driven conversation pattern of small-time workers, who seek jobs and/or attack resources from e-commerce fraudsters, to model the interaction process as a \ufb01nite state machine, thereby enabling an autonomous conversation. Aubrey successfully chatted with 470 real-world e-commerce miscreants and gathered a large amount of fraud-related artifacts, including previously-unknown SIM gateways, account trading websites, and attack toolkits, etc. Further, the conversations revealed the supply chain of e-commerce fraudulent activities on the deep web and the complicated relations (e.g., complicity and reselling) among miscreants.",
            "keywords": [
                "E-commerce Fraud",
                "Cybercrime",
                "Instant Messaging",
                "Threat Intelligence",
                "Autonomous Chatbot"
            ]
        },
        "url": "URL#2305552",
        "sema_paperId": "b9a69b880894b438970e9b0481b7dcc5b1bde55b"
    },
    {
        "@score": "1",
        "@id": "2305553",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "215/0123",
                        "text": "Haohuang Wen"
                    },
                    {
                        "@pid": "156/1033",
                        "text": "Qingchuan Zhao"
                    },
                    {
                        "@pid": "150/3272",
                        "text": "Qi Alfred Chen"
                    },
                    {
                        "@pid": "49/4102-1",
                        "text": "Zhiqiang Lin 0001"
                    }
                ]
            },
            "title": "Automated Cross-Platform Reverse Engineering of CAN Bus Commands From Mobile Apps.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/WenZCL20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/automated-cross-platform-reverse-engineering-of-can-bus-commands-from-mobile-apps/",
            "url": "https://dblp.org/rec/conf/ndss/WenZCL20",
            "abstract": "In modern automobiles, CAN bus commands are necessary for a wide range of applications such as diagnosis, security monitoring, and recently autonomous driving. However, only a small portion of CAN bus commands is standardized, and a vast majority of them is developed privately by car manufacturers. Today, the most effective way of revealing the proprietary CAN bus commands is to reverse engineer with real cars, which unfortunately is time-consuming and costly. In this paper, we propose a cost-effective (no real car needed) and automatic (no human intervention required) system, CANHUNTER, for reverse engineering of CAN bus commands using just car companion mobile apps. To achieve high effectiveness, we design an efficient technique to uncover the syntactics of CAN bus commands with backward slicing and dynamic forced execution, and a novel algorithm to uncover the semantics of CAN bus commands by leveraging code-level semantic clues. We have implemented a prototype of CANHUNTER for both Android and iOS platforms, and tested it with all free car companion apps (236 in total) from both Google Play and Apple App Store. Among these apps, CANHUNTER discovered 182, 619 unique CAN bus commands with 86.1% of them revealed with semantics, covering 360 car models from 21 car manufactures. We have also evaluated their correctness (both syntactics and semantics) using public resources, cross-platform and cross-app validation, and also realcar testing, with which over 70% of all the uncovered commands are validated. We observe no inconsistency in cross-platform and cross-app validation. While there are 3 semantic inconsistency among 241 manually validated CAN bus commands from public resources and real-car testing, we find that these three cases are actually caused by mistakes from app developers.",
            "keywords": [
                "CAN Bus Commands",
                "Reverse Engineering",
                "Mobile Apps",
                "Automotive Systems",
                "Semantic Analysis"
            ]
        },
        "url": "URL#2305553",
        "sema_paperId": "10b7f8d9292925d8849a1b3d2f8a8efc87dd3dce"
    },
    {
        "@score": "1",
        "@id": "2305554",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "248/1662",
                        "text": "Qiushi Wu"
                    },
                    {
                        "@pid": "06/1998",
                        "text": "Yang He"
                    },
                    {
                        "@pid": "29/4899",
                        "text": "Stephen McCamant"
                    },
                    {
                        "@pid": "67/10639",
                        "text": "Kangjie Lu"
                    }
                ]
            },
            "title": "Precisely Characterizing Security Impact in a Flood of Patches via Symbolic Rule Comparison.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/WuHML20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/precisely-characterizing-security-impact-in-a-flood-of-patches-via-symbolic-rule-comparison/",
            "url": "https://dblp.org/rec/conf/ndss/WuHML20",
            "abstract": "A bug is a vulnerability if it has security impacts when triggered. Determining the security impacts of a bug is important to both defenders and attackers. Maintainers of large software systems are bombarded with numerous bug reports and proposed patches, with missing or unreliable information about their impact. Determining which few bugs are vulnerabilities is difficult, and bugs that a maintainer believes do not have security impact will be de-prioritized or even ignored. On the other hand, a public report of a bug with a security impact is a powerful first step towards exploitation. Adversaries may exploit such bugs to launch devastating attacks if defenders do not fix them promptly. Common practice is for maintainers to assess the security impacts of bugs manually, but the scaling and reliability challenges of manual analysis lead to missed vulnerabilities. We propose an automated approach, SID, to determine the security impacts for a bug given its patch, so that maintainers can effectively prioritize applying the patch to the affected programs. The insight behind SID is that both the effect of a patch (either submitted or applied) and security-rule violations (e.g., out-of-bound access) can be modeled as constraints that can be automatically solved. SID incorporates rule comparison, using under-constrained symbolic execution of a patch to determine the security impacts of an un-applied patch. SID can further automatically classify vulnerabilities based on their security impacts. We have implemented SID and applied it to bug patches of the Linux kernel and matching CVE-assigned vulnerabilities to evaluate its precision and recall. We optimized SID to reduce false positives, and our evaluation shows that, from 54K recent valid commit patches, SID detected 227 security bugs with at least 243 security impacts at a 97% precision rate. Critically, 197 of them were not reported as vulnerabilities before, leading to delayed or ignored patching in derivative programs. Even worse, 21 of them are still unpatched in the latest Android kernel. Once exploited, they can cause critical security impacts on Android devices. The evaluation results confirm that SID\u2019s approach is effective and precise in automatically determining security impacts for a massive stream of bug patches.",
            "keywords": [
                "Automated Vulnerability Detection",
                "Security Impact Analysis",
                "Symbolic Execution",
                "Patch Evaluation",
                "Linux Kernel Vulnerabilities"
            ]
        },
        "url": "URL#2305554",
        "sema_paperId": "27c9166785a33906f9da707bb2d2b837b579852d"
    },
    {
        "@score": "1",
        "@id": "2305555",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "152/3962-1",
                        "text": "Yuan Xiao 0001"
                    },
                    {
                        "@pid": "77/3503",
                        "text": "Yinqian Zhang"
                    },
                    {
                        "@pid": "04/3074",
                        "text": "Radu Teodorescu"
                    }
                ]
            },
            "title": "SPEECHMINER: A Framework for Investigating and Measuring Speculative Execution Vulnerabilities.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/XiaoZT20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/speechminer-a-framework-for-investigating-and-measuring-speculative-execution-vulnerabilities/",
            "url": "https://dblp.org/rec/conf/ndss/XiaoZT20",
            "abstract": "SPEculative Execution side Channel Hardware (SPEECH) Vulnerabilities have enabled the notorious Meltdown, Spectre, and L1 terminal fault (L1TF) attacks. While a number of studies have reported different variants of SPEECH vulnerabilities, they are still not well understood. This is primarily due to the lack of information about microprocessor implementation details that impact the timing and order of various micro-architectural events. Moreover, to date, there is no systematic approach to quantitatively measure SPEECH vulnerabilities on commodity processors.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2020/02/23105-paper.pdf",
            "keywords": [
                "Speculative Execution",
                "SPEECH Vulnerabilities",
                "Microprocessor Implementation",
                "Timing Attacks",
                "Quantitative Measurement"
            ]
        },
        "url": "URL#2305555"
    },
    {
        "@score": "1",
        "@id": "2305556",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "86/10809",
                        "text": "Qiben Yan"
                    },
                    {
                        "@pid": "270/2291",
                        "text": "Kehai Liu"
                    },
                    {
                        "@pid": "80/7814",
                        "text": "Qin Zhou"
                    },
                    {
                        "@pid": "206/6471",
                        "text": "Hanqing Guo"
                    },
                    {
                        "@pid": "181/2597-17",
                        "text": "Ning Zhang 0017"
                    }
                ]
            },
            "title": "SurfingAttack: Interactive Hidden Attack on Voice Assistants Using Ultrasonic Guided Waves.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/YanLZGZ20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/surfingattack-interactive-hidden-attack-on-voice-assistants-using-ultrasonic-guided-waves/",
            "url": "https://dblp.org/rec/conf/ndss/YanLZGZ20",
            "abstract": "\u2014With recent advances in arti\ufb01cial intelligence and natural language processing, voice has become a primary method for human-computer interaction. It has enabled game-changing new technologies in both commercial sectors and military sectors, such as Siri, Alexa, Google Assistant, and voice-controlled naval warships. Recently, researchers have demonstrated that these voice assistant systems are susceptible to signal injection at the inaudible frequencies. To date, most of the existing works focus primarily on delivering a single command via line-of-sight ultrasound speaker or extending the range of this attack via speaker array. However, besides air, sound waves also propagate through other materials where vibration is possible. In this work, we aim to understand the characteristics of this new genre of attack in the context of different transmission media. Furthermore, by leveraging the unique properties of acoustic transmission in solid materials, we design a new attack called Sur\ufb01ngAttack that would enable multiple rounds of interactions between the voice-controlled device and the attacker over a longer distance and without the need to be in line-of-sight. By completing the interaction loop of inaudible sound attack, Sur\ufb01ngAttack enables new attack scenarios, such as hijacking a mobile Short Message Service (SMS) passcode, making ghost fraud calls without owners\u2019 knowledge, etc. To accomplish Sur\ufb01ngAttack , we have solved several major challenges. First, the signal has been specially designed to allow omni-directional transmission for performing effective attacks over a solid medium. Second, the new attack enables multi-round interaction without alerting the legitimate user at the scene, which is challenging since the device is designed to interact with users in physical proximity rather than sensors. To mitigate this newly discovered threat,",
            "keywords": [
                "Voice Assistants",
                "Ultrasonic Waves",
                "Signal Injection",
                "Interactive Attacks",
                "Sur\ufb01ngAttack"
            ]
        },
        "url": "URL#2305556",
        "sema_paperId": "7a688c1968c4475a330b5704cf27c29dc0e796d4"
    },
    {
        "@score": "1",
        "@id": "2305557",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "03/7065",
                        "text": "Runqing Yang"
                    },
                    {
                        "@pid": "172/8745",
                        "text": "Shiqing Ma"
                    },
                    {
                        "@pid": "41/10114-2",
                        "text": "Haitao Xu 0002"
                    },
                    {
                        "@pid": "95/3760-1",
                        "text": "Xiangyu Zhang 0001"
                    },
                    {
                        "@pid": "88/2827-4",
                        "text": "Yan Chen 0004"
                    }
                ]
            },
            "title": "UIScope: Accurate, Instrumentation-free, and Visible Attack Investigation for GUI Applications.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/YangMXZ020",
            "ee": "https://www.ndss-symposium.org/ndss-paper/uiscope-accurate-instrumentation-free-and-visible-attack-investigation-for-gui-applications/",
            "url": "https://dblp.org/rec/conf/ndss/YangMXZ020",
            "abstract": "Existing attack investigation solutions for GUI applications suffer from a few limitations such as inaccuracy (because of the dependence explosion problem), requiring instrumentation, and providing very low visibility. Such limitations have hindered their widespread and practical deployment. In this paper, we present UIScope, a novel accurate, instrumentation-free, and visible attack investigation system for GUI applications. The core idea of UIScope is to perform causality analysis on both UI elements/events which represent users' perspective and low-level system events which provide detailed information of what happens under the hood, and then correlate system events with UI events to provide high accuracy and visibility. Long running processes are partitioned to individual UI transitions, to which low-level system events are attributed, making the results accurate. The produced graphs contain (causally related) UI elements with which users are very familiar, making them easily accessible. We deployed UIScope on 7 machines for a week, and also utilized UIScope to conduct an investigation of 6 real-world attacks. Our evaluation shows that compared to existing works, UIScope introduces negligible overhead (less than 1% runtime overhead and 3.05 MB event logs per hour on average) while UIScope can precisely identify attack provenance while offering users thorough visibility into the attack context.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2020/02/24329-paper.pdf",
            "keywords": [
                "GUI Application Security",
                "Attack Investigation",
                "Causality Analysis",
                "Instrumentation-free",
                "Attack Provenance"
            ]
        },
        "url": "URL#2305557"
    },
    {
        "@score": "1",
        "@id": "2305558",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "127/8463",
                        "text": "Honggang Yu"
                    },
                    {
                        "@pid": "157/9274",
                        "text": "Kaichen Yang"
                    },
                    {
                        "@pid": "38/5156-2",
                        "text": "Teng Zhang 0002"
                    },
                    {
                        "@pid": "241/1190",
                        "text": "Yun-Yun Tsai"
                    },
                    {
                        "@pid": "63/4181",
                        "text": "Tsung-Yi Ho"
                    },
                    {
                        "@pid": "34/756",
                        "text": "Yier Jin"
                    }
                ]
            },
            "title": "CloudLeak: Large-Scale Deep Learning Models Stealing Through Adversarial Examples.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/YuYZTHJ20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/cloudleak-large-scale-deep-learning-models-stealing-through-adversarial-examples/",
            "url": "https://dblp.org/rec/conf/ndss/YuYZTHJ20",
            "abstract": "Cloud-based Machine Learning as a Service (MLaaS) is gradually gaining acceptance as a reliable solution to various real-life scenarios. These services typically utilize Deep Neural Networks (DNNs) to perform classification and detection tasks and are accessed through Application Programming Interfaces (APIs). Unfortunately, it is possible for an adversary to steal models from cloud-based platforms, even with black-box constraints, by repeatedly querying the public prediction API with malicious inputs. In this paper, we introduce an effective and efficient black-box attack methodology that extracts largescale DNN models from cloud-based platforms with near-perfect performance. In comparison to existing attack methods, we significantly reduce the number of queries required to steal the target model by incorporating several novel algorithms, including active learning, transfer learning, and adversarial attacks. During our experimental evaluations, we validate our proposed model for conducting theft attacks on various commercialized MLaaS platforms hosted by Microsoft, Face++, IBM, Google and Clarifai. Our results demonstrate that the proposed method can easily reveal/steal large-scale DNN models from these cloud platforms. The proposed attack method can also be used to accurately evaluates the robustness of DNN based MLaaS classifiers against theft attacks.",
            "keywords": [
                "Model Theft",
                "Black-Box Attack",
                "Cloud-Based MLaaS",
                "Adversarial Examples",
                "DNN Model Extraction"
            ]
        },
        "url": "URL#2305558",
        "sema_paperId": "4d548fd21aad60e3052455e22b7a57cc1f06e3c3"
    },
    {
        "@score": "1",
        "@id": "2305559",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "188/5710-1",
                        "text": "Menghao Zhang 0001"
                    },
                    {
                        "@pid": "93/7765",
                        "text": "Guanyu Li"
                    },
                    {
                        "@pid": "65/7762",
                        "text": "Shicheng Wang"
                    },
                    {
                        "@pid": "52/5716-21",
                        "text": "Chang Liu 0021"
                    },
                    {
                        "@pid": "59/146-1",
                        "text": "Ang Chen 0001"
                    },
                    {
                        "@pid": "02/2870",
                        "text": "Hongxin Hu"
                    },
                    {
                        "@pid": "64/1147",
                        "text": "Guofei Gu"
                    },
                    {
                        "@pid": "181/2688-2",
                        "text": "Qi Li 0002"
                    },
                    {
                        "@pid": "18/6055",
                        "text": "Mingwei Xu"
                    },
                    {
                        "@pid": "82/4905",
                        "text": "Jianping Wu"
                    }
                ]
            },
            "title": "Poseidon: Mitigating Volumetric DDoS Attacks with Programmable Switches.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ZhangLWLCHG0XW20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/poseidon-mitigating-volumetric-ddos-attacks-with-programmable-switches/",
            "url": "https://dblp.org/rec/conf/ndss/ZhangLWLCHG0XW20",
            "abstract": "\u2014Distributed Denial-of-Service (DDoS) attacks have become a critical threat to the Internet. Due to the increasing number of vulnerable Internet of Things (IoT) devices, attackers can easily compromise a large set of nodes and launch high-volume DDoS attacks from the botnets. State-of-the-art DDoS defenses, however, have not caught up with the fast develop-ment of the attacks. Middlebox-based defenses can achieve high performance with specialized hardware; however, these defenses incur a high cost, and deploying new defenses typically requires a device upgrade. On the other hand, software-based defenses are highly \ufb02exible, but software-based packet processing leads to high performance overheads. In this paper, we propose P OSEIDON , a system that addresses these limitations in today\u2019s DDoS defenses. It leverages emerging programmable switches, which can be recon\ufb01gured in the \ufb01eld without additional hardware upgrade. Users of P OSEIDON can specify their defense strategies in a modular fashion in the form of a set of defense primitives; this can be further customized easily for each network and extended to include new defenses. P OSEIDON then maps the defense primitives to run on programmable switches\u2014and when necessary, on server software\u2014for effective defense. When attacks change, P OSEIDON can recon\ufb01gure the underlying defense primitives to respond to the new attack patterns. Evaluations using our prototype demonstrate that P OSEIDON can effectively defend against high-volume attacks, easily support customization of defense strategies, and adapt to dynamic attacks with low",
            "keywords": [
                "DDoS Mitigation",
                "Programmable Switches",
                "Defense Strategies",
                "Volumetric Attacks",
                "Dynamic Attack Adaptation"
            ]
        },
        "url": "URL#2305559",
        "sema_paperId": "e6e836c6bc5258e1e7787cf9ead8dd80e5ebb724"
    },
    {
        "@score": "1",
        "@id": "2305560",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "43/4074",
                        "text": "Zhenfeng Zhang"
                    },
                    {
                        "@pid": "82/8599",
                        "text": "Yuchen Wang"
                    },
                    {
                        "@pid": "86/8501-2",
                        "text": "Kang Yang 0002"
                    }
                ]
            },
            "title": "Strong Authentication without Temper-Resistant Hardware and Application to Federated Identities.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ZhangWY20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/strong-authentication-without-temper-resistant-hardware-and-application-to-federated-identities/",
            "url": "https://dblp.org/rec/conf/ndss/ZhangWY20",
            "abstract": "Shared credential is currently the most widespread form of end user authentication with its convenience, but it is also criticized for being vulnerable to credential database theft and phishing attacks. While several alternative mechanisms are proposed to offer strong authentication with cryptographic challenge-response protocols, they are cumbersome to use due to the need of tamper-resistant hardware modules at user end.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2020/02/24462-paper.pdf",
            "keywords": [
                "Strong Authentication",
                "Federated Identities",
                "Credential Theft",
                "Phishing Attacks",
                "Cryptographic Challenge-Response"
            ]
        },
        "url": "URL#2305560"
    },
    {
        "@score": "1",
        "@id": "2305561",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "188/6037",
                        "text": "Benjamin Zi Hao Zhao"
                    },
                    {
                        "@pid": "70/7706",
                        "text": "Hassan Jameel Asghar"
                    },
                    {
                        "@pid": "71/5612",
                        "text": "Mohamed Ali K\u00e2afar"
                    }
                ]
            },
            "title": "On the Resilience of Biometric Authentication Systems against Random Inputs.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ZhaoAK20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/on-the-resilience-of-biometric-authentication-systems-against-random-inputs/",
            "url": "https://dblp.org/rec/conf/ndss/ZhaoAK20",
            "abstract": "We assess the security of machine learning based biometric authentication systems against an attacker who submits uniform random inputs, either as feature vectors or raw inputs, in order to find an accepting sample of a target user. The average false positive rate (FPR) of the system, i.e., the rate at which an impostor is incorrectly accepted as the legitimate user, may be interpreted as a measure of the success probability of such an attack. However, we show that the success rate is often higher than the FPR. In particular, for one reconstructed biometric system with an average FPR of 0.03, the success rate was as high as 0.78. This has implications for the security of the system, as an attacker with only the knowledge of the length of the feature space can impersonate the user with less than 2 attempts on average. We provide detailed analysis of why the attack is successful, and validate our results using four different biometric modalities and four different machine learning classifiers. Finally, we propose mitigation techniques that render such attacks ineffective, with little to no effect on the accuracy of the system.",
            "keywords": [
                "Biometric Authentication",
                "Impersonation Attack",
                "False Positive Rate",
                "Random Input Attack",
                "Mitigation Techniques"
            ]
        },
        "url": "URL#2305561",
        "sema_paperId": "d295b043e2b24981a6304fcc627611f2acfc0cf8"
    },
    {
        "@score": "1",
        "@id": "2305562",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "141/9370",
                        "text": "Yanzi Zhu"
                    },
                    {
                        "@pid": "176/5291",
                        "text": "Zhujun Xiao"
                    },
                    {
                        "@pid": "11/5123-1",
                        "text": "Yuxin Chen 0001"
                    },
                    {
                        "@pid": "149/3951-1",
                        "text": "Zhijing Li 0001"
                    },
                    {
                        "@pid": "228/8469",
                        "text": "Max Liu"
                    },
                    {
                        "@pid": "z/BenYZhao",
                        "text": "Ben Y. Zhao"
                    },
                    {
                        "@pid": "43/4261",
                        "text": "Heather Zheng"
                    }
                ]
            },
            "title": "Et Tu Alexa? When Commodity WiFi Devices Turn into Adversarial Motion Sensors.",
            "venue": "NDSS",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ZhuXCLLZZ20",
            "ee": "https://www.ndss-symposium.org/ndss-paper/et-tu-alexa-when-commodity-wifi-devices-turn-into-adversarial-motion-sensors/",
            "url": "https://dblp.org/rec/conf/ndss/ZhuXCLLZZ20",
            "abstract": "Our work demonstrates a new set of silent reconnaissance attacks, which leverages the presence of commodity WiFi devices to track users inside private homes and offices, without compromising any WiFi network, data packets, or devices. We show that just by sniffing existing WiFi signals, an adversary can accurately detect and track movements of users inside a building. This is made possible by our new signal model that links together human motion near WiFi transmitters and variance of multipath signal propagation seen by the attacker sniffer outside of the property. The resulting attacks are cheap, highly effective, and yet difficult to detect. We implement the attack using a single commodity smartphone, deploy it in 11 real-world offices and residential apartments, and show it is highly effective. Finally, we evaluate potential defenses, and propose a practical and effective defense based on AP signal obfuscation.",
            "keywords": [
                "WiFi Signal Tracking",
                "Adversarial Motion Sensing",
                "Silent Reconnaissance Attacks",
                "Signal Propagation Variance",
                "AP Signal Obfuscation"
            ]
        },
        "url": "URL#2305562",
        "sema_paperId": "44609b244fe0360ea5bbfc8213acdc92c9514695"
    },
    {
        "@score": "1",
        "@id": "2344730",
        "info": {
            "title": "27th Annual Network and Distributed System Security Symposium, NDSS 2020, San Diego, California, USA, February 23-26, 2020",
            "venue": "NDSS",
            "publisher": "The Internet Society",
            "year": "2020",
            "type": "Editorship",
            "access": "open",
            "key": "conf/ndss/2020",
            "ee": "https://www.ndss-symposium.org/ndss2020/",
            "url": "https://dblp.org/rec/conf/ndss/2020",
            "abstract": null
        },
        "url": "URL#2344730",
        "sema_paperId": "66dfb949772f567fb5edff7f73599e9a61237297"
    }
]