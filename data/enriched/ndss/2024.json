[
    {
        "@score": "1",
        "@id": "358341",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "25/1825-1",
                        "text": "Hui Xia 0001"
                    },
                    {
                        "@pid": "60/2536-50",
                        "text": "Rui Zhang 0050"
                    },
                    {
                        "@pid": "322/8426",
                        "text": "Zi Kang"
                    },
                    {
                        "@pid": "322/8917",
                        "text": "Shuliang Jiang"
                    },
                    {
                        "@pid": "90/2170",
                        "text": "Shuo Xu"
                    }
                ]
            },
            "title": "Enhance Stealthiness and Transferability of Adversarial Attacks with Class Activation Mapping Ensemble Attack.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/00010KJX24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/enhance-stealthiness-and-transferability-of-adversarial-attacks-with-class-activation-mapping-ensemble-attack/",
            "url": "https://dblp.org/rec/conf/ndss/00010KJX24",
            "abstract": "\u2014Although there has been extensive research on the transferability of adversarial attacks, existing methods for generating adversarial examples suffer from two signi\ufb01cant drawbacks: poor stealthiness and low attack ef\ufb01cacy under low-round attacks. To address the above issues, we creatively propose an adversarial example generation method that ensembles the class activation maps of multiple models, called class activation mapping ensemble attack. We \ufb01rst use the class activation mapping method to discover the relationship between the decision of the Deep Neural Network and the image region. Then we calculate the class activation score for each pixel and use it as the weight for perturbation to enhance the stealthiness of adversarial examples and improve attack performance under low attack rounds. In the optimization process, we also ensemble class activation maps of multiple models to ensure the transferability of the adversarial attack algorithm. Experimental results show that our method generates adversarial examples with high perceptibility, transferability, attack performance under low-round attacks, and evasiveness. Speci\ufb01cally, when our attack capability is comparable to the most potent attack (VMIFGSM), our perceptibility is close to the best-performing attack (TPGD). For non-targeted attacks, our method outperforms the VMIFGSM by an average of 11.69% in attack capability against 13 target models and outperforms the TPGD by an average of 37.15%. For targeted attacks, our method achieves the fastest convergence, the most potent attack ef\ufb01cacy, and signi\ufb01cantly outperforms the eight baseline methods in low-round",
            "keywords": [
                "Adversarial Attacks",
                "Class Activation Mapping",
                "Transferability",
                "Stealthiness",
                "Low-Round Attack Performance"
            ]
        },
        "url": "URL#358341",
        "sema_paperId": "1ad545fc1d400c525cd1d8338e98061675f65063"
    },
    {
        "@score": "1",
        "@id": "358342",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "168/6451-1",
                        "text": "Jiafan Wang 0001"
                    },
                    {
                        "@pid": "c/ShermanSMChow",
                        "text": "Sherman S. M. Chow"
                    }
                ]
            },
            "title": "Unus pro omnibus: Multi-Client Searchable Encryption via Access Control.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/0001C24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/unus-pro-omnibus-multi-client-searchable-encryption-via-access-control/",
            "url": "https://dblp.org/rec/conf/ndss/0001C24",
            "abstract": "\u2014Searchable encryption lets an untrusted cloud server store keyword-document tuples encrypted by writers and conduct keyword searches with tokens from readers . Multi-writer schemes naturally offer broad applicability; however, it is unclear how to achieve the distinctive features of single-writer systems, namely, optimal search traversing only the result set and forward privacy invalidating old search tokens against any new data. Cutting-edge results by Wang and Chow (Usenix Security 2022) incur extra traversal over existing keywords and weaken forward privacy that only invalidates previous-issued search tokens periodically. We propose delegatable searchable encryption (DSE) with optimal search time for the multi-writer multi-reader setting. Beyond forward privacy, DSE supports security measures countering new integrity threats by malicious clients and keyword-guessing attacks inherent to public-key schemes. These are simultaneously made conceivable via one-time delegations of updating and/or searching power from the data owner and our tailored notion of shiftable multi-recipient counter encryption. DSE also benefits from the hybrid searchable encryption idea of Wang and Chow but at a microscopic level. Our evaluation confirms the order-of-magnitude improvement in search time over real-world datasets.",
            "keywords": [
                "Searchable Encryption",
                "Multi-Client Systems",
                "Forward Privacy",
                "Integrity Threats",
                "Keyword-Guessing Attacks"
            ]
        },
        "url": "URL#358342",
        "sema_paperId": "341993584fb666eaa90cf3fd8ec6cfcd8ba7bef4"
    },
    {
        "@score": "1",
        "@id": "358343",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "l/PascalLafourcade",
                        "text": "Pascal Lafourcade 0001"
                    },
                    {
                        "@pid": "379/0166",
                        "text": "Dhekra Mahmoud"
                    },
                    {
                        "@pid": "130/9389",
                        "text": "Sylvain Ruhault"
                    }
                ]
            },
            "title": "A Unified Symbolic Analysis of WireGuard.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/0001MR24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/a-unified-symbolic-analysis-of-wireguard/",
            "url": "https://dblp.org/rec/conf/ndss/0001MR24",
            "abstract": "\u2014WireGuard [22], [21] is a Virtual Private Network (VPN), presented at NDSS 2017, recently integrated into the Linux Kernel [57] and paid commercial VPNs such as NordVPN, Mullvad and ProtonVPN [56]. It proposes a different approach from other classical VPN such as IPsec [29] or OpenVPN [48] because it does not let users configure cryptographic algorithms. The protocol inside WireGuard is a dedicated extension of IKpsk2 protocol from Noise Framework [49]. Different analyses of WireGuard and IKpsk2 protocols have been proposed, in both the symbolic and the computational model, with or without computer-aided proof assistants. These analyses however consider different adversarial models or refer to incomplete versions of the protocols. In this work, we propose a unified formal model of WireGuard protocol in the symbolic model. Our model uses the automatic cryptographic protocol verifiers S APIC + , P RO V ERIF and T AMARIN . We consider a complete protocol execution, including cookie messages used for resistance against denial of service attacks. We model a precise adversary that can read or set static, ephemeral or pre-shared keys, read or set ecdh pre-computations, control key distribution. Eventually, we present our results in a unified and interpretable way, allowing comparisons with previous analyses. Finally thanks to our models, we give necessary and sufficient conditions for security properties to be compromised, we confirm a flaw on the anonymity of the communications and point an implementation choice which considerably weakens its security. We propose a remediation that we prove secure using our models.",
            "keywords": [
                "WireGuard",
                "VPN Protocols",
                "Symbolic Analysis",
                "Cryptographic Security",
                "Anonymity Flaw"
            ]
        },
        "url": "URL#358343",
        "sema_paperId": "f55e19ea75f72cebb7e7b671eb2a01f6625bfe8f"
    },
    {
        "@score": "1",
        "@id": "358344",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "205/5551-1",
                        "text": "Zitao Chen 0001"
                    },
                    {
                        "@pid": "91/5344",
                        "text": "Karthik Pattabiraman"
                    }
                ]
            },
            "title": "Overconfidence is a Dangerous Thing: Mitigating Membership Inference Attacks by Enforcing Less Confident Prediction.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/0001P24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/overconfidence-is-a-dangerous-thing-mitigating-membership-inference-attacks-by-enforcing-less-confident-prediction/",
            "url": "https://dblp.org/rec/conf/ndss/0001P24",
            "abstract": "Machine learning (ML) models are vulnerable to membership inference attacks (MIAs), which determine whether a given input is used for training the target model. While there have been many efforts to mitigate MIAs, they often suffer from limited privacy protection, large accuracy drop, and/or requiring additional data that may be difficult to acquire. This work proposes a defense technique, HAMP that can achieve both strong membership privacy and high accuracy, without requiring extra data. To mitigate MIAs in different forms, we observe that they can be unified as they all exploit the ML model's overconfidence in predicting training samples through different proxies. This motivates our design to enforce less confident prediction by the model, hence forcing the model to behave similarly on the training and testing samples. HAMP consists of a novel training framework with high-entropy soft labels and an entropy-based regularizer to constrain the model's prediction while still achieving high accuracy. To further reduce privacy risk, HAMP uniformly modifies all the prediction outputs to become low-confidence outputs while preserving the accuracy, which effectively obscures the differences between the prediction on members and non-members. We conduct extensive evaluation on five benchmark datasets, and show that HAMP provides consistently high accuracy and strong membership privacy. Our comparison with seven state-of-the-art defenses shows that HAMP achieves a superior privacy-utility trade off than those techniques.",
            "keywords": [
                "Membership Inference Attacks",
                "Privacy Preservation",
                "Overconfidence Mitigation",
                "High-Entropy Soft Labels",
                "Entropy-Based Regularizer"
            ]
        },
        "url": "URL#358344",
        "sema_paperId": "22e769587f83466e0140307b560282e15aaaf430"
    },
    {
        "@score": "1",
        "@id": "358345",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "179/7914",
                        "text": "Song Bian 0001"
                    },
                    {
                        "@pid": "223/0159",
                        "text": "Zian Zhao"
                    },
                    {
                        "@pid": "335/6237",
                        "text": "Zhou Zhang 0016"
                    },
                    {
                        "@pid": "358/0128",
                        "text": "Ran Mao"
                    },
                    {
                        "@pid": "82/6723",
                        "text": "Kohei Suenaga"
                    },
                    {
                        "@pid": "34/756",
                        "text": "Yier Jin"
                    },
                    {
                        "@pid": "121/1665",
                        "text": "Zhenyu Guan"
                    },
                    {
                        "@pid": "43/3771-1",
                        "text": "Jianwei Liu 0001"
                    }
                ]
            },
            "title": "HEIR: A Unified Representation for Cross-Scheme Compilation of Fully Homomorphic Computation.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/0001Z0MSJG024",
            "ee": "https://www.ndss-symposium.org/ndss-paper/heir-a-unified-representation-for-cross-scheme-compilation-of-fully-homomorphic-computation/",
            "url": "https://dblp.org/rec/conf/ndss/0001Z0MSJG024",
            "abstract": "We propose a new compiler framework that automates code generation over multiple fully homomorphic encryption (FHE) schemes. While it was recently shown that algorithms combining multiple FHE schemes (e.g., CKKS and TFHE) achieve high execution efficiency and task utility at the same time, developing fast cross-scheme FHE algorithms for real-world applications generally require heavy hand-tuned optimizations by cryptographic experts, resulting in either high usability costs or low computational efficiency. To solve the usability and efficiency dilemma, we design and implement HEIR, a compiler framework based on multi-level intermediate representation (IR). To achieve cross-scheme compilation of efficient FHE circuits, we develop a two-stage code-lowering structure based on our custom IR dialects. First, the plaintext program along with the associated data types are converted into FHE-friendly dialects in the transformation stage. Then, in the optimization stage, we apply FHE-specific optimizations to lower the transformed dialect into our bottom-level FHE library operators. In the experiment, we implement the entire software stack for HEIR, and demonstrate that complex end-to-end programs, such as homomorphic K-Means clustering and homomorphic data aggregation in databases, can easily be compiled to run 72~179\u00d7 faster than the program generated by the state-of-the-art FHE compilers.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2024-67-paper.pdf",
            "keywords": [
                "Fully Homomorphic Encryption",
                "Cross-Scheme Compilation",
                "Compiler Framework",
                "Code Generation",
                "Execution Efficiency"
            ]
        },
        "url": "URL#358345",
        "sema_paperId": "3f769f0be8abb251837ac72b7b9621bd01ca5fe1"
    },
    {
        "@score": "1",
        "@id": "358346",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "308/8567-3",
                        "text": "Mahdi Rahimi 0003"
                    },
                    {
                        "@pid": "177/1859",
                        "text": "Piyush Kumar Sharma"
                    },
                    {
                        "@pid": "d/ClaudiaDiaz",
                        "text": "Claudia D\u00edaz"
                    }
                ]
            },
            "title": "LARMix: Latency-Aware Routing in Mix Networks.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/0003SD24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/larmix-latency-aware-routing-in-mix-networks/",
            "url": "https://dblp.org/rec/conf/ndss/0003SD24",
            "abstract": "\u2014Anonymous communication systems such as mix networks achieve anonymity at the expense of latency that is introduced to alter the flow of packets and hinder their tracing. A high latency however has a negative impact on usability. In this work, we propose LARMix, a novel latency-aware routing scheme for mixnets that reduces propagation latency with a limited impact on anonymity. LARMix can achieve this while also load balancing the traffic in the network. We additionally show how a network can be configured to maximize anonymity while meeting an average end-to-end latency constraint. Lastly, we perform a security analysis studying various adversarial strategies and conclude that LARMix does not significantly increase adversarial advantage as long as the adversary is not able to selectively compromise mixnodes after the LARMix routing policy has been computed.",
            "keywords": [
                "Mix Networks",
                "Anonymity",
                "Latency Reduction",
                "Traffic Load Balancing",
                "Routing Scheme"
            ]
        },
        "url": "URL#358346",
        "sema_paperId": "dbfe0a9aa599a29bf11b0794f39f2ac8d978d321"
    },
    {
        "@score": "1",
        "@id": "358347",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "61/7498-7",
                        "text": "Ya-Nan Li 0007"
                    },
                    {
                        "@pid": "32/222",
                        "text": "Tian Qiu"
                    },
                    {
                        "@pid": "17/2212-5",
                        "text": "Qiang Tang 0005"
                    }
                ]
            },
            "title": "Pisces: Private and Compliable Cryptocurrency Exchange.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/0007Q024",
            "ee": "https://www.ndss-symposium.org/ndss-paper/pisces-private-and-compliable-cryptocurrency-exchange/",
            "url": "https://dblp.org/rec/conf/ndss/0007Q024",
            "abstract": "Cryptocurrency exchange platforms such as Coinbase, enable users to purchase and sell cryptocurrencies conveniently just like trading stocks/commodities. However, because of the nature of blockchain, when a user withdraws coins (i.e., transfers coins to an external on-chain account), all future transactions can be learned by the platform. This is in sharp contrast to conventional stock exchange where all external activities of users are always hidden from the platform. Since the platform knows highly sensitive user private information such as passport number, bank information etc, linking all (on-chain) transactions raises a serious privacy concern about the potential disastrous data breach in those cryptocurrency exchange platforms.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2024-220-paper.pdf",
            "keywords": [
                "Cryptocurrency Exchange",
                "User Privacy",
                "Blockchain Transactions",
                "Data Breach Risk",
                "Sensitive Information Exposure"
            ]
        },
        "url": "URL#358347"
    },
    {
        "@score": "1",
        "@id": "358348",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "63/778-9",
                        "text": "Hao Zhou 0009"
                    },
                    {
                        "@pid": "311/8828",
                        "text": "Shuohan Wu"
                    },
                    {
                        "@pid": "147/2276",
                        "text": "Chenxiong Qian"
                    },
                    {
                        "@pid": "53/1565",
                        "text": "Xiapu Luo"
                    },
                    {
                        "@pid": "117/7062",
                        "text": "Haipeng Cai"
                    },
                    {
                        "@pid": "94/3019-8",
                        "text": "Chao Zhang 0008"
                    }
                ]
            },
            "title": "Beyond the Surface: Uncovering the Unprotected Components of Android Against Overlay Attack.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/0009WQLC024",
            "ee": "https://www.ndss-symposium.org/ndss-paper/beyond-the-surface-uncovering-the-unprotected-components-of-android-against-overlay-attack/",
            "url": "https://dblp.org/rec/conf/ndss/0009WQLC024",
            "abstract": "\u2014Overlay is a notable user interface feature in the Android system, which allows an app to draw over other apps\u2019 windows. While overlay enhances user experience and allows concurrent app interaction, it has been extensively abused for malicious purposes, such as \"tapjacking\", leading to so-called overlay attacks. In order to combat this threat, Google introduced a dedicated window flag SYSTEM_FLAG_HIDE_NON_SYSTEM_OVERLAY_WINDOWS to protect critical system apps\u2019 windows against overlay attacks. Unfortunately, the adequacy of such protection in the Android system remains unstudied, with a noticeable absence of clear usage guidelines. To bridge the gap, in this paper, we conduct the first systematic study on the unprotected windows of system apps against overlay attacks. We propose a comprehensive guideline and then design and develop a new tool named OverlayChecker to identify the missing protections in Android system apps. To verify the uncovered issues, we also design and create Proof-of-Concept apps. After applying OverlayChecker to 8 commercial Android systems on 4 recently released Android versions, we totally discovered 49 vulnerable system apps\u2019 windows. We reported our findings to the mobile vendors, including Google, Samsung, Vivo, Xiaomi, and Honor. At the time of writing, 15 of them have been confirmed. 5 CVEs have been assigned, and 3 of them are rated high severity. We also received bug bounty rewards from these mobile vendors.",
            "keywords": [
                "Android Security",
                "Overlay Attacks",
                "User Interface Vulnerabilities",
                "System App Protection",
                "Tapjacking"
            ]
        },
        "url": "URL#358348",
        "sema_paperId": "86f42a15c549591760caddd542a6dcb80b5d9793"
    },
    {
        "@score": "1",
        "@id": "358349",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "48/450-26",
                        "text": "Yang Yang 0026"
                    },
                    {
                        "@pid": "d/RobertHDeng",
                        "text": "Robert H. Deng"
                    },
                    {
                        "@pid": "78/2235",
                        "text": "Guomin Yang"
                    },
                    {
                        "@pid": "15/2506",
                        "text": "Yingjiu Li"
                    },
                    {
                        "@pid": "p/HweeHwaPang",
                        "text": "HweeHwa Pang"
                    },
                    {
                        "@pid": "54/3441",
                        "text": "Minming Huang"
                    },
                    {
                        "@pid": "66/4466",
                        "text": "Rui Shi"
                    },
                    {
                        "@pid": "81/1232-1",
                        "text": "Jian Weng 0001"
                    }
                ]
            },
            "title": "PriSrv: Privacy-Enhanced and Highly Usable Service Discovery in Wireless Communications.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/0026DYLPHS024",
            "ee": "https://www.ndss-symposium.org/ndss-paper/prisrv-privacy-enhanced-and-highly-usable-service-discovery-in-wireless-communications/",
            "url": "https://dblp.org/rec/conf/ndss/0026DYLPHS024",
            "abstract": "\u2014Service discovery is essential in wireless communications. However, existing service discovery protocols provide no or very limited privacy protection for service providers and clients, and they often leak sensitive information (e.g., service type, client\u2019s identity and mobility pattern), which leads to various network-based attacks (e.g., spoofing, man-in-the-middle, identification and tracking). In this paper, we propose a private service discovery protocol, called PriSrv, which allows a service provider and a client to respectively specify a fine-grained authentication policy that the other party must satisfy before a connection is established. PriSrv consists of a private service broadcast phase and an anonymous mutual authentication phase with bilateral control, where the private information of both parties is hidden beyond the fact that a mutual match to the respective authentication policy occurred. As a core component of PriSrv, we introduce the notion of anonymous credential-based matchmaking encryption (ACME), which exerts dual-layer matching in one step to simultaneously achieve bilateral flexible policy control, selective attribute disclosure and multi-show unlinkability. As a building block of ACME, we design a fast anonymous credential (FAC) scheme to provide constant size credentials and efficient show/verification mechanisms, which is suitable for privacy-enhanced and highly usable service discovery in wireless networks. We present a concrete PriSrv protocol that is interoperable with popular wireless communication protocols, such as Wi-Fi Extensible Authentication Protocol (EAP), mDNS, BLE and Airdrop, to offer privacy-enhanced protection. We present formal security proof of our protocol and evaluate its performance on multiple hardware platforms: desktop, laptop, mobile phone and Raspberry Pi. PriSrv accomplishes private discovery and secure connection in less than 0.973 s on the first three platforms, and in less than 2.712 s on Raspberry Pi 4B. We also implement PriSrv into IEEE 802.1X in the real network to demonstrate its practicality.",
            "keywords": [
                "Wireless Communications",
                "Service Discovery",
                "Privacy Protection",
                "Anonymous Authentication",
                "Credential-Based Matchmaking"
            ]
        },
        "url": "URL#358349",
        "sema_paperId": "106f9298408d556be77ae10eed4c2851f210e259"
    },
    {
        "@score": "1",
        "@id": "358350",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "308/7059",
                        "text": "Gorka Abad"
                    },
                    {
                        "@pid": "180/5557",
                        "text": "Oguzhan Ersoy"
                    },
                    {
                        "@pid": "50/10230",
                        "text": "Stjepan Picek"
                    },
                    {
                        "@pid": "63/4658",
                        "text": "Aitor Urbieta"
                    }
                ]
            },
            "title": "Sneaky Spikes: Uncovering Stealthy Backdoor Attacks in Spiking Neural Networks with Neuromorphic Data.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/AbadEPU24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/sneaky-spikes-uncovering-stealthy-backdoor-attacks-in-spiking-neural-networks-with-neuromorphic-data/",
            "url": "https://dblp.org/rec/conf/ndss/AbadEPU24",
            "abstract": "Deep neural networks (DNNs) have demonstrated remarkable performance across various tasks, including image and speech recognition. However, maximizing the effectiveness of DNNs requires meticulous optimization of numerous hyperparameters and network parameters through training. Moreover, high-performance DNNs entail many parameters, which consume significant energy during training. In order to overcome these challenges, researchers have turned to spiking neural networks (SNNs), which offer enhanced energy efficiency and biologically plausible data processing capabilities, rendering them highly suitable for sensory data tasks, particularly in neuromorphic data. Despite their advantages, SNNs, like DNNs, are susceptible to various threats, including adversarial examples and backdoor attacks. Yet, the field of SNNs still needs to be explored in terms of understanding and countering these attacks. This paper delves into backdoor attacks in SNNs using neuromorphic datasets and diverse triggers. Specifically, we explore backdoor triggers within neuromorphic data that can manipulate their position and color, providing a broader scope of possibilities than conventional triggers in domains like images. We present various attack strategies, achieving an attack success rate of up to 100% while maintaining a negligible impact on clean accuracy. Furthermore, we assess these attacks' stealthiness, revealing that our most potent attacks possess significant stealth capabilities. Lastly, we adapt several state-of-the-art defenses from the image domain, evaluating their efficacy on neuromorphic data and uncovering instances where they fall short, leading to compromised performance.",
            "keywords": [
                "Spiking Neural Networks",
                "Backdoor Attacks",
                "Neuromorphic Data",
                "Attack Strategies",
                "Stealth Capabilities"
            ]
        },
        "url": "URL#358350",
        "sema_paperId": "4985c2fbef4c33899129ea8e902ca324a4eb98db"
    },
    {
        "@score": "1",
        "@id": "358351",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "195/5992",
                        "text": "Abbas Acar"
                    },
                    {
                        "@pid": "118/3426",
                        "text": "G\u00fcliz Seray Tuncay"
                    },
                    {
                        "@pid": "385/8499",
                        "text": "Esteban Luques"
                    },
                    {
                        "@pid": "285/5550",
                        "text": "Harun Oz"
                    },
                    {
                        "@pid": "69/10491",
                        "text": "Ahmet Aris"
                    },
                    {
                        "@pid": "46/1500",
                        "text": "A. Selcuk Uluagac"
                    }
                ]
            },
            "title": "50 Shades of Support: A Device-Centric Analysis of Android Security Updates.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/AcarTLOAU24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/50-shades-of-support-a-device-centric-analysis-of-android-security-updates/",
            "url": "https://dblp.org/rec/conf/ndss/AcarTLOAU24",
            "abstract": "\u2014Android is by far the most popular OS with over three billion active mobile devices. As in any software, uncovering vulnerabilities on Android devices and applying timely patches are both critical. Android Open Source Project has initiated efforts to improve the traceability of security updates through Security Patch Levels assigned to devices. While this initiative provided better traceability for the vulnerabilities, it has not entirely resolved the issues related to the timeliness and availability of security updates for end users. Recent studies on Android security updates have focused on the issue of delay during the security update roll-out, largely attributing this to factors related to fragmentation. However, these studies fail to capture the entire Android ecosystem as they primarily examine flagship devices or do not paint a comprehensive picture of the Android devices\u2019 lifecycle due to the datasets spanning over a short timeframe. To address this gap in the literature, we utilize a device-centric approach to analyze the security update behavior of Android devices. Our approach aims to understand the security update distribution behavior of Original Equipment Manufacturers (OEM) by using a representative set of devices from each OEM and characterize the complete lifecycle of an average Android device. We obtained 367K official security update records from public sources, spanning from 2014 to 2023. Our dataset contains 599 unique devices from four major OEMs that are used in 97 countries and are associated with 109 carriers. We identify significant differences in the roll-out of security updates across different OEMs, device models and types, and geographical regions across the world. Our findings show that the reasons for the delay in the roll-out of security updates are not limited to fragmentation but also involve several OEM-specific factors such as the type of support the device receives (",
            "keywords": [
                "Android Security Updates",
                "Device-Centric Analysis",
                "OEM Update Behavior",
                "Fragmentation Issues",
                "Security Patch Levels"
            ]
        },
        "url": "URL#358351",
        "sema_paperId": "81ebc8ed831307cbc47238f78eacd1ae077ed720"
    },
    {
        "@score": "1",
        "@id": "358352",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "347/9388",
                        "text": "Kosei Akama"
                    },
                    {
                        "@pid": "205/8037",
                        "text": "Yoshimichi Nakatsuka"
                    },
                    {
                        "@pid": "27/2012",
                        "text": "Masaaki Sato"
                    },
                    {
                        "@pid": "43/1420",
                        "text": "Keisuke Uehara"
                    }
                ]
            },
            "title": "Scrappy: SeCure Rate Assuring Protocol with PrivacY.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/AkamaNSU24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/scrappy-secure-rate-assuring-protocol-with-privacy/",
            "url": "https://dblp.org/rec/conf/ndss/AkamaNSU24",
            "abstract": "Preventing abusive activities caused by adversaries accessing online services at a rate exceeding that expected by websites has become an ever-increasing problem. CAPTCHAs and SMS authentication are widely used to provide a solution by implementing rate limiting, although they are becoming less effective, and some are considered privacy-invasive. In light of this, many studies have proposed better rate-limiting systems that protect the privacy of legitimate users while blocking malicious actors. However, they suffer from one or more shortcomings: (1) assume trust in the underlying hardware and (2) are vulnerable to side-channel attacks. Motivated by the aforementioned issues, this paper proposes Scrappy: SeCure Rate Assuring Protocol with PrivacY. Scrappy allows clients to generate unforgeable yet unlinkable rate-assuring proofs, which provides the server with cryptographic guarantees that the client is not misbehaving. We design Scrappy using a combination of DAA and hardware security devices. Scrappy is implemented over three types of devices, including one that can immediately be deployed in the real world. Our baseline evaluation shows that the end-to-end latency of Scrappy is minimal, taking only 0.32 seconds, and uses only 679 bytes of bandwidth when transferring necessary data. We also conduct an extensive security evaluation, showing that the rate-limiting capability of Scrappy is unaffected even if the hardware security device is compromised.",
            "keywords": [
                "Rate Limiting",
                "Privacy Preservation",
                "Cryptographic Protocols",
                "Unforgeable Proofs",
                "Side-Channel Attacks"
            ]
        },
        "url": "URL#358352",
        "sema_paperId": "970b394744046250b809bd5058be3aa19126b88f"
    },
    {
        "@score": "1",
        "@id": "358353",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "385/8650",
                        "text": "Ayomide Akinsanya"
                    },
                    {
                        "@pid": "137/8806",
                        "text": "Tegan Brennan"
                    }
                ]
            },
            "title": "Timing Channels in Adaptive Neural Networks.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/AkinsanyaB24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/timing-channels-in-adaptive-neural-networks/",
            "url": "https://dblp.org/rec/conf/ndss/AkinsanyaB24",
            "abstract": "\u2014Current machine learning systems offer great predictive power but also require significant computational resources. As a result, the promise of a class of optimized machine learning models, called adaptive neural networks (ADNNs), has seen recent wide appeal. These models make dynamic decisions about the amount of computation to perform based on the given input, allowing for fast predictions on \u201ceasy\u201d input. While various considerations of ADNNs have been extensively researched, how these input-dependent optimizations might introduce vulnerabilities has been hitherto under-explored. Our work is the first to demonstrate and evaluate timing channels due to the optimizations of ADNNs with the capacity to leak sensitive attributes about a user\u2019s input. We empirically study six ADNNs types and demonstrate how an attacker can significantly improve their ability to infer sensitive attributes, such as class label, of another user\u2019s input from an observed timing measurement. Our results show that timing information can increase an attacker\u2019s probability of correctly inferring the attribute of the user\u2019s input by up to a factor of 9.89 x . Our empirical evaluation uses four different datasets, including those containing sensitive medical and demographic information, and considers leakage across a variety of sensitive attributes of the user\u2019s input. We conclude by demonstrating how timing channels can be exploited across the public internet in two fictitious web applications \u2014 Fictitious Health Company and Fictitious HR \u2014 that make use of ADNNs for serving predictions to their clients.",
            "keywords": [
                "Adaptive Neural Networks",
                "Timing Channels",
                "Information Leakage",
                "Attribute Inference",
                "Sensitive Data Exposure"
            ]
        },
        "url": "URL#358353",
        "sema_paperId": "6cddc25cae4e086425ba34aa1a7192616e9773dd"
    },
    {
        "@score": "1",
        "@id": "358354",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "67/4350",
                        "text": "Guy Amit"
                    },
                    {
                        "@pid": "75/6343",
                        "text": "Moshe Levy"
                    },
                    {
                        "@pid": "160/6851",
                        "text": "Yisroel Mirsky"
                    }
                ]
            },
            "title": "Transpose Attack: Stealing Datasets with Bidirectional Training.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/AmitLM24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/transpose-attack-stealing-datasets-with-bidirectional-training/",
            "url": "https://dblp.org/rec/conf/ndss/AmitLM24",
            "abstract": "Deep neural networks are normally executed in the forward direction. However, in this work, we identify a vulnerability that enables models to be trained in both directions and on different tasks. Adversaries can exploit this capability to hide rogue models within seemingly legitimate models. In addition, in this work we show that neural networks can be taught to systematically memorize and retrieve specific samples from datasets. Together, these findings expose a novel method in which adversaries can exfiltrate datasets from protected learning environments under the guise of legitimate models. We focus on the data exfiltration attack and show that modern architectures can be used to secretly exfiltrate tens of thousands of samples with high fidelity, high enough to compromise data privacy and even train new models. Moreover, to mitigate this threat we propose a novel approach for detecting infected models.",
            "keywords": [
                "Data Exfiltration",
                "Bidirectional Training",
                "Model Infiltration",
                "Dataset Privacy",
                "Rogue Models"
            ]
        },
        "url": "URL#358354",
        "sema_paperId": "7151a1b98f519fad7fb0e481b283b158a743e29e"
    },
    {
        "@score": "1",
        "@id": "358355",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "303/3273",
                        "text": "Meenatchi Sundaram Muthu Selva Annamalai"
                    },
                    {
                        "@pid": "52/8356",
                        "text": "Igor Bilogrevic"
                    },
                    {
                        "@pid": "36/6225",
                        "text": "Emiliano De Cristofaro"
                    }
                ]
            },
            "title": "FP-Fed: Privacy-Preserving Federated Detection of Browser Fingerprinting.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/AnnamalaiBC24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/fp-fed-privacy-preserving-federated-detection-of-browser-fingerprinting/",
            "url": "https://dblp.org/rec/conf/ndss/AnnamalaiBC24",
            "abstract": "Browser fingerprinting often provides an attractive alternative to third-party cookies for tracking users across the web. In fact, the increasing restrictions on third-party cookies placed by common web browsers and recent regulations like the GDPR may accelerate the transition. To counter browser fingerprinting, previous work proposed several techniques to detect its prevalence and severity. However, these rely on 1) centralized web crawls and/or 2) computationally intensive operations to extract and process signals (e.g., information-flow and static analysis). To address these limitations, we present FP-Fed, the first distributed system for browser fingerprinting detection. Using FP-Fed, users can collaboratively train on-device models based on their real browsing patterns, without sharing their training data with a central entity, by relying on Differentially Private Federated Learning (DP-FL). To demonstrate its feasibility and effectiveness, we evaluate FP-Fed's performance on a set of 18.3k popular websites with different privacy levels, numbers of participants, and features extracted from the scripts. Our experiments show that FP-Fed achieves reasonably high detection performance and can perform both training and inference efficiently, on-device, by only relying on runtime signals extracted from the execution trace, without requiring any resource-intensive operation.",
            "keywords": [
                "Browser Fingerprinting",
                "Federated Learning",
                "Privacy Preservation",
                "Detection Techniques",
                "Differential Privacy"
            ]
        },
        "url": "URL#358355",
        "sema_paperId": "0f9cf686102d90d68f82053ee7480890a3388bad"
    },
    {
        "@score": "1",
        "@id": "358356",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "323/4231",
                        "text": "Kerem Arikan"
                    },
                    {
                        "@pid": "385/8446",
                        "text": "Abraham Farrell"
                    },
                    {
                        "@pid": "385/8380",
                        "text": "Williams Zhang Cen"
                    },
                    {
                        "@pid": "385/8456",
                        "text": "Jack McMahon"
                    },
                    {
                        "@pid": "200/3103",
                        "text": "Barry Williams"
                    },
                    {
                        "@pid": "30/3456",
                        "text": "Yu David Liu"
                    },
                    {
                        "@pid": "86/2654",
                        "text": "Nael B. Abu-Ghazaleh"
                    },
                    {
                        "@pid": "p/DmitryVPonomarev",
                        "text": "Dmitry Ponomarev 0001"
                    }
                ]
            },
            "title": "TEE-SHirT: Scalable Leakage-Free Cache Hierarchies for TEEs.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ArikanFCMWLA024",
            "ee": "https://www.ndss-symposium.org/ndss-paper/tee-shirt-scalable-leakage-free-cache-hierarchies-for-tees/",
            "url": "https://dblp.org/rec/conf/ndss/ArikanFCMWLA024",
            "abstract": "\u2014Protection of cache hierarchies from side-channel attacks is critical for building secure systems, particularly the ones using Trusted Execution Environments (TEEs). In this paper, we consider the problem of efficient and secure fine-grained partitioning of cache hierarchies and propose a framework, called Secure Hierarchies for TEEs (TEE-SHirT). In the context of a three-level cache system, TEE-SHirT consists of partitioned shared last-level cache, partitioned private L2 caches, and non-partitioned L1 caches that are flushed on context switches and system calls. Efficient and correct partitioning requires careful design. Towards this goal, TEE-SHirT makes three contributions: 1) we demonstrate how the hardware structures used for holding cache partitioning metadata can be effectively virtualized to avoid flushing of cache partition content on context switches and system calls; 2) we show how to support multi-threaded enclaves in TEE-SHirT, addressing the issues of coherency and consistency that arise with both intra-core and inter-core data sharing; 3) we develop a formal security model for TEE-SHirT to rigorously reason about the security of our design.",
            "keywords": [
                "Trusted Execution Environments",
                "Cache Hierarchies",
                "Side-Channel Attacks",
                "Cache Partitioning",
                "Security Model"
            ]
        },
        "url": "URL#358356",
        "sema_paperId": "e6c3f6bdfff1d49fed25dd6259cb18556bfd7573"
    },
    {
        "@score": "1",
        "@id": "358357",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "356/8261",
                        "text": "Fatemeh Arkannezhad"
                    },
                    {
                        "@pid": "346/2836",
                        "text": "Justin Feng"
                    },
                    {
                        "@pid": "139/9042",
                        "text": "Nader Sehatbakhsh"
                    }
                ]
            },
            "title": "IDA: Hybrid Attestation with Support for Interrupts and TOCTOU.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ArkannezhadFS24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/ida-hybrid-attestation-with-support-for-interrupts-and-toctou/",
            "url": "https://dblp.org/rec/conf/ndss/ArkannezhadFS24",
            "abstract": "\u2014Remote attestation has received much attention recently due to the proliferation of embedded and IoT devices. Among various solutions, methods based on hardware-software co-design (hybrid) are particularly popular due to their low overhead yet effective approaches. Despite their usefulness, hybrid methods still suffer from multiple limitations such as strict protections required for the attestation keys and restrictive operation and threat models such as disabling interrupts and neglecting time-of-check-time-of-use (TOCTOU) attacks. In this paper, we propose a new hybrid attestation method called IDA , which removes the requirement for disabling in-terrupts and restrictive access control for the secret key and attestation code, thus improving the system\u2019s overall security and flexibility. Rather than making use of a secret key to calculate the response, IDA verifies the attestation process with trusted hardware monitoring and certifies its authenticity only if it was followed precisely. Further, to prevent TOCTOU attacks and handle interrupts, we propose IDA+ , which monitors program memory between attestation requests or during interrupts and informs the verifier of changes to the program memory. We implement and evaluate IDA and IDA+ on open-source MSP430 architecture, showing a reasonable overhead in terms of runtime, memory footprint, and hardware overhead while being robust against various attack scenarios. Comparing our method with the state-of-the-art, we show that it has minimal overhead while achieving important new properties such as support for interrupts and DMA requests and detecting TOCTOU attacks.",
            "keywords": [
                "Hybrid Attestation",
                "Interrupt Handling",
                "TOCTOU Attacks",
                "Embedded Systems Security",
                "Trusted Hardware Monitoring"
            ]
        },
        "url": "URL#358357",
        "sema_paperId": "06fd28e3f12b718a7f737ad9b4318882aa9c34a1"
    },
    {
        "@score": "1",
        "@id": "358358",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "331/2639",
                        "text": "Arjun Arunasalam"
                    },
                    {
                        "@pid": "25/3543",
                        "text": "Andrew Chu"
                    },
                    {
                        "@pid": "202/6743",
                        "text": "Muslum Ozgur Ozmen"
                    },
                    {
                        "@pid": "222/5923",
                        "text": "Habiba Farrukh"
                    },
                    {
                        "@pid": "143/2298",
                        "text": "Z. Berkay Celik"
                    }
                ]
            },
            "title": "The Dark Side of E-Commerce: Dropshipping Abuse as a Business Model.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ArunasalamCOFC24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/the-dark-side-of-e-commerce-dropshipping-abuse-as-a-business-model/",
            "url": "https://dblp.org/rec/conf/ndss/ArunasalamCOFC24",
            "abstract": "\u2014The impact of e-commerce on today\u2019s society is a global phenomenon. Given the increased demand for online purchases of items, e-commerce platforms often defer item sales to third-party sellers. A number of these sellers are dropshippers , sellers acting as middlemen who fulfill their customers\u2019 orders through third-party suppliers. While this allows customers to access more products on e-commerce sites, we uncover that abusive dropshippers, who exploit the standard permitted dropshipping model, exist, deceiving customers, and damaging other e-commerce sellers. In this paper, we present the first comprehensive study on the characterization of abusive dropshippers and uncover harmful strategies they use to list items and evade account suspension on e-commerce marketplaces. We crawled the web to discover online forums, instructional material, and software used by the abusive dropshipping community. We inductively code forum threads and instructional material and read software documentation, installing when possible, to create an end-to-end lifecycle of this abuse. We also identify exploitative strategies abusive dropshippers use to ensure persistence on platforms. We then interviewed six individuals experienced in e-commerce (legal consultants and sellers) and developed an understanding of how abusive dropshipping harms customers and sellers. Through this, we present five characteristics that warrant future investigation into automated detection of abusive dropshippers on e-commerce platforms. Our efforts present a comprehensive view of how abusive dropshippers operate and how sellers and consumers interact with them, providing a framework to motivate future investigations into countering these harmful operations.",
            "keywords": [
                "E-Commerce",
                "Dropshipping",
                "Abusive Practices",
                "Consumer Deception",
                "Seller Exploitation"
            ]
        },
        "url": "URL#358358",
        "sema_paperId": "adc824d03352820503f10d2162267f1b7054288c"
    },
    {
        "@score": "1",
        "@id": "358359",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "239/8466",
                        "text": "Pietro Borrello"
                    },
                    {
                        "@pid": "252/5052",
                        "text": "Andrea Fioraldi"
                    },
                    {
                        "@pid": "32/9698",
                        "text": "Daniele Cono D&apos;Elia"
                    },
                    {
                        "@pid": "56/490",
                        "text": "Davide Balzarotti"
                    },
                    {
                        "@pid": "24/2123",
                        "text": "Leonardo Querzoni"
                    },
                    {
                        "@pid": "75/8194",
                        "text": "Cristiano Giuffrida"
                    }
                ]
            },
            "title": "Predictive Context-sensitive Fuzzing.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/BorrelloFDBQG24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/predictive-context-sensitive-fuzzing/",
            "url": "https://dblp.org/rec/conf/ndss/BorrelloFDBQG24",
            "abstract": "\u2014Coverage-guided fuzzers expose bugs by progressively mutating testcases to drive execution to new program locations. Code coverage is currently the most effective and popular exploration feedback. For several bugs, though, also how execution reaches a buggy program location may matter: for those, only tracking what code a testcase exercises may lead fuzzers to overlook interesting program states. Unfortunately, context-sensitive coverage tracking comes with an inherent state explosion problem. Existing attempts to implement context-sensitive coverage-guided fuzzers struggle with it, experiencing non-trivial issues for precision (due to coverage collisions) and performance (due to context tracking and queue/map explosion). In this paper, we show that a much more effective approach to context-sensitive fuzzing is possible. First, we propose function cloning as a backward-compatible instrumentation primitive to enable precise (i.e., collision-free) context-sensitive coverage tracking. Then, to tame the state explosion problem, we argue to account for contextual information only when a fuzzer explores contexts selected as promising. We propose a prediction scheme to identify one pool of such contexts: we analyze the data-flow diversity of the incoming argument values at call sites, exposing to the fuzzer a contextually refined clone of the callee if the latter sees incoming abstract objects that its uses at other sites do not. Our work shows that, by applying function cloning to program regions that we predict to benefit from context-sensitivity, we can overcome the aforementioned issues while preserving, and even improving, fuzzing effectiveness. On the FuzzBench suite, our approach largely outperforms state-of-the-art coverage-guided fuzzing embodiments, unveiling more and different bugs",
            "keywords": [
                "Fuzzing",
                "Context-sensitive Coverage",
                "Function Cloning",
                "State Explosion Problem",
                "Bug Detection"
            ]
        },
        "url": "URL#358359",
        "sema_paperId": "e75d9092895784fa9eb6840a7473ab27dc5f0aad"
    },
    {
        "@score": "1",
        "@id": "358360",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "204/3788",
                        "text": "Frank Capobianco"
                    },
                    {
                        "@pid": "29/5849",
                        "text": "Quan Zhou"
                    },
                    {
                        "@pid": "154/9562",
                        "text": "Aditya Basu"
                    },
                    {
                        "@pid": "45/576",
                        "text": "Trent Jaeger"
                    },
                    {
                        "@pid": "23/3719",
                        "text": "Danfeng Zhang"
                    }
                ]
            },
            "title": "TALISMAN: Tamper Analysis for Reference Monitors.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/CapobiancoZBJZ24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/talisman-tamper-analysis-for-reference-monitors/",
            "url": "https://dblp.org/rec/conf/ndss/CapobiancoZBJZ24",
            "abstract": "\u2014Correct access control enforcement is a critical foundation for data security. The reference monitor is the key component for enforcing access control, which is supposed to provide tamperproof mediation of all security-sensitive operations. Since reference monitors are often deployed in complex software handling a wide variety of operation requests, such as operating systems and server programs, a question is whether reference monitor implementations may have flaws that prevent them from achieving these requirements. In the past, automated analyses detected flaws in complete mediation. However, researchers have not yet developed methods to detect flaws that may tamper with the reference monitor, despite the many vulnerabilities found in such programs. In this paper, we develop T ALISMAN , an automated analysis for detecting flaws that may tamper the execution of reference monitor implementations. At its core, T ALISMAN implements a precise information flow integrity analysis to detect violations that may tamper the construction of authorization queries. T ALISMAN applies a new, relaxed variant of noninterference that eliminates several spurious implicit flow violations. T ALISMAN also provides a means to vet expected uses of untrusted data in authorization using endorsement. We apply T ALISMAN on three reference monitor implementations used in the Linux Security Modules framework, SELinux, AppArmor, and Tomoyo, verifying 80% of the arguments in authorization queries generated by these LSMs. Using T ALISMAN , we also found vulnerabilities in how pathnames are used in authorization by Tomoyo and AppArmor allowing adversaries to circumvent authorization. T ALISMAN shows that tamper analysis of reference monitor implementations can automatically verify many cases and also enable the detection of critical flaws.",
            "keywords": [
                "Reference Monitor",
                "Access Control Enforcement",
                "Tamper Analysis",
                "Information Flow Integrity",
                "Authorization Vulnerabilities"
            ]
        },
        "url": "URL#358360",
        "sema_paperId": "11fb08f7ade9735df1e20bbe16b5c7907b72220a"
    },
    {
        "@score": "1",
        "@id": "358361",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "309/0955",
                        "text": "Huiling Chen"
                    },
                    {
                        "@pid": "196/7070",
                        "text": "Wenqiang Jin"
                    },
                    {
                        "@pid": "62/7825",
                        "text": "Yupeng Hu"
                    },
                    {
                        "@pid": "47/8535",
                        "text": "Zhenyu Ning"
                    },
                    {
                        "@pid": "l/KenliLi",
                        "text": "Kenli Li 0001"
                    },
                    {
                        "@pid": "95/6861-1",
                        "text": "Zheng Qin 0001"
                    },
                    {
                        "@pid": "157/2422",
                        "text": "Mingxing Duan"
                    },
                    {
                        "@pid": "06/2422",
                        "text": "Yong Xie"
                    },
                    {
                        "@pid": "141/1957",
                        "text": "Daibo Liu"
                    },
                    {
                        "@pid": "l/MingLi6",
                        "text": "Ming Li 0006"
                    }
                ]
            },
            "title": "Eavesdropping on Black-box Mobile Devices via Audio Amplifier&apos;s EMR.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ChenJHN00DXLL24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/eavesdropping-on-black-box-mobile-devices-via-audio-amplifiers-emr/",
            "url": "https://dblp.org/rec/conf/ndss/ChenJHN00DXLL24",
            "abstract": "\u2014Audio eavesdropping poses serious threats to user privacy in daily mobile usage scenarios such as phone calls, voice messaging, and confidential meetings. Headphones are thus favored by mobile users as it provide physical sound isolation to protect audio privacy. However, our paper presents the first proof-of-concept system, Periscope , that demonstrates the vulnerabilities of headphone-plugged mobile devices. The system shows that unintentionally leaked electromagnetic radiations (EMR) from mobile devices\u2019 audio amplifiers can be exploited as an effective side-channel in recovering victim\u2019s audio sounds. Additionally, plugged headphones act as antennas that enhance the EMR strengths, making them easily measurable at long distances. Our feasibility studies and hardware analysis further reveal that EMRs are highly correlated with the device\u2019s audio inputs but suffer from signal distortions and ambient noises, making recovering audio sounds extremely challenging. To address this challenge, we develop signal processing techniques with a spectrogram clustering scheme that clears noises and distortions, enabling EMRs to be converted back to audio sounds. Our attack prototype, comparable in size to hidden voice recorders, successfully recovers victims\u2019 private audio sounds with a word error rate (WER) as low as 7.44% across 11 mobile devices and 6 headphones. The recovery results are recognizable to natural human hearing and online speech-to-text tools,",
            "keywords": [
                "Audio Eavesdropping",
                "Electromagnetic Radiation",
                "Mobile Device Security",
                "Signal Processing",
                "Audio Recovery"
            ]
        },
        "url": "URL#358361",
        "sema_paperId": "3cb9112e0206586000256f3ea01687102b9aca0c"
    },
    {
        "@score": "1",
        "@id": "358362",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "218/6794",
                        "text": "Liheng Chen"
                    },
                    {
                        "@pid": "62/7776",
                        "text": "Zheming Li"
                    },
                    {
                        "@pid": "249/4978",
                        "text": "Zheyu Ma"
                    },
                    {
                        "@pid": "86/6196",
                        "text": "Yuan Li"
                    },
                    {
                        "@pid": "312/7359",
                        "text": "Baojian Chen"
                    },
                    {
                        "@pid": "94/3019-8",
                        "text": "Chao Zhang 0008"
                    }
                ]
            },
            "title": "EnclaveFuzz: Finding Vulnerabilities in SGX Applications.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ChenLMLC024",
            "ee": "https://www.ndss-symposium.org/ndss-paper/enclavefuzz-finding-vulnerabilities-in-sgx-applications/",
            "url": "https://dblp.org/rec/conf/ndss/ChenLMLC024",
            "abstract": "\u2014 Intel\u2019s Software Guard Extensions (SGX) offers an isolated execution environment, known as an enclave, where everything outside the enclave is considered potentially malicious, including non-enclave memory region, peripherals, and the operating system. Despite its robust attack model, the code running within enclaves is still prone to common memory corruption vulnerabilities. Moreover, such an attack model may introduce new threats or amplify existing ones. For instance, any direct memory access to untrusted memory from within an enclave can lead to Time-of-Check-Time-of-Use (TOCTOU) bugs since attackers are capable of controlling the whole untrusted memory. Moreover, null-pointer dereference may have a more severe security impact since the zero page controlled by the operating system is also considered malicious. Current fuzzing solutions, such as SGXFuzz and FuzzSGX, have limitations detecting such SGX-specific vulnerabilities. In this paper, we propose EnclaveFuzz, a multi-dimension structure-aware fuzzing framework that analyzes enclave sources to extract input structures and correlations, then generates fuzz harnesses that can produce valid inputs to pass sanity checks. To conduct multi-dimensional fuzzing, EnclaveFuzz creates data for all three input dimensions of an enclave, including both parameters and return values that enter an enclave, as well as direct untrusted memory access from within an enclave. To detect more types of vulnerabilities, we design a new sanitizer to detect both SGX-specific vulnerabilities and typical",
            "keywords": [
                "SGX Applications",
                "Memory Corruption",
                "Fuzzing Framework",
                "Vulnerability Detection",
                "Time-of-Check-Time-of-Use (TOCTOU)"
            ]
        },
        "url": "URL#358362",
        "sema_paperId": "2ced7128e1fc7e2481a9e75302e27ee2726f25d1"
    },
    {
        "@score": "1",
        "@id": "358363",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "328/3574",
                        "text": "Yikang Chen"
                    },
                    {
                        "@pid": "07/8499",
                        "text": "Yibo Liu"
                    },
                    {
                        "@pid": "350/4832",
                        "text": "Ka Lok Wu"
                    },
                    {
                        "@pid": "178/9776",
                        "text": "Duc V. Le"
                    },
                    {
                        "@pid": "201/9242",
                        "text": "Sze Yiu Chau"
                    }
                ]
            },
            "title": "Towards Precise Reporting of Cryptographic Misuses.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ChenLWLC24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/towards-precise-reporting-of-cryptographic-misuses/",
            "url": "https://dblp.org/rec/conf/ndss/ChenLWLC24",
            "abstract": "\u2014In the last decade, a series of papers were published on using static analysis to detect cryptographic API misuse. In each paper, apps are checked against a set of rules to see if violations exist. A common theme among these papers is that rule violations are plentiful, often at the scale of thousands. Interestingly, while much effort went into tackling false negatives, curiously, not much has been said on (1) whether the misuse alarms are indeed correct and meaningful, and (2) what can future work improve upon apart from finding more misuses. In this paper, we take a deep dive into the rule violations reported by various academic papers as well as the rules, models and implementations of their detectors, in an attempt to (1) explain the gap between their misuse alarms and actual vulnerabilities, and (2) shed light on possible directions for improving the precision and usability of misuse detectors. Results of our analysis suggest that the small-scale inspections done by previous work had some unfortunate blind-spots, leaving problems in their rules, models, and implementations unnoticed, which in turn led to unnecessary overestimation of misuses (and vulnerabilities). To facilitate future research on the topic, we distill these avoidable false alarms into high-level patterns that capture their root causes, and discuss design, evaluation and reporting strategies that can improve the precision of misuse findings. Furthermore, to demonstrate the generalizability of these false alarm patterns and improvement directions, we also investigate a popular industry detector and a dynamic detector, and discuss how some of the false alarm patterns do and do not apply to them. Our findings suggest that the problem of precisely reporting cryptographic misuses still has much room for future work to improve upon.",
            "keywords": [
                "Cryptographic API Misuse",
                "Static Analysis",
                "False Alarms",
                "Vulnerability Detection",
                "Precision Improvement"
            ]
        },
        "url": "URL#358363",
        "sema_paperId": "6aad5ac154fc567c8a96fe14762c4d05ceacbcf0"
    },
    {
        "@score": "1",
        "@id": "358364",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "252/5255",
                        "text": "Guangke Chen"
                    },
                    {
                        "@pid": "230/8027",
                        "text": "Yedi Zhang"
                    },
                    {
                        "@pid": "09/10016",
                        "text": "Fu Song"
                    }
                ]
            },
            "title": "SLMIA-SR: Speaker-Level Membership Inference Attacks against Speaker Recognition Systems.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ChenZS24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/slmia-sr-speaker-level-membership-inference-attacks-against-speaker-recognition-systems/",
            "url": "https://dblp.org/rec/conf/ndss/ChenZS24",
            "abstract": "Membership inference attacks allow adversaries to determine whether a particular example was contained in the model's training dataset. While previous works have confirmed the feasibility of such attacks in various applications, none has focused on speaker recognition (SR), a promising voice-based biometric recognition technique. In this work, we propose SLMIA-SR, the first membership inference attack tailored to SR. In contrast to conventional example-level attack, our attack features speaker-level membership inference, i.e., determining if any voices of a given speaker, either the same as or different from the given inference voices, have been involved in the training of a model. It is particularly useful and practical since the training and inference voices are usually distinct, and it is also meaningful considering the open-set nature of SR, namely, the recognition speakers were often not present in the training data. We utilize intra-similarity and inter-dissimilarity, two training objectives of SR, to characterize the differences between training and non-training speakers and quantify them with two groups of features driven by carefully-established feature engineering to mount the attack. To improve the generalizability of our attack, we propose a novel mixing ratio training strategy to train attack models. To enhance the attack performance, we introduce voice chunk splitting to cope with the limited number of inference voices and propose to train attack models dependent on the number of inference voices. Our attack is versatile and can work in both white-box and black-box scenarios. Additionally, we propose two novel techniques to reduce the number of black-box queries while maintaining the attack performance. Extensive experiments demonstrate the effectiveness of SLMIA-SR.",
            "keywords": [
                "Speaker Recognition",
                "Membership Inference Attack",
                "Speaker-Level Inference",
                "Voice Biometric Security",
                "Training Dataset Leakage"
            ]
        },
        "url": "URL#358364",
        "sema_paperId": "d16b9c5e9c336f5864aca3562c560cc25c959fb4"
    },
    {
        "@score": "1",
        "@id": "358365",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "58/5381",
                        "text": "Zhuo Cheng"
                    },
                    {
                        "@pid": "180/5502",
                        "text": "Maria Apostolaki"
                    },
                    {
                        "@pid": "166/6255",
                        "text": "Zaoxing Liu"
                    },
                    {
                        "@pid": "45/4044",
                        "text": "Vyas Sekar"
                    }
                ]
            },
            "title": "TrustSketch: Trustworthy Sketch-based Telemetry on Cloud Hosts.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ChengALS24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/trustsketch-trustworthy-sketch-based-telemetry-on-cloud-hosts/",
            "url": "https://dblp.org/rec/conf/ndss/ChengALS24",
            "abstract": "\u2014Cloud providers deploy telemetry tools in software to perform end-host network analytics. Recent efforts show that sketches, a kind of approximate data structure, are a promising basis for software-based telemetry, as they provide high fidelity for many statistics with a low resource footprint. However, an attacker can compromise sketch-based telemetry results via software vulnerabilities. Consequently, they can nullify the use of telemetry; e.g., avoiding attack detection or inducing accounting discrepancies. In this paper, we formally define the requirements for trustworthy sketch-based telemetry and show that prior work cannot meet those due to the sketch\u2019s probabilistic nature and performance requirements. We present the design and implementation T RUST S KETCH , a general framework for trustworthy sketch telemetry that can support a wide spectrum of sketching algorithms. We show that T RUST S KETCH is able to detect a wide range of attacks on sketch-based telemetry in a timely fashion while incurring only minimal overhead.",
            "keywords": [
                "Cloud Telemetry",
                "Sketch-based Analytics",
                "Trustworthy Telemetry",
                "Attack Detection",
                "Resource Overhead"
            ]
        },
        "url": "URL#358365",
        "sema_paperId": "79de44f24d4375aaf5c21375b8fe4de55ab5111f"
    },
    {
        "@score": "1",
        "@id": "358366",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "31/6808-1",
                        "text": "Sourav Das 0001"
                    },
                    {
                        "@pid": "175/1673",
                        "text": "Zhuolun Xiang"
                    },
                    {
                        "@pid": "30/10661",
                        "text": "Ling Ren 0001"
                    }
                ]
            },
            "title": "Powers of Tau in Asynchrony.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/DasX024",
            "ee": "https://www.ndss-symposium.org/ndss-paper/powers-of-tau-in-asynchrony/",
            "url": "https://dblp.org/rec/conf/ndss/DasX024",
            "abstract": "The $q$-Strong Diffie-Hellman~($q$-SDH) parameters are foundational to efficient constructions of many cryptographic primitives such as zero-knowledge succinct non-interactive argument of knowledge, polynomial/vector commitments, verifiable secret sharing, and randomness beacon. The only existing method to generate these parameters securely is highly sequential, requires strong network synchrony assumptions, and has very high communication and computation cost. For example, to generate parameters for any given $q$, each party incurs a communication cost of $Omega(nq)$ and requires $Omega(n)$ rounds. Here $n$ is the number of parties in the secure multiparty computation protocol. Since $q$ is typically large, i.e., on the order of billions, the cost is highly prohibitive.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2024-733-paper.pdf",
            "keywords": [
                "Cryptographic Protocols",
                "q-Strong Diffie-Hellman",
                "Secure Multiparty Computation",
                "Parameter Generation",
                "Network Synchrony"
            ]
        },
        "url": "URL#358366"
    },
    {
        "@score": "1",
        "@id": "358367",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "145/1034",
                        "text": "Yaniv David"
                    },
                    {
                        "@pid": "277/2335",
                        "text": "Neophytos Christou"
                    },
                    {
                        "@pid": "318/2989",
                        "text": "Andreas D. Kellas"
                    },
                    {
                        "@pid": "87/1029",
                        "text": "Vasileios P. Kemerlis"
                    },
                    {
                        "@pid": "71/3724",
                        "text": "Junfeng Yang"
                    }
                ]
            },
            "title": "QUACK: Hindering Deserialization Attacks via Static Duck Typing.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/DavidCKKY24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/quack-hindering-deserialization-attacks-via-static-duck-typing/",
            "url": "https://dblp.org/rec/conf/ndss/DavidCKKY24",
            "abstract": "\u2014Managed languages facilitate convenient ways for serializing objects, allowing applications to persist and transfer them easily, yet this feature opens them up to attacks. By manipulating serialized objects, attackers can trigger a chained execution of existing code segments, using them as gadgets to form an exploit. Protecting deserialization calls against attacks is cumbersome and tedious, leading to many developers avoiding deploying defenses properly. We present Q UACK , a framework for automatically protecting applications by fixing calls to deseri-alization APIs. This \u201cbinding\u201d limits the classes allowed for usage in the deserialization process, severely limiting the code available for (ab)use as part of exploits. Q UACK computes the set of classes that should be allowed using a novel static duck typing inference technique. In particular, it statically collects all statements in the program code that manipulate objects after they are deserialized, and puts together a filter for the list of classes that should be available at runtime. We have implemented Q UACK for PHP and evaluated it on a set of applications with known CVEs, and popular applications crawled from GitHub. Q UACK managed to fix the applications in a way that prevented any attempt at automatically generating an exploit against them, by blocking, on average, 97% of the application\u2019s code that could be used as gadgets. We submitted a sample of three fixes generated by Q UACK as pull requests, and their developers merged them.",
            "keywords": [
                "Deserialization Attacks",
                "Static Analysis",
                "Duck Typing",
                "Code Gadget Exploits",
                "PHP Security"
            ]
        },
        "url": "URL#358367",
        "sema_paperId": "414394809dc6a6ee3fb25af7029cd38b2a4cf087"
    },
    {
        "@score": "1",
        "@id": "358368",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "236/9144",
                        "text": "Gelei Deng"
                    },
                    {
                        "@pid": "97/4626-69",
                        "text": "Yi Liu 0069"
                    },
                    {
                        "@pid": "204/3729",
                        "text": "Yuekang Li"
                    },
                    {
                        "@pid": "171/1258",
                        "text": "Kailong Wang 0001"
                    },
                    {
                        "@pid": "13/6769-66",
                        "text": "Ying Zhang 0066"
                    },
                    {
                        "@pid": "189/8685",
                        "text": "Zefeng Li"
                    },
                    {
                        "@pid": "50/8499-1",
                        "text": "Haoyu Wang 0001"
                    },
                    {
                        "@pid": "77/7902-4",
                        "text": "Tianwei Zhang 0004"
                    },
                    {
                        "@pid": "51/3710-3",
                        "text": "Yang Liu 0003"
                    }
                ]
            },
            "title": "MASTERKEY: Automated Jailbreaking of Large Language Model Chatbots.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/DengLLWZLW0L24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/masterkey-automated-jailbreaking-of-large-language-model-chatbots/",
            "url": "https://dblp.org/rec/conf/ndss/DengLLWZLW0L24",
            "abstract": "Large Language Models (LLMs) have revolutionized Artificial Intelligence (AI) services due to their exceptional proficiency in understanding and generating human-like text. LLM chatbots, in particular, have seen widespread adoption, transforming human-machine interactions. However, these LLM chatbots are susceptible to\"jailbreak\"attacks, where malicious users manipulate prompts to elicit inappropriate or sensitive responses, contravening service policies. Despite existing attempts to mitigate such threats, our research reveals a substantial gap in our understanding of these vulnerabilities, largely due to the undisclosed defensive measures implemented by LLM service providers. In this paper, we present Jailbreaker, a comprehensive framework that offers an in-depth understanding of jailbreak attacks and countermeasures. Our work makes a dual contribution. First, we propose an innovative methodology inspired by time-based SQL injection techniques to reverse-engineer the defensive strategies of prominent LLM chatbots, such as ChatGPT, Bard, and Bing Chat. This time-sensitive approach uncovers intricate details about these services' defenses, facilitating a proof-of-concept attack that successfully bypasses their mechanisms. Second, we introduce an automatic generation method for jailbreak prompts. Leveraging a fine-tuned LLM, we validate the potential of automated jailbreak generation across various commercial LLM chatbots. Our method achieves a promising average success rate of 21.58%, significantly outperforming the effectiveness of existing techniques. We have responsibly disclosed our findings to the concerned service providers, underscoring the urgent need for more robust defenses. Jailbreaker thus marks a significant step towards understanding and mitigating jailbreak threats in the realm of LLM chatbots.",
            "keywords": [
                "Large Language Models",
                "Jailbreaking",
                "Prompt Manipulation",
                "Defensive Strategies",
                "Automated Jailbreak Generation"
            ]
        },
        "url": "URL#358368",
        "sema_paperId": "6987c95f7054d2653178ac93df52aa3c0b99fcf5"
    },
    {
        "@score": "1",
        "@id": "358369",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "246/4947",
                        "text": "Linkang Du"
                    },
                    {
                        "@pid": "50/6996-32",
                        "text": "Min Chen 0032"
                    },
                    {
                        "@pid": "143/6589",
                        "text": "Mingyang Sun"
                    },
                    {
                        "@pid": "07/8388",
                        "text": "Shouling Ji"
                    },
                    {
                        "@pid": "76/185-1",
                        "text": "Peng Cheng 0001"
                    },
                    {
                        "@pid": "55/2484-1",
                        "text": "Jiming Chen 0001"
                    },
                    {
                        "@pid": "90/545-1",
                        "text": "Zhikun Zhang 0001"
                    }
                ]
            },
            "title": "ORL-AUDITOR: Dataset Auditing in Offline Deep Reinforcement Learning.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/Du0SJ00024",
            "ee": "https://www.ndss-symposium.org/ndss-paper/orl-auditor-dataset-auditing-in-offline-deep-reinforcement-learning/",
            "url": "https://dblp.org/rec/conf/ndss/Du0SJ00024",
            "abstract": "Data is a critical asset in AI, as high-quality datasets can significantly improve the performance of machine learning models. In safety-critical domains such as autonomous vehicles, offline deep reinforcement learning (offline DRL) is frequently used to train models on pre-collected datasets, as opposed to training these models by interacting with the real-world environment as the online DRL. To support the development of these models, many institutions make datasets publicly available with open-source licenses, but these datasets are at risk of potential misuse or infringement. Injecting watermarks to the dataset may protect the intellectual property of the data, but it cannot handle datasets that have already been published and is infeasible to be altered afterward. Other existing solutions, such as dataset inference and membership inference, do not work well in the offline DRL scenario due to the diverse model behavior characteristics and offline setting constraints.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2024-184-paper.pdf",
            "keywords": [
                "Offline Deep Reinforcement Learning",
                "Dataset Auditing",
                "Intellectual Property Protection",
                "Data Misuse",
                "Watermarking Challenges"
            ]
        },
        "url": "URL#358369"
    },
    {
        "@score": "1",
        "@id": "358370",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "20/5251",
                        "text": "Rui Duan"
                    },
                    {
                        "@pid": "48/2774",
                        "text": "Zhe Qu"
                    },
                    {
                        "@pid": "59/2353-3",
                        "text": "Leah Ding"
                    },
                    {
                        "@pid": "64/424-7",
                        "text": "Yao Liu 0007"
                    },
                    {
                        "@pid": "41/4718",
                        "text": "Zhuo Lu"
                    }
                ]
            },
            "title": "Parrot-Trained Adversarial Examples: Pushing the Practicality of Black-Box Audio Attacks against Speaker Recognition Models.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/DuanQD0L24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/parrot-trained-adversarial-examples-pushing-the-practicality-of-black-box-audio-attacks-against-speaker-recognition-models/",
            "url": "https://dblp.org/rec/conf/ndss/DuanQD0L24",
            "abstract": "Audio adversarial examples (AEs) have posed significant security challenges to real-world speaker recognition systems. Most black-box attacks still require certain information from the speaker recognition model to be effective (e.g., keeping probing and requiring the knowledge of similarity scores). This work aims to push the practicality of the black-box attacks by minimizing the attacker's knowledge about a target speaker recognition model. Although it is not feasible for an attacker to succeed with completely zero knowledge, we assume that the attacker only knows a short (or a few seconds) speech sample of a target speaker. Without any probing to gain further knowledge about the target model, we propose a new mechanism, called parrot training, to generate AEs against the target model. Motivated by recent advancements in voice conversion, we propose to use the one short sentence knowledge to generate more synthetic speech samples that sound like the target speaker, called parrot speech. Then, we use these parrot speech samples to train a parrot-trained (PT) surrogate model for the attacker. Under a joint transferability and perception framework, we investigate different ways to generate AEs on the PT model (called PT-AEs) to ensure the PT-AEs can be generated with high transferability to a black-box target model with good human perceptual quality. Real-world experiments show that the resultant PT-AEs achieve the attack success rates of 45.8%-80.8% against the open-source models in the digital-line scenario and 47.9%-58.3% against smart devices, including Apple HomePod (Siri), Amazon Echo, and Google Home, in the over-the-air scenario.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2024-545-paper.pdf",
            "keywords": [
                "Audio Adversarial Examples",
                "Speaker Recognition",
                "Black-Box Attacks",
                "Parrot Training",
                "Transferability"
            ]
        },
        "url": "URL#358370",
        "sema_paperId": "5d603433c86d72709e9e03ba1157b21a64c8fc2b"
    },
    {
        "@score": "1",
        "@id": "358371",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "160/7653",
                        "text": "Shahriar Ebrahimi"
                    },
                    {
                        "@pid": "382/0119",
                        "text": "Parisa Hassanizadeh"
                    }
                ]
            },
            "title": "From Interaction to Independence: zkSNARKs for Transparent and Non-Interactive Remote Attestation.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/EbrahimiH24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/from-interaction-to-independence-zksnarks-for-transparent-and-non-interactive-remote-attestation/",
            "url": "https://dblp.org/rec/conf/ndss/EbrahimiH24",
            "abstract": "Remote attestation (RA) protocols have been widely used to evaluate the integrity of software on remote devices. Currently, the state-of-the-art RA protocols lack a crucial feature: transparency. This means that the details of the final attestation verification are not openly accessible or verifiable by the public. Furthermore, the interactivity of these protocols often limits attestation to trusted parties who possess privileged access to confidential device data, such as pre-shared keys and initial measurements. These constraints impede the widespread adoption of these protocols in various applications.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2024-815-paper.pdf",
            "keywords": [
                "Remote Attestation",
                "Transparency",
                "zkSNARKs",
                "Non-Interactive Protocols",
                "Integrity Verification"
            ]
        },
        "url": "URL#358371"
    },
    {
        "@score": "1",
        "@id": "358372",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "318/9454",
                        "text": "Hossam ElAtali"
                    },
                    {
                        "@pid": "131/6896",
                        "text": "Lachlan J. Gunn"
                    },
                    {
                        "@pid": "188/5871",
                        "text": "Hans Liljestrand"
                    },
                    {
                        "@pid": "39/2508",
                        "text": "N. Asokan"
                    }
                ]
            },
            "title": "BliMe: Verifiably Secure Outsourced Computation with Hardware-Enforced Taint Tracking.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ElAtaliGLA24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/blime-verifiably-secure-outsourced-computation-with-hardware-enforced-taint-tracking/",
            "url": "https://dblp.org/rec/conf/ndss/ElAtaliGLA24",
            "abstract": "Outsourced computing is widely used today. However, current approaches for protecting client data in outsourced computing fall short: use of cryptographic techniques like fully-homomorphic encryption incurs substantial costs, whereas use of hardware-assisted trusted execution environments has been shown to be vulnerable to run-time and side-channel attacks.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2024-105-paper.pdf",
            "keywords": [
                "Outsourced Computation",
                "Taint Tracking",
                "Trusted Execution Environments",
                "Data Protection",
                "Side-Channel Attacks"
            ]
        },
        "url": "URL#358372"
    },
    {
        "@score": "1",
        "@id": "358373",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "151/8708",
                        "text": "Hossein Fereidooni"
                    },
                    {
                        "@pid": "344/3222",
                        "text": "Alessandro Pegoraro"
                    },
                    {
                        "@pid": "283/4641",
                        "text": "Phillip Rieger"
                    },
                    {
                        "@pid": "67/8264",
                        "text": "Alexandra Dmitrienko"
                    },
                    {
                        "@pid": "s/AhmadRezaSadeghi",
                        "text": "Ahmad-Reza Sadeghi"
                    }
                ]
            },
            "title": "FreqFed: A Frequency Analysis-Based Approach for Mitigating Poisoning Attacks in Federated Learning.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/FereidooniPRDS24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/freqfed-a-frequency-analysis-based-approach-for-mitigating-poisoning-attacks-in-federated-learning/",
            "url": "https://dblp.org/rec/conf/ndss/FereidooniPRDS24",
            "abstract": "Federated learning (FL) is a collaborative learning paradigm allowing multiple clients to jointly train a model without sharing their training data. However, FL is susceptible to poisoning attacks, in which the adversary injects manipulated model updates into the federated model aggregation process to corrupt or destroy predictions (untargeted poisoning) or implant hidden functionalities (targeted poisoning or backdoors). Existing defenses against poisoning attacks in FL have several limitations, such as relying on specific assumptions about attack types and strategies or data distributions or not sufficiently robust against advanced injection techniques and strategies and simultaneously maintaining the utility of the aggregated model. To address the deficiencies of existing defenses, we take a generic and completely different approach to detect poisoning (targeted and untargeted) attacks. We present FreqFed, a novel aggregation mechanism that transforms the model updates (i.e., weights) into the frequency domain, where we can identify the core frequency components that inherit sufficient information about weights. This allows us to effectively filter out malicious updates during local training on the clients, regardless of attack types, strategies, and clients' data distributions. We extensively evaluate the efficiency and effectiveness of FreqFed in different application domains, including image classification, word prediction, IoT intrusion detection, and speech recognition. We demonstrate that FreqFed can mitigate poisoning attacks effectively with a negligible impact on the utility of the aggregated model.",
            "keywords": [
                "Federated Learning",
                "Poisoning Attacks",
                "Model Aggregation",
                "Frequency Analysis",
                "Malicious Updates"
            ]
        },
        "url": "URL#358373",
        "sema_paperId": "df5926b4f9d193eb3cc0f1141957b07c119d3950"
    },
    {
        "@score": "1",
        "@id": "358374",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "199/8537",
                        "text": "Clement Fung"
                    },
                    {
                        "@pid": "202/7659",
                        "text": "Eric Zeng"
                    },
                    {
                        "@pid": "32/3440",
                        "text": "Lujo Bauer"
                    }
                ]
            },
            "title": "Attributions for ML-based ICS Anomaly Detection: From Theory to Practice.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/FungZB24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/attributions-for-ml-based-ics-anomaly-detection-from-theory-to-practice/",
            "url": "https://dblp.org/rec/conf/ndss/FungZB24",
            "abstract": "\u2014Industrial Control Systems (ICS) govern critical infrastructure like power plants and water treatment plants. ICS can be attacked through manipulations of its sensor or actuator values, causing physical harm. A promising technique for detecting such attacks is machine-learning-based anomaly detection, but it does not identify which sensor or actuator was manipulated and makes it difficult for ICS operators to diagnose the anomaly\u2019s root cause. Prior work has proposed using attribution methods to identify what features caused an ICS anomaly-detection model to raise an alarm, but it is unclear how well these attribution methods work in practice. In this paper, we compare state-of-the-art attribution methods for the ICS domain with real attacks from multiple datasets. We find that attribution methods for ICS anomaly detection do not perform as well as suggested in prior work and identify two main reasons. First, anomaly detectors often detect attacks either immediately or significantly after the attack start; we find that attributions computed at these detection points are inaccurate. Second, attribution accuracy varies greatly across attack properties, and attribution methods struggle with attacks on categorical-valued actuators. Despite these challenges, we find that ensembles of attributions can compensate for weaknesses in individual attribution methods.",
            "keywords": [
                "Industrial Control Systems",
                "Anomaly Detection",
                "Attribution Methods",
                "Attack Detection",
                "Sensor Manipulation"
            ]
        },
        "url": "URL#358374",
        "sema_paperId": "acbab58b9480db9e34e5c0098f5cf2565de7a310"
    },
    {
        "@score": "1",
        "@id": "358375",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "263/9668",
                        "text": "Zicong Gao"
                    },
                    {
                        "@pid": "94/3019-8",
                        "text": "Chao Zhang 0008"
                    },
                    {
                        "@pid": "385/6824",
                        "text": "Hangtian Liu"
                    },
                    {
                        "@pid": "384/3951",
                        "text": "Wenhou Sun"
                    },
                    {
                        "@pid": "385/8038",
                        "text": "Zhizhuo Tang"
                    },
                    {
                        "@pid": "52/7938",
                        "text": "Liehui Jiang"
                    },
                    {
                        "@pid": "20/1036-5",
                        "text": "Jianjun Chen 0005"
                    },
                    {
                        "@pid": "06/2422",
                        "text": "Yong Xie"
                    }
                ]
            },
            "title": "Faster and Better: Detecting Vulnerabilities in Linux-based IoT Firmware with Optimized Reaching Definition Analysis.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/Gao0LSTJ0X24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/faster-and-better-detecting-vulnerabilities-in-linux-based-iot-firmware-with-optimized-reaching-definition-analysis/",
            "url": "https://dblp.org/rec/conf/ndss/Gao0LSTJ0X24",
            "abstract": "\u2014IoT devices are often found vulnerable, i.e., un-trusted inputs may trigger potential vulnerabilities and flow to sensitive operations in the firmware, which could cause severe damage. As such vulnerabilities are in general taint-style, a promising solution to find them is static taint analysis. However, existing solutions have limited e ffi ciency and e ff ectiveness. In this paper, we propose a new e ffi cient and e ff ective taint analysis solution, namely HermeScan, to discover such vulnerabilities, which utilizes reaching definition analysis (RDA) to conduct taint analysis and gets much fewer false negatives, false positives, and time costs. We have implemented a prototype of HermeScan and conducted a thorough evaluation on two datasets, i.e., one 0-day dataset with 30 latest firmware and one N-day dataset with 98 older firmware, and compared with two state-of-the-art (SOTA) solutions, i.e., KARONTE and SaTC. In terms of e ff ectiveness, HermeScan, SaTC, and KARONTE find 163, 32, and 0 vulnerabilities in the 0-day dataset respectively. In terms of accuracy, the true positive rates of HermeScan, SaTC, and KARONTE are 81%, 42%, and 0% in the 0-day dataset. In terms of e ffi ciency, HermeScan is 7.5X and 3.8X faster than SaTC and KARONTE on average in finding 0-day vulnerabilities.",
            "keywords": [
                "IoT Firmware Security",
                "Static Taint Analysis",
                "Vulnerability Detection",
                "Reaching Definition Analysis",
                "HermeScan"
            ]
        },
        "url": "URL#358375",
        "sema_paperId": "b0c89d6af392758abab13e5f88c6e28608def8e1"
    },
    {
        "@score": "1",
        "@id": "358376",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "119/0646",
                        "text": "Lian Gao"
                    },
                    {
                        "@pid": "70/7820",
                        "text": "Yu Qu"
                    },
                    {
                        "@pid": "181/2830",
                        "text": "Sheng Yu"
                    },
                    {
                        "@pid": "10/9994",
                        "text": "Yue Duan"
                    },
                    {
                        "@pid": "77/6178-1",
                        "text": "Heng Yin 0001"
                    }
                ]
            },
            "title": "SigmaDiff: Semantics-Aware Deep Graph Matching for Pseudocode Diffing.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/GaoQYD024",
            "ee": "https://www.ndss-symposium.org/ndss-paper/sigmadiff-semantics-aware-deep-graph-matching-for-pseudocode-diffing/",
            "url": "https://dblp.org/rec/conf/ndss/GaoQYD024",
            "abstract": "\u2014Pseudocode dif\ufb01ng precisely locates similar parts and captures differences between the decompiled pseudocode of two given binaries. It is particularly useful in many security scenarios such as code plagiarism detection, lineage analysis, patch, vulnerability analysis, etc. However, existing pseudocode dif\ufb01ng and binary dif\ufb01ng tools suffer from low accuracy and poor scalability, since they either rely on manually-designed heuristics (e.g., Diaphora) or heavy computations like matrix factorization (e.g., DeepBinDiff). To address the limitations, in this paper, we propose a semantics-aware, deep neural network-based model called S IGMA D IFF . S IGMA D IFF \ufb01rst constructs IR (Intermediate Representation) level interprocedural program dependency graphs (IPDGs). Then it uses a lightweight symbolic analysis to extract initial node features and locate training nodes for the neural network model. S IGMA D IFF then leverages the state-of-the-art graph matching model called Deep Graph Matching Consensus (DGMC) to match the nodes in IPDGs. S IGMA D IFF also introduces several important updates to the design of DGMC such as the pre-training and \ufb01ne-tuning schema. Experimental results show that S IGMA D IFF signi\ufb01cantly outperforms the state-of-the-art heuristic-based and deep learning-based techniques in terms of both accuracy and ef\ufb01ciency. It is able to precisely pinpoint eight vulnerabilities in a widely-used video conferencing application.",
            "keywords": [
                "Pseudocode Diffing",
                "Binary Analysis",
                "Program Dependency Graphs",
                "Vulnerability Detection",
                "Deep Graph Matching"
            ]
        },
        "url": "URL#358376",
        "sema_paperId": "f8bc101842cdd16e687beb69f5799da9a99c409b"
    },
    {
        "@score": "1",
        "@id": "358377",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "207/6560",
                        "text": "Syed Mahbub Hafiz"
                    },
                    {
                        "@pid": "372/4273",
                        "text": "Chitrabhanu Gupta"
                    },
                    {
                        "@pid": "372/3238",
                        "text": "Warren Wnuck"
                    },
                    {
                        "@pid": "354/9612",
                        "text": "Brijesh Vora"
                    },
                    {
                        "@pid": "47/4465",
                        "text": "Chen-Nee Chuah"
                    }
                ]
            },
            "title": "Private Aggregate Queries to Untrusted Databases.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/HafizGWVC24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/private-aggregate-queries-to-untrusted-databases/",
            "url": "https://dblp.org/rec/conf/ndss/HafizGWVC24",
            "abstract": "An essential part of ensuring privacy for internet service users is to protect what data they access so that the database host cannot infer sensitive information (e.g., political affiliation, sexual orientation, etc.) from the query pattern to exploit it or share it with third parties. Often, database users submit aggregate queries (e.g., SUM, MEAN, etc.) with searching and filtering constraints to extract statistically meaningful information from a database by seeking the privacy of its query's sensitive values and database interactions. Private information retrieval (PIR), a privacy-preserving cryptographic tool, solves a simplified version of this problem by hiding the database item that a client accesses. Most PIR protocols require the client to know the exact row index of the intended database item, which cannot support the complicated aggregation-based statistical query in a similar setting. Some works in the PIR space contain keyword searching and SQL-like queries, but most need multiple interactions between the PIR client and PIR servers. Some schemes support searching SQL-like expressive queries in a single round but fail to enable aggregate queries. These schemes are the main focus of this paper. To bridge the gap, we have built a general-purpose novel information-theoretic PIR (IT-PIR) framework that permits a user to fetch the aggregated result, hiding all sensitive sections of the complex query from the hosting PIR server in a single round of interaction. In other words, the server will not know which records contribute to the aggregation. We then evaluate the feasibility of our protocol for both benchmarking and real-world application settings. For instance, in a complex aggregate query to the Twitter microblogging database of $1$ million tweets, our protocol takes $0.014$ seconds for a PIR server to generate the result when the user is interested in one of ~$3k$ user handles. In contrast, for a much-simplified task, not an aggregate but a positional query, Goldberg's regular IT-PIR (Oakland 2007) takes $1.13$ seconds. For all possible user handles, $300k$, it takes equal time compared to the regular IT-PIR. This example shows that complicated aggregate queries through our framework do not incur additional overhead if not less, compared to the conventional query.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2024-1211-paper.pdf",
            "keywords": [
                "Private Information Retrieval",
                "Aggregate Queries",
                "Privacy-Preserving Cryptography",
                "Untrusted Databases",
                "Information-Theoretic PIR"
            ]
        },
        "url": "URL#358377"
    },
    {
        "@score": "1",
        "@id": "358378",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "49/7449",
                        "text": "Marian Harbach"
                    },
                    {
                        "@pid": "52/8356",
                        "text": "Igor Bilogrevic"
                    },
                    {
                        "@pid": "162/1919",
                        "text": "Enrico Bacis"
                    },
                    {
                        "@pid": "227/2228",
                        "text": "Serena Chen"
                    },
                    {
                        "@pid": "385/8941",
                        "text": "Ravjit Uppal"
                    },
                    {
                        "@pid": "385/7679",
                        "text": "Andy Paicu"
                    },
                    {
                        "@pid": "385/8894",
                        "text": "Elias Klim"
                    },
                    {
                        "@pid": "301/5805",
                        "text": "Meggyn Watkins"
                    },
                    {
                        "@pid": "301/5887",
                        "text": "Balazs Engedy"
                    }
                ]
            },
            "title": "Don&apos;t Interrupt Me - A Large-Scale Study of On-Device Permission Prompt Quieting in Chrome.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/HarbachBBCUPKWE24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/dont-interrupt-me-a-large-scale-study-of-on-device-permission-prompt-quieting-in-chrome/",
            "url": "https://dblp.org/rec/conf/ndss/HarbachBBCUPKWE24",
            "abstract": "\u2014A recent large-scale experiment conducted by Chrome [4] has demonstrated that a \u201cquieter\u201d web permission prompt can reduce unwanted interruptions while only marginally affecting grant rates. However, the experiment and the partial roll-out were missing two important elements: (1) an effective and context-aware activation mechanism for such a quieter prompt, and (2) an analysis of user attitudes and sentiment towards such an intervention. In this paper, we address these two limitations by means of a novel ML-based activation mechanism \u2013 and its real-world on-device deployment in Chrome \u2013 and a large-scale user study with 13.1k participants from 156 countries. First, the telemetry-based results, computed on more than 20 million samples from Chrome users in-the-wild, indicate that the novel on-device ML-based approach is both extremely precise ( > 99% post-hoc precision) and has very high coverage (96% recall for noti\ufb01cations permission). Second, our large-scale, in-context user study shows that quieting is often perceived as helpful and does not cause high levels of unease for most respondents.",
            "keywords": [
                "Web Permission Prompts",
                "User Experience",
                "On-Device Activation",
                "User Sentiment",
                "Interruption Reduction"
            ]
        },
        "url": "URL#358378",
        "sema_paperId": "635f9dd0a8b587e6ff1c379f2b1bc9aed372e5ea"
    },
    {
        "@score": "1",
        "@id": "358379",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "306/1330",
                        "text": "Chaoxiang He"
                    },
                    {
                        "@pid": "45/7549",
                        "text": "Xiaojing Ma 0002"
                    },
                    {
                        "@pid": "85/5693",
                        "text": "Bin B. Zhu"
                    },
                    {
                        "@pid": "385/8280",
                        "text": "Yimiao Zeng"
                    },
                    {
                        "@pid": "156/5179",
                        "text": "Hanqing Hu"
                    },
                    {
                        "@pid": "384/4279",
                        "text": "Xiaofan Bai"
                    },
                    {
                        "@pid": "98/4156",
                        "text": "Hai Jin 0001"
                    },
                    {
                        "@pid": "87/461-1",
                        "text": "Dongmei Zhang 0001"
                    }
                ]
            },
            "title": "DorPatch: Distributed and Occlusion-Robust Adversarial Patch to Evade Certifiable Defenses.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/He0ZZHB0024",
            "ee": "https://www.ndss-symposium.org/ndss-paper/dorpatch-distributed-and-occlusion-robust-adversarial-patch-to-evade-certifiable-defenses/",
            "url": "https://dblp.org/rec/conf/ndss/He0ZZHB0024",
            "abstract": "\u2014Adversarial patch attacks are among the most practical adversarial attacks. Recent efforts focus on providing a certifiable guarantee on correct predictions in the presence of white-box adversarial patch attacks. In this paper, we propose DorPatch, an effective adversarial patch attack to evade both certifiably robust defenses and empirical defenses. DorPatch employs group lasso on a patch\u2019s mask, image dropout, density regularization, and structural loss to generate a fully optimized, distributed, occlusion-robust, and inconspicuous adversarial patch that can be deployed in physical-world adversarial patch attacks. Our extensive experimental evaluation with both digital-domain and physical-world tests indicates that DorPatch can effectively evade PatchCleanser [64], the state-of-the-art certifiable defense, and empirical defenses against adversarial patch attacks. More critically, mispredicted results of adversarially patched examples generated by DorPatch can receive certification from PatchCleanser, producing a false trust in guaranteed predictions. DorPatch achieves state-of-the-art attacking performance and perceptual quality among all adversarial patch attacks. DorPatch poses a significant threat to real-world applications of DNN models and calls for developing effective defenses to thwart the attack.",
            "keywords": [
                "Adversarial Patch Attacks",
                "Certifiable Defenses",
                "Occlusion-Robustness",
                "Distributed Optimization",
                "False Trust in Predictions"
            ]
        },
        "url": "URL#358379",
        "sema_paperId": "18668a78c8811eaeae38e2bbc21b21576441579a"
    },
    {
        "@score": "1",
        "@id": "358380",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "262/1641",
                        "text": "Anxiao He"
                    },
                    {
                        "@pid": "340/0030",
                        "text": "Jiandong Fu"
                    },
                    {
                        "@pid": "14/3799",
                        "text": "Kai Bu"
                    },
                    {
                        "@pid": "381/0143",
                        "text": "Ruiqi Zhou"
                    },
                    {
                        "@pid": "288/4087",
                        "text": "Chenlu Miao"
                    },
                    {
                        "@pid": "20/6179-1",
                        "text": "Kui Ren 0001"
                    }
                ]
            },
            "title": "Symphony: Path Validation at Scale.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/HeFBZM024",
            "ee": "https://www.ndss-symposium.org/ndss-paper/symphony-path-validation-at-scale/",
            "url": "https://dblp.org/rec/conf/ndss/HeFBZM024",
            "abstract": "\u2014Path validation has long been explored as a fundamental solution to secure future Internet architectures. It enables end-hosts to specify forwarding paths for their traffic and to verify whether the traffic follows the specified paths. In comparison with the current Internet architecture that keeps packet forwarding uncontrolled and transparent to end-hosts, path validation benefits end-hosts with flexibility, security, and privacy. The key design enforces routers to embed their credentials into cryptographic proofs in packet headers. Such proofs require sufficiently complex computation to guarantee unforgeability. This imposes an inevitable barrier on validation efficiency for a single packet. In this paper, we propose aggregate validation to implement path validation in a group-wise way. Amortizing overhead across packets in a group, aggregate validation promises higher validation efficiency without sacrificing security. We implement aggregation validation through Symphony, with various design techniques integrated and security properties formally proved. In comparison with state-of-the-art EPIC, Symphony speeds up packet processing by 3.78 \u00d7\u223c 18.40 \u00d7 and increases communication throughput by 1.13 \u00d7\u223c 6.11 \u00d7 .",
            "keywords": [
                "Path Validation",
                "Internet Architecture",
                "Aggregate Validation",
                "Packet Processing Efficiency",
                "Cryptographic Proofs"
            ]
        },
        "url": "URL#358380",
        "sema_paperId": "d95aede8cbd28d2ddd57f9b8614fded5a0fbcaf4"
    },
    {
        "@score": "1",
        "@id": "358381",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "204/2257",
                        "text": "Fannv He"
                    },
                    {
                        "@pid": "230/3262",
                        "text": "Yan Jia"
                    },
                    {
                        "@pid": "172/1704",
                        "text": "Jiayu Zhao"
                    },
                    {
                        "@pid": "92/4710",
                        "text": "Yue Fang"
                    },
                    {
                        "@pid": "217/2370",
                        "text": "Jice Wang"
                    },
                    {
                        "@pid": "325/4107",
                        "text": "Mengyue Feng"
                    },
                    {
                        "@pid": "21/6121-5",
                        "text": "Peng Liu 0005"
                    },
                    {
                        "@pid": "83/6530-1",
                        "text": "Yuqing Zhang 0001"
                    }
                ]
            },
            "title": "Maginot Line: Assessing a New Cross-app Threat to PII-as-Factor Authentication in Chinese Mobile Apps.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/HeJZFWF0024",
            "ee": "https://www.ndss-symposium.org/ndss-paper/maginot-line-assessing-a-new-cross-app-threat-to-pii-as-factor-authentication-in-chinese-mobile-apps/",
            "url": "https://dblp.org/rec/conf/ndss/HeJZFWF0024",
            "abstract": "\u2014Authentication is one of the established practices to ensure user security. Personally identifiable information (PII), such as national identity card number (ID number) and bank card number, is used widely in China\u2019s mobile apps as an additional secret to authenticate users, i.e., PII-as-Factor Au-thentication ( PaFA ). In this paper, we found a new threat that calls on the cautiousness of PaFA : the simultaneous usages and business-related interactions of apps make the authentication strength of a target app weaker than designed. An adversary, who knows fewer authentication factors (only SMS OTP) than a PaFA system required, can break the authentication by gathering information or abusing cross-app authorization from other apps. To systematically study the potential risks, we proposed a semi-automatic system, MAGGIE , to evaluate the security of PaFA in target apps. By measuring 234 real-world apps in Chinese app markets with the help of MAGGIE , we found 75.4% of apps that deployed PaFA can be bypassed, including the popular and sensitive ones (e.g., AliPay, WeChat, UnionPay), leading to severe consequences like hijack user accounts and making unauthorized purchases. Additionally, we conducted a survey to demonstrate the practical implications of the new risk on users. Finally, we reported our findings to the vendors and provided several mitigation measures.",
            "keywords": [
                "Mobile App Security",
                "PII-as-Factor Authentication",
                "Cross-App Threats",
                "Authentication Bypass",
                "User Account Hijacking"
            ]
        },
        "url": "URL#358381",
        "sema_paperId": "011e5d6f4c38a5a9770637f092357910940d3120"
    },
    {
        "@score": "1",
        "@id": "358382",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "279/6684",
                        "text": "Ashish Hooda"
                    },
                    {
                        "@pid": "312/2370",
                        "text": "Andrey Labunets"
                    },
                    {
                        "@pid": "k/TadayoshiKohno",
                        "text": "Tadayoshi Kohno"
                    },
                    {
                        "@pid": "16/10817",
                        "text": "Earlence Fernandes"
                    }
                ]
            },
            "title": "Experimental Analyses of the Physical Surveillance Risks in Client-Side Content Scanning.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/HoodaLKF24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/experimental-analyses-of-the-physical-surveillance-risks-in-client-side-content-scanning/",
            "url": "https://dblp.org/rec/conf/ndss/HoodaLKF24",
            "abstract": "\u2014 Content scanning systems employ perceptual hashing algorithms to scan user content for illicit material, such as child pornography or terrorist recruitment flyers. Perceptual hashing algorithms help determine whether two images are visually similar while preserving the privacy of the input images. Several efforts from industry and academia propose scanning on client devices such as smartphones due to the impending rollout of end-to-end encryption that will make server-side scanning difficult. These proposals have met with strong criticism because of the potential for the technology to be misused for censorship. However, the risks of this technology in the context of surveillance are not well understood. Our work informs this conversation by experimentally characterizing the potential for one type of misuse \u2014 attackers manipulating the content scanning system to perform physical surveillance on target locations. Our contributions are threefold: (1) we offer a definition of physical surveillance in the context of client-side image scanning systems; (2) we experimentally characterize this risk and create a surveillance algorithm that achieves physical surveillance rates more than 30% by poisoning 0.2% of the perceptual hash database; (3) we experimentally study the trade-off between the robustness of client-side image scanning systems and surveillance, showing that more robust detection of illicit material leads to an increased potential for physical surveillance in most settings.",
            "keywords": [
                "Client-Side Content Scanning",
                "Perceptual Hashing",
                "Physical Surveillance",
                "Content Scanning Misuse",
                "Surveillance Algorithm"
            ]
        },
        "url": "URL#358382",
        "sema_paperId": "bb9a682380e5d95402dfdf3a772c27be06faf924"
    },
    {
        "@score": "1",
        "@id": "358383",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "122/0826",
                        "text": "Hongsheng Hu"
                    },
                    {
                        "@pid": "63/1591-12",
                        "text": "Shuo Wang 0012"
                    },
                    {
                        "@pid": "342/7693",
                        "text": "Jiamin Chang"
                    },
                    {
                        "@pid": "228/2099",
                        "text": "Haonan Zhong"
                    },
                    {
                        "@pid": "72/7683-1",
                        "text": "Ruoxi Sun 0001"
                    },
                    {
                        "@pid": "07/6713-1",
                        "text": "Shuang Hao 0001"
                    },
                    {
                        "@pid": "22/5702",
                        "text": "Haojin Zhu"
                    },
                    {
                        "@pid": "166/1912",
                        "text": "Minhui Xue 0001"
                    }
                ]
            },
            "title": "A Duty to Forget, a Right to be Assured? Exposing Vulnerabilities in Machine Unlearning Services.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/Hu0CZ00ZX24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/a-duty-to-forget-a-right-to-be-assured-exposing-vulnerabilities-in-machine-unlearning-services/",
            "url": "https://dblp.org/rec/conf/ndss/Hu0CZ00ZX24",
            "abstract": "The right to be forgotten requires the removal or\"unlearning\"of a user's data from machine learning models. However, in the context of Machine Learning as a Service (MLaaS), retraining a model from scratch to fulfill the unlearning request is impractical due to the lack of training data on the service provider's side (the server). Furthermore, approximate unlearning further embraces a complex trade-off between utility (model performance) and privacy (unlearning performance). In this paper, we try to explore the potential threats posed by unlearning services in MLaaS, specifically over-unlearning, where more information is unlearned than expected. We propose two strategies that leverage over-unlearning to measure the impact on the trade-off balancing, under black-box access settings, in which the existing machine unlearning attacks are not applicable. The effectiveness of these strategies is evaluated through extensive experiments on benchmark datasets, across various model architectures and representative unlearning approaches. Results indicate significant potential for both strategies to undermine model efficacy in unlearning scenarios. This study uncovers an underexplored gap between unlearning and contemporary MLaaS, highlighting the need for careful considerations in balancing data unlearning, model utility, and security.",
            "keywords": [
                "Machine Unlearning",
                "MLaaS",
                "Data Privacy",
                "Over-Unlearning",
                "Model Utility Trade-off"
            ]
        },
        "url": "URL#358383",
        "sema_paperId": "e717b642d0b03f6f241bcf76728d59625be2e83c"
    },
    {
        "@score": "1",
        "@id": "358384",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "277/8277",
                        "text": "Peiwei Hu"
                    },
                    {
                        "@pid": "232/3062",
                        "text": "Ruigang Liang"
                    },
                    {
                        "@pid": "c/KaiChen12",
                        "text": "Kai Chen 0012"
                    }
                ]
            },
            "title": "DeGPT: Optimizing Decompiler Output with LLM.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/HuL024",
            "ee": "https://www.ndss-symposium.org/ndss-paper/degpt-optimizing-decompiler-output-with-llm/",
            "url": "https://dblp.org/rec/conf/ndss/HuL024",
            "abstract": "\u2014Reverse engineering is essential in malware analysis, vulnerability discovery, etc. Decompilers assist the reverse engineers by lifting the assembly to the high-level programming language, which highly boosts binary comprehension. However, decompilers suffer from problems such as meaningless variable names, redundant variables, and lacking comments describing the purpose of the code. Previous studies have shown promising performance in refining the decompiler output by training the models with huge datasets containing various decompiler outputs. However, even datasets that take much time to construct cover limited binaries in the real world. The performance degrades severely facing the binary migration. In this paper, we present DeGPT, an end-to-end framework aiming to optimize the decompiler output to improve its readability and simplicity and further assist the reverse engineers in understanding the binaries better. The Large Language Model (LLM) can mitigate performance degradation with its extraordinary ability endowed by large model size and training set containing rich multi-modal data. However, its potential is difficult to unlock through one-shot use. Thus, we propose the three-role mechanism, which includes referee (R_ref), advisor (R_adv), and operator (R_ope), to adapt the LLM to our optimization tasks. Specifically, R_ref provides the optimization scheme for the target decompiler output, while R_adv gives the rectification measures based on the scheme, and R_ope inspects whether the optimization changes the original function semantics and concludes the final verdict about whether to accept the optimizations. We evaluate DeGPT on the datasets containing decompiler outputs of various software, such as the practical command line tools, malware, a library for audio processing, and implementations of algorithms. The experimental results show that even on the output of the current top-level decompiler (Ghidra), DeGPT can achieve 24.4% reduction in the cognitive burden of understanding the decompiler outputs and provide comments of which 62.9% can provide practical semantics for the reverse engineers to help the understanding of binaries. Our user surveys also show that the optimizations can significantly simplify the code and add helpful semantic information (variable names and comments), facilitating a quick and accurate understanding of the binary.",
            "keywords": [
                "Reverse Engineering",
                "Decompiler Optimization",
                "Binary Analysis",
                "Cognitive Burden Reduction",
                "Large Language Model (LLM)"
            ]
        },
        "url": "URL#358384",
        "sema_paperId": "32bb8b85124e554dd995e1c3a102eb921a710a99"
    },
    {
        "@score": "1",
        "@id": "358385",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "91/3734",
                        "text": "David Hunt"
                    },
                    {
                        "@pid": "342/7698",
                        "text": "Kristen Angell"
                    },
                    {
                        "@pid": "228/6004",
                        "text": "Zhenzhou Qi"
                    },
                    {
                        "@pid": "149/4695",
                        "text": "Tingjun Chen"
                    },
                    {
                        "@pid": "74/7446",
                        "text": "Miroslav Pajic"
                    }
                ]
            },
            "title": "MadRadar: A Black-Box Physical Layer Attack Framework on mmWave Automotive FMCW Radars.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/HuntAQCP24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/madradar-a-black-box-physical-layer-attack-framework-on-mmwave-automotive-fmcw-radars/",
            "url": "https://dblp.org/rec/conf/ndss/HuntAQCP24",
            "abstract": "Frequency modulated continuous wave (FMCW) millimeter-wave (mmWave) radars play a critical role in many of the advanced driver assistance systems (ADAS) featured on today's vehicles. While previous works have demonstrated (only) successful false-positive spoofing attacks against these sensors, all but one assumed that an attacker had the runtime knowledge of the victim radar's configuration. In this work, we introduce MadRadar, a general black-box radar attack framework for automotive mmWave FMCW radars capable of estimating the victim radar's configuration in real-time, and then executing an attack based on the estimates. We evaluate the impact of such attacks maliciously manipulating a victim radar's point cloud, and show the novel ability to effectively `add' (i.e., false positive attacks), `remove' (i.e., false negative attacks), or `move' (i.e., translation attacks) object detections from a victim vehicle's scene. Finally, we experimentally demonstrate the feasibility of our attacks on real-world case studies performed using a real-time physical prototype on a software-defined radio platform.",
            "keywords": [
                "Automotive Radar",
                "FMCW Radar",
                "Black-Box Attack",
                "Point Cloud Manipulation",
                "False Positive/Negative Attacks"
            ]
        },
        "url": "URL#358385",
        "sema_paperId": "260737db6f2dc2c556df94daeef73f61548d8343"
    },
    {
        "@score": "1",
        "@id": "358386",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "278/2709",
                        "text": "Deepak Sirone Jegan"
                    },
                    {
                        "@pid": "s/MichaelMSwift",
                        "text": "Michael M. Swift"
                    },
                    {
                        "@pid": "16/10817",
                        "text": "Earlence Fernandes"
                    }
                ]
            },
            "title": "Architecting Trigger-Action Platforms for Security, Performance and Functionality.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/JeganSF24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/architecting-trigger-action-platforms-for-security-performance-and-functionality/",
            "url": "https://dblp.org/rec/conf/ndss/JeganSF24",
            "abstract": "\u2014A Trigger-action platform (TAP) is a type of distributed system that allows end-users to create programs that stitch their web-based services together to achieve useful automation. For example, a program can be triggered when a new spreadsheet row is added, it can compute on that data and invoke an action, such as sending a message on Slack. Current TAP architectures require users to place complete trust in their secure operation. Experience has shown that unconditional trust in cloud services is unwarranted \u2014 an attacker who compromises the TAP cloud service will gain access to sensitive data and devices for millions of users. In this work, we re-architect TAPs so that users have to place minimal trust in the cloud. Specifically, we design and implement TAPDance, a TAP that guarantees confidentiality and integrity of program execution in the presence of an untrustworthy TAP service. We utilize RISC-V Keystone enclaves to enable these security guarantees while minimizing the trusted software and hardware base. Performance results indicate that TAPDance outperforms a baseline TAP implementation using Node.js with 32% lower latency and 33% higher throughput on average.",
            "keywords": [
                "Trigger-Action Platforms",
                "Cloud Security",
                "Confidentiality",
                "Integrity",
                "TAPDance"
            ]
        },
        "url": "URL#358386",
        "sema_paperId": "b89519bd8db825b18180289a569df4c66453cde7"
    },
    {
        "@score": "1",
        "@id": "358387",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "34/2005",
                        "text": "Bo Jiang"
                    },
                    {
                        "@pid": "58/2985",
                        "text": "Jian Du"
                    },
                    {
                        "@pid": "79/6531",
                        "text": "Qiang Yan"
                    }
                ]
            },
            "title": "AnonPSI: An Anonymity Assessment Framework for PSI.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/JiangDY24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/anonpsi-an-anonymity-assessment-framework-for-psi/",
            "url": "https://dblp.org/rec/conf/ndss/JiangDY24",
            "abstract": "Private Set Intersection (PSI) is a widely used protocol that enables two parties to securely compute a function over the intersected part of their shared datasets and has been a significant research focus over the years. However, recent studies have highlighted its vulnerability to Set Membership Inference Attacks (SMIA), where an adversary might deduce an individual's membership by invoking multiple PSI protocols. This presents a considerable risk, even in the most stringent versions of PSI, which only return the cardinality of the intersection. This paper explores the evaluation of anonymity within the PSI context. Initially, we highlight the reasons why existing works fall short in measuring privacy leakage, and subsequently propose two attack strategies that address these deficiencies. Furthermore, we provide theoretical guarantees on the performance of our proposed methods. In addition to these, we illustrate how the integration of auxiliary information, such as  the sum of payloads associated with members of the intersection (PSI-SUM), can enhance attack efficiency. We conducted a comprehensive performance evaluation of various attack strategies proposed utilizing two real datasets. Our findings indicate that the methods we propose markedly enhance attack efficiency when contrasted with previous research endeavors.  The effective attacking implies that depending solely on existing PSI protocols may not provide an adequate level of privacy assurance. It is recommended to combine privacy-enhancing technologies synergistically to enhance privacy protection even further.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2024-1279-paper.pdf",
            "keywords": [
                "Private Set Intersection",
                "Anonymity Assessment",
                "Set Membership Inference Attacks",
                "Privacy Leakage",
                "Auxiliary Information Integration"
            ]
        },
        "url": "URL#358387"
    },
    {
        "@score": "1",
        "@id": "358388",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "262/3567",
                        "text": "Qinhong Jiang"
                    },
                    {
                        "@pid": "169/4595",
                        "text": "Yanze Ren"
                    },
                    {
                        "@pid": "38/4289-2",
                        "text": "Yan Long 0002"
                    },
                    {
                        "@pid": "46/1162-1",
                        "text": "Chen Yan 0001"
                    },
                    {
                        "@pid": "385/7935",
                        "text": "Yumai Sun"
                    },
                    {
                        "@pid": "39/1697-1",
                        "text": "Xiaoyu Ji 0001"
                    },
                    {
                        "@pid": "f/KevinFu",
                        "text": "Kevin Fu"
                    },
                    {
                        "@pid": "10/3878-1",
                        "text": "Wenyuan Xu 0001"
                    }
                ]
            },
            "title": "GhostType: The Limits of Using Contactless Electromagnetic Interference to Inject Phantom Keys into Analog Circuits of Keyboards.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/JiangRL0S0F024",
            "ee": "https://www.ndss-symposium.org/ndss-paper/ghosttype-the-limits-of-using-contactless-electromagnetic-interference-to-inject-phantom-keys-into-analog-circuits-of-keyboards/",
            "url": "https://dblp.org/rec/conf/ndss/JiangRL0S0F024",
            "abstract": "\u2014Keyboards are the primary peripheral input devices for various critical computer application scenarios. This paper performs a security analysis of the keyboard sensing mechanisms and uncovers a new class of vulnerabilities that can be exploited to induce phantom keys\u2014fake keystrokes injected into keyboards\u2019 analog circuits in a contactless way using electromagnetic interference (EMI). Besides regular keystrokes, such phantom keys also include keystrokes that human operators cannot achieve, such as rapidly injecting over 10,000 keys per minute and injecting hidden keys that do not exist on the physical keyboard. The underlying principles of phantom key injections consist in inducing false voltages on keyboard sensing GPIO pins through EMI coupled onto matrix circuits. We investigate the voltage and timing requirements of injection signals both theoretically and empirically to establish the theory of phantom key injection. To validate the threat of keyboard sensing vulnerabilities, we design GhostType that can cause denial-of-service of the keyboard and inject random keystrokes as well as certain targeted keystrokes of the adversary\u2019s choice. We have validated GhostType on 48 of 50 off-the-shelf keyboards/keypads from 20 brands, including both membrane/mechanical structures and USB/Bluetooth protocols. Some example consequences of GhostType include completely blocking keyboard operations, crashing and turning off down-stream computers, and deleting computer files. Finally, we glean lessons from our investigations and propose countermeasures, including shielding keyboards with metal materials and enhancing the keystroke sensing mechanism.",
            "keywords": [
                "Keyboard Security",
                "Electromagnetic Interference",
                "Phantom Key Injection",
                "Analog Circuit Vulnerabilities",
                "Denial-of-Service Attack"
            ]
        },
        "url": "URL#358388",
        "sema_paperId": "6f1b2a89650efd8240af22d880830acc2ee4f33c"
    },
    {
        "@score": "1",
        "@id": "358389",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "222/0315",
                        "text": "Beomjin Jin"
                    },
                    {
                        "@pid": "185/1645",
                        "text": "Eunsoo Kim"
                    },
                    {
                        "@pid": "55/8846-1",
                        "text": "Hyunwoo Lee 0001"
                    },
                    {
                        "@pid": "b/ElisaBertino",
                        "text": "Elisa Bertino"
                    },
                    {
                        "@pid": "133/4707",
                        "text": "Doowon Kim"
                    },
                    {
                        "@pid": "64/5383",
                        "text": "Hyoungshick Kim"
                    }
                ]
            },
            "title": "Sharing cyber threat intelligence: Does it really help?",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/JinKLBKK24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/sharing-cyber-threat-intelligence-does-it-really-help/",
            "url": "https://dblp.org/rec/conf/ndss/JinKLBKK24",
            "abstract": "\u2014The sharing of Cyber Threat Intelligence (CTI) across organizations is gaining traction, as it can automate threat analysis and improve security awareness. However, limited empirical studies exist on the prevalent types of cybersecurity threat data and their effectiveness in mitigating cyber attacks. We propose a framework named CTI-Lense to collect and analyze the volume, timeliness, coverage, and quality of Structured Threat Information eXpression (STIX) data, a de facto standard CTI format, from a list of publicly available CTI sources. We collected about 6 million STIX data objects from October 31, 2014 to April 10, 2023 from ten data sources and analyzed their characteristics. Our analysis reveals that STIX data sharing has steadily increased in recent years, but the volume of STIX data shared is still relatively low to cover all cyber threats. Additionally, only a few types of threat data objects have been shared, with malware signatures and URLs accounting for more than 90% of the collected data. While URLs are usually shared promptly, with about 72% of URLs shared earlier than or on the same day as VirusTotal, the sharing of malware signatures is significantly slower. Furthermore, we found that 19% of the Threat actor data contained incorrect information, and only 0.09% of the Indicator data provided security rules to detect cyber attacks. Based on our findings, we recommend practical considerations for effective and scalable STIX data sharing among organizations.",
            "keywords": [
                "Cyber Threat Intelligence",
                "STIX Data",
                "Threat Data Sharing",
                "Malware Signatures",
                "Threat Actor Information"
            ]
        },
        "url": "URL#358389",
        "sema_paperId": "e7def8bedf3cac3db298c1524f96b69c308a43c0"
    },
    {
        "@score": "1",
        "@id": "358390",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "257/1302",
                        "text": "Minhyeok Kang"
                    },
                    {
                        "@pid": "213/7358",
                        "text": "Weitong Li"
                    },
                    {
                        "@pid": "155/5773",
                        "text": "Roland van Rijswijk-Deij"
                    },
                    {
                        "@pid": "14/2293-1",
                        "text": "Ted Taekyoung Kwon"
                    },
                    {
                        "@pid": "90/8396",
                        "text": "Taejoong Chung"
                    }
                ]
            },
            "title": "IRRedicator: Pruning IRR with RPKI-Valid BGP Insights.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/KangLRKC24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/irredicator-pruning-irr-with-rpki-valid-bgp-insights/",
            "url": "https://dblp.org/rec/conf/ndss/KangLRKC24",
            "abstract": "\u2014Border Gateway Protocol (BGP) provides a way of exchanging routing information to help routers construct their routing tables. However, due to the lack of security considerations, BGP has been suffering from vulnerabilities such as BGP hijacking attacks. To mitigate these issues, two data sources have been used, Internet Routing Registry (IRR) and Resource Public Key Infrastructure (RPKI), to provide reliable mappings between IP prefixes and their authorized Autonomous Systems (ASes). Each of the data sources, however, has its own limitations. IRR has been well-known for its stale Route objects with outdated AS information since network operators do not have enough incentives to keep them up to date, and RPKI has been slowly deployed due to its operational complexities. In this paper, we measure the prevalent inconsistencies between Route objects in IRR and ROA objects in RPKI. We next characterize inconsistent and consistent Route objects, respectively, by focusing on their BGP announcement patterns. Based on this insight, we develop a technique that identifies stale Route objects by leveraging a machine learning algorithm and evaluate its performance. From real trace-based experiments, we show that our technique can offer advantages against the status quo by reducing the percentage of potentially stale Route objects from 72% to 40% (of the whole IRR Route objects). In this way, we achieve 93% of the accuracy of validating BGP announcements while covering 87% of BGP announcements.",
            "keywords": [
                "BGP Routing",
                "RPKI",
                "IRR",
                "Route Object Staleness",
                "BGP Announcement Validation"
            ]
        },
        "url": "URL#358390",
        "sema_paperId": "cc32362ae4a37014faa47a0301b9059e69eecc86"
    },
    {
        "@score": "1",
        "@id": "358391",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "296/4778",
                        "text": "Tejas Kannan"
                    },
                    {
                        "@pid": "385/8099",
                        "text": "Synthia Qia Wang"
                    },
                    {
                        "@pid": "385/8309",
                        "text": "Max Sunog"
                    },
                    {
                        "@pid": "385/8577",
                        "text": "Abraham Bueno de Mesquita"
                    },
                    {
                        "@pid": "87/840",
                        "text": "Nick Feamster"
                    },
                    {
                        "@pid": "h/HenryHoffmann",
                        "text": "Henry Hoffmann"
                    }
                ]
            },
            "title": "Acoustic Keystroke Leakage on Smart Televisions.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/KannanWSMFH24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/acoustic-keystroke-leakage-on-smart-televisions/",
            "url": "https://dblp.org/rec/conf/ndss/KannanWSMFH24",
            "abstract": "\u2014Smart Televisions (TVs) are internet-connected TVs that support video streaming applications and web browsers. Users enter information into Smart TVs through on-screen virtual keyboards. These keyboards require users to navigate between keys with directional commands from a remote controller. Given the extensive functionality of Smart TVs, users type sensitive information (e.g., passwords) into these devices, making keystroke privacy necessary. This work develops and demonstrates a new side-channel attack that exposes keystrokes from the audio of two popular Smart TVs: Apple and Samsung. This side-channel attack exploits how Smart TVs make different sounds when selecting a key, moving the cursor, and deleting a character. These properties allow an attacker to extract the number of cursor movements between selections from the TV\u2019s audio. Our attack uses this extracted information to identify the likeliest typed strings. Against realistic users, the attack finds up to 33.33% of credit card details and 60.19% of common passwords within 100 guesses. This vulnerability has been acknowledged by Samsung and highlights how Smart TVs must better protect sensitive data.",
            "keywords": [
                "Smart Television Security",
                "Keystroke Leakage",
                "Side-Channel Attack",
                "Audio Analysis",
                "User Privacy"
            ]
        },
        "url": "URL#358391",
        "sema_paperId": "b254136d3d3fdba7e11a77ef5f2baa56b376cc8d"
    },
    {
        "@score": "1",
        "@id": "358392",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "318/4217",
                        "text": "Hugo Kermabon-Bobinnec"
                    },
                    {
                        "@pid": "24/5158",
                        "text": "Yosr Jarraya"
                    },
                    {
                        "@pid": "w/LingyuWang",
                        "text": "Lingyu Wang 0001"
                    },
                    {
                        "@pid": "175/5819",
                        "text": "Suryadipta Majumdar"
                    },
                    {
                        "@pid": "22/3167",
                        "text": "Makan Pourzandi"
                    }
                ]
            },
            "title": "Phoenix: Surviving Unpatched Vulnerabilities via Accurate and Efficient Filtering of Syscall Sequences.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/Kermabon-Bobinnec24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/phoenix-surviving-unpatched-vulnerabilities-via-accurate-and-efficient-filtering-of-syscall-sequences/",
            "url": "https://dblp.org/rec/conf/ndss/Kermabon-Bobinnec24",
            "abstract": "\u2014Known, but unpatched vulnerabilities represent one of the most concerning threats for businesses today. The average time-to-patch of zero-day vulnerabilities remains around 100 days in recent years. The lack of means to mitigate an unpatched vulnerability may force businesses to temporarily shut down their services, which can lead to significant financial loss. Existing solutions for filtering system calls unused by a container can effectively reduce the general attack surface, but cannot prevent a specific vulnerability that shares the same system calls with the container. On the other hand, existing provenance analysis solutions can help identify a sequence of system calls behind the vulnerability, although they do not provide a direct solution for filtering such a sequence. To bridge such a research gap, we propose Phoenix , a solution for preventing exploits of unpatched vulnerabilities by accurately and efficiently filtering sequences of system calls identified through provenance analysis. To achieve this, Phoenix cleverly combines the efficiency of Seccomp filters with the accuracy of Ptrace-based deep argument inspection, and it provides the novel capability of filtering system call sequences through a dynamic Seccomp design. Our implementation and experiments show that Phoenix can effectively mitigate real-world vulnerabilities which evade existing solutions, while introducing negligible delay (less than 4%) and less overhead (e.g., 98% less CPU consumption than existing solution).",
            "keywords": [
                "Unpatched Vulnerabilities",
                "Syscall Filtering",
                "Provenance Analysis",
                "Dynamic Seccomp Design",
                "Exploitation Mitigation"
            ]
        },
        "url": "URL#358392",
        "sema_paperId": "165abb2e97745e0f6edc6eccb7a2992583931f49"
    },
    {
        "@score": "1",
        "@id": "358393",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "309/7519",
                        "text": "Asbat El Khairi"
                    },
                    {
                        "@pid": "125/3305",
                        "text": "Marco Caselli"
                    },
                    {
                        "@pid": "43/8243",
                        "text": "Andreas Peter"
                    },
                    {
                        "@pid": "190/9885",
                        "text": "Andrea Continella"
                    }
                ]
            },
            "title": "REPLICAWATCHER: Training-less Anomaly Detection in Containerized Microservices.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/KhairiCPC24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/replicawatcher-training-less-anomaly-detection-in-containerized-microservices/",
            "url": "https://dblp.org/rec/conf/ndss/KhairiCPC24",
            "abstract": "\u2014Despite its detection capabilities against previously unseen threats, anomaly detection suffers from critical limitations, which often prevent its deployment in real-world settings. In fact, anomaly-based intrusion detection systems rely on comprehensive pre-established baselines for effectively identifying suspicious activities. Unfortunately, prior research showed that these baselines age and gradually lose their effectiveness over time, especially in dynamic deployments such as microservices-based environments, where the concept of \u201cnormality\u201d is frequently redefined due to shifting operational conditions. This scenario reinforces the need for periodic retraining to uphold optimal performance \u2014 a process that proves challenging, particularly in the context of security applications. We propose a novel, training-less approach to monitoring microservices-based environments. Our system, R EPLI - CA W ATCHER , observes the behavior of identical container instances (i.e., replicas ) and detects anomalies without requiring prior training. Our key insight is that replicas, adopted for fault tolerance or scalability reasons, execute analogous tasks and exhibit similar behavioral patterns, which allow anomalous containers to stand out as a notable deviation from their corresponding replicas, thereby serving as a crucial indicator of security threats. The results of our experimental evaluation show that our approach is resilient against normality shifts and maintains its effectiveness without the necessity for retraining. Besides, despite not relying on a training phase, R EPLICA W ATCHER performs comparably to state-of-the-art, training-based solutions, achieving an average precision of 91.08% and recall of 98.35%.",
            "keywords": [
                "Anomaly Detection",
                "Microservices",
                "Containerized Environments",
                "Training-less Monitoring",
                "Behavioral Patterns"
            ]
        },
        "url": "URL#358393",
        "sema_paperId": "c0bcd3e6d71c327fc64950f61f58c4c1b53d9fe5"
    },
    {
        "@score": "1",
        "@id": "358394",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "132/8044",
                        "text": "Hanna Kim"
                    },
                    {
                        "@pid": "41/5360",
                        "text": "Jian Cui"
                    },
                    {
                        "@pid": "294/0262",
                        "text": "Eugene Jang"
                    },
                    {
                        "@pid": "99/8883",
                        "text": "Chanhee Lee"
                    },
                    {
                        "@pid": "99/1170",
                        "text": "Yongjae Lee"
                    },
                    {
                        "@pid": "47/9656",
                        "text": "Jin-Woo Chung"
                    },
                    {
                        "@pid": "84/3319-1",
                        "text": "Seungwon Shin 0001"
                    }
                ]
            },
            "title": "DRAINCLoG: Detecting Rogue Accounts with Illegally-obtained NFTs using Classifiers Learned on Graphs.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/KimCJLLCS24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/drainclog-detecting-rogue-accounts-with-illegally-obtained-nfts-using-classifiers-learned-on-graphs/",
            "url": "https://dblp.org/rec/conf/ndss/KimCJLLCS24",
            "abstract": "As Non-Fungible Tokens (NFTs) continue to grow in popularity, NFT users have become targets of phishing attacks by cybercriminals, called \\textit{NFT drainers}. Over the last year, \\$100 million worth of NFTs were stolen by drainers, and their presence remains a serious threat to the NFT trading space. However, no work has yet comprehensively investigated the behaviors of drainers in the NFT ecosystem. In this paper, we present the first study on the trading behavior of NFT drainers and introduce the first dedicated NFT drainer detection system. We collect 127M NFT transaction data from the Ethereum blockchain and 1,135 drainer accounts from five sources for the year 2022. We find that drainers exhibit significantly different transactional and social contexts from those of regular users. With these insights, we design \\textit{DRAINCLoG}, an automatic drainer detection system utilizing Graph Neural Networks. This system effectively captures the multifaceted web of interactions within the NFT space through two distinct graphs: the NFT-User graph for transaction contexts and the User graph for social contexts. Evaluations using real-world NFT transaction data underscore the robustness and precision of our model. Additionally, we analyze the security of \\textit{DRAINCLoG} under a wide variety of evasion attacks.",
            "keywords": [
                "NFT Security",
                "Rogue Accounts",
                "Phishing Attacks",
                "Drainer Detection",
                "Graph Neural Networks"
            ]
        },
        "url": "URL#358394",
        "sema_paperId": "4e0a84f20de2ebf83a574a4668c346a932bb2642"
    },
    {
        "@score": "1",
        "@id": "358395",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "331/2127",
                        "text": "Torsten Krau\u00df"
                    },
                    {
                        "@pid": "339/7112",
                        "text": "Jan K\u00f6nig"
                    },
                    {
                        "@pid": "67/8264",
                        "text": "Alexandra Dmitrienko"
                    },
                    {
                        "@pid": "14/1362",
                        "text": "Christian Kanzow"
                    }
                ]
            },
            "title": "Automatic Adversarial Adaption for Stealthy Poisoning Attacks in Federated Learning.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/KraussKDK24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/automatic-adversarial-adaption-for-stealthy-poisoning-attacks-in-federated-learning/",
            "url": "https://dblp.org/rec/conf/ndss/KraussKDK24",
            "abstract": "\u2014Federated Learning (FL) enables the training of machine learning models using distributed data. This approach offers benefits such as improved data privacy, reduced communication costs, and enhanced model performance through increased data diversity. However, FL systems are vulnerable to poisoning attacks, where adversaries introduce malicious updates to compromise the integrity of the aggregated model. Existing defense strategies against such attacks include filtering, influence reduction, and robust aggregation techniques. Filtering approaches have the advantage of not reducing classification accuracy, but face the challenge of adversaries adapting to the defense mechanisms. The lack of a universally accepted definition of \u201cadaptive adversaries\u201d in the literature complicates the assessment of detection capabilities and meaningful comparisons of FL defenses. In this paper, we address the limitations of the commonly used definition of \u201cadaptive attackers\u201d proposed by Bagdasaryan et al. We propose AutoAdapt, a novel adaptation method that leverages an Augmented Lagrangian optimization technique. AutoAdapt eliminates the manual search for optimal hyper-parameters by providing a more rational alternative. It generates more effective solutions by accommodating multiple inequality constraints, allowing adaptation to valid value ranges within the defensive metrics. Our proposed method significantly enhances adversaries\u2019 capabilities and accelerates research in developing attacks and defenses. By accommodating multiple valid range constraints and adapting to diverse defense metrics, AutoAdapt challenges defenses relying on multiple metrics and expands the range of potential adversarial behaviors. Through comprehensive studies, we demonstrate the effectiveness of AutoAdapt in simultaneously adapting to multiple constraints and showcasing its power by accelerating the performance of tests by a factor of 15. Furthermore, we establish the versatility of AutoAdapt across various application scenarios, encompassing datasets, model architectures, and hyper-parameters, emphasizing its practical utility in real-world contexts. Overall, our contributions advance the evaluation of FL defenses and drive progress in this field.",
            "keywords": [
                "Federated Learning",
                "Poisoning Attacks",
                "Adaptive Adversaries",
                "AutoAdapt",
                "Augmented Lagrangian Optimization"
            ]
        },
        "url": "URL#358395",
        "sema_paperId": "e3f547a0f9c596d748c521e91680034bc912f16f"
    },
    {
        "@score": "1",
        "@id": "358396",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "124/3795",
                        "text": "Kavita Kumari"
                    },
                    {
                        "@pid": "344/3222",
                        "text": "Alessandro Pegoraro"
                    },
                    {
                        "@pid": "151/8708",
                        "text": "Hossein Fereidooni"
                    },
                    {
                        "@pid": "s/AhmadRezaSadeghi",
                        "text": "Ahmad-Reza Sadeghi"
                    }
                ]
            },
            "title": "DEMASQ: Unmasking the ChatGPT Wordsmith.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/KumariPFS24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/demasq-unmasking-the-chatgpt-wordsmith/",
            "url": "https://dblp.org/rec/conf/ndss/KumariPFS24",
            "abstract": "The potential misuse of ChatGPT and other Large Language Models (LLMs) has raised concerns regarding the dissemination of false information, plagiarism, academic dishonesty, and fraudulent activities. Consequently, distinguishing between AI-generated and human-generated content has emerged as an intriguing research topic. However, current text detection methods lack precision and are often restricted to specific tasks or domains, making them inadequate for identifying content generated by ChatGPT. In this paper, we propose an effective ChatGPT detector named DEMASQ, which accurately identifies ChatGPT-generated content. Our method addresses two critical factors: (i) the distinct biases in text composition observed in human and machine-generated content and (ii) the alterations made by humans to evade previous detection methods. DEMASQ is an energy-based detection model that incorporates novel aspects, such as (i) optimization inspired by the Doppler effect to capture the interdependence between input text embeddings and output labels, and (ii) the use of explainable AI techniques to generate diverse perturbations. To evaluate our detector, we create a benchmark dataset comprising a mixture of prompts from both ChatGPT and humans, encompassing domains such as medical, open Q&A, finance, wiki, and Reddit. Our evaluation demonstrates that DEMASQ achieves high accuracy in identifying content generated by ChatGPT.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2024-1190-paper.pdf",
            "keywords": [
                "ChatGPT Detection",
                "AI-generated Content",
                "Text Composition Biases",
                "Content Authenticity",
                "Explainable AI Techniques"
            ]
        },
        "url": "URL#358396"
    },
    {
        "@score": "1",
        "@id": "358397",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "04/8388",
                        "text": "Xinfeng Li"
                    },
                    {
                        "@pid": "46/1162-1",
                        "text": "Chen Yan 0001"
                    },
                    {
                        "@pid": "354/6407",
                        "text": "Xuancun Lu"
                    },
                    {
                        "@pid": "255/5534",
                        "text": "Zihan Zeng"
                    },
                    {
                        "@pid": "39/1697-1",
                        "text": "Xiaoyu Ji 0001"
                    },
                    {
                        "@pid": "10/3878-1",
                        "text": "Wenyuan Xu 0001"
                    }
                ]
            },
            "title": "Inaudible Adversarial Perturbation: Manipulating the Recognition of User Speech in Real Time.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/Li0LZ0024",
            "ee": "https://www.ndss-symposium.org/ndss-paper/inaudible-adversarial-perturbation-manipulating-the-recognition-of-user-speech-in-real-time/",
            "url": "https://dblp.org/rec/conf/ndss/Li0LZ0024",
            "abstract": "Automatic speech recognition (ASR) systems have been shown to be vulnerable to adversarial examples (AEs). Recent success all assumes that users will not notice or disrupt the attack process despite the existence of music/noise-like sounds and spontaneous responses from voice assistants. Nonetheless, in practical user-present scenarios, user awareness may nullify existing attack attempts that launch unexpected sounds or ASR usage. In this paper, we seek to bridge the gap in existing research and extend the attack to user-present scenarios. We propose VRIFLE, an inaudible adversarial perturbation (IAP) attack via ultrasound delivery that can manipulate ASRs as a user speaks. The inherent differences between audible sounds and ultrasounds make IAP delivery face unprecedented challenges such as distortion, noise, and instability. In this regard, we design a novel ultrasonic transformation model to enhance the crafted perturbation to be physically effective and even survive long-distance delivery. We further enable VRIFLE\u2019s robustness by adopting a series of augmentation on user and real-world variations during the generation process. In this way, VRIFLE features an effective real-time manipulation of the ASR output from different distances and under any speech of users, with an alter-and-mute strategy that suppresses the impact of user disruption. Our extensive experiments in both digital and physical worlds verify VRIFLE\u2019s effectiveness under various configurations, robustness against six kinds of defenses, and universality in a targeted manner. We also show that VRIFLE can be delivered with a portable attack device and even everyday-life loudspeakers.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2024-30-paper.pdf",
            "keywords": [
                "Automatic Speech Recognition",
                "Adversarial Examples",
                "Inaudible Perturbation",
                "Ultrasound Delivery",
                "Real-time Manipulation"
            ]
        },
        "url": "URL#358397"
    },
    {
        "@score": "1",
        "@id": "358398",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "251/7559",
                        "text": "Shaofei Li"
                    },
                    {
                        "@pid": "62/2555-8",
                        "text": "Feng Dong 0008"
                    },
                    {
                        "@pid": "13/9656",
                        "text": "Xusheng Xiao"
                    },
                    {
                        "@pid": "50/8499-1",
                        "text": "Haoyu Wang 0001"
                    },
                    {
                        "@pid": "84/11310",
                        "text": "Fei Shao"
                    },
                    {
                        "@pid": "352/4020",
                        "text": "Jiedong Chen"
                    },
                    {
                        "@pid": "07/6300-1",
                        "text": "Yao Guo 0001"
                    },
                    {
                        "@pid": "49/628",
                        "text": "Xiangqun Chen"
                    },
                    {
                        "@pid": "95/7132-1",
                        "text": "Ding Li 0001"
                    }
                ]
            },
            "title": "NODLINK: An Online System for Fine-Grained APT Attack Detection and Investigation.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/LiDXWSC0C024",
            "ee": "https://www.ndss-symposium.org/ndss-paper/nodlink-an-online-system-for-fine-grained-apt-attack-detection-and-investigation/",
            "url": "https://dblp.org/rec/conf/ndss/LiDXWSC0C024",
            "abstract": "Advanced Persistent Threats (APT) attacks have plagued modern enterprises, causing significant financial losses. To counter these attacks, researchers propose techniques that capture the complex and stealthy scenarios of APT attacks by using provenance graphs to model system entities and their dependencies. Particularly, to accelerate attack detection and reduce financial losses, online provenance-based detection systems that detect and investigate APT attacks under the constraints of timeliness and limited resources are in dire need. Unfortunately, existing online systems usually sacrifice detection granularity to reduce computational complexity and produce provenance graphs with more than 100,000 nodes, posing challenges for security admins to interpret the detection results.  In this paper, we design and implement NodLink, the first online detection system that maintains high detection accuracy without sacrificing detection granularity. Our insight is that the APT attack detection process in online provenance-based detection systems can be modeled as a Steiner Tree Problem (STP), which has efficient online approximation algorithms that recover concise attack-related provenance graphs with a theoretically bounded error. To utilize the frameworks of the STP approximation algorithm for APT attack detection, we propose a novel design of in-memory cache, an efficient attack screening method, and a new STP approximation algorithm that is more efficient than the conventional one in APT attack detection while maintaining the same complexity. We evaluate NodLink in a production environment. The open-world experiment shows that NodLink outperforms two state-of-the-art (SOTA) online provenance analysis systems by achieving magnitudes higher detection and investigation accuracy while having the same or higher throughput.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2024-204-paper.pdf",
            "keywords": [
                "Advanced Persistent Threats",
                "Provenance Graphs",
                "Online Detection System",
                "Steiner Tree Problem",
                "Attack Detection Accuracy"
            ]
        },
        "url": "URL#358398"
    },
    {
        "@score": "1",
        "@id": "358399",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "332/3196",
                        "text": "Levi Taiji Li"
                    },
                    {
                        "@pid": "228/1460",
                        "text": "Ningyu He"
                    },
                    {
                        "@pid": "50/8499-1",
                        "text": "Haoyu Wang 0001"
                    },
                    {
                        "@pid": "28/3341-1",
                        "text": "Mu Zhang 0001"
                    }
                ]
            },
            "title": "VETEOS: Statically Vetting EOSIO Contracts for the &quot;Groundhog Day&quot; Vulnerabilities.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/LiH0024",
            "ee": "https://www.ndss-symposium.org/ndss-paper/veteos-statically-vetting-eosio-contracts-for-the-groundhog-day-vulnerabilities/",
            "url": "https://dblp.org/rec/conf/ndss/LiH0024",
            "abstract": "\u2014In this paper, we propose V ET EOS, a static vetting tool for the \u201cGroundhog Day\u201d vulnerabilities in EOSIO contracts. In a \u201cGroundhog Day\u201d attack, culprits leverage the distinctive rollback issue in EOSIO contracts, which allows them to persistently execute identical contract code with varying inputs. By using the information exposed in prior executions, these attackers unlawfully amass insights about the target contract, thereby figuring out a reliable method to generate unauthorized profits. To tackle this problem, we formally define this unique vulnerability as a control and data dependency problem, and develop a custom static analysis tool, V ET EOS, that can precisely discover such bugs directly from EOSIO WebAssembly (WASM) bytecode. V ET EOS has detected 735 new vulnerabilities in the wild and outperforms the state-of-the-art EOSIO contract analyzer.",
            "keywords": [
                "EOSIO Contracts",
                "Static Analysis",
                "Groundhog Day Vulnerabilities",
                "Control and Data Dependency",
                "VETEOS Tool"
            ]
        },
        "url": "URL#358399",
        "sema_paperId": "1a0bbf54cf322567a56401b082660cd566115502"
    },
    {
        "@score": "1",
        "@id": "358400",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "85/9245",
                        "text": "Zhengyi Li"
                    },
                    {
                        "@pid": "129/1113",
                        "text": "Xiaojing Liao"
                    }
                ]
            },
            "title": "Understanding and Analyzing Appraisal Systems in the Underground Marketplaces.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/LiL24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/understanding-and-analyzing-appraisal-systems-in-the-underground-marketplaces/",
            "url": "https://dblp.org/rec/conf/ndss/LiL24",
            "abstract": "\u2014An appraisal system is a feedback mechanism that has gained popularity in underground marketplaces. This system allows appraisers, who receive free samples from vendors, to provide assessments (i.e., appraisal reviews) for products in underground marketplaces. In this paper, we present the first measurement study on the appraisal system within underground marketplaces. Specifically, from 17M communication traces from eight marketplaces spanning from Feb 2006 to Mar 2023, we discover 56,229 appraisal reviews posted by 18,701 unique ap-praisers. We look into the appraisal review ecosystem, revealing five commonly used requirements and merits in the appraiser selection process. These findings indicate that the appraisal system is a well-established and structured process within the underground marketplace ecosystem. Furthermore, we reveal the presence of high-quality and unique cyber threat intelligence (CTI) in appraisal reviews. For example, we identify the ge-olocations of followers for a social booster and programming languages used for malware. Leveraging our extraction model, which integrates 41 distinct types of CTI, we capture 23,978 artifacts associated with 16,668 (50.2%) appraisal reviews. In contrast, artifacts are found in only 8.9% of listings and 2.7% of non-appraisal reviews. Our study provides valuable insights into this under-explored source of CTI, complementing existing research on threat intelligence gathering.",
            "keywords": [
                "Underground Marketplaces",
                "Appraisal Systems",
                "Cyber Threat Intelligence",
                "Appraiser Selection",
                "Appraisal Reviews"
            ]
        },
        "url": "URL#358400",
        "sema_paperId": "091a74cd661a3466f6071e7f90249a0f2363c391"
    },
    {
        "@score": "1",
        "@id": "358401",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "199/5197",
                        "text": "Xigao Li"
                    },
                    {
                        "@pid": "125/0358",
                        "text": "Amir Rahmati"
                    },
                    {
                        "@pid": "04/8280",
                        "text": "Nick Nikiforakis"
                    }
                ]
            },
            "title": "Like, Comment, Get Scammed: Characterizing Comment Scams on Media Platforms.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/LiRN24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/like-comment-get-scammed-characterizing-comment-scams-on-media-platforms/",
            "url": "https://dblp.org/rec/conf/ndss/LiRN24",
            "abstract": "\u2014Given the meteoric rise of large media platforms (such as YouTube) on the web, it is no surprise that attackers seek to abuse them in order to easily reach hundreds of millions of users. Among other social-engineering attacks perpetrated on these platforms, comment scams have increased in popularity despite the presence of mechanisms that purportedly give content creators control over their channel comments. In a comment scam, attackers set up script-controlled accounts that automatically post or reply to comments on media platforms, enticing users to contact them. Through the promise of free prizes and investment opportunities, attackers aim to steal financial assets from the end users who contact them. In this paper, we present the first systematic, large-scale study of comment scams. We design and implement an infrastructure to collect a dataset of 8.8 million comments from 20 different YouTube channels over a 6-month period. We develop filters based on textual, graphical, and temporal features of comments and identify 206K scam comments from 10K unique accounts. Using this dataset, we present our analysis of scam campaigns, comment dynamics, and evasion techniques used by scammers. Lastly, through an IRB-approved study, we interact with 50 scammers to gain insights into their social-engineering tactics and payment preferences. Using transaction records on public blockchains, we perform a quantitative analysis of the financial assets stolen by scammers, finding that just the scammers that were part of our user study have stolen funds equivalent to millions of dollars. Our study demonstrates that existing scam-detection mechanisms are insufficient for curbing abuse, pointing to the need for better comment-moderation tools as well as other changes that would make it difficult for attackers to obtain tens of thousands of accounts on these large platforms.",
            "keywords": [
                "Comment Scams",
                "Social Engineering",
                "YouTube Platforms",
                "Scam Detection",
                "Financial Fraud"
            ]
        },
        "url": "URL#358401",
        "sema_paperId": "d0cf6b270feb61b2ca5bfbe820c5d540a9ecf738"
    },
    {
        "@score": "1",
        "@id": "358402",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "97/8097",
                        "text": "Qiushi Li"
                    },
                    {
                        "@pid": "04/3348",
                        "text": "Yan Zhang"
                    },
                    {
                        "@pid": "00/468-1",
                        "text": "Ju Ren 0001"
                    },
                    {
                        "@pid": "181/2688-2",
                        "text": "Qi Li 0002"
                    },
                    {
                        "@pid": "99/4094",
                        "text": "Yaoxue Zhang"
                    }
                ]
            },
            "title": "You Can Use But Cannot Recognize: Preserving Visual Privacy in Deep Neural Networks.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/LiZ00Z24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/you-can-use-but-cannot-recognize-preserving-visual-privacy-in-deep-neural-networks/",
            "url": "https://dblp.org/rec/conf/ndss/LiZ00Z24",
            "abstract": "Image data have been extensively used in Deep Neural Network (DNN) tasks in various scenarios, e.g., autonomous driving and medical image analysis, which incurs significant privacy concerns. Existing privacy protection techniques are unable to efficiently protect such data. For example, Differential Privacy (DP) that is an emerging technique protects data with strong privacy guarantee cannot effectively protect visual features of exposed image dataset. In this paper, we propose a novel privacy-preserving framework VisualMixer that protects the training data of visual DNN tasks by pixel shuffling, while not injecting any noises. VisualMixer utilizes a new privacy metric called Visual Feature Entropy (VFE) to effectively quantify the visual features of an image from both biological and machine vision aspects. In VisualMixer, we devise a task-agnostic image obfuscation method to protect the visual privacy of data for DNN training and inference. For each image, it determines regions for pixel shuffling in the image and the sizes of these regions according to the desired VFE. It shuffles pixels both in the spatial domain and in the chromatic channel space in the regions without injecting noises so that it can prevent visual features from being discerned and recognized, while incurring negligible accuracy loss. Extensive experiments on real-world datasets demonstrate that VisualMixer can effectively preserve the visual privacy with negligible accuracy loss, i.e., at average 2.35 percentage points of model accuracy loss, and almost no performance degradation on model training.",
            "keywords": [
                "Visual Privacy",
                "Image Obfuscation",
                "Pixel Shuffling",
                "Visual Feature Entropy",
                "Deep Neural Network Training"
            ]
        },
        "url": "URL#358402",
        "sema_paperId": "fcfbab9ba012c2ab1c0c0ef8aca1ddd99646a9b0"
    },
    {
        "@score": "1",
        "@id": "358403",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "280/7107",
                        "text": "Zhengchuan Liang"
                    },
                    {
                        "@pid": "210/0533",
                        "text": "Xiaochen Zou"
                    },
                    {
                        "@pid": "69/6818",
                        "text": "Chengyu Song"
                    },
                    {
                        "@pid": "31/8302",
                        "text": "Zhiyun Qian"
                    }
                ]
            },
            "title": "K-LEAK: Towards Automating the Generation of Multi-Step Infoleak Exploits against the Linux Kernel.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/LiangZSQ24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/k-leak-towards-automating-the-generation-of-multi-step-infoleak-exploits-against-the-linux-kernel/",
            "url": "https://dblp.org/rec/conf/ndss/LiangZSQ24",
            "abstract": "\u2014The severity of information leak ( infoleak for short) in OS kernels cannot be underestimated, and various exploitation techniques have been proposed to achieve infoleak in OS kernels. Among them, memory-error-based infoleak is powerful and widely used in real-world exploits. However, existing approaches to finding memory-error-based infoleak lack the systematic reasoning about its search space, and do not fully explore the search space. Consequently, they fail to exploit a large number of memory errors in the kernel. According to a theoretical modeling of memory errors, the actual search space of such approach is huge, as multiple steps could be involved in the exploitation process, and virtually any memory error can be exploited to achieve infoleak. To bridge the gap between the theory and reality, we propose a framework K-LEAK to facilitate generating memory-error-based infoleak exploits in the Linux kernel. K-LEAK considers infoleak exploit generation as a data-flow search problem. By modeling unintended data flows introduced by memory errors, and how existing memory errors can create new memory errors, K-LEAK can systematically search for infoleak data-flow paths in a multi-step manner. We implement a prototype of K-LEAK and evaluate it with memory errors from syzbot and CVEs. The evaluation results demonstrate the effectiveness of K-LEAK in generating diverse infoleak exploits using various multi-step strategies.",
            "keywords": [
                "Linux Kernel Exploits",
                "Information Leak",
                "Memory Errors",
                "Data-Flow Analysis",
                "Multi-Step Exploitation"
            ]
        },
        "url": "URL#358403",
        "sema_paperId": "0b732dc681d24d720ec7a19f1550dd60a8c7cf06"
    },
    {
        "@score": "1",
        "@id": "358404",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "84/1781",
                        "text": "Hai Lin"
                    },
                    {
                        "@pid": "83/7820-6",
                        "text": "Chenglong Li 0006"
                    },
                    {
                        "@pid": "62/2814-1",
                        "text": "Jiahai Yang 0001"
                    },
                    {
                        "@pid": "58/5311",
                        "text": "Zhiliang Wang"
                    },
                    {
                        "@pid": "238/8673",
                        "text": "Linna Fan"
                    },
                    {
                        "@pid": "280/2169",
                        "text": "Chenxin Duan"
                    }
                ]
            },
            "title": "CP-IoT: A Cross-Platform Monitoring System for Smart Home.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/Lin00WFD24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/cp-iot-a-cross-platform-monitoring-system-for-smart-home/",
            "url": "https://dblp.org/rec/conf/ndss/Lin00WFD24",
            "abstract": "\u2014Today, smart home platforms are widely used around the world and offer users automation to define their daily routines. However, individual automation rule anomalies and cross-automation threats that exist in different platforms put the smart home in danger. Recent researches focus on detecting these threats of the specific platform and can only cover limited threat plane. To solve these problems, we design a novel system called CP-IoT, which can monitor the execution behavior of the automation and discover the anomalies, as well as hidden risks among them on heterogeneous IoT platforms. Specifically, CP-IoT constructs a centralized, dynamic graph model for portraying the behavior of automation and the state transition. By analyzing two kinds of app pages with different description granularity, CP-IoT extracts the rule execution logic and collects user policy from different platforms. To detect the inconsistent behavior of an automation rule in different platforms, we propose a self-learning method for event fingerprint extraction by clustering the traffic of different platforms collected from the side channel, and an anomaly detection method by checking the rule execution behavior with its specification reflected in the graph model. To detect the cross-rule threats, we formalize each threat type as a symbolic representation and apply the searching algorithm on the graph. We validate the performance of CP-IoT on four platforms. The evaluation shows that CP-IoT can detect anomalies with high accuracy and effectively discover various types of cross-rule threats.",
            "keywords": [
                "Smart Home Automation",
                "Cross-Platform Monitoring",
                "Anomaly Detection",
                "IoT Security Risks",
                "Rule Execution Behavior"
            ]
        },
        "url": "URL#358404",
        "sema_paperId": "86ac7abeb5923ca3f9249f5a48e923905471802c"
    },
    {
        "@score": "1",
        "@id": "358405",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "352/4369",
                        "text": "Peihong Lin"
                    },
                    {
                        "@pid": "90/4693-10",
                        "text": "Pengfei Wang 0010"
                    },
                    {
                        "@pid": "66/5686",
                        "text": "Xu Zhou"
                    },
                    {
                        "@pid": "87/1010-7",
                        "text": "Wei Xie 0007"
                    },
                    {
                        "@pid": "210/5280",
                        "text": "Gen Zhang"
                    },
                    {
                        "@pid": "31/6932",
                        "text": "Kai Lu"
                    }
                ]
            },
            "title": "DeepGo: Predictive Directed Greybox Fuzzing.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/Lin0Z0ZL24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/deepgo-predictive-directed-greybox-fuzzing/",
            "url": "https://dblp.org/rec/conf/ndss/Lin0Z0ZL24",
            "abstract": "\u2014Directed Greybox Fuzzing (DGF) is an effective approach designed to strengthen testing vulnerable code areas via predefined target sites. The state-of-the-art DGF techniques redefine and optimize the fitness metric to reach the target sites precisely and quickly. However, optimizations for fitness metrics are mainly based on heuristic algorithms, which usually rely on historical execution information and lack foresight on paths that have not been exercised yet. Thus, those hard-to-execute paths with complex constraints would hinder DGF from reaching the targets, making DGF less efficient. In this paper, we propose DeepGo, a predictive directed grey-box fuzzer that can combine historical and predicted information to steer DGF to reach the target site via an optimal path. We first propose the path transition model , which models DGF as a process of reaching the target site through specific path transition sequences. The new seed generated by mutation would cause the path transition, and the path corresponding to the high-reward path transition sequence indicates a high likelihood of reaching the target site through it. Then, to predict the path transitions and the corresponding rewards, we use deep neural networks to construct a Virtual Ensemble Environment (VEE), which gradually imitates the path transition model and predicts the rewards of path transitions that have not been taken yet. To determine the optimal path, we develop a Reinforcement Learning for Fuzzing (RLF) model to generate the transition sequences with the highest sequence rewards. The RLF model can combine historical and predicted path transitions to generate the optimal path transition sequences, along with the policy to guide the mutation strategy of fuzzing. Finally, to exercise the high-reward path transition sequence, we propose the concept of an action group , which comprehensively optimizes the critical steps of fuzzing to realize the optimal path to reach the target efficiently. We evaluated DeepGo on 2 benchmark suites consisting of 25 programs with a total of 100 target sites. The experimental results show that DeepGo achieves 3.23 \u00d7 , 1.72 \u00d7 , 1.81 \u00d7 , and 4.83 \u00d7 speedup compared to AFLGo, BEACON, WindRanger, and ParmeSan, respectively in reaching target sites, and 2.61 \u00d7 , 3.32 \u00d7 , 2.43 \u00d7 and 2.53 \u00d7 speedup in exposing known vulnerabilities.",
            "keywords": [
                "Directed Greybox Fuzzing",
                "Path Transition Model",
                "Predictive Fuzzing",
                "Reinforcement Learning for Fuzzing",
                "Vulnerability Exposure"
            ]
        },
        "url": "URL#358405",
        "sema_paperId": "09c4838fcdab5ef9ae56264c4192109ddfbdd4ff"
    },
    {
        "@score": "1",
        "@id": "358406",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "345/3464",
                        "text": "Elizabeth Lin"
                    },
                    {
                        "@pid": "295/1145",
                        "text": "Igibek Koishybayev"
                    },
                    {
                        "@pid": "322/0152",
                        "text": "Trevor Dunlap"
                    },
                    {
                        "@pid": "22/4463",
                        "text": "William Enck"
                    },
                    {
                        "@pid": "22/1459",
                        "text": "Alexandros Kapravelos"
                    }
                ]
            },
            "title": "UntrustIDE: Exploiting Weaknesses in VS Code Extensions.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/LinKDEK24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/untrustide-exploiting-weaknesses-in-vs-code-extensions/",
            "url": "https://dblp.org/rec/conf/ndss/LinKDEK24",
            "abstract": "\u2014With the rise in threats against the software supply chain, developer integrated development environments (IDEs) present an attractive target for attackers. For example, researchers have found extensions for Visual Studio Code (VS Code) that start web servers and can be exploited via JavaScript executing in a web browser on the developer\u2019s host. This paper seeks to systematically understand the landscape of vulnerabilities in VS Code\u2019s extension marketplace. We identify a set of four sources of untrusted input and three code targets that can be used for code injection and file integrity attacks and use them to design taint analysis rules in CodeQL. We then perform an ecosystem-level analysis of the VS Code extension marketplace, studying 25,402 extensions that contain code. Our results show that while vulnerabilities are not pervasive, they exist and impact millions of users. Specifically, we find 21 extensions with verified proof of concept exploits of code injection attacks impacting a total of over 6 million installations. Through this study, we demonstrate the need for greater attention to the security of IDE extensions.",
            "keywords": [
                "IDE Security",
                "VS Code Extensions",
                "Code Injection",
                "Software Supply Chain",
                "Taint Analysis"
            ]
        },
        "url": "URL#358406",
        "sema_paperId": "62b8156ea3f4c9e10df5f68f69e72443c1b33fa1"
    },
    {
        "@score": "1",
        "@id": "358407",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "68/4713",
                        "text": "Weiran Lin"
                    },
                    {
                        "@pid": "250/5769",
                        "text": "Keane Lucas"
                    },
                    {
                        "@pid": "350/5053",
                        "text": "Neo Eyal"
                    },
                    {
                        "@pid": "32/3440",
                        "text": "Lujo Bauer"
                    },
                    {
                        "@pid": "r/MichaelKReiter",
                        "text": "Michael K. Reiter"
                    },
                    {
                        "@pid": "136/8393",
                        "text": "Mahmood Sharif"
                    }
                ]
            },
            "title": "Group-based Robustness: A General Framework for Customized Robustness in the Real World.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/LinLEBRS24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/group-based-robustness-a-general-framework-for-customized-robustness-in-the-real-world/",
            "url": "https://dblp.org/rec/conf/ndss/LinLEBRS24",
            "abstract": "Machine-learning models are known to be vulnerable to evasion attacks that perturb model inputs to induce misclassifications. In this work, we identify real-world scenarios where the true threat cannot be assessed accurately by existing attacks. Specifically, we find that conventional metrics measuring targeted and untargeted robustness do not appropriately reflect a model's ability to withstand attacks from one set of source classes to another set of target classes. To address the shortcomings of existing methods, we formally define a new metric, termed group-based robustness, that complements existing metrics and is better-suited for evaluating model performance in certain attack scenarios. We show empirically that group-based robustness allows us to distinguish between models' vulnerability against specific threat models in situations where traditional robustness metrics do not apply. Moreover, to measure group-based robustness efficiently and accurately, we 1) propose two loss functions and 2) identify three new attack strategies. We show empirically that with comparable success rates, finding evasive samples using our new loss functions saves computation by a factor as large as the number of targeted classes, and finding evasive samples using our new attack strategies saves time by up to 99\\% compared to brute-force search methods. Finally, we propose a defense method that increases group-based robustness by up to 3.52$\\times$.",
            "keywords": [
                "Group-based Robustness",
                "Evasion Attacks",
                "Robustness Metrics",
                "Model Vulnerability",
                "Attack Strategies"
            ]
        },
        "url": "URL#358407",
        "sema_paperId": "2c0645d5c8010b532969558d41bed4fc88ca70cf"
    },
    {
        "@score": "1",
        "@id": "358408",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "253/7461",
                        "text": "Mingxuan Liu"
                    },
                    {
                        "@pid": "76/5416-9",
                        "text": "Yiming Zhang 0009"
                    },
                    {
                        "@pid": "40/1491-108",
                        "text": "Xiang Li 0108"
                    },
                    {
                        "@pid": "223/6794",
                        "text": "Chaoyi Lu"
                    },
                    {
                        "@pid": "89/10754",
                        "text": "Baojun Liu"
                    },
                    {
                        "@pid": "36/5143",
                        "text": "Haixin Duan"
                    },
                    {
                        "@pid": "11/11005",
                        "text": "Xiaofeng Zheng"
                    }
                ]
            },
            "title": "Understanding the Implementation and Security Implications of Protective DNS Services.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/Liu00LLDZ24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/understanding-the-implementation-and-security-implications-of-protective-dns-services/",
            "url": "https://dblp.org/rec/conf/ndss/Liu00LLDZ24",
            "abstract": "\u2014Domain names are often registered and abused for harmful and illegal Internet activities. To mitigate such threats, as an emerging security service, Protective DNS ( PDNS ) blocks access to harmful content by proactively offering rewritten DNS responses, which resolve malicious domains to controlled hosts. While it has become an effective tool against cybercrime, given their implementation divergence, little has been done from the security community in understanding the deployment, operational status and security policies of PDNS services. In this paper, we present a large-scale measurement study of the deployment and security implications of open PDNS services. We first perform empirical analysis over 28 popular PDNS providers and summarize major formats of DNS rewriting policies. Then, powered by the derived rules, we design a methodology that identifies intentional DNS rewriting enforced by open PDNS servers in the wild. Our findings are multi-faceted. On the plus side, the deployment of PDNS is now starting to scale: we identify 17,601 DNS servers (9.1% of all probed) offering such service. For DNS clients, switching from regular DNS to PDNS induces negligible query latency, despite additional steps (e.g., checking against threat intelligence and rewriting DNS response) being required from the server side. However, we also find flaws and vulnerabilities within PDNS implementation, including evasion of blocking policies and denial of service. Through responsible vulnerability disclosure, we have received 12 audit assessment results of high-risk vulnerabilities. Our study calls for proper guidance and best practices for",
            "keywords": [
                "Protective DNS",
                "Cybercrime Mitigation",
                "DNS Rewriting Policies",
                "Vulnerabilities in PDNS",
                "Denial of Service"
            ]
        },
        "url": "URL#358408",
        "sema_paperId": "185a3e07a038764e3870a433c77bde048d778d88"
    },
    {
        "@score": "1",
        "@id": "358409",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "52/5716",
                        "text": "Chang Liu"
                    },
                    {
                        "@pid": "84/6889-73",
                        "text": "Jie Zhang 0073"
                    },
                    {
                        "@pid": "77/7902-4",
                        "text": "Tianwei Zhang 0004"
                    },
                    {
                        "@pid": "13/1520",
                        "text": "Xi Yang"
                    },
                    {
                        "@pid": "20/612-1",
                        "text": "Weiming Zhang 0001"
                    },
                    {
                        "@pid": "96/5144",
                        "text": "Nenghai Yu"
                    }
                ]
            },
            "title": "Detecting Voice Cloning Attacks via Timbre Watermarking.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/Liu00Y0Y24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/detecting-voice-cloning-attacks-via-timbre-watermarking/",
            "url": "https://dblp.org/rec/conf/ndss/Liu00Y0Y24",
            "abstract": "Nowadays, it is common to release audio content to the public. However, with the rise of voice cloning technology, attackers have the potential to easily impersonate a specific person by utilizing his publicly released audio without any permission. Therefore, it becomes significant to detect any potential misuse of the released audio content and protect its timbre from being impersonated. To this end, we introduce a novel concept,\"Timbre Watermarking\", which embeds watermark information into the target individual's speech, eventually defeating the voice cloning attacks. To ensure the watermark is robust to the voice cloning model's learning process, we design an end-to-end voice cloning-resistant detection framework. The core idea of our solution is to embed and extract the watermark in the frequency domain in a temporally invariant manner. To acquire generalization across different voice cloning attacks, we modulate their shared process and integrate it into our framework as a distortion layer. Experiments demonstrate that the proposed timbre watermarking can defend against different voice cloning attacks, exhibit strong resistance against various adaptive attacks (e.g., reconstruction-based removal attacks, watermark overwriting attacks), and achieve practicality in real-world services such as PaddleSpeech, Voice-Cloning-App, and so-vits-svc. In addition, ablation studies are also conducted to verify the effectiveness of our design. Some audio samples are available at https://timbrewatermarking.github.io/samples.",
            "keywords": [
                "Voice Cloning",
                "Timbre Watermarking",
                "Audio Content Protection",
                "Impersonation Detection",
                "Adaptive Attacks"
            ]
        },
        "url": "URL#358409",
        "sema_paperId": "928118243a57a03d9b8c4cc617a6da297afdbc61"
    },
    {
        "@score": "1",
        "@id": "358410",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "234/8706",
                        "text": "Xuanqi Liu"
                    },
                    {
                        "@pid": "69/11514",
                        "text": "Zhuotao Liu"
                    },
                    {
                        "@pid": "181/2688-2",
                        "text": "Qi Li 0002"
                    },
                    {
                        "@pid": "181/2626-2",
                        "text": "Ke Xu 0002"
                    },
                    {
                        "@pid": "18/6055",
                        "text": "Mingwei Xu"
                    }
                ]
            },
            "title": "Pencil: Private and Extensible Collaborative Learning without the Non-Colluding Assumption.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/LiuL00X24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/pencil-private-and-extensible-collaborative-learning-without-the-non-colluding-assumption/",
            "url": "https://dblp.org/rec/conf/ndss/LiuL00X24",
            "abstract": "The escalating focus on data privacy poses significant challenges for collaborative neural network training, where data ownership and model training/deployment responsibilities reside with distinct entities. Our community has made substantial contributions to addressing this challenge, proposing various approaches such as federated learning (FL) and privacy-preserving machine learning based on cryptographic constructs like homomorphic encryption (HE) and secure multiparty computation (MPC). However, FL completely overlooks model privacy, and HE has limited extensibility (confined to only one data provider). While the state-of-the-art MPC frameworks provide reasonable throughput and simultaneously ensure model/data privacy, they rely on a critical non-colluding assumption on the computing servers, and relaxing this assumption is still an open problem. In this paper, we present Pencil, the first private training framework for collaborative learning that simultaneously offers data privacy, model privacy, and extensibility to multiple data providers, without relying on the non-colluding assumption. Our fundamental design principle is to construct the n-party collaborative training protocol based on an efficient two-party protocol, and meanwhile ensuring that switching to different data providers during model training introduces no extra cost. We introduce several novel cryptographic protocols to realize this design principle and conduct a rigorous security and privacy analysis. Our comprehensive evaluations of Pencil demonstrate that (i) models trained in plaintext and models trained privately using Pencil exhibit nearly identical test accuracies; (ii) The training overhead of Pencil is greatly reduced: Pencil achieves 10 ~ 260x higher throughput and 2 orders of magnitude less communication than prior art; (iii) Pencil is resilient against both existing and adaptive (white-box) attacks.",
            "keywords": [
                "Collaborative Learning",
                "Data Privacy",
                "Model Privacy",
                "Extensible Framework",
                "Non-Colluding Assumption"
            ]
        },
        "url": "URL#358410",
        "sema_paperId": "d69afa44f8c9c8b5f51af772026549014e331c9a"
    },
    {
        "@score": "1",
        "@id": "358411",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "38/4289-2",
                        "text": "Yan Long 0002"
                    },
                    {
                        "@pid": "262/3567",
                        "text": "Qinhong Jiang"
                    },
                    {
                        "@pid": "46/1162-1",
                        "text": "Chen Yan 0001"
                    },
                    {
                        "@pid": "385/8562",
                        "text": "Tobias Alam"
                    },
                    {
                        "@pid": "39/1697-1",
                        "text": "Xiaoyu Ji 0001"
                    },
                    {
                        "@pid": "10/3878-1",
                        "text": "Wenyuan Xu 0001"
                    },
                    {
                        "@pid": "f/KevinFu",
                        "text": "Kevin Fu"
                    }
                ]
            },
            "title": "EM Eye: Characterizing Electromagnetic Side-channel Eavesdropping on Embedded Cameras.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/LongJ0A00F24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/em-eye-characterizing-electromagnetic-side-channel-eavesdropping-on-embedded-cameras/",
            "url": "https://dblp.org/rec/conf/ndss/LongJ0A00F24",
            "abstract": "\u2014IoT devices and other embedded systems are increasingly equipped with cameras that can sense critical information in private spaces. The data security of these cameras, however, has hardly been scrutinized from the hardware design perspective. Our paper presents the first attempt to analyze the attack surface of physical-channel eavesdropping on embedded cameras. We characterize EM Eye\u2014a vulnerability in the digital image data transmission interface that allows adversaries to reconstruct high-quality image streams from the cameras\u2019 unintentional electromagnetic emissions, even from over 2 meters away in many cases. Our evaluations of 4 popular IoT camera development platforms and 12 commercial off-the-shelf devices with cameras show that EM Eye poses threats to a wide range of devices, from smartphones to dash cams and home security cameras. By exploiting this vulnerability, adversaries may be able to visually spy on private activities in an enclosed room from the other side of a wall. We provide root cause analysis and modeling that enable system defenders to identify and simulate mitigation against this vulnerability, such as improving embedded cameras\u2019 data transmission protocols with minimum costs. We further discuss EM Eye\u2019s relationship with known computer display eavesdropping attacks to reveal the gaps that need to be addressed to protect the data confidentiality of sensing systems.",
            "keywords": [
                "Embedded Systems Security",
                "Electromagnetic Eavesdropping",
                "IoT Cameras",
                "Data Transmission Vulnerability",
                "Image Data Reconstruction"
            ]
        },
        "url": "URL#358411",
        "sema_paperId": "2411a8af14105cb39de473a8b56b401aab891b66"
    },
    {
        "@score": "1",
        "@id": "358412",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "332/3062",
                        "text": "Daniela Lopes"
                    },
                    {
                        "@pid": "222/1664",
                        "text": "Jin-Dong Dong"
                    },
                    {
                        "@pid": "219/2971",
                        "text": "Pedro Medeiros"
                    },
                    {
                        "@pid": "64/1368-4",
                        "text": "Daniel Castro 0004"
                    },
                    {
                        "@pid": "204/5176",
                        "text": "Diogo Barradas"
                    },
                    {
                        "@pid": "175/5735",
                        "text": "Bernardo Portela"
                    },
                    {
                        "@pid": "65/11204",
                        "text": "Jo\u00e3o Vinagre"
                    },
                    {
                        "@pid": "145/9850",
                        "text": "Bernardo Ferreira"
                    },
                    {
                        "@pid": "c/NicolasChristin",
                        "text": "Nicolas Christin"
                    },
                    {
                        "@pid": "07/967-1",
                        "text": "Nuno Santos 0001"
                    }
                ]
            },
            "title": "Flow Correlation Attacks on Tor Onion Service Sessions with Sliding Subset Sum.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/LopesDM0BPVFC024",
            "ee": "https://www.ndss-symposium.org/ndss-paper/flow-correlation-attacks-on-tor-onion-service-sessions-with-sliding-subset-sum/",
            "url": "https://dblp.org/rec/conf/ndss/LopesDM0BPVFC024",
            "abstract": "\u2014Tor is one of the most popular anonymity networks in use today. Its ability to defend against flow correlation attacks is essential for providing strong anonymity guarantees. However, the feasibility of flow correlation attacks against Tor onion services (formerly known as \u201chidden services\u201d) has remained an open challenge. In this paper, we present an effective flow correlation attack that can deanonymize onion service sessions in the Tor network. Our attack is based on a novel distributed technique named Sliding Subset Sum (SUMo), which can be deployed by a group of colluding ISPs worldwide in a federated fashion. These ISPs collect Tor traffic at multiple vantage points in the network, and analyze it through a pipelined architecture based on machine learning classifiers and a novel similarity function based on the classic subset sum decision problem. These classifiers enable SUMo to deanonymize onion service sessions effectively and efficiently. We also analyze possible countermeasures that the Tor community can adopt to hinder the efficacy of these attacks.",
            "keywords": [
                "Tor Network",
                "Onion Services",
                "Flow Correlation Attacks",
                "Deanonymization",
                "Sliding Subset Sum (SUMo)"
            ]
        },
        "url": "URL#358412",
        "sema_paperId": "3d1d21f44e4edc54e1d1dd50f7e340462973c239"
    },
    {
        "@score": "1",
        "@id": "358413",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "253/1632-2",
                        "text": "Zhengxiong Luo 0002"
                    },
                    {
                        "@pid": "41/10217",
                        "text": "Kai Liang"
                    },
                    {
                        "@pid": "78/5804",
                        "text": "Yanyang Zhao"
                    },
                    {
                        "@pid": "312/8570",
                        "text": "Feifan Wu"
                    },
                    {
                        "@pid": "265/9249",
                        "text": "Junze Yu"
                    },
                    {
                        "@pid": "192/6867",
                        "text": "Heyuan Shi"
                    },
                    {
                        "@pid": "21/4633-1",
                        "text": "Yu Jiang 0001"
                    }
                ]
            },
            "title": "DynPRE: Protocol Reverse Engineering via Dynamic Inference.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/LuoLZWYS024",
            "ee": "https://www.ndss-symposium.org/ndss-paper/dynpre-protocol-reverse-engineering-via-dynamic-inference/",
            "url": "https://dblp.org/rec/conf/ndss/LuoLZWYS024",
            "abstract": "\u2014Automatic protocol reverse engineering is essential for various security applications. While many existing techniques achieve this task by analyzing static network traces, they face increasing challenges due to their dependence on high-quality samples. This paper introduces D YN PRE, a protocol reverse engineering tool that exploits the interactive capabilities of protocol servers to obtain more semantic information and additional traf\ufb01c for dynamic inference. D YN PRE \ufb01rst processes the initial input network traces and learns the rules for interacting with the server in different contexts based on session-speci\ufb01c identi\ufb01er detection and adaptive message rewriting. It then applies exploratory request crafting to obtain semantic information and supplementary samples and performs real-time analysis. Our evaluation on 12 widely used protocols shows that D YN PRE identi\ufb01es \ufb01elds with a perfection score of 0.50 and infers message types with a V-measure of 0.94, signi\ufb01cantly outperforming state-of-the-art methods like Netzob, Netplier, FieldHunter, BinaryInferno, and Nemesys, which achieve average perfection and V-measure scores of (0.15, 0.72), (0.16, 0.73), (0.15, 0.83), (0.15, -), and (0.31, -), respectively. Furthermore, case studies on unknown protocols highlight the effectiveness of D YN PRE in real-world applications.",
            "keywords": [
                "Protocol Reverse Engineering",
                "Dynamic Inference",
                "Interactive Protocol Analysis",
                "Network Traces",
                "Message Type Inference"
            ]
        },
        "url": "URL#358413",
        "sema_paperId": "f0e4bacc48829eb7b07fe373e9a786687ab203a4"
    },
    {
        "@score": "1",
        "@id": "358414",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "243/3648",
                        "text": "Shiqing Luo"
                    },
                    {
                        "@pid": "52/5285",
                        "text": "Anh Nguyen"
                    },
                    {
                        "@pid": "358/1041",
                        "text": "Hafsa Farooq"
                    },
                    {
                        "@pid": "30/3530-1",
                        "text": "Kun Sun 0001"
                    },
                    {
                        "@pid": "28/10126",
                        "text": "Zhisheng Yan"
                    }
                ]
            },
            "title": "Eavesdropping on Controller Acoustic Emanation for Keystroke Inference Attack in Virtual Reality.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/LuoNF0Y24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/eavesdropping-on-controller-acoustic-emanation-for-keystroke-inference-attack-in-virtual-reality/",
            "url": "https://dblp.org/rec/conf/ndss/LuoNF0Y24",
            "abstract": "\u2014Understanding the vulnerability of virtual reality (VR) is crucial for protecting sensitive data and building user trust in VR ecosystems. Previous attacks have demonstrated the feasibility of inferring VR keystrokes inside head-mounted displays (HMDs) by recording side-channel signals generated during user-HMD interactions. However, these attacks are heavily constrained by the physical layout or victim pose in the attack scenario since the recording device must be strictly positioned and oriented in a particular way with respect to the victim. In this paper, we unveil a placement-flexible keystroke inference attack in VR by eavesdropping the clicking sounds of the moving hand controller during keystrokes. The malicious recording smartphone can be placed anywhere surrounding the victim, making the attack more flexible and practical to deploy in VR environments. As the first acoustic attack in VR, our system, Heimdall , overcomes unique challenges unaddressed by previous acoustic attacks on physical keyboards and touchscreens. These challenges include differentiating sounds in a 3D space, adaptive mapping between keystroke sound and key in varying recording placement, and handling occasional hand rotations. Experiments with 30 participants show that Heimdall achieves key inference accuracy of 96.51% and top-5 accuracy of 85.14%\u201391.22% for inferring passwords with 4\u20138 characters. Heimdall is also robust under various practical impacts such as smartphone-user placement, attack environments, hardware models, and victim conditions.",
            "keywords": [
                "Virtual Reality Security",
                "Keystroke Inference",
                "Acoustic Emanation",
                "Hand Controller Eavesdropping",
                "Placement-Flexible Attack"
            ]
        },
        "url": "URL#358414",
        "sema_paperId": "9dca07a3afdad9095a3117529d49cb87a786842d"
    },
    {
        "@score": "1",
        "@id": "358415",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "289/1355",
                        "text": "Peizhuo Lv"
                    },
                    {
                        "@pid": "72/2643",
                        "text": "Pan Li"
                    },
                    {
                        "@pid": "277/3333",
                        "text": "Shenchen Zhu"
                    },
                    {
                        "@pid": "65/3618",
                        "text": "Shengzhi Zhang"
                    },
                    {
                        "@pid": "c/KaiChen12",
                        "text": "Kai Chen 0012"
                    },
                    {
                        "@pid": "232/3062",
                        "text": "Ruigang Liang"
                    },
                    {
                        "@pid": "303/6148",
                        "text": "Chang Yue"
                    },
                    {
                        "@pid": "94/9669",
                        "text": "Fan Xiang"
                    },
                    {
                        "@pid": "329/3998",
                        "text": "Yuling Cai"
                    },
                    {
                        "@pid": "307/2737",
                        "text": "Hualong Ma"
                    },
                    {
                        "@pid": "01/944",
                        "text": "Yingjun Zhang"
                    },
                    {
                        "@pid": "134/8681",
                        "text": "Guozhu Meng"
                    }
                ]
            },
            "title": "SSL-WM: A Black-Box Watermarking Approach for Encoders Pre-trained by Self-Supervised Learning.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/LvLZZ0LYXCMZM24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/ssl-wm-a-black-box-watermarking-approach-for-encoders-pre-trained-by-self-supervised-learning/",
            "url": "https://dblp.org/rec/conf/ndss/LvLZZ0LYXCMZM24",
            "abstract": "We propose SSL-WM , a novel system work that effectively protects the ownership of SSL encoders without assuming any knowledge of downstream tasks during watermark embedding or accessing intermediate results from the suspect model during ownership verification",
            "keywords": [
                "Watermarking",
                "Self-Supervised Learning",
                "Ownership Protection",
                "Model Verification",
                "Black-Box Approach"
            ]
        },
        "url": "URL#358415",
        "sema_paperId": "2bda74acd9ed1485fe944db4d948bc81065241e0"
    },
    {
        "@score": "1",
        "@id": "358416",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "351/0588",
                        "text": "Pengxiang Ma"
                    },
                    {
                        "@pid": "228/1460",
                        "text": "Ningyu He"
                    },
                    {
                        "@pid": "174/1767",
                        "text": "Yuhua Huang"
                    },
                    {
                        "@pid": "50/8499-1",
                        "text": "Haoyu Wang 0001"
                    },
                    {
                        "@pid": "53/1565",
                        "text": "Xiapu Luo"
                    }
                ]
            },
            "title": "Abusing the Ethereum Smart Contract Verification Services for Fun and Profit.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/MaHH0L24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/abusing-the-ethereum-smart-contract-verification-services-for-fun-and-profit/",
            "url": "https://dblp.org/rec/conf/ndss/MaHH0L24",
            "abstract": "Smart contracts play a vital role in the Ethereum ecosystem. Due to the prevalence of kinds of security issues in smart contracts, the smart contract verification is urgently needed, which is the process of matching a smart contract's source code to its on-chain bytecode for gaining mutual trust between smart contract developers and users. Although smart contract verification services are embedded in both popular Ethereum browsers (e.g., Etherscan and Blockscout) and official platforms (i.e., Sourcify), and gain great popularity in the ecosystem, their security and trustworthiness remain unclear. To fill the void, we present the first comprehensive security analysis of smart contract verification services in the wild. By diving into the detailed workflow of existing verifiers, we have summarized the key security properties that should be met, and observed eight types of vulnerabilities that can break the verification. Further, we propose a series of detection and exploitation methods to reveal the presence of vulnerabilities in the most popular services, and uncover 19 exploitable vulnerabilities in total. All the studied smart contract verification services can be abused to help spread malicious smart contracts, and we have already observed the presence of using this kind of tricks for scamming by attackers. It is hence urgent for our community to take actions to detect and mitigate security issues related to smart contract verification, a key component of the Ethereum smart contract ecosystem.",
            "keywords": [
                "Ethereum Smart Contracts",
                "Smart Contract Verification",
                "Security Vulnerabilities",
                "Malicious Contracts",
                "Exploitation Methods"
            ]
        },
        "url": "URL#358416",
        "sema_paperId": "d425598ea6424118f029144fdf269bd7bb704e46"
    },
    {
        "@score": "1",
        "@id": "358417",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "232/2235",
                        "text": "Sunil Manandhar"
                    },
                    {
                        "@pid": "87/6804",
                        "text": "Kapil Singh"
                    },
                    {
                        "@pid": "136/8334",
                        "text": "Adwait Nadkarni"
                    }
                ]
            },
            "title": "Towards Automated Regulation Analysis for Effective Privacy Compliance.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ManandharSN24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/towards-automated-regulation-analysis-for-effective-privacy-compliance/",
            "url": "https://dblp.org/rec/conf/ndss/ManandharSN24",
            "abstract": "\u2014Privacy regulations are being introduced and amended around the globe to effectively regulate the processing of consumer data. These regulations are often analyzed to fulfill compliance mandates and to aid the design of practical systems that improve consumer privacy. However, at present, this is done manually, making the task error-prone, while also incurring significant time, effort, and cost for companies. This paper describes the design and implementation of ARC, a framework that transforms unstructured and complex regulatory text into a structured representation, the ARC tuple(s), which can be queried to assist in the analysis and understanding of regulations. We demonstrate ARC\u2019s effectiveness in extracting three forms of tuples with a high F-1 score (avg. 82.1% across all three) using four major privacy regulations: CCPA, GDPR, VCDPA, and PIPEDA. We then build ARCBert that identifies semantically similar phrases across regulations, enabling compliance analysts to identify common requirements. We run ARC on 16 additional privacy regulations and identify 1,556 ARC tuples and clusters of semantically similar phrases. Finally, we extend ARC to evaluate the compliance of privacy policies by comparing it against the disclosure requirements in the four regulations. Our empirical evaluation with the privacy policies of S&P 500 companies finds 476 missing disclosures, which when manually validated, result in 71.05% true positives, as well as the discovery of 288 additional missing disclosures from the partial matches identified by ARC.",
            "keywords": [
                "Privacy Regulations",
                "Compliance Analysis",
                "Automated Regulation Analysis",
                "Consumer Data Protection",
                "Regulatory Text Structuring"
            ]
        },
        "url": "URL#358417",
        "sema_paperId": "a3944d55ab1a4f4b8e080c3d16e683edfee05dfc"
    },
    {
        "@score": "1",
        "@id": "358418",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "246/5331",
                        "text": "Ruijie Meng"
                    },
                    {
                        "@pid": "351/7622",
                        "text": "Martin Mirchev"
                    },
                    {
                        "@pid": "91/7541",
                        "text": "Marcel B\u00f6hme"
                    },
                    {
                        "@pid": "04/5884",
                        "text": "Abhik Roychoudhury"
                    }
                ]
            },
            "title": "Large Language Model guided Protocol Fuzzing.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/MengMBR24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/large-language-model-guided-protocol-fuzzing/",
            "url": "https://dblp.org/rec/conf/ndss/MengMBR24",
            "abstract": "\u2014How to find security flaws in a protocol implementation without a machine-readable specification of the protocol? Facing the internet, protocol implementations are particularly security-critical software systems where inputs must adhere to a specific structure and order that is often informally specified in hundreds of pages in natural language (RFC). Without some machine-readable version of that protocol, it is difficult to automatically generate valid test inputs for its implementation that follow the required structure and order. It is possible to partially alleviate this challenge using mutational fuzzing on a set of recorded message sequences as seed inputs. However, the set of available seeds is often quite limited and will hardly cover the great diversity of protocol states and input structures. In this paper, we explore the opportunities of systematic interaction with pre-trained large language models (LLMs), which have ingested millions of pages of human-readable protocol specifications, to draw out machine-readable information about the protocol that can be used during protocol fuzzing. We use the knowledge of the LLMs about protocol message types for well-known protocols. We also checked the LLM\u2019s capability in detecting \u201cstates\u201d for stateful protocol implementations by generating sequences of messages and predicting response codes. Based on these observations, we have developed an LLM-guided protocol implementation fuzzing engine. Our protocol fuzzer C HAT AFL constructs grammars for each message type in a protocol, and then mutates messages or predicts the next messages in a message sequence via interactions with LLMs. Experiments on a wide range of real-world protocols from P RO F UZZ B ENCH show significant efficacy in state and code coverage. Our LLM-guided stateful fuzzer was compared with state-of-the-art fuzzers AFLN ET and NSF UZZ . C HAT AFL covers 47.60% and 42.69% more state transitions, 29.55% and 25.75% more",
            "keywords": [
                "Protocol Fuzzing",
                "Large Language Models",
                "Stateful Protocols",
                "Message Sequence Generation",
                "Protocol Implementation Testing"
            ]
        },
        "url": "URL#358418",
        "sema_paperId": "4fcd49afa8d0a960c6d07aa4e7a37956f5307a8a"
    },
    {
        "@score": "1",
        "@id": "358419",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "248/0549",
                        "text": "Donika Mirdita"
                    },
                    {
                        "@pid": "94/7397",
                        "text": "Haya Schulmann"
                    },
                    {
                        "@pid": "332/3113",
                        "text": "Niklas Vogel"
                    },
                    {
                        "@pid": "90/308",
                        "text": "Michael Waidner"
                    }
                ]
            },
            "title": "The CURE to Vulnerabilities in RPKI Validation.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/MirditaSVW24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/the-cure-to-vulnerabilities-in-rpki-validation/",
            "url": "https://dblp.org/rec/conf/ndss/MirditaSVW24",
            "abstract": "Over recent years, the Resource Public Key Infrastructure (RPKI) has seen increasing adoption, with now 37.8% of the major networks filtering bogus BGP routes. Systems interact with the RPKI over Relying Party (RP) implementations that fetch RPKI objects and feed BGP routers with the validated prefix-ownership data. Consequently, any vulnerabilities or flaws within the RP software can substantially threaten the stability and security of Internet routing.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2024-1093-paper.pdf",
            "keywords": [
                "Resource Public Key Infrastructure (RPKI)",
                "BGP Route Validation",
                "Relying Party (RP) Implementations",
                "Internet Routing Security",
                "RPKI Vulnerabilities"
            ]
        },
        "url": "URL#358419",
        "sema_paperId": "a25478a9197a49e855c654b953933bfd2d00b981"
    },
    {
        "@score": "1",
        "@id": "358420",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "254/3236",
                        "text": "Nimish Mishra"
                    },
                    {
                        "@pid": "73/2286-3",
                        "text": "Anirban Chakraborty 0003"
                    },
                    {
                        "@pid": "85/3079",
                        "text": "Debdeep Mukhopadhyay"
                    }
                ]
            },
            "title": "Faults in Our Bus: Novel Bus Fault Attack to Break ARM TrustZone.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/Mishra0M24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/faults-in-our-bus-novel-bus-fault-attack-to-break-arm-trustzone/",
            "url": "https://dblp.org/rec/conf/ndss/Mishra0M24",
            "abstract": "\u2014The ever-increasing growth of Internet-of-Things (IoT) has led to wide-scale deployment of high-frequency, highly complex Systems-on-a-Chip (SoCs), which are capable of running a full-fledged operating system (OS). The presence of OS and other software countermeasures make SoCs resilient against the traditional fault attacks that are relevant on FPGAs and microprocessors. In this work, we present the first practical implications of targeting an orthogonal aspect of SoC\u2019s architecture: the system bus . We inject electromagnetic pulses onto the system bus during the execution of instructions involving processor-memory interaction. We show how address bus faults compromise software implementations of masked implementations of ciphers, illustrated using implementations of state-of-the-art post-quantum cryptography (PQC) schemes, leaking entire secret keys with a single fault . We also demonstrate that data bus faults can be controlled and exploited to launch Differential Fault Analysis (DFA) attacks on table-based implementation of the Advanced Encryption Standard (AES). Furthermore, we demonstrate that the impact of such bus faults can be far-reaching and mislead the security guarantees of the popular and widely used ARM TrustZone. We use data-bus faults (along with loopholes in the GlobalPlatform API specification) to mislead the signature verification step to load a malicious Trusted Application (TA) inside the TrustZone. We follow this up with address bus faults to steal symmetric encryption keys of other benign TAs in the system, leading to complete breakdown of security on TrustZone. We note that since the attack relies upon loopholes in the GlobalPlatform API specification, it is portable to any TEE following this specification. To emphasize upon this portability of the attack, we demonstrate successful installation of malicious TAs on two TrustZone implementations (OP-TEE and MyTEE) on two different platforms (Raspberry Pi 3 and Raspberry Pi 4). Finally, we propose countermeasures that can be integrated into the SoC environment to defend against these attack vectors.",
            "keywords": [
                "System-on-a-Chip (SoC)",
                "Fault Injection",
                "ARM TrustZone",
                "Differential Fault Analysis (DFA)",
                "Post-Quantum Cryptography (PQC)"
            ]
        },
        "url": "URL#358420",
        "sema_paperId": "6b43bde47f2f7d5f07632d5439c0db1e6f9db948"
    },
    {
        "@score": "1",
        "@id": "358421",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "295/1435",
                        "text": "Cameron Morris"
                    },
                    {
                        "@pid": "62/3150",
                        "text": "Amir Herzberg"
                    },
                    {
                        "@pid": "06/1909-1",
                        "text": "Bing Wang 0001"
                    },
                    {
                        "@pid": "385/8739",
                        "text": "Samuel Secondo"
                    }
                ]
            },
            "title": "BGP-iSec: Improved Security of Internet Routing Against Post-ROV Attacks.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/MorrisH0S24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/bgp-isec-improved-security-of-internet-routing-against-post-rov-attacks/",
            "url": "https://dblp.org/rec/conf/ndss/MorrisH0S24",
            "abstract": "\u2014We present BGP-iSec, an enhancement of the BGP-sec protocol for securing BGP, the Internet\u2019s inter-domain routing protocol. BGP-iSec ensures additional and stronger security properties, compared to BGPsec, without significant extra overhead. The main improvements are: (i) Security for partial adoption: BGP-iSec provides significant security benefits for early adopters, in contrast to BGPsec, which requires universal adoption. (ii) Defense against route leakage: BGP-iSec defends against route leakage, a common cause of misrouting that is not prevented by BGPsec. (iii) Integrity of attributes: BGP-iSec ensures the integrity of integrity-protected attributes , thereby preventing announcement manipulation attacks not prevented by BGPsec. We argue that BGP-iSec achieves these goals using extensive simulations as well as security analysis. The BGP-iSec design conforms, where possible, with the BGPsec design, modifying it only where necessary to improve security or ease deployment. By providing stronger security guarantees, especially for partial adoption, we hope BGP-iSec will be a step towards finally protecting inter-domain routing, which remains, for many years, a vulnerability of the Internet\u2019s infrastructure.",
            "keywords": [
                "BGP Security",
                "Inter-Domain Routing",
                "Route Leakage",
                "BGP-iSec",
                "Announcement Manipulation Attacks"
            ]
        },
        "url": "URL#358421",
        "sema_paperId": "a7587c2ebcadcd71876ef0901e73cdaf276330a9"
    },
    {
        "@score": "1",
        "@id": "358422",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "256/4491",
                        "text": "Ke Mu"
                    },
                    {
                        "@pid": "98/3612-4",
                        "text": "Bo Yin 0004"
                    },
                    {
                        "@pid": "07/10238",
                        "text": "Alia Asheralieva"
                    },
                    {
                        "@pid": "09/5916",
                        "text": "Xuetao Wei"
                    }
                ]
            },
            "title": "Separation is Good: A Faster Order-Fairness Byzantine Consensus.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/MuYAW24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/separation-is-good-a-faster-order-fairness-byzantine-consensus/",
            "url": "https://dblp.org/rec/conf/ndss/MuYAW24",
            "abstract": "\u2014Order-fairness has been introduced recently as a new property for Byzantine Fault-Tolerant (BFT) consensus protocol to prevent unilaterally deciding the final order of transactions, which allows mitigating the threat of adversarial transaction order manipulation attacks (e.g., front-running) in blockchain networks and decentralized finance (DeFi). However, existing leader-based order-fairness protocols (which do not rely on synchronized clocks) still suffer from poor performance since they strongly couple fair ordering with consensus processes. In this paper, we propose SpeedyFair , a high-performance order-fairness consensus protocol, which is motivated by our insight that the ordering of transactions does not rely on the execution results of transactions in previous proposals (after consensus). SpeedyFair achieves its efficiency through a decoupled design that performs fair ordering individually and consecutively, sepa-rating from consensus. In addition, by decoupling fair ordering from consensus, SpeedyFair enables parallelizing the order/verify mode that was originally executed serially in the consensus process, which further speeds up the performance. We implement a prototype of SpeedyFair on the top of the Hotstuff protocol. Extensive experimental results demonstrate that SpeedyFair significantly outperforms the state-of-the-art order-fairness protocol (i.e., Themis), which achieves a throughput of 1.5 \u00d7 -2.45 \u00d7 greater than Themis while reducing latency by 35%-59%.",
            "keywords": [
                "Byzantine Consensus",
                "Order-Fairness",
                "Transaction Ordering",
                "Decoupled Design",
                "Performance Improvement"
            ]
        },
        "url": "URL#358422",
        "sema_paperId": "bf6b90644e2f506c61bad5a7ba1d3eb8eca35800"
    },
    {
        "@score": "1",
        "@id": "358423",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "351/1090",
                        "text": "Yarin Ozery"
                    },
                    {
                        "@pid": "198/8291",
                        "text": "Asaf Nadler"
                    },
                    {
                        "@pid": "56/5380",
                        "text": "Asaf Shabtai"
                    }
                ]
            },
            "title": "Information Based Heavy Hitters for Real-Time DNS Data Exfiltration Detection.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/OzeryNS24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/information-based-heavy-hitters-for-real-time-dns-data-exfiltration-detection/",
            "url": "https://dblp.org/rec/conf/ndss/OzeryNS24",
            "abstract": "Data exfiltration over the DNS protocol and its detection have been researched extensively in recent years. Prior studies focused on offline detection methods, which although capable of detecting attacks, allow a large amount of data to be exfiltrated before the attack is detected and dealt with. In this paper, we introduce Information-based Heavy Hitters (ibHH), a real-time detection method which is based on live estimations of the amount of information transmitted to registered domains. ibHH uses constant-size memory and supports constant-time queries, which makes it suitable for deployment on recursive DNS servers to further reduce detection and response time. In our eval- uation, we compared the performance of the proposed method to that of leading state-of-the-art DNS exfiltration detection methods on real-world datasets comprising over 250 billion DNS queries. The evaluation demonstrates ibHH\u2019s ability to successfully detect exfiltration rates as slow as 0.7B/s, with a false positive alert rate of less than 0.004, with significantly lower resource consumption compared to other methods.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2024-388-paper.pdf",
            "keywords": [
                "DNS Data Exfiltration",
                "Real-Time Detection",
                "Information-Based Heavy Hitters",
                "Constant-Time Queries",
                "False Positive Rate"
            ]
        },
        "url": "URL#358423"
    },
    {
        "@score": "1",
        "@id": "358424",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "385/8453",
                        "text": "Nishit V. Pandya"
                    },
                    {
                        "@pid": "76/898",
                        "text": "Himanshu Kumar"
                    },
                    {
                        "@pid": "320/0342",
                        "text": "Gokulnath Pillai"
                    },
                    {
                        "@pid": "46/1879",
                        "text": "Vinod Ganapathy"
                    }
                ]
            },
            "title": "Decentralized Information-Flow Control for ROS2.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/PandyaKPG24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/decentralized-information-flow-control-for-ros2/",
            "url": "https://dblp.org/rec/conf/ndss/PandyaKPG24",
            "abstract": "\u2014ROS2 is a popular publish / subscribe based middleware that allows developers to build and deploy a wide-variety of distributed robotics applications. Unfortunately, ROS2 o ff ers applications poor control over how their data is consumed downstream by other applications. Although decentralized information-flow control (DIFC) o ff ers a solution to this problem, the decentralized and distributed architecture of ROS2 poses new challenges to building a practical DIFC system for ROS2. We present Picaros, a DIFC system tailored for ROS2. Picaros adopts a novel approach to DIFC that casts and solves DIFC\u2019s access control problem in the framework of attribute-based encryption (ABE). Picaros\u2019s design embraces the unique nature of the ROS2 platform and carefully avoids any centralized elements. This paper presents the design and implementation of Picaros and reports results from our experiments that use Picaros\u2019s ABE-based approach for DIFC with ROS2 applications.",
            "keywords": [
                "Decentralized Information-Flow Control",
                "ROS2",
                "Attribute-Based Encryption",
                "Access Control Problem",
                "Distributed Robotics Applications"
            ]
        },
        "url": "URL#358424",
        "sema_paperId": "17a113aab476afdbc4ee55aeff8c22b20fb20c60"
    },
    {
        "@score": "1",
        "@id": "358425",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "44/8421",
                        "text": "Qi Pang"
                    },
                    {
                        "@pid": "295/5277",
                        "text": "Yuanyuan Yuan"
                    },
                    {
                        "@pid": "42/1503-11",
                        "text": "Shuai Wang 0011"
                    }
                ]
            },
            "title": "MPCDiff: Testing and Repairing MPC-Hardened Deep Learning Models.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/PangY024",
            "ee": "https://www.ndss-symposium.org/ndss-paper/mpcdiff-testing-and-repairing-mpc-hardened-deep-learning-models/",
            "url": "https://dblp.org/rec/conf/ndss/PangY024",
            "abstract": "\u2014Secure multi-party computation (MPC) has recently become prominent as a concept to enable multiple parties to perform privacy-preserving machine learning without leaking sensitive data or details of pre-trained models to the other parties. Industry and the community have been actively developing and promoting high-quality MPC frameworks (e.g., based on TensorFlow and PyTorch) to enable the usage of MPC-hardened models, greatly easing the development cycle of integrating deep learning models with MPC primitives. Despite the prosperous development and adoption of MPC frameworks, a principled and systematic understanding toward the correctness of those MPC frameworks does not yet exist. To \ufb01ll this critical gap, this paper introduces MPCD IFF , a differential testing framework to effectively uncover inputs that cause deviant outputs of MPC-hardened models and their plaintext versions. We further develop techniques to localize error-causing computation units in MPC-hardened models and automatically repair those defects. We evaluate MPCD IFF using real-world popular MPC frameworks for deep learning developed by Meta (Facebook), Alibaba Group, Cape Privacy, and OpenMined. MPCD IFF successfully detected over one thousand inputs that result in largely deviant outputs. These deviation-triggering inputs are (visually) meaningful in comparison to regular inputs, indicating that our \ufb01ndings may cause great confusion in the daily usage of MPC frameworks. After localizing and repairing error-causing computation units, the robustness of MPC-hardened models can be notably enhanced without sacri\ufb01cing accuracy and with negligible overhead.",
            "keywords": [
                "MPC Frameworks",
                "Differential Testing",
                "Error Localization",
                "Model Robustness",
                "MPC-Hardened Models"
            ]
        },
        "url": "URL#358425",
        "sema_paperId": "cb70bd5a1bcaf9db56bbfac55f9bbd6a6b8639ed"
    },
    {
        "@score": "1",
        "@id": "358426",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "170/5430",
                        "text": "Chanyoung Park"
                    },
                    {
                        "@pid": "119/7680",
                        "text": "Hyungon Moon"
                    }
                ]
            },
            "title": "Efficient Use-After-Free Prevention with Opportunistic Page-Level Sweeping.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ParkM24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/efficient-use-after-free-prevention-with-opportunistic-page-level-sweeping/",
            "url": "https://dblp.org/rec/conf/ndss/ParkM24",
            "abstract": "\u2014Defeating use-after-free exploits presents a challenging problem, one for which a universal solution remains elusive. Recent efforts towards efficient prevention of use-after-free exploits have found that delaying the reuse of freed memory can both be effective and efficient in many cases. Previous studies have proposed two primary approaches: one where reuse is postponed until the allocator can confidently ascertain the absence of any dangling pointers to the freed memory, and another that refrains from reusing a freed heap chunk until the program\u2019s termination. We make an intriguing observation from our in-depth analysis of these two approaches and their reported performance impacts. When compared to the design that delays the reuse until the program terminates the strategy that delays the reuse just until no dangling pointer references the freed chunk suffers from a significant performance overhead for some workloads. The change in the reuse of each heap chunk affects the distribution of allocated chunks in the heap, and the performance of some benchmarks. This study proposes H USH V AC , an allocator that performs delayed reuse in such a way that the distribution of heap chunks becomes more friendly to such workloads. An evaluation of H USH V AC showed that the average performance overhead of H USH V AC (4.7%) was lower than that of the state-of-the-art (11.4%) when running the SPEC CPU 2006 benchmark suite. Specifically, the overhead of H USH V AC on the distribution-sensitive benchmark was about 35.2% while the prior work has an overhead of 110%.",
            "keywords": [
                "Use-After-Free Prevention",
                "Memory Management",
                "Heap Allocator",
                "Performance Overhead",
                "Delayed Reuse Strategy"
            ]
        },
        "url": "URL#358426",
        "sema_paperId": "e6c0e76e30e42e67a13c1260efd49ceef818752e"
    },
    {
        "@score": "1",
        "@id": "358427",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "243/7002",
                        "text": "Hengzhi Pei"
                    },
                    {
                        "@pid": "24/5124-1",
                        "text": "Jinyuan Jia 0001"
                    },
                    {
                        "@pid": "144/1238-2",
                        "text": "Wenbo Guo 0002"
                    },
                    {
                        "@pid": "50/3402-26",
                        "text": "Bo Li 0026"
                    },
                    {
                        "@pid": "s/DXSong",
                        "text": "Dawn Song"
                    }
                ]
            },
            "title": "TextGuard: Provable Defense against Backdoor Attacks on Text Classification.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/Pei000S24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/textguard-provable-defense-against-backdoor-attacks-on-text-classification/",
            "url": "https://dblp.org/rec/conf/ndss/Pei000S24",
            "abstract": "Backdoor attacks have become a major security threat for deploying machine learning models in security-critical applications. Existing research endeavors have proposed many defenses against backdoor attacks. Despite demonstrating certain empirical defense efficacy, none of these techniques could provide a formal and provable security guarantee against arbitrary attacks. As a result, they can be easily broken by strong adaptive attacks, as shown in our evaluation. In this work, we propose TextGuard, the first provable defense against backdoor attacks on text classification. In particular, TextGuard first divides the (backdoored) training data into sub-training sets, achieved by splitting each training sentence into sub-sentences. This partitioning ensures that a majority of the sub-training sets do not contain the backdoor trigger. Subsequently, a base classifier is trained from each sub-training set, and their ensemble provides the final prediction. We theoretically prove that when the length of the backdoor trigger falls within a certain threshold, TextGuard guarantees that its prediction will remain unaffected by the presence of the triggers in training and testing inputs. In our evaluation, we demonstrate the effectiveness of TextGuard on three benchmark text classification tasks, surpassing the certification accuracy of existing certified defenses against backdoor attacks. Furthermore, we propose additional strategies to enhance the empirical performance of TextGuard. Comparisons with state-of-the-art empirical defenses validate the superiority of TextGuard in countering multiple backdoor attacks. Our code and data are available at https://github.com/AI-secure/TextGuard.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2024-90-paper.pdf",
            "keywords": [
                "Backdoor Attacks",
                "Text Classification",
                "Provable Defense",
                "TextGuard",
                "Empirical Performance"
            ]
        },
        "url": "URL#358427"
    },
    {
        "@score": "1",
        "@id": "358428",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "353/0383",
                        "text": "Ryan Pickren"
                    },
                    {
                        "@pid": "187/9868",
                        "text": "Tohid Shekari"
                    },
                    {
                        "@pid": "89/4316",
                        "text": "Saman A. Zonouz"
                    },
                    {
                        "@pid": "12/6354",
                        "text": "Raheem Beyah"
                    }
                ]
            },
            "title": "Compromising Industrial Processes using Web-Based Programmable Logic Controller Malware.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/PickrenSZB24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/compromising-industrial-processes-using-web-based-programmable-logic-controller-malware/",
            "url": "https://dblp.org/rec/conf/ndss/PickrenSZB24",
            "abstract": "\u2014We present a novel approach to developing programmable logic controller (PLC) malware that proves to be more flexible, resilient, and impactful than current strategies. While previous attacks on PLCs infect either the control logic or firmware portions of PLC computation, our proposed malware exclusively infects the web application hosted by the emerging embedded webservers within the PLCs. This strategy allows the malware to stealthily attack the underlying real-world machinery using the legitimate web application program interfaces (APIs) exposed by the admin portal website. Such attacks include falsifying sensor readings, disabling safety alarms, and manipulating physical actuators. Furthermore, this approach has significant advantages over existing PLC malware techniques (control logic and firmware) such as platform independence, ease-of-deployment, and higher levels of persistence. Our research shows that the emergence of web technology in industrial control environments has introduced new security concerns that are not present in the IT domain or consumer IoT devices. Depending on the industrial process being controlled by the PLC, our attack can potentially cause catastrophic incidents or even loss of life. We verified these claims by performing a Stuxnet-style attack using a prototype implementation of this malware on a widely-used PLC model by exploiting zero-day vulnerabilities that we discovered during our research 1 . Our investigation reveals that every major PLC vendor (80% of global market share [1]) produces a PLC that is vulnerable to our proposed attack vector. Lastly, we discuss potential countermeasures and mitigations.",
            "keywords": [
                "PLC Malware",
                "Industrial Control Systems",
                "Web-Based Attacks",
                "Zero-Day Vulnerabilities",
                "Sensor Manipulation"
            ]
        },
        "url": "URL#358428",
        "sema_paperId": "d20766a7259f14c864d4d5bd8de47ae552227438"
    },
    {
        "@score": "1",
        "@id": "358429",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "331/2299",
                        "text": "Lancheng Qin"
                    },
                    {
                        "@pid": "c/LiChen8",
                        "text": "Li Chen 0008"
                    },
                    {
                        "@pid": "48/4185-1",
                        "text": "Dan Li 0001"
                    },
                    {
                        "@pid": "01/4124",
                        "text": "Honglin Ye"
                    },
                    {
                        "@pid": "41/1658",
                        "text": "Yutian Wang"
                    }
                ]
            },
            "title": "Understanding Route Origin Validation (ROV) Deployment in the Real World and Why MANRS Action 1 Is Not Followed.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/Qin00YW24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/understanding-route-origin-validation-rov-deployment-in-the-real-world-and-why-manrs-action-1-is-not-followed/",
            "url": "https://dblp.org/rec/conf/ndss/Qin00YW24",
            "abstract": "\u2014BGP hijacking is one of the most important threats to routing security. To improve the reliability and availability of inter-domain routing, a lot of work has been done to defend against BGP hijacking, and Route Origin Validation (ROV) has become the best current practice. However, although the Mutually Agreed Norms for Routing Security (MANRS) has been encouraging network operators to at least validate announcements of their customers, recent research indicates that a large number of networks still do not fully deploy ROV or propagate illegitimate announcements of their customers. To understand ROV deployment in the real world and why network operators are not following the action proposed by MANRS, we make a long-term measurement for ROV deployment and further find that many non-compliant networks may deploy ROV only at part of customer interfaces, or at provider or peer interfaces. Then, we present the first notification experiment to investigate the impact of notifications on ROV remediation. However, our analysis indicates that none of the notification treatments has a significant effect. After that, we conduct a survey among network operators and find that economical and technical problems are the two major classes of reasons for non-compliance. Seeking a realistic ROV deployment strategy, we perform large-scale simulations, and, to our surprise, find that not following MANRS Action 1 can lead to better defence of prefix hijacking. Finally, with all our findings, we provide practical recommendations and outline future directions to help promote ROV deployment.",
            "keywords": [
                "BGP Hijacking",
                "Route Origin Validation",
                "Routing Security",
                "MANRS Compliance",
                "Network Operator Challenges"
            ]
        },
        "url": "URL#358429",
        "sema_paperId": "327bdfdff735d85e58e0c31d81466b3fdd7d6676"
    },
    {
        "@score": "1",
        "@id": "358430",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "356/7457",
                        "text": "Yuqi Qing"
                    },
                    {
                        "@pid": "230/1810",
                        "text": "Qilei Yin"
                    },
                    {
                        "@pid": "247/1165",
                        "text": "Xinhao Deng"
                    },
                    {
                        "@pid": "205/4031",
                        "text": "Yihao Chen"
                    },
                    {
                        "@pid": "69/11514",
                        "text": "Zhuotao Liu"
                    },
                    {
                        "@pid": "30/3530-1",
                        "text": "Kun Sun 0001"
                    },
                    {
                        "@pid": "181/2626-2",
                        "text": "Ke Xu 0002"
                    },
                    {
                        "@pid": "80/2266-4",
                        "text": "Jia Zhang 0004"
                    },
                    {
                        "@pid": "181/2688-2",
                        "text": "Qi Li 0002"
                    }
                ]
            },
            "title": "Low-Quality Training Data Only? A Robust Framework for Detecting Encrypted Malicious Network Traffic.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/QingYDCL000024",
            "ee": "https://www.ndss-symposium.org/ndss-paper/low-quality-training-data-only-a-robust-framework-for-detecting-encrypted-malicious-network-traffic/",
            "url": "https://dblp.org/rec/conf/ndss/QingYDCL000024",
            "abstract": "Machine learning (ML) is promising in accurately detecting malicious flows in encrypted network traffic; however, it is challenging to collect a training dataset that contains a sufficient amount of encrypted malicious data with correct labels. When ML models are trained with low-quality training data, they suffer degraded performance. In this paper, we aim at addressing a real-world low-quality training dataset problem, namely, detecting encrypted malicious traffic generated by continuously evolving malware. We develop RAPIER that fully utilizes different distributions of normal and malicious traffic data in the feature space, where normal data is tightly distributed in a certain area and the malicious data is scattered over the entire feature space to augment training data for model training. RAPIER includes two pre-processing modules to convert traffic into feature vectors and correct label noises. We evaluate our system on two public datasets and one combined dataset. With 1000 samples and 45% noises from each dataset, our system achieves the F1 scores of 0.770, 0.776, and 0.855, respectively, achieving average improvements of 352.6%, 284.3%, and 214.9% over the existing methods, respectively. Furthermore, We evaluate RAPIER with a real-world dataset obtained from a security enterprise. RAPIER effectively achieves encrypted malicious traffic detection with the best F1 score of 0.773 and improves the F1 score of existing methods by an average of 272.5%.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2024-81-paper.pdf",
            "keywords": [
                "Encrypted Traffic Detection",
                "Malicious Network Traffic",
                "Low-Quality Training Data",
                "Feature Space Distribution",
                "RAPIER Framework"
            ]
        },
        "url": "URL#358430"
    },
    {
        "@score": "1",
        "@id": "358431",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "362/2615",
                        "text": "Fabian Rauscher"
                    },
                    {
                        "@pid": "280/4649",
                        "text": "Andreas Kogler"
                    },
                    {
                        "@pid": "207/7615",
                        "text": "Jonas Juffinger"
                    },
                    {
                        "@pid": "166/1494",
                        "text": "Daniel Gruss"
                    }
                ]
            },
            "title": "IdleLeak: Exploiting Idle State Side Effects for Information Leakage.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/RauscherKJG24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/idleleak-exploiting-idle-state-side-effects-for-information-leakage/",
            "url": "https://dblp.org/rec/conf/ndss/RauscherKJG24",
            "abstract": "\u2014Modern processors are equipped with numerous features to regulate energy consumption according to the work-load. For this purpose, software brings processor cores into idle states via dedicated instructions such as hlt . Recently, Intel introduced the C0.1 and C0.2 idle states. While idle states previously could only be reached via privileged operations, these new idle states can also be reached by an unprivileged attacker. However, the attack surface these idle states open is still unclear. In this paper, we present IdleLeak, a novel side-channel attack exploiting the new C0.1 and C0.2 idle states in two distinct ways. Specifically, we exploit the processor idle state C0.2 to monitor system activity and for novel means of data exfiltration, and the idle state C0.1 to monitor system activity on logical sibling cores. IdleLeak still works regardless of where the victim workload is scheduled, i.e. , cross-core, due to the low-level x86 design. We demonstrate that IdleLeak leaks significant information in a native keystroke-timing attack, achieving an F1 score of 90 . 5 % and a standard error on the timing prediction of only 12 \u00b5s. We also demonstrate website-and video-fingerprinting attacks using IdleLeak traces, pre-processed with short-time Fourier transforms, and classified with convolutional neural networks. These attacks are highly practical with F1 scores of 85 . 2 % (open-world website fingerprinting) and 81 . 5 % (open-world video fingerprinting). We evaluate the throughput of IdleLeak side channels in both directions in covert channel scenarios, i.e. , using interrupts and performance-increasing effects. With the performance-increasing effect, IdleLeak achieves a true capacity of 7 . 1 Mbit/s in a native and 46 . 3 kbit/s in a cross-VM scenario",
            "keywords": [
                "Side-Channel Attacks",
                "Idle States",
                "Information Leakage",
                "Data Exfiltration",
                "Keystroke Timing Attack"
            ]
        },
        "url": "URL#358431",
        "sema_paperId": "d82809498ebb0d636bf43c565c302037014b0ac3"
    },
    {
        "@score": "1",
        "@id": "358432",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "190/9213",
                        "text": "Ge Ren"
                    },
                    {
                        "@pid": "176/5848",
                        "text": "Gaolei Li"
                    },
                    {
                        "@pid": "47/1217-1",
                        "text": "Shenghong Li 0001"
                    },
                    {
                        "@pid": "08/4315",
                        "text": "Libo Chen"
                    },
                    {
                        "@pid": "20/6179-1",
                        "text": "Kui Ren 0001"
                    }
                ]
            },
            "title": "ActiveDaemon: Unconscious DNN Dormancy and Waking Up via User-specific Invisible Token.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/RenL0C024",
            "ee": "https://www.ndss-symposium.org/ndss-paper/activedaemon-unconscious-dnn-dormancy-and-waking-up-via-user-specific-invisible-token/",
            "url": "https://dblp.org/rec/conf/ndss/RenL0C024",
            "abstract": "\u2014Well-trained deep neural network (DNN) models can be treated as commodities for commercial transactions and generate significant revenues, raising the urgent need for intellectual property (IP) protection against illegitimate reproducing. Emerging studies on IP protection often aim at inserting watermarks into DNNs, allowing owners to passively verify the ownership of target models after counterfeit models appear and commercial benefits are infringed, while active authentication against unauthorized queries of DNN-based applications is still neglected. In this paper, we propose a novel approach to protect model intellectual property, called ActiveDaemon, which incorporates a built-in access control function in DNNs to safeguard against commercial piracy. Specifically, our approach enables DNNs to predict correct outputs only for authorized users with user-specific tokens while producing poor accuracy for unauthorized users. In ActiveDaemon, the user-specific tokens are generated by a specially designed U-Net style encoder-decoder network, which can map strings and input images into numerous noise images to address identity management with large-scale user capacity. Compared to existing studies, these user-specific tokens are invisible, dynamic and more perceptually concealed, enhancing the stealthiness and reliability of model IP protection. To automatically wake up the model accuracy, we utilize the data poisoning-based training technique to unconsciously embed the ActiveDaemon into the neuron\u2019s function. We conduct experiments to compare the protection performance of ActiveDaemon with four state-of-the-art approaches over four datasets. The experimental results show that ActiveDaemon can reduce the accuracy of unauthorized queries by as much as 81% with less than a 1.4% decrease in that of authorized queries. Meanwhile, our approach can also reduce the LPIPS scores of the authorized tokens to 0.0027 on CIFAR10 and 0.0368 on ImageNet 1 .",
            "keywords": [
                "DNN Intellectual Property Protection",
                "Active Authentication",
                "User-specific Tokens",
                "Model Accuracy Control",
                "Commercial Piracy Prevention"
            ]
        },
        "url": "URL#358432",
        "sema_paperId": "d36b7ea6ee806387ca5452099fd088f41d49f60d"
    },
    {
        "@score": "1",
        "@id": "358433",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "283/4641",
                        "text": "Phillip Rieger"
                    },
                    {
                        "@pid": "331/2127",
                        "text": "Torsten Krau\u00df"
                    },
                    {
                        "@pid": "05/617",
                        "text": "Markus Miettinen"
                    },
                    {
                        "@pid": "67/8264",
                        "text": "Alexandra Dmitrienko"
                    },
                    {
                        "@pid": "s/AhmadRezaSadeghi",
                        "text": "Ahmad-Reza Sadeghi"
                    }
                ]
            },
            "title": "CrowdGuard: Federated Backdoor Detection in Federated Learning.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/RiegerKMDS24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/crowdguard-federated-backdoor-detection-in-federated-learning/",
            "url": "https://dblp.org/rec/conf/ndss/RiegerKMDS24",
            "abstract": "Federated Learning (FL) is a promising approach enabling multiple clients to train Deep Neural Networks (DNNs) collaboratively without sharing their local training data. However, FL is susceptible to backdoor (or targeted poisoning) attacks. These attacks are initiated by malicious clients who seek to compromise the learning process by introducing specific behaviors into the learned model that can be triggered by carefully crafted inputs. Existing FL safeguards have various limitations: They are restricted to specific data distributions or reduce the global model accuracy due to excluding benign models or adding noise, are vulnerable to adaptive defense-aware adversaries, or require the server to access local models, allowing data inference attacks. This paper presents a novel defense mechanism, CrowdGuard, that effectively mitigates backdoor attacks in FL and overcomes the deficiencies of existing techniques. It leverages clients' feedback on individual models, analyzes the behavior of neurons in hidden layers, and eliminates poisoned models through an iterative pruning scheme. CrowdGuard employs a server-located stacked clustering scheme to enhance its resilience to rogue client feedback. The evaluation results demonstrate that CrowdGuard achieves a 100% True-Positive-Rate and True-Negative-Rate across various scenarios, including IID and non-IID data distributions. Additionally, CrowdGuard withstands adaptive adversaries while preserving the original performance of protected models. To ensure confidentiality, CrowdGuard uses a secure and privacy-preserving architecture leveraging Trusted Execution Environments (TEEs) on both client and server sides.",
            "keywords": [
                "Federated Learning",
                "Backdoor Attacks",
                "Model Poisoning",
                "Client Feedback Analysis",
                "Privacy-Preserving Architecture"
            ]
        },
        "url": "URL#358433",
        "sema_paperId": "a75b291b72663a846d57189218b809fea82dc6a1"
    },
    {
        "@score": "1",
        "@id": "358434",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "218/0179",
                        "text": "Nicola Ruaro"
                    },
                    {
                        "@pid": "201/9325",
                        "text": "Fabio Gritti"
                    },
                    {
                        "@pid": "10/6810",
                        "text": "Robert McLaughlin"
                    },
                    {
                        "@pid": "180/7263",
                        "text": "Ilya Grishchenko"
                    },
                    {
                        "@pid": "k/ChristopherKruegel",
                        "text": "Christopher Kruegel"
                    },
                    {
                        "@pid": "v/GiovanniVigna",
                        "text": "Giovanni Vigna"
                    }
                ]
            },
            "title": "Not your Type! Detecting Storage Collision Vulnerabilities in Ethereum Smart Contracts.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/RuaroGMGKV24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/not-your-type-detecting-storage-collision-vulnerabilities-in-ethereum-smart-contracts/",
            "url": "https://dblp.org/rec/conf/ndss/RuaroGMGKV24",
            "abstract": "\u2014In recent years, the Ethereum blockchain has seen significant growth and adoption. One of the key factors of its success is the possibility to run immutable programs known as smart contracts . Smart contracts allow for the automatic manipulation of digital assets and play a central role in the new decentralized finance (DeFi) ecosystem. With the growth of DeFi, the interactions between smart contracts have become increasingly complex, enabling advanced financial protocols and applications. However, bugs in smart contract interactions are also a common cause of critical vulnerabilities that result in considerable financial losses. In this paper, we study and detect a type of cross-contract vulnerability known as a storage collision . A smart contract uses storage to persistently store its data on the blockchain. Typically, each contract has its own separate storage. However, it is also possible that two smart contracts share their storage (using a delegate call). Unfortunately, when these two contracts have different understandings of the types/semantics of their shared storage, a storage collision vulnerability can occur. This may lead to unexpected behavior such as denial of service (frozen funds), privilege escalation, and theft of financial assets. To detect and investigate the impact of storage collision vulnerabilities at scale, we propose C RUSH , a novel analysis system that discovers these flaws and synthesizes proof-of-concept exploits. We leverage C RUSH to perform a large-scale analysis of 14,237,696 smart contracts deployed on the Ethereum blockchain since its genesis. C RUSH identifies 14,891 potentially vulnerable contracts and automatically synthesizes an end-to-end exploit for 956 of them. Our system uncovers more than $6 million of novel, previously unreported potential financial damage caused by storage collision vulnerabilities.",
            "keywords": [
                "Ethereum Smart Contracts",
                "Storage Collision",
                "Cross-Contract Vulnerability",
                "Decentralized Finance (DeFi)",
                "Financial Exploits"
            ]
        },
        "url": "URL#358434",
        "sema_paperId": "dabe9b8e1a1484bdbaf1beacef452c3e8bd32eab"
    },
    {
        "@score": "1",
        "@id": "358435",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "249/5653",
                        "text": "Fan Sang"
                    },
                    {
                        "@pid": "127/7890",
                        "text": "Jaehyuk Lee"
                    },
                    {
                        "@pid": "158/4724",
                        "text": "Xiaokuan Zhang"
                    },
                    {
                        "@pid": "75/4287",
                        "text": "Meng Xu"
                    },
                    {
                        "@pid": "303/0434",
                        "text": "Scott Constable"
                    },
                    {
                        "@pid": "152/3962",
                        "text": "Yuan Xiao"
                    },
                    {
                        "@pid": "64/5301-1",
                        "text": "Michael Steiner 0001"
                    },
                    {
                        "@pid": "47/9256",
                        "text": "Mona Vij"
                    },
                    {
                        "@pid": "38/8882",
                        "text": "Taesoo Kim"
                    }
                ]
            },
            "title": "SENSE: Enhancing Microarchitectural Awareness for TEEs via Subscription-Based Notification.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/SangLZXCX0VK24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/sense-enhancing-microarchitectural-awareness-for-tees-via-subscription-based-notification/",
            "url": "https://dblp.org/rec/conf/ndss/SangLZXCX0VK24",
            "abstract": "\u2014Effectively mitigating side-channel attacks (SCAs) in Trusted Execution Environments (TEEs) remains challenging despite advances in existing defenses. Current detection-based defenses hinge on observing abnormal victim performance characteristics but struggle to detect attacks leaking smaller portions of the secret across multiple executions. Limitations of existing detection-based defenses stem from various factors, including the absence of a trusted microarchitectural data source in TEEs, low-quality available data, inflexibility of victim responses, and platform-specific constraints. We contend that the primary obstacles to effective detection techniques can be attributed to the lack of direct access to precise microarchitectural information within TEEs. We propose S ENSE , a solution that actively exposes underlying microarchitectural information to userspace TEEs. S ENSE enables userspace software in TEEs to subscribe to fine-grained microarchitectural events and utilize the events as a means to contextualize the ongoing microarchitectural states. We initially demonstrate S ENSE \u2019s capability by applying it to defeat the state-of-the-art cache-based side-channel attacks. We conduct a comprehensive security analysis to ensure that S ENSE does not leak more information than a system without it does. We prototype S ENSE on a gem5-based emulator, and our evaluation shows that S ENSE is secure, can effectively defeats cache SCAs, and incurs negligible performance overhead (1.2%) under benign situations.",
            "keywords": [
                "Trusted Execution Environments",
                "Side-Channel Attacks",
                "Microarchitectural Awareness",
                "Cache-Based Attacks",
                "Performance Overhead"
            ]
        },
        "url": "URL#358435",
        "sema_paperId": "d0d71c3b8a8d6a75e4c1611ac9316af2960f9d33"
    },
    {
        "@score": "1",
        "@id": "358436",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "212/7432",
                        "text": "Takami Sato"
                    },
                    {
                        "@pid": "331/5580",
                        "text": "Sri Hrushikesh Varma Bhupathiraju"
                    },
                    {
                        "@pid": "51/793",
                        "text": "Michael Clifford"
                    },
                    {
                        "@pid": "68/2734",
                        "text": "Takeshi Sugawara 0001"
                    },
                    {
                        "@pid": "150/3272",
                        "text": "Qi Alfred Chen"
                    },
                    {
                        "@pid": "135/7828",
                        "text": "Sara Rampazzi"
                    }
                ]
            },
            "title": "Invisible Reflections: Leveraging Infrared Laser Reflections to Target Traffic Sign Perception.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/SatoBC0CR24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/invisible-reflections-leveraging-infrared-laser-reflections-to-target-traffic-sign-perception/",
            "url": "https://dblp.org/rec/conf/ndss/SatoBC0CR24",
            "abstract": "All vehicles must follow the rules that govern traffic behavior, regardless of whether the vehicles are human-driven or Connected Autonomous Vehicles (CAVs). Road signs indicate locally active rules, such as speed limits and requirements to yield or stop. Recent research has demonstrated attacks, such as adding stickers or projected colored patches to signs, that cause CAV misinterpretation, resulting in potential safety issues. Humans can see and potentially defend against these attacks. But humans can not detect what they can not observe. We have developed an effective physical-world attack that leverages the sensitivity of filterless image sensors and the properties of Infrared Laser Reflections (ILRs), which are invisible to humans. The attack is designed to affect CAV cameras and perception, undermining traffic sign recognition by inducing misclassification. In this work, we formulate the threat model and requirements for an ILR-based traffic sign perception attack to succeed. We evaluate the effectiveness of the ILR attack with real-world experiments against two major traffic sign recognition architectures on four IR-sensitive cameras. Our black-box optimization methodology allows the attack to achieve up to a 100% attack success rate in indoor, static scenarios and a>80.5% attack success rate in our outdoor, moving vehicle scenarios. We find the latest state-of-the-art certifiable defense is ineffective against ILR attacks as it mis-certifies>33.5% of cases. To address this, we propose a detection strategy based on the physical properties of IR laser reflections which can detect 96% of ILR attacks.",
            "keywords": [
                "Connected Autonomous Vehicles",
                "Traffic Sign Recognition",
                "Infrared Laser Reflections",
                "Perception Attack",
                "Detection Strategy"
            ]
        },
        "url": "URL#358436",
        "sema_paperId": "2387b80f30767a6cb92481819cdb3aae4e9c3643"
    },
    {
        "@score": "1",
        "@id": "358437",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "212/7432",
                        "text": "Takami Sato"
                    },
                    {
                        "@pid": "75/9299",
                        "text": "Yuki Hayakawa"
                    },
                    {
                        "@pid": "94/909",
                        "text": "Ryo Suzuki"
                    },
                    {
                        "@pid": "244/7602",
                        "text": "Yohsuke Shiiki"
                    },
                    {
                        "@pid": "38/7609",
                        "text": "Kentaro Yoshioka"
                    },
                    {
                        "@pid": "150/3272",
                        "text": "Qi Alfred Chen"
                    }
                ]
            },
            "title": "LiDAR Spoofing Meets the New-Gen: Capability Improvements, Broken Assumptions, and New Attack Strategies.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/SatoHSSYC24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/lidar-spoofing-meets-the-new-gen-capability-improvements-broken-assumptions-and-new-attack-strategies/",
            "url": "https://dblp.org/rec/conf/ndss/SatoHSSYC24",
            "abstract": "LiDAR (Light Detection And Ranging) is an indispensable sensor for precise long- and wide-range 3D sensing, which directly benefited the recent rapid deployment of autonomous driving (AD). Meanwhile, such a safety-critical application strongly motivates its security research. A recent line of research finds that one can manipulate the LiDAR point cloud and fool object detectors by firing malicious lasers against LiDAR. However, these efforts face 3 critical research gaps: (1) considering only one specific LiDAR (VLP-16); (2) assuming unvalidated attack capabilities; and (3) evaluating object detectors with limited spoofing capability modeling and setup diversity. To fill these critical research gaps, we conduct the first large-scale measurement study on LiDAR spoofing attack capabilities on object detectors with 9 popular LiDARs, covering both first- and new-generation LiDARs, and 3 major types of object detectors trained on 5 different datasets. To facilitate the measurements, we (1) identify spoofer improvements that significantly improve the latest spoofing capability, (2) identify a new object removal attack that overcomes the applicability limitation of the latest method to new-generation LiDARs, and (3) perform novel mathematical modeling for both object injection and removal attacks based on our measurement results. Through this study, we are able to uncover a total of 15 novel findings, including not only completely new ones due to the measurement angle novelty, but also many that can directly challenge the latest understandings in this problem space. We also discuss defenses.",
            "keywords": [
                "LiDAR Spoofing",
                "Autonomous Driving",
                "Object Detection",
                "Point Cloud Manipulation",
                "Attack Strategies"
            ]
        },
        "url": "URL#358437",
        "sema_paperId": "ef8e31932c8d436b710feb2b1f59ba748573af37"
    },
    {
        "@score": "1",
        "@id": "358438",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "306/0783",
                        "text": "Gianluca Scopelliti"
                    },
                    {
                        "@pid": "09/7271",
                        "text": "Christoph Baumann"
                    },
                    {
                        "@pid": "217/3027",
                        "text": "Fritz Alder"
                    },
                    {
                        "@pid": "43/5593",
                        "text": "Eddy Truyen"
                    },
                    {
                        "@pid": "84/4044",
                        "text": "Jan Tobias M\u00fchlberg"
                    }
                ]
            },
            "title": "Efficient and Timely Revocation of V2X Credentials.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ScopellitiBATM24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/efficient-and-timely-revocation-of-v2x-credentials/",
            "url": "https://dblp.org/rec/conf/ndss/ScopellitiBATM24",
            "abstract": "\u2014In Intelligent Transport Systems, secure communication between vehicles, infrastructure, and other road users is critical to maintain road safety. This includes the revocation of cryptographic credentials of misbehaving or malicious vehicles in a timely manner. However, current standards are vague about how revocation should be handled, and recent surveys suggest severe limitations in the scalability and effectiveness of existing revocation schemes. In this paper, we present a formally verified mechanism for self-revocation of Vehicle-to-Everything (V2X) pseudonymous credentials, which relies on a trusted processing element in vehicles but does not require a trusted time source. Our scheme is compatible with ongoing standardization efforts and, leveraging the Tamarin prover, is the first to guarantee the actual revocation of credentials with a predictable upper bound on revocation time and in the presence of realistic attackers. We test our revocation mechanism in a virtual 5G-Edge deployment scenario where a large number of vehicles communicate with each other, simulating real-world conditions such as network malfunctions and delays. Results show that our scheme upholds formal guarantees in practice, while exhibiting low network overhead and good scalability.",
            "keywords": [
                "Intelligent Transport Systems",
                "V2X Communication",
                "Credential Revocation",
                "Scalability",
                "Self-Revocation Mechanism"
            ]
        },
        "url": "URL#358438",
        "sema_paperId": "b38a2c9a8c1b8d05399addfe2a5bee8adaf53ebf"
    },
    {
        "@score": "1",
        "@id": "358439",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "275/3798",
                        "text": "Christoph Sendner"
                    },
                    {
                        "@pid": "295/8221",
                        "text": "Jasper Stang"
                    },
                    {
                        "@pid": "67/8264",
                        "text": "Alexandra Dmitrienko"
                    },
                    {
                        "@pid": "241/1641",
                        "text": "Raveen Wijewickrama"
                    },
                    {
                        "@pid": "09/5967",
                        "text": "Murtuza Jadliwala"
                    }
                ]
            },
            "title": "MirageFlow: A New Bandwidth Inflation Attack on Tor.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/SendnerSDWJ24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/mirageflow-a-new-bandwidth-inflation-attack-on-tor/",
            "url": "https://dblp.org/rec/conf/ndss/SendnerSDWJ24",
            "abstract": "\u2014The Tor network is the most prominent system for providing anonymous communication to web users, with a daily user base of 2 million users. However, since its inception, it has been constantly targeted by various traffic fingerprinting and correlation attacks aiming at deanonymizing its users. A critical requirement for these attacks is to attract as much user traffic to adversarial relays as possible, which is typically accomplished by means of bandwidth inflation attacks. This paper proposes a new inflation attack vector in Tor, referred to as MirageFlow, which enables inflation of measured bandwidth. The underlying attack technique exploits resource sharing among Tor relay nodes and employs a cluster of attacker-controlled relays with coordinated resource allocation within the cluster to deceive bandwidth measurers into believing that each relay node in the cluster possesses ample resources. We propose two attack variants, C-MirageFlow and D-MirageFlow, and test both versions in a private Tor test network. Our evaluation demonstrates that an attacker can inflate the measured bandwidth by a factor close to n using C-MirageFlow and nearly half n \u2217 N using D-MirageFlow, where n is the size of the cluster hosted on one server and N is the number of servers. Furthermore, our theoretical analysis reveals that gaining control over half of the Tor network\u2019s traffic can be achieved by employing just 10 dedicated servers with a cluster size of 109 relays running the MirageFlow attack, each with a bandwidth of 100MB/s. The problem is further exacerbated by the fact that Tor not only allows resource sharing but, according to recent reports, even promotes it.",
            "keywords": [
                "Tor Network",
                "Bandwidth Inflation Attack",
                "Traffic Fingerprinting",
                "Anonymity Compromise",
                "MirageFlow"
            ]
        },
        "url": "URL#358439",
        "sema_paperId": "4950460f41d9026326c01d66db7532cacce424ce"
    },
    {
        "@score": "1",
        "@id": "358440",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "253/8366",
                        "text": "Lujia Shen"
                    },
                    {
                        "@pid": "220/9652",
                        "text": "Yuwen Pu"
                    },
                    {
                        "@pid": "07/8388",
                        "text": "Shouling Ji"
                    },
                    {
                        "@pid": "216/3218",
                        "text": "Changjiang Li"
                    },
                    {
                        "@pid": "139/6932-2",
                        "text": "Xuhong Zhang 0002"
                    },
                    {
                        "@pid": "20/7563-1",
                        "text": "Chunpeng Ge 0001"
                    },
                    {
                        "@pid": "12/2633-6",
                        "text": "Ting Wang 0006"
                    }
                ]
            },
            "title": "Improving the Robustness of Transformer-based Large Language Models with Dynamic Attention.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ShenPJL0G024",
            "ee": "https://www.ndss-symposium.org/ndss-paper/improving-the-robustness-of-transformer-based-large-language-models-with-dynamic-attention/",
            "url": "https://dblp.org/rec/conf/ndss/ShenPJL0G024",
            "abstract": "Transformer-based models, such as BERT and GPT, have been widely adopted in natural language processing (NLP) due to their exceptional performance. However, recent studies show their vulnerability to textual adversarial attacks where the model's output can be misled by intentionally manipulating the text inputs. Despite various methods that have been proposed to enhance the model's robustness and mitigate this vulnerability, many require heavy consumption resources (e.g., adversarial training) or only provide limited protection (e.g., defensive dropout).",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2024-115-paper.pdf",
            "keywords": [
                "Transformer Models",
                "Natural Language Processing",
                "Adversarial Attacks",
                "Model Robustness",
                "Dynamic Attention"
            ]
        },
        "url": "URL#358440"
    },
    {
        "@score": "1",
        "@id": "358441",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "240/7816",
                        "text": "Peiyao Sheng"
                    },
                    {
                        "@pid": "133/8422",
                        "text": "Nikita Yadav"
                    },
                    {
                        "@pid": "59/10956",
                        "text": "Vishal Sevani"
                    },
                    {
                        "@pid": "191/8676",
                        "text": "Arun Babu"
                    },
                    {
                        "@pid": "28/855",
                        "text": "Anand SVR"
                    },
                    {
                        "@pid": "11/4803",
                        "text": "Himanshu Tyagi"
                    },
                    {
                        "@pid": "56/2613",
                        "text": "Pramod Viswanath"
                    }
                ]
            },
            "title": "Proof of Backhaul: Trustfree Measurement of Broadband Bandwidth.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ShengYSBSTV24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/proof-of-backhaul-trustfree-measurement-of-broadband-bandwidth/",
            "url": "https://dblp.org/rec/conf/ndss/ShengYSBSTV24",
            "abstract": "Recent years have seen the emergence of decentralized wireless networks consisting of nodes hosted by many individuals and small enterprises, reawakening the decades-old dream of open networking. These networks have been deployed in an organic, distributed manner and are driven by new economic models resting on tokenized incentives. A critical requirement for the incentives to scale is the ability to prove network performance in a decentralized trustfree manner, i.e., a Byzantine fault tolerant network telemetry system. In this paper, we present a Proof of Backhaul (PoB) protocol which measures the bandwidth of the (broadband) backhaul link of a wireless access point, termed prover, in a decentralized and trustfree manner. In particular, our proposed protocol is the first one to satisfy the following two properties: (1) Trustfree. Bandwidth measurement is secure against Byzantine attacks by collaborations of challenge servers and the prover. (2) Open. The barrier-to-entry for being a challenge server is low; there is no requirement of having a low latency and high throughput path to the measured link. At a high-level, our protocol aggregates the challenge traffic from multiple challenge servers and uses cryptographic primitives to ensure that a subset of challengers or, even challengers and provers, cannot maliciously modify results in their favor. A formal security model allows us to establish guarantees of accurate bandwidth measurement as a function of the fraction of malicious actors. Our evaluation shows that our PoB protocol can verify backhaul bandwidth of up to 1000 Mbps with less than 8% error using measurements lasting only 100 ms. The measurement accuracy is not affected in the presence of corrupted challengers. Importantly, the basic verification protocol lends itself to a minor modification that can measure available bandwidth even in the presence of cross-traffic.",
            "keywords": [
                "Decentralized Wireless Networks",
                "Network Performance Measurement",
                "Byzantine Fault Tolerance",
                "Bandwidth Measurement",
                "Proof of Backhaul (PoB)"
            ]
        },
        "url": "URL#358441",
        "sema_paperId": "aea51a804a81130472e44f65586e9be8057079d7"
    },
    {
        "@score": "1",
        "@id": "358442",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "160/6225",
                        "text": "Jiameng Shi"
                    },
                    {
                        "@pid": "79/8042",
                        "text": "Wenqiang Li"
                    },
                    {
                        "@pid": "33/9876",
                        "text": "Wenwen Wang"
                    },
                    {
                        "@pid": "137/5266",
                        "text": "Le Guan"
                    }
                ]
            },
            "title": "Facilitating Non-Intrusive In-Vivo Firmware Testing with Stateless Instrumentation.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ShiLWG24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/facilitating-non-intrusive-in-vivo-firmware-testing-with-stateless-instrumentation/",
            "url": "https://dblp.org/rec/conf/ndss/ShiLWG24",
            "abstract": "\u2014Although numerous dynamic testing techniques have been developed, they can hardly be directly applied to firmware of deeply embedded (e.g., microcontroller-based) devices due to the tremendously different runtime environment and restricted resources on these devices. This work tackles these challenges by leveraging the unique position of microcontroller devices during firmware development. That is, firmware developers have to rely on a powerful engineering workstation that connects to the target device to program and debug code. Therefore, we develop a decoupled firmware testing framework named IPEA , which shifts the overhead of resource-intensive analysis tasks from the microcontroller to the workstation. Only lightweight \u201cneedle probes\u201d are left in the firmware to collect internal execution information without processing it. We also instantiated this framework with a sanitizer based on pointer capability ( IPEA-San ) and a greybox fuzzer ( IPEA-Fuzz ). By comparing IPEA-San with a port of AddressSanitizer for micro-controllers, we show that IPEA-San reduces memory overhead by 62.75% in real-world firmware with better detection accuracy. Combining IPEA-Fuzz with IPEA-San , we found 7 zero-day bugs in popular IoT libraries (3) and peripheral driver code (4).",
            "keywords": [
                "Firmware Testing",
                "Embedded Systems",
                "Stateless Instrumentation",
                "Dynamic Analysis",
                "IoT Vulnerabilities"
            ]
        },
        "url": "URL#358442",
        "sema_paperId": "ba33b3243de9a2004f575db0b69ae067da09b3fd"
    },
    {
        "@score": "1",
        "@id": "358443",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "207/8079",
                        "text": "Xiangfu Song"
                    },
                    {
                        "@pid": "85/4137",
                        "text": "Dong Yin"
                    },
                    {
                        "@pid": "267/1089",
                        "text": "Jianli Bai"
                    },
                    {
                        "@pid": "34/5882",
                        "text": "Changyu Dong"
                    },
                    {
                        "@pid": "67/4662",
                        "text": "Ee-Chien Chang"
                    }
                ]
            },
            "title": "Secret-Shared Shuffle with Malicious Security.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/SongYBDC24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/secret-shared-shuffle-with-malicious-security/",
            "url": "https://dblp.org/rec/conf/ndss/SongYBDC24",
            "abstract": "A secret-shared shuffle (SSS) protocol permutes a secret-shared vector using a random secret permutation. It has found numerous applications, however, it is also an expensive operation and often a performance bottleneck. Chase et al. (Asiacrypt'20) recently proposed a highly efficient semi-honest two-party SSS protocol known as the CGP protocol. It utilizes purposely designed pseudorandom correlations that facilitate a communication-efficient online shuffle phase. That said, semi-honest security is insufficient in many real-world application scenarios since shuffle is usually used for highly sensitive applications. Considering this, recent works (CANS'21, NDSS'22) attempted to enhance the CGP protocol with malicious security over authenticated secret sharings. However, we find that these attempts are flawed, and malicious adversaries can still learn private information via malicious deviations. This is demonstrated with concrete attacks proposed in this paper. Then the question is how to fill the gap and design a maliciously secure CGP shuffle protocol. We answer this question by introducing a set of lightweight correlation checks and a leakage reduction mechanism. Then we apply our techniques with authenticated secret sharings to achieve malicious security. Notably, our protocol, while increasing security, is also efficient. In the two-party setting, experiment results show that our maliciously secure protocol introduces an acceptable overhead compared to its semi-honest version and is more efficient than the state-of-the-art maliciously secure SSS protocol from the MP-SPDZ library.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2024-21-paper.pdf",
            "keywords": [
                "Secret-Shared Shuffle",
                "Malicious Security",
                "Pseudorandom Correlations",
                "Authenticated Secret Sharing",
                "Efficiency in Secure Computation"
            ]
        },
        "url": "URL#358443"
    },
    {
        "@score": "1",
        "@id": "358444",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "254/8997",
                        "text": "Srivatsan Sridhar"
                    },
                    {
                        "@pid": "62/7401",
                        "text": "Onur Ascigil"
                    },
                    {
                        "@pid": "276/3745",
                        "text": "Navin V. Keizer"
                    },
                    {
                        "@pid": "353/1163",
                        "text": "Fran\u00e7ois Genon"
                    },
                    {
                        "@pid": "353/0304",
                        "text": "S\u00e9bastien Pierre"
                    },
                    {
                        "@pid": "269/9979",
                        "text": "Yiannis Psaras"
                    },
                    {
                        "@pid": "01/6018",
                        "text": "Etienne Rivi\u00e8re"
                    },
                    {
                        "@pid": "157/4436",
                        "text": "Michal Kr\u00f3l"
                    }
                ]
            },
            "title": "Content Censorship in the InterPlanetary File System.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/SridharAKGPPRK24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/content-censorship-in-the-interplanetary-file-system/",
            "url": "https://dblp.org/rec/conf/ndss/SridharAKGPPRK24",
            "abstract": "The InterPlanetary File System (IPFS) is currently the largest decentralized storage solution in operation, with thousands of active participants and millions of daily content transfers. IPFS is used as remote data storage for numerous blockchain-based smart contracts, Non-Fungible Tokens (NFT), and decentralized applications.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2024-153-paper.pdf",
            "keywords": [
                "InterPlanetary File System",
                "Decentralized Storage",
                "Content Censorship",
                "Blockchain Applications",
                "Non-Fungible Tokens (NFT)"
            ]
        },
        "url": "URL#358444"
    },
    {
        "@score": "1",
        "@id": "358445",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "17/1580",
                        "text": "Yingying Su"
                    },
                    {
                        "@pid": "48/4185-1",
                        "text": "Dan Li 0001"
                    },
                    {
                        "@pid": "c/LiChen8",
                        "text": "Li Chen 0008"
                    },
                    {
                        "@pid": "181/2688-2",
                        "text": "Qi Li 0002"
                    },
                    {
                        "@pid": "357/4640",
                        "text": "Sitong Ling"
                    }
                ]
            },
            "title": "dRR: A Decentralized, Scalable, and Auditable Architecture for RPKI Repository.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/SuLC0L24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/drr-a-decentralized-scalable-and-auditable-architecture-for-rpki-repository/",
            "url": "https://dblp.org/rec/conf/ndss/SuLC0L24",
            "abstract": "\u2014Although Resource Public Key Infrastructure (RPKI) is critical for securing inter-domain routing, we find that its key component, the RPKI Repository, is under studied. We conduct the first data-driven analysis of the existing RPKI Repository infrastructure, including a survey of worldwide AS administrators and a large-scale measurement of the existing RPKI Repository. Based on the findings of our study, we identify three key problems. Firstly, misbehaving RPKI authorities can easily manipulate RPKI objects, and Internet Number Resources holders (INRs holders) and Relying Parties (RPs) can neither prevent malicious behaviors of misbehaving authorities nor hold them accountable. Secondly, RPKI Repository is sensitive to failures: An attack or downtime of any repository Publication Point (PP) will prevent RPs from obtaining complete RPKI object views. Finally, we identify scalability issues with the current RPKI Repository, which are expected to worsen with the further deployment of Route Origin Authorization (ROA). To address these problems, we propose dRR , an architecture that enhances the security, robustness, and scalability of the RPKI Repository while being compatible with standard RPKI. By introducing two new entities: Certificate Servers (CSs) and Monitors, dRR forms a decentralized federation of CSs, which enables the RPKI Repository to proactively defend against malicious behavior from authorities and to tolerate PPs\u2019 failures. dRR is also scalable for future large-scale deployment. We present the design of dRR in detail and implement a prototype of dRR on a global Internet testbed spanning 15 countries. Experimental results show that, although new security features are introduced, dRR only incurs negligible latency for certificate issuance and revocation. The throughput",
            "keywords": [
                "RPKI Repository",
                "Decentralized Architecture",
                "Scalability",
                "Malicious Behavior",
                "Certificate Servers"
            ]
        },
        "url": "URL#358445",
        "sema_paperId": "3b13821b04a618bbe143a406cd907b4f3382de0e"
    },
    {
        "@score": "1",
        "@id": "358446",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "297/8628",
                        "text": "Aozhuo Sun"
                    },
                    {
                        "@pid": "57/4208",
                        "text": "Jingqiang Lin"
                    },
                    {
                        "@pid": "35/7092-314",
                        "text": "Wei Wang 0314"
                    },
                    {
                        "@pid": "284/4048",
                        "text": "Zeyan Liu"
                    },
                    {
                        "@pid": "49/1389",
                        "text": "Bingyu Li"
                    },
                    {
                        "@pid": "385/9113",
                        "text": "Shushang Wen"
                    },
                    {
                        "@pid": "52/8379",
                        "text": "Qiongxiao Wang"
                    },
                    {
                        "@pid": "66/6000",
                        "text": "Fengjun Li"
                    }
                ]
            },
            "title": "Certificate Transparency Revisited: The Public Inspections on Third-party Monitors.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/SunL0LLWWL24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/certificate-transparency-revisited-the-public-inspections-on-third-party-monitors/",
            "url": "https://dblp.org/rec/conf/ndss/SunL0LLWWL24",
            "abstract": "The certificate transparency (CT) framework has been deployed to improve the accountability of the TLS certificate ecosystem. However, the current implementation of CT does not enforce or guarantee the correct behavior of third-party monitors, which are essential components of the CT framework, and raises security and reliability concerns. For example, recent studies reported that 5 popular third-party CT monitors cannot always return the complete set of certificates inquired by users, which fundamentally impairs the protection that CT aims to offer. This work revisits the CT design and proposes an additional component of the CT framework, CT watchers. A watcher acts as an inspector of third-party CT monitors to detect any misbehavior by inspecting the certificate search services of a third-party monitor and detecting any inconsistent results returned by multiple monitors. It also semi-automatically analyzes potential causes of the inconsistency, e.g., a monitor\u2019s misconfiguration, implementation flaws, etc. We implemented a prototype of the CT watcher and conducted a 52-day trial operation and several confirmation experiments involving 8.26M unique certificates of about 6,000 domains. From the results returned by 6 active third-party monitors in the wild, the prototype detected 14 potential design or implementation issues of these monitors, demonstrating its effectiveness in public inspections on third-party monitors and the potential to improve the overall reliability of CT.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2024-834-paper.pdf",
            "keywords": [
                "Certificate Transparency",
                "Third-party Monitors",
                "CT Watchers",
                "Certificate Inconsistency",
                "Monitoring Reliability"
            ]
        },
        "url": "URL#358446",
        "sema_paperId": "610e237b920339f3248bcdb4d0dbb94f8cd4187e"
    },
    {
        "@score": "1",
        "@id": "358447",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "228/2031",
                        "text": "Cem Topcuoglu"
                    },
                    {
                        "@pid": "77/8031",
                        "text": "Kaan Onarlioglu"
                    },
                    {
                        "@pid": "291/2820",
                        "text": "Bahruz Jabiyev"
                    },
                    {
                        "@pid": "k/EnginKirda",
                        "text": "Engin Kirda"
                    }
                ]
            },
            "title": "Untangle: Multi-Layer Web Server Fingerprinting.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/TopcuogluOJK24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/untangle-multi-layer-web-server-fingerprinting/",
            "url": "https://dblp.org/rec/conf/ndss/TopcuogluOJK24",
            "abstract": "\u2014Web server fingerprinting is a common activity in vulnerability management and security testing, with network scanners offering the capability for over two decades. All known fingerprinting techniques are designed for probing a single, isolated web server. However, the modern Internet is made up of complex layered architectures, where chains of CDNs, reverse proxies, and cloud services front origin servers. That renders existing fingerprinting tools and techniques utterly ineffective. We present the first methodology that can fingerprint servers in a multi-layer architecture, by leveraging the HTTP processing discrepancies between layers. This technique is capable of detecting both the server technologies involved and their correct ordering. It is theoretically extendable to any number of layers, any server technology, deployed in any order, but of course within practical constraints. We then address those practical considerations and present a concrete implementation of the scheme in a tool called Untangle , empirically demonstrating its ability to fingerprint 3-layer architectures with high accuracy.",
            "keywords": [
                "Web Server Fingerprinting",
                "Multi-Layer Architecture",
                "HTTP Processing Discrepancies",
                "Vulnerability Management",
                "Untangle Tool"
            ]
        },
        "url": "URL#358447",
        "sema_paperId": "75b72dd008f75ea77dfdcbbd14ea6f5c37aad58b"
    },
    {
        "@score": "1",
        "@id": "358448",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "301/5874",
                        "text": "Elisa Tsai"
                    },
                    {
                        "@pid": "270/2488",
                        "text": "Ram Sundara Raman"
                    },
                    {
                        "@pid": "p/AtulPrakash",
                        "text": "Atul Prakash 0001"
                    },
                    {
                        "@pid": "24/973",
                        "text": "Roya Ensafi"
                    }
                ]
            },
            "title": "Modeling and Detecting Internet Censorship Events.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/TsaiR0E24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/modeling-and-detecting-internet-censorship-events/",
            "url": "https://dblp.org/rec/conf/ndss/TsaiR0E24",
            "abstract": "Publicly accessible censorship datasets, such as OONI and Censored Planet, provide valuable resources for understanding global censorship events. However, censorship event detection in these datasets is challenging due to the overwhelming amount of data, the dynamic nature of censorship, and potentially heterogeneous blocking policies across networks in the same country. This paper presents CenDTect, an unsupervised learning system based on decision trees that overcomes the scalability issue of manual analysis and the interpretability issues of previous time-series methods. CenDTect employs iterative parallel DBSCAN to identify domains with similar blocking patterns, using an adapted cross-classification accuracy as the distance metric. The system analyzes more than 70 billion data points from Censored Planet between January 2019 and December 2022, discovering 15,360 HTTP(S) event clusters in 192 countries and 1,166 DNS event clusters in 77 countries. By evaluating CenDTect's findings with a curated list of 38 potential censorship events from news media and reports, we show how all events confirmed by the manual inspection are easy to characterize with CenDTect's output. We report more than 100 ASes in 32 countries with persistent ISP blocking. Additionally, we identify 11 temporary blocking events in clusters discovered in 2022, observed during periods of election, political unrest, protest, and war. Our approach provides informative and interpretable outputs, making censorship data more accessible to data consumers including researchers, journalists, and NGOs.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2024-409-paper.pdf",
            "keywords": [
                "Internet Censorship",
                "Censorship Detection",
                "Unsupervised Learning",
                "Blocking Patterns",
                "Censorship Events"
            ]
        },
        "url": "URL#358448",
        "sema_paperId": "8b6244a708bd1ba7d63bd926ee14e6357a609a61"
    },
    {
        "@score": "1",
        "@id": "358449",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "297/6590",
                        "text": "Geoff Twardokus"
                    },
                    {
                        "@pid": "167/3021",
                        "text": "Nina Bindel"
                    },
                    {
                        "@pid": "133/3880",
                        "text": "Hanif Rahbari"
                    },
                    {
                        "@pid": "210/3353",
                        "text": "Sarah McCarthy"
                    }
                ]
            },
            "title": "When Cryptography Needs a Hand: Practical Post-Quantum Authentication for V2V Communications.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/TwardokusBRM24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/when-cryptography-needs-a-hand-practical-post-quantum-authentication-for-v2v-communications/",
            "url": "https://dblp.org/rec/conf/ndss/TwardokusBRM24",
            "abstract": "\u2014We tackle the atypical challenge of supporting post-quantum cryptography (PQC) and its significant overhead in safety-critical vehicle-to-vehicle (V2V) communications, dealing with strict overhead and latency restrictions within the limited radio spectrum for V2V. For example, we show that the current use of spectrum to support signature verification in V2V makes it nearly impossible to adopt PQC. Accordingly, we propose a scheduling technique for message signing certificate transmissions (which we find are currently up to 93% redundant) that learns to adaptively reduce the use of radio spectrum. In combination, we design the first integration of PQC and V2V, which satisfies the above stringent constraints given the available spectrum. Specifically, we analyze the three PQ signature algorithms selected for standardization by NIST, as well as XMSS (RFC 8391), and propose a Partially Hybrid authentication protocol\u2014a tailored fusion of classical cryptography and PQC\u2014for use in the V2V ecosystem during the nascent transition period we outline towards fully PQ V2V. Our provably secure protocol efficiently balances security and performance, as demonstrated experimentally with software-defined radios (USRPs), commercial V2V devices, and road traffic and V2V simulators. We show our joint transmission scheduling optimization and Partially Hybrid design are scalable and reliable under realistic conditions, adding a negligible average delay (0.39ms per message) against the current state-of-the-art.",
            "keywords": [
                "Post-Quantum Cryptography",
                "Vehicle-to-Vehicle Communications",
                "Signature Verification",
                "Transmission Scheduling",
                "Partially Hybrid Authentication"
            ]
        },
        "url": "URL#358449",
        "sema_paperId": "fa082298feaff15bd88aa3fb8da1bd44157c1c84"
    },
    {
        "@score": "1",
        "@id": "358450",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "213/7598",
                        "text": "Ryan Wails"
                    },
                    {
                        "@pid": "331/2217",
                        "text": "George Arnold Sullivan"
                    },
                    {
                        "@pid": "57/3752",
                        "text": "Micah Sherr"
                    },
                    {
                        "@pid": "14/7561",
                        "text": "Rob Jansen"
                    }
                ]
            },
            "title": "On Precisely Detecting Censorship Circumvention in Real-World Networks.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/WailsSSJ24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/on-precisely-detecting-censorship-circumvention-in-real-world-networks/",
            "url": "https://dblp.org/rec/conf/ndss/WailsSSJ24",
            "abstract": "\u2014The understanding of realistic censorship threats enables the development of more resilient censorship circumvention systems, which are vitally important for advancing human rights and fundamental freedoms. We argue that current state-of-the-art methods for detecting circumventing flows in Tor are unrealistic: they are overwhelmed with false positives ( > 94% ), even when considering conservatively high base rates ( 10 \u2212 3 ). In this paper, we present a new methodology for detecting censorship circumvention in which a deep-learning flow-based classifier is combined with a host-based detection strategy that incorporates information from multiple flows over time. Using over 60,000,000 real-world network flows to over 600,000 destinations, we demonstrate how our detection methods become more precise as they temporally accumulate information, allowing us to detect circumvention servers with perfect recall and no false positives. Our evaluation considers a range of circumventing flow base rates spanning six orders of magnitude and real-world protocol distributions. Our findings suggest that future circumvention system designs need to more carefully consider host-based detection strategies, and we offer suggestions for designs that are more resistant to these attacks.",
            "keywords": [
                "Censorship Circumvention",
                "Network Flow Analysis",
                "Deep Learning Classifier",
                "Host-Based Detection",
                "False Positives Reduction"
            ]
        },
        "url": "URL#358450",
        "sema_paperId": "26ecaacfeb748c35d853abec5ba2b0255087225e"
    },
    {
        "@score": "1",
        "@id": "358451",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "32/5536-4",
                        "text": "Shu Wang 0004"
                    },
                    {
                        "@pid": "30/3530-1",
                        "text": "Kun Sun 0001"
                    },
                    {
                        "@pid": "181/2688-2",
                        "text": "Qi Li 0002"
                    }
                ]
            },
            "title": "Compensating Removed Frequency Components: Thwarting Voice Spectrum Reduction Attacks.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/Wang0024",
            "ee": "https://www.ndss-symposium.org/ndss-paper/compensating-removed-frequency-components-thwarting-voice-spectrum-reduction-attacks/",
            "url": "https://dblp.org/rec/conf/ndss/Wang0024",
            "abstract": "Automatic speech recognition (ASR) provides diverse audio-to-text services for humans to communicate with machines. However, recent research reveals ASR systems are vulnerable to various malicious audio attacks. In particular, by removing the non-essential frequency components, a new spectrum reduction attack can generate adversarial audios that can be perceived by humans but cannot be correctly interpreted by ASR systems. It raises a new challenge for content moderation solutions to detect harmful content in audio and video available on social media platforms. In this paper, we propose an acoustic compensation system named ACE to counter the spectrum reduction attacks over ASR systems. Our system design is based on two observations, namely, frequency component dependencies and perturbation sensitivity. First, since the Discrete Fourier Transform computation inevitably introduces spectral leakage and aliasing effects to the audio frequency spectrum, the frequency components with similar frequencies will have a high correlation. Thus, considering the intrinsic dependencies between neighboring frequency components, it is possible to recover more of the original audio by compensating for the removed components based on the remaining ones. Second, since the removed components in the spectrum reduction attacks can be regarded as an inverse of adversarial noise, the attack success rate will decrease when the adversarial audio is replayed in an over-the-air scenario. Hence, we can model the acoustic propagation process to add over-the-air perturbations into the attacked audio. We implement a prototype of ACE and the experiments show that ACE can effectively reduce up to 87.9% of ASR inference errors caused by spectrum reduction attacks. Furthermore, by analyzing the residual errors on real audio samples, we summarize six general types of ASR inference errors and investigate the error causes and potential mitigation solutions.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2024-150-paper.pdf",
            "keywords": [
                "Automatic Speech Recognition",
                "Spectrum Reduction Attacks",
                "Acoustic Compensation",
                "Adversarial Audio",
                "ASR Inference Errors"
            ]
        },
        "url": "URL#358451"
    },
    {
        "@score": "1",
        "@id": "358452",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "19/3687",
                        "text": "Shiming Wang"
                    },
                    {
                        "@pid": "65/4179",
                        "text": "Zhe Ji"
                    },
                    {
                        "@pid": "115/6308",
                        "text": "Liyao Xiang"
                    },
                    {
                        "@pid": "55/2270-63",
                        "text": "Hao Zhang 0063"
                    },
                    {
                        "@pid": "96/1149",
                        "text": "Xinbing Wang"
                    },
                    {
                        "@pid": "85/1324",
                        "text": "Chenghu Zhou"
                    },
                    {
                        "@pid": "50/3402-115",
                        "text": "Bo Li 0115"
                    }
                ]
            },
            "title": "Crafter: Facial Feature Crafting against Inversion-based Identity Theft on Deep Models.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/WangJX0WZL24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/crafter-facial-feature-crafting-against-inversion-based-identity-theft-on-deep-models/",
            "url": "https://dblp.org/rec/conf/ndss/WangJX0WZL24",
            "abstract": "With the increased capabilities at the edge (e.g., mobile device)  and more stringent privacy requirement, it becomes a recent trend for deep learning-enabled applications to pre-process sensitive raw data at the edge and transmit the features to the backend cloud for further processing. A typical application is to run machine learning (ML) services on facial images collected from different individuals. To prevent identity theft, conventional methods commonly rely on an adversarial game-based approach to shed the identity information from the feature. However, such methods can not defend against adaptive attacks, in which an attacker takes a countermove against a known defence strategy.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2024-326-paper.pdf",
            "keywords": [
                "Facial Feature Crafting",
                "Identity Theft Prevention",
                "Adversarial Attacks",
                "Feature Privacy",
                "Inversion-based Attacks"
            ]
        },
        "url": "URL#358452"
    },
    {
        "@score": "1",
        "@id": "358453",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "210/1379",
                        "text": "Chuhan Wang"
                    },
                    {
                        "@pid": "385/8741",
                        "text": "Yasuhiro Kuranaga"
                    },
                    {
                        "@pid": "161/4762",
                        "text": "Yihang Wang"
                    },
                    {
                        "@pid": "29/3959",
                        "text": "Mingming Zhang"
                    },
                    {
                        "@pid": "385/8278",
                        "text": "Linkai Zheng"
                    },
                    {
                        "@pid": "40/1491-108",
                        "text": "Xiang Li 0108"
                    },
                    {
                        "@pid": "20/1036-5",
                        "text": "Jianjun Chen 0005"
                    },
                    {
                        "@pid": "36/5143",
                        "text": "Haixin Duan"
                    },
                    {
                        "@pid": "331/2560",
                        "text": "Yanzhong Lin"
                    },
                    {
                        "@pid": "245/2668",
                        "text": "Qingfeng Pan"
                    }
                ]
            },
            "title": "BreakSPF: How Shared Infrastructures Magnify SPF Vulnerabilities Across the Internet.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/WangKWZZLCDLP24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/breakspf-how-shared-infrastructures-magnify-spf-vulnerabilities-across-the-internet/",
            "url": "https://dblp.org/rec/conf/ndss/WangKWZZLCDLP24",
            "abstract": "\u2014Email spoofing attacks pose a severe threat to email systems by forging the sender\u2019s address to deceive email recipients. Sender Policy Framework (SPF), an email authentication protocol that verifies senders by their IP addresses, is critical for preventing email spoofing attacks. However, attackers can bypass SPF validation and launch convincing spoofing attacks that evade email authentication. This paper proposes BreakSPF, a novel attack framework that bypasses SPF validation to enable email spoofing. Attackers can actively target domains with permissive SPF configurations by utilizing cloud services, proxies, and content delivery networks (CDNs) with shared IP pools. We leverage BreakSPF to conduct a large-scale experiment evaluating the security of SPF deployment across Tranco top 1 million domain names. We uncover that 23,916 domains are vulnerable to BreakSPF attacks, including 23 domains that rank within the top 1,000 most popular domains. The results underscore the widespread SPF configuration vulnerabilities and their potential to undermine the security of email systems. Our study provides valuable insights for detecting and mitigating SPF vulnerabilities and strengthening email system security overall.",
            "keywords": [
                "Email Authentication",
                "Sender Policy Framework (SPF)",
                "Email Spoofing",
                "SPF Vulnerabilities",
                "BreakSPF Attack Framework"
            ]
        },
        "url": "URL#358453",
        "sema_paperId": "977ca72dcacd75f118ca949ac58e9a77af0b54e6"
    },
    {
        "@score": "1",
        "@id": "358454",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "220/3081",
                        "text": "Ke Coby Wang"
                    },
                    {
                        "@pid": "r/MichaelKReiter",
                        "text": "Michael K. Reiter"
                    }
                ]
            },
            "title": "Bernoulli Honeywords.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/WangR24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/bernoulli-honeywords/",
            "url": "https://dblp.org/rec/conf/ndss/WangR24",
            "abstract": "Decoy passwords, or\"honeywords,\"planted in a credential database can alert a site to its breach if ever submitted in a login attempt. To be effective, some honeywords must appear at least as likely to be user-chosen passwords as the real ones, and honeywords must be very difficult to guess without having breached the database, to prevent false breach alarms. These goals have proved elusive, however, for heuristic honeyword generation algorithms. In this paper we explore an alternative strategy in which the defender treats honeyword selection as a Bernoulli process in which each possible password (except the user-chosen one) is selected as a honeyword independently with some fixed probability. We show how Bernoulli honeywords can be integrated into two existing system designs for leveraging honeywords: one based on a honeychecker that stores the secret index of the user-chosen password in the list of account passwords, and another that does not leverage secret state at all. We show that Bernoulli honeywords enable analytic derivation of false breach-detection probabilities irrespective of what information the attacker gathers about the sites' users; that their true and false breach-detection probabilities demonstrate compelling efficacy; and that Bernoulli honeywords can even enable performance improvements in modern honeyword system designs.",
            "keywords": [
                "Honeywords",
                "Password Security",
                "Breach Detection",
                "Bernoulli Process",
                "Decoy Passwords"
            ]
        },
        "url": "URL#358454",
        "sema_paperId": "dcf8be62e15fb5a7634db8296c84ac2a1ccc45d3"
    },
    {
        "@score": "1",
        "@id": "358455",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "65/7762",
                        "text": "Shicheng Wang"
                    },
                    {
                        "@pid": "188/5710-1",
                        "text": "Menghao Zhang 0001"
                    },
                    {
                        "@pid": "208/4892",
                        "text": "Yuying Du"
                    },
                    {
                        "@pid": "255/9408",
                        "text": "Ziteng Chen"
                    },
                    {
                        "@pid": "58/5311",
                        "text": "Zhiliang Wang"
                    },
                    {
                        "@pid": "18/6055",
                        "text": "Mingwei Xu"
                    },
                    {
                        "@pid": "191/1022",
                        "text": "Renjie Xie"
                    },
                    {
                        "@pid": "62/2814-1",
                        "text": "Jiahai Yang 0001"
                    }
                ]
            },
            "title": "LoRDMA: A New Low-Rate DoS Attack in RDMA Networks.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/WangZDCWXX024",
            "ee": "https://www.ndss-symposium.org/ndss-paper/lordma-a-new-low-rate-dos-attack-in-rdma-networks/",
            "url": "https://dblp.org/rec/conf/ndss/WangZDCWXX024",
            "abstract": "\u2014RDMA is being widely used from private data center applications to multi-tenant clouds, which makes RDMA security gain tremendous attention. However, existing RDMA security studies mainly focus on the security of RDMA systems, and the security of the coupled traffic control mechanisms (represented by PFC and DCQCN) in RDMA networks is largely overlooked. In this paper, through extensive experiments and analysis, we demonstrate that concurrent short-duration bursts can cause drastic performance loss on flows across multiple hops via the interaction between PFC and DCQCN. And we also summarize the vulnerabilities between the performance loss and the burst peak rate, as well as the duration. Based on these vulnerabilities, we propose the LoRDMA attack, a low-rate DoS attack against RDMA traffic control mechanisms. By monitoring RTT as the feedback signal, LoRDMA can adaptively 1) coordinate the bots to different target switch ports to cover more victim flows efficiently; 2) schedule the burst parameters to cause significant performance loss efficiently. We conduct and evaluate the LoRDMA attack at both ns-3 simulations and a cloud RDMA cluster. The results show that compared to existing attacks, the LoRDMA attack achieves higher victim flow coverage and performance loss with much lower attack traffic and detectability. And the communication performance of typical distributed machine learning training applications ( NCCL Tests ) in the cloud RDMA cluster can be degraded from 18.23% to 56.12% under the LoRDMA attack.",
            "keywords": [
                "RDMA Networks",
                "Traffic Control Mechanisms",
                "DoS Attack",
                "Performance Loss",
                "LoRDMA Attack"
            ]
        },
        "url": "URL#358455",
        "sema_paperId": "e8fff78a8e5dc9a4333f2558774d525ab36a1ff6"
    },
    {
        "@score": "1",
        "@id": "358456",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "16/10143",
                        "text": "Chenxu Wang"
                    },
                    {
                        "@pid": "20/11242",
                        "text": "Fengwei Zhang"
                    },
                    {
                        "@pid": "246/6970",
                        "text": "Yunjie Deng"
                    },
                    {
                        "@pid": "133/3698",
                        "text": "Kevin Leach"
                    },
                    {
                        "@pid": "c/JiannongCao",
                        "text": "Jiannong Cao 0001"
                    },
                    {
                        "@pid": "47/8535",
                        "text": "Zhenyu Ning"
                    },
                    {
                        "@pid": "08/6611",
                        "text": "Shoumeng Yan"
                    },
                    {
                        "@pid": "79/7449",
                        "text": "Zhengyu He"
                    }
                ]
            },
            "title": "CAGE: Complementing Arm CCA with GPU Extensions.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/WangZDL0NYH24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/cage-complementing-arm-cca-with-gpu-extensions/",
            "url": "https://dblp.org/rec/conf/ndss/WangZDL0NYH24",
            "abstract": "\u2014Confidential computing is an emerging technique that provides users and third-party developers with an isolated and transparent execution environment. To support this technique, Arm introduced the Confidential Computing Architecture (CCA), which creates multiple isolated address spaces, known as realms, to ensure data confidentiality and integrity in security-sensitive tasks. Arm recently proposed the concept of confidential computing on GPU hardware, which is widely used in general-purpose, high-performance, and artificial intelligence computing scenarios. However, hardware and firmware supporting confidential GPU workloads remain unavailable. Existing studies leverage Trusted Execution Environments (TEEs) to secure GPU computing on Arm-or Intel-based platforms, but they are not suitable for CCA\u2019s realm-style architecture, such as using incompatible hardware or introducing a large trusted computing base (TCB). Therefore, there is a need to complement existing Arm CCA capabilities with GPU acceleration. To address this challenge, we present CAGE to support confidential GPU computing for Arm CCA. By leveraging the existing security features in Arm CCA, CAGE ensures data security during confidential computing on unified-memory GPUs, the mainstream accelerators in Arm devices. To adapt the GPU workflow to CCA\u2019s realm-style architecture, CAGE proposes a novel shadow task mechanism",
            "keywords": [
                "Confidential Computing",
                "Arm Confidential Computing Architecture",
                "GPU Acceleration",
                "Data Security",
                "Shadow Task Mechanism"
            ]
        },
        "url": "URL#358456",
        "sema_paperId": "7e9b4793cbe08927ea4be2dba515179487b10506"
    },
    {
        "@score": "1",
        "@id": "358457",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "264/6729",
                        "text": "Chengkun Wei"
                    },
                    {
                        "@pid": "210/4401",
                        "text": "Wenlong Meng"
                    },
                    {
                        "@pid": "90/545-1",
                        "text": "Zhikun Zhang 0001"
                    },
                    {
                        "@pid": "50/6996-32",
                        "text": "Min Chen 0032"
                    },
                    {
                        "@pid": "347/1390",
                        "text": "Minghu Zhao"
                    },
                    {
                        "@pid": "20/11504",
                        "text": "Wenjing Fang"
                    },
                    {
                        "@pid": "181/2817",
                        "text": "Lei Wang"
                    },
                    {
                        "@pid": "133/7227",
                        "text": "Zihui Zhang"
                    },
                    {
                        "@pid": "70/2079",
                        "text": "Wenzhi Chen"
                    }
                ]
            },
            "title": "LMSanitator: Defending Prompt-Tuning Against Task-Agnostic Backdoors.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/WeiM00ZFWZC24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/lmsanitator-defending-prompt-tuning-against-task-agnostic-backdoors/",
            "url": "https://dblp.org/rec/conf/ndss/WeiM00ZFWZC24",
            "abstract": "*Prompt-tuning* has emerged as an attractive paradigm for deploying large-scale language models due to its strong downstream task performance and efficient multitask serving ability. Despite its wide adoption, we empirically show that prompt-tuning is vulnerable to downstream task-agnostic backdoors, which reside in the pretrained models and can affect arbitrary downstream tasks. The state-of-the-art backdoor detection approaches cannot defend against task-agnostic backdoors since they hardly converge in reversing the backdoor triggers. To address this issue, we propose LMSanitator, a novel approach for detecting and removing task-agnostic backdoors on Transformer models. Instead of directly inverting the triggers, LMSanitator aims to invert the *predefined attack vectors* (pretrained models' output when the input is embedded with triggers) of the task-agnostic backdoors, which achieves much better convergence performance and backdoor detection accuracy. LMSanitator further leverages prompt-tuning\u2019s property of freezing the pretrained model to perform accurate and fast output monitoring and input purging during the inference phase. Extensive experiments on multiple language models and NLP tasks illustrate the effectiveness of LMSanitator. For instance, LMSanitator achieves 92.8% backdoor detection accuracy on 960 models and decreases the attack success rate to less than 1% in most scenarios.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2024-238-paper.pdf",
            "keywords": [
                "Prompt-Tuning",
                "Task-Agnostic Backdoors",
                "Backdoor Detection",
                "Transformer Models",
                "Output Monitoring"
            ]
        },
        "url": "URL#358457"
    },
    {
        "@score": "1",
        "@id": "358458",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "215/0123",
                        "text": "Haohuang Wen"
                    },
                    {
                        "@pid": "48/3729",
                        "text": "Phillip A. Porras"
                    },
                    {
                        "@pid": "75/3570",
                        "text": "Vinod Yegneswaran"
                    },
                    {
                        "@pid": "21/2267",
                        "text": "Ashish Gehani"
                    },
                    {
                        "@pid": "49/4102-1",
                        "text": "Zhiqiang Lin 0001"
                    }
                ]
            },
            "title": "5G-Spector: An O-RAN Compliant Layer-3 Cellular Attack Detection Service.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/WenPYGL24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/5g-spector-an-o-ran-compliant-layer-3-cellular-attack-detection-service/",
            "url": "https://dblp.org/rec/conf/ndss/WenPYGL24",
            "abstract": "\u2014Over the past several years, the mobile security community has discovered a wide variety of exploits against link and session-establishment protocols. These exploits can be implemented on software-defined radios (SDRs) that disrupt, spoof, or flood layer-3 (L3) messages to compromise security and privacy, which still apply to the latest 5G mobile network standard. Interestingly, unlike the prior generations of closed (proprietary) mobile network infrastructures, 5G networks are migrating toward a more intelligent and open-standards-based fully interoperable mobile architecture, called Open RAN or O-RAN . The implications of transitioning mobile infrastructures to a software-defined architectural abstraction are quite significant to the INFOSEC community, as it allows us to extend the mobile data plane and control plane with security-focused protocol auditing services and exploit detection. Based on this design, we present 5G-S PECTOR , the first comprehensive framework for detecting the wide spectrum of L3 protocol exploits on O-RAN. It features a novel security audit stream called M OBI F LOW that transfers fine-grained cellular network telemetry, and a programmable control-plane xApp called M OBIE X PERT . We present an extensible prototype of 5G-S PECTOR which can detect 7 types of cellular attacks in real-time. We also demonstrate its scalability to 11 unknown attacks as well as 31 real-world cellular traces, with effective performance (high accuracy, no false alarms) and low ( < 2% CPU, < 100 MB memory) overhead.",
            "keywords": [
                "5G Security",
                "O-RAN",
                "Layer-3 Protocol Exploits",
                "Cellular Attack Detection",
                "Real-time Telemetry"
            ]
        },
        "url": "URL#358458",
        "sema_paperId": "2d5a6e17e202670991dd3dd258590f13e069cd55"
    },
    {
        "@score": "1",
        "@id": "358459",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "187/5566",
                        "text": "Harry W. H. Wong"
                    },
                    {
                        "@pid": "205/2191",
                        "text": "Jack P. K. Ma"
                    },
                    {
                        "@pid": "c/ShermanSMChow",
                        "text": "Sherman S. M. Chow"
                    }
                ]
            },
            "title": "Secure Multiparty Computation of Threshold Signatures Made More Efficient.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/WongMC24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/secure-multiparty-computation-of-threshold-signatures-made-more-efficient/",
            "url": "https://dblp.org/rec/conf/ndss/WongMC24",
            "abstract": ".",
            "keywords": [
                "Secure Multiparty Computation",
                "Threshold Signatures",
                "Cryptographic Protocols",
                "Efficiency Improvement",
                "Distributed Systems"
            ]
        },
        "url": "URL#358459",
        "sema_paperId": "6bf53c63b531e03f0c7b71165f8f18ed8f744ae2"
    },
    {
        "@score": "1",
        "@id": "358460",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "220/9034",
                        "text": "Bang Wu"
                    },
                    {
                        "@pid": "24/2058-12",
                        "text": "He Zhang 0012"
                    },
                    {
                        "@pid": "248/2087",
                        "text": "Xiangwen Yang"
                    },
                    {
                        "@pid": "63/1591-12",
                        "text": "Shuo Wang 0012"
                    },
                    {
                        "@pid": "166/1912",
                        "text": "Minhui Xue 0001"
                    },
                    {
                        "@pid": "91/8171",
                        "text": "Shirui Pan"
                    },
                    {
                        "@pid": "21/8884",
                        "text": "Xingliang Yuan"
                    }
                ]
            },
            "title": "GraphGuard: Detecting and Counteracting Training Data Misuse in Graph Neural Networks.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/Wu0Y0XPY24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/graphguard-detecting-and-counteracting-training-data-misuse-in-graph-neural-networks/",
            "url": "https://dblp.org/rec/conf/ndss/Wu0Y0XPY24",
            "abstract": "The emergence of Graph Neural Networks (GNNs) in graph data analysis and their deployment on Machine Learning as a Service platforms have raised critical concerns about data misuse during model training. This situation is further exacerbated due to the lack of transparency in local training processes, potentially leading to the unauthorized accumulation of large volumes of graph data, thereby infringing on the intellectual property rights of data owners. Existing methodologies often address either data misuse detection or mitigation, and are primarily designed for local GNN models rather than cloud-based MLaaS platforms. These limitations call for an effective and comprehensive solution that detects and mitigates data misuse without requiring exact training data while respecting the proprietary nature of such data. This paper introduces a pioneering approach called GraphGuard, to tackle these challenges. We propose a training-data-free method that not only detects graph data misuse but also mitigates its impact via targeted unlearning, all without relying on the original training data. Our innovative misuse detection technique employs membership inference with radioactive data, enhancing the distinguishability between member and non-member data distributions. For mitigation, we utilize synthetic graphs that emulate the characteristics previously learned by the target model, enabling effective unlearning even in the absence of exact graph data. We conduct comprehensive experiments utilizing four real-world graph datasets to demonstrate the efficacy of GraphGuard in both detection and unlearning. We show that GraphGuard attains a near-perfect detection rate of approximately 100% across these datasets with various GNN models. In addition, it performs unlearning by eliminating the impact of the unlearned graph with a marginal decrease in accuracy (less than 5%).",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2024-441-paper.pdf",
            "keywords": [
                "Graph Neural Networks",
                "Data Misuse Detection",
                "Training Data Privacy",
                "Unlearning Techniques",
                "Cloud-based MLaaS"
            ]
        },
        "url": "URL#358460"
    },
    {
        "@score": "1",
        "@id": "358461",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "27/8792",
                        "text": "Zhihao Wu"
                    },
                    {
                        "@pid": "63/4074",
                        "text": "Yushi Cheng"
                    },
                    {
                        "@pid": "35/1541",
                        "text": "Shibo Zhang"
                    },
                    {
                        "@pid": "39/1697-1",
                        "text": "Xiaoyu Ji 0001"
                    },
                    {
                        "@pid": "10/3878-1",
                        "text": "Wenyuan Xu 0001"
                    }
                ]
            },
            "title": "UniID: Spoofing Face Authentication System by Universal Identity.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/WuCZ0024",
            "ee": "https://www.ndss-symposium.org/ndss-paper/uniid-spoofing-face-authentication-system-by-universal-identity/",
            "url": "https://dblp.org/rec/conf/ndss/WuCZ0024",
            "abstract": "\u2014Face authentication systems are widely employed in access control systems to ensure the security of confidential facilities. Recent works have demonstrated their vulnerabilities to adversarial attacks. However, such attacks typically require adversaries to wear disguises such as glasses or hats during every authentication, which may raise suspicion and reduce their attack impacts. In this paper, we propose the UniID attack, which allows multiple adversaries to perform face spoofing attacks without any additional disguise by enabling an insider to register a universal identity into the face authentication database by wearing an adversarial patch. To achieve it, we first select appropriate adversaries through feature engineering, then generate the desired adversarial patch with a multi-target joint-optimization approach, and finally overcome practical challenges such as improving the transferability of the adversarial patch towards black-box systems and enhancing its robustness in the physical world. We implement UniID in laboratory setups and evaluate its effectiveness with six face recognition models (FaceNet, Mobile-FaceNet, ArcFace-18/50, and MagFace-18/50) and two commercial face authentication systems (ArcSoft and Face++). Simulation and real-world experimental results demonstrate that UniID can achieve a max attack success rate of 100% and 79% in 3-user scenarios under the white-box setting and black-box setting respectively, and it can be extended to more than 8 users.",
            "keywords": [
                "Face Authentication",
                "Spoofing Attacks",
                "Adversarial Patch",
                "Universal Identity",
                "Transferability and Robustness"
            ]
        },
        "url": "URL#358461",
        "sema_paperId": "78e2d8472ea33326213d4b96572ef9396c367961"
    },
    {
        "@score": "1",
        "@id": "358462",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "248/1662",
                        "text": "Qiushi Wu"
                    },
                    {
                        "@pid": "76/10471",
                        "text": "Zhongshu Gu"
                    },
                    {
                        "@pid": "45/1350",
                        "text": "Hani Jamjoom"
                    },
                    {
                        "@pid": "67/10639",
                        "text": "Kangjie Lu"
                    }
                ]
            },
            "title": "GNNIC: Finding Long-Lost Sibling Functions with Abstract Similarity.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/WuGJL24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/gnnic-finding-long-lost-sibling-functions-with-abstract-similarity/",
            "url": "https://dblp.org/rec/conf/ndss/WuGJL24",
            "abstract": "\u2014Generating accurate call graphs for large programs, particularly at the operating system (OS) level, poses a well-known challenge. This difficulty stems from the widespread use of indirect calls within large programs, wherein the computation of call targets is deferred until runtime to achieve program polymorphism. Consequently, compilers are unable to statically determine indirect call edges. Recent advancements have attempted to use type analysis to globally match indirect call targets in programs. However, these approaches still suffer from low precision when handling large target programs or generic types. This paper presents GNNIC, a Graph Neural Network (GNN) based Indirect Call analyzer. GNNIC employs a technique called abstract-similarity search to accurately identify indirect call targets in large programs. The approach is based on the observation that although indirect call targets exhibit intricate polymorphic behaviors, they share common abstract characteristics, such as function descriptions, data types, and invoked function calls. We consolidate such information into a representative abstraction graph (RAG) and employ GNNs to learn function embeddings. Abstract-similarity search relies on at least one anchor target to bootstrap. Therefore, we also propose a new program analysis technique to locally identify valid targets of each indirect call. Starting from anchor targets, GNNIC can expand the search scope to find more targets of indirect calls in the whole program. The implementation of GNNIC utilizes LLVM and GNN, and we evaluated it on multiple OS kernels. The results demonstrate that GNNIC outperforms state-of-the-art type-based techniques by reducing 86% to 93% of false target functions. Moreover, the abstract similarity and precise call graphs generated by GNNIC can enhance security applications by discovering new bugs, alleviating path-explosion issues, and improving the efficiency of static program analysis. The combination of static analysis and GNNIC resulted in finding 97 new bugs in Linux and",
            "keywords": [
                "Indirect Call Analysis",
                "Graph Neural Networks",
                "Call Graph Generation",
                "Abstract Similarity Search",
                "Function Target Identification"
            ]
        },
        "url": "URL#358462",
        "sema_paperId": "05ba7dc7616db3e60964e1f9ea8741850d18031f"
    },
    {
        "@score": "1",
        "@id": "358463",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "264/1642",
                        "text": "Jiangrong Wu"
                    },
                    {
                        "@pid": "167/0416",
                        "text": "Yuhong Nan"
                    },
                    {
                        "@pid": "34/8412",
                        "text": "Luyi Xing"
                    },
                    {
                        "@pid": "381/1599",
                        "text": "Jiatao Cheng"
                    },
                    {
                        "@pid": "184/6164",
                        "text": "Zimin Lin"
                    },
                    {
                        "@pid": "z/ZibinZheng",
                        "text": "Zibin Zheng"
                    },
                    {
                        "@pid": "02/1640-2",
                        "text": "Min Yang 0002"
                    }
                ]
            },
            "title": "Leaking the Privacy of Groups and More: Understanding Privacy Risks of Cross-App Content Sharing in Mobile Ecosystem.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/WuNXCLZ024",
            "ee": "https://www.ndss-symposium.org/ndss-paper/leaking-the-privacy-of-groups-and-more-understanding-privacy-risks-of-cross-app-content-sharing-in-mobile-ecosystem/",
            "url": "https://dblp.org/rec/conf/ndss/WuNXCLZ024",
            "abstract": "\u2014 Cross-app content sharing is one of the prominent features widely used in mobile apps. For example, a short video from one app can be shared to another (e.g., a messaging app) and further viewed by other users. In many cases, such Cross-app content sharing activities could have privacy implications for both the sharer and sharee, such as exposing app users\u2019 personal interests. In this paper, we provide the first in-depth study on the privacy implications of Cross-app content sharing (as we call Cracs ) activities in the mobile ecosystem. Our research showed that during the sharing process, the adversary can not only track and infer user interests as traditional web trackers but also cause other severe privacy implications to app users. More specifically, due to multiple privacy-intrusive designs and implementations of Cracs , an adversary can easily reveal a user\u2019s social relations to an outside party, or unnecessarily expose user identities and her associated personal data (e.g., user accounts in another app). Such privacy implications are indeed a concern for app users, as confirmed by a user study we have performed with 300 participants. To further evaluate the impact of our identified privacy implications at large, we have designed an automatic pipeline named Shark , combined with static analysis and dynamic analysis to effectively identify whether a given app introduces unnecessary data exposure in Cracs . We analyzed 300 top downloaded apps collected from app stores in both the US and China. The analysis results showed",
            "keywords": [
                "Cross-App Content Sharing",
                "Mobile Privacy",
                "User Data Exposure",
                "Privacy Implications",
                "Social Relations Leakage"
            ]
        },
        "url": "URL#358463",
        "sema_paperId": "f2ecaadcd0ebd9471e1ef6dbc61c238fb5366c82"
    },
    {
        "@score": "1",
        "@id": "358464",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "335/5794",
                        "text": "Shichen Wu"
                    },
                    {
                        "@pid": "29/7664",
                        "text": "Puwen Wei"
                    },
                    {
                        "@pid": "68/6577-3",
                        "text": "Ren Zhang 0003"
                    },
                    {
                        "@pid": "142/2975",
                        "text": "Bowen Jiang"
                    }
                ]
            },
            "title": "Security-Performance Tradeoff in DAG-based Proof-of-Work Blockchain Protocols.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/WuW0J24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/security-performance-tradeoff-in-dag-based-proof-of-work-blockchain-protocols/",
            "url": "https://dblp.org/rec/conf/ndss/WuW0J24",
            "abstract": "Proof-of-work (PoW) blockchain protocols based on directed acyclic graphs (DAGs) have demonstrated superior transaction confirmation performance compared to their chain-based predecessors. However, it is uncertain whether their security deteriorates in high-throughput settings similar to their predecessors, because their acceptance of simultaneous blocks and complex block dependencies presents challenges for rigorous security analysis.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2024-685-paper.pdf",
            "keywords": [
                "DAG-based Blockchain",
                "Proof-of-Work",
                "Transaction Confirmation",
                "Security Analysis",
                "High-Throughput Settings"
            ]
        },
        "url": "URL#358464"
    },
    {
        "@score": "1",
        "@id": "358465",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "80/6791",
                        "text": "Yue Xiao"
                    },
                    {
                        "@pid": "65/425",
                        "text": "Yi He"
                    },
                    {
                        "@pid": "67/6767-3",
                        "text": "Xiaoli Zhang 0003"
                    },
                    {
                        "@pid": "75/5723-2",
                        "text": "Qian Wang 0002"
                    },
                    {
                        "@pid": "191/1022",
                        "text": "Renjie Xie"
                    },
                    {
                        "@pid": "30/3530-1",
                        "text": "Kun Sun 0001"
                    },
                    {
                        "@pid": "181/2626-2",
                        "text": "Ke Xu 0002"
                    },
                    {
                        "@pid": "181/2688-2",
                        "text": "Qi Li 0002"
                    }
                ]
            },
            "title": "From Hardware Fingerprint to Access Token: Enhancing the Authentication on IoT Devices.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/XiaoH00X00024",
            "ee": "https://www.ndss-symposium.org/ndss-paper/from-hardware-fingerprint-to-access-token-enhancing-the-authentication-on-iot-devices/",
            "url": "https://dblp.org/rec/conf/ndss/XiaoH00X00024",
            "abstract": "The proliferation of consumer IoT products in our daily lives has raised the need for secure device authentication and access control.\nUnfortunately, these resource-constrained devices typically use token-based authentication, which is vulnerable to token compromise attacks that allow attackers to impersonate the devices and perform malicious operations by stealing the access token.\nUsing hardware fingerprints to secure their authentication is a promising way to mitigate these threats.\nHowever, once attackers have stolen some hardware fingerprints (e.g., via MitM attacks), they can bypass the hardware authentication by training a machine learning model to mimic fingerprints or reusing these fingerprints to craft forge requests.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2024-1231-paper.pdf",
            "keywords": [
                "IoT Device Authentication",
                "Hardware Fingerprints",
                "Access Control",
                "Token Compromise",
                "MitM Attacks"
            ]
        },
        "url": "URL#358465"
    },
    {
        "@score": "1",
        "@id": "358466",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "188/6025",
                        "text": "Jiacheng Xu"
                    },
                    {
                        "@pid": "139/6932-2",
                        "text": "Xuhong Zhang 0002"
                    },
                    {
                        "@pid": "07/8388",
                        "text": "Shouling Ji"
                    },
                    {
                        "@pid": "39/5423-1",
                        "text": "Yuan Tian 0001"
                    },
                    {
                        "@pid": "79/7820",
                        "text": "Binbin Zhao"
                    },
                    {
                        "@pid": "156/1247",
                        "text": "Qinying Wang"
                    },
                    {
                        "@pid": "76/185-1",
                        "text": "Peng Cheng 0001"
                    },
                    {
                        "@pid": "55/2484-1",
                        "text": "Jiming Chen 0001"
                    }
                ]
            },
            "title": "MOCK: Optimizing Kernel Fuzzing Mutation with Context-aware Dependency.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/Xu0J0ZW0024",
            "ee": "https://www.ndss-symposium.org/ndss-paper/mock-optimizing-kernel-fuzzing-mutation-with-context-aware-dependency/",
            "url": "https://dblp.org/rec/conf/ndss/Xu0J0ZW0024",
            "abstract": "\u2014Kernels are at the heart of modern operating systems, whereas their development comes with vulnerabilities. Coverage-guided fuzzing has proven to be a promising software testing technique. When applying fuzzing to kernels, the salient aspect of it is that the input is a sequence of system calls (syscalls). As kernels are complex and stateful, specific sequences of syscalls are required to build up necessary states to trigger code deep in the kernels. However, the syscall sequences generated by existing fuzzers fall short in maintaining states to sufficiently cover deep code in the kernels where vulnerabilities favor residing. In this paper, we present a practical and effective kernel fuzzing framework, called M OCK , which is capable of learning the contextual dependencies in syscall sequences and then generating context-aware syscall sequences. To conform to the statefulness when fuzzing kernel, M OCK adaptively mutates syscall sequences in line with the calling context. M OCK integrates the context-aware dependency with (1) a customized language model-guided dependency learning algorithm, (2) a context-aware syscall sequence mutation algorithm, and (3) an adaptive task scheduling strategy to balance exploration and exploitation. Our evaluation shows that M OCK performs effectively in achieving branch coverage (up to 32% coverage growth), producing high-quality input (50% more interrelated sequences), and discovering bugs (15% more unique crashes) than the state-of-the-art kernel fuzzers. Various setups including initial seeds and a pre-trained model further boost M OCK \u2019s performance. Additionally, M OCK also discovers 15 unique bugs in the most recent Linux kernels, including two CVEs.",
            "keywords": [
                "Kernel Fuzzing",
                "System Calls",
                "Context-aware Mutation",
                "Stateful Input Generation",
                "Vulnerability Discovery"
            ]
        },
        "url": "URL#358466",
        "sema_paperId": "dfe21e3850dcaa4a8defe75d8d63f8fa4b765063"
    },
    {
        "@score": "1",
        "@id": "358467",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "155/0624",
                        "text": "Yibin Xu"
                    },
                    {
                        "@pid": "166/3143",
                        "text": "Jingyi Zheng"
                    },
                    {
                        "@pid": "118/3885",
                        "text": "Boris D\u00fcdder"
                    },
                    {
                        "@pid": "66/10278",
                        "text": "Tijs Slaats"
                    },
                    {
                        "@pid": "z/YongluanZhou",
                        "text": "Yongluan Zhou"
                    }
                ]
            },
            "title": "A Two-Layer Blockchain Sharding Protocol Leveraging Safety and Liveness for Enhanced Performance.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/XuZDSZ24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/a-two-layer-blockchain-sharding-protocol-leveraging-safety-and-liveness-for-enhanced-performance/",
            "url": "https://dblp.org/rec/conf/ndss/XuZDSZ24",
            "abstract": "Sharding is a critical technique that enhances the scalability of blockchain technology. However, existing protocols often assume adversarial nodes in a general term without considering the different types of attacks, which limits transaction throughput at runtime because attacks on liveness could be mitigated. There have been attempts to increase transaction throughput by separately handling the attacks; however, they have security vulnerabilities. This paper introduces Reticulum, a novel sharding protocol that overcomes these limitations and achieves enhanced scalability in a blockchain network without security vulnerabilities.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2024-6-paper.pdf",
            "keywords": [
                "Blockchain Sharding",
                "Scalability",
                "Transaction Throughput",
                "Adversarial Attacks",
                "Safety and Liveness"
            ]
        },
        "url": "URL#358467"
    },
    {
        "@score": "1",
        "@id": "358468",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "225/4590",
                        "text": "Tarun Kumar Yadav"
                    },
                    {
                        "@pid": "s/KentESeamons",
                        "text": "Kent E. Seamons"
                    }
                ]
            },
            "title": "A Security and Usability Analysis of Local Attacks Against FIDO2.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/YadavS24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/a-security-and-usability-analysis-of-local-attacks-against-fido2/",
            "url": "https://dblp.org/rec/conf/ndss/YadavS24",
            "abstract": "The FIDO2 protocol aims to strengthen or replace password authentication using public-key cryptography. FIDO2 has primarily focused on defending against attacks from afar by remote attackers that compromise a password or attempt to phish the user. In this paper, we explore threats from local attacks on FIDO2 that have received less attention -- a browser extension compromise and attackers gaining physical access to an HSK. Our systematic analysis of current implementations of FIDO2 reveals four underlying flaws, and we demonstrate the feasibility of seven attacks that exploit those flaws. The flaws include (1) Lack of confidentiality/integrity of FIDO2 messages accessible to browser extensions, (2) Broken clone detection algorithm, (3) Potential for user misunderstanding from social engineering and notification/error messages, and (4) Cookie life cycle. We build malicious browser extensions and demonstrate the attacks on ten popular web servers that use FIDO2. We also show that many browser extensions have sufficient permissions to conduct the attacks if they were compromised. A static and dynamic analysis of current browser extensions finds no evidence of the attacks in the wild. We conducted two user studies confirming that participants do not detect the attacks with current error messages, email notifications, and UX responses to the attacks. We provide an improved clone detection algorithm and recommendations for relying part",
            "keywords": [
                "FIDO2 Protocol",
                "Local Attacks",
                "Browser Extension Security",
                "Clone Detection",
                "User Misunderstanding"
            ]
        },
        "url": "URL#358468",
        "sema_paperId": "4385ff92713d6f8e626a8d6522da11aaa91b34e7"
    },
    {
        "@score": "1",
        "@id": "358469",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "167/5749",
                        "text": "Huaiyu Yan"
                    },
                    {
                        "@pid": "79/7563",
                        "text": "Zhen Ling"
                    },
                    {
                        "@pid": "203/1987",
                        "text": "Haobo Li"
                    },
                    {
                        "@pid": "18/5122",
                        "text": "Lan Luo"
                    },
                    {
                        "@pid": "12/5975",
                        "text": "Xinhui Shao"
                    },
                    {
                        "@pid": "88/7785",
                        "text": "Kai Dong"
                    },
                    {
                        "@pid": "21/6889",
                        "text": "Ping Jiang"
                    },
                    {
                        "@pid": "98/2604-1",
                        "text": "Ming Yang 0001"
                    },
                    {
                        "@pid": "l/JunzhouLuo",
                        "text": "Junzhou Luo"
                    },
                    {
                        "@pid": "49/2189",
                        "text": "Xinwen Fu"
                    }
                ]
            },
            "title": "LDR: Secure and Efficient Linux Driver Runtime for Embedded TEE Systems.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/YanLLLSDJ0LF24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/ldr-secure-and-efficient-linux-driver-runtime-for-embedded-tee-systems/",
            "url": "https://dblp.org/rec/conf/ndss/YanLLLSDJ0LF24",
            "abstract": "\u2014Trusted execution environments (TEEs), like Trust-Zone, are pervasively employed to protect security sensitive programs and data from various attacks. We target compact TEE operating systems like OP-TEE, which implement minimum TEE internal core APIs. Such a TEE OS often has poor device driver support and we want to alleviate such issue by reusing existing Linux drivers inside TEE OSes. An intuitive approach is to port all its dependency functions into the TEE OS so that the driver can directly execute inside the TEE. But this approach significantly enlarges the trusted computing base (TCB), making the TEE OS no longer compact. In this paper, we propose a TEE driver execution environment\u2014Linux driver runtime (LDR). A Linux driver needs two types of functions, library functions and Linux kernel subsystem functions that a compact TEE OS does not have. The LDR reuses the existing TEE OS library functions whenever possible and redirects the kernel subsystem function calls to the Linux kernel in the normal world. LDR is realized as a sandbox environment, which confines the Linux driver inside the TEE through the ARM domain access control features to address associated security issues. The sandbox mediates the driver\u2019s TEE functions calls, sanitizing arguments and return values as well as enforcing forward control flow integrity. We implement and deploy an LDR prototype on an NXP IMX6Q SABRE-SD evaluation board, adapt 6 existing Linux drivers into LDR, and evaluate their performance. The experimental results show that the LDR drivers can achieve comparable performance with their Linux counterparts with negligible overheads. We are the first to",
            "keywords": [
                "Trusted Execution Environments",
                "TEEs",
                "Linux Driver Runtime",
                "Device Driver Support",
                "Trusted Computing Base (TCB)"
            ]
        },
        "url": "URL#358469",
        "sema_paperId": "a54fe9f1c73ae32738d32bfb4dfe4e50a4988cac"
    },
    {
        "@score": "1",
        "@id": "358470",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "59/5778",
                        "text": "Yuxiang Yang"
                    },
                    {
                        "@pid": "53/8376",
                        "text": "Xuewei Feng"
                    },
                    {
                        "@pid": "181/2688-2",
                        "text": "Qi Li 0002"
                    },
                    {
                        "@pid": "30/3530-1",
                        "text": "Kun Sun 0001"
                    },
                    {
                        "@pid": "68/2002",
                        "text": "Ziqiang Wang"
                    },
                    {
                        "@pid": "181/2626-2",
                        "text": "Ke Xu 0002"
                    }
                ]
            },
            "title": "Exploiting Sequence Number Leakage: TCP Hijacking in NAT-Enabled Wi-Fi Networks.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/YangF00W024",
            "ee": "https://www.ndss-symposium.org/ndss-paper/exploiting-sequence-number-leakage-tcp-hijacking-in-nat-enabled-wi-fi-networks/",
            "url": "https://dblp.org/rec/conf/ndss/YangF00W024",
            "abstract": "In this paper, we uncover a new side-channel vulnerability in the widely used NAT port preservation strategy and an insufficient reverse path validation strategy of Wi-Fi routers, which allows an off-path attacker to infer if there is one victim client in the same network communicating with another host on the Internet using TCP. After detecting the presence of TCP connections between the victim client and the server, the attacker can evict the original NAT mapping and reconstruct a new mapping at the router by sending fake TCP packets due to the routers' vulnerability of disabling TCP window tracking strategy, which has been faithfully implemented in most of the routers for years. In this way, the attacker can intercept TCP packets from the server and obtain the current sequence and acknowledgment numbers, which in turn allows the attacker to forcibly close the connection, poison the traffic in plain text, or reroute the server's incoming packets to the attacker.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2024-419-paper.pdf",
            "keywords": [
                "TCP Hijacking",
                "NAT Vulnerability",
                "Wi-Fi Security",
                "Sequence Number Leakage",
                "Traffic Interception"
            ]
        },
        "url": "URL#358470"
    },
    {
        "@score": "1",
        "@id": "358471",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "256/6148",
                        "text": "Chendong Yu"
                    },
                    {
                        "@pid": "181/1848-11",
                        "text": "Yang Xiao 0011"
                    },
                    {
                        "@pid": "39/2936",
                        "text": "Jie Lu"
                    },
                    {
                        "@pid": "204/3729",
                        "text": "Yuekang Li"
                    },
                    {
                        "@pid": "185/7953",
                        "text": "Yeting Li"
                    },
                    {
                        "@pid": "57/1586",
                        "text": "Lian Li"
                    },
                    {
                        "@pid": "51/8133",
                        "text": "Yifan Dong"
                    },
                    {
                        "@pid": "39/449-67",
                        "text": "Jian Wang 0067"
                    },
                    {
                        "@pid": "211/4082",
                        "text": "Jingyi Shi"
                    },
                    {
                        "@pid": "385/7659",
                        "text": "Defang Bo"
                    },
                    {
                        "@pid": "24/679",
                        "text": "Wei Huo"
                    }
                ]
            },
            "title": "File Hijacking Vulnerability: The Elephant in the Room.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/Yu0LLLLDWSBH24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/file-hijacking-vulnerability-the-elephant-in-the-room/",
            "url": "https://dblp.org/rec/conf/ndss/Yu0LLLLDWSBH24",
            "abstract": "\u2014Files are a significant attack vector for security boundary violation, yet a systematic understanding of the vulnerabilities underlying these attacks is lacking. To bridge this gap, we present a comprehensive analysis of File Hijacking Vulnerabilities (FHVulns), a type of vulnerability that enables attackers to breach security boundaries through the manipulation of file content or file paths. We provide an in-depth empirical study on 268 well-documented FHVuln CVE records from January 2020 to October 2022. Our study reveals the origins and triggering mechanisms of FHVulns and highlights that existing detection techniques have overlooked the majority of FHVulns. As a result, we anticipate a significant prevalence of zero-day FHVulns in software. We developed a dynamic analysis tool, J ERRY , which effectively detects FHVulns at runtime by simulating hijacking actions during program execution. We applied J ERRY to 438 popular software programs from vendors including Microsoft, Google, Adobe, and Intel, and found 339 zero-day FHVulns. We reported all vulnerabilities identified by J ERRY to the corresponding vendors, and as of now, 84 of them have been confirmed or fixed, with 51 CVE IDs granted and $83,400 bug bounties earned.",
            "keywords": [
                "File Hijacking Vulnerabilities",
                "Security Boundary Violation",
                "Dynamic Analysis",
                "Zero-day Vulnerabilities",
                "CVE Records"
            ]
        },
        "url": "URL#358471",
        "sema_paperId": "eda5303583b19fdaaeb8c6f8923f9481b3ce8d4e"
    },
    {
        "@score": "1",
        "@id": "358472",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "256/7594",
                        "text": "Hexuan Yu"
                    },
                    {
                        "@pid": "02/6435",
                        "text": "Changlai Du"
                    },
                    {
                        "@pid": "181/1848-10",
                        "text": "Yang Xiao 0010"
                    },
                    {
                        "@pid": "k/AngelosDKeromytis",
                        "text": "Angelos D. Keromytis"
                    },
                    {
                        "@pid": "84/2428",
                        "text": "Chonggang Wang"
                    },
                    {
                        "@pid": "220/9737",
                        "text": "Robert Gazda"
                    },
                    {
                        "@pid": "h/YTHou",
                        "text": "Y. Thomas Hou 0001"
                    },
                    {
                        "@pid": "73/3673",
                        "text": "Wenjing Lou"
                    }
                ]
            },
            "title": "AAKA: An Anti-Tracking Cellular Authentication Scheme Leveraging Anonymous Credentials.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/YuD0KWG0L24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/aaka-an-anti-tracking-cellular-authentication-scheme-leveraging-anonymous-credentials/",
            "url": "https://dblp.org/rec/conf/ndss/YuD0KWG0L24",
            "abstract": "\u2014Mobile tracking has long been a privacy problem, where the geographic data and timestamps gathered by mobile network operators (MNOs) are used to track the locations and movements of mobile subscribers. Additionally, selling the geolocation information of subscribers has become a lucrative business. Many mobile carriers have violated user privacy agreements by selling users\u2019 location history to third parties without user consent, exacerbating privacy issues related to mobile tracking and profiling. This paper presents AAKA , an anonymous authentication and key agreement scheme designed to protect against mobile tracking by honest-but-curious MNOs . AAKA leverages anonymous credentials and introduces a novel mobile authentication protocol that allows legitimate subscribers to access the network anonymously, without revealing their unique (real) IDs. It ensures the integrity of user credentials, preventing forgery, and ensures that connections made by the same user at different times cannot be linked. While the MNO alone cannot identify or profile a user, AAKA enables identification of a user under legal intervention, such as when the MNOs collaborate with an authorized law enforcement agency. Our design is compatible with the latest cellular architecture and SIM standardized by 3GPP, meeting 3GPP\u2019s fundamental security requirements for User Equipment (UE) authentication and key agreement processes. A comprehensive security analysis demonstrates the scheme\u2019s effectiveness. The evaluation shows that the scheme is practical, with a credential presentation generation taking \u223c 52 ms on a constrained host device equipped with a standard cellular SIM.",
            "keywords": [
                "Mobile Privacy",
                "Anonymous Authentication",
                "Location Tracking",
                "Mobile Network Operators",
                "User Identification"
            ]
        },
        "url": "URL#358472",
        "sema_paperId": "023f8718e2de225ad60315282e5c76911ee4cc0d"
    },
    {
        "@score": "1",
        "@id": "358473",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "88/2172",
                        "text": "Kunpeng Zhang"
                    },
                    {
                        "@pid": "171/2501",
                        "text": "Xiaogang Zhu 0001"
                    },
                    {
                        "@pid": "83/6642",
                        "text": "Xi Xiao"
                    },
                    {
                        "@pid": "166/1912",
                        "text": "Minhui Xue 0001"
                    },
                    {
                        "@pid": "94/3019-8",
                        "text": "Chao Zhang 0008"
                    },
                    {
                        "@pid": "41/3095",
                        "text": "Sheng Wen"
                    }
                ]
            },
            "title": "ShapFuzz: Efficient Fuzzing via Shapley-Guided Byte Selection.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/Zhang0XXZW24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/shapfuzz-efficient-fuzzing-via-shapley-guided-byte-selection/",
            "url": "https://dblp.org/rec/conf/ndss/Zhang0XXZW24",
            "abstract": "Mutation-based fuzzing is popular and effective in discovering unseen code and exposing bugs. However, only a few studies have concentrated on quantifying the importance of input bytes, which refers to the degree to which a byte contributes to the discovery of new code. They often focus on obtaining the relationship between input bytes and path constraints, ignoring the fact that not all constraint-related bytes can discover new code. In this paper, we conduct Shapely analysis to understand the effect of byte positions on fuzzing performance, and find that some byte positions contribute more than others and this property often holds across seeds. Based on this observation, we propose a novel fuzzing solution, ShapFuzz, to guide byte selection and mutation. Specifically, ShapFuzz updates Shapley values (importance) of bytes when each input is tested during fuzzing with a low overhead, and utilizes contextual multi-armed bandit to trade off between mutating high Shapley value bytes and low-frequently chosen bytes. We implement a prototype of this solution based on AFL++, i.e., ShapFuzz. We evaluate ShapFuzz against ten state-of-the-art fuzzers, including five byte schedule-reinforced fuzzers and five commonly used fuzzers. Compared with byte schedule-reinforced fuzzers, ShapFuzz discovers more edges and exposes more bugs than the best baseline on three different sets of initial seeds. Compared with commonly used fuzzers, ShapFuzz exposes 20 more bugs than the best comparison fuzzer, and discovers 6 more CVEs than the best baseline on MAGMA. Furthermore, ShapFuzz discovers 11 new bugs on the latest versions of programs, and 3 of them are confirmed by vendors.",
            "keywords": [
                "Fuzzing",
                "Shapley Values",
                "Byte Selection",
                "Mutation-Based Testing",
                "Bug Discovery"
            ]
        },
        "url": "URL#358473",
        "sema_paperId": "83b2584cdf4825cb37f7b15aa6de01d52c62138d"
    },
    {
        "@score": "1",
        "@id": "358474",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "55/2716",
                        "text": "Jianting Zhang"
                    },
                    {
                        "@pid": "02/8379",
                        "text": "Wuhui Chen"
                    },
                    {
                        "@pid": "349/4140",
                        "text": "Sifu Luo"
                    },
                    {
                        "@pid": "270/9951",
                        "text": "Tiantian Gong"
                    },
                    {
                        "@pid": "239/5523",
                        "text": "Zicong Hong"
                    },
                    {
                        "@pid": "12/3394",
                        "text": "Aniket Kate"
                    }
                ]
            },
            "title": "Front-running Attack in Sharded Blockchains and Fair Cross-shard Consensus.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ZhangCLGHK24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/front-running-attack-in-sharded-blockchains-and-fair-cross-shard-consensus/",
            "url": "https://dblp.org/rec/conf/ndss/ZhangCLGHK24",
            "abstract": "Sharding is a prominent technique for scaling blockchains. By dividing the network into smaller components known as shards, a sharded blockchain can process transactions in parallel without introducing inconsistencies through the coordination of intra-shard and cross-shard consensus protocols. However, we observe a critical security issue with sharded systems: transaction ordering manipulations can occur when coordinating intra-shard and cross-shard consensus protocols, leaving the system vulnerable to attack. Specifically, we identify a novel security issue known as finalization fairness, which can be exploited through a front-running attack. This attack allows an attacker to manipulate the execution order of transactions, even if the victim's transaction has already been processed and added to the blockchain by a fair intra-shard consensus. To address the issue, we offer Haechi, a novel cross-shard protocol that is immune to front-running attacks. Haechi introduces an ordering phase between transaction processing and execution, ensuring that the execution order of transactions is the same as the processing order and achieving finalization fairness. To accommodate different consensus speeds among shards, Haechi incorporates a finalization fairness algorithm to achieve a globally fair order with minimal performance loss. By providing a global order, Haechi ensures strong consistency among shards, enabling better parallelism in handling conflicting transactions across shards. These features make Haechi a promising solution for supporting popular smart contracts in the real world. To evaluate Haechi's performance, we implemented the protocol using Tendermint and conducted extensive experiments on a geo-distributed AWS environment. Our results demonstrate that Haechi achieves finalization fairness with little performance sacrifice compared to existing cross-shard consensus protocols.",
            "keywords": [
                "Sharded Blockchains",
                "Cross-shard Consensus",
                "Finalization Fairness",
                "Front-running Attack",
                "Transaction Ordering Manipulation"
            ]
        },
        "url": "URL#358474",
        "sema_paperId": "1e5465fbf37475074143209dbe92eb41e33bd81c"
    },
    {
        "@score": "1",
        "@id": "358475",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "06/2243",
                        "text": "Quan Zhang"
                    },
                    {
                        "@pid": "135/9001",
                        "text": "Yiwen Xu"
                    },
                    {
                        "@pid": "297/2408",
                        "text": "Zijing Yin"
                    },
                    {
                        "@pid": "228/5716",
                        "text": "Chijin Zhou"
                    },
                    {
                        "@pid": "21/4633-1",
                        "text": "Yu Jiang 0001"
                    }
                ]
            },
            "title": "Automatic Policy Synthesis and Enforcement for Protecting Untrusted Deserialization.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ZhangXYZ024",
            "ee": "https://www.ndss-symposium.org/ndss-paper/automatic-policy-synthesis-and-enforcement-for-protecting-untrusted-deserialization/",
            "url": "https://dblp.org/rec/conf/ndss/ZhangXYZ024",
            "abstract": "\u2014Java deserialization vulnerabilities have long been a grave security concern for Java applications. By injecting malicious objects with carefully crafted structures, attackers can reuse a series of existing methods during deserialization to achieve diverse attacks like remote code execution. To mitigate such attacks, developers are encouraged to implement policies restricting the object types that applications can deserialize. However, the design of precise policies requires expertise and significant manual effort, often leading to either the absence of policy or the implementation of inadequate ones. In this paper, we propose D ESERI G UARD , a tool designed to assist developers in securing their applications seamlessly against deserialization attacks. It can automatically formulate a policy based on the application\u2019s semantics and then enforce it to restrict illegal deserialization attempts. First, D ESERI G UARD utilizes dataflow analysis to construct a semantic-aware property tree, which records the potential structures of deserialized objects. Based on the tree, D ESERI G UARD identifies the types of objects that can be safely deserialized and synthesizes an allowlist policy. Then, with the Java agent, D ESERI G UARD can seamlessly enforce the policy during runtime to protect various deserialization procedures. In evaluation, D ESERI G UARD successfully blocks all deserialization attacks on 12 real-world vulnerabilities. In addition, we compare D ESERI G UARD \u2019s automatically synthesized policies with 109 developer-designed policies. The results demonstrate that D ESERI G UARD effectively restricts 99.12% more classes. Meanwhile, we test the policy-enhanced applications with their unit tests and integration tests, which demonstrate that D ESERI G UARD \u2019s policies will not interfere with applications\u2019 execution and induce a negligible time overhead of 2.17%.",
            "keywords": [
                "Java Deserialization",
                "Security Vulnerabilities",
                "Policy Synthesis",
                "Deserialization Attacks",
                "D ESERI G UARD"
            ]
        },
        "url": "URL#358475",
        "sema_paperId": "0b880813b905f8c88940173eeb8f0a72615764b8"
    },
    {
        "@score": "1",
        "@id": "358476",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "385/8278",
                        "text": "Linkai Zheng"
                    },
                    {
                        "@pid": "40/1491-108",
                        "text": "Xiang Li 0108"
                    },
                    {
                        "@pid": "210/1379",
                        "text": "Chuhan Wang"
                    },
                    {
                        "@pid": "234/0112",
                        "text": "Run Guo"
                    },
                    {
                        "@pid": "36/5143",
                        "text": "Haixin Duan"
                    },
                    {
                        "@pid": "20/1036-5",
                        "text": "Jianjun Chen 0005"
                    },
                    {
                        "@pid": "94/3019-8",
                        "text": "Chao Zhang 0008"
                    },
                    {
                        "@pid": "245/2568",
                        "text": "Kaiwen Shen"
                    }
                ]
            },
            "title": "ReqsMiner: Automated Discovery of CDN Forwarding Request Inconsistencies and DoS Attacks with Grammar-based Fuzzing.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ZhengLWGDC0S24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/reqsminer-automated-discovery-of-cdn-forwarding-request-inconsistencies-and-dos-attacks-with-grammar-based-fuzzing/",
            "url": "https://dblp.org/rec/conf/ndss/ZhengLWGDC0S24",
            "abstract": "\u2014Content Delivery Networks (CDNs) are ubiquitous middleboxes designed to enhance the performance of hosted websites and shield them from various attacks. Numerous notable studies show that CDNs modify a client\u2019s request when forwarding it to the original server. Multiple inconsistencies in this forwarding operation have been found to potentially result in security vulnerabilities like DoS attacks. Nonetheless, existing research lacks a systematic approach to studying CDN forwarding request inconsistencies. In this work, we present R EQS M INER , an innovative fuzzing framework developed to discover previously unexamined inconsistencies in CDN forwarding requests. The framework uses techniques derived from reinforcement learning to generate valid test cases, even with minimal feedback, and incorporates real field values into the grammar-based fuzzer. With the help of R EQS M INER , we comprehensively test 22 major CDN providers and uncover a wealth of hitherto unstudied CDN forwarding request inconsistencies. Moreover, the application of specialized analyzers enables R EQS M INER to extend its capabilities, evolving into a framework capable of detecting specific types of attacks. By extension, our work further identifies three novel types of HTTP amplification DoS attacks and uncovers 74 new potential DoS vulnerabilities with an amplification factor that can reach up to 2,000 generally, and even 1,920,000 under specific conditions. The vulnerabilities detected were responsibly disclosed to the affected CDN vendors, and mitigation suggestions were proposed. Our work contributes to fortifying CDN security, thereby enhancing their resilience against malicious attacks and preventing misuse.",
            "keywords": [
                "Content Delivery Networks",
                "Fuzzing Framework",
                "Request Forwarding Inconsistencies",
                "Denial of Service Attacks",
                "HTTP Amplification Vulnerabilities"
            ]
        },
        "url": "URL#358476",
        "sema_paperId": "bc357f3e3917619eacfdac78c82264c4cd6bb6bf"
    },
    {
        "@score": "1",
        "@id": "358477",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "165/8236",
                        "text": "Man Zhou"
                    },
                    {
                        "@pid": "375/0829",
                        "text": "Shuao Su"
                    },
                    {
                        "@pid": "75/5723-2",
                        "text": "Qian Wang 0002"
                    },
                    {
                        "@pid": "181/2688-2",
                        "text": "Qi Li 0002"
                    },
                    {
                        "@pid": "158/8682",
                        "text": "Yuting Zhou"
                    },
                    {
                        "@pid": "58/3273",
                        "text": "Xiaojing Ma"
                    },
                    {
                        "@pid": "217/8466",
                        "text": "Zhengxiong Li"
                    }
                ]
            },
            "title": "PrintListener: Uncovering the Vulnerability of Fingerprint Authentication via the Finger Friction Sound.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ZhouS00ZML24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/printlistener-uncovering-the-vulnerability-of-fingerprint-authentication-via-the-finger-friction-sound/",
            "url": "https://dblp.org/rec/conf/ndss/ZhouS00ZML24",
            "abstract": "Fingerprint authentication has been extensively employed in contemporary identity verification systems owing to its rapidity and cost-effectiveness. Due to its widespread use, fingerprint leakage may cause sensitive information theft, enormous economic and personnel losses, and even a potential compromise of national security. As a fingerprint that can coincidentally match a specific proportion of the overall fingerprint population, MasterPrint rings the alarm bells for the security of fingerprint authentication. In this paper, we propose a new side-channel attack on the minutiae-based Automatic Fingerprint Identification System (AFIS), called PrintListener, which leverages users' fingertip swiping actions on the screen to extract fingerprint pattern features (the first-level features) and synthesizes a stronger targeted PatternMasterPrint with potential second-level features. The attack scenario of PrintListener is extensive and covert. It only needs to record users' fingertip friction sound and can be launched by leveraging a large number of social media platforms. Extensive experimental results in realworld scenarios show that Printlistener can significantly improve the attack potency of MasterPrint.",
            "keywords": [
                "Fingerprint Authentication",
                "Side-Channel Attack",
                "PrintListener",
                "MasterPrint",
                "Fingerprint Pattern Features"
            ]
        },
        "url": "URL#358477",
        "sema_paperId": "d95e18a2ed90ae7edc230df1c7349c488b5f0605"
    },
    {
        "@score": "1",
        "@id": "358478",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "72/1974",
                        "text": "Rui Zhu"
                    },
                    {
                        "@pid": "77/1147-1",
                        "text": "Di Tang 0001"
                    },
                    {
                        "@pid": "44/10369",
                        "text": "Siyuan Tang"
                    },
                    {
                        "@pid": "148/9655",
                        "text": "Zihao Wang"
                    },
                    {
                        "@pid": "88/10370-1",
                        "text": "Guanhong Tao 0001"
                    },
                    {
                        "@pid": "172/8745",
                        "text": "Shiqing Ma"
                    },
                    {
                        "@pid": "06/6268",
                        "text": "XiaoFeng Wang 0001"
                    },
                    {
                        "@pid": "90/3951",
                        "text": "Haixu Tang"
                    }
                ]
            },
            "title": "Gradient Shaping: Enhancing Backdoor Attack Against Reverse Engineering.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/Zhu0TW0M0T24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/gradient-shaping-enhancing-backdoor-attack-against-reverse-engineering/",
            "url": "https://dblp.org/rec/conf/ndss/Zhu0TW0M0T24",
            "abstract": "Most existing methods to detect backdoored machine learning (ML) models take one of the two approaches: trigger inversion (aka. reverse engineer) and weight analysis (aka. model diagnosis). In particular, the gradient-based trigger inversion is considered to be among the most effective backdoor detection techniques, as evidenced by the TrojAI competition, Trojan Detection Challenge and backdoorBench. However, little has been done to understand why this technique works so well and, more importantly, whether it raises the bar to the backdoor attack. In this paper, we report the first attempt to answer this question by analyzing the change rate of the backdoored model's output around its trigger-carrying inputs. Our study shows that existing attacks tend to inject the backdoor characterized by a low change rate around trigger-carrying inputs, which are easy to capture by gradient-based trigger inversion. In the meantime, we found that the low change rate is not necessary for a backdoor attack to succeed: we design a new attack enhancement method called Gradient Shaping (GRASP), which follows the opposite direction of adversarial training to reduce the change rate of a backdoored model with regard to the trigger, without undermining its backdoor effect. Also, we provide a theoretic analysis to explain the effectiveness of this new technique and the fundamental weakness of gradient-based trigger inversion. Finally, we perform both theoretical and experimental analysis, showing that the GRASP enhancement does not reduce the effectiveness of the stealthy attacks designed to evade the backdoor detection methods based on weight analysis, as well as other backdoor mitigation methods without using detection.",
            "pdf_url": "https://www.ndss-symposium.org/wp-content/uploads/2024-450-paper.pdf",
            "keywords": [
                "Backdoor Attack",
                "Gradient Shaping",
                "Trigger Inversion",
                "Model Diagnosis",
                "Stealthy Attacks"
            ]
        },
        "url": "URL#358478"
    },
    {
        "@score": "1",
        "@id": "358479",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "83/4183",
                        "text": "Wenjun Zhu"
                    },
                    {
                        "@pid": "75/5247",
                        "text": "Yuan Sun"
                    },
                    {
                        "@pid": "365/4072",
                        "text": "Jiani Liu 0009"
                    },
                    {
                        "@pid": "63/4074",
                        "text": "Yushi Cheng"
                    },
                    {
                        "@pid": "39/1697-1",
                        "text": "Xiaoyu Ji 0001"
                    },
                    {
                        "@pid": "10/3878-1",
                        "text": "Wenyuan Xu 0001"
                    }
                ]
            },
            "title": "CamPro: Camera-based Anti-Facial Recognition.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/ZhuS0C0024",
            "ee": "https://www.ndss-symposium.org/ndss-paper/campro-camera-based-anti-facial-recognition/",
            "url": "https://dblp.org/rec/conf/ndss/ZhuS0C0024",
            "abstract": "The proliferation of images captured from millions of cameras and the advancement of facial recognition (FR) technology have made the abuse of FR a severe privacy threat. Existing works typically rely on obfuscation, synthesis, or adversarial examples to modify faces in images to achieve anti-facial recognition (AFR). However, the unmodified images captured by camera modules that contain sensitive personally identifiable information (PII) could still be leaked. In this paper, we propose a novel approach, CamPro, to capture inborn AFR images. CamPro enables well-packed commodity camera modules to produce images that contain little PII and yet still contain enough information to support other non-sensitive vision applications, such as person detection. Specifically, CamPro tunes the configuration setup inside the camera image signal processor (ISP), i.e., color correction matrix and gamma correction, to achieve AFR, and designs an image enhancer to keep the image quality for possible human viewers. We implemented and validated CamPro on a proof-of-concept camera, and our experiments demonstrate its effectiveness on ten state-of-the-art black-box FR models. The results show that CamPro images can significantly reduce face identification accuracy to 0.3\\% while having little impact on the targeted non-sensitive vision application. Furthermore, we find that CamPro is resilient to adaptive attackers who have re-trained their FR models using images generated by CamPro, even with full knowledge of privacy-preserving ISP parameters.",
            "keywords": [
                "Anti-Facial Recognition",
                "Camera Technology",
                "Privacy Preservation",
                "Image Signal Processing",
                "Face Identification Accuracy"
            ]
        },
        "url": "URL#358479",
        "sema_paperId": "47270a45d0626c2084481b9987346c36d9c2e0bb"
    },
    {
        "@score": "1",
        "@id": "358480",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "210/0533",
                        "text": "Xiaochen Zou"
                    },
                    {
                        "@pid": "33/3270-6",
                        "text": "Yu Hao 0006"
                    },
                    {
                        "@pid": "181/2621",
                        "text": "Zheng Zhang"
                    },
                    {
                        "@pid": "385/8658",
                        "text": "Juefei Pu"
                    },
                    {
                        "@pid": "224/9379",
                        "text": "Weiteng Chen"
                    },
                    {
                        "@pid": "31/8302",
                        "text": "Zhiyun Qian"
                    }
                ]
            },
            "title": "SyzBridge: Bridging the Gap in Exploitability Assessment of Linux Kernel Bugs in the Linux Ecosystem.",
            "venue": "NDSS",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/ndss/Zou0ZPCQ24",
            "ee": "https://www.ndss-symposium.org/ndss-paper/syzbridge-bridging-the-gap-in-exploitability-assessment-of-linux-kernel-bugs-in-the-linux-ecosystem/",
            "url": "https://dblp.org/rec/conf/ndss/Zou0ZPCQ24",
            "abstract": "\u2014Continuous fuzzing has become an integral part of the Linux kernel ecosystem, discovering thousands of bugs over the past few years. Interestingly, only a tiny fraction of them were turned into real-world exploits that target downstream distributions, e.g., Ubuntu and Fedora. This contradicts the conclusions of existing exploitability assessment tools, which classify hundreds of those bugs as high-risk, implying a high likelihood of exploitability. Our study aims to understand the gap and bridge it. Through our investigation, we realize that the current exploitability assessment tools exclusively test bug exploitability on the upstream Linux, which is for development only; in fact, we find many of them fail to reproduce directly in downstreams. Through a large-scale measurement study of 230 bugs on 43 distros (8,032 bug/distro pairs), we find that each distro only reproduces 19.1% of bugs on average by running the upstream PoCs as root user, and 0.9% without root. Remarkably, both numbers can be significantly improved by 61% and 1300% times respectively through appropriate PoC adaptations, necessitated by environment differences. To this end, we developed SyzBridge, a fully automated system that adapts upstream PoCs to downstream kernels. We further integrate SyzBridge with SyzScope, a state-of-the-art exploitability assessment tool that can identify high-risk exploit primitives, e.g., control flow hijack. Our integrated pipeline successfully identified 53 bugs originated from syzbot that are likely exploitable on downstream distributions, surpassing the mere 5 bugs that were turned into real-world exploits among 5,000 upstream bugs from",
            "keywords": [
                "Linux Kernel Exploitability",
                "Fuzzing",
                "Downstream Distributions",
                "Bug Assessment",
                "PoC Adaptation"
            ]
        },
        "url": "URL#358480",
        "sema_paperId": "815f8863b5cb74a00664f5b77653e6229627f50c"
    },
    {
        "@score": "1",
        "@id": "390771",
        "info": {
            "title": "31st Annual Network and Distributed System Security Symposium, NDSS 2024, San Diego, California, USA, February 26 - March 1, 2024",
            "venue": "NDSS",
            "publisher": "The Internet Society",
            "year": "2024",
            "type": "Editorship",
            "access": "open",
            "key": "conf/ndss/2024",
            "ee": "https://www.ndss-symposium.org/ndss2024/",
            "url": "https://dblp.org/rec/conf/ndss/2024",
            "abstract": null
        },
        "url": "URL#390771",
        "sema_paperId": "2557539ae276d98bdcf0db2359e2f44bcdd269b1"
    }
]