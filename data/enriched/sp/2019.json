[
    {
        "@score": "1",
        "@id": "2761134",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "22/3870-2",
                        "text": "Zhen Huang 0002"
                    },
                    {
                        "@pid": "l/DavidLie",
                        "text": "David Lie"
                    },
                    {
                        "@pid": "91/6206",
                        "text": "Gang Tan"
                    },
                    {
                        "@pid": "45/576",
                        "text": "Trent Jaeger"
                    }
                ]
            },
            "title": "Using Safety Properties to Generate Vulnerability Patches.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "539-554",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/0002LTJ19",
            "doi": "10.1109/SP.2019.00071",
            "ee": "https://doi.org/10.1109/SP.2019.00071",
            "url": "https://dblp.org/rec/conf/sp/0002LTJ19",
            "abstract": "Security vulnerabilities are among the most critical software defects in existence. When identified, programmers aim to produce patches that prevent the vulnerability as quickly as possible, motivating the need for automatic program repair (APR) methods to generate patches automatically. Unfortunately, most current APR methods fall short because they approximate the properties necessary to prevent the vulnerability using examples. Approximations result in patches that either do not fix the vulnerability comprehensively, or may even introduce new bugs. Instead, we propose property-based APR, which uses human-specified, program-independent and vulnerability-specific safety properties to derive source code patches for security vulnerabilities. Unlike properties that are approximated by observing the execution of test cases, such safety properties are precise and complete. The primary challenge lies in mapping such safety properties into source code patches that can be instantiated into an existing program. To address these challenges, we propose Senx, which, given a set of safety properties and a single input that triggers the vulnerability, detects the safety property violated by the vulnerability input and generates a corresponding patch that enforces the safety property and thus, removes the vulnerability. Senx solves several challenges with property-based APR: it identifies the program expressions and variables that must be evaluated to check safety properties and identifies the program scopes where they can be evaluated, it generates new code to selectively compute the values it needs if calling existing program code would cause unwanted side effects, and it uses a novel access range analysis technique to avoid placing patches inside loops where it could incur performance overhead. Our evaluation shows that the patches generated by Senx successfully fix 32 of 42 real-world vulnerabilities from 11 applications including various tools or libraries for manipulating graphics/media files, a programming language interpreter, a relational database engine, a collection of programming tools for creating and managing binary programs, and a collection of basic file, shell, and text manipulation tools.",
            "keywords": [
                "Automatic Program Repair",
                "Vulnerability Patching",
                "Safety Properties",
                "Program Analysis",
                "Security Vulnerabilities"
            ]
        },
        "url": "URL#2761134",
        "sema_paperId": "1f95ac730dcbfb8244ff3d9aeee54dd484b20db5"
    },
    {
        "@score": "1",
        "@id": "2761135",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "125/3714-2",
                        "text": "Hang Hu 0002"
                    },
                    {
                        "@pid": "49/683",
                        "text": "Peng Peng"
                    },
                    {
                        "@pid": "71/4292-11",
                        "text": "Gang Wang 0011"
                    }
                ]
            },
            "title": "Characterizing Pixel Tracking through the Lens of Disposable Email Services.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "365-379",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/0002PW19",
            "doi": "10.1109/SP.2019.00033",
            "ee": "https://doi.org/10.1109/SP.2019.00033",
            "url": "https://dblp.org/rec/conf/sp/0002PW19",
            "abstract": "Disposable email services provide temporary email addresses, which allows people to register online accounts without exposing their real email addresses. In this paper, we perform the first measurement study on disposable email services with two main goals. First, we aim to understand what disposable email services are used for, and what risks (if any) are involved in the common use cases. Second, we use the disposable email services as a public gateway to collect a large-scale email dataset for measuring email tracking. Over three months, we collected a dataset from 7 popular disposable email services which contain 2.3 million emails sent by 210K domains. We show that online accounts registered through disposable email addresses can be easily hijacked, leading to potential information leakage and financial loss. By empirically analyzing email tracking, we find that third-party tracking is highly prevalent, especially in the emails sent by popular services. We observe that trackers are using various methods to hide their tracking behavior such as falsely claiming the size of tracking images or hiding real trackers behind redirections. A few top trackers stand out in the tracking ecosystem but are not yet dominating the market.",
            "keywords": [
                "Disposable Email Services",
                "Email Tracking",
                "Data Privacy",
                "Account Hijacking",
                "Third-Party Trackers"
            ]
        },
        "url": "URL#2761135",
        "sema_paperId": "ee4c089b4378fbb1fa720559081abbb4842dc182"
    },
    {
        "@score": "1",
        "@id": "2761136",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "68/6577-3",
                        "text": "Ren Zhang 0003"
                    },
                    {
                        "@pid": "p/BartPreneel",
                        "text": "Bart Preneel"
                    }
                ]
            },
            "title": "Lay Down the Common Metrics: Evaluating Proof-of-Work Consensus Protocols&apos; Security.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "175-192",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/0003P19",
            "doi": "10.1109/SP.2019.00086",
            "ee": "https://doi.org/10.1109/SP.2019.00086",
            "url": "https://dblp.org/rec/conf/sp/0003P19",
            "abstract": "Following Bitcoin's Nakamoto Consensus protocol (NC), hundreds of cryptocurrencies utilize proofs of work (PoW) to maintain their ledgers. However, research shows that NC fails to achieve perfect chain quality, allowing malicious miners to alter the public ledger in order to launch several attacks, i.e., selfish mining, double-spending and feather-forking. Some later designs, represented by Ethereum, Bitcoin-NG, DECOR+, Byzcoin and Publish or Perish, aim to solve the problem by raising the chain quality; other designs, represented by Fruitchains, DECOR+ and Subchains, claim to successfully defend against the attacks in the absence of perfect chain quality. As their effectiveness remains self-claimed, the community is divided on whether a secure PoW protocol is possible. In order to resolve this ambiguity and to lay down the foundation of a common body of knowledge, this paper introduces a multi-metric evaluation framework to quantitatively analyze PoW protocols' chain quality and attack resistance. Subsequently we use this framework to evaluate the security of these improved designs through Markov decision processes. We conclude that to date, no PoW protocol achieves ideal chain quality or is resistant against all three attacks. We attribute existing PoW protocols' imperfect chain quality to their unrealistic security assumptions, and their unsatisfactory attack resistance to a dilemma between \"rewarding the bad\" and \"punishing the good\". Moreover, our analysis reveals various new protocol-specific attack strategies. Based on our analysis, we propose future directions toward more secure PoW protocols and indicate several common pitfalls in PoW security analyses.",
            "keywords": [
                "Proof-of-Work Protocols",
                "Chain Quality",
                "Attack Resistance",
                "Malicious Mining Attacks",
                "Security Evaluation Framework"
            ]
        },
        "url": "URL#2761136",
        "sema_paperId": "01b198ed09d52a7c601bcf229705508847cf48ca"
    },
    {
        "@score": "1",
        "@id": "2761140",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "180/3056",
                        "text": "Alejandro Cabrera Aldaya"
                    },
                    {
                        "@pid": "25/1876",
                        "text": "Billy Bob Brumley"
                    },
                    {
                        "@pid": "223/9675",
                        "text": "Sohaib ul Hassan"
                    },
                    {
                        "@pid": "181/1564",
                        "text": "Cesar Pereida Garc\u00eda"
                    },
                    {
                        "@pid": "54/10083",
                        "text": "Nicola Tuveri"
                    }
                ]
            },
            "title": "Port Contention for Fun and Profit.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "870-887",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/AldayaBHGT19",
            "doi": "10.1109/SP.2019.00066",
            "ee": "https://doi.org/10.1109/SP.2019.00066",
            "url": "https://dblp.org/rec/conf/sp/AldayaBHGT19",
            "abstract": "Simultaneous Multithreading (SMT) architectures are attractive targets for side-channel enabled attackers, with their inherently broader attack surface that exposes more per physical core microarchitecture components than cross-core attacks. In this work, we explore SMT execution engine sharing as a side-channel leakage source. We target ports to stacks of execution units to create a high-resolution timing side-channel due to port contention, inherently stealthy since it does not depend on the memory subsystem like other cache or TLB based attacks. Implementing our channel on Intel Skylake and Kaby Lake architectures featuring Hyper-Threading, we mount an end-to-end attack that recovers a P-384 private key from an OpenSSL-powered TLS server using a small number of repeated TLS handshake attempts. Furthermore, we show that traces targeting shared libraries, static builds, and SGX enclaves are essentially identical, hence our channel has wide target application.",
            "pdf_url": "",
            "keywords": [
                "Simultaneous Multithreading",
                "Side-Channel Attacks",
                "Port Contention",
                "Execution Engine Sharing",
                "P-384 Private Key Recovery"
            ]
        },
        "url": "URL#2761140"
    },
    {
        "@score": "1",
        "@id": "2761141",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "127/7110",
                        "text": "Omar Alrawi"
                    },
                    {
                        "@pid": "134/8710",
                        "text": "Chaz Lever"
                    },
                    {
                        "@pid": "26/216",
                        "text": "Manos Antonakakis"
                    },
                    {
                        "@pid": "50/6700",
                        "text": "Fabian Monrose"
                    }
                ]
            },
            "title": "SoK: Security Evaluation of Home-Based IoT Deployments.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "1362-1380",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/AlrawiLAM19",
            "doi": "10.1109/SP.2019.00013",
            "ee": "https://doi.org/10.1109/SP.2019.00013",
            "url": "https://dblp.org/rec/conf/sp/AlrawiLAM19",
            "abstract": "Home-based IoT devices have a bleak reputation regarding their security practices. On the surface, the insecurities of IoT devices seem to be caused by integration problems that may be addressed by simple measures, but this work finds that to be a naive assumption. The truth is, IoT deployments, at their core, utilize traditional compute systems, such as embedded, mobile, and network. These components have many unexplored challenges such as the effect of over-privileged mobile applications on embedded devices. Our work proposes a methodology that researchers and practitioners could employ to analyze security properties for home-based IoT devices. We systematize the literature for home-based IoT using this methodology in order to understand attack techniques, mitigations, and stakeholders. Further, we evaluate \\numDevices devices to augment the systematized literature in order to identify neglected research areas. To make this analysis transparent and easier to adapt by the community, we provide a public portal to share our evaluation data and invite the community to contribute their independent findings.",
            "keywords": [
                "Home-Based IoT Security",
                "IoT Device Vulnerabilities",
                "Embedded Systems",
                "Attack Techniques",
                "Security Evaluation Methodology"
            ]
        },
        "url": "URL#2761141",
        "sema_paperId": "c7737579b08914a7d589af550336cca41a602d65"
    },
    {
        "@score": "1",
        "@id": "2761143",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "201/4848",
                        "text": "Subarno Banerjee"
                    },
                    {
                        "@pid": "127/3085",
                        "text": "David Devecsery"
                    },
                    {
                        "@pid": "c/PeterMChen",
                        "text": "Peter M. Chen"
                    },
                    {
                        "@pid": "27/3820",
                        "text": "Satish Narayanasamy"
                    }
                ]
            },
            "title": "Iodine: Fast Dynamic Taint Tracking Using Rollback-free Optimistic Hybrid Analysis.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "490-504",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/BanerjeeDCN19",
            "doi": "10.1109/SP.2019.00043",
            "ee": "https://doi.org/10.1109/SP.2019.00043",
            "url": "https://dblp.org/rec/conf/sp/BanerjeeDCN19",
            "abstract": "Dynamic information-flow tracking (DIFT) is useful for enforcing security policies, but rarely used in practice, as it can slow down a program by an order of magnitude. Static program analyses can be used to prove safe execution states and elide unnecessary DIFT monitors, but the performance improvement from these analyses is limited by their need to maintain soundness. In this paper, we present a novel optimistic hybrid analysis (OHA) to significantly reduce DIFT overhead while still guaranteeing sound results. It consists of a predicated whole-program static taint analysis, which assumes likely invariants gathered from profiles to dramatically improve precision. The optimized DIFT is sound for executions in which those invariants hold true, and recovers to a conservative DIFT for executions in which those invariants are false. We show how to overcome the main problem with using OHA to optimize live executions, which is the possibility of unbounded rollbacks. We eliminate the need for any rollback during recovery by tailoring our predicated static analysis to eliminate only safe elisions of noop monitors. Our tool, Iodine, reduces the overhead of DIFT for enforcing security policies to 9%, which is 4.4x lower than that with traditional hybrid analysis, while still being able to be run on live systems.",
            "keywords": [
                "Dynamic Information-Flow Tracking",
                "Optimistic Hybrid Analysis",
                "Taint Analysis",
                "Performance Optimization",
                "Rollback-free Recovery"
            ]
        },
        "url": "URL#2761143",
        "sema_paperId": "454aa56c5de80b6f03c8d50af4a8da60d2518f45"
    },
    {
        "@score": "1",
        "@id": "2761144",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "249/3164",
                        "text": "Robert Brotzman"
                    },
                    {
                        "@pid": "19/6036-2",
                        "text": "Shen Liu 0002"
                    },
                    {
                        "@pid": "23/3719",
                        "text": "Danfeng Zhang"
                    },
                    {
                        "@pid": "91/6206",
                        "text": "Gang Tan"
                    },
                    {
                        "@pid": "k/MahmutTKandemir",
                        "text": "Mahmut T. Kandemir"
                    }
                ]
            },
            "title": "CaSym: Cache Aware Symbolic Execution for Side Channel Detection and Mitigation.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "505-521",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/BrotzmanLZTK19",
            "doi": "10.1109/SP.2019.00022",
            "ee": "https://doi.org/10.1109/SP.2019.00022",
            "url": "https://dblp.org/rec/conf/sp/BrotzmanLZTK19",
            "abstract": "Cache-based side channels are becoming an important attack vector through which secret information can be leaked to malicious parties. Previous work on cache-based side channel detection, however, suffers from the code coverage problem or does not provide diagnostic information that is crucial for applying mitigation techniques to vulnerable software. We propose CaSym, a cache-aware symbolic execution to identify and report precise information about where side channels occur in an input program. Compared with existing work, CaSym provides several unique features: (1) CaSym enables verification against various attack models and cache models, (2) unlike many symbolic-execution systems for bug finding, CaSym verifies all program execution paths in a sound way, (3) CaSym uses two novel abstract cache models that provide good balance between analysis scalability and precision, and (4) CaSym provides sufficient information on where and how to mitigate the identified side channels through techniques including preloading and pinning. Evaluation on a set of crypto and database benchmarks shows that CaSym is effective at identifying and mitigating side channels, with reasonable efficiency. Keywords-side-channels; symbolic execution; cache",
            "keywords": [
                "Cache-based Side Channels",
                "Symbolic Execution",
                "Side Channel Detection",
                "Mitigation Techniques",
                "Abstract Cache Models"
            ]
        },
        "url": "URL#2761144",
        "sema_paperId": "8897f9121f2726b50aca4628272853d6b66729c2"
    },
    {
        "@score": "1",
        "@id": "2761145",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "157/1187",
                        "text": "Nathan Burow"
                    },
                    {
                        "@pid": "34/10151",
                        "text": "Xinping Zhang"
                    },
                    {
                        "@pid": "31/1273",
                        "text": "Mathias Payer"
                    }
                ]
            },
            "title": "SoK: Shining Light on Shadow Stacks.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "985-999",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/BurowZP19",
            "doi": "10.1109/SP.2019.00076",
            "ee": "https://doi.org/10.1109/SP.2019.00076",
            "url": "https://dblp.org/rec/conf/sp/BurowZP19",
            "abstract": "Control-Flow Hijacking attacks are the dominant attack vector against C/C++ programs. Control-Flow Integrity (CFI) solutions mitigate these attacks on the forward edge, i.e., indirect calls through function pointers and virtual calls. Protecting the backward edge is left to stack canaries, which are easily bypassed through information leaks. Shadow Stacks are a fully precise mechanism for protecting backwards edges, and should be deployed with CFI mitigations. We present a comprehensive analysis of all possible shadow stack mechanisms along three axes: performance, compatibil- ity, and security. For performance comparisons we use SPEC CPU2006, while security and compatibility are qualitatively analyzed. Based on our study, we renew calls for a shadow stack design that leverages a dedicated register, resulting in low performance overhead, and minimal memory overhead, but sacrifices compatibility. We present case studies of our implementation of such a design, Shadesmar, on Phoronix and Apache to demonstrate the feasibility of dedicating a general purpose register to a security monitor on modern architectures, and Shadesmar\u2019s deployability. Our comprehensive analysis, including detailed case studies for our novel design, allows compiler designers and practitioners to select the correct shadow stack design for different usage scenarios. Shadow stacks belong to the class of defense mechanisms that require metadata about the program\u2019s state to enforce their defense policies. Protecting this metadata for deployed mitigations requires in-process isolation of a segment of the virtual address space. Prior work on defenses in this class has relied on information hiding to protect metadata. We show that stronger guarantees are possible by repurposing two new Intel x86 extensions for memory protection (MPX), and page table control (MPK). Building on our isolation efforts with MPX and MPK, we present the design requirements for a dedicated hardware mechanism to support intra-process memory isolation, and discuss how such a mechanism can empower the next wave of highly precise software security mitigations that rely on partially isolated information in a process.",
            "keywords": [
                "Control-Flow Hijacking",
                "Control-Flow Integrity",
                "Shadow Stacks",
                "Memory Protection",
                "Intra-Process Isolation"
            ]
        },
        "url": "URL#2761145",
        "sema_paperId": "d937580aff538e8c2fb5009c638da6dba29bd5d2"
    },
    {
        "@score": "1",
        "@id": "2761146",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "89/9526",
                        "text": "Stefano Calzavara"
                    },
                    {
                        "@pid": "f/RiccardoFocardi",
                        "text": "Riccardo Focardi"
                    },
                    {
                        "@pid": "185/1617",
                        "text": "Mat\u00fas Nemec"
                    },
                    {
                        "@pid": "159/0703",
                        "text": "Alvise Rabitti"
                    },
                    {
                        "@pid": "117/7980",
                        "text": "Marco Squarcina"
                    }
                ]
            },
            "title": "Postcards from the Post-HTTP World: Amplification of HTTPS Vulnerabilities in the Web Ecosystem.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "281-298",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/CalzavaraFNRS19",
            "doi": "10.1109/SP.2019.00053",
            "ee": "https://doi.org/10.1109/SP.2019.00053",
            "url": "https://dblp.org/rec/conf/sp/CalzavaraFNRS19",
            "abstract": "HTTPS aims at securing communication over the Web by providing a cryptographic protection layer that ensures the confidentiality and integrity of communication and enables client/server authentication. However, HTTPS is based on the SSL/TLS protocol suites that have been shown to be vulnerable to various attacks in the years. This has required fixes and mitigations both in the servers and in the browsers, producing a complicated mixture of protocol versions and implementations in the wild, which makes it unclear which attacks are still effective on the modern Web and what is their import on web application security. In this paper, we present the first systematic quantitative evaluation of web application insecurity due to cryptographic vulnerabilities. We specify attack conditions against TLS using attack trees and we crawl the Alexa Top 10k to assess the import of these issues on page integrity, authentication credentials and web tracking. Our results show that the security of a consistent number of websites is severely harmed by cryptographic weaknesses that, in many cases, are due to external or related-domain hosts. This empirically, yet systematically demonstrates how a relatively limited number of exploitable HTTPS vulnerabilities are amplified by the complexity of the web ecosystem.",
            "keywords": [
                "HTTPS Vulnerabilities",
                "Web Ecosystem",
                "Cryptographic Weaknesses",
                "TLS Attacks",
                "Page Integrity"
            ]
        },
        "url": "URL#2761146",
        "sema_paperId": "92b012b1793a735a35c14f00c6d04515dfaf2068"
    },
    {
        "@score": "1",
        "@id": "2761148",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "49/6574",
                        "text": "Yi Chen"
                    },
                    {
                        "@pid": "205/3769",
                        "text": "Mingming Zha"
                    },
                    {
                        "@pid": "28/6297-18",
                        "text": "Nan Zhang 0018"
                    },
                    {
                        "@pid": "94/8594",
                        "text": "Dandan Xu"
                    },
                    {
                        "@pid": "129/1039",
                        "text": "Qianqian Zhao"
                    },
                    {
                        "@pid": "09/8674",
                        "text": "Xuan Feng"
                    },
                    {
                        "@pid": "03/7768",
                        "text": "Kan Yuan"
                    },
                    {
                        "@pid": "211/7696",
                        "text": "Fnu Suya"
                    },
                    {
                        "@pid": "39/5423-1",
                        "text": "Yuan Tian 0001"
                    },
                    {
                        "@pid": "c/KaiChen12",
                        "text": "Kai Chen 0012"
                    },
                    {
                        "@pid": "06/6268",
                        "text": "XiaoFeng Wang 0001"
                    },
                    {
                        "@pid": "10/328",
                        "text": "Wei Zou"
                    }
                ]
            },
            "title": "Demystifying Hidden Privacy Settings in Mobile Apps.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "570-586",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/ChenZZXZFYST00Z19",
            "doi": "10.1109/SP.2019.00054",
            "ee": "https://doi.org/10.1109/SP.2019.00054",
            "url": "https://dblp.org/rec/conf/sp/ChenZZXZFYST00Z19",
            "abstract": "Mobile apps include privacy settings that allow their users to configure how their data should be shared. These settings, however, are often hard to locate and hard to understand by the users, even in popular apps, such as Facebook. More seriously, they are often set to share user data by default, exposing her privacy without proper consent. In this paper, we report the first systematic study on the problem, which is made possible through an in-depth analysis of user perception of the privacy settings. More specifically, we first conduct two user studies (involving nearly one thousand users) to understand privacy settings from the user\u2019s perspective, and identify these hard-to-find settings. Then we select 14 features that uniquely characterize such hidden privacy settings and utilize a novel technique called semantics- based UI tracing to extract them from a given app. On top of these features, a classifier is trained to automatically discover the hidden privacy settings, which together with other innovations, has been implemented into a tool called Hound. Over our labeled data set, the tool achieves an accuracy of 93.54%. Further running it on 100,000 latest apps from both Google Play and third-party markets, we find that over a third (36.29%) of the privacy settings identified from these apps are \u201chidden\u201d. Looking into these settings, we observe that they become hard to discover and hard to understand primarily due to the problematic categorization on the apps\u2019 user interfaces and/or confusing descriptions. Further importantly, though more privacy options have been offered to the user over time, also discovered is the persistence of their usability issue, which becomes even more serious, e.g., originally easy-to-find settings now harder to locate. And among all such hidden privacy settings, 82.16% are set to leak user privacy by default. We provide suggestions for improving the usability of these privacy settings at the end of our study.",
            "keywords": [
                "Mobile App Privacy",
                "User Interface Usability",
                "Hidden Privacy Settings",
                "User Data Sharing",
                "Privacy Consent Issues"
            ]
        },
        "url": "URL#2761148",
        "sema_paperId": "8c3e4093d632d2b2e13190365ffb932afb396607"
    },
    {
        "@score": "1",
        "@id": "2761152",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "160/9382",
                        "text": "Giovanni Cherubin"
                    },
                    {
                        "@pid": "32/858",
                        "text": "Konstantinos Chatzikokolakis 0001"
                    },
                    {
                        "@pid": "p/CPalamidessi",
                        "text": "Catuscia Palamidessi"
                    }
                ]
            },
            "title": "F-BLEAU: Fast Black-Box Leakage Estimation.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "835-852",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/Cherubin0P19",
            "doi": "10.1109/SP.2019.00073",
            "ee": "https://doi.org/10.1109/SP.2019.00073",
            "url": "https://dblp.org/rec/conf/sp/Cherubin0P19",
            "abstract": "We consider the problem of measuring how much a system reveals about its secret inputs. We work in the black-box setting: we assume no prior knowledge of the system's internals, and we run the system for choices of secrets and measure its leakage from the respective outputs. Our goal is to estimate the Bayes risk, from which one can derive some of the most popular leakage measures (e.g., min-entropy leakage). The state-of-the-art method for estimating these leakage measures is the frequentist paradigm, which approximates the system's internals by looking at the frequencies of its inputs and outputs. Unfortunately, this does not scale for systems with large output spaces, where it would require too many input-output examples. Consequently, it also cannot be applied to systems with continuous outputs (e.g., time side channels, network traffic). In this paper, we exploit an analogy between Machine Learning (ML) and black-box leakage estimation to show that the Bayes risk of a system can be estimated by using a class of ML methods: the universally consistent learning rules; these rules can exploit patterns in the input-output examples to improve the estimates' convergence, while retaining formal optimality guarantees. We focus on a set of them, the nearest neighbor rules; we show that they significantly reduce the number of black-box queries required for a precise estimation whenever nearby outputs tend to be produced by the same secret; furthermore, some of them can tackle systems with continuous outputs. We illustrate the applicability of these techniques on both synthetic and real-world data, and we compare them with the state-of-the-art tool, leakiEst, which is based on the frequentist approach.",
            "keywords": [
                "Black-Box Leakage Estimation",
                "Bayes Risk",
                "Leakage Measures",
                "Nearest Neighbor Rules",
                "Continuous Outputs"
            ]
        },
        "url": "URL#2761152",
        "sema_paperId": "000685e039f89a4baf3e0de2502dbc988e663db4"
    },
    {
        "@score": "1",
        "@id": "2761153",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "34/8322",
                        "text": "Pern Hui Chia"
                    },
                    {
                        "@pid": "161/2646",
                        "text": "Damien Desfontaines"
                    },
                    {
                        "@pid": "71/11234",
                        "text": "Irippuge Milinda Perera"
                    },
                    {
                        "@pid": "248/7800",
                        "text": "Daniel Simmons-Marengo"
                    },
                    {
                        "@pid": "66/190",
                        "text": "Chao Li"
                    },
                    {
                        "@pid": "88/8813",
                        "text": "Wei-Yen Day"
                    },
                    {
                        "@pid": "58/7677",
                        "text": "Qiushi Wang"
                    },
                    {
                        "@pid": "249/3173",
                        "text": "Miguel Guevara"
                    }
                ]
            },
            "title": "KHyperLogLog: Estimating Reidentifiability and Joinability of Large Data at Scale.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "350-364",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/ChiaDPSLDWG19",
            "doi": "10.1109/SP.2019.00046",
            "ee": "https://doi.org/10.1109/SP.2019.00046",
            "url": "https://dblp.org/rec/conf/sp/ChiaDPSLDWG19",
            "abstract": "Understanding the privacy relevant characteristics of data sets, such as reidentifiability and joinability, is crucial for data governance, yet can be difficult for large data sets. While computing the data characteristics by brute force is straightforward, the scale of systems and data collected by large organizations demands an efficient approach. We present KHyperLogLog (KHLL), an algorithm based on approximate counting techniques that can estimate the reidentifiability and joinability risks of very large databases using linear runtime and minimal memory. KHLL enables one to measure reidentifiability of data quantitatively, rather than based on expert judgement or manual reviews. Meanwhile, joinability analysis using KHLL helps ensure the separation of pseudonymous and identified data sets. We describe how organizations can use KHLL to improve protection of user privacy. The efficiency of KHLL allows one to schedule periodic analyses that detect any deviations from the expected risks over time as a regression test for privacy. We validate the performance and accuracy of KHLL through experiments using proprietary and publicly available data sets.",
            "keywords": [
                "Data Privacy",
                "Reidentifiability",
                "Joinability",
                "Approximate Counting",
                "KHyperLogLog (KHLL)"
            ]
        },
        "url": "URL#2761153",
        "sema_paperId": "b249879f464e851929c2cd5dfb5dfbf628c3d510"
    },
    {
        "@score": "1",
        "@id": "2761154",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "172/8756",
                        "text": "Lucian Cojocar"
                    },
                    {
                        "@pid": "121/2685",
                        "text": "Kaveh Razavi"
                    },
                    {
                        "@pid": "75/8194",
                        "text": "Cristiano Giuffrida"
                    },
                    {
                        "@pid": "91/800",
                        "text": "Herbert Bos"
                    }
                ]
            },
            "title": "Exploiting Correcting Codes: On the Effectiveness of ECC Memory Against Rowhammer Attacks.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "55-71",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/CojocarRGB19",
            "doi": "10.1109/SP.2019.00089",
            "ee": "https://doi.org/10.1109/SP.2019.00089",
            "url": "https://dblp.org/rec/conf/sp/CojocarRGB19",
            "abstract": "Given the increasing impact of Rowhammer, and the dearth of adequate other hardware defenses, many in the security community have pinned their hopes on error-correcting code (ECC) memory as one of the few practical defenses against Rowhammer attacks. Specifically, the expectation is that the ECC algorithm will correct or detect any bits they manage to flip in memory in real-world settings. However, the extent to which ECC really protects against Rowhammer is an open research question, due to two key challenges. First, the details of the ECC implementations in commodity systems are not known. Second, existing Rowhammer exploitation techniques cannot yield reliable attacks in presence of ECC memory. In this paper, we address both challenges and provide concrete evidence of the susceptibility of ECC memory to Rowhammer attacks. To address the first challenge, we describe a novel approach that combines a custom-made hardware probe, Rowhammer bit flips, and a cold boot attack to reverse engineer ECC functions on commodity AMD and Intel processors. To address the second challenge, we present ECCploit, a new Rowhammer attack based on composable, data-controlled bit flips and a novel side channel in the ECC memory controller. We show that, while ECC memory does reduce the attack surface for Rowhammer, ECCploit still allows an attacker to mount reliable Rowhammer attacks against vulnerable ECC memory on a variety of systems and configurations. In addition, we show that, despite the non-trivial constraints imposed by ECC, ECCploit can still be powerful in practice and mimic the behavior of prior Rowhammer exploits.",
            "keywords": [
                "Rowhammer Attacks",
                "ECC Memory",
                "Memory Vulnerabilities",
                "Bit Flips",
                "ECCploit"
            ]
        },
        "url": "URL#2761154",
        "sema_paperId": "c6a4361d09de8a269ea24f7b0434881b6f489e25"
    },
    {
        "@score": "1",
        "@id": "2761156",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "d/IvanDamgaard",
                        "text": "Ivan Damg\u00e5rd"
                    },
                    {
                        "@pid": "05/4011-1",
                        "text": "Daniel Escudero 0001"
                    },
                    {
                        "@pid": "126/5963",
                        "text": "Tore Kasper Frederiksen"
                    },
                    {
                        "@pid": "69/8323",
                        "text": "Marcel Keller"
                    },
                    {
                        "@pid": "00/10576",
                        "text": "Peter Scholl"
                    },
                    {
                        "@pid": "150/5131",
                        "text": "Nikolaj Volgushev"
                    }
                ]
            },
            "title": "New Primitives for Actively-Secure MPC over Rings with Applications to Private Machine Learning.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "1102-1120",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/Damgard0FKSV19",
            "doi": "10.1109/SP.2019.00078",
            "ee": "https://doi.org/10.1109/SP.2019.00078",
            "url": "https://dblp.org/rec/conf/sp/Damgard0FKSV19",
            "abstract": "At CRYPTO 2018 Cramer et al. presented SPDZ2k , a new secret-sharing based protocol for actively secure multi-party computation against a dishonest majority, that works over rings instead of fields. Their protocol uses slightly more communication than competitive schemes working over fields. However, implementation-wise, their approach allows for arithmetic to be carried out using native 32 or 64-bit CPU operations rather than modulo a large prime. The authors thus conjectured that the increased communication would be more than made up for by the increased efficiency of implementations. In this work we answer their conjecture in the affirmative. We do so by implementing their scheme, and designing and implementing new efficient protocols for equality test, comparison, and truncation over rings. We further show that these operations find application in the machine learning domain, and indeed significantly outperform their field-based competitors. In particular, we implement and benchmark oblivious algorithms for decision tree and support vector machine (SVM) evaluation.",
            "keywords": [
                "Multi-Party Computation",
                "Secret Sharing",
                "Active Security",
                "Ring Arithmetic",
                "Private Machine Learning"
            ]
        },
        "url": "URL#2761156",
        "sema_paperId": "c72d6f5baffff6f831c7ac0218be1ffd68d3b258"
    },
    {
        "@score": "1",
        "@id": "2761157",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "50/1928",
                        "text": "Sanjeev Das"
                    },
                    {
                        "@pid": "55/3764",
                        "text": "Jan Werner"
                    },
                    {
                        "@pid": "26/216",
                        "text": "Manos Antonakakis"
                    },
                    {
                        "@pid": "09/1231",
                        "text": "Michalis Polychronakis"
                    },
                    {
                        "@pid": "50/6700",
                        "text": "Fabian Monrose"
                    }
                ]
            },
            "title": "SoK: The Challenges, Pitfalls, and Perils of Using Hardware Performance Counters for Security.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "20-38",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/DasWAPM19",
            "doi": "10.1109/SP.2019.00021",
            "ee": "https://doi.org/10.1109/SP.2019.00021",
            "url": "https://dblp.org/rec/conf/sp/DasWAPM19",
            "abstract": "Hardware Performance Counters (HPCs) have been available in processors for more than a decade. These counters can be used to monitor and measure events that occur at the CPU level. Modern processors provide hundreds of hardware events that can be monitored, and with each new processor architecture more are added. Yet, there has been little in the way of systematic studies on how performance counters can best be utilized to accurately monitor events in real-world settings. Especially when it comes to the use of HPCs for security applications, measurement imprecisions or incorrect assumptions regarding the measured values can undermine the offered protection. To shed light on this issue, we embarked on a year-long effort to (i) study the best practices for obtaining accurate measurement of events using performance counters, (ii) understand the challenges and pitfalls of using HPCs in various settings, and (iii) explore ways to obtain consistent and accurate measurements across different settings and architectures. Additionally, we then empirically evaluated the way HPCs have been used throughout a wide variety of papers. Not wanting to stop there, we explored whether these widely used techniques are in fact obtaining performance counter data correctly. As part of that assessment, we (iv) extended the seminal work of Weaver and McKee from almost 10 years ago on non-determinism in HPCs, and applied our findings to 56 papers across various application domains. In that follow-up study, we found the acceptance of HPCs in security applications is in stark contrast to other application areas \u2014 especially in the last five years. Given that, we studied an additional representative set of 41 works from the security literature that rely on HPCs, to better elucidate how the intricacies we discovered can impact the soundness and correctness of their approaches and conclusions. Toward that goal, we (i) empirically evaluated how failure to accommodate for various subtleties in the use of HPCs can undermine the effectiveness of security applications, specifically in the case of exploit prevention and malware detection. Lastly, we showed how (ii) an adversary can manipulate HPCs to bypass certain security defenses.",
            "keywords": [
                "Hardware Performance Counters",
                "Security Applications",
                "Measurement Accuracy",
                "Non-Determinism",
                "Adversarial Manipulation"
            ]
        },
        "url": "URL#2761157",
        "sema_paperId": "03401ffa763cf6d365a5de83f67e87379d04a399"
    },
    {
        "@score": "1",
        "@id": "2761158",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "228/8084",
                        "text": "Emma Dauterman"
                    },
                    {
                        "@pid": "87/8037",
                        "text": "Henry Corrigan-Gibbs"
                    },
                    {
                        "@pid": "m/DMazieres",
                        "text": "David Mazi\u00e8res"
                    },
                    {
                        "@pid": "b/DanBoneh",
                        "text": "Dan Boneh"
                    },
                    {
                        "@pid": "09/5053",
                        "text": "Dominic Rizzo"
                    }
                ]
            },
            "title": "True2F: Backdoor-Resistant Authentication Tokens.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "398-416",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/DautermanCMBR19",
            "doi": "10.1109/SP.2019.00048",
            "ee": "https://doi.org/10.1109/SP.2019.00048",
            "url": "https://dblp.org/rec/conf/sp/DautermanCMBR19",
            "abstract": "We present True2F, a system for second-factor authentication that provides the benefits of conventional authentication tokens in the face of phishing and software compromise, while also providing strong protection against token faults and backdoors. To do so, we develop new lightweight two-party protocols for generating cryptographic keys and ECDSA signatures, and we implement new privacy defenses to prevent cross-origin token-fingerprinting attacks. To facilitate real-world deployment, our system is backwards-compatible with today's U2F-enabled web services and runs on commodity hardware tokens after a firmware modification. A True2F-protected authentication takes just 57ms to complete on the token, compared with 23ms for unprotected U2F.",
            "pdf_url": "",
            "keywords": [
                "Second-Factor Authentication",
                "Backdoor Resistance",
                "Cryptographic Keys",
                "Token Fingerprinting",
                "Phishing Protection"
            ]
        },
        "url": "URL#2761158"
    },
    {
        "@score": "1",
        "@id": "2761159",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "216/3907",
                        "text": "Dominic Deuber"
                    },
                    {
                        "@pid": "142/1669",
                        "text": "Bernardo Magri"
                    },
                    {
                        "@pid": "164/5298",
                        "text": "Sri Aravinda Krishnan Thyagarajan"
                    }
                ]
            },
            "title": "Redactable Blockchain in the Permissionless Setting.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "124-138",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/DeuberMT19",
            "doi": "10.1109/SP.2019.00039",
            "ee": "https://doi.org/10.1109/SP.2019.00039",
            "url": "https://dblp.org/rec/conf/sp/DeuberMT19",
            "abstract": "Bitcoin is an immutable permissionless blockchain system that has been extensively used as a public bulletin board by many different applications that heavily relies on its immutability. However, Bitcoin's immutability is not without its fair share of demerits. Interpol exposed the existence of harmful and potentially illegal documents, images and links in the Bitcoin blockchain, and since then there have been several qualitative and quantitative analysis on the types of data currently residing in the Bitcoin blockchain. Although there is a lot of attention on blockchains, surprisingly the previous solutions proposed for data redaction in the permissionless setting are far from feasible, and require additional trust assumptions. Hence, the problem of harmful data still poses a huge challenge for law enforcement agencies like Interpol (Tziakouris, IEEE S&P'18). We propose the first efficient redactable blockchain for the permissionless setting that is easily integrable into Bitcoin, and that does not rely on heavy cryptographic tools or trust assumptions. Our protocol uses a consensus-based voting and is parameterised by a policy that dictates the requirements and constraints for the redactions; if a redaction gathers enough votes the operation is performed on the chain. As an extra feature, our protocol offers public verifiability and accountability for the redacted chain. Moreover, we provide formal security definitions and proofs showing that our protocol is secure against redactions that were not agreed by consensus. Additionally, we show the viability of our approach with a proof-of-concept implementation that shows only a tiny overhead in the chain validation of our protocol when compared to an immutable one.",
            "pdf_url": "",
            "keywords": [
                "Redactable Blockchain",
                "Permissionless Blockchain",
                "Data Redaction",
                "Harmful Data",
                "Consensus-based Voting"
            ]
        },
        "url": "URL#2761159"
    },
    {
        "@score": "1",
        "@id": "2761160",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "161/1183",
                        "text": "Steven H. H. Ding"
                    },
                    {
                        "@pid": "f/BCMFung",
                        "text": "Benjamin C. M. Fung"
                    },
                    {
                        "@pid": "30/1570",
                        "text": "Philippe Charland"
                    }
                ]
            },
            "title": "Asm2Vec: Boosting Static Representation Robustness for Binary Clone Search against Code Obfuscation and Compiler Optimization.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "472-489",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/DingFC19",
            "doi": "10.1109/SP.2019.00003",
            "ee": "https://doi.org/10.1109/SP.2019.00003",
            "url": "https://dblp.org/rec/conf/sp/DingFC19",
            "abstract": "Reverse engineering is a manually intensive but necessary technique for understanding the inner workings of new malware, finding vulnerabilities in existing systems, and detecting patent infringements in released software. An assembly clone search engine facilitates the work of reverse engineers by identifying those duplicated or known parts. However, it is challenging to design a robust clone search engine, since there exist various compiler optimization options and code obfuscation techniques that make logically similar assembly functions appear to be very different. A practical clone search engine relies on a robust vector representation of assembly code. However, the existing clone search approaches, which rely on a manual feature engineering process to form a feature vector for an assembly function, fail to consider the relationships between features and identify those unique patterns that can statistically distinguish assembly functions. To address this problem, we propose to jointly learn the lexical semantic relationships and the vector representation of assembly functions based on assembly code. We have developed an assembly code representation learning model \\emph{Asm2Vec}. It only needs assembly code as input and does not require any prior knowledge such as the correct mapping between assembly functions. It can find and incorporate rich semantic relationships among tokens appearing in assembly code. We conduct extensive experiments and benchmark the learning model with state-of-the-art static and dynamic clone search approaches. We show that the learned representation is more robust and significantly outperforms existing methods against changes introduced by obfuscation and optimizations.",
            "keywords": [
                "Binary Clone Search",
                "Code Obfuscation",
                "Compiler Optimization",
                "Assembly Code Representation",
                "Asm2Vec"
            ]
        },
        "url": "URL#2761160",
        "sema_paperId": "35c667eaad1af5043896d6a6a5a4ef0f4acf861b"
    },
    {
        "@score": "1",
        "@id": "2761161",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "199/4885",
                        "text": "Craig Disselkoen"
                    },
                    {
                        "@pid": "j/RJagadeesan",
                        "text": "Radha Jagadeesan"
                    },
                    {
                        "@pid": "89/740",
                        "text": "Alan Jeffrey"
                    },
                    {
                        "@pid": "04/522",
                        "text": "James Riely"
                    }
                ]
            },
            "title": "The Code That Never Ran: Modeling Attacks on Speculative Evaluation.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "1238-1255",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/DisselkoenJJR19",
            "doi": "10.1109/SP.2019.00047",
            "ee": "https://doi.org/10.1109/SP.2019.00047",
            "url": "https://dblp.org/rec/conf/sp/DisselkoenJJR19",
            "abstract": "This paper studies information flow caused by speculation mechanisms in hardware and software. The Spectre attack shows that there are practical information flow attacks which use an interaction of dynamic security checks, speculative evaluation and cache timing. Previous formal models of program execution are designed to capture computer architecture, rather than micro-architecture, and so do not capture attacks such as Spectre. In this paper, we propose a model based on pomsets which is designed to model speculative evaluation. The model is abstract with respect to specific micro-architectural features, such as caches and pipelines, yet is powerful enough to express known attacks such as Spectre and Prime+Abort, and verify their countermeasures. The model also allows for the prediction of new information flow attacks. We derive two such attacks, which exploit compiler optimizations, and validate these experimentally against gcc and clang.",
            "keywords": [
                "Speculative Execution",
                "Information Flow Attacks",
                "Micro-architectural Security",
                "Spectre Attack",
                "Compiler Optimizations"
            ]
        },
        "url": "URL#2761161",
        "sema_paperId": "b4aa2eeb323bd2e7a86b07b99312e52a348834da"
    },
    {
        "@score": "1",
        "@id": "2761162",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "184/6169",
                        "text": "Jack Doerner"
                    },
                    {
                        "@pid": "201/6467",
                        "text": "Yashvanth Kondi"
                    },
                    {
                        "@pid": "202/3137",
                        "text": "Eysa Lee"
                    },
                    {
                        "@pid": "s/AShelat",
                        "text": "Abhi Shelat"
                    }
                ]
            },
            "title": "Threshold ECDSA from ECDSA Assumptions: The Multiparty Case.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "1051-1066",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/DoernerKLS19",
            "doi": "10.1109/SP.2019.00024",
            "ee": "https://doi.org/10.1109/SP.2019.00024",
            "url": "https://dblp.org/rec/conf/sp/DoernerKLS19",
            "abstract": "Cryptocurrency applications have spurred a resurgence of interest in the computation of ECDSA signatures using threshold protocols---that is, protocols in which the signing key is secret-shared among n parties, of which any subset of size t must interact in order to compute a signature. Among the resulting works to date, that of Doerner et al. requires the most natural assumptions while also achieving the best practical signing speed. It is, however, limited to the setting in which the threshold is two. We propose an extension of their scheme to arbitrary thresholds, and prove it secure against a malicious adversary corrupting up to one party less than the threshold under only the Computational Diffie-Hellman assumption in the Random Oracle model, an assumption strictly weaker than those under which ECDSA is proven. Whereas the best current schemes for threshold-two ECDSA signing use a Diffie-Hellman Key Exchange to calculate each signature's nonce, a direct adaptation of this technique to a larger threshold t would incur a round count linear in t; thus we abandon it in favor of a new mechanism that yields a protocol requiring log(t)+6 rounds in total. We design a new consistency check, similar in spirit to that of Doerner et al., but suitable for an arbitrary number of participants, and we optimize the underlying two-party multiplication protocol on which our scheme is based, reducing its concrete communication and computation costs. We implement our scheme and evaluate it among groups of up to 256 of co-located and 128 geographically-distributed parties, and among small groups of embedded devices. We find that in the LAN setting, our scheme outperforms all prior works by orders of magnitude, and that it is efficient enough for use even on smartphones or hardware tokens. In the WAN setting we find that, despite its logarithmic round count, our protocol outperforms the best constant-round protocols in realistic scenarios.",
            "keywords": [
                "Threshold ECDSA",
                "Cryptocurrency Security",
                "Multiparty Computation",
                "Signature Generation",
                "Computational Diffie-Hellman Assumption"
            ]
        },
        "url": "URL#2761162",
        "sema_paperId": "3fb34ad7e23b3f94d66aad241f2a59b464882b0b"
    },
    {
        "@score": "1",
        "@id": "2761163",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "129/9841",
                        "text": "Manu Drijvers"
                    },
                    {
                        "@pid": "220/2826",
                        "text": "Kasra Edalatnejad"
                    },
                    {
                        "@pid": "f/BryanFord",
                        "text": "Bryan Ford"
                    },
                    {
                        "@pid": "k/EikeKiltz",
                        "text": "Eike Kiltz"
                    },
                    {
                        "@pid": "184/3870",
                        "text": "Julian Loss"
                    },
                    {
                        "@pid": "30/3210",
                        "text": "Gregory Neven"
                    },
                    {
                        "@pid": "153/5527",
                        "text": "Igors Stepanovs"
                    }
                ]
            },
            "title": "On the Security of Two-Round Multi-Signatures.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "1084-1101",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/DrijversEFKLNS19",
            "doi": "10.1109/SP.2019.00050",
            "ee": "https://doi.org/10.1109/SP.2019.00050",
            "url": "https://dblp.org/rec/conf/sp/DrijversEFKLNS19",
            "abstract": "A multi-signature scheme allows a group of signers to collaboratively sign a message, creating a single signature that convinces a verifier that every individual signer approved the message. The increased interest in technologies to decentralize trust has triggered the proposal of highly efficient two-round Schnorr-based multi-signature schemes designed to scale up to thousands of signers, namely BCJ by Bagherzandi et al. (CCS 2008), MWLD by Ma et al. (DCC 2010), CoSi by Syta et al. (S&P 2016), and MuSig by Maxwell et al. (ePrint 2018). In this work, we point out serious security issues in all currently known two-round multi-signature schemes (without pairings). First, we prove that none of the schemes can be proved secure without radically departing from currently known techniques. Namely, we show that if the one-more discrete-logarithm problem is hard, then no algebraic reduction exists that proves any of these schemes secure under the discrete-logarithm or one-more discrete-logarithm problem. We point out subtle flaws in the published security proofs of the above schemes (except CoSi, which was not proved secure) to clarify the contradiction between our result and the existing proofs. Next, we describe practical sub-exponential attacks on all schemes, providing further evidence to their insecurity. Being left without two-round multi-signature schemes, we present mBCJ, a variant of the BCJ scheme that we prove secure under the discrete-logarithm assumption in the random-oracle model. Our experiments show that mBCJ barely affects scalability compared to CoSi, allowing 16384 signers to collaboratively sign a message in about 2 seconds, making it a highly practical and provably secure alternative for large-scale deployments.",
            "keywords": [
                "Multi-Signature Schemes",
                "Schnorr Signatures",
                "Security Proofs",
                "Discrete-Logarithm Problem",
                "Scalability"
            ]
        },
        "url": "URL#2761163",
        "sema_paperId": "f09ee666ef7aa525a7b7444da596b33dd946eaf1"
    },
    {
        "@score": "1",
        "@id": "2761164",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "86/5357",
                        "text": "Stefan Dziembowski"
                    },
                    {
                        "@pid": "203/4287",
                        "text": "Lisa Eckey"
                    },
                    {
                        "@pid": "71/4369",
                        "text": "Sebastian Faust"
                    },
                    {
                        "@pid": "138/8989",
                        "text": "Daniel Malinowski"
                    }
                ]
            },
            "title": "Perun: Virtual Payment Hubs over Cryptocurrencies.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "106-123",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/DziembowskiEFM19",
            "doi": "10.1109/SP.2019.00020",
            "ee": "https://doi.org/10.1109/SP.2019.00020",
            "url": "https://dblp.org/rec/conf/sp/DziembowskiEFM19",
            "abstract": "Payment channels emerged recently as an efficient method for performing cheap micropayments in cryptocurrencies. In contrast to traditional on-chain transactions, payment channels have the advantage that they allow for nearly unlimited number of transactions between parties without involving the blockchain. In this work, we introduce Perun, an off-chain channel system that offers a new method for connecting channels that is more efficient than the existing technique of ``routing transactions'' over multiple channels. To this end, Perun introduces a technique called ``virtual payment channels'' that avoids involvement of the intermediary for each individual payment. In this paper we formally model and prove security of this technique in the case of one intermediary, who can be viewed as a ``payment hub'' that has direct channels with several parties. Our scheme works over any cryptocurrency that provides Turing-complete smart contracts. As a proof of concept, we implemented Perun's smart contracts in Ethereum.",
            "keywords": [
                "Cryptocurrency Payment Channels",
                "Off-Chain Transactions",
                "Virtual Payment Hubs",
                "Micropayments",
                "Smart Contracts in Ethereum"
            ]
        },
        "url": "URL#2761164",
        "sema_paperId": "1359efc261974700c2b57f3f4bde869993e30f73"
    },
    {
        "@score": "1",
        "@id": "2761166",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "222/4224",
                        "text": "Andres Erbsen"
                    },
                    {
                        "@pid": "158/5810",
                        "text": "Jade Philipoom"
                    },
                    {
                        "@pid": "140/7502",
                        "text": "Jason Gross"
                    },
                    {
                        "@pid": "249/3097",
                        "text": "Robert Sloan"
                    },
                    {
                        "@pid": "52/796",
                        "text": "Adam Chlipala"
                    }
                ]
            },
            "title": "Simple High-Level Code for Cryptographic Arithmetic - With Proofs, Without Compromises.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "1202-1219",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/ErbsenPGSC19",
            "doi": "10.1109/SP.2019.00005",
            "ee": "https://doi.org/10.1109/SP.2019.00005",
            "url": "https://dblp.org/rec/conf/sp/ErbsenPGSC19",
            "abstract": "We introduce a new approach for implementing cryptographic arithmetic in short high-level code with machine-checked proofs of functional correctness. We further demonstrate that simple partial evaluation is sufficient to transform into the fastest-known C code, breaking the decades-old pattern that the only fast implementations are those whose instruction-level steps were written out by hand. These techniques were used to build an elliptic-curve library that achieves competitive performance for 80 prime fields and multiple CPU architectures, showing that implementation and proof effort scales with the number and complexity of conceptually different algorithms, not their use cases. As one outcome, we present the first verified high-performance implementation of P-256, the most widely used elliptic curve. implementations from our library were included in BoringSSL to replace existing specialized code, for inclusion in several large deployments for Chrome, Android, and CloudFlare.",
            "keywords": [
                "Cryptographic Arithmetic",
                "High-Level Code",
                "Functional Correctness",
                "Elliptic-Curve Library",
                "P-256 Implementation"
            ]
        },
        "url": "URL#2761166",
        "sema_paperId": "db5d5f7fac0a04458ce5801cd4134be78e206830"
    },
    {
        "@score": "1",
        "@id": "2761167",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "198/0935",
                        "text": "Saba Eskandarian"
                    },
                    {
                        "@pid": "227/3402",
                        "text": "Jonathan Cogan"
                    },
                    {
                        "@pid": "227/2318",
                        "text": "Sawyer Birnbaum"
                    },
                    {
                        "@pid": "227/2202",
                        "text": "Peh Chang Wei Brandon"
                    },
                    {
                        "@pid": "227/3457",
                        "text": "Dillon Franke"
                    },
                    {
                        "@pid": "190/3061",
                        "text": "Forest Fraser"
                    },
                    {
                        "@pid": "227/2082",
                        "text": "Gaspar Garcia Jr."
                    },
                    {
                        "@pid": "227/3382",
                        "text": "Eric Gong"
                    },
                    {
                        "@pid": "05/3382",
                        "text": "Hung T. Nguyen"
                    },
                    {
                        "@pid": "227/2342",
                        "text": "Taresh K. Sethi"
                    },
                    {
                        "@pid": "227/3090",
                        "text": "Vishal Subbiah"
                    },
                    {
                        "@pid": "b/MichaelBackes1",
                        "text": "Michael Backes 0001"
                    },
                    {
                        "@pid": "35/9056",
                        "text": "Giancarlo Pellegrino"
                    },
                    {
                        "@pid": "b/DanBoneh",
                        "text": "Dan Boneh"
                    }
                ]
            },
            "title": "Fidelius: Protecting User Secrets from Compromised Browsers.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "264-280",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/EskandarianCBBF19",
            "doi": "10.1109/SP.2019.00036",
            "ee": "https://doi.org/10.1109/SP.2019.00036",
            "url": "https://dblp.org/rec/conf/sp/EskandarianCBBF19",
            "abstract": "Users regularly enter sensitive data, such as passwords, credit card numbers, or tax information, into the browser window. While modern browsers provide powerful client-side privacy measures to protect this data, none of these defenses prevent a browser compromised by malware from stealing it. In this work, we present Fidelius, a new architecture that uses trusted hardware enclaves integrated into the browser to enable protection of user secrets during web browsing sessions, even if the entire underlying browser and OS are fully controlled by a malicious attacker. Fidelius solves many challenges involved in providing protection for browsers in a fully malicious environment, offering support for integrity and privacy for form data, JavaScript execution, XMLHttpRequests, and protected web storage, while minimizing the TCB. Moreover, interactions between the enclave and the browser, the keyboard, and the display all require new protocols, each with their own security considerations. Finally, Fidelius takes into account UI considerations to ensure a consistent and simple interface for both developers and users. As part of this project, we develop the first open source system that provides a trusted path from input and output peripherals to a hardware enclave with no reliance on additional hypervisor security assumptions. These components may be of independent interest and useful to future projects. We implement and evaluate Fidelius to measure its performance overhead, finding that Fidelius imposes acceptable overhead on page load and user interaction for secured pages and has no impact on pages and page components that do not use its enhanced security features.",
            "pdf_url": "",
            "keywords": [
                "Trusted Hardware Enclaves",
                "Browser Security",
                "User Data Protection",
                "Malware Resistance",
                "Privacy and Integrity"
            ]
        },
        "url": "URL#2761167"
    },
    {
        "@score": "1",
        "@id": "2761169",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "143/7334",
                        "text": "Daniel Fett"
                    },
                    {
                        "@pid": "234/9064",
                        "text": "Pedram Hosseyni"
                    },
                    {
                        "@pid": "k/RKusters",
                        "text": "Ralf K\u00fcsters"
                    }
                ]
            },
            "title": "An Extensive Formal Security Analysis of the OpenID Financial-Grade API.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "453-471",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/FettHK19",
            "doi": "10.1109/SP.2019.00067",
            "ee": "https://doi.org/10.1109/SP.2019.00067",
            "url": "https://dblp.org/rec/conf/sp/FettHK19",
            "abstract": "Forced by regulations and industry demand, banks worldwide are working to open their customers' online banking accounts to third-party services via web-based APIs. By using these so-called Open Banking APIs, third-party companies, such as FinTechs, are able to read information about and initiate payments from their users' bank accounts. Such access to financial data and resources needs to meet particularly high security requirements to protect customers. One of the most promising standards in this segment is the OpenID Financial-grade API (FAPI), currently under development in an open process by the OpenID Foundation and backed by large industry partners. The FAPI is a profile of OAuth 2.0 designed for high-risk scenarios and aiming to be secure against very strong attackers. To achieve this level of security, the FAPI employs a range of mechanisms that have been developed to harden OAuth 2.0, such as Code and Token Binding (including mTLS and OAUTB), JWS Client Assertions, and Proof Key for Code Exchange. In this paper, we perform a rigorous, systematic formal analysis of the security of the FAPI, based on an existing comprehensive model of the web infrastructure - the Web Infrastructure Model (WIM) proposed by Fett, K\u00fcsters, and Schmitz. To this end, we first develop a precise model of the FAPI in the WIM, including different profiles for read-only and read-write access, different flows, different types of clients, and different combinations of security features, capturing the complex interactions in a web-based environment. We then use our model of the FAPI to precisely define central security properties. In an attempt to prove these properties, we uncover partly severe attacks, breaking authentication, authorization, and session integrity properties. We develop mitigations against these attacks and finally are able to formally prove the security of a fixed version of the FAPI. Although financial applications are high-stakes environments, this work is the first to formally analyze and, importantly, verify an Open Banking security profile. By itself, this analysis is an important contribution to the development of the FAPI since it helps to define exact security properties and attacker models, and to avoid severe security risks before the first implementations of the standard go live. Of independent interest, we also uncover weaknesses in the aforementioned security mechanisms for hardening OAuth 2.0. We illustrate that these mechanisms do not necessarily achieve the security properties they have been designed for.",
            "pdf_url": "",
            "keywords": [
                "Open Banking APIs",
                "OpenID Financial-grade API",
                "OAuth 2.0 Security",
                "Formal Security Analysis",
                "Authentication and Authorization Attacks"
            ]
        },
        "url": "URL#2761169"
    },
    {
        "@score": "1",
        "@id": "2761170",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "06/701",
                        "text": "Peter Gazi"
                    },
                    {
                        "@pid": "47/3682",
                        "text": "Aggelos Kiayias"
                    },
                    {
                        "@pid": "197/1222",
                        "text": "Dionysis Zindros"
                    }
                ]
            },
            "title": "Proof-of-Stake Sidechains.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "139-156",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/GaziKZ19",
            "doi": "10.1109/SP.2019.00040",
            "ee": "https://doi.org/10.1109/SP.2019.00040",
            "url": "https://dblp.org/rec/conf/sp/GaziKZ19",
            "abstract": "Sidechains have long been heralded as the key enabler of blockchain scalability and interoperability. However, no modeling of the concept or a provably secure construction has so far been attempted. We provide the first formal definition of what a sidechain system is and how assets can be moved between sidechains securely. We put forth a security definition that augments the known transaction ledger properties of liveness and safety to hold across multiple ledgers and enhance them with a new \u201cfirewall\u201d security property which safeguards each blockchain from its sidechains, limiting the impact of an otherwise catastrophic sidechain failure. We then provide a sidechain construction that is suitable for proof-of-stake (PoS) sidechain systems. As an exemplary concrete instantiation we present our construction for an epoch- based PoS system consistent with Ouroboros (Crypto 2017), the PoS blockchain protocol used in Cardano which is one of the largest pure PoS systems by market capitalisation, and we also comment how the construction can be adapted for other protocols such as Ouroboros Praos (Eurocrypt 2018), Ouroboros Genesis (CCS 2018), Snow White and Algorand. An important feature of our construction is merged-staking that prevents \u201cgoldfinger\u201d attacks against a sidechain that is only carrying a small amount of stake. An important technique for pegging chains that we use in our construction is cross-chain certification which is facilitated by a novel cryptographic primitive we introduce called ad-hoc threshold multisignatures (ATMS) which may be of independent interest. We show how ATMS can be securely instantiated by regular and aggregate digital signatures as well as succinct arguments of knowledge such as STARKs and bulletproofs with varying degrees of storage efficiency.",
            "keywords": [
                "Sidechains",
                "Proof-of-Stake",
                "Blockchain Scalability",
                "Cross-Chain Certification",
                "Ad-hoc Threshold Multisignatures (ATMS)"
            ]
        },
        "url": "URL#2761170",
        "sema_paperId": "f5e9ff85c17769a8842fb3f587e80137ad879299"
    },
    {
        "@score": "1",
        "@id": "2761171",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "98/8283",
                        "text": "Daniel Genkin"
                    },
                    {
                        "@pid": "227/3478",
                        "text": "Mihir Pattani"
                    },
                    {
                        "@pid": "180/8190",
                        "text": "Roei Schuster"
                    },
                    {
                        "@pid": "t/EranTromer",
                        "text": "Eran Tromer"
                    }
                ]
            },
            "title": "Synesthesia: Detecting Screen Content via Remote Acoustic Side Channels.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "853-869",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/GenkinPST19",
            "doi": "10.1109/SP.2019.00074",
            "ee": "https://doi.org/10.1109/SP.2019.00074",
            "url": "https://dblp.org/rec/conf/sp/GenkinPST19",
            "abstract": "We show that subtle acoustic noises emanating from within computer screens can be used to detect the content displayed on the screens. This sound can be picked up by ordinary microphones built into webcams or screens, and is inadvertently transmitted to other parties, e.g., during a videoconference call or archived recordings. It can also be recorded by a smartphone or ``smart speaker'' placed on a desk next to the screen, or from as far as 10 meters away using a parabolic microphone. Empirically demonstrating various attack scenarios, we show how this channel can be used for real-time detection of on-screen text, or users' input into on-screen virtual keyboards. We also demonstrate how an attacker can analyze the audio received during video call (e.g., on Google Hangout) to infer whether the other side is browsing the web in lieu of watching the video call, and which web site is displayed on their screen.",
            "keywords": [
                "Acoustic Side Channels",
                "Screen Content Detection",
                "Remote Eavesdropping",
                "On-screen Text Recognition",
                "Virtual Keyboard Input Analysis"
            ]
        },
        "url": "URL#2761171",
        "sema_paperId": "51c03d864d0d519a4263c96d08604e0e151ea0a4"
    },
    {
        "@score": "1",
        "@id": "2761173",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "139/2372",
                        "text": "Paul Grubbs"
                    },
                    {
                        "@pid": "172/4062",
                        "text": "Marie-Sarah Lacharit\u00e9"
                    },
                    {
                        "@pid": "154/9600",
                        "text": "Brice Minaud"
                    },
                    {
                        "@pid": "39/780",
                        "text": "Kenneth G. Paterson"
                    }
                ]
            },
            "title": "Learning to Reconstruct: Statistical Learning Theory and Encrypted Database Attacks.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "1067-1083",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/GrubbsLMP19",
            "doi": "10.1109/SP.2019.00030",
            "ee": "https://doi.org/10.1109/SP.2019.00030",
            "url": "https://dblp.org/rec/conf/sp/GrubbsLMP19",
            "abstract": "We show that the problem of reconstructing encrypted databases from access pattern leakage is closely related to statistical learning theory. This new viewpoint enables us to develop broader attacks that are supported by streamlined performance analyses. First, we address the problem of \u03b5-approximate database reconstruction (\u03b5-ADR) from range query leakage, giving attacks whose query cost scales only with the relative error \u03b5, and is independent of the size of the database, or the number N of possible values of data items. This already goes significantly beyond the state-of-the-art for such attacks, as represented by Kellaris et al. (ACM CCS 2016) and Lacharit\u00e9 et al. (IEEE S&P 2018). We also study the new problem of \u03b5-approximate order reconstruction (\u03b5-AOR), where the adversary is tasked with reconstructing the order of records, except for records whose values are approximately equal. We show that as few as O(\u03b5^\u22121 log \u03b5^\u22121) uniformly random range queries suffice. Our analysis relies on an application of learning theory to PQ-trees, special data structures tuned to compactly record certain ordering constraints. We then show that when an auxiliary distribution is available, \u03b5-AOR can be enhanced to achieve \u03b5-ADR; using real data, we show that devastatingly small numbers of queries are needed to attain very accurate database reconstruction. Finally, we generalize from ranges to consider what learning theory tells us about the impact of access pattern leakage for other classes of queries, focusing on prefix and suffix queries. We illustrate this with both concrete attacks for prefix queries and with a general lower bound for all query classes. We also show a very general reduction from reconstruction with known or chosen queries to PAC learning.",
            "keywords": [
                "Encrypted Database Attacks",
                "Statistical Learning Theory",
                "Database Reconstruction",
                "Access Pattern Leakage",
                "Range Query Leakage"
            ]
        },
        "url": "URL#2761173",
        "sema_paperId": "91dcb0d3750e681602fa3a63ccfce536803c59ad"
    },
    {
        "@score": "1",
        "@id": "2761174",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "189/1684",
                        "text": "Marcella Hastings"
                    },
                    {
                        "@pid": "33/4721",
                        "text": "Brett Hemenway"
                    },
                    {
                        "@pid": "216/6426",
                        "text": "Daniel Noble"
                    },
                    {
                        "@pid": "99/3437",
                        "text": "Steve Zdancewic"
                    }
                ]
            },
            "title": "SoK: General Purpose Compilers for Secure Multi-Party Computation.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "1220-1237",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/HastingsHNZ19",
            "doi": "10.1109/SP.2019.00028",
            "ee": "https://doi.org/10.1109/SP.2019.00028",
            "url": "https://dblp.org/rec/conf/sp/HastingsHNZ19",
            "abstract": "Secure multi-party computation (MPC) allows a group of mutually distrustful parties to compute a joint function on their inputs without revealing any information beyond the result of the computation. This type of computation is extremely powerful and has wide-ranging applications in academia, industry, and government. Protocols for secure computation have existed for decades, but only recently have general-purpose compilers for executing MPC on arbitrary functions been developed. These projects rapidly improved the state of the art, and began to make MPC accessible to non-expert users. However, the field is changing so rapidly that it is difficult even for experts to keep track of the varied capabilities of modern frameworks. In this work, we survey general-purpose compilers for secure multi-party computation. These tools provide high-level abstractions to describe arbitrary functions and execute secure computation protocols. We consider eleven systems: EMP-toolkit, Obliv-C, ObliVM, TinyGarble, SCALE-MAMBA (formerly SPDZ), Wysteria, Sharemind, PICCO, ABY, Frigate and CBMC-GC. We evaluate these systems on a range of criteria, including language expressibility, capabilities of the cryptographic back-end, and accessibility to developers. We advocate for improved documentation of MPC frameworks, standardization within the community, and make recommendations for future directions in compiler development. Installing and running these systems can be challenging, and for each system, we also provide a complete virtual environment (Docker container) with all the necessary dependencies to run the compiler and our example programs.",
            "keywords": [
                "Secure Multi-Party Computation",
                "General-Purpose Compilers",
                "MPC Frameworks",
                "Cryptographic Back-End",
                "Documentation and Standardization"
            ]
        },
        "url": "URL#2761174",
        "sema_paperId": "d06e413d71e910c2c4f29a74a7fe7be8e43fb28c"
    },
    {
        "@score": "1",
        "@id": "2761176",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "212/6818",
                        "text": "Roger Iyengar"
                    },
                    {
                        "@pid": "39/5361",
                        "text": "Joseph P. Near"
                    },
                    {
                        "@pid": "s/DXSong",
                        "text": "Dawn Song"
                    },
                    {
                        "@pid": "166/1707",
                        "text": "Om Thakkar 0001"
                    },
                    {
                        "@pid": "31/8315",
                        "text": "Abhradeep Thakurta"
                    },
                    {
                        "@pid": "130/1339-1",
                        "text": "Lun Wang 0001"
                    }
                ]
            },
            "title": "Towards Practical Differentially Private Convex Optimization.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "299-316",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/IyengarNSTTW19",
            "doi": "10.1109/SP.2019.00001",
            "ee": "https://doi.org/10.1109/SP.2019.00001",
            "url": "https://dblp.org/rec/conf/sp/IyengarNSTTW19",
            "abstract": "Building useful predictive models often involves learning from sensitive data. Training models with differential privacy can guarantee the privacy of such sensitive data. For convex optimization tasks, several differentially private algorithms are known, but none has yet been deployed in practice. In this work, we make two major contributions towards practical differentially private convex optimization. First, we present Approximate Minima Perturbation, a novel algorithm that can leverage any off-the-shelf optimizer. We show that it can be employed without any hyperparameter tuning, thus making it an attractive technique for practical deployment. Second, we perform an extensive empirical evaluation of the state-of-the-art algorithms for differentially private convex optimization, on a range of publicly available benchmark datasets, and real-world datasets obtained through an industrial collaboration. We release open-source implementations of all the differentially private convex optimization algorithms considered, and benchmarks on as many as nine public datasets, four of which are high-dimensional.",
            "keywords": [
                "Differential Privacy",
                "Convex Optimization",
                "Approximate Minima Perturbation",
                "Empirical Evaluation",
                "Sensitive Data Protection"
            ]
        },
        "url": "URL#2761176",
        "sema_paperId": "24ab25338b1bb8934afd682f136e902f24aeb884"
    },
    {
        "@score": "1",
        "@id": "2761177",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "201/5448",
                        "text": "Dae R. Jeong"
                    },
                    {
                        "@pid": "78/5052",
                        "text": "Kyungtae Kim"
                    },
                    {
                        "@pid": "268/6914",
                        "text": "Basavesh Shivakumar"
                    },
                    {
                        "@pid": "45/7986",
                        "text": "Byoungyoung Lee"
                    },
                    {
                        "@pid": "45/4154",
                        "text": "Insik Shin"
                    }
                ]
            },
            "title": "Razzer: Finding Kernel Race Bugs through Fuzzing.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "754-768",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/JeongKSLS19",
            "doi": "10.1109/SP.2019.00017",
            "ee": "https://doi.org/10.1109/SP.2019.00017",
            "url": "https://dblp.org/rec/conf/sp/JeongKSLS19",
            "abstract": "A data race in a kernel is an important class of bugs, critically impacting the reliability and security of the associated system. As a result of a race, the kernel may become unresponsive. Even worse, an attacker may launch a privilege escalation attack to acquire root privileges. In this paper, we propose Razzer, a tool to find race bugs in kernels. The core of Razzer is in guiding fuzz testing towards potential data race spots in the kernel. Razzer employs two techniques to find races efficiently: a static analysis and a deterministic thread interleaving technique. Using a static analysis, Razzer identifies over-approximated potential data race spots, guiding the fuzzer to search for data races in the kernel more efficiently. Using the deterministic thread interleaving technique implemented at the hypervisor, Razzer tames the non-deterministic behavior of the kernel such that it can deterministically trigger a race. We implemented a prototype of Razzer and ran the latest Linux kernel (from v4.16-rc3 to v4.18-rc3) using Razzer. As a result, Razzer discovered 30 new races in the kernel, with 16 subsequently confirmed and accordingly patched by kernel developers after they were reported.",
            "keywords": [
                "Kernel Fuzzing",
                "Data Race Detection",
                "Static Analysis",
                "Thread Interleaving",
                "Kernel Bugs"
            ]
        },
        "url": "URL#2761177",
        "sema_paperId": "f76b67b9ea2b3d809976cf89bf085006af28ced5"
    },
    {
        "@score": "1",
        "@id": "2761178",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "241/1000",
                        "text": "Matthew Joslin"
                    },
                    {
                        "@pid": "166/5290",
                        "text": "Neng Li"
                    },
                    {
                        "@pid": "07/6713-1",
                        "text": "Shuang Hao 0001"
                    },
                    {
                        "@pid": "166/1912",
                        "text": "Minhui Xue 0001"
                    },
                    {
                        "@pid": "22/5702",
                        "text": "Haojin Zhu"
                    }
                ]
            },
            "title": "Measuring and Analyzing Search Engine Poisoning of Linguistic Collisions.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "1311-1325",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/JoslinLHXZ19",
            "doi": "10.1109/SP.2019.00025",
            "ee": "https://doi.org/10.1109/SP.2019.00025",
            "url": "https://dblp.org/rec/conf/sp/JoslinLHXZ19",
            "abstract": "Misspelled keywords have become an appealing target in search poisoning, since they are less competitive to promote than the correct queries and account for a considerable amount of search traffic. Search engines have adopted several countermeasure strategies, e.g., Google applies automated corrections on queried keywords and returns search results of the corrected versions directly. However, a sophisticated class of attack, which we term as linguistic-collision misspelling, can evade auto-correction and poison search results. Cybercriminals target special queries where the misspelled terms are existent words, even in other languages (e.g., \"idobe\", a misspelling of the English word \"adobe\", is a legitimate word in the Nigerian language). In this paper, we perform the first large-scale analysis on linguistic-collision search poisoning attacks. In particular, we check 1.77 million misspelled search terms on Google and Baidu and analyze both English and Chinese languages, which are the top two languages used by Internet users. We leverage edit distance operations and linguistic properties to generate misspelling candidates. To more efficiently identify linguistic-collision search terms, we design a deep learning model that can improve collection rate by 2.84x compared to random sampling. Our results show that the abuse is prevalent: around 1.19% of linguistic-collision search terms on Google and Baidu have results on the first page directing to malicious websites. We also find that cybercriminals mainly target categories of gambling, drugs, and adult content. Mobile-device users disproportionately search for misspelled keywords, presumably due to small screen for input. Our work highlights this new class of search engine poisoning and provides insights to help mitigate the threat.",
            "keywords": [
                "Search Engine Poisoning",
                "Linguistic Collisions",
                "Misspelled Keywords",
                "Cybercriminal Attacks",
                "Malicious Search Results"
            ]
        },
        "url": "URL#2761178",
        "sema_paperId": "d09dc109b46dec3f9fa77802355695b07232d606"
    },
    {
        "@score": "1",
        "@id": "2761180",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "231/4519",
                        "text": "Thomas Kerber"
                    },
                    {
                        "@pid": "47/3682",
                        "text": "Aggelos Kiayias"
                    },
                    {
                        "@pid": "12/2177",
                        "text": "Markulf Kohlweiss"
                    },
                    {
                        "@pid": "70/3130",
                        "text": "Vassilis Zikas"
                    }
                ]
            },
            "title": "Ouroboros Crypsinous: Privacy-Preserving Proof-of-Stake.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "157-174",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/KerberKKZ19",
            "doi": "10.1109/SP.2019.00063",
            "ee": "https://doi.org/10.1109/SP.2019.00063",
            "url": "https://dblp.org/rec/conf/sp/KerberKKZ19",
            "abstract": "We present Ouroboros Crypsinous, the first formally analyzed privacy-preserving proof-of-stake blockchain protocol. To model its security we give a thorough treatment of private ledgers in the (G)UC setting that might be of independent interest. To prove our protocol secure against adaptive attacks, we introduce a new coin evolution technique relying on SNARKs and key-private forward secure encryption. The latter primitive-and the associated construction-can be of independent interest. We stress that existing approaches to private blockchain, such as the proof-of-work-based Zerocash are analyzed only against static corruptions.",
            "pdf_url": "",
            "keywords": [
                "Privacy-Preserving Blockchain",
                "Proof-of-Stake",
                "Adaptive Attacks",
                "SNARKs",
                "Key-Private Forward Secure Encryption"
            ]
        },
        "url": "URL#2761180"
    },
    {
        "@score": "1",
        "@id": "2761181",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "122/8486",
                        "text": "Hongil Kim"
                    },
                    {
                        "@pid": "137/1560",
                        "text": "Jiho Lee"
                    },
                    {
                        "@pid": "51/6686",
                        "text": "Eunkyu Lee"
                    },
                    {
                        "@pid": "20/6892",
                        "text": "Yongdae Kim"
                    }
                ]
            },
            "title": "Touching the Untouchables: Dynamic Security Analysis of the LTE Control Plane.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "1153-1168",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/KimLLK19",
            "doi": "10.1109/SP.2019.00038",
            "ee": "https://doi.org/10.1109/SP.2019.00038",
            "url": "https://dblp.org/rec/conf/sp/KimLLK19",
            "abstract": "This paper presents our extensive investigation of the security aspects of control plane procedures based on dynamic testing of the control components in operational Long Term Evolution (LTE) networks. For dynamic testing in LTE networks, we implemented a semi-automated testing tool, named LTEFuzz, by using open-source LTE software over which the user has full control. We systematically generated test cases by defining three basic security properties by closely analyzing the standards. Based on the security property, LTEFuzz generates and sends the test cases to a target network, and classifies the problematic behavior by only monitoring the device-side logs. Accordingly, we uncovered 36 vulnerabilities, which have not been disclosed previously. These findings are categorized into five types: Improper handling of (1) unprotected initial procedure, (2) crafted plain requests, (3) messages with invalid integrity protection, (4) replayed messages, and (5) security procedure bypass. We confirmed those vulnerabilities by demonstrating proof-of-concept attacks against operational LTE networks. The impact of the attacks is to either deny LTE services to legitimate users, spoof SMS messages, or eavesdrop/manipulate user data traffic. Precise root cause analysis and potential countermeasures to address these problems are presented as well. Cellular carriers were partially involved to maintain ethical standards as well as verify our findings in commercial LTE networks.",
            "keywords": [
                "LTE Security",
                "Control Plane Vulnerabilities",
                "Dynamic Testing",
                "LTEFuzz Tool",
                "Proof-of-Concept Attacks"
            ]
        },
        "url": "URL#2761181",
        "sema_paperId": "d89bb9db1efe4970dd2688d5e56ca44bb10557b9"
    },
    {
        "@score": "1",
        "@id": "2761182",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "28/701",
                        "text": "Paul Kocher"
                    },
                    {
                        "@pid": "224/9372",
                        "text": "Jann Horn"
                    },
                    {
                        "@pid": "187/8985",
                        "text": "Anders Fogh"
                    },
                    {
                        "@pid": "98/8283",
                        "text": "Daniel Genkin"
                    },
                    {
                        "@pid": "166/1494",
                        "text": "Daniel Gruss"
                    },
                    {
                        "@pid": "32/5044-4",
                        "text": "Werner Haas 0004"
                    },
                    {
                        "@pid": "30/2998",
                        "text": "Mike Hamburg"
                    },
                    {
                        "@pid": "172/1127",
                        "text": "Moritz Lipp"
                    },
                    {
                        "@pid": "91/4831",
                        "text": "Stefan Mangard"
                    },
                    {
                        "@pid": "92/10140-2",
                        "text": "Thomas Prescher 0002"
                    },
                    {
                        "@pid": "08/1117-1",
                        "text": "Michael Schwarz 0001"
                    },
                    {
                        "@pid": "90/10901",
                        "text": "Yuval Yarom"
                    }
                ]
            },
            "title": "Spectre Attacks: Exploiting Speculative Execution.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "1-19",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/KocherHFGGHHLM019",
            "doi": "10.1109/SP.2019.00002",
            "ee": "https://doi.org/10.1109/SP.2019.00002",
            "url": "https://dblp.org/rec/conf/sp/KocherHFGGHHLM019",
            "abstract": "Modern processors use branch prediction and speculative execution to maximize performance. For example, if the destination of a branch depends on a memory value that is in the process of being read, CPUs will try to guess the destination and attempt to execute ahead. When the memory value finally arrives, the CPU either discards or commits the speculative computation. Speculative logic is unfaithful in how it executes, can access the victim's memory and registers, and can perform operations with measurable side effects. Spectre attacks involve inducing a victim to speculatively perform operations that would not occur during correct program execution and which leak the victim's confidential information via a side channel to the adversary. This paper describes practical attacks that combine methodology from side channel attacks, fault attacks, and return-oriented programming that can read arbitrary memory from the victim's process. More broadly, the paper shows that speculative execution implementations violate the security assumptions underpinning numerous software security mechanisms, including operating system process separation, containerization, just-in-time (JIT) compilation, and countermeasures to cache timing and side-channel attacks. These attacks represent a serious threat to actual systems since vulnerable speculative execution capabilities are found in microprocessors from Intel, AMD, and ARM that are used in billions of devices. While makeshift processor-specific countermeasures are possible in some cases, sound solutions will require fixes to processor designs as well as updates to instruction set architectures (ISAs) to give hardware architects and software developers a common understanding as to what computation state CPU implementations are (and are not) permitted to leak.",
            "pdf_url": "",
            "keywords": [
                "Speculative Execution",
                "Side Channel Attacks",
                "Memory Leakage",
                "Processor Vulnerabilities",
                "Spectre Attacks"
            ]
        },
        "url": "URL#2761182"
    },
    {
        "@score": "1",
        "@id": "2761184",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "89/10042",
                        "text": "Evgenios M. Kornaropoulos"
                    },
                    {
                        "@pid": "p/CharalamposPapamanthou",
                        "text": "Charalampos Papamanthou"
                    },
                    {
                        "@pid": "t/RobertoTamassia",
                        "text": "Roberto Tamassia"
                    }
                ]
            },
            "title": "Data Recovery on Encrypted Databases with k-Nearest Neighbor Query Leakage.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "1033-1050",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/KornaropoulosPT19",
            "doi": "10.1109/SP.2019.00015",
            "ee": "https://doi.org/10.1109/SP.2019.00015",
            "url": "https://dblp.org/rec/conf/sp/KornaropoulosPT19",
            "abstract": "Recent works by Kellaris et al. (CCS'16) and Lacharite et al. (SP'18) demonstrated attacks of data recovery for encrypted databases that support rich queries such as range queries. In this paper, we develop the first data recovery attacks on encrypted databases supporting one-dimensional k-nearest neighbor (k-NN) queries, which are widely used in spatial data management. Our attacks exploit a generic k-NN query leakage profile: the attacker observes the identifiers of matched records. We consider both unordered responses, where the leakage is a set, and ordered responses, where the leakage is a k-tuple ordered by distance from the query point. As a first step, we perform a theoretical feasibility study on exact reconstruction, i.e., recovery of the exact plaintext values of the encrypted database. For ordered responses, we show that exact reconstruction is feasible if the attacker has additional access to some auxiliary information that is normally not available in practice. For unordered responses, we prove that exact reconstruction is impossible due to the infinite number of valid reconstructions. As a next step, we propose practical and more realistic approximate reconstruction attacks so as to recover an approximation of the plaintext values. For ordered responses, we show that after observing enough query responses, the attacker can approximate the client's encrypted database with considerable accuracy. For unordered responses we characterize the set of valid reconstructions as a convex polytope in a k-dimensional space and present a rigorous attack that reconstructs the plaintext database with bounded approximation error. As multidimensional spatial data can be efficiently processed by mapping it to one dimension via Hilbert curves, we demonstrate our approximate reconstruction attacks on privacy-sensitive geolocation data. Our experiments on real-world datasets show that our attacks reconstruct the plaintext values with relative error ranging from 2.9% to 0.003%.",
            "pdf_url": "",
            "keywords": [
                "Encrypted Databases",
                "k-Nearest Neighbor Queries",
                "Data Recovery Attacks",
                "Approximate Reconstruction",
                "Geolocation Data"
            ]
        },
        "url": "URL#2761184"
    },
    {
        "@score": "1",
        "@id": "2761185",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "128/4803",
                        "text": "Katharina Krombholz"
                    },
                    {
                        "@pid": "185/1721",
                        "text": "Karoline Busse"
                    },
                    {
                        "@pid": "166/1105",
                        "text": "Katharina Pfeffer"
                    },
                    {
                        "@pid": "88/5808-1",
                        "text": "Matthew Smith 0001"
                    },
                    {
                        "@pid": "44/3837",
                        "text": "Emanuel von Zezschwitz"
                    }
                ]
            },
            "title": "&quot;If HTTPS Were Secure, I Wouldn&apos;t Need 2FA&quot; - End User and Administrator Mental Models of HTTPS.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "246-263",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/KrombholzBP0Z19",
            "doi": "10.1109/SP.2019.00060",
            "ee": "https://doi.org/10.1109/SP.2019.00060",
            "url": "https://dblp.org/rec/conf/sp/KrombholzBP0Z19",
            "abstract": "HTTPS is one of the most important protocols used to secure communication and is, fortunately, becoming more pervasive. However, especially the long tail of websites is still not sufficiently secured. HTTPS involves different types of users, e.g., end users who are forced to make critical security decisions when faced with warnings or administrators who are required to deal with cryptographic fundamentals and complex decisions concerning compatibility. In this work, we present the first qualitative study of both end user and administrator mental models of HTTPS. We interviewed 18 end users and 12 administrators; our findings reveal misconceptions about security benefits and threat models from both groups. We identify protocol components that interfere with secure configurations and usage behavior and reveal differences between administrator and end user mental models. Our results suggest that end user mental models are more conceptual while administrator models are more protocol-based. We also found that end users often confuse encryption with authentication, significantly underestimate the security benefits of HTTPS, and ignore and distrust security indicators while administrators often do not understand the interplay of functional protocol components. Based on the different mental models, we discuss implications and provide actionable recommendations for future designs of user interfaces and protocols.",
            "keywords": [
                "HTTPS",
                "End User Mental Models",
                "Administrator Mental Models",
                "Security Misconceptions",
                "User Interface Design"
            ]
        },
        "url": "URL#2761185",
        "sema_paperId": "1d367eca2dbdba297b02c4fbc9d80b5d5557dc7a"
    },
    {
        "@score": "1",
        "@id": "2761186",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "185/1646",
                        "text": "Yujin Kwon"
                    },
                    {
                        "@pid": "64/5383",
                        "text": "Hyoungshick Kim"
                    },
                    {
                        "@pid": "31/7062",
                        "text": "Jinwoo Shin"
                    },
                    {
                        "@pid": "20/6892",
                        "text": "Yongdae Kim"
                    }
                ]
            },
            "title": "Bitcoin vs. Bitcoin Cash: Coexistence or Downfall of Bitcoin Cash?",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "935-951",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/KwonKSK19",
            "doi": "10.1109/SP.2019.00075",
            "ee": "https://doi.org/10.1109/SP.2019.00075",
            "url": "https://dblp.org/rec/conf/sp/KwonKSK19",
            "abstract": "Bitcoin has become the most popular cryptocurrency based on a peer-to-peer network. In Aug. 2017, Bitcoin was split into the original Bitcoin (BTC) and Bitcoin Cash (BCH). Since then, miners have had a choice between BTC and BCH mining because they have compatible proof-of-work algorithms. Therefore, they can freely choose which coin to mine for higher profit, where the profitability depends on both the coin price and mining difficulty. Some miners can immediately switch the coin to mine only when mining difficulty changes because the difficulty changes are more predictable than that for the coin price, and we call this behavior fickle mining. In this paper, we study the effects of fickle mining by modeling a game between two coins. To do this, we consider both fickle miners and some factions (e.g., BITMAIN for BCH mining) that stick to mining one coin to maintain that chain. In this model, we show that fickle mining leads to a Nash equilibrium in which only a faction sticking to its coin mining remains as a loyal miner to the less valued coin (e.g., BCH), where loyal miners refer to those who conduct mining even after coin mining difficulty increases. This situation would cause severe centralization, weakening the security of the coin system. To determine which equilibrium the competing coin systems (e.g., BTC vs. BCH) are moving toward, we traced the historical changes of mining power for BTC and BCH and found that BCH often lacked loyal miners until Nov. 13, 2017, when the difficulty adjustment algorithm of BCH mining was changed. However, the change in difficulty adjustment algorithm of BCH mining led to a state close to the stable coexistence of BTC and BCH. We also demonstrate that the lack of BCH loyal miners may still be reached when a fraction of miners automatically and repeatedly switches to the most profitable coin to mine (i.e., automatic mining). According to our analysis, as of Dec. 2018, loyal miners to BCH would leave if more than about 5% of the total mining capacity for BTC and BCH has engaged in the automatic mining. In addition, we analyze the recent \u201chash war\u201d between Bitcoin ABC and SV, which confirms our theoretical analysis. Finally, we note that our results can be applied to any competing cryptocurrency systems in which the same hardware (e.g., ASICs or GPUs) can be used for mining. Therefore, our study brings new and important angles in competitive coin markets: a coin can intentionally weaken the security and decentralization level of the other rival coin when mining hardware is shared between them, allowing for automatic mining.",
            "keywords": [
                "Cryptocurrency Mining",
                "Fickle Mining",
                "Bitcoin Cash",
                "Nash Equilibrium",
                "Mining Difficulty Adjustment"
            ]
        },
        "url": "URL#2761186",
        "sema_paperId": "7bf7a722e44d1eea9a9ec1db896dc00f2ed0a38c"
    },
    {
        "@score": "1",
        "@id": "2761187",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "176/8068",
                        "text": "Andrew Kwong"
                    },
                    {
                        "@pid": "10/3878-1",
                        "text": "Wenyuan Xu 0001"
                    },
                    {
                        "@pid": "f/KevinFu",
                        "text": "Kevin Fu"
                    }
                ]
            },
            "title": "Hard Drive of Hearing: Disks that Eavesdrop with a Synthesized Microphone.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "905-919",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/KwongXF19",
            "doi": "10.1109/SP.2019.00008",
            "ee": "https://doi.org/10.1109/SP.2019.00008",
            "url": "https://dblp.org/rec/conf/sp/KwongXF19",
            "abstract": "Security conscious individuals may take considerable measures to disable sensors in order to protect their privacy. However, they often overlook the cyberphysical attack surface exposed by devices that were never designed to be sensors in the first place. Our research demonstrates that the mechanical components in magnetic hard disk drives behave as microphones with sufficient precision to extract and parse human speech. These unintentional microphones sense speech with high enough fidelity for the Shazam service to recognize a song recorded through the hard drive. This proof of concept attack sheds light on the possibility of invasion of privacy even in absence of traditional sensors. We also present defense mechanisms, such as the use of ultrasonic aliasing, that can mitigate acoustic eavesdropping by synthesized microphones in hard disk drives.",
            "keywords": [
                "Cyberphysical Security",
                "Acoustic Eavesdropping",
                "Hard Disk Drives",
                "Privacy Invasion",
                "Ultrasonic Aliasing"
            ]
        },
        "url": "URL#2761187",
        "sema_paperId": "a63376c861cf08025ea2c43e95ac82e2c0f16f26"
    },
    {
        "@score": "1",
        "@id": "2761188",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "130/0417",
                        "text": "Mathias L\u00e9cuyer"
                    },
                    {
                        "@pid": "117/6972",
                        "text": "Vaggelis Atlidakis"
                    },
                    {
                        "@pid": "g/RoxanaGeambasu",
                        "text": "Roxana Geambasu"
                    },
                    {
                        "@pid": "h/DanielHsu",
                        "text": "Daniel Hsu 0001"
                    },
                    {
                        "@pid": "74/28",
                        "text": "Suman Jana"
                    }
                ]
            },
            "title": "Certified Robustness to Adversarial Examples with Differential Privacy.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "656-672",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/LecuyerAG0J19",
            "doi": "10.1109/SP.2019.00044",
            "ee": "https://doi.org/10.1109/SP.2019.00044",
            "url": "https://dblp.org/rec/conf/sp/LecuyerAG0J19",
            "abstract": "Adversarial examples that fool machine learning models, particularly deep neural networks, have been a topic of intense research interest, with attacks and defenses being developed in a tight back-and-forth. Most past defenses are best effort and have been shown to be vulnerable to sophisticated attacks. Recently a set of certified defenses have been introduced, which provide guarantees of robustness to norm-bounded attacks. However these defenses either do not scale to large datasets or are limited in the types of models they can support. This paper presents the first certified defense that both scales to large networks and datasets (such as Google\u2019s Inception network for ImageNet) and applies broadly to arbitrary model types. Our defense, called PixelDP, is based on a novel connection between robustness against adversarial examples and differential privacy, a cryptographically-inspired privacy formalism, that provides a rigorous, generic, and flexible foundation for defense.",
            "keywords": [
                "Certified Defense",
                "Adversarial Robustness",
                "Differential Privacy",
                "Large Scale Models",
                "PixelDP"
            ]
        },
        "url": "URL#2761188",
        "sema_paperId": "3e86a51d1f2051ab8f448b66c6dcc17924d17cfa"
    },
    {
        "@score": "1",
        "@id": "2761190",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "26/5329-1",
                        "text": "Xiang Ling 0001"
                    },
                    {
                        "@pid": "07/8388",
                        "text": "Shouling Ji"
                    },
                    {
                        "@pid": "246/6127",
                        "text": "Jiaxu Zou"
                    },
                    {
                        "@pid": "39/7183-2",
                        "text": "Jiannan Wang 0002"
                    },
                    {
                        "@pid": "97/8329-1",
                        "text": "Chunming Wu 0001"
                    },
                    {
                        "@pid": "50/3402-26",
                        "text": "Bo Li 0026"
                    },
                    {
                        "@pid": "12/2633-6",
                        "text": "Ting Wang 0006"
                    }
                ]
            },
            "title": "DEEPSEC: A Uniform Platform for Security Analysis of Deep Learning Model.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "673-690",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/LingJZWWLW19",
            "doi": "10.1109/SP.2019.00023",
            "ee": "https://doi.org/10.1109/SP.2019.00023",
            "url": "https://dblp.org/rec/conf/sp/LingJZWWLW19",
            "abstract": "Deep learning (DL) models are inherently vulnerable to adversarial examples \u2013 maliciously crafted inputs to trigger target DL models to misbehave \u2013 which significantly hinders the application of DL in security-sensitive domains. Intensive research on adversarial learning has led to an arms race between adversaries and defenders. Such plethora of emerging attacks and defenses raise many questions: Which attacks are more evasive, preprocessing-proof, or transferable? Which defenses are more effective, utility-preserving, or general? Are ensembles of multiple defenses more robust than individuals? Yet, due to the lack of platforms for comprehensive evaluation on adversarial attacks and defenses, these critical questions remain largely unsolved. In this paper, we present the design, implementation, and evaluation of DEEPSEC, a uniform platform that aims to bridge this gap. In its current implementation, DEEPSEC incorporates 16 state-of-the-art attacks with 10 attack utility metrics, and 13 state-of-the-art defenses with 5 defensive utility metrics. To our best knowledge, DEEPSEC is the first platform that enables researchers and practitioners to (i) measure the vulnerability of DL models, (ii) evaluate the effectiveness of various attacks/defenses, and (iii) conduct comparative studies on attacks/defenses in a comprehensive and informative manner. Leveraging DEEPSEC, we systematically evaluate the existing adversarial attack and defense methods, and draw a set of key findings, which demonstrate DEEPSEC\u2019s rich functionality, such as (1) the trade-off between misclassification and imperceptibility is empirically confirmed; (2) most defenses that claim to be universally applicable can only defend against limited types of attacks under restricted settings; (3) it is not necessary that adversarial examples with higher perturbation magnitude are easier to be detected; (4) the ensemble of multiple defenses cannot improve the overall defense capability, but can improve the lower bound of the defense effectiveness of individuals. Extensive analysis on DEEPSEC demonstrates its capabilities and advantages as a benchmark platform which can benefit future adversarial learning research.",
            "keywords": [
                "Adversarial Learning",
                "Security Analysis",
                "Deep Learning Vulnerabilities",
                "Adversarial Attacks",
                "Defense Mechanisms"
            ]
        },
        "url": "URL#2761190",
        "sema_paperId": "fda5f4facce9d5567c090d7ac733158e0fe93dc7"
    },
    {
        "@score": "1",
        "@id": "2761191",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "249/3123-1",
                        "text": "Enze Liu 0001"
                    },
                    {
                        "@pid": "249/3147",
                        "text": "Amanda Nakanishi"
                    },
                    {
                        "@pid": "177/0313",
                        "text": "Maximilian Golla"
                    },
                    {
                        "@pid": "68/158",
                        "text": "David Cash"
                    },
                    {
                        "@pid": "66/9786",
                        "text": "Blase Ur"
                    }
                ]
            },
            "title": "Reasoning Analytically about Password-Cracking Software.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "380-397",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/LiuNGCU19",
            "doi": "10.1109/SP.2019.00070",
            "ee": "https://doi.org/10.1109/SP.2019.00070",
            "url": "https://dblp.org/rec/conf/sp/LiuNGCU19",
            "abstract": "A rich literature has presented efficient techniques for estimating password strength by modeling password-cracking algorithms. Unfortunately, these previous techniques only apply to probabilistic password models, which real attackers seldom use. In this paper, we introduce techniques to reason analytically and efficiently about transformation-based password cracking in software tools like John the Ripper and Hashcat. We define two new operations, rule inversion and guess counting, with which we analyze these tools without needing to enumerate guesses. We implement these techniques and find orders-of-magnitude reductions in the time it takes to estimate password strength. We also present four applications showing how our techniques enable increased scientific rigor in optimizing these attacks' configurations. In particular, we show how our techniques can leverage revealed password data to improve orderings of transformation rules and to identify rules and words potentially missing from an attack configuration. Our work thus introduces some of the first principled mechanisms for reasoning scientifically about the types of password-guessing attacks that occur in practice.",
            "keywords": [
                "Password Cracking",
                "Transformation Rules",
                "Guessing Attacks",
                "Password Strength Estimation",
                "Rule Inversion"
            ]
        },
        "url": "URL#2761191",
        "sema_paperId": "09fa0d6b4af56716636902a97bbd1998369b3dbe"
    },
    {
        "@score": "1",
        "@id": "2761194",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "195/5925",
                        "text": "Seita Maruyama"
                    },
                    {
                        "@pid": "195/5647",
                        "text": "Satohiro Wakabayashi"
                    },
                    {
                        "@pid": "62/6630",
                        "text": "Tatsuya Mori"
                    }
                ]
            },
            "title": "Tap &apos;n Ghost: A Compilation of Novel Attack Techniques against Smartphone Touchscreens.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "620-637",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/MaruyamaWM19",
            "doi": "10.1109/SP.2019.00037",
            "ee": "https://doi.org/10.1109/SP.2019.00037",
            "url": "https://dblp.org/rec/conf/sp/MaruyamaWM19",
            "abstract": "We present a novel attack named \"Tap 'n Ghost\", which aims to attack the touchscreens of NFC-enabled mobile devices such as smartphones. Tap 'n Ghost consists of two striking attack techniques --- \"Tag-based Adaptive Ploy (TAP)\" and \"Ghost Touch Generator.\" First, using a NFC card emulator embedded in a common object such as table, a TAP system performs tailored attacks on the victim's smartphone by employing device fingerprinting; e.g., popping up a customized dialogue box asking whether or not to connect to an attacker's Bluetooth mouse. Further, Ghost Touch Generator forces the victim to connect to the mouse even if she or he aimed to cancel the dialogue by touching the \"cancel\" button; i.e., it alters the selection of a button on a screen. After the connection is established, the attacker can remotely take control of the smartphone, with the knowledge about the layout of the screen derived from the device fingerprinting. To evaluate the reality of the attack, we perform an online survey with 300 respondents and a user study involving 16 participants. The results demonstrate that the attack is realistic. We additionally discuss the possible countermeasures against the threats posed by Tap 'n Ghost.",
            "keywords": [
                "Smartphone Security",
                "Touchscreen Attacks",
                "NFC-enabled Devices",
                "Device Fingerprinting",
                "Remote Control Vulnerabilities"
            ]
        },
        "url": "URL#2761194",
        "sema_paperId": "6d08fb1bb30c65e30c225b29f705daf974e6608d"
    },
    {
        "@score": "1",
        "@id": "2761195",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "168/2334",
                        "text": "Carlo Meijer"
                    },
                    {
                        "@pid": "10/7271",
                        "text": "Bernard van Gastel"
                    }
                ]
            },
            "title": "Self-Encrypting Deception: Weaknesses in the Encryption of Solid State Drives.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "72-87",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/MeijerG19",
            "doi": "10.1109/SP.2019.00088",
            "ee": "https://doi.org/10.1109/SP.2019.00088",
            "url": "https://dblp.org/rec/conf/sp/MeijerG19",
            "abstract": "We have analyzed the hardware full-disk encryption of several solid state drives (SSDs) by reverse engineering their firmware. These drives were produced by three manufacturers between 2014 and 2018, and are both internal models using the SATA and NVMe interfaces (in a M.2 or 2.5\" traditional form factor) and external models using the USB interface. In theory, the security guarantees offered by hardware encryption are similar to or better than software implementations. In reality, we found that many models using hardware encryption have critical security weaknesses due to specification, design, and implementation issues. For many models, these security weaknesses allow for complete recovery of the data without knowledge of any secret (such as the password). BitLocker, the encryption software built into Microsoft Windows will rely exclusively on hardware full-disk encryption if the SSD advertises support for it. Thus, for these drives, data protected by BitLocker is also compromised. We conclude that, given the state of affairs affecting roughly 60% of the market, currently one should not rely solely on hardware encryption offered by SSDs and users should take additional measures to protect their data.",
            "keywords": [
                "Solid State Drive Encryption",
                "Hardware Encryption",
                "Data Recovery",
                "Firmware Vulnerabilities",
                "BitLocker Compromise"
            ]
        },
        "url": "URL#2761195",
        "sema_paperId": "9f194c84186404f12fba36a674a5511eb833926e"
    },
    {
        "@score": "1",
        "@id": "2761196",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "20/5104",
                        "text": "Luca Melis"
                    },
                    {
                        "@pid": "186/8335",
                        "text": "Congzheng Song"
                    },
                    {
                        "@pid": "36/6225",
                        "text": "Emiliano De Cristofaro"
                    },
                    {
                        "@pid": "46/6275",
                        "text": "Vitaly Shmatikov"
                    }
                ]
            },
            "title": "Exploiting Unintended Feature Leakage in Collaborative Learning.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "691-706",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/MelisSCS19",
            "doi": "10.1109/SP.2019.00029",
            "ee": "https://doi.org/10.1109/SP.2019.00029",
            "url": "https://dblp.org/rec/conf/sp/MelisSCS19",
            "abstract": "Collaborative machine learning and related techniques such as federated learning allow multiple participants, each with his own training dataset, to build a joint model by training locally and periodically exchanging model updates. We demonstrate that these updates leak unintended information about participants' training data and develop passive and active inference attacks to exploit this leakage. First, we show that an adversarial participant can infer the presence of exact data points -- for example, specific locations -- in others' training data (i.e., membership inference). Then, we show how this adversary can infer properties that hold only for a subset of the training data and are independent of the properties that the joint model aims to capture. For example, he can infer when a specific person first appears in the photos used to train a binary gender classifier. We evaluate our attacks on a variety of tasks, datasets, and learning configurations, analyze their limitations, and discuss possible defenses.",
            "keywords": [
                "Collaborative Learning",
                "Federated Learning",
                "Feature Leakage",
                "Membership Inference",
                "Inference Attacks"
            ]
        },
        "url": "URL#2761196",
        "sema_paperId": "30e0ffeb519a4df2d4a2067e899c5fb5c5e85e70"
    },
    {
        "@score": "1",
        "@id": "2761197",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "192/2270",
                        "text": "Xianghang Mi"
                    },
                    {
                        "@pid": "09/8674",
                        "text": "Xuan Feng"
                    },
                    {
                        "@pid": "129/1113",
                        "text": "Xiaojing Liao"
                    },
                    {
                        "@pid": "89/10754",
                        "text": "Baojun Liu"
                    },
                    {
                        "@pid": "06/6268",
                        "text": "XiaoFeng Wang 0001"
                    },
                    {
                        "@pid": "54/476-1",
                        "text": "Feng Qian 0001"
                    },
                    {
                        "@pid": "62/4119-1",
                        "text": "Zhou Li 0001"
                    },
                    {
                        "@pid": "123/3274",
                        "text": "Sumayah A. Alrwais"
                    },
                    {
                        "@pid": "37/4705-1",
                        "text": "Limin Sun 0001"
                    },
                    {
                        "@pid": "91/112-24",
                        "text": "Ying Liu 0024"
                    }
                ]
            },
            "title": "Resident Evil: Understanding Residential IP Proxy as a Dark Service.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "1185-1201",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/MiFLL0QLASL19",
            "doi": "10.1109/SP.2019.00011",
            "ee": "https://doi.org/10.1109/SP.2019.00011",
            "url": "https://dblp.org/rec/conf/sp/MiFLL0QLASL19",
            "abstract": "An emerging Internet business is residential proxy (RESIP) as a service, in which a provider utilizes the hosts within residential networks (in contrast to those running in a datacenter) to relay their customers\u2019 traffic, in an attempt to avoid server- side blocking and detection. With the prominent roles the services could play in the underground business world, little has been done to understand whether they are indeed involved in Cybercrimes and how they operate, due to the challenges in identifying their RESIPs, not to mention any in-depth analysis on them. In this paper, we report the first study on RESIPs, which sheds light on the behaviors and the ecosystem of these elusive gray services. Our research employed an infiltration framework, including our clients for RESIP services and the servers they visited, to detect 6 million RESIP IPs across 230+ countries and 52K+ ISPs. The observed addresses were analyzed and the hosts behind them were further fingerprinted using a new profiling system. Our effort led to several surprising findings about the RESIP services unknown before. Surprisingly, despite the providers\u2019 claim that the proxy hosts are willingly joined, many proxies run on likely compromised hosts including IoT devices. Through cross-matching the hosts we discovered and labeled PUP (potentially unwanted programs) logs provided by a leading IT company, we uncovered various illicit operations RESIP hosts performed, including illegal promotion, Fast fluxing, phishing, malware hosting, and others. We also reverse engi- neered RESIP services\u2019 internal infrastructures, uncovered their potential rebranding and reselling behaviors. Our research takes the first step toward understanding this new Internet service, contributing to the effective control of their security risks.",
            "keywords": [
                "Residential Proxy Services",
                "Cybercrime",
                "Traffic Relay",
                "Compromised Hosts",
                "Illicit Operations"
            ]
        },
        "url": "URL#2761197",
        "sema_paperId": "08ba95f8c086c063f57f4d63357418ae95dd5d01"
    },
    {
        "@score": "1",
        "@id": "2761198",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "161/7154",
                        "text": "Sadegh Momeni Milajerdi"
                    },
                    {
                        "@pid": "88/4984",
                        "text": "Rigel Gjomemo"
                    },
                    {
                        "@pid": "37/7954",
                        "text": "Birhanu Eshete"
                    },
                    {
                        "@pid": "90/1136-1",
                        "text": "R. Sekar 0001"
                    },
                    {
                        "@pid": "90/5014",
                        "text": "V. N. Venkatakrishnan"
                    }
                ]
            },
            "title": "HOLMES: Real-Time APT Detection through Correlation of Suspicious Information Flows.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "1137-1152",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/MilajerdiGESV19",
            "doi": "10.1109/SP.2019.00026",
            "ee": "https://doi.org/10.1109/SP.2019.00026",
            "url": "https://dblp.org/rec/conf/sp/MilajerdiGESV19",
            "abstract": "In this paper, we present HOLMES, a system that implements a new approach to the detection of Advanced and Persistent Threats (APTs). HOLMES is inspired by several case studies of real-world APTs that highlight some common goals of APT actors. In a nutshell, HOLMES aims to produce a detection signal that indicates the presence of a coordinated set of activities that are part of an APT campaign. One of the main challenges addressed by our approach involves developing a suite of techniques that make the detection signal robust and reliable. At a high-level, the techniques we develop effectively leverage the correlation between suspicious information flows that arise during an attacker campaign. In addition to its detection capability, HOLMES is also able to generate a high-level graph that summarizes the attacker\u2019s actions in real-time. This graph can be used by an analyst for an effective cyber response. An evaluation of our approach against some real-world APTs indicates that HOLMES can detect APT campaigns with high precision and low false alarm rate. The compact high-level graphs produced by HOLMES effectively summarizes an ongoing attack campaign and can assist real-time cyber-response operations.",
            "keywords": [
                "APT Detection",
                "Information Flow Correlation",
                "Cyber Threat Analysis",
                "Real-Time Monitoring",
                "Attack Campaign Visualization"
            ]
        },
        "url": "URL#2761198",
        "sema_paperId": "92cf40b989d0d6aba4166d7820a304f2a27225e9"
    },
    {
        "@score": "1",
        "@id": "2761200",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "168/9038",
                        "text": "Stefan Nagy"
                    },
                    {
                        "@pid": "09/2334",
                        "text": "Matthew Hicks"
                    }
                ]
            },
            "title": "Full-Speed Fuzzing: Reducing Fuzzing Overhead through Coverage-Guided Tracing.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "787-802",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/NagyH19",
            "doi": "10.1109/SP.2019.00069",
            "ee": "https://doi.org/10.1109/SP.2019.00069",
            "url": "https://dblp.org/rec/conf/sp/NagyH19",
            "abstract": "Coverage-guided fuzzing is one of the most successful approaches for discovering software bugs and security vulnerabilities. Of its three main components: (1) test case generation, (2) code coverage tracing, and (3) crash triage, code coverage tracing is a dominant source of overhead. Coverage-guided fuzzers trace every test case's code coverage through either static or dynamic binary instrumentation, or more recently, using hardware support. Unfortunately, tracing all test cases incurs significant performance penalties--even when the overwhelming majority of test cases and their coverage information are discarded because they do not increase code coverage. To eliminate needless tracing by coverage-guided fuzzers, we introduce the notion of coverage-guided tracing. Coverage-guided tracing leverages two observations: (1) only a fraction of generated test cases increase coverage, and thus require tracing; and (2) coverage-increasing test cases become less frequent over time. Coverage-guided tracing encodes the current frontier of coverage in the target binary so that it self-reports when a test case produces new coverage--without tracing. This acts as a filter for tracing; restricting the expense of tracing to only coverage-increasing test cases. Thus, coverage-guided tracing trades increased time handling coverage-increasing test cases for decreased time handling non-coverage-increasing test cases. To show the potential of coverage-guided tracing, we create an implementation based on the static binary instrumentor Dyninst called UnTracer. We evaluate UnTracer using eight real-world binaries commonly used by the fuzzing community. Experiments show that after only an hour of fuzzing, UnTracer's average overhead is below 1%, and after 24-hours of fuzzing, UnTracer approaches 0% overhead, while tracing every test case with popular white- and black-box-binary tracers AFL-Clang, AFL-QEMU, and AFL-Dyninst incurs overheads of 36%, 612%, and 518%, respectively. We further integrate UnTracer with the state-of-the-art hybrid fuzzer QSYM and show that in 24-hours of fuzzing, QSYM-UnTracer executes 79% and 616% more test cases than QSYM-Clang and QSYM-QEMU, respectively.",
            "pdf_url": "",
            "keywords": [
                "Coverage-Guided Fuzzing",
                "Code Coverage Tracing",
                "Fuzzing Overhead",
                "Dynamic Binary Instrumentation",
                "Test Case Generation"
            ]
        },
        "url": "URL#2761200"
    },
    {
        "@score": "1",
        "@id": "2761201",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "148/4618",
                        "text": "Sashank Narain"
                    },
                    {
                        "@pid": "23/11190",
                        "text": "Aanjhan Ranganathan"
                    },
                    {
                        "@pid": "25/5432",
                        "text": "Guevara Noubir"
                    }
                ]
            },
            "title": "Security of GPS/INS Based On-road Location Tracking Systems.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "587-601",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/NarainRN19",
            "doi": "10.1109/SP.2019.00068",
            "ee": "https://doi.org/10.1109/SP.2019.00068",
            "url": "https://dblp.org/rec/conf/sp/NarainRN19",
            "abstract": "Location information is critical to a wide variety of navigation and tracking applications. GPS, today's de-facto outdoor localization system has been shown to be vulnerable to signal spoofing attacks. Inertial Navigation Systems (INS) are emerging as a popular complementary system, especially in road transportation systems as they enable improved navigation and tracking as well as offer resilience to wireless signals spoofing and jamming attacks. In this paper, we evaluate the security guarantees of INS-aided GPS tracking and navigation for road transportation systems. We consider an adversary required to travel from a source location to a destination and monitored by an INS-aided GPS system. The goal of the adversary is to travel to alternate locations without being detected. We develop and evaluate algorithms that achieve this goal, providing the adversary significant latitude. Our algorithms build a graph model for a given road network and enable us to derive potential destinations an attacker can reach without raising alarms even with the INS-aided GPS tracking and navigation system. The algorithms render the gyroscope and accelerometer sensors useless as they generate road trajectories indistinguishable from plausible paths (both in terms of turn angles and roads curvature). We also design, build and demonstrate that the magnetometer can be actively spoofed using a combination of carefully controlled coils. To experimentally demonstrate and evaluate the feasibility of the attack in real-world, we implement a first real-time integrated GPS/INS spoofer that accounts for traffic fluidity, congestion, lights, and dynamically generates corresponding spoofing signals. Furthermore, we evaluate our attack on ten different cities using driving traces and publicly available city plans. Our evaluations show that it is possible for an attacker to reach destinations that are as far as 30 km away from the actual destination without being detected. We also show that it is possible for the adversary to reach almost 60-80% of possible points within the target region in some cities. Such results are only a lower-bound, as an adversary can adjust our parameters to spend more resources (e.g., time) on the target source/destination than we did for our performance evaluations of thousands of paths. We propose countermeasures that limit an attacker's ability, without the need for any hardware modifications. Our system can be used as the foundation for countering such attacks, both detecting and recommending paths that are difficult to spoof.",
            "pdf_url": "",
            "keywords": [
                "GPS/INS Security",
                "Location Tracking",
                "Signal Spoofing",
                "Adversarial Navigation",
                "Countermeasures for Spoofing"
            ]
        },
        "url": "URL#2761201"
    },
    {
        "@score": "1",
        "@id": "2761202",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "187/8997",
                        "text": "Milad Nasr"
                    },
                    {
                        "@pid": "20/3101",
                        "text": "Reza Shokri"
                    },
                    {
                        "@pid": "22/1797",
                        "text": "Amir Houmansadr"
                    }
                ]
            },
            "title": "Comprehensive Privacy Analysis of Deep Learning: Passive and Active White-box Inference Attacks against Centralized and Federated Learning.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "739-753",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/NasrSH19",
            "doi": "10.1109/SP.2019.00065",
            "ee": "https://doi.org/10.1109/SP.2019.00065",
            "url": "https://dblp.org/rec/conf/sp/NasrSH19",
            "abstract": "Deep neural networks are susceptible to various inference attacks as they remember information about their training data. We design white-box inference attacks to perform a comprehensive privacy analysis of deep learning models. We measure the privacy leakage through parameters of fully trained models as well as the parameter updates of models during training. We design inference algorithms for both centralized and federated learning, with respect to passive and active inference attackers, and assuming different adversary prior knowledge. We evaluate our novel white-box membership inference attacks against deep learning algorithms to trace their training data records. We show that a straightforward extension of the known black-box attacks to the white-box setting (through analyzing the outputs of activation functions) is ineffective. We therefore design new algorithms tailored to the white-box setting by exploiting the privacy vulnerabilities of the stochastic gradient descent algorithm, which is the algorithm used to train deep neural networks. We investigate the reasons why deep learning models may leak information about their training data. We then show that even well-generalized models are significantly susceptible to white-box membership inference attacks, by analyzing state-of-the-art pre-trained and publicly available models for the CIFAR dataset. We also show how adversarial participants, in the federated learning setting, can successfully run active membership inference attacks against other participants, even when the global model achieves high prediction accuracies.",
            "keywords": [
                "Privacy Analysis",
                "Inference Attacks",
                "Membership Inference",
                "Centralized and Federated Learning",
                "Stochastic Gradient Descent Vulnerabilities"
            ]
        },
        "url": "URL#2761202",
        "sema_paperId": "fd9541fe4317904b9a0637b6505fb0bea0979491"
    },
    {
        "@score": "1",
        "@id": "2761203",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "192/2096",
                        "text": "Ben Nassi"
                    },
                    {
                        "@pid": "213/7615",
                        "text": "Raz Ben-Netanel"
                    },
                    {
                        "@pid": "s/AdiShamir",
                        "text": "Adi Shamir"
                    },
                    {
                        "@pid": "38/4086",
                        "text": "Yuval Elovici"
                    }
                ]
            },
            "title": "Drones&apos; Cryptanalysis - Smashing Cryptography with a Flicker.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "1397-1414",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/NassiBSE19",
            "doi": "10.1109/SP.2019.00051",
            "ee": "https://doi.org/10.1109/SP.2019.00051",
            "url": "https://dblp.org/rec/conf/sp/NassiBSE19",
            "abstract": "In an \"open skies\" era in which drones fly among us, a new question arises: how can we tell whether a passing drone is being used by its operator for a legitimate purpose (e.g., delivering pizza) or an illegitimate purpose (e.g., taking a peek at a person showering in his/her own house)? Over the years, many methods have been suggested to detect the presence of a drone in a specific location, however since populated areas are no longer off limits for drone flights, the previously suggested methods for detecting a privacy invasion attack are irrelevant. In this paper, we present a new method that can detect whether a specific POI (point of interest) is being video streamed by a drone. We show that applying a periodic physical stimulus on a target/victim being video streamed by a drone causes a watermark to be added to the encrypted video traffic that is sent from the drone to its operator and how this watermark can be detected using interception. Based on this method, we present an algorithm for detecting a privacy invasion attack. We analyze the performance of our algorithm using four commercial drones (DJI Mavic Air, Parrot Bebop 2, DJI Spark, and DJI Mavic Pro). We show how our method can be used to (1) determine whether a detected FPV (first-person view) channel is being used to video stream a POI by a drone, and (2) locate a spying drone in space; we also demonstrate how the physical stimulus can be applied covertly. In addition, we present a classification algorithm that differentiates FPV transmissions from other suspicious radio transmissions. We implement this algorithm in a new invasion attack detection system which we evaluate in two use cases (when the victim is inside his/her house and when the victim is being tracked by a drone while driving his/her car); our evaluation shows that a privacy invasion attack can be detected by our system in about 2-3 seconds.",
            "keywords": [
                "Drone Surveillance",
                "Privacy Invasion Detection",
                "Video Streaming Watermark",
                "Physical Stimulus",
                "FPV Channel Classification"
            ]
        },
        "url": "URL#2761203",
        "sema_paperId": "7317e51f29bcb6fb6e3cbb60b9ccdebc51e8f88e"
    },
    {
        "@score": "1",
        "@id": "2761204",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "45/1042-1",
                        "text": "Duc Cuong Nguyen 0001"
                    },
                    {
                        "@pid": "180/8205",
                        "text": "Erik Derr"
                    },
                    {
                        "@pid": "b/MichaelBackes1",
                        "text": "Michael Backes 0001"
                    },
                    {
                        "@pid": "31/7561",
                        "text": "Sven Bugiel"
                    }
                ]
            },
            "title": "Short Text, Large Effect: Measuring the Impact of User Reviews on Android App Security &amp; Privacy.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "555-569",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/NguyenD0B19",
            "doi": "10.1109/SP.2019.00012",
            "ee": "https://doi.org/10.1109/SP.2019.00012",
            "url": "https://dblp.org/rec/conf/sp/NguyenD0B19",
            "abstract": "Application markets streamline the end-users\u2019 task of finding and installing applications. They also form an immediate communication channel between app developers and their end-users in form of app reviews, which allow users to provide developers feedback on their apps. However, it is unclear to which extent users employ this channel to point out their security and privacy concerns about apps, about which aspects of apps users express concerns, and how developers react to such security- and privacy-related reviews. In this paper, we present the first study of the relationship between end-user reviews and security- & privacy-related changes in apps. Using natural language processing on 4.5M user reviews for the top 2,583 apps in Google Play, we identified 5,527 security and privacy relevant reviews (SPR). For each app version mentioned in the SPR, we use static code analysis to extract permission-protected features mentioned in the reviews. We successfully mapped SPRs to privacy-related changes in app updates in 60.77% of all cases. Using exploratory data analysis and regression analysis we are able to show that preceding SPR are a significant factor for predicting privacy-related app updates, indicating that user reviews in fact lead to privacy improvements of apps. Our results further show that apps that adopt runtime permissions receive a significantly higher number of SPR, showing that runtime permissions put privacy-jeopardizing actions better into users\u2019 minds. Further, we can attribute about half of all privacy-relevant app changes exclusively to third-party library code. This hints at larger problems for app developers to adhere to users\u2019 privacy expectations and markets\u2019 privacy regulations. Our results make a call for action to make app behavior more transparent to users in order to leverage their reviews in creating incentives for developers to adhere to security and privacy best practices, while our results call at the same time for better tools to support app developers in this endeavor.",
            "keywords": [
                "Android App Security",
                "User Reviews",
                "Privacy Concerns",
                "Static Code Analysis",
                "Third-Party Libraries"
            ]
        },
        "url": "URL#2761204",
        "sema_paperId": "89fcc3199ea70e16469eb5f2ea3beaecafc79a41"
    },
    {
        "@score": "1",
        "@id": "2761205",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "47/8535",
                        "text": "Zhenyu Ning"
                    },
                    {
                        "@pid": "20/11242",
                        "text": "Fengwei Zhang"
                    }
                ]
            },
            "title": "Understanding the Security of ARM Debugging Features.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "602-619",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/NingZ19",
            "doi": "10.1109/SP.2019.00061",
            "ee": "https://doi.org/10.1109/SP.2019.00061",
            "url": "https://dblp.org/rec/conf/sp/NingZ19",
            "abstract": "Processors nowadays are consistently equipped with debugging features to facilitate the program analysis. Specifically, the ARM debugging architecture involves a series of CoreSight components and debug registers to aid the system debugging, and a group of debug authentication signals are designed to restrict the usage of these components and registers. Meantime, the security of the debugging features is under-examined since it normally requires physical access to use these features in the traditional debugging model. However, ARM introduces a new debugging model that requires no physical access since ARMv7, which exacerbates our concern on the security of the debugging features. In this paper, we perform a comprehensive security analysis of the ARM debugging features, and summarize the security and vulnerability implications. To understand the impact of the implications, we also investigate a series of ARM-based platforms in different product domains (i.e., development boards, IoT devices, cloud servers, and mobile devices). We consider the analysis and investigation expose a new attacking surface that universally exists in ARM-based platforms. To verify our concern, we further craft Nailgun attack, which obtains sensitive information (e.g., AES encryption key and fingerprint image) and achieves arbitrary payload execution in a high-privilege mode from a low-privilege mode via misusing the debugging features. This attack does not rely on software bugs, and our experiments show that almost all the platforms we investigated are vulnerable to the attack. The potential mitigations are discussed from different perspectives in the ARM ecosystem.",
            "keywords": [
                "ARM Debugging Architecture",
                "CoreSight Components",
                "Debugging Security",
                "Nailgun Attack",
                "Vulnerability Analysis"
            ]
        },
        "url": "URL#2761205",
        "sema_paperId": "d7db4bb4cfaeeeaca0304c291741a85ee20cf019"
    },
    {
        "@score": "1",
        "@id": "2761206",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "72/10989",
                        "text": "Adam Oest"
                    },
                    {
                        "@pid": "183/8531",
                        "text": "Yeganeh Safaei"
                    },
                    {
                        "@pid": "28/8280",
                        "text": "Adam Doup\u00e9"
                    },
                    {
                        "@pid": "a/GailJoonAhn",
                        "text": "Gail-Joon Ahn"
                    },
                    {
                        "@pid": "91/8856",
                        "text": "Brad Wardman"
                    },
                    {
                        "@pid": "249/2935",
                        "text": "Kevin Tyers"
                    }
                ]
            },
            "title": "PhishFarm: A Scalable Framework for Measuring the Effectiveness of Evasion Techniques against Browser Phishing Blacklists.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "1344-1361",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/OestSDAWT19",
            "doi": "10.1109/SP.2019.00049",
            "ee": "https://doi.org/10.1109/SP.2019.00049",
            "url": "https://dblp.org/rec/conf/sp/OestSDAWT19",
            "abstract": "Phishing attacks have reached record volumes in recent years. Simultaneously, modern phishing websites are growing in sophistication by employing diverse cloaking techniques to avoid detection by security infrastructure. In this paper, we present PhishFarm: a scalable framework for methodically testing the resilience of anti-phishing entities and browser blacklists to attackers' evasion efforts. We use PhishFarm to deploy 2,380 live phishing sites (on new, unique, and previously-unseen .com domains) each using one of six different HTTP request filters based on real phishing kits. We reported subsets of these sites to 10 distinct anti-phishing entities and measured both the occurrence and timeliness of native blacklisting in major web browsers to gauge the effectiveness of protection ultimately extended to victim users and organizations. Our experiments revealed shortcomings in current infrastructure, which allows some phishing sites to go unnoticed by the security community while remaining accessible to victims. We found that simple cloaking techniques representative of real-world attacks\u2014 including those based on geolocation, device type, or JavaScript\u2014 were effective in reducing the likelihood of blacklisting by over 55% on average. We also discovered that blacklisting did not function as intended in popular mobile browsers (Chrome, Safari, and Firefox), which left users of these browsers particularly vulnerable to phishing attacks. Following disclosure of our findings, anti-phishing entities are now better able to detect and mitigate several cloaking techniques (including those that target mobile users), and blacklisting has also become more consistent between desktop and mobile platforms\u2014 but work remains to be done by anti-phishing entities to ensure users are adequately protected. Our PhishFarm framework is designed for continuous monitoring of the ecosystem and can be extended to test future state-of-the-art evasion techniques used by malicious websites.",
            "keywords": [
                "Phishing Detection",
                "Cloaking Techniques",
                "Anti-Phishing Infrastructure",
                "Browser Blacklists",
                "Evasion Techniques"
            ]
        },
        "url": "URL#2761206",
        "sema_paperId": "f41ae561b4bad3649a566a491ae410dea6d187c1"
    },
    {
        "@score": "1",
        "@id": "2761207",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "241/9681",
                        "text": "Bijeeta Pal"
                    },
                    {
                        "@pid": "05/9543",
                        "text": "Tal Daniel"
                    },
                    {
                        "@pid": "03/9962",
                        "text": "Rahul Chatterjee 0001"
                    },
                    {
                        "@pid": "26/3399",
                        "text": "Thomas Ristenpart"
                    }
                ]
            },
            "title": "Beyond Credential Stuffing: Password Similarity Models Using Neural Networks.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "417-434",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/PalD0R19",
            "doi": "10.1109/SP.2019.00056",
            "ee": "https://doi.org/10.1109/SP.2019.00056",
            "url": "https://dblp.org/rec/conf/sp/PalD0R19",
            "abstract": "Attackers increasingly use passwords leaked from one website to compromise associated accounts on other websites. Such targeted attacks work because users reuse, or pick similar, passwords for different websites. We recast one of the core technical challenges underlying targeted attacks as the task of modeling similarity of human-chosen passwords. We show how to learn good password similarity models using a compilation of 1.4 billion leaked email, password pairs. Using our trained models of password similarity, we exhibit the most damaging targeted attack to date. Simulations indicate that our attack compromises more than 16% of user accounts in less than a thousand guesses, should one of their other passwords be known to the attacker and despite the use of state-of-the art countermeasures. We show via a case study involving a large university authentication service that the attacks are also effective in practice. We go on to propose the first-ever defense against such targeted attacks, by way of personalized password strength meters (PPSMs). These are password strength meters that can warn users when they are picking passwords that are vulnerable to attacks, including targeted ones that take advantage of the user\u2019s previously compromised passwords. We design and build a PPSM that can be compressed to less than 3 MB, making it easy to deploy in order to accurately estimate the strength of a password against all known guessing attacks.",
            "keywords": [
                "Password Reuse",
                "Password Similarity",
                "Targeted Attacks",
                "Credential Stuffing",
                "Personalized Password Strength Meters (PPSMs)"
            ]
        },
        "url": "URL#2761207",
        "sema_paperId": "ccfd04396b1f520e34f90fdb3ba4b81044e4a061"
    },
    {
        "@score": "1",
        "@id": "2761210",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "132/3972",
                        "text": "Jonathan Protzenko"
                    },
                    {
                        "@pid": "165/5515",
                        "text": "Benjamin Beurdouche"
                    },
                    {
                        "@pid": "242/3141",
                        "text": "Denis Merigoux"
                    },
                    {
                        "@pid": "80/3503",
                        "text": "Karthikeyan Bhargavan"
                    }
                ]
            },
            "title": "Formally Verified Cryptographic Web Applications in WebAssembly.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "1256-1274",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/ProtzenkoBMB19",
            "doi": "10.1109/SP.2019.00064",
            "ee": "https://doi.org/10.1109/SP.2019.00064",
            "url": "https://dblp.org/rec/conf/sp/ProtzenkoBMB19",
            "abstract": "After suffering decades of high-profile attacks, the need for formal verification of security-critical software has never been clearer. Verification-oriented programming languages like F* are now being used to build high-assurance cryptographic libraries and implementations of standard protocols like TLS. In this paper, we seek to apply these verification techniques to modern Web applications, like WhatsApp, that embed sophisticated custom cryptographic components. The problem is that these components are often implemented in JavaScript, a language that is both hostile to cryptographic code and hard to reason about. So we instead target WebAssembly, a new instruction set that is supported by all major JavaScript runtimes. We present a new toolchain that compiles Low*, a low-level subset of the F* programming language, into WebAssembly. Unlike other WebAssembly compilers like Emscripten, our compilation pipeline is focused on compactness and auditability: we formalize the full translation rules in the paper and implement it in a few thousand lines of OCaml. Using this toolchain, we present two case studies. First, we build WHACL*, a WebAssembly version of the existing, verified HACL* cryptographic library. Then, we present LibSignal*, a brand new, verified implementation of the Signal protocol in WebAssembly, that can be readily used by messaging applications like WhatsApp, Skype, and Signal.",
            "keywords": [
                "Formal Verification",
                "WebAssembly",
                "Cryptographic Libraries",
                "Low* Programming Language",
                "Signal Protocol Implementation"
            ]
        },
        "url": "URL#2761210",
        "sema_paperId": "f39df8f217036d1fd3e5e44385291f02258a5a7f"
    },
    {
        "@score": "1",
        "@id": "2761211",
        "info": {
            "authors": {
                "author": {
                    "@pid": "141/9244",
                    "text": "Elissa M. Redmiles"
                }
            },
            "title": "&quot;Should I Worry?&quot; A Cross-Cultural Examination of Account Security Incident Response.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "920-934",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/Redmiles19",
            "doi": "10.1109/SP.2019.00059",
            "ee": "https://doi.org/10.1109/SP.2019.00059",
            "url": "https://dblp.org/rec/conf/sp/Redmiles19",
            "abstract": "Digital security technology is able to identify and prevent many threats to users accounts. However, some threats remain that, to provide reliable security, require human intervention: e.g., through users paying attention to warning messages or completing secondary authentication procedures. While prior work has broadly explored people's mental models of digital security threats, we know little about users' precise, in-the-moment response process to in-the-wild threats. In this work, we conduct a series of qualitative interviews (n=67) with users who had recently experienced suspicious login incidents on their real Facebook accounts in order to explore this process of account security incident response. We find a common process across participants from five countries - with differing online and offline cultures - allowing us to identify areas for future technical development to best support user security. We provide additional insights on the unique nature of incident-response information seeking, known attacker threat models, and lessons learned from a large, cross-cultural qualitative study of digital security.",
            "pdf_url": "",
            "keywords": [
                "Account Security",
                "Incident Response",
                "User Behavior",
                "Cross-Cultural Study",
                "Threat Awareness"
            ]
        },
        "url": "URL#2761211"
    },
    {
        "@score": "1",
        "@id": "2761212",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "141/9244",
                        "text": "Elissa M. Redmiles"
                    },
                    {
                        "@pid": "159/0234",
                        "text": "Sean Kross"
                    },
                    {
                        "@pid": "20/7983",
                        "text": "Michelle L. Mazurek"
                    }
                ]
            },
            "title": "How Well Do My Results Generalize? Comparing Security and Privacy Survey Results from MTurk, Web, and Telephone Samples.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "1326-1343",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/RedmilesKM19",
            "doi": "10.1109/SP.2019.00014",
            "ee": "https://doi.org/10.1109/SP.2019.00014",
            "url": "https://dblp.org/rec/conf/sp/RedmilesKM19",
            "abstract": "Security and privacy researchers often rely on data collected from Amazon Mechanical Turk (MTurk) to evaluate security tools, to understand users' privacy preferences and to measure online behavior. Yet, little is known about how well Turkers' survey responses and performance on security- and privacy-related tasks generalizes to a broader population. This paper takes a first step toward understanding the generalizability of security and privacy user studies by comparing users' self-reports of their security and privacy knowledge, past experiences, advice sources, and behavior across samples collected using MTurk (n=480), a census-representative web-panel (n=428), and a probabilistic telephone sample (n=3,000) statistically weighted to be accurate within 2.7% of the true prevalence in the U.S. Surprisingly, the results suggest that: (1) MTurk responses regarding security and privacy experiences, advice sources, and knowledge are more representative of the U.S. population than are responses from the census-representative panel; (2) MTurk and general population reports of security and privacy experiences, knowledge, and advice sources are quite similar for respondents who are younger than 50 or who have some college education; and (3) respondents' answers to the survey questions we ask are stable over time and robust to relevant, broadly-reported news events. Further, differences in responses cannot be ameliorated with simple demographic weighting, possibly because MTurk and panel participants have more internet experience compared to their demographic peers. Together, these findings lend tempered support for the generalizability of prior crowdsourced security and privacy user studies; provide context to more accurately interpret the results of such studies; and suggest rich directions for future work to mitigate experience- rather than demographic-related sample biases.",
            "keywords": [
                "Security and Privacy Research",
                "MTurk",
                "Survey Generalizability",
                "User Behavior",
                "Sample Biases"
            ]
        },
        "url": "URL#2761212",
        "sema_paperId": "62e86916443a40f799424458e49b3490f5a6b64b"
    },
    {
        "@score": "1",
        "@id": "2761214",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "180/7297",
                        "text": "Eyal Ronen"
                    },
                    {
                        "@pid": "28/2203",
                        "text": "Robert Gillham"
                    },
                    {
                        "@pid": "98/8283",
                        "text": "Daniel Genkin"
                    },
                    {
                        "@pid": "s/AdiShamir",
                        "text": "Adi Shamir"
                    },
                    {
                        "@pid": "47/318",
                        "text": "David Wong"
                    },
                    {
                        "@pid": "90/10901",
                        "text": "Yuval Yarom"
                    }
                ]
            },
            "title": "The 9 Lives of Bleichenbacher&apos;s CAT: New Cache ATtacks on TLS Implementations.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "435-452",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/RonenGGSWY19",
            "doi": "10.1109/SP.2019.00062",
            "ee": "https://doi.org/10.1109/SP.2019.00062",
            "url": "https://dblp.org/rec/conf/sp/RonenGGSWY19",
            "abstract": "At CRYPTO'98, Bleichenbacher published his seminal paper which described a padding oracle attack against RSA implementations that follow the PKCS #1 v1.5 standard. Over the last twenty years researchers and implementors had spent a huge amount of effort in developing and deploying numerous mitigation techniques which were supposed to plug all the possible sources of Bleichenbacher-like leakages. However, as we show in this paper, most implementations are still vulnerable to several novel types of attack based on leakage from various microarchitectural side channels: Out of nine popular implementations of TLS that we tested, we were able to break the security of seven implementations with practical proof-of-concept attacks. We demonstrate the feasibility of using those Cache-like ATacks (CATs) to perform a downgrade attack against any TLS connection to a vulnerable server, using a BEAST-like Man in the Browser attack. The main difficulty we face is how to perform the thousands of oracle queries required before the browser's imposed timeout (which is 30 seconds for almost all browsers, with the exception of Firefox which can be tricked into extending this period). Due to its use of adaptive chosen ciphertext queries, the attack seems to be inherently sequential, but we describe a new way to parallelize Bleichenbacher-like padding attacks by exploiting any available number of TLS servers that share the same public key certificate. With this improvement, we can demonstrate the feasibility of a downgrade attack which could recover all the 2048 bits of the RSA plaintext (including the premaster secret value, which suffices to establish a secure connection) from five available TLS servers in under 30 seconds. This sequential-to-parallel transformation of such attacks can be of independent interest, speeding up and facilitating other side channel attacks on RSA implementations.",
            "pdf_url": "",
            "keywords": [
                "TLS Implementations",
                "Cache Attacks",
                "Bleichenbacher Attack",
                "Microarchitectural Side Channels",
                "Downgrade Attack"
            ]
        },
        "url": "URL#2761214"
    },
    {
        "@score": "1",
        "@id": "2761215",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "77/2192",
                        "text": "David Rupprecht"
                    },
                    {
                        "@pid": "155/5132",
                        "text": "Katharina Kohls"
                    },
                    {
                        "@pid": "h/ThorstenHolz",
                        "text": "Thorsten Holz"
                    },
                    {
                        "@pid": "11/3019",
                        "text": "Christina P\u00f6pper"
                    }
                ]
            },
            "title": "Breaking LTE on Layer Two.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "1121-1136",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/RupprechtKHP19",
            "doi": "10.1109/SP.2019.00006",
            "ee": "https://doi.org/10.1109/SP.2019.00006",
            "url": "https://dblp.org/rec/conf/sp/RupprechtKHP19",
            "abstract": "Long Term Evolution (LTE) is the latest mobile communication standard and has a pivotal role in our information society: LTE combines performance goals with modern security mechanisms and serves casual use cases as well as critical infrastructure and public safety communications. Both scenarios are demanding towards a resilient and secure specification and implementation of LTE, as outages and open attack vectors potentially lead to severe risks. Previous work on LTE protocol security identified crucial attack vectors for both the physical (layer one) and network (layer three) layers. Data link layer (layer two) protocols, however, remain a blind spot in existing LTE security research. In this paper, we present a comprehensive layer two security analysis and identify three attack vectors. These attacks impair the confidentiality and/or privacy of LTE communication. More specifically, we first present a passive identity mapping attack that matches volatile radio identities to longer lasting network identities, enabling us to identify users within a cell and serving as a stepping stone for follow-up attacks. Second, we demonstrate how a passive attacker can abuse the resource allocation as a side channel to perform website fingerprinting that enables the attacker to learn the websites a user accessed. Finally, we present the A LTE R attack that exploits the fact that LTE user data is encrypted in counter mode (AES-CTR) but not integrity protected, which allows us to modify the message payload. As a proof-of-concept demonstration, we show how an active attacker can redirect DNS requests and then perform a DNS spoofing attack. As a result, the user is redirected to a malicious website. Our experimental analysis demonstrates the real-world applicability of all three attacks and emphasizes the threat of open attack vectors on LTE layer two protocols.",
            "keywords": [
                "LTE Security",
                "Layer Two Protocols",
                "Identity Mapping Attack",
                "Website Fingerprinting",
                "DNS Spoofing Attack"
            ]
        },
        "url": "URL#2761215",
        "sema_paperId": "95c271707aae799ccf34e78bca865b59c8889b1c"
    },
    {
        "@score": "1",
        "@id": "2761217",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "167/0436",
                        "text": "Nolen Scaife"
                    },
                    {
                        "@pid": "192/6415",
                        "text": "Jasmine D. Bowers"
                    },
                    {
                        "@pid": "224/2404",
                        "text": "Christian Peeters"
                    },
                    {
                        "@pid": "190/9888",
                        "text": "Grant Hernandez"
                    },
                    {
                        "@pid": "320/8568",
                        "text": "Imani N. Sherman"
                    },
                    {
                        "@pid": "14/3295",
                        "text": "Patrick Traynor"
                    },
                    {
                        "@pid": "63/2020",
                        "text": "Lisa Anthony"
                    }
                ]
            },
            "title": "Kiss from a Rogue: Evaluating Detectability of Pay-at-the-Pump Card Skimmers.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "1000-1014",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/ScaifeBPHSTA19",
            "doi": "10.1109/SP.2019.00077",
            "ee": "https://doi.org/10.1109/SP.2019.00077",
            "url": "https://dblp.org/rec/conf/sp/ScaifeBPHSTA19",
            "abstract": "Credit and debit cards enable \ufb01nancial transactions at unattended \"pay-at-the-pump\" gas station terminals across North America. Attackers discreetly open these pumps and install skimmers, which copy sensitive card data. While EMV (\u201cchip-and-PIN\u201d) has made substantial inroads in traditional retailers, such systems have virtually no deployment at pay-at-the-pump terminals due to dramatically higher costs and logistical/regulatory constraints, leaving consumers vulnerable in these contexts. In an effort to improve security, station owners have deployed security indicators such as low-cost tamper-evident seals, and technologists have developed skimmer detection apps for mobile phones. Not only do these solutions put the onus on consumers to notice and react to security concerns at the pump, but the ef\ufb01cacy of these solutions has not been measured. In this paper, we evaluate the indicators available to consumers to detect skimmers. We perform a comprehensive teardown of all known skimmer detection apps for iOS and Android devices, and then conduct a forensic analysis of real-world gas pump skimmer hardware recovered by multiple law enforcement agencies. Finally, we analyze anti-skimmer mechanisms deployed by pump owners/operators, and augment this investigation with an analysis of skimmer reports and accompanying security measures collected by the Florida Department of Agriculture and Consumer Services over four years, making this the most comprehensive long-term study of such devices. Our results show that common gas pump security indicators are not only ineffective at empowering consumers to detect tampering, but may be providing a false sense of security. Accordingly, stronger, reliable, inexpensive measures must be developed to protect consumers and merchants from fraud.",
            "keywords": [
                "Pay-at-the-Pump Security",
                "Card Skimmers",
                "Tamper Detection",
                "Consumer Protection",
                "Fraud Prevention"
            ]
        },
        "url": "URL#2761217",
        "sema_paperId": "627200d20d5e2d1ac29e90f4a14bba8465088ff7"
    },
    {
        "@score": "1",
        "@id": "2761218",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "200/3206",
                        "text": "Stephan van Schaik"
                    },
                    {
                        "@pid": "212/6785",
                        "text": "Alyssa Milburn"
                    },
                    {
                        "@pid": "238/5438",
                        "text": "Sebastian \u00d6sterlund"
                    },
                    {
                        "@pid": "224/2335",
                        "text": "Pietro Frigo"
                    },
                    {
                        "@pid": "185/1690",
                        "text": "Giorgi Maisuradze"
                    },
                    {
                        "@pid": "121/2685",
                        "text": "Kaveh Razavi"
                    },
                    {
                        "@pid": "91/800",
                        "text": "Herbert Bos"
                    },
                    {
                        "@pid": "75/8194",
                        "text": "Cristiano Giuffrida"
                    }
                ]
            },
            "title": "RIDL: Rogue In-Flight Data Load.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "88-105",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/SchaikMOFMRBG19",
            "doi": "10.1109/SP.2019.00087",
            "ee": "https://doi.org/10.1109/SP.2019.00087",
            "url": "https://dblp.org/rec/conf/sp/SchaikMOFMRBG19",
            "abstract": "We present Rogue In-flight Data Load (RIDL), a new class of speculative unprivileged and constrained attacks to leak arbitrary data across address spaces and privilege boundaries (e.g., process, kernel, SGX, and even CPU-internal operations). Our reverse engineering efforts show such vulnerabilities originate from a variety of micro-optimizations pervasive in commodity (Intel) processors, which cause the CPU to speculatively serve loads using extraneous CPU-internal in-flight data (e.g., in the line fill buffers). Contrary to other state-of-the-art speculative execution attacks, such as Spectre, Meltdown and Foreshadow, RIDL can leak this arbitrary in-flight data with no assumptions on the state of the caches or translation data structures controlled by privileged software. The implications are worrisome. First, RIDL attacks can be implemented even from linear execution with no invalid page faults, eliminating the need for exception suppression mechanisms and enabling system-wide attacks from arbitrary unprivileged code (including JavaScript in the browser). To exemplify such attacks, we build a number of practical exploits that leak sensitive information from victim processes, virtual machines, kernel, SGX and CPU-internal components. Second, and perhaps more importantly, RIDL bypasses all existing \u201cspot\u201d mitigations in software (e.g., KPTI, PTE inversion) and hardware (e.g., speculative store bypass disable) and cannot easily be mitigated even by more heavyweight defenses (e.g., L1D flushing or disabling SMT). RIDL questions the sustainability of a per-variant, spot mitigation strategy and suggests more fundamental mitigations are needed to contain ever-emerging speculative execution attacks.",
            "keywords": [
                "Speculative Execution Attacks",
                "Data Leakage",
                "Micro-optimizations",
                "Unprivileged Code Exploits",
                "RIDL Vulnerabilities"
            ]
        },
        "url": "URL#2761218",
        "sema_paperId": "d5e0f5cfb95f9da8b8a9f7a004695dc3eeef0a7e"
    },
    {
        "@score": "1",
        "@id": "2761219",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "168/9537",
                        "text": "Dongdong She"
                    },
                    {
                        "@pid": "145/6061",
                        "text": "Kexin Pei"
                    },
                    {
                        "@pid": "223/4206",
                        "text": "Dave Epstein"
                    },
                    {
                        "@pid": "71/3724",
                        "text": "Junfeng Yang"
                    },
                    {
                        "@pid": "74/1969",
                        "text": "Baishakhi Ray"
                    },
                    {
                        "@pid": "74/28",
                        "text": "Suman Jana"
                    }
                ]
            },
            "title": "NEUZZ: Efficient Fuzzing with Neural Program Smoothing.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "803-817",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/ShePEYRJ19",
            "doi": "10.1109/SP.2019.00052",
            "ee": "https://doi.org/10.1109/SP.2019.00052",
            "url": "https://dblp.org/rec/conf/sp/ShePEYRJ19",
            "abstract": "Fuzzing has become the de facto standard technique for finding software vulnerabilities. However, even state-of-the-art fuzzers are not very efficient at finding hard-to-trigger software bugs. Most popular fuzzers use evolutionary guidance to generate inputs that can trigger different bugs. Such evolutionary algorithms, while fast and simple to implement, often get stuck in fruitless sequences of random mutations. Gradient-guided optimization presents a promising alternative to evolutionary guidance. Gradient-guided techniques have been shown to significantly outperform evolutionary algorithms at solving high-dimensional structured optimization problems in domains like machine learning by efficiently utilizing gradients or higher-order derivatives of the underlying function. However, gradient-guided approaches are not directly applicable to fuzzing as real-world program behaviors contain many discontinuities, plateaus, and ridges where the gradient-based methods often get stuck. We observe that this problem can be addressed by creating a smooth surrogate function approximating the target program\u2019s discrete branching behavior. In this paper, we propose a novel program smoothing technique using surrogate neural network models that can incrementally learn smooth approximations of a complex, real-world program's branching behaviors. We further demonstrate that such neural network models can be used together with gradient-guided input generation schemes to significantly increase the efficiency of the fuzzing process. Our extensive evaluations demonstrate that NEUZZ significantly outperforms 10 state-of-the-art graybox fuzzers on 10 popular real-world programs both at finding new bugs and achieving higher edge coverage. NEUZZ found 31 previously unknown bugs (including two CVEs) that other fuzzers failed to find in 10 real-world programs and achieved 3X more edge coverage than all of the tested graybox fuzzers over 24 hour runs. Furthermore, NEUZZ also outperformed existing fuzzers on both LAVA-M and DARPA CGC bug datasets.",
            "keywords": [
                "Fuzzing",
                "Program Smoothing",
                "Neural Surrogate Models",
                "Bug Detection",
                "Gradient-guided Optimization"
            ]
        },
        "url": "URL#2761219",
        "sema_paperId": "51652bfba5204fc4476849bffa2295187267c356"
    },
    {
        "@score": "1",
        "@id": "2761223",
        "info": {
            "authors": {
                "author": {
                    "@pid": "190/7601",
                    "text": "Doli\u00e8re Francis Som\u00e9"
                }
            },
            "title": "EmPoWeb: Empowering Web Applications with Browser Extensions.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "227-245",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/Some19",
            "doi": "10.1109/SP.2019.00058",
            "ee": "https://doi.org/10.1109/SP.2019.00058",
            "url": "https://dblp.org/rec/conf/sp/Some19",
            "abstract": "Browser extensions are third party programs, tightly integrated to browsers, where they execute with elevated privileges in order to provide users with additional functionalities. Unlike web applications, extensions are not subject to the Same Origin Policy (SOP) and therefore can read and write user data on any web application. They also have access to sensitive user information including browsing history, bookmarks, credentials (cookies) and list of installed extensions. They have access to a permanent storage in which they can store data as long as they are installed in the user's browser. They can trigger the download of arbitrary files and save them on the user's device. For security reasons, browser extensions and web applications are executed in separate contexts. Nonetheless, in all major browsers, extensions and web applications can interact by exchanging messages. Through these communication channels, a web application can exploit extension privileged capabilities and thereby access and exfiltrate sensitive user information. In this work, we analyzed the communication interfaces exposed to web applications by Chrome, Firefox and Opera browser extensions. As a result, we identified many extensions that web applications can exploit to access privileged capabilities. Through extensions' APIS, web applications can bypass SOP and access user data on any other web application, access user credentials (cookies), browsing history, bookmarks, list of installed extensions, extensions storage, and download and save arbitrary files in the user's device. Our results demonstrate that the communications between browser extensions and web applications pose serious security and privacy threats to browsers, web applications and more importantly to users. We discuss countermeasures and proposals, and believe that our study and in particular the tool we used to detect and exploit these threats, can be used as part of extensions review process by browser vendors to help them identify and fix the aforementioned problems in extensions.",
            "keywords": [
                "Browser Extensions",
                "Web Application Interaction",
                "Privacy Threats",
                "Sensitive User Data Access",
                "Same Origin Policy Bypass"
            ]
        },
        "url": "URL#2761223",
        "sema_paperId": "e406579f2a410c5424557e940912c50b68632f69"
    },
    {
        "@score": "1",
        "@id": "2761224",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "210/0976",
                        "text": "Dokyung Song"
                    },
                    {
                        "@pid": "182/6599",
                        "text": "Julian Lettner"
                    },
                    {
                        "@pid": "205/2020",
                        "text": "Prabhu Rajasekaran"
                    },
                    {
                        "@pid": "37/9431",
                        "text": "Yeoul Na"
                    },
                    {
                        "@pid": "127/6103",
                        "text": "Stijn Volckaert"
                    },
                    {
                        "@pid": "12/4238",
                        "text": "Per Larsen"
                    },
                    {
                        "@pid": "f/MichaelFranz",
                        "text": "Michael Franz"
                    }
                ]
            },
            "title": "SoK: Sanitizing for Security.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "1275-1295",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/SongLRNVLF19",
            "doi": "10.1109/SP.2019.00010",
            "ee": "https://doi.org/10.1109/SP.2019.00010",
            "url": "https://dblp.org/rec/conf/sp/SongLRNVLF19",
            "abstract": "The C and C++ programming languages are notoriously insecure yet remain indispensable. Developers therefore resort to a multi-pronged approach to find security issues before adversaries. These include manual, static, and dynamic program analysis. Dynamic bug finding tools\u2014henceforth \"sanitizers\"\u2014can find bugs that elude other types of analysis because they observe the actual execution of a program, and can therefore directly observe incorrect program behavior as it happens. A vast number of sanitizers have been prototyped by academics and refined by practitioners. We provide a systematic overview of sanitizers with an emphasis on their role in finding security issues. Specifically, we taxonomize the available tools and the security vulnerabilities they cover, describe their performance and compatibility properties, and highlight various trade-offs.",
            "keywords": [
                "C/C++ Security",
                "Dynamic Bug Finding",
                "Sanitizers",
                "Security Vulnerabilities",
                "Program Analysis"
            ]
        },
        "url": "URL#2761224",
        "sema_paperId": "be60cd79a3b9d48ba1de71d4fc5df3edfc68a646"
    },
    {
        "@score": "1",
        "@id": "2761226",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "56/7708",
                        "text": "Emily Stark 0001"
                    },
                    {
                        "@pid": "207/6600",
                        "text": "Ryan Sleevi"
                    },
                    {
                        "@pid": "249/2973",
                        "text": "Rijad Muminovic"
                    },
                    {
                        "@pid": "249/3090",
                        "text": "Devon O&apos;Brien"
                    },
                    {
                        "@pid": "34/3319",
                        "text": "Eran Messeri"
                    },
                    {
                        "@pid": "52/8024",
                        "text": "Adrienne Porter Felt"
                    },
                    {
                        "@pid": "198/4613",
                        "text": "Brendan McMillion"
                    },
                    {
                        "@pid": "93/5018",
                        "text": "Parisa Tabriz"
                    }
                ]
            },
            "title": "Does Certificate Transparency Break the Web? Measuring Adoption and Error Rate.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "211-226",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/StarkSMOMFMT19",
            "doi": "10.1109/SP.2019.00027",
            "ee": "https://doi.org/10.1109/SP.2019.00027",
            "url": "https://dblp.org/rec/conf/sp/StarkSMOMFMT19",
            "abstract": "Certificate Transparency (CT) is an emerging system for enabling the rapid discovery of malicious or misissued certificates. Initially standardized in 2013, CT is now finally beginning to see widespread support. Although CT provides desirable security benefits, web browsers cannot begin requiring all websites to support CT at once, due to the risk of breaking large numbers of websites. We discuss challenges for deployment, analyze the adoption of CT on the web, and measure the error rates experienced by users of the Google Chrome web browser. We find that CT has so far been widely adopted with minimal breakage and warnings. Security researchers often struggle with the tradeoff between security and user frustration: rolling out new security requirements often causes breakage. We view CT as a case study for deploying ecosystem-wide change while trying to minimize end user impact. We discuss the design properties of CT that made its success possible, as well as draw lessons from its risks and pitfalls that could be avoided in future large-scale security deployments.",
            "keywords": [
                "Certificate Transparency",
                "Web Security",
                "Adoption Measurement",
                "Error Rate Analysis",
                "User Impact"
            ]
        },
        "url": "URL#2761226",
        "sema_paperId": "c328399bf4ca64d59e1fc56f13c55908658a7597"
    },
    {
        "@score": "1",
        "@id": "2761231",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "159/0537",
                        "text": "Dave Jing Tian"
                    },
                    {
                        "@pid": "190/9888",
                        "text": "Grant Hernandez"
                    },
                    {
                        "@pid": "202/2912",
                        "text": "Joseph I. Choi"
                    },
                    {
                        "@pid": "224/9362",
                        "text": "Vanessa Frost"
                    },
                    {
                        "@pid": "36/4590-1",
                        "text": "Peter C. Johnson 0001"
                    },
                    {
                        "@pid": "82/1935",
                        "text": "Kevin R. B. Butler"
                    }
                ]
            },
            "title": "LBM: A Security Framework for Peripherals within the Linux Kernel.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "967-984",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/TianHCFJB19",
            "doi": "10.1109/SP.2019.00041",
            "ee": "https://doi.org/10.1109/SP.2019.00041",
            "url": "https://dblp.org/rec/conf/sp/TianHCFJB19",
            "abstract": "Modern computer peripherals are diverse in their capabilities and functionality, ranging from keyboards and printers to smartphones and external GPUs. In recent years, peripherals increasingly connect over a small number of standardized communication protocols, including USB, Bluetooth, and NFC. The host operating system is responsible for managing these devices; however, malicious peripherals can request additional functionality from the OS resulting in system compromise, or can craft data packets to exploit vulnerabilities within OS software stacks. Defenses against malicious peripherals to date only partially cover the peripheral attack surface and are limited to specific protocols (e.g., USB). In this paper, we propose Linux (e)BPF Modules (LBM), a general security framework that provides a unified API for enforcing protection against malicious peripherals within the Linux kernel. LBM leverages the eBPF packet filtering mechanism for performance and extensibility and we provide a high-level language to facilitate the development of powerful filtering functionality. We demonstrate how LBM can provide host protection against malicious USB, Bluetooth, and NFC devices; we also instantiate and unify existing defenses under the LBM framework. Our evaluation shows that the overhead introduced by LBM is within 1 \u03bcs per packet in most cases, application and system overhead is negligible, and LBM outperforms other state-of-the-art solutions. To our knowledge, LBM is the first security framework designed to provide comprehensive protection against malicious peripherals within the Linux kernel.",
            "keywords": [
                "Linux Kernel Security",
                "Malicious Peripherals",
                "eBPF",
                "USB Bluetooth NFC Protection",
                "Security Framework"
            ]
        },
        "url": "URL#2761231",
        "sema_paperId": "36d4ae91073601faeee0186eaffd8d931fc03ffb"
    },
    {
        "@score": "1",
        "@id": "2761232",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "216/6267",
                        "text": "Muoi Tran"
                    },
                    {
                        "@pid": "75/8333",
                        "text": "Min Suk Kang"
                    },
                    {
                        "@pid": "59/7124",
                        "text": "Hsu-Chun Hsiao"
                    },
                    {
                        "@pid": "249/3048",
                        "text": "Wei-Hsuan Chiang"
                    },
                    {
                        "@pid": "249/3057",
                        "text": "Shu-Po Tung"
                    },
                    {
                        "@pid": "28/5745",
                        "text": "Yu-Su Wang"
                    }
                ]
            },
            "title": "On the Feasibility of Rerouting-Based DDoS Defenses.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "1169-1184",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/TranKHCTW19",
            "doi": "10.1109/SP.2019.00055",
            "ee": "https://doi.org/10.1109/SP.2019.00055",
            "url": "https://dblp.org/rec/conf/sp/TranKHCTW19",
            "abstract": "Large botnet-based flooding attacks have recently demonstrated unprecedented damage. However, the best-known end-to-end availability guarantees against flooding attacks require costly global-scale coordination among autonomous systems (ASes). A recent proposal called routing around congestion (or RAC) attempts to offer strong end-to-end availability to a selected critical flow by dynamically rerouting it to an uncongested detour path without requiring any inter-AS coordination. This paper presents an in-depth analysis of the (in)feasibility of the RAC defense and points out that its rerouting approach, though intriguing, cannot possibly solve the challenging flooding problem. An effective RAC solution should find an inter-domain detour path for its critical flow with the two following desired properties: (1) it guarantees the establishment of an arbitrary detour path of its choice, and (2) it isolates the established detour path from non-critical flows so that the path is used exclusively for its critical flow. However, we show a fundamental trade-off between the two desired properties, and as a result, only one of them can be achieved but not both. Worse yet, we show that failing to achieve either of the two properties makes the RAC defense not just ineffective but nearly unusable. When the newly established detour path is not isolated, a new adaptive adversary can detect it in real time and immediately congest the path, defeating the goals of the RAC defense. Conversely, when the establishment of an arbitrary detour path is not guaranteed, more than 80% of critical flows we test have only a small number (e.g., three or less) of detour paths that can actually be established and disjoint from each other, which significantly restricts the available options for the reliable RAC operation. The first lesson of this study is that BGP-based rerouting solutions in the current inter-domain infrastructure seem to be impractical due to implicit assumptions (e.g., the invisibility of poisoning messages) that are unattainable in BGP's current practice. Second, we learn that the analysis of protocol specifications alone is insufficient for the feasibility study of any new defense proposal and, thus, additional rigorous security analysis and various network evaluations, including real-world testing, are required. Finally, our findings in this paper agree well with the conclusion of the major literature about end-to-end guarantees; that is, strong end-to-end availability should be a security feature of the Internet routing by design, not an ad hoc feature obtained via exploiting current routing protocols.",
            "keywords": [
                "DDoS Defense",
                "Rerouting",
                "Congestion Management",
                "Inter-Domain Routing",
                "Flooding Attacks"
            ]
        },
        "url": "URL#2761232",
        "sema_paperId": "1b5f56796a5c12bf6f02fdbaf90a5c1179d70641"
    },
    {
        "@score": "1",
        "@id": "2761235",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "195/6219",
                        "text": "Pepe Vila"
                    },
                    {
                        "@pid": "10/3908",
                        "text": "Boris K\u00f6pf"
                    },
                    {
                        "@pid": "03/305",
                        "text": "Jos\u00e9 F. Morales 0001"
                    }
                ]
            },
            "title": "Theory and Practice of Finding Eviction Sets.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "39-54",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/VilaKM19",
            "doi": "10.1109/SP.2019.00042",
            "ee": "https://doi.org/10.1109/SP.2019.00042",
            "url": "https://dblp.org/rec/conf/sp/VilaKM19",
            "abstract": "Many micro-architectural attacks rely on the capability of an attacker to efficiently find small eviction sets: groups of virtual addresses that map to the same cache set. This capability has become a decisive primitive for cache side-channel, rowhammer, and speculative execution attacks. Despite their importance, algorithms for finding small eviction sets have not been systematically studied in the literature. In this paper, we perform such a systematic study. We begin by formalizing the problem and analyzing the probability that a set of random virtual addresses is an eviction set. We then present novel algorithms, based on ideas from threshold group testing, that reduce random eviction sets to their minimal core in linear time, improving over the quadratic state-of-the-art. We complement the theoretical analysis of our algorithms with a rigorous empirical evaluation in which we identify and isolate factors that affect their reliability in practice, such as adaptive cache replacement strategies and TLB thrashing. Our results indicate that our algorithms enable finding small eviction sets much faster than before, and under conditions where this was previously deemed impractical.",
            "keywords": [
                "Micro-architectural Attacks",
                "Cache Side-channel",
                "Eviction Sets",
                "Threshold Group Testing",
                "Cache Replacement Strategies"
            ]
        },
        "url": "URL#2761235",
        "sema_paperId": "b601d7994f417e08520d606f589d9aad00ea99c1"
    },
    {
        "@score": "1",
        "@id": "2761237",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "56/4499-23",
                        "text": "Liang Wang 0023"
                    },
                    {
                        "@pid": "25/7423",
                        "text": "Gilad Asharov"
                    },
                    {
                        "@pid": "p/RPass",
                        "text": "Rafael Pass"
                    },
                    {
                        "@pid": "26/3399",
                        "text": "Thomas Ristenpart"
                    },
                    {
                        "@pid": "s/AShelat",
                        "text": "Abhi Shelat"
                    }
                ]
            },
            "title": "Blind Certificate Authorities.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "1015-1032",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/WangAPRS19",
            "doi": "10.1109/SP.2019.00007",
            "ee": "https://doi.org/10.1109/SP.2019.00007",
            "url": "https://dblp.org/rec/conf/sp/WangAPRS19",
            "abstract": "We explore how to build a blind certificate authority (CA). Unlike conventional CAs, which learn the exact identity of those registering a public key, a blind CA can simultaneously validate an identity and provide a certificate binding a public key to it, without ever learning the identity. Blind CAs would therefore allow bootstrapping truly anonymous systems in which no party ever learns who participates. In this work we focus on constructing blind CAs that can bind an email address to a public key. To do so, we first introduce secure channel injection (SCI) protocols. These allow one party (in our setting, the blind CA) to insert a private message into another party's encrypted communications. We construct an efficient SCI protocol for communications delivered over TLS, and use it to realize anonymous proofs of account ownership for SMTP servers. Combined with a zero-knowledge certificate signing protocol, we build the first blind CA that allows Alice to obtain a X.509 certificate binding her email address alice@domain.com to a public key of her choosing without ever revealing ``alice'' to the CA. We show experimentally that our system works with standard email server implementations as well as Gmail.",
            "keywords": [
                "Blind Certificate Authority",
                "Anonymous Systems",
                "Email Address Binding",
                "Secure Channel Injection",
                "Zero-Knowledge Proofs"
            ]
        },
        "url": "URL#2761237",
        "sema_paperId": "27ec11f24ab763078fa27ac68adbd927d5f141d0"
    },
    {
        "@score": "1",
        "@id": "2761238",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "147/5236",
                        "text": "Bolun Wang"
                    },
                    {
                        "@pid": "186/1486",
                        "text": "Yuanshun Yao"
                    },
                    {
                        "@pid": "217/9308",
                        "text": "Shawn Shan"
                    },
                    {
                        "@pid": "23/4315",
                        "text": "Huiying Li"
                    },
                    {
                        "@pid": "24/604",
                        "text": "Bimal Viswanath"
                    },
                    {
                        "@pid": "43/4261",
                        "text": "Haitao Zheng 0001"
                    },
                    {
                        "@pid": "z/BenYZhao",
                        "text": "Ben Y. Zhao"
                    }
                ]
            },
            "title": "Neural Cleanse: Identifying and Mitigating Backdoor Attacks in Neural Networks.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "707-723",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/WangYSLVZZ19",
            "doi": "10.1109/SP.2019.00031",
            "ee": "https://doi.org/10.1109/SP.2019.00031",
            "url": "https://dblp.org/rec/conf/sp/WangYSLVZZ19",
            "abstract": "Lack of transparency in deep neural networks (DNNs) make them susceptible to backdoor attacks, where hidden associations or triggers override normal classification to produce unexpected results. For example, a model with a backdoor always identifies a face as Bill Gates if a specific symbol is present in the input. Backdoors can stay hidden indefinitely until activated by an input, and present a serious security risk to many security or safety related applications, e.g. biometric authentication systems or self-driving cars. We present the first robust and generalizable detection and mitigation system for DNN backdoor attacks. Our techniques identify backdoors and reconstruct possible triggers. We identify multiple mitigation techniques via input filters, neuron pruning and unlearning. We demonstrate their efficacy via extensive experiments on a variety of DNNs, against two types of backdoor injection methods identified by prior work. Our techniques also prove robust against a number of variants of the backdoor attack.",
            "keywords": [
                "Backdoor Attacks",
                "Neural Network Security",
                "Trigger Identification",
                "Mitigation Techniques",
                "Input Filters"
            ]
        },
        "url": "URL#2761238",
        "sema_paperId": "42658c812d60d26a0bdad91b4d81e8620b994bf6"
    },
    {
        "@score": "1",
        "@id": "2761241",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "75/4287-1",
                        "text": "Meng Xu 0001"
                    },
                    {
                        "@pid": "178/4673",
                        "text": "Manuel Huber 0001"
                    },
                    {
                        "@pid": "184/5980",
                        "text": "Zhichuang Sun"
                    },
                    {
                        "@pid": "51/3259",
                        "text": "Paul England"
                    },
                    {
                        "@pid": "56/6925",
                        "text": "Marcus Peinado"
                    },
                    {
                        "@pid": "17/5702-1",
                        "text": "Sangho Lee 0001"
                    },
                    {
                        "@pid": "130/0711",
                        "text": "Andrey Marochko"
                    },
                    {
                        "@pid": "185/1651",
                        "text": "Dennis Mattoon"
                    },
                    {
                        "@pid": "185/1691",
                        "text": "Rob Spiger"
                    },
                    {
                        "@pid": "185/1599",
                        "text": "Stefan Thom"
                    }
                ]
            },
            "title": "Dominance as a New Trusted Computing Primitive for the Internet of Things.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "1415-1430",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/XuHSEP0MMST19",
            "doi": "10.1109/SP.2019.00084",
            "ee": "https://doi.org/10.1109/SP.2019.00084",
            "url": "https://dblp.org/rec/conf/sp/XuHSEP0MMST19",
            "abstract": "The Internet of Things (IoT) is rapidly emerging as one of the dominant computing paradigms of this decade. Applications range from in-home entertainment to large-scale industrial deployments such as controlling assembly lines and monitoring traffic. While IoT devices are in many respects similar to traditional computers, user expectations and deployment scenarios as well as cost and hardware constraints are sufficiently different to create new security challenges as well as new opportunities. This is especially true for large-scale IoT deployments in which a central entity deploys and controls a large number of IoT devices with minimal human interaction. Like traditional computers, IoT devices are subject to attack and compromise. Large IoT deployments consisting of many nearly identical devices are especially attractive targets. At the same time, recovery from root compromise by conventional means becomes costly and slow, even more so if the devices are dispersed over a large geographical area. In the worst case, technicians have to travel to all devices and manually recover them. Data center solutions such as the Intelligent Platform Management Interface (IPMI) which rely on separate service processors and network connections are not only not supported by existing IoT hardware, but are unlikely to be in the foreseeable future due to the cost constraints of mainstream IoT devices. This paper presents Cider, a system that can recover IoT devices within a short amount of time, even if attackers have taken root control of every device in a large deployment. The recovery requires minimal manual intervention. After the administrator has identified the compromise and produced an updated firmware image, he/she can instruct Cider to force the devices to reset and to install the patched firmware on the devices. We demonstrate the universality and practicality of Cider by implementing it on three popular IoT platforms (HummingBoard Edge, Raspberry Pi Compute Module 3 and Nucleo-L476RG) spanning the range from high to low end. Our evaluation shows that the performance overhead of Cider is generally negligible.",
            "keywords": [
                "Internet of Things (IoT)",
                "Device Recovery",
                "Root Compromise",
                "Firmware Update",
                "Cider System"
            ]
        },
        "url": "URL#2761241",
        "sema_paperId": "546dd4377da815a1142c3b9350e2369c8ebc8c10"
    },
    {
        "@score": "1",
        "@id": "2761242",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "42/1870-2",
                        "text": "Wen Xu 0002"
                    },
                    {
                        "@pid": "119/7680",
                        "text": "Hyungon Moon"
                    },
                    {
                        "@pid": "145/0912",
                        "text": "Sanidhya Kashyap"
                    },
                    {
                        "@pid": "168/8683",
                        "text": "Po-Ning Tseng"
                    },
                    {
                        "@pid": "38/8882",
                        "text": "Taesoo Kim"
                    }
                ]
            },
            "title": "Fuzzing File Systems via Two-Dimensional Input Space Exploration.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "818-834",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/XuMKTK19",
            "doi": "10.1109/SP.2019.00035",
            "ee": "https://doi.org/10.1109/SP.2019.00035",
            "url": "https://dblp.org/rec/conf/sp/XuMKTK19",
            "abstract": "File systems, a basic building block of an OS, are too big and too complex to be bug free. Nevertheless, file systems rely on regular stress-testing tools and formal checkers to find bugs, which are limited due to the ever-increasing complexity of both file systems and OSes. Thus, fuzzing, proven to be an effective and a practical approach, becomes a preferable choice, as it does not need much knowledge about a target. However, three main challenges exist in fuzzing file systems: mutating a large image blob that degrades overall performance, generating image-dependent file operations, and reproducing found bugs, which is difficult for existing OS fuzzers. Hence, we present JANUS, the first feedback-driven fuzzer that explores the two-dimensional input space of a file system, i.e., mutating metadata on a large image, while emitting image-directed file operations. In addition, JANUS relies on a library OS rather than on traditional VMs for fuzzing, which enables JANUS to load a fresh copy of the OS, thereby leading to better reproducibility of bugs. We evaluate JANUS on eight file systems and found 90 bugs in the upstream Linux kernel, 62 of which have been acknowledged. Forty-three bugs have been fixed with 32 CVEs assigned. In addition, JANUS achieves higher code coverage on all the file systems after fuzzing 12 hours, when compared with the state-of-the-art fuzzer Syzkaller for fuzzing file systems. JANUS visits 4.19x and 2.01x more code paths in Btrfs and ext4, respectively. Moreover, JANUS is able to reproduce 88\u2013100% of the crashes, while Syzkaller fails on all of them.",
            "keywords": [
                "File System Fuzzing",
                "Input Space Exploration",
                "Feedback-Driven Fuzzer",
                "Bug Reproduction",
                "Metadata Mutation"
            ]
        },
        "url": "URL#2761242",
        "sema_paperId": "f688568ac0f434fcaedffb5c75fdb03063435685"
    },
    {
        "@score": "1",
        "@id": "2761243",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "137/0590",
                        "text": "Mengjia Yan 0001"
                    },
                    {
                        "@pid": "141/1911",
                        "text": "Read Sprabery"
                    },
                    {
                        "@pid": "178/3211",
                        "text": "Bhargava Gopireddy"
                    },
                    {
                        "@pid": "25/8166",
                        "text": "Christopher W. Fletcher"
                    },
                    {
                        "@pid": "c/RoyHCampbell",
                        "text": "Roy H. Campbell"
                    },
                    {
                        "@pid": "t/JosepTorrellas",
                        "text": "Josep Torrellas"
                    }
                ]
            },
            "title": "Attack Directories, Not Caches: Side Channel Attacks in a Non-Inclusive World.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "888-904",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/YanSGFCT19",
            "doi": "10.1109/SP.2019.00004",
            "ee": "https://doi.org/10.1109/SP.2019.00004",
            "url": "https://dblp.org/rec/conf/sp/YanSGFCT19",
            "abstract": "Although clouds have strong virtual memory isolation guarantees, cache attacks stemming from shared caches have proved to be a large security problem. However, despite the past effectiveness of cache attacks, their viability has recently been called into question on modern systems, due to trends in cache hierarchy design moving away from inclusive cache hierarchies. In this paper, we reverse engineer the structure of the directory in a sliced, non-inclusive cache hierarchy, and prove that the directory can be used to bootstrap conflict-based cache attacks on the last-level cache. We design the first cross-core Prime+Probe attack on non-inclusive caches. This attack works with minimal assumptions: the adversary does not need to share any virtual memory with the victim, nor run on the same processor core. We also show the first high-bandwidth Evict+Reload attack on the same hardware. We demonstrate both attacks by extracting key bits during RSA operations in GnuPG on a state-of-the-art non-inclusive Intel Skylake-X server.",
            "keywords": [
                "Cache Attacks",
                "Non-Inclusive Caches",
                "Side Channel Attacks",
                "Conflict-Based Attacks",
                "Evict+Reload Attack"
            ]
        },
        "url": "URL#2761243",
        "sema_paperId": "e1494a7f7a27001a8dbaaa68c7e0cba1a17279b7"
    },
    {
        "@score": "1",
        "@id": "2761244",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "194/0001-1",
                        "text": "Qingqing Ye 0001"
                    },
                    {
                        "@pid": "90/5236-1",
                        "text": "Haibo Hu 0001"
                    },
                    {
                        "@pid": "m/XiaofengMeng-1",
                        "text": "Xiaofeng Meng 0001"
                    },
                    {
                        "@pid": "198/9507",
                        "text": "Huadi Zheng"
                    }
                ]
            },
            "title": "PrivKV: Key-Value Data Collection with Local Differential Privacy.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "317-331",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/YeHMZ19",
            "doi": "10.1109/SP.2019.00018",
            "ee": "https://doi.org/10.1109/SP.2019.00018",
            "url": "https://dblp.org/rec/conf/sp/YeHMZ19",
            "abstract": "Local differential privacy (LDP), where each user perturbs her data locally before sending to an untrusted data collector, is a new and promising technique for privacy-preserving distributed data collection. The advantage of LDP is to enable the collector to obtain accurate statistical estimation on sensitive user data (e.g., location and app usage) without accessing them. However, existing work on LDP is limited to simple data types, such as categorical, numerical, and set-valued data. To the best of our knowledge, there is no existing LDP work on key-value data, which is an extremely popular NoSQL data model and the generalized form of set-valued and numerical data. In this paper, we study this problem of frequency and mean estimation on key-value data by first designing a baseline approach PrivKV within the same \"perturbation-calibration\" paradigm as existing LDP techniques. To address the poor estimation accuracy due to the clueless perturbation of users, we then propose two iterative solutions PrivKVM and PrivKVM+ that can gradually improve the estimation results through a series of iterations. An optimization strategy is also presented to reduce network latency and increase estimation accuracy by introducing virtual iterations in the collector side without user involvement. We verify the correctness and effectiveness of these solutions through theoretical analysis and extensive experimental results.",
            "keywords": [
                "Local Differential Privacy",
                "Key-Value Data",
                "Data Perturbation",
                "Statistical Estimation",
                "Privacy-Preserving Data Collection"
            ]
        },
        "url": "URL#2761244",
        "sema_paperId": "25b7fe2ac81189952c72c5b869a6be1c5fcf410c"
    },
    {
        "@score": "1",
        "@id": "2761245",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "87/6465",
                        "text": "Wei You"
                    },
                    {
                        "@pid": "60/8494",
                        "text": "Xueqiang Wang"
                    },
                    {
                        "@pid": "172/8745",
                        "text": "Shiqing Ma"
                    },
                    {
                        "@pid": "41/2181-1",
                        "text": "Jianjun Huang 0001"
                    },
                    {
                        "@pid": "95/3760-1",
                        "text": "Xiangyu Zhang 0001"
                    },
                    {
                        "@pid": "06/6268",
                        "text": "XiaoFeng Wang 0001"
                    },
                    {
                        "@pid": "71/6053-2",
                        "text": "Bin Liang 0002"
                    }
                ]
            },
            "title": "ProFuzzer: On-the-fly Input Type Probing for Better Zero-Day Vulnerability Discovery.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "769-786",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/YouWMHZ0019",
            "doi": "10.1109/SP.2019.00057",
            "ee": "https://doi.org/10.1109/SP.2019.00057",
            "url": "https://dblp.org/rec/conf/sp/YouWMHZ0019",
            "abstract": "Existing mutation based fuzzers tend to randomly mutate the input of a program without understanding its underlying syntax and semantics. In this paper, we propose a novel on-the-fly probing technique (called ProFuzzer) that automatically recovers and understands input fields of critical importance to vulnerability discovery during a fuzzing process and intelligently adapts the mutation strategy to enhance the chance of hitting zero-day targets. Since such probing is transparently piggybacked to the regular fuzzing, no prior knowledge of the input specification is needed. During fuzzing, individual bytes are first mutated and their fuzzing results are automatically analyzed to link those related together and identify the type for the field connecting them; these bytes are further mutated together following type-specific strategies, which substantially prunes the search space. We define the probe types generally across all applications, thereby making our technique application agnostic. Our experiments on standard benchmarks and real-world applications show that ProFuzzer substantially outperforms AFL and its optimized version AFLFast, as well as other state-of-art fuzzers including VUzzer, Driller and QSYM. Within two months, it exposed 42 zero-days in 10 intensively tested programs, generating 30 CVEs.",
            "keywords": [
                "Fuzzing",
                "Zero-Day Vulnerabilities",
                "Input Probing",
                "Mutation Strategies",
                "Application Agnostic"
            ]
        },
        "url": "URL#2761245",
        "sema_paperId": "bc3e836e948b6fbc220f508e33cc68b9c64f5411"
    },
    {
        "@score": "1",
        "@id": "2761246",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "01/2775-2",
                        "text": "Lei Yu 0002"
                    },
                    {
                        "@pid": "l/LingLiu",
                        "text": "Ling Liu 0001"
                    },
                    {
                        "@pid": "p/CaltonPu",
                        "text": "Calton Pu"
                    },
                    {
                        "@pid": "165/5531",
                        "text": "Mehmet Emre Gursoy"
                    },
                    {
                        "@pid": "205/9231",
                        "text": "Stacey Truex"
                    }
                ]
            },
            "title": "Differentially Private Model Publishing for Deep Learning.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "332-349",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/Yu0PGT19",
            "doi": "10.1109/SP.2019.00019",
            "ee": "https://doi.org/10.1109/SP.2019.00019",
            "url": "https://dblp.org/rec/conf/sp/Yu0PGT19",
            "abstract": "Deep learning techniques based on neural networks have shown significant success in a wide range of AI tasks. Large-scale training datasets are one of the critical factors for their success. However, when the training datasets are crowdsourced from individuals and contain sensitive information, the model parameters may encode private information and bear the risks of privacy leakage. The recent growing trend of the sharing and publishing of pre-trained models further aggravates such privacy risks. To tackle this problem, we propose a differentially private approach for training neural networks. Our approach includes several new techniques for optimizing both privacy loss and model accuracy. We employ a generalization of differential privacy called concentrated differential privacy(CDP), with both a formal and refined privacy loss analysis on two different data batching methods. We implement a dynamic privacy budget allocator over the course of training to improve model accuracy. Extensive experiments demonstrate that our approach effectively improves privacy loss accounting, training efficiency and model quality under a given privacy budget.",
            "pdf_url": "",
            "keywords": [
                "Differential Privacy",
                "Concentrated Differential Privacy",
                "Privacy Loss Analysis",
                "Dynamic Privacy Budget",
                "Model Accuracy"
            ]
        },
        "url": "URL#2761246"
    },
    {
        "@score": "1",
        "@id": "2761247",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "03/7768",
                        "text": "Kan Yuan"
                    },
                    {
                        "@pid": "77/1147-1",
                        "text": "Di Tang 0001"
                    },
                    {
                        "@pid": "129/1113",
                        "text": "Xiaojing Liao"
                    },
                    {
                        "@pid": "06/6268",
                        "text": "XiaoFeng Wang 0001"
                    },
                    {
                        "@pid": "09/8674",
                        "text": "Xuan Feng"
                    },
                    {
                        "@pid": "49/6574",
                        "text": "Yi Chen"
                    },
                    {
                        "@pid": "192/8009",
                        "text": "Menghan Sun"
                    },
                    {
                        "@pid": "122/4355",
                        "text": "Haoran Lu"
                    },
                    {
                        "@pid": "66/6560",
                        "text": "Kehuan Zhang"
                    }
                ]
            },
            "title": "Stealthy Porn: Understanding Real-World Adversarial Images for Illicit Online Promotion.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "952-966",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/YuanTLWFCSLZ19",
            "doi": "10.1109/SP.2019.00032",
            "ee": "https://doi.org/10.1109/SP.2019.00032",
            "url": "https://dblp.org/rec/conf/sp/YuanTLWFCSLZ19",
            "abstract": "Recent years have witnessed the rapid progress in deep learning (DP), which also brings their potential weaknesses to the spotlights of security and machine learning studies. With important discoveries made by adversarial learning research, surprisingly little attention, however, has been paid to the real-world adversarial techniques deployed by the cybercriminal to evade image-based detection. Unlike the adversarial examples that induce misclassification using nearly imperceivable perturbation, real-world adversarial images tend to be less optimal yet equally effective. As a first step to understand the threat, we report in the paper a study on adversarial promotional porn images (APPIs) that are extensively used in underground advertising. We show that the adversary today\u2019s strategically constructs the APPIs to evade explicit content detection while still preserving their sexual appeal, even though the distortions and noise introduced are clearly observable to humans. To understand such real-world adversarial images and the underground business behind them, we develop a novel DP-based methodology called Male`na, which focuses on the regions of an image where sexual content is least obfuscated and therefore visible to the target audience of a promotion. Using this technique, we have discovered over 4,000 APPIs from 4,042,690 images crawled from popular social media, and further brought to light the unique techniques they use to evade popular explicit content detectors (e.g., Google Cloud Vision API, Yahoo Open NSFW model), and the reason that these techniques work. Also studied are the ecosystem of such illicit promotions, including the obfuscated contacts advertised through those images, compromised accounts used to disseminate them, and large APPI campaigns involving thousands of images. Another interesting finding is the apparent attempt made by cybercriminals to steal others\u2019 images for their advertising. The study highlights the importance of the research on real-world adversarial learning and makes the first step towards mitigating the threats it poses.",
            "keywords": [
                "Adversarial Images",
                "Illicit Online Promotion",
                "Explicit Content Detection",
                "Underground Advertising",
                "Adversarial Promotional Porn Images (APPIs)"
            ]
        },
        "url": "URL#2761247",
        "sema_paperId": "8478ae42b24b169c1f6d8e0b30cbb125eae7a6a8"
    },
    {
        "@score": "1",
        "@id": "2761248",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "202/7280",
                        "text": "Alexei Zamyatin"
                    },
                    {
                        "@pid": "213/7973",
                        "text": "Dominik Harz"
                    },
                    {
                        "@pid": "188/9951",
                        "text": "Joshua Lind"
                    },
                    {
                        "@pid": "249/3012-2",
                        "text": "Panayiotis Panayiotou 0002"
                    },
                    {
                        "@pid": "138/9020",
                        "text": "Arthur Gervais"
                    },
                    {
                        "@pid": "37/1901",
                        "text": "William J. Knottenbelt"
                    }
                ]
            },
            "title": "XCLAIM: Trustless, Interoperable, Cryptocurrency-Backed Assets.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "193-210",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/ZamyatinHLPGK19",
            "doi": "10.1109/SP.2019.00085",
            "ee": "https://doi.org/10.1109/SP.2019.00085",
            "url": "https://dblp.org/rec/conf/sp/ZamyatinHLPGK19",
            "abstract": "Building trustless cross-blockchain trading protocols is challenging. Centralized exchanges thus remain the preferred route to execute transfers across blockchains. However, these services require trust and therefore undermine the very nature of the blockchains on which they operate. To overcome this, several decentralized exchanges have recently emerged which offer support for atomic cross-chain swaps (ACCS). ACCS enable the trustless exchange of cryptocurrencies across blockchains, and are the only known mechanism to do so. However, ACCS suffer significant limitations; they are slow, inefficient and costly, meaning that they are rarely used in practice. We present XCLAIM: the first generic framework for achieving trustless and efficient cross-chain exchanges using cryptocurrency-backed assets (CbAs). XCLAIM offers protocols for issuing, transferring, swapping and redeeming CbAs securely in a non-interactive manner on existing blockchains. We instantiate XCLAIM between Bitcoin and Ethereum and evaluate our implementation; it costs less than USD 0.50 to issue an arbitrary amount of Bitcoin-backed tokens on Ethereum. We show XCLAIM is not only faster, but also significantly cheaper than atomic cross-chain swaps. Finally, XCLAIM is compatible with the majority of existing blockchains without modification, and enables several novel cryptocurrency applications, such as cross-chain payment channels and efficient multi-party swaps.",
            "keywords": [
                "Cross-Chain Trading",
                "Decentralized Exchanges",
                "Cryptocurrency-Backed Assets",
                "Atomic Cross-Chain Swaps",
                "Trustless Asset Exchange"
            ]
        },
        "url": "URL#2761248",
        "sema_paperId": "17cff826c2780dc747534ae5563853c4aaf4dac7"
    },
    {
        "@score": "1",
        "@id": "2761249",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "86/3523-1",
                        "text": "Jiexin Zhang 0001"
                    },
                    {
                        "@pid": "29/361",
                        "text": "Alastair R. Beresford"
                    },
                    {
                        "@pid": "249/3153",
                        "text": "Ian Sheret"
                    }
                ]
            },
            "title": "SensorID: Sensor Calibration Fingerprinting for Smartphones.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "638-655",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/ZhangBS19",
            "doi": "10.1109/SP.2019.00072",
            "ee": "https://doi.org/10.1109/SP.2019.00072",
            "url": "https://dblp.org/rec/conf/sp/ZhangBS19",
            "abstract": "Sensors are an essential component of many computer systems today. Mobile devices are a good example, containing a vast array of sensors from accelerometers and GPS units, to cameras and microphones. Data from these sensors are accessible to application programmers who can use this data to build context-aware applications. Good sensor accuracy is often crucial, and therefore manufacturers often use per-device factory calibration to compensate for systematic errors introduced during manufacture. In this paper we explore a new type of fingerprinting attack on sensor data: calibration fingerprinting. A calibration fingerprinting attack infers the per-device factory calibration data from a device by careful analysis of the sensor output alone. Such an attack does not require direct access to any calibration parameters since these are often embedded inside the firmware of the device and are not directly accessible by application developers. We demonstrate the potential of this new class of attack by performing calibration fingerprinting attacks on the inertial measurement unit sensors found in iOS and Android devices. These sensors are good candidates because access to these sensors does not require any special permissions, and the data can be accessed via both a native app installed on a device and also by JavaScript when visiting a website on an iOS and Android device. We find we are able to perform a very effective calibration fingerprinting attack: our approach requires fewer than 100 samples of sensor data and takes less than one second to collect and process into a device fingerprint that does not change over time or after factory reset. We demonstrate that our approach is very likely to produce globally unique fingerprints for iOS devices, with an estimated 67 bits of entropy in the fingerprint for iPhone 6S devices. In addition, we find that the accelerometer of Google Pixel 2 and Pixel 3 devices can also be fingerprinted by our approach.",
            "keywords": [
                "Sensor Calibration",
                "Fingerprinting Attack",
                "Mobile Device Sensors",
                "Inertial Measurement Unit",
                "Data Privacy"
            ]
        },
        "url": "URL#2761249",
        "sema_paperId": "b1ab6c7ef13d1bc738fe6b8d399e3c0d6c4d41ef"
    },
    {
        "@score": "1",
        "@id": "2761250",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "28/3341-1",
                        "text": "Mu Zhang 0001"
                    },
                    {
                        "@pid": "49/7998",
                        "text": "Chien-Ying Chen"
                    },
                    {
                        "@pid": "249/3007",
                        "text": "Bin-Chou Kao"
                    },
                    {
                        "@pid": "204/5802",
                        "text": "Yassine Qamsane"
                    },
                    {
                        "@pid": "147/2116",
                        "text": "Yuru Shao"
                    },
                    {
                        "@pid": "159/3922",
                        "text": "Yikai Lin"
                    },
                    {
                        "@pid": "80/4580",
                        "text": "Elaine Shi"
                    },
                    {
                        "@pid": "60/5790",
                        "text": "Sibin Mohan"
                    },
                    {
                        "@pid": "93/7142",
                        "text": "Kira Barton"
                    },
                    {
                        "@pid": "19/5792",
                        "text": "James R. Moyne"
                    },
                    {
                        "@pid": "91/584",
                        "text": "Z. Morley Mao"
                    }
                ]
            },
            "title": "Towards Automated Safety Vetting of PLC Code in Real-World Plants.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "522-538",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/ZhangCKQSLSMBMM19",
            "doi": "10.1109/SP.2019.00034",
            "ee": "https://doi.org/10.1109/SP.2019.00034",
            "url": "https://dblp.org/rec/conf/sp/ZhangCKQSLSMBMM19",
            "abstract": "Safety violations in programmable logic controllers (PLCs), caused either by faults or attacks, have recently garnered significant attention. However, prior efforts at PLC code vetting suffer from many drawbacks. Static analyses and verification cause significant false positives and cannot reveal specific runtime contexts. Dynamic analyses and symbolic execution, on the other hand, fail due to their inability to handle real-world PLC programs that are event-driven and timing sensitive. In this paper, we propose VetPLC, a temporal context-aware, program analysis-based approach to produce timed event sequences that can be used for automatic safety vetting. To this end, we (a) perform static program analysis to create timed event causality graphs in order to understand causal relations among events in PLC code and (b) mine temporal invariants from data traces collected in Industrial Control System (ICS) testbeds to quantitatively gauge temporal dependencies that are constrained by machine operations. Our VetPLC prototype has been implemented in 15K lines of code. We evaluate it on 10 real-world scenarios from two different ICS settings. Our experiments show that VetPLC outperforms state-of-the-art techniques and can generate event sequences that can be used to automatically detect hidden safety violations.",
            "keywords": [
                "Programmable Logic Controllers",
                "Safety Vetting",
                "Temporal Context Awareness",
                "Event-Driven Systems",
                "Safety Violations"
            ]
        },
        "url": "URL#2761250",
        "sema_paperId": "2eda71b48500c1b9c26b7c14f9bb8fb94644cd20"
    },
    {
        "@score": "1",
        "@id": "2761251",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "28/6297-18",
                        "text": "Nan Zhang 0018"
                    },
                    {
                        "@pid": "192/2270",
                        "text": "Xianghang Mi"
                    },
                    {
                        "@pid": "09/8674",
                        "text": "Xuan Feng"
                    },
                    {
                        "@pid": "06/6268",
                        "text": "XiaoFeng Wang 0001"
                    },
                    {
                        "@pid": "39/5423-1",
                        "text": "Yuan Tian 0001"
                    },
                    {
                        "@pid": "54/476-1",
                        "text": "Feng Qian 0001"
                    }
                ]
            },
            "title": "Dangerous Skills: Understanding and Mitigating Security Risks of Voice-Controlled Third-Party Functions on Virtual Personal Assistant Systems.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "1381-1396",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/ZhangMFW0Q19",
            "doi": "10.1109/SP.2019.00016",
            "ee": "https://doi.org/10.1109/SP.2019.00016",
            "url": "https://dblp.org/rec/conf/sp/ZhangMFW0Q19",
            "abstract": "Virtual personal assistants (VPA) (e.g., Amazon Alexa and Google Assistant) today mostly rely on the voice channel to communicate with their users, which however is known to be vulnerable, lacking proper authentication (from the user to the VPA). A new authentication challenge, from the VPA service to the user, has emerged with the rapid growth of the VPA ecosystem, which allows a third party to publish a function (called skill) for the service and therefore can be exploited to spread malicious skills to a large audience during their interactions with smart speakers like Amazon Echo and Google Home. In this paper, we report a study that concludes such remote, large-scale attacks are indeed realistic. We discovered two new attacks: voice squatting in which the adversary exploits the way a skill is invoked (e.g., ``open capital one''), using a malicious skill with a similarly pronounced name (e.g., ``capital won'') or a paraphrased name (e.g., ``capital one please'') to hijack the voice command meant for a legitimate skill (e.g., ``capital one''), and voice masquerading in which a malicious skill impersonates the VPA service or a legitimate skill during the user's conversation with the service to steal her personal information. These attacks aim at the way VPAs work or the user's misconceptions about their functionalities, and are found to pose a realistic threat by our experiments (including user studies and real-world deployments) on Amazon Echo and Google Home. The significance of our findings has already been acknowledged by Amazon and Google, and further evidenced by the risky skills found on Alexa and Google markets by the new squatting detector we built. We further developed a technique that automatically captures an ongoing masquerading attack and demonstrated its efficacy.",
            "keywords": [
                "Virtual Personal Assistants",
                "Voice-Controlled Systems",
                "Security Risks",
                "Voice Squatting",
                "Voice Masquerading"
            ]
        },
        "url": "URL#2761251",
        "sema_paperId": "97855989936ed45485f15e470f8c70a8a3a1e93c"
    },
    {
        "@score": "1",
        "@id": "2761252",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "94/4314",
                        "text": "Wenting Zheng"
                    },
                    {
                        "@pid": "91/275",
                        "text": "Raluca Ada Popa"
                    },
                    {
                        "@pid": "61/8262",
                        "text": "Joseph E. Gonzalez"
                    },
                    {
                        "@pid": "s/IonStoica",
                        "text": "Ion Stoica"
                    }
                ]
            },
            "title": "Helen: Maliciously Secure Coopetitive Learning for Linear Models.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "724-738",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/ZhengPGS19",
            "doi": "10.1109/SP.2019.00045",
            "ee": "https://doi.org/10.1109/SP.2019.00045",
            "url": "https://dblp.org/rec/conf/sp/ZhengPGS19",
            "abstract": "Many organizations wish to collaboratively train machine learning models on their combined datasets for a common benefit (e.g., better medical research, or fraud detection). However, they often cannot share their plaintext datasets due to privacy concerns and/or business competition. In this paper, we design and build Helen, a system that allows multiple parties to train a linear model without revealing their data, a setting we call coopetitive learning. Compared to prior secure training systems, Helen protects against a much stronger adversary who is malicious and can compromise m\u22121 out of m parties. Our evaluation shows that Helen can achieve up to five orders of magnitude of performance improvement when compared to training using an existing state-of-the-art secure multi-party computation framework.",
            "keywords": [
                "Coopetitive Learning",
                "Secure Multi-Party Computation",
                "Malicious Adversaries",
                "Privacy-Preserving Machine Learning",
                "Linear Model Training"
            ]
        },
        "url": "URL#2761252",
        "sema_paperId": "6528dcb989e450dd806176ab54e8274e961e4d46"
    },
    {
        "@score": "1",
        "@id": "2761254",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "149/8302",
                        "text": "Chaoshun Zuo"
                    },
                    {
                        "@pid": "49/4102-1",
                        "text": "Zhiqiang Lin 0001"
                    },
                    {
                        "@pid": "77/3503",
                        "text": "Yinqian Zhang"
                    }
                ]
            },
            "title": "Why Does Your Data Leak? Uncovering the Data Leakage in Cloud from Mobile Apps.",
            "venue": "IEEE Symposium on Security and Privacy",
            "pages": "1296-1310",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/ZuoLZ19",
            "doi": "10.1109/SP.2019.00009",
            "ee": "https://doi.org/10.1109/SP.2019.00009",
            "url": "https://dblp.org/rec/conf/sp/ZuoLZ19",
            "abstract": "Increasingly, more and more mobile applications (apps for short) are using the cloud as the back-end, in particular the cloud APIs, for data storage, data analytics, message notification, and monitoring. Unfortunately, we have recently witnessed massive data leaks from the cloud, ranging from personally identifiable information to corporate secrets. In this paper, we seek to understand why such significant leaks occur and design tools to automatically identify them. To our surprise, our study reveals that lack of authentication, misuse of various keys (e.g., normal user keys and superuser keys) in authentication, or misconfiguration of user permissions in authorization are the root causes. Then, we design a set of automated program analysis techniques including obfuscation-resilient cloud API identification and string value analysis, and implement them in a tool called LeakScope to identify the potential data leakage vulnerabilities from mobile apps based on how the cloud APIs are used. Our evaluation with over 1.6 million mobile apps from the Google Play Store has uncovered 15, 098 app servers managed by mainstream cloud providers such as Amazon, Google, and Microsoft that are subject to data leakage attacks. We have made responsible disclosure to each of the cloud service providers, and they have all confirmed the vulnerabilities we have identified and are actively working with the mobile app developers to patch their vulnerable services.",
            "keywords": [
                "Cloud Security",
                "Mobile Application Vulnerabilities",
                "Data Leakage",
                "Authentication Misconfiguration",
                "Cloud API Misuse"
            ]
        },
        "url": "URL#2761254",
        "sema_paperId": "fd27d0e8a9a95913a506897398b3c49ebd571950"
    },
    {
        "@score": "1",
        "@id": "2782155",
        "info": {
            "title": "2019 IEEE Symposium on Security and Privacy, SP 2019, San Francisco, CA, USA, May 19-23, 2019",
            "venue": "IEEE Symposium on Security and Privacy",
            "publisher": "IEEE",
            "year": "2019",
            "type": "Editorship",
            "key": "conf/sp/2019",
            "ee": "https://ieeexplore.ieee.org/xpl/conhome/8826229/proceeding",
            "url": "https://dblp.org/rec/conf/sp/2019",
            "abstract": null
        },
        "url": "URL#2782155",
        "sema_paperId": "f01cd37be2b05f602e293367f8d945aec4c1e7d2"
    }
]