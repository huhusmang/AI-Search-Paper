[
    {
        "@score": "1",
        "@id": "2326600",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "92/5367-1",
                        "text": "Nishant Kumar 0001"
                    },
                    {
                        "@pid": "33/2105-2",
                        "text": "Mayank Rathee"
                    },
                    {
                        "@pid": "77/5616",
                        "text": "Nishanth Chandran"
                    },
                    {
                        "@pid": "66/11477-1",
                        "text": "Divya Gupta 0001"
                    },
                    {
                        "@pid": "81/10809",
                        "text": "Aseem Rastogi"
                    },
                    {
                        "@pid": "22/846-1",
                        "text": "Rahul Sharma 0001"
                    }
                ]
            },
            "title": "CrypTFlow: Secure TensorFlow Inference.",
            "venue": "SP",
            "pages": "336-353",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/0001RCGR020",
            "doi": "10.1109/SP40000.2020.00092",
            "ee": "https://doi.org/10.1109/SP40000.2020.00092",
            "url": "https://dblp.org/rec/conf/sp/0001RCGR020",
            "abstract": "We present CrypTFlow, a first of its kind system that converts TensorFlow inference code into Secure Multi-party Computation (MPC) protocols at the push of a button. To do this, we build three components. Our first component, Athos, is an end-to-end compiler from TensorFlow to a variety of semihonest MPC protocols. The second component, Porthos, is an improved semi-honest 3-party protocol that provides significant speedups for TensorFlow like applications. Finally, to provide malicious secure MPC protocols, our third component, Aramis, is a novel technique that uses hardware with integrity guarantees to convert any semi-honest MPC protocol into an MPC protocol that provides malicious security. The malicious security of the protocols output by Aramis relies on integrity of the hardware and semi-honest security of MPC. Moreover, our system matches the inference accuracy of plaintext TensorFlow.We experimentally demonstrate the power of our system by showing the secure inference of real-world neural networks such as ResNet50 and DenseNet121 over the ImageNet dataset with running times of about 30 seconds for semi-honest security and under two minutes for malicious security. Prior work in the area of secure inference has been limited to semi-honest security of small networks over tiny datasets such as MNIST or CIFAR. Even on MNIST/CIFAR, CrypTFlow outperforms prior work.",
            "pdf_url": "",
            "keywords": [
                "Secure Multi-party Computation",
                "TensorFlow Inference",
                "Malicious Security",
                "Semi-honest Protocols",
                "Neural Network Inference"
            ]
        },
        "url": "URL#2326600"
    },
    {
        "@score": "1",
        "@id": "2326601",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "36/5720",
                        "text": "Ittai Abraham"
                    },
                    {
                        "@pid": "m/DahliaMalkhi",
                        "text": "Dahlia Malkhi"
                    },
                    {
                        "@pid": "143/4459",
                        "text": "Kartik Nayak"
                    },
                    {
                        "@pid": "30/10661",
                        "text": "Ling Ren 0001"
                    },
                    {
                        "@pid": "166/6440",
                        "text": "Maofan Yin"
                    }
                ]
            },
            "title": "Sync HotStuff: Simple and Practical Synchronous State Machine Replication.",
            "venue": "SP",
            "pages": "106-118",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/AbrahamMN0Y20",
            "doi": "10.1109/SP40000.2020.00044",
            "ee": "https://doi.org/10.1109/SP40000.2020.00044",
            "url": "https://dblp.org/rec/conf/sp/AbrahamMN0Y20",
            "abstract": "Synchronous solutions for Byzantine Fault Tolerance (BFT) can tolerate up to minority faults. In this work, we present Sync HotStuff, a surprisingly simple and intuitive synchronous BFT solution that achieves consensus with a latency of 2\u0394 in the steady state (where \u0394 is a synchronous message delay upper bound). In addition, Sync HotStuff ensures safety in a weaker synchronous model in which the synchrony assumption does not have to hold for all replicas all the time. Moreover, Sync HotStuff has optimistic responsiveness, i.e., it advances at network speed when less than one-quarter of the replicas are not responding. Borrowing from practical partially synchronous BFT solutions, Sync HotStuff has a two-phase leader-based structure, and has been fully prototyped under the standard synchrony assumption. When tolerating a single fault, Sync HotStuff achieves a throughput of over 280 Kops/sec under typical network performance, which is comparable to the best known partially synchronous solution.",
            "keywords": [
                "Byzantine Fault Tolerance",
                "Synchronous Consensus",
                "State Machine Replication",
                "Optimistic Responsiveness",
                "HotStuff Protocol"
            ]
        },
        "url": "URL#2326601",
        "sema_paperId": "1eb1f1e86692a2ff30be7d84f0d476fbfa83cf1d"
    },
    {
        "@score": "1",
        "@id": "2326603",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "181/0549",
                        "text": "Sam Ainsworth"
                    },
                    {
                        "@pid": "62/1131",
                        "text": "Timothy M. Jones 0001"
                    }
                ]
            },
            "title": "MarkUs: Drop-in use-after-free prevention for low-level languages.",
            "venue": "SP",
            "pages": "578-591",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/Ainsworth020",
            "doi": "10.1109/SP40000.2020.00058",
            "ee": "https://doi.org/10.1109/SP40000.2020.00058",
            "url": "https://dblp.org/rec/conf/sp/Ainsworth020",
            "abstract": "Use-after-free vulnerabilities have plagued software written in low-level languages, such as C and C++, becoming one of the most frequent classes of exploited software bugs. Attackers identify code paths where data is manually freed by the programmer, but later incorrectly reused, and take advantage by reallocating the data to themselves. They then alter the data behind the program\u2019s back, using the erroneous reuse to gain control of the application and, potentially, the system. While a variety of techniques have been developed to deal with these vulnerabilities, they often have unacceptably high performance or memory overheads, especially in the worst case.We have designed MarkUs, a memory allocator that prevents this form of attack at low overhead, sufficient for deployment in real software, even under allocation- and memory-intensive scenarios. We prevent use-after-free attacks by quarantining data freed by the programmer and forbidding its reallocation until we are sure that there are no dangling pointers targeting it. To identify these we traverse live-objects accessible from registers and memory, marking those we encounter, to check whether quarantined data is accessible from any currently allocated location. Unlike garbage collection, which is unsafe in C and C++, MarkUs ensures safety by only freeing data that is both quarantined by the programmer and has no identifiable dangling pointers. The information provided by the programmer\u2019s allocations and frees further allows us to optimise the process by freeing physical addresses early for large objects, specialising analysis for small objects, and only performing marking when sufficient data is in quarantine. Using MarkUs, we reduce the overheads of temporal safety in low-level languages to 1.1\u00d7 on average for SPEC CPU2006, with a maximum slowdown of only 2\u00d7, vastly improving upon the state-of-the-art.",
            "keywords": [
                "Memory Management",
                "Use-After-Free",
                "Low-Level Languages",
                "Memory Allocator",
                "Temporal Safety"
            ]
        },
        "url": "URL#2326603",
        "sema_paperId": "462d0f23dc164fc615213f24a8540d4aa3aae1f1"
    },
    {
        "@score": "1",
        "@id": "2326606",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "66/3456",
                        "text": "Jos\u00e9 Bacelar Almeida"
                    },
                    {
                        "@pid": "06/5631",
                        "text": "Manuel Barbosa"
                    },
                    {
                        "@pid": "b/GBarthe",
                        "text": "Gilles Barthe"
                    },
                    {
                        "@pid": "28/2414",
                        "text": "Benjamin Gr\u00e9goire"
                    },
                    {
                        "@pid": "160/4605",
                        "text": "Adrien Koutsos"
                    },
                    {
                        "@pid": "66/8883",
                        "text": "Vincent Laporte"
                    },
                    {
                        "@pid": "87/4879-4",
                        "text": "Tiago Oliveira 0004"
                    },
                    {
                        "@pid": "35/5080",
                        "text": "Pierre-Yves Strub"
                    }
                ]
            },
            "title": "The Last Mile: High-Assurance and High-Speed Cryptographic Implementations.",
            "venue": "SP",
            "pages": "965-982",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/AlmeidaBBGKL0S20",
            "doi": "10.1109/SP40000.2020.00028",
            "ee": "https://doi.org/10.1109/SP40000.2020.00028",
            "url": "https://dblp.org/rec/conf/sp/AlmeidaBBGKL0S20",
            "abstract": "We develop a new approach for building cryptographic implementations. Our approach goes the last mile and delivers assembly code that is provably functionally correct, protected against side-channels, and as efficient as hand-written assembly. We illustrate our approach using ChaCha20-Poly1305, one of the two ciphersuites recommended in TLS 1.3, and deliver formally verified vectorized implementations which outperform the fastest non-verified code.We realize our approach by combining the Jasmin framework, which offers in a single language features of high-level and low-level programming, and the EasyCrypt proof assistant, which offers a versatile verification infrastructure that supports proofs of functional correctness and equivalence checking. Neither of these tools had been used for functional correctness before. Taken together, these infrastructures empower programmers to develop efficient and verified implementations by \"game hopping\", starting from reference implementations that are proved functionally correct against a specification, and gradually introducing program optimizations that are proved correct by equivalence checking.We also make several contributions of independent interest, including a new and extensible verified compiler for Jasmin, with a richer memory model and support for vectorized instructions, and a new embedding of Jasmin in EasyCrypt.",
            "pdf_url": "",
            "keywords": [
                "Cryptographic Implementations",
                "Functional Correctness",
                "Side-Channel Protection",
                "ChaCha20-Poly1305",
                "Verified Compiler"
            ]
        },
        "url": "URL#2326606"
    },
    {
        "@score": "1",
        "@id": "2326608",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "212/5112",
                        "text": "Mary Jean Amon"
                    },
                    {
                        "@pid": "157/1889-1",
                        "text": "Rakibul Hasan 0001"
                    },
                    {
                        "@pid": "20/8704",
                        "text": "Kurt Hugenberg"
                    },
                    {
                        "@pid": "130/5588",
                        "text": "Bennett I. Bertenthal"
                    },
                    {
                        "@pid": "50/6916",
                        "text": "Apu Kapadia"
                    }
                ]
            },
            "title": "Influencing Photo Sharing Decisions on Social Media: A Case of Paradoxical Findings.",
            "venue": "SP",
            "pages": "1350-1366",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/AmonHHBK20",
            "doi": "10.1109/SP40000.2020.00006",
            "ee": "https://doi.org/10.1109/SP40000.2020.00006",
            "url": "https://dblp.org/rec/conf/sp/AmonHHBK20",
            "abstract": "We investigate the effects of perspective taking, privacy cues, and portrayal of photo subjects (i.e., photo valence) on decisions to share photos of people via social media. In an online experiment we queried 379 participants about 98 photos (that were previously rated for photo valence) in three conditions: (1) Baseline: participants judged their likelihood of sharing each photo; (2) Perspective-taking: participants judged their likelihood of sharing each photo when cued to imagine they are the person in the photo; and (3) Privacy: participants judged their likelihood to share after being cued to consider the privacy of the person in the photo. While participants across conditions indicated a lower likelihood of sharing photos that portrayed people negatively, they \u2013 surprisingly \u2013 reported a higher likelihood of sharing photos when primed to consider the privacy of the person in the photo. Frequent photo sharers on real-world social media platforms and people without strong personal privacy preferences were especially likely to want to share photos in the experiment, regardless of how the photo portrayed the subject. A follow-up study with 100 participants explaining their responses revealed that the Privacy condition led to a lack of concern with others\u2019 privacy. These findings suggest that developing interventions for reducing photo sharing and protecting the privacy of others is a multivariate problem in which seemingly obvious solutions can sometimes go awry.",
            "keywords": [
                "Social Media Privacy",
                "Photo Sharing Behavior",
                "Perspective Taking",
                "Privacy Cues",
                "Photo Valence"
            ]
        },
        "url": "URL#2326608",
        "sema_paperId": "0bd9a61178605f62e0491df334e64e5d3c3c86a7"
    },
    {
        "@score": "1",
        "@id": "2326609",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "132/8480",
                        "text": "Sebastian Angel"
                    },
                    {
                        "@pid": "86/5425",
                        "text": "Sampath Kannan"
                    },
                    {
                        "@pid": "191/9335",
                        "text": "Zachary B. Ratliff"
                    }
                ]
            },
            "title": "Private resource allocators and their applications.",
            "venue": "SP",
            "pages": "372-391",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/AngelKR20",
            "doi": "10.1109/SP40000.2020.00065",
            "ee": "https://doi.org/10.1109/SP40000.2020.00065",
            "url": "https://dblp.org/rec/conf/sp/AngelKR20",
            "abstract": "This paper introduces a new cryptographic primitive called a private resource allocator (PRA) that can be used to allocate resources (e.g., network bandwidth, CPUs) to a set of clients without revealing to the clients whether any other clients received resources. We give several constructions of PRAs that provide guarantees ranging from information-theoretic to differential privacy. PRAs are useful in preventing a new class of attacks that we call allocation-based side-channel attacks. These attacks can be used, for example, to break the privacy guarantees of anonymous messaging systems that were designed specifically to defend against side-channel and traffic analysis attacks. Our implementation of PRAs in Alpenhorn, which is a recent anonymous messaging system, shows that PRAs increase the network resources required to start a conversation by up to 16\u00d7 (can be made as low as 4\u00d7 in some cases), but add no overhead once the conversation has been established.",
            "keywords": [
                "Private Resource Allocators",
                "Cryptographic Primitives",
                "Allocation-based Side-channel Attacks",
                "Anonymous Messaging Systems",
                "Differential Privacy"
            ]
        },
        "url": "URL#2326609",
        "sema_paperId": "e8f60499efcd4b591800624424625bfd286a66eb"
    },
    {
        "@score": "1",
        "@id": "2326610",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "133/5077",
                        "text": "Daniele Antonioli"
                    },
                    {
                        "@pid": "32/7125",
                        "text": "Nils Ole Tippenhauer"
                    },
                    {
                        "@pid": "01/4779",
                        "text": "Kasper Rasmussen"
                    }
                ]
            },
            "title": "BIAS: Bluetooth Impersonation AttackS.",
            "venue": "SP",
            "pages": "549-562",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/AntonioliTR20",
            "doi": "10.1109/SP40000.2020.00093",
            "ee": "https://doi.org/10.1109/SP40000.2020.00093",
            "url": "https://dblp.org/rec/conf/sp/AntonioliTR20",
            "abstract": "Bluetooth (BR/EDR) is a pervasive technology for wireless communication used by billions of devices. The Bluetooth standard includes a legacy authentication procedure and a secure authentication procedure, allowing devices to authenticate to each other using a long term key. Those procedures are used during pairing and secure connection establishment to prevent impersonation attacks. In this paper, we show that the Bluetooth specification contains vulnerabilities enabling to perform impersonation attacks during secure connection establishment. Such vulnerabilities include the lack of mandatory mutual authentication, overly permissive role switching, and an authentication procedure downgrade. We describe each vulnerability in detail, and we exploit them to design, implement, and evaluate master and slave impersonation attacks on both the legacy authentication procedure and the secure authentication procedure. We refer to our attacks as Bluetooth Impersonation AttackS (BIAS).Our attacks are standard compliant, and are therefore effective against any standard compliant Bluetooth device regardless the Bluetooth version, the security mode (e.g., Secure Connections), the device manufacturer, and the implementation details. Our attacks are stealthy because the Bluetooth standard does not require to notify end users about the outcome of an authentication procedure, or the lack of mutual authentication. To confirm that the BIAS attacks are practical, we successfully conduct them against 31 Bluetooth devices (28 unique Bluetooth chips) from major hardware and software vendors, implementing all the major Bluetooth versions, including Apple, Qualcomm, Intel, Cypress, Broadcom, Samsung, and CSR.",
            "keywords": [
                "Bluetooth Security",
                "Impersonation Attacks",
                "Authentication Vulnerabilities",
                "Bluetooth Impersonation AttackS (BIAS)",
                "Secure Connection Establishment"
            ]
        },
        "url": "URL#2326610",
        "sema_paperId": "30d576514605023dd172e0e993546bfac9779df9"
    },
    {
        "@score": "1",
        "@id": "2326611",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "160/7844",
                        "text": "Cornelius Aschermann"
                    },
                    {
                        "@pid": "205/2072",
                        "text": "Sergej Schumilo"
                    },
                    {
                        "@pid": "73/2297-2",
                        "text": "Ali Abbasi 0002"
                    },
                    {
                        "@pid": "h/ThorstenHolz",
                        "text": "Thorsten Holz"
                    }
                ]
            },
            "title": "Ijon: Exploring Deep State Spaces via Fuzzing.",
            "venue": "SP",
            "pages": "1597-1612",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/AschermannSAH20",
            "doi": "10.1109/SP40000.2020.00117",
            "ee": "https://doi.org/10.1109/SP40000.2020.00117",
            "url": "https://dblp.org/rec/conf/sp/AschermannSAH20",
            "abstract": "Although current fuzz testing (fuzzing) methods are highly effective, there are still many situations such as complex state machines where fully automated approaches fail. State-of-the-art fuzzing methods offer very limited ability for a human to interact and aid the fuzzer in such cases. More specifically, most current approaches are limited to adding a dictionary or new seed inputs to guide the fuzzer. When dealing with complex programs, these mechanisms are unable to uncover new parts of the code base.In this paper, we propose Ijon, an annotation mechanism that a human analyst can use to guide the fuzzer. In contrast to the two aforementioned techniques, this approach allows a more systematic exploration of the program\u2019s behavior based on the data representing the internal state of the program. As a consequence, using only a small (usually one line) annotation, a user can help the fuzzer to solve previously unsolvable challenges. We extended various AFL-based fuzzers with the ability to annotate the source code of the target application with guidance hints. Our evaluation demonstrates that such simple annotations are able to solve problems that\u2014to the best of our knowledge\u2014 no other current fuzzer or symbolic execution based tool can overcome. For example, with our extension, a fuzzer is able to play and solve games such as Super Mario Bros. or resolve more complex patterns such as hash map lookups. To further demonstrate the capabilities of our annotations, we use AFL combined with Ijon to uncover both novel security issues and issues that previously required a custom and comprehensive grammar to be uncovered. Lastly, we show that using Ijon and AFL, one can solve many challenges from the CGC data set that resisted all fully automated and human guided attempts so far.",
            "keywords": [
                "Fuzz Testing",
                "State Machine Exploration",
                "Human Interaction",
                "Annotation Mechanism",
                "Complex Program Behavior"
            ]
        },
        "url": "URL#2326611",
        "sema_paperId": "4ab25272b5c6cfcfd2277a7c300f1de1487707ae"
    },
    {
        "@score": "1",
        "@id": "2326613",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "72/6104",
                        "text": "Jonathan Berger"
                    },
                    {
                        "@pid": "98/3396",
                        "text": "Amit Klein 0001"
                    },
                    {
                        "@pid": "31/1735",
                        "text": "Benny Pinkas"
                    }
                ]
            },
            "title": "Flaw Label: Exploiting IPv6 Flow Label.",
            "venue": "SP",
            "pages": "1259-1276",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/BergerKP20",
            "doi": "10.1109/SP40000.2020.00075",
            "ee": "https://doi.org/10.1109/SP40000.2020.00075",
            "url": "https://dblp.org/rec/conf/sp/BergerKP20",
            "abstract": "The IPv6 protocol was designed with security in mind. One of the changes that IPv6 has introduced over IPv4 is a new 20-bit flow label field in its protocol header.We show that remote servers can use the flow label field in order to assign a unique ID to each device when communicating with machines running Windows 10 (versions 1703 and higher), and Linux and Android (kernel versions 4.3 and higher). The servers are then able to associate the respective device IDs with subsequent transmissions sent from those machines. This identification is done by exploiting the flow label field generation logic and works across all browsers regardless of network changes. Furthermore, a variant of this attack also works passively, namely without actively triggering traffic from those machines.To design the attack we reverse-engineered and cryptanalyzed the Windows flow label generation code and inspected the Linux kernel flow label generation code. We provide a practical technique to partially extract the key used by each of these algorithms, and observe that this key can identify individual devices across networks, VPNs, browsers and privacy settings. We deployed a demo (for both Windows and Linux/Android) showing that key extraction and machine fingerprinting works in the wild, and tested it from networks around the world.",
            "keywords": [
                "IPv6 Protocol",
                "Flow Label Exploitation",
                "Device Fingerprinting",
                "Key Extraction",
                "Network Privacy"
            ]
        },
        "url": "URL#2326613",
        "sema_paperId": "4aeb5a7ceeec8d2173a3f396c6e617bc8936e879"
    },
    {
        "@score": "1",
        "@id": "2326614",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "189/5540",
                        "text": "Matthew Bernhard"
                    },
                    {
                        "@pid": "205/2107",
                        "text": "Allison McDonald"
                    },
                    {
                        "@pid": "272/8287",
                        "text": "Henry Meng"
                    },
                    {
                        "@pid": "272/8306",
                        "text": "Jensen Hwa"
                    },
                    {
                        "@pid": "272/8289",
                        "text": "Nakul Bajaj"
                    },
                    {
                        "@pid": "69/5103-4",
                        "text": "Kevin Chang 0004"
                    },
                    {
                        "@pid": "h/JAlexHalderman",
                        "text": "J. Alex Halderman"
                    }
                ]
            },
            "title": "Can Voters Detect Malicious Manipulation of Ballot Marking Devices?",
            "venue": "SP",
            "pages": "679-694",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/BernhardMMHBCH20",
            "doi": "10.1109/SP40000.2020.00118",
            "ee": "https://doi.org/10.1109/SP40000.2020.00118",
            "url": "https://dblp.org/rec/conf/sp/BernhardMMHBCH20",
            "abstract": "Ballot marking devices (BMDs) allow voters to select candidates on a computer kiosk, which prints a paper ballot that the voter can review before inserting it into a scanner to be tabulated. Unlike paperless voting machines, BMDs provide voters an opportunity to verify an auditable physical record of their choices, and a growing number of U.S. jurisdictions are adopting them for all voters. However, the security of BMDs depends on how reliably voters notice and correct any adversarially induced errors on their printed ballots. In order to measure voters\u2019 error detection abilities, we conducted a large study (N = 241) in a realistic polling place setting using real voting machines that we modified to introduce an error into each printout. Without intervention, only 40% of participants reviewed their printed ballots at all, and only 6.6% told a poll worker something was wrong. We also find that carefully designed interventions can improve verification performance. Verbally instructing voters to review the printouts and providing a written slate of candidates for whom to vote both significantly increased review and reporting rates\u2014although the improvements may not be large enough to provide strong security in close elections, especially when BMDs are used by all voters. Based on these findings, we make several evidence-based recommendations to help better defend BMD-based elections.",
            "keywords": [
                "Ballot Marking Devices",
                "Voter Verification",
                "Election Security",
                "Error Detection",
                "Malicious Manipulation"
            ]
        },
        "url": "URL#2326614",
        "sema_paperId": "8f9a0520333a0a3c567d12d28d19a45b7b862f5d"
    },
    {
        "@score": "1",
        "@id": "2326616",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "203/4291",
                        "text": "Sean Bowe"
                    },
                    {
                        "@pid": "27/8534",
                        "text": "Alessandro Chiesa"
                    },
                    {
                        "@pid": "74/4531-1",
                        "text": "Matthew Green 0001"
                    },
                    {
                        "@pid": "129/9500",
                        "text": "Ian Miers"
                    },
                    {
                        "@pid": "161/3103",
                        "text": "Pratyush Mishra"
                    },
                    {
                        "@pid": "192/8757",
                        "text": "Howard Wu"
                    }
                ]
            },
            "title": "ZEXE: Enabling Decentralized Private Computation.",
            "venue": "SP",
            "pages": "947-964",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/BoweC0MMW20",
            "doi": "10.1109/SP40000.2020.00050",
            "ee": "https://doi.org/10.1109/SP40000.2020.00050",
            "url": "https://dblp.org/rec/conf/sp/BoweC0MMW20",
            "abstract": "Ledger-based systems that support rich applications often suffer from two limitations. First, validating a transaction requires re-executing the state transition that it attests to. Second, transactions not only reveal which application had a state transition but also reveal the application\u2019s internal state.We design, implement, and evaluate ZEXE, a ledger-based system where users can execute offline computations and subsequently produce transactions, attesting to the correctness of these computations, that satisfy two main properties. First, transactions hide all information about the offline computations. Second, transactions can be validated in constant time by anyone, regardless of the offline computation.The core of ZEXE is a construction for a new cryptographic primitive that we introduce, decentralized private computation (DPC) schemes. In order to achieve an efficient implementation of our construction, we leverage tools in the area of cryptographic proofs, including succinct zero knowledge proofs and recursive proof composition. Overall, transactions in ZEXE are 968 bytes regardless of the offline computation, and generating them takes less than 1min plus a time that grows with the offline computation.We demonstrate how to use ZEXE to realize privacy-preserving analogues of popular applications: private user-defined assets and private decentralized exchanges for these assets.",
            "keywords": [
                "Decentralized Private Computation",
                "Ledger-based Systems",
                "Privacy-preserving Transactions",
                "Cryptographic Proofs",
                "Succinct Zero Knowledge Proofs"
            ]
        },
        "url": "URL#2326616",
        "sema_paperId": "91e91df4bdf9a6afe64c55d44b58e5e431b7c9a0"
    },
    {
        "@score": "1",
        "@id": "2326617",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "137/8806",
                        "text": "Tegan Brennan"
                    },
                    {
                        "@pid": "94/7855",
                        "text": "Nicol\u00e1s Rosner"
                    },
                    {
                        "@pid": "07/3368",
                        "text": "Tevfik Bultan"
                    }
                ]
            },
            "title": "JIT Leaks: Inducing Timing Side Channels through Just-In-Time Compilation.",
            "venue": "SP",
            "pages": "1207-1222",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/BrennanRB20",
            "doi": "10.1109/SP40000.2020.00007",
            "ee": "https://doi.org/10.1109/SP40000.2020.00007",
            "url": "https://dblp.org/rec/conf/sp/BrennanRB20",
            "abstract": "Side-channel vulnerabilities in software are caused by an observable imbalance in resource usage across different program paths. We show that just-in-time (JIT) compilation, which is crucial to the runtime performance of modern interpreted languages, can introduce timing side channels in cases where the input distribution to the program is non-uniform. Such timing channels can enable an attacker to infer potentially sensitive information about predicates on the program input.We define three attack models under which such side channels are harnessable and five vulnerability templates to detect susceptible code fragments and predicates. We also propose profiling algorithms to generate the representative statistical information necessary for the attacker to perform accurate inference.We systematically evaluate the strength of these JIT-based side channels on the java.lang.String, java.lang.Math, and java.math.BigInteger classes from the Java standard library, and on the JavaScript built-in objects String, Math, and Array. We carry out our evaluation using two widely adopted, open-source, JIT-enhanced runtime engines for the Java and JavaScript languages: the Oracle HotSpot Java Virtual Machine and the Google V8 JavaScript engine, respectively.Finally, we demonstrate a few examples of JIT-based side channels in the Apache Shiro security framework and the GraphHopper route planning server, and show that they are observable over the public Internet.",
            "keywords": [
                "Just-In-Time Compilation",
                "Timing Side Channels",
                "Side-Channel Vulnerabilities",
                "Input Distribution",
                "Vulnerability Detection"
            ]
        },
        "url": "URL#2326617",
        "sema_paperId": "4095233bff5e86170ef05bc884dd189f0260d148"
    },
    {
        "@score": "1",
        "@id": "2326618",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "167/1573",
                        "text": "Jo Van Bulck"
                    },
                    {
                        "@pid": "241/6242",
                        "text": "Daniel Moghimi"
                    },
                    {
                        "@pid": "08/1117-1",
                        "text": "Michael Schwarz 0001"
                    },
                    {
                        "@pid": "172/1127",
                        "text": "Moritz Lipp"
                    },
                    {
                        "@pid": "198/6796",
                        "text": "Marina Minkin"
                    },
                    {
                        "@pid": "98/8283",
                        "text": "Daniel Genkin"
                    },
                    {
                        "@pid": "90/10901",
                        "text": "Yuval Yarom"
                    },
                    {
                        "@pid": "91/465",
                        "text": "Berk Sunar"
                    },
                    {
                        "@pid": "166/1494",
                        "text": "Daniel Gruss"
                    },
                    {
                        "@pid": "85/6647",
                        "text": "Frank Piessens"
                    }
                ]
            },
            "title": "LVI: Hijacking Transient Execution through Microarchitectural Load Value Injection.",
            "venue": "SP",
            "pages": "54-72",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/BulckM0LMGYSGP20",
            "doi": "10.1109/SP40000.2020.00089",
            "ee": "https://doi.org/10.1109/SP40000.2020.00089",
            "url": "https://dblp.org/rec/conf/sp/BulckM0LMGYSGP20",
            "abstract": "The recent Spectre attack first showed how to inject incorrect branch targets into a victim domain by poisoning microarchitectural branch prediction history. In this paper, we generalize injection-based methodologies to the memory hierarchy by directly injecting incorrect, attacker-controlled values into a victim\u2019s transient execution. We propose Load Value Injection (LVI) as an innovative technique to reversely exploit Meltdown-type microarchitectural data leakage. LVI abuses that faulting or assisted loads, executed by a legitimate victim program, may transiently use dummy values or poisoned data from various microarchitectural buffers, before eventually being re-issued by the processor. We show how LVI gadgets allow to expose victim secrets and hijack transient control flow. We practically demonstrate LVI in several proof-of-concept attacks against Intel SGX enclaves, and we discuss implications for traditional user process and kernel isolation. State-of-the-art Meltdown and Spectre defenses, including widespread silicon-level and microcode mitigations, are orthogonal to our novel LVI techniques. LVI drastically widens the spectrum of incorrect transient paths. Fully mitigating our attacks requires serializing the processor pipeline with lfence instructions after possibly every memory load. Additionally and even worse, due to implicit loads, certain instructions have to be blacklisted, including the ubiquitous x86 ret instruction. Intel plans compiler and assembler-based full mitigations that will allow at least SGX enclave programs to remain secure on LVI-vulnerable systems. Depending on the application and optimization strategy, we observe extensive overheads of factor 2 to 19 for prototype implementations of the full mitigation.",
            "keywords": [
                "Microarchitectural Attacks",
                "Load Value Injection",
                "Transient Execution",
                "Meltdown Exploitation",
                "Intel SGX Vulnerabilities"
            ]
        },
        "url": "URL#2326618",
        "sema_paperId": "5cbf634d4308a30b2cddb4c769056750233ddaf6"
    },
    {
        "@score": "1",
        "@id": "2326619",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "161/0070",
                        "text": "Benedikt B\u00fcnz"
                    },
                    {
                        "@pid": "209/8649",
                        "text": "Lucianna Kiffer"
                    },
                    {
                        "@pid": "145/1016",
                        "text": "Loi Luu"
                    },
                    {
                        "@pid": "27/7672",
                        "text": "Mahdi Zamani"
                    }
                ]
            },
            "title": "FlyClient: Super-Light Clients for Cryptocurrencies.",
            "venue": "SP",
            "pages": "928-946",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/BunzKLZ20",
            "doi": "10.1109/SP40000.2020.00049",
            "ee": "https://doi.org/10.1109/SP40000.2020.00049",
            "url": "https://dblp.org/rec/conf/sp/BunzKLZ20",
            "abstract": "To validate transactions, cryptocurrencies such as Bitcoin and Ethereum require nodes to verify that a blockchain is valid. This entails downloading and verifying all blocks, taking hours and requiring gigabytes of bandwidth and storage. Hence, clients with limited resources cannot verify transactions independently without trusting full nodes. Bitcoin and Ethereum offer light clients known as simplified payment verification (SPV) clients, that can verify the chain by downloading only the block headers. Unfortunately, the storage and bandwidth requirements of SPV clients still increase linearly with the chain length. For example, as of July 2019, an SPV client in Ethereum needs to download and store about 4 GB of data.Recently, Kiayias et al. proposed a solution known as noninteractive proofs of proof-of-work (NIPoPoW) that allows a light client to download and store only a polylogarithmic number of block headers in expectation. Unfortunately, NIPoPoWs are succinct only as long as no adversary influences the honest chain, and can only be used in chains with fixed block difficulty, contrary to most cryptocurrencies which adjust block difficulty frequently according to the network hashrate.We introduce FlyClient, a novel transaction verification light client for chains of variable difficulty. FlyClient is efficient both asymptotically and practically and requires downloading only a logarithmic number of block headers while storing only a single block header between executions. Using an optimal probabilistic block sampling protocol and Merkle Mountain Range (MMR) commitments, FlyClient overcomes the limitations of NIPoPoWs and generates shorter proofs over all measured parameters. In Ethereum, FlyClient achieves a synchronization proof size of less than 500 KB which is roughly 6,600x smaller than SPV proofs. We finally discuss how FlyClient can be deployed with minimal changes to the existing cryptocurrencies via an uncontentious velvet fork.",
            "pdf_url": "",
            "keywords": [
                "Cryptocurrency Light Clients",
                "Transaction Verification",
                "Variable Difficulty",
                "FlyClient",
                "NIPoPoW"
            ]
        },
        "url": "URL#2326619"
    },
    {
        "@score": "1",
        "@id": "2326621",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "255/2388",
                        "text": "David Cerdeira"
                    },
                    {
                        "@pid": "07/967-1",
                        "text": "Nuno Santos 0001"
                    },
                    {
                        "@pid": "11/3119-1",
                        "text": "Pedro Fonseca 0001"
                    },
                    {
                        "@pid": "170/0331",
                        "text": "Sandro Pinto 0001"
                    }
                ]
            },
            "title": "SoK: Understanding the Prevailing Security Vulnerabilities in TrustZone-assisted TEE Systems.",
            "venue": "SP",
            "pages": "1416-1432",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/Cerdeira0FP20",
            "doi": "10.1109/SP40000.2020.00061",
            "ee": "https://doi.org/10.1109/SP40000.2020.00061",
            "url": "https://dblp.org/rec/conf/sp/Cerdeira0FP20",
            "abstract": "Hundreds of millions of mobile devices worldwide rely on Trusted Execution Environments (TEEs) built with Arm TrustZone for the protection of security-critical applications (e.g., DRM) and operating system (OS) components (e.g., Android keystore). TEEs are often assumed to be highly secure; however, over the past years, TEEs have been successfully attacked multiple times, with highly damaging impact across various platforms. Unfortunately, these attacks have been possible by the presence of security flaws in TEE systems. In this paper, we aim to understand which types of vulnerabilities and limitations affect existing TrustZone-assisted TEE systems, what are the main challenges to build them correctly, and what contributions can be borrowed from the research community to overcome them. To this end, we present a security analysis of popular TrustZone-assisted TEE systems (targeting Cortex-A processors) developed by Qualcomm, Trustonic, Huawei, Nvidia, and Linaro. By studying publicly documented exploits and vulnerabilities as well as by reverse engineering the TEE firmware, we identified several critical vulnerabilities across existing systems which makes it legitimate to raise reasonable concerns about the security of commercial TEE implementations.",
            "keywords": [
                "Trusted Execution Environments",
                "Arm TrustZone",
                "Security Vulnerabilities",
                "TEE Firmware Analysis",
                "Commercial TEE Implementations"
            ]
        },
        "url": "URL#2326621",
        "sema_paperId": "a6207c415ac99b662c09547896169ba8a8090bbc"
    },
    {
        "@score": "1",
        "@id": "2326624",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "30/7449",
                        "text": "Jianbo Chen"
                    },
                    {
                        "@pid": "j/MichaelIJordan",
                        "text": "Michael I. Jordan"
                    },
                    {
                        "@pid": "48/6396",
                        "text": "Martin J. Wainwright"
                    }
                ]
            },
            "title": "HopSkipJumpAttack: A Query-Efficient Decision-Based Attack.",
            "venue": "SP",
            "pages": "1277-1294",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/ChenJW20",
            "doi": "10.1109/SP40000.2020.00045",
            "ee": "https://doi.org/10.1109/SP40000.2020.00045",
            "url": "https://dblp.org/rec/conf/sp/ChenJW20",
            "abstract": "The goal of a decision-based adversarial attack on a trained model is to generate adversarial examples based solely on observing output labels returned by the targeted model. We develop HopSkipJumpAttack, a family of algorithms based on a novel estimate of the gradient direction using binary information at the decision boundary. The proposed family includes both untargeted and targeted attacks optimized for \u2113 and \u2113\u221e similarity metrics respectively. Theoretical analysis is provided for the proposed algorithms and the gradient direction estimate. Experiments show HopSkipJumpAttack requires significantly fewer model queries than several state-of-the-art decision-based adversarial attacks. It also achieves competitive performance in attacking several widely-used defense mechanisms.",
            "keywords": [
                "Adversarial Attacks",
                "Decision-Based Attacks",
                "Gradient Estimation",
                "Model Queries",
                "Adversarial Examples"
            ]
        },
        "url": "URL#2326624",
        "sema_paperId": "493d5f344eea1468260946b29a80dc81b2be409c"
    },
    {
        "@score": "1",
        "@id": "2326625",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "89/8201",
                        "text": "Yaohui Chen"
                    },
                    {
                        "@pid": "83/6353",
                        "text": "Peng Li"
                    },
                    {
                        "@pid": "90/514-24",
                        "text": "Jun Xu 0024"
                    },
                    {
                        "@pid": "162/3606",
                        "text": "Shengjian Guo"
                    },
                    {
                        "@pid": "148/1300",
                        "text": "Rundong Zhou"
                    },
                    {
                        "@pid": "32/9374",
                        "text": "Yulong Zhang"
                    },
                    {
                        "@pid": "64/5099",
                        "text": "Tao Wei"
                    },
                    {
                        "@pid": "81/7428",
                        "text": "Long Lu"
                    }
                ]
            },
            "title": "SAVIOR: Towards Bug-Driven Hybrid Testing.",
            "venue": "SP",
            "pages": "1580-1596",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/ChenLXGZZWL20",
            "doi": "10.1109/SP40000.2020.00002",
            "ee": "https://doi.org/10.1109/SP40000.2020.00002",
            "url": "https://dblp.org/rec/conf/sp/ChenLXGZZWL20",
            "abstract": "Hybrid testing combines fuzz testing and concolic execution. It leverages fuzz testing to test easy-to-reach code regions and uses concolic execution to explore code blocks guarded by complex branch conditions. As a result, hybrid testing is able to reach deeper into program state space than fuzz testing or concolic execution alone. Recently, hybrid testing has seen significant advancement. However, its code coverage-centric design is inefficient in vulnerability detection. First, it blindly selects seeds for concolic execution and aims to explore new code continuously. However, as statistics show, a large portion of the explored code is often bug-free. Therefore, giving equal attention to every part of the code during hybrid testing is a non-optimal strategy. It slows down the detection of real vulnerabilities by over 43%. Second, classic hybrid testing quickly moves on after reaching a chunk of code, rather than examining the hidden defects inside. It may frequently miss subtle vulnerabilities despite that it has already explored the vulnerable code paths.We propose SAVIOR, a new hybrid testing framework pioneering a bug-driven principle. Unlike the existing hybrid testing tools, SAVIOR prioritizes the concolic execution of the seeds that are likely to uncover more vulnerabilities. Moreover, SAVIOR verifies all vulnerable program locations along the executing program path. By modeling faulty situations using SMT constraints, SAVIOR reasons the feasibility of vulnerabilities and generates concrete test cases as proofs. Our evaluation shows that the bug-driven approach outperforms mainstream automated testing techniques, including state-of-the-art hybrid testing systems driven by code coverage. On average, SAVIOR detects vulnerabilities 43.4% faster than DRILLER and 44.3% faster than QSYM, leading to the discovery of 88 and 76 more unique bugs, respectively. According to the evaluation on 11 well fuzzed benchmark programs, within the first 24 hours, SAVIOR triggers 481 UBSAN violations, among which 243 are real bugs.",
            "pdf_url": "",
            "keywords": [
                "Hybrid Testing",
                "Fuzz Testing",
                "Concolic Execution",
                "Vulnerability Detection",
                "Bug-Driven Testing"
            ]
        },
        "url": "URL#2326625"
    },
    {
        "@score": "1",
        "@id": "2326627",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "272/8273",
                        "text": "Eunyong Cheon"
                    },
                    {
                        "@pid": "76/104",
                        "text": "Yonghwan Shin"
                    },
                    {
                        "@pid": "58/3207",
                        "text": "Jun Ho Huh"
                    },
                    {
                        "@pid": "64/5383",
                        "text": "Hyoungshick Kim"
                    },
                    {
                        "@pid": "76/3174",
                        "text": "Ian Oakley"
                    }
                ]
            },
            "title": "Gesture Authentication for Smartphones: Evaluation of Gesture Password Selection Policies.",
            "venue": "SP",
            "pages": "249-267",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/CheonSHKO20",
            "doi": "10.1109/SP40000.2020.00034",
            "ee": "https://doi.org/10.1109/SP40000.2020.00034",
            "url": "https://dblp.org/rec/conf/sp/CheonSHKO20",
            "abstract": "Touchscreen gestures are attracting research attention as an authentication method. While studies have showcased their usability, it has proven more complex to determine, let alone enhance, their security. Problems stem both from the small scale of current data sets and the fact that gestures are matched imprecisely \u2013 by a distance metric. This makes it challenging to assess entropy with traditional algorithms. To address these problems, we captured a large set of gesture passwords (N=2594) from crowd workers, and developed a security assessment framework that can calculate partial guessing entropy estimates, and generate dictionaries that crack 23.13% or more gestures in online attacks (within 20 guesses). To improve the entropy of gesture passwords, we designed novel blacklist and lexical policies to, respectively, restrict and inspire gesture creation. We close by validating both our security assessment framework and policies in a new crowd-sourced study (N=4000). Our blacklists increase entropy and resistance to dictionary based guessing attacks.",
            "keywords": [
                "Gesture Authentication",
                "Touchscreen Gestures",
                "Password Security",
                "Entropy Assessment",
                "Dictionary Attacks"
            ]
        },
        "url": "URL#2326627",
        "sema_paperId": "737718f77de243c5c8d3dd353533a9822db2dcaa"
    },
    {
        "@score": "1",
        "@id": "2326630",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "170/3520",
                        "text": "Shaanan Cohney"
                    },
                    {
                        "@pid": "176/8068",
                        "text": "Andrew Kwong"
                    },
                    {
                        "@pid": "265/8863",
                        "text": "Shahar Paz"
                    },
                    {
                        "@pid": "98/8283",
                        "text": "Daniel Genkin"
                    },
                    {
                        "@pid": "12/3207",
                        "text": "Nadia Heninger"
                    },
                    {
                        "@pid": "180/7297",
                        "text": "Eyal Ronen"
                    },
                    {
                        "@pid": "90/10901",
                        "text": "Yuval Yarom"
                    }
                ]
            },
            "title": "Pseudorandom Black Swans: Cache Attacks on CTR_DRBG.",
            "venue": "SP",
            "pages": "1241-1258",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/CohneyKPGHRY20",
            "doi": "10.1109/SP40000.2020.00046",
            "ee": "https://doi.org/10.1109/SP40000.2020.00046",
            "url": "https://dblp.org/rec/conf/sp/CohneyKPGHRY20",
            "abstract": "Modern cryptography requires the ability to securely generate pseudorandom numbers. However, despite decades of work on side-channel attacks, there is little discussion of their application to pseudorandom number generators (PRGs). In this work we set out to address this gap, empirically evaluating the side-channel resistance of common PRG implementations.We find that hard-learned lessons about side-channel leakage from encryption primitives have not been applied to PRGs, at all abstraction levels. At the design level, the NIST-recommended CTR_DRBG does not have forward security if an attacker is able to compromise the state (e.g., via a side-channel). At the primitive level, popular implementations of CTR_DRBG such as OpenSSL\u2019s FIPS module and NetBSD\u2019s kernel use leaky T-table AES as their underlying cipher, enabling cache side-channel attacks. Finally, we find that many implementations make parameter choices that enable an attacker to fully exploit side-channels and recover secret keys from TLS connections.We empirically demonstrate our attack in two scenarios. First, we carry out a cache attack that recovers the private state from vulnerable CTR_DRBG implementations when the TLS client connects to an attacker-controlled server. We then subsequently use the recovered state to compute the client\u2019s long-term authentication keys, thereby allowing the attacker to impersonate the client. In the second scenario, we show that an attacker can exploit the high temporal resolution provided by Intel SGX to carry out a blind attack to recover CTR_DRBG\u2019s state within three AES encryptions, without viewing output, and thus decrypt passively collected TLS connections from the victim.",
            "keywords": [
                "Pseudorandom Number Generators",
                "Side-Channel Attacks",
                "CTR_DRBG",
                "Cache Attacks",
                "TLS Vulnerabilities"
            ]
        },
        "url": "URL#2326630",
        "sema_paperId": "d25db494baeafe4f63994582678256c048ea2054"
    },
    {
        "@score": "1",
        "@id": "2326631",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "172/8756",
                        "text": "Lucian Cojocar"
                    },
                    {
                        "@pid": "148/9733",
                        "text": "Jeremie S. Kim"
                    },
                    {
                        "@pid": "147/0857",
                        "text": "Minesh Patel"
                    },
                    {
                        "@pid": "178/4784",
                        "text": "Lillian Tsai"
                    },
                    {
                        "@pid": "17/3782",
                        "text": "Stefan Saroiu"
                    },
                    {
                        "@pid": "06/915",
                        "text": "Alec Wolman"
                    },
                    {
                        "@pid": "m/OnurMutlu",
                        "text": "Onur Mutlu"
                    }
                ]
            },
            "title": "Are We Susceptible to Rowhammer? An End-to-End Methodology for Cloud Providers.",
            "venue": "SP",
            "pages": "712-728",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/CojocarKPTSWM20",
            "doi": "10.1109/SP40000.2020.00085",
            "ee": "https://doi.org/10.1109/SP40000.2020.00085",
            "url": "https://dblp.org/rec/conf/sp/CojocarKPTSWM20",
            "abstract": "Cloud providers are concerned that Rowhammer poses a potentially critical threat to their servers, yet today they lack a systematic way to test whether the DRAM used in their servers is vulnerable to Rowhammer attacks. This paper presents an endto-end methodology to determine if cloud servers are susceptible to these attacks. With our methodology, a cloud provider can construct worst-case testing conditions for DRAM.We apply our methodology to three classes of servers from a major cloud provider. Our findings show that none of the CPU instruction sequences used in prior work to mount Rowhammer attacks create worst-case DRAM testing conditions. To address this limitation, we develop an instruction sequence that leverages microarchitectural side-effects to \"hammer\" DRAM at a near-optimal rate on modern Intel Skylake and Cascade Lake platforms. We also design a DDR4 fault injector that can reverse engineer row adjacency for any DDR4 DIMM. When applied to our cloud provider's DIMMs, we find that DRAM rows do not always follow a linear map.",
            "pdf_url": "",
            "keywords": [
                "Rowhammer",
                "Cloud Computing",
                "DRAM Vulnerability",
                "Microarchitectural Side-Effects",
                "Fault Injection"
            ]
        },
        "url": "URL#2326631"
    },
    {
        "@score": "1",
        "@id": "2326632",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "249/2786",
                        "text": "Marco Cominelli"
                    },
                    {
                        "@pid": "59/4302",
                        "text": "Francesco Gringoli"
                    },
                    {
                        "@pid": "03/7603",
                        "text": "Paul Patras"
                    },
                    {
                        "@pid": "272/8285",
                        "text": "Margus Lind"
                    },
                    {
                        "@pid": "25/5432",
                        "text": "Guevara Noubir"
                    }
                ]
            },
            "title": "Even Black Cats Cannot Stay Hidden in the Dark: Full-band De-anonymization of Bluetooth Classic Devices.",
            "venue": "SP",
            "pages": "534-548",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/CominelliGPLN20",
            "doi": "10.1109/SP40000.2020.00091",
            "ee": "https://doi.org/10.1109/SP40000.2020.00091",
            "url": "https://dblp.org/rec/conf/sp/CominelliGPLN20",
            "abstract": "Bluetooth Classic (BT) remains the de facto connectivity technology in car stereo systems, wireless headsets, laptops, and a plethora of wearables, especially for applications that require high data rates, such as audio streaming, voice calling, tethering, etc. Unlike in Bluetooth Low Energy (BLE), where address randomization is a feature available to manufactures, BT addresses are not randomized because they are largely believed to be immune to tracking attacks. We analyze the design of BT and devise a robust de-anonymization technique that hinges on the apparently benign information leaking from frame encoding, to infer a piconet\u2019s clock, hopping sequence, and ultimately the Upper Address Part (UAP) of the master device\u2019s physical address, which are never exchanged in clear. Used together with the Lower Address Part (LAP), which is present in all frames transmitted, this enables tracking of the piconet master, thereby debunking the privacy guarantees of BT. We validate this attack by developing the first Software-defined Radio (SDR) based sniffer that allows full BT spectrum analysis (79 MHz) and implements the proposed de-anonymization technique. We study the feasibility of privacy attacks with multiple testbeds, considering different numbers of devices, traffic regimes, and communication ranges. We demonstrate that it is possible to track BT devices up to 85 meters from the sniffer, and achieve more than 80% device identification accuracy within less than 1 second of sniffing and 100% detection within less than 4 seconds. Lastly, we study the identified privacy attack in the wild, capturing BT traffic at a road junction over 5 days, demonstrating that our system can re-identify hundreds of users and infer their commuting patterns.",
            "keywords": [
                "Bluetooth Classic",
                "De-anonymization",
                "Device Tracking",
                "Privacy Attacks",
                "Piconet Master Identification"
            ]
        },
        "url": "URL#2326632",
        "sema_paperId": "4cee3687f40e3ef12a8fc876cccbb860976588c5"
    },
    {
        "@score": "1",
        "@id": "2326634",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "168/1849",
                        "text": "Philip Daian"
                    },
                    {
                        "@pid": "151/5205",
                        "text": "Steven Goldfeder"
                    },
                    {
                        "@pid": "239/5193",
                        "text": "Tyler Kell"
                    },
                    {
                        "@pid": "25/1892-2",
                        "text": "Yunqi Li 0002"
                    },
                    {
                        "@pid": "56/39",
                        "text": "Xueyuan Zhao"
                    },
                    {
                        "@pid": "24/508",
                        "text": "Iddo Bentov"
                    },
                    {
                        "@pid": "216/6355",
                        "text": "Lorenz Breidenbach"
                    },
                    {
                        "@pid": "j/AriJuels",
                        "text": "Ari Juels"
                    }
                ]
            },
            "title": "Flash Boys 2.0: Frontrunning in Decentralized Exchanges, Miner Extractable Value, and Consensus Instability.",
            "venue": "SP",
            "pages": "910-927",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/DaianGKLZBBJ20",
            "doi": "10.1109/SP40000.2020.00040",
            "ee": "https://doi.org/10.1109/SP40000.2020.00040",
            "url": "https://dblp.org/rec/conf/sp/DaianGKLZBBJ20",
            "abstract": "Blockchains, and specifically smart contracts, have promised to create fair and transparent trading ecosystems.Unfortunately, we show that this promise has not been met. We document and quantify the widespread and rising deployment of arbitrage bots in blockchain systems, specifically in decentralized exchanges (or \"DEXes\"). Like high-frequency traders on Wall Street, these bots exploit inefficiencies in DEXes, paying high transaction fees and optimizing network latency to frontrun, i.e., anticipate and exploit, ordinary users\u2019 DEX trades.We study the breadth of DEX arbitrage bots in a subset of transactions that yield quantifiable revenue to these bots. We also study bots\u2019 profit-making strategies, with a focus on blockchain-specific elements. We observe bots engage in what we call priority gas auctions (PGAs), competitively bidding up transaction fees in order to obtain priority ordering, i.e., early block position and execution, for their transactions. PGAs present an interesting and complex new continuous-time, partial-information, game-theoretic model that we formalize and study. We release an interactive web portal, frontrun.me, to provide the community with real-time data on PGAs.We additionally show that high fees paid for priority transaction ordering poses a systemic risk to consensus-layer security. We explain that such fees are just one form of a general phenomenon in DEXes and beyond\u2014what we call miner extractable value (MEV)\u2014that poses concrete, measurable, consensus-layer security risks. We show empirically that MEV poses a realistic threat to Ethereum today.Our work highlights the large, complex risks created by transaction-ordering dependencies in smart contracts and the ways in which traditional forms of financial-market exploitation are adapting to and penetrating blockchain economies.",
            "keywords": [
                "Decentralized Exchanges",
                "Frontrunning",
                "Miner Extractable Value",
                "Priority Gas Auctions",
                "Consensus Layer Security"
            ]
        },
        "url": "URL#2326634",
        "sema_paperId": "128a5c0ddd09c6d36ef5d483b6d140dfbbcb0ce3"
    },
    {
        "@score": "1",
        "@id": "2326635",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "219/7484",
                        "text": "Savino Dambra"
                    },
                    {
                        "@pid": "15/6037",
                        "text": "Leyla Bilge"
                    },
                    {
                        "@pid": "56/490",
                        "text": "Davide Balzarotti"
                    }
                ]
            },
            "title": "SoK: Cyber Insurance - Technical Challenges and a System Security Roadmap.",
            "venue": "SP",
            "pages": "1367-1383",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/DambraBB20",
            "doi": "10.1109/SP40000.2020.00019",
            "ee": "https://doi.org/10.1109/SP40000.2020.00019",
            "url": "https://dblp.org/rec/conf/sp/DambraBB20",
            "abstract": "Cyber attacks have increased in number and complexity in recent years, and companies and organizations have accordingly raised their investments in more robust infrastructure to preserve their data, assets and reputation. However, the full protection against these countless and constantly evolving threats is unattainable by the sole use of preventive measures. Therefore, to handle residual risks and contain business losses in case of an incident, firms are increasingly adopting a cyber insurance as part of their corporate risk management strategy.As a result, the cyber insurance sector \u2013 which offers to transfer the financial risks related to network and computer incidents to a third party \u2013 is rapidly growing, with recent claims that already reached a $100M dollars. However, while other insurance sectors rely on consolidated methodologies to accurately predict risks, the many peculiarities of the cyber domain resulted in carriers to often resort to qualitative approaches based on experts opinions.This paper looks at past research conducted in the area of cyber insurance and classifies previous studies in four different areas, focused respectively on studying the economical aspects, the mathematical models, the risk management methodologies, and the predictions of cyber events. We then identify, for each insurance phase, a group of practical research problems where security experts can help develop new data-driven methodologies and automated tools to replace the existing qualitative approaches.",
            "keywords": [
                "Cyber Insurance",
                "Risk Management",
                "Data-Driven Methodologies",
                "Financial Risk Transfer",
                "Cyber Event Prediction"
            ]
        },
        "url": "URL#2326635",
        "sema_paperId": "62f81eacb1dd4fe2f05b081010706e41b7016ca8"
    },
    {
        "@score": "1",
        "@id": "2326636",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "222/9411",
                        "text": "Lesly-Ann Daniel"
                    },
                    {
                        "@pid": "b/SebastienBardin",
                        "text": "S\u00e9bastien Bardin"
                    },
                    {
                        "@pid": "42/6705",
                        "text": "Tamara Rezk"
                    }
                ]
            },
            "title": "Binsec/Rel: Efficient Relational Symbolic Execution for Constant-Time at Binary-Level.",
            "venue": "SP",
            "pages": "1021-1038",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/DanielBR20",
            "doi": "10.1109/SP40000.2020.00074",
            "ee": "https://doi.org/10.1109/SP40000.2020.00074",
            "url": "https://dblp.org/rec/conf/sp/DanielBR20",
            "abstract": "The constant-time programming discipline (CT) is an efficient countermeasure against timing side-channel attacks, requiring the control flow and the memory accesses to be independent from the secrets. Yet, writing CT code is challenging as it demands to reason about pairs of execution traces (2-hypersafety property) and it is generally not preserved by the compiler, requiring binary-level analysis. Unfortunately, current verification tools for CT either reason at higher level (C or LLVM), or sacrifice bug-finding or bounded-verification, or do not scale. We tackle the problem of designing an efficient binary-level verification tool for CT providing both bug-finding and bounded-verification. The technique builds on relational symbolic execution enhanced with new optimizations dedicated to information flow and binary-level analysis, yielding a dramatic improvement over prior work based on symbolic execution. We implement a prototype, BINSEC/REL, and perform extensive experiments on a set of 338 cryptographic implementations, demonstrating the benefits of our approach in both bug-finding and bounded-verification. Using BINSEC/REL, we also automate a previous manual study of CT preservation by compilers. Interestingly, we discovered that gcc -O0 and backend passes of clang introduce violations of CT in implementations that were previously deemed secure by a state-of-the-art CT verification tool operating at LLVM level, showing the importance of reasoning at binary-level.",
            "pdf_url": "",
            "keywords": [
                "Constant-Time Programming",
                "Binary-Level Analysis",
                "Relational Symbolic Execution",
                "Timing Side-Channel Attacks",
                "Bug-Finding and Bounded-Verification"
            ]
        },
        "url": "URL#2326636"
    },
    {
        "@score": "1",
        "@id": "2326638",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "120/6314",
                        "text": "Luke Deshotels"
                    },
                    {
                        "@pid": "166/8961",
                        "text": "Costin Carabas"
                    },
                    {
                        "@pid": "272/8281",
                        "text": "Jordan Beichler"
                    },
                    {
                        "@pid": "38/7719",
                        "text": "Razvan Deaconescu"
                    },
                    {
                        "@pid": "22/4463",
                        "text": "William Enck"
                    }
                ]
            },
            "title": "Kobold: Evaluating Decentralized Access Control for Remote NSXPC Methods on iOS.",
            "venue": "SP",
            "pages": "1056-1070",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/DeshotelsCBDE20",
            "doi": "10.1109/SP40000.2020.00023",
            "ee": "https://doi.org/10.1109/SP40000.2020.00023",
            "url": "https://dblp.org/rec/conf/sp/DeshotelsCBDE20",
            "abstract": "Apple uses several access control mechanisms to prevent third party applications from directly accessing security sensitive resources, including sandboxing and file access control. However, third party applications may also indirectly access these resources using inter-process communication (IPC) with system daemons. If these daemons fail to properly enforce access control on IPC, confused deputy vulnerabilities may result. Identifying such vulnerabilities begins with an enumeration of all IPC services accessible to third party applications. However, the IPC interfaces and their corresponding access control policies are unknown and must be reverse engineered at a large scale. In this paper, we present the Kobold framework to study NSXPC-based system services using a combination of static and dynamic analysis. Using Kobold, we discovered multiple NSXPC services with confused deputy vulnerabilities and daemon crashes. Our findings include the ability to activate the microphone, disable access to all websites, and leak private data stored in iOS File Providers.",
            "keywords": [
                "Decentralized Access Control",
                "Inter-Process Communication",
                "NSXPC Services",
                "Confused Deputy Vulnerabilities",
                "iOS Security"
            ]
        },
        "url": "URL#2326638",
        "sema_paperId": "ce9fab6f249c1ec30105ea933ce174ede4c76e3e"
    },
    {
        "@score": "1",
        "@id": "2326639",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "194/2840",
                        "text": "Clemens Deu\u00dfer"
                    },
                    {
                        "@pid": "211/3812",
                        "text": "Steffen Passmann"
                    },
                    {
                        "@pid": "69/2809",
                        "text": "Thorsten Strufe"
                    }
                ]
            },
            "title": "Browsing Unicity: On the Limits of Anonymizing Web Tracking Data.",
            "venue": "SP",
            "pages": "777-790",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/DeusserPS20",
            "doi": "10.1109/SP40000.2020.00018",
            "ee": "https://doi.org/10.1109/SP40000.2020.00018",
            "url": "https://dblp.org/rec/conf/sp/DeusserPS20",
            "abstract": "Cross domain tracking has become the rule, rather than the exception, and scripts that collect behavioral data from visitors across sites have become ubiquitous on the Web. The collections form comprehensive profiles of browsing patterns and contain personal, sensitive information. This data can easily be linked back to the tracked individuals, most of whom are likely unaware of this information\u2019s mere existence, let alone its perpetual storage and processing. As public pressure has increased, tracking companies like Google, Facebook, or Baidu now claim to anonymize their datasets, thus limiting or eliminating the possibility of linking it back to data subjects.In cooperation with Europe\u2019s largest audience measurement association we use access to a comprehensive tracking dataset to assess both identifiability and the possibility of convincingly anonymizing browsing data. Our results show that anonymization through generalization does not sufficiently protect anonymity. Reducing unicity of browsing data to negligible levels would necessitate removal of all client and web domain information as well as click timings. In tangible adversary scenarios, supposedly anonymized datasets are highly vulnerable to dataset enrichment and shoulder surfing adversaries, with almost half of all browsing sessions being identified by just two observations. We conclude that while it may be possible to store single coarsened clicks anonymously, any collection of higher complexity will contain large amounts of pseudonymous data.",
            "keywords": [
                "Web Tracking",
                "Data Anonymization",
                "Cross-Domain Tracking",
                "Browsing Data Identifiability",
                "Pseudonymous Data Vulnerability"
            ]
        },
        "url": "URL#2326639",
        "sema_paperId": "432c56843259e9ef17f3dc13f78a7e6757238cd5"
    },
    {
        "@score": "1",
        "@id": "2326640",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "266/8877",
                        "text": "Sushant Dinesh"
                    },
                    {
                        "@pid": "157/1187",
                        "text": "Nathan Burow"
                    },
                    {
                        "@pid": "59/5539",
                        "text": "Dongyan Xu"
                    },
                    {
                        "@pid": "31/1273",
                        "text": "Mathias Payer"
                    }
                ]
            },
            "title": "RetroWrite: Statically Instrumenting COTS Binaries for Fuzzing and Sanitization.",
            "venue": "SP",
            "pages": "1497-1511",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/DineshBXP20",
            "doi": "10.1109/SP40000.2020.00009",
            "ee": "https://doi.org/10.1109/SP40000.2020.00009",
            "url": "https://dblp.org/rec/conf/sp/DineshBXP20",
            "abstract": "Analyzing the security of closed source binaries is currently impractical for end-users, or even developers who rely on third-party libraries. Such analysis relies on automatic vulnerability discovery techniques, most notably fuzzing with sanitizers enabled. The current state of the art for applying fuzzing or sanitization to binaries is dynamic binary translation, which has prohibitive performance overhead. The alternate technique, static binary rewriting, cannot fully recover symbolization information and hence has difficulty modifying binaries to track code coverage for fuzzing or to add security checks for sanitizers.The ideal solution for binary security analysis would be a static rewriter that can intelligently add the required instrumentation as if it were inserted at compile time. Such instrumentation requires an analysis to statically disambiguate between references and scalars, a problem known to be undecidable in the general case. We show that recovering this information is possible in practice for the most common class of software and libraries: 64-bit, position independent code. Based on this observation, we develop RetroWrite, a binary-rewriting instrumentation to support American Fuzzy Lop (AFL) and Address Sanitizer (ASan), and show that it can achieve compiler-level performance while retaining precision. Binaries rewritten for coverage-guided fuzzing using RetroWrite are identical in performance to compiler-instrumented binaries and outperform the default QEMU-based instrumentation by 4.5x while triggering more bugs. Our implementation of binary-only Address Sanitizer is 3x faster than Valgrind\u2019s memcheck, the state-of-the-art binary-only memory checker, and detects 80% more bugs in our evaluation.",
            "keywords": [
                "Binary Rewriting",
                "Fuzzing",
                "Static Instrumentation",
                "Address Sanitizer",
                "Vulnerability Detection"
            ]
        },
        "url": "URL#2326640",
        "sema_paperId": "845cafb153b0e4b9943c6d9b6a7e42c14845a0d6"
    },
    {
        "@score": "1",
        "@id": "2326642",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "236/5179",
                        "text": "Laura Edelson"
                    },
                    {
                        "@pid": "00/3175",
                        "text": "Tobias Lauinger"
                    },
                    {
                        "@pid": "58/4016",
                        "text": "Damon McCoy"
                    }
                ]
            },
            "title": "A Security Analysis of the Facebook Ad Library.",
            "venue": "SP",
            "pages": "661-678",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/EdelsonLM20",
            "doi": "10.1109/SP40000.2020.00084",
            "ee": "https://doi.org/10.1109/SP40000.2020.00084",
            "url": "https://dblp.org/rec/conf/sp/EdelsonLM20",
            "abstract": "Actors engaged in election disinformation are using online advertising platforms to spread political messages. In response to this threat, online advertising networks have started making political advertising on their platforms more transparent in order to enable third parties to detect malicious advertisers. We present a set of methodologies and perform a security analysis of Facebook\u2019s U.S. Ad Library, which is their political advertising transparency product. Unfortunately, we find that there are several weaknesses that enable a malicious advertiser to avoid accurate disclosure of their political ads. We also propose a clustering-based method to detect advertisers engaged in undeclared coordinated activity. Our clustering method identified 16 clusters of likely inauthentic communities that spent a total of over four million dollars on political advertising. This supports the idea that transparency could be a promising tool for combating disinformation. Finally, based on our findings, we make recommendations for improving the security of advertising transparency on Facebook and other platforms.",
            "keywords": [
                "Political Advertising Transparency",
                "Disinformation Detection",
                "Facebook Ad Library",
                "Malicious Advertisers",
                "Coordinated Activity Detection"
            ]
        },
        "url": "URL#2326642",
        "sema_paperId": "75c1442fe727c51ce2fcea70a6b0499fa73d5e83"
    },
    {
        "@score": "1",
        "@id": "2326644",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "18/10309",
                        "text": "Nathaniel Wesley Filardo"
                    },
                    {
                        "@pid": "239/8902",
                        "text": "Brett F. Gutstein"
                    },
                    {
                        "@pid": "136/3901",
                        "text": "Jonathan Woodruff"
                    },
                    {
                        "@pid": "181/0549",
                        "text": "Sam Ainsworth"
                    },
                    {
                        "@pid": "272/8269",
                        "text": "Lucian Paul-Trifu"
                    },
                    {
                        "@pid": "57/429",
                        "text": "Brooks Davis"
                    },
                    {
                        "@pid": "209/9036",
                        "text": "Hongyan Xia"
                    },
                    {
                        "@pid": "209/9047",
                        "text": "Edward Tomasz Napierala"
                    },
                    {
                        "@pid": "200/4453",
                        "text": "Alexander Richardson"
                    },
                    {
                        "@pid": "74/3740",
                        "text": "John Baldwin"
                    },
                    {
                        "@pid": "85/1618",
                        "text": "David Chisnall"
                    },
                    {
                        "@pid": "211/0885",
                        "text": "Jessica Clarke 0001"
                    },
                    {
                        "@pid": "22/4668",
                        "text": "Khilan Gudka"
                    },
                    {
                        "@pid": "189/1762",
                        "text": "Alexandre Joannou"
                    },
                    {
                        "@pid": "20/4458",
                        "text": "A. Theodore Markettos"
                    },
                    {
                        "@pid": "209/9026",
                        "text": "Alfredo Mazzinghi"
                    },
                    {
                        "@pid": "233/0169",
                        "text": "Robert M. Norton"
                    },
                    {
                        "@pid": "21/5870",
                        "text": "Michael Roe"
                    },
                    {
                        "@pid": "74/185",
                        "text": "Peter Sewell"
                    },
                    {
                        "@pid": "189/1765",
                        "text": "Stacey D. Son"
                    },
                    {
                        "@pid": "62/1131",
                        "text": "Timothy M. Jones 0001"
                    },
                    {
                        "@pid": "m/SimonWMoore",
                        "text": "Simon W. Moore"
                    },
                    {
                        "@pid": "n/PeterGNeumann",
                        "text": "Peter G. Neumann"
                    },
                    {
                        "@pid": "70/2118",
                        "text": "Robert N. M. Watson"
                    }
                ]
            },
            "title": "Cornucopia: Temporal Safety for CHERI Heaps.",
            "venue": "SP",
            "pages": "608-625",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/FilardoGWAPDXNR20",
            "doi": "10.1109/SP40000.2020.00098",
            "ee": "https://doi.org/10.1109/SP40000.2020.00098",
            "url": "https://dblp.org/rec/conf/sp/FilardoGWAPDXNR20",
            "abstract": "Use-after-free violations of temporal memory safety continue to plague software systems, underpinning many high-impact exploits. The CHERI capability system shows great promise in achieving C and C++ language spatial memory safety, preventing out-of-bounds accesses. Enforcing language-level temporal safety on CHERI requires capability revocation, traditionally achieved either via table lookups (avoided for performance in the CHERI design) or by identifying capabilities in memory to revoke them (similar to a garbage-collector sweep). CHERIvoke, a prior feasibility study, suggested that CHERI\u2019s tagged capabilities could make this latter strategy viable, but modeled only architectural limits and did not consider the full implementation or evaluation of the approach.Cornucopia is a lightweight capability revocation system for CHERI that implements non-probabilistic C/C++ temporal memory safety for standard heap allocations. It extends the CheriBSD virtual-memory subsystem to track capability flow through memory and provides a concurrent kernel-resident revocation service that is amenable to multi-processor and hardware acceleration. We demonstrate an average overhead of less than 2% and a worst-case of 8.9% for concurrent revocation on compatible SPEC CPU2006 benchmarks on a multi-core CHERI CPU on FPGA, and we validate Cornucopia against the Juliet test suite\u2019s corpus of temporally unsafe programs. We test its compatibility with a large corpus of C programs by using a revoking allocator as the system allocator while booting multi-user CheriBSD. Cornucopia is a viable strategy for always-on temporal heap memory safety, suitable for production environments.",
            "keywords": [
                "Temporal Memory Safety",
                "Capability Revocation",
                "CHERI Architecture",
                "Heap Memory Management",
                "Use-After-Free Vulnerabilities"
            ]
        },
        "url": "URL#2326644",
        "sema_paperId": "4ab15efe99624b33a4c82af2567b6086967758a8"
    },
    {
        "@score": "1",
        "@id": "2326645",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "200/8880",
                        "text": "Daniel Frassinelli"
                    },
                    {
                        "@pid": "272/8319",
                        "text": "Sohyeon Park"
                    },
                    {
                        "@pid": "45/1876",
                        "text": "Stefan N\u00fcrnberger"
                    }
                ]
            },
            "title": "I Know Where You Parked Last Summer : Automated Reverse Engineering and Privacy Analysis of Modern Cars.",
            "venue": "SP",
            "pages": "1401-1415",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/FrassinelliPN20",
            "doi": "10.1109/SP40000.2020.00081",
            "ee": "https://doi.org/10.1109/SP40000.2020.00081",
            "url": "https://dblp.org/rec/conf/sp/FrassinelliPN20",
            "abstract": "Nowadays, cars are equipped with hundreds of sensors and dozens of computers that process data. Unfortunately, due to the very secret nature of the automotive industry, there is no official nor objective source of information as to what data exactly their vehicles collect. Anecdotal evidence suggests that OEMs are collecting huge amounts of personal data about their drivers, which they suddenly reveal when requested in court.In this paper, we present our tool AutoCAN for privacy and security analysis of cars that reveals what data cars collect by tapping into in-vehicle networks and extracting time series of data and automatically making sense of them by establishing relationships based on laws of physics. These algorithms work irrespective of make, model or used protocols. Our results show that car makers track the GPS position, the number of occupants, their weight, usage statistics of doors, lights, and AC. We also reveal that OEMs embed functions to remotely disable the car or get an alert when the driver is speeding.",
            "keywords": [
                "Automotive Privacy",
                "Data Collection",
                "In-Vehicle Networks",
                "Sensor Data Analysis",
                "Remote Vehicle Control"
            ]
        },
        "url": "URL#2326645",
        "sema_paperId": "f974740440e60111bb079824208838a324a8b576"
    },
    {
        "@score": "1",
        "@id": "2326646",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "224/2335",
                        "text": "Pietro Frigo"
                    },
                    {
                        "@pid": "262/3667",
                        "text": "Emanuele Vannacci"
                    },
                    {
                        "@pid": "147/4013",
                        "text": "Hasan Hassan"
                    },
                    {
                        "@pid": "119/2260",
                        "text": "Victor van der Veen"
                    },
                    {
                        "@pid": "m/OnurMutlu",
                        "text": "Onur Mutlu"
                    },
                    {
                        "@pid": "75/8194",
                        "text": "Cristiano Giuffrida"
                    },
                    {
                        "@pid": "91/800",
                        "text": "Herbert Bos"
                    },
                    {
                        "@pid": "121/2685",
                        "text": "Kaveh Razavi"
                    }
                ]
            },
            "title": "TRRespass: Exploiting the Many Sides of Target Row Refresh.",
            "venue": "SP",
            "pages": "747-762",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/FrigoVHVMGBR20",
            "doi": "10.1109/SP40000.2020.00090",
            "ee": "https://doi.org/10.1109/SP40000.2020.00090",
            "url": "https://dblp.org/rec/conf/sp/FrigoVHVMGBR20",
            "abstract": "After a plethora of high-profile RowHammer attacks, CPU and DRAM vendors scrambled to deliver what was meant to be the definitive hardware solution against the RowHammer problem: Target Row Refresh (TRR). A common belief among practitioners is that, for the latest generation of DDR4 systems that are protected by TRR, RowHammer is no longer an issue in practice. However, in reality, very little is known about TRR. How does TRR exactly prevent RowHammer? Which parts of a system are responsible for operating the TRR mechanism? Does TRR completely solve the RowHammer problem or does it have weaknesses? In this paper, we demystify the inner workings of TRR and debunk its security guarantees. We show that what is advertised as a single mitigation mechanism is actually a series of different solutions coalesced under the umbrella term Target Row Refresh. We inspect and disclose, via a deep analysis, different existing TRR solutions and demonstrate that modern implementations operate entirely inside DRAM chips. Despite the difficulties of analyzing in-DRAM mitigations, we describe novel techniques for gaining insights into the operation of these mitigation mechanisms. These insights allow us to build TRRespass, a scalable black-box RowHammer fuzzer that we evaluate on 42 recent DDR4 modules. TRRespass shows that even the latest generation DDR4 chips with in-DRAM TRR, immune to all known RowHammer attacks, are often still vulnerable to new TRR-aware variants of RowHammer that we develop. In particular, TRRespass finds that, on present-day DDR4 modules, RowHammer is still possible when many aggressor rows are used (as many as 19 in some cases), with a method we generally refer to as Many-sided RowHammer. Overall, our analysis shows that 13 out of the 42 modules from all three major DRAM vendors (i.e., Samsung, Micron, and Hynix) are vulnerable to our TRR-aware RowHammer access patterns, and thus one can still mount existing state-of-the-art system-level RowHammer attacks. In addition to DDR4, we also experiment with LPDDR4(X)1 chips and show that they are susceptible to RowHammer bit flips too. Our results provide concrete evidence that the pursuit of better RowHammer mitigations must continue.",
            "keywords": [
                "RowHammer",
                "Target Row Refresh",
                "DRAM Vulnerabilities",
                "Memory Security",
                "Many-sided RowHammer"
            ]
        },
        "url": "URL#2326646",
        "sema_paperId": "6316e1473e478c5ff5099b3b3b77b529d36f9f77"
    },
    {
        "@score": "1",
        "@id": "2326647",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "220/5536",
                        "text": "Julien Gamba"
                    },
                    {
                        "@pid": "241/5097",
                        "text": "Mohammed Rashed"
                    },
                    {
                        "@pid": "149/9322",
                        "text": "Abbas Razaghpanah"
                    },
                    {
                        "@pid": "98/3527",
                        "text": "Juan Tapiador"
                    },
                    {
                        "@pid": "50/7563",
                        "text": "Narseo Vallina-Rodriguez"
                    }
                ]
            },
            "title": "An Analysis of Pre-installed Android Software.",
            "venue": "SP",
            "pages": "1039-1055",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/GambaRRTV20",
            "doi": "10.1109/SP40000.2020.00013",
            "ee": "https://doi.org/10.1109/SP40000.2020.00013",
            "url": "https://dblp.org/rec/conf/sp/GambaRRTV20",
            "abstract": "The open-source nature of the Android OS makes it possible for manufacturers to ship custom versions of the OS along with a set of pre-installed apps, often for product differentiation. Some device vendors have recently come under scrutiny for potentially invasive private data collection practices and other potentially harmful or unwanted behavior of the preinstalled apps on their devices. Yet, the landscape of preinstalled software in Android has largely remained unexplored, particularly in terms of the security and privacy implications of such customizations. In this paper, we present the first large- scale study of pre-installed software on Android devices from more than 200 vendors. Our work relies on a large dataset of real-world Android firmware acquired worldwide using crowd-sourcing methods. This allows us to answer questions related to the stakeholders involved in the supply chain, from device manufacturers and mobile network operators to third- party organizations like advertising and tracking services, and social network platforms. Our study allows us to also uncover relationships between these actors, which seem to revolve primarily around advertising and data-driven services. Overall, the supply chain around Android's open source model lacks transparency and has facilitated potentially harmful behaviors and backdoored access to sensitive data and services without user consent or awareness. We conclude the paper with recommendations to improve transparency, attribution, and accountability in the Android ecosystem.",
            "pdf_url": "",
            "keywords": [
                "Android OS Customization",
                "Pre-installed Apps",
                "Data Privacy",
                "Supply Chain Transparency",
                "User Consent"
            ]
        },
        "url": "URL#2326647"
    },
    {
        "@score": "1",
        "@id": "2326648",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "173/0112",
                        "text": "Ilias Giechaskiel"
                    },
                    {
                        "@pid": "01/4779",
                        "text": "Kasper Bonne Rasmussen"
                    },
                    {
                        "@pid": "66/8277",
                        "text": "Jakub Szefer"
                    }
                ]
            },
            "title": "C3APSULe: Cross-FPGA Covert-Channel Attacks through Power Supply Unit Leakage.",
            "venue": "SP",
            "pages": "1728-1741",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/GiechaskielRS20",
            "doi": "10.1109/SP40000.2020.00070",
            "ee": "https://doi.org/10.1109/SP40000.2020.00070",
            "url": "https://dblp.org/rec/conf/sp/GiechaskielRS20",
            "abstract": "Field-Programmable Gate Arrays (FPGAs) are versatile, reconfigurable integrated circuits that can be used as hardware accelerators to process highly-sensitive data. Leaking this data and associated cryptographic keys, however, can undermine a system\u2019s security. To prevent potentially unintentional interactions that could break separation of privilege between different data center tenants, FPGAs in cloud environments are currently dedicated on a per-user basis. Nevertheless, while the FPGAs themselves are not shared among different users, other parts of the data center infrastructure are. This paper specifically shows for the first time that powering FPGAs, CPUs, and GPUs through the same power supply unit (PSU) can be exploited in FPGA-to-FPGA, CPU-to-FPGA, and GPU-to-FPGA covert channels between independent boards. These covert channels can operate remotely, without the need for physical access to, or modifications of, the boards. To demonstrate the attacks, this paper uses a novel combination of \"sensing\" and \"stressing\" ring oscillators as receivers on the sink FPGA. Further, ring oscillators are used as transmitters on the source FPGA. The transmitting and receiving circuits are used to determine the presence of the leakage on off-the-shelf Xilinx boards containing Artix 7 and Kintex 7 FPGA chips. Experiments are conducted with PSUs by two vendors, as well as CPUs and GPUs of different generations. Moreover, different sizes and types of ring oscillators are also tested. In addition, this work discusses potential countermeasures to mitigate the impact of the cross-board leakage. The results of this paper highlight the dangers of shared power supply units in local and cloud FPGAs, and therefore a fundamental need to re-think FPGA security for shared infrastructures.",
            "keywords": [
                "FPGA Security",
                "Covert Channels",
                "Power Supply Unit Leakage",
                "Data Center Infrastructure",
                "Cross-Board Leakage"
            ]
        },
        "url": "URL#2326648",
        "sema_paperId": "b226d8f4017f9706d90c8f728df5c64133d6c1c8"
    },
    {
        "@score": "1",
        "@id": "2326649",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "118/6449",
                        "text": "Marco Guarnieri"
                    },
                    {
                        "@pid": "10/3908",
                        "text": "Boris K\u00f6pf"
                    },
                    {
                        "@pid": "03/305",
                        "text": "Jos\u00e9 F. Morales 0001"
                    },
                    {
                        "@pid": "67/3331",
                        "text": "Jan Reineke 0001"
                    },
                    {
                        "@pid": "232/3235",
                        "text": "Andr\u00e9s S\u00e1nchez"
                    }
                ]
            },
            "title": "Spectector: Principled Detection of Speculative Information Flows.",
            "venue": "SP",
            "pages": "1-19",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/GuarnieriKMRS20",
            "doi": "10.1109/SP40000.2020.00011",
            "ee": "https://doi.org/10.1109/SP40000.2020.00011",
            "url": "https://dblp.org/rec/conf/sp/GuarnieriKMRS20",
            "abstract": "Since the advent of Spectre, a number of counter-measures have been proposed and deployed. Rigorously reasoning about their effectiveness, however, requires a well-defined notion of security against speculative execution attacks, which has been missing until now.In this paper (1) we put forward speculative non-interference, the first semantic notion of security against speculative execution attacks, and (2) we develop Spectector, an algorithm based on symbolic execution to automatically prove speculative non-interference, or to detect violations.We implement Spectector in a tool, which we use to detect subtle leaks and optimizations opportunities in the way major compilers place Spectre countermeasures. A scalability analysis indicates that checking speculative non-interference does not exhibit fundamental bottlenecks beyond those inherited by symbolic execution.",
            "keywords": [
                "Speculative Execution",
                "Security Analysis",
                "Speculative Non-Interference",
                "Information Flow Leakage",
                "Symbolic Execution"
            ]
        },
        "url": "URL#2326649",
        "sema_paperId": "c8ee0eeb0d386ec3e11fdf5423acb8f3bd257461"
    },
    {
        "@score": "1",
        "@id": "2326650",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "85/10076-2",
                        "text": "Chun Guo 0002"
                    },
                    {
                        "@pid": "k/JonathanKatz",
                        "text": "Jonathan Katz"
                    },
                    {
                        "@pid": "150/9413",
                        "text": "Xiao Wang 0012"
                    },
                    {
                        "@pid": "33/0-1",
                        "text": "Yu Yu 0001"
                    }
                ]
            },
            "title": "Efficient and Secure Multiparty Computation from Fixed-Key Block Ciphers.",
            "venue": "SP",
            "pages": "825-841",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/GuoKW020",
            "doi": "10.1109/SP40000.2020.00016",
            "ee": "https://doi.org/10.1109/SP40000.2020.00016",
            "url": "https://dblp.org/rec/conf/sp/GuoKW020",
            "abstract": "Many implementations of secure computation use fixed-key AES (modeled as a random permutation); this results in substantial performance benefits due to existing hardware support for AES and the ability to avoid recomputing the AES key schedule. Surveying these implementations, however, we find that most utilize AES in a heuristic fashion; in the best case this leaves a gap in the security proof, but in many cases we show it allows for explicit attacks.Motivated by this unsatisfactory state of affairs, we initiate a comprehensive study of how to use fixed-key block ciphers for secure computation-in particular for OT extension and circuit garbling-efficiently and securely. Specifically: \u00b7 Weconsider several notions of pseudorandomness for hash functions (e.g., correlation robustness), and show provably secure schemes for OT extension, garbling, and other applications based on hash functions satisfying these notions. \u00b7 We provide provably secure constructions, in the (non-programmable) random-permutation model, of hash functions satisfying the different notions of pseudorandomness we consider. Taken together, our results provide end-to-end security proofs for implementations of secure-computation protocols based on fixed-key block ciphers (modeled as random permutations). Perhaps surprisingly, at the same time our work also results in noticeable performance improvements over the state-of-the-art.",
            "pdf_url": "",
            "keywords": [
                "Multiparty Computation",
                "Fixed-Key Block Ciphers",
                "Secure Computation",
                "OT Extension",
                "Circuit Garbling"
            ]
        },
        "url": "URL#2326650"
    },
    {
        "@score": "1",
        "@id": "2326653",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "175/6283",
                        "text": "Thomas Haines"
                    },
                    {
                        "@pid": "244/5552",
                        "text": "Sarah Jamie Lewis"
                    },
                    {
                        "@pid": "78/1061",
                        "text": "Olivier Pereira"
                    },
                    {
                        "@pid": "t/VanessaTeague",
                        "text": "Vanessa Teague"
                    }
                ]
            },
            "title": "How not to prove your election outcome.",
            "venue": "SP",
            "pages": "644-660",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/HainesLPT20",
            "doi": "10.1109/SP40000.2020.00048",
            "ee": "https://doi.org/10.1109/SP40000.2020.00048",
            "url": "https://dblp.org/rec/conf/sp/HainesLPT20",
            "abstract": "The Scytl/SwissPost e-voting solution was intended to provide complete verifiability for Swiss government elections. We show failures in both individual verifiability and universal verifiability (as defined in Swiss Federal Ordinance 161.116), based on mistaken implementations of cryptographic components. These failures allow for the construction of \"proofs\" of an accurate election outcome that pass verification though the votes have been manipulated. Using sophisticated cryptographic protocols without a proper consideration of what properties they offer, and under which conditions, can introduce opportunities for undetectable fraud even though the system appears to allow verification of the outcome.Our findings are immediately relevant to systems in use in Switzerland and Australia, and probably also elsewhere.",
            "keywords": [
                "E-voting Systems",
                "Cryptographic Protocols",
                "Verifiability",
                "Election Integrity",
                "Vote Manipulation"
            ]
        },
        "url": "URL#2326653",
        "sema_paperId": "dbb39f68d815099fdbad939bdcfe25c01c5f8698"
    },
    {
        "@score": "1",
        "@id": "2326655",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "157/1889-1",
                        "text": "Rakibul Hasan 0001"
                    },
                    {
                        "@pid": "c/DavidCrandall",
                        "text": "David J. Crandall"
                    },
                    {
                        "@pid": "07/5701",
                        "text": "Mario Fritz"
                    },
                    {
                        "@pid": "50/6916",
                        "text": "Apu Kapadia"
                    }
                ]
            },
            "title": "Automatically Detecting Bystanders in Photos to Reduce Privacy Risks.",
            "venue": "SP",
            "pages": "318-335",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/HasanCFK20",
            "doi": "10.1109/SP40000.2020.00097",
            "ee": "https://doi.org/10.1109/SP40000.2020.00097",
            "url": "https://dblp.org/rec/conf/sp/HasanCFK20",
            "abstract": "Photographs taken in public places often contain bystanders - people who are not the main subject of a photo. These photos, when shared online, can reach a large number of viewers and potentially undermine the bystanders\u2019 privacy. Furthermore, recent developments in computer vision and machine learning can be used by online platforms to identify and track individuals. To combat this problem, researchers have proposed technical solutions that require bystanders to be proactive and use specific devices or applications to broadcast their privacy policy and identifying information to locate them in an image.We explore the prospect of a different approach \u2013 identifying bystanders solely based on the visual information present in an image. Through an online user study, we catalog the rationale humans use to classify subjects and bystanders in an image, and systematically validate a set of intuitive concepts (such as intentionally posing for a photo) that can be used to automatically identify bystanders. Using image data, we infer those concepts and then use them to train several classifier models. We extensively evaluate the models and compare them with human raters. On our initial dataset, with a 10-fold cross validation, our best model achieves a mean detection accuracy of 93% for images when human raters have 100% agreement on the class label and 80% when the agreement is only 67%. We validate this model on a completely different dataset and achieve similar results, demonstrating that our model generalizes well.",
            "keywords": [
                "Bystander Detection",
                "Privacy Risks",
                "Computer Vision",
                "Image Classification",
                "User Study"
            ]
        },
        "url": "URL#2326655",
        "sema_paperId": "5fa89b222fc433847d422be9c32bdf115cc93b71"
    },
    {
        "@score": "1",
        "@id": "2326656",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "184/8086",
                        "text": "Wajih Ul Hassan"
                    },
                    {
                        "@pid": "126/3601",
                        "text": "Adam Bates 0001"
                    },
                    {
                        "@pid": "92/5876",
                        "text": "Daniel Marino"
                    }
                ]
            },
            "title": "Tactical Provenance Analysis for Endpoint Detection and Response Systems.",
            "venue": "SP",
            "pages": "1172-1189",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/Hassan0M20",
            "doi": "10.1109/SP40000.2020.00096",
            "ee": "https://doi.org/10.1109/SP40000.2020.00096",
            "url": "https://dblp.org/rec/conf/sp/Hassan0M20",
            "abstract": "Endpoint Detection and Response (EDR) tools provide visibility into sophisticated intrusions by matching system events against known adversarial behaviors. However, current solutions suffer from three challenges: 1) EDR tools generate a high volume of false alarms, creating backlogs of investigation tasks for analysts; 2) determining the veracity of these threat alerts requires tedious manual labor due to the overwhelming amount of low-level system logs, creating a \"needle-in-a-haystack\" problem; and 3) due to the tremendous resource burden of log retention, in practice the system logs describing long-lived attack campaigns are often deleted before an investigation is ever initiated.This paper describes an effort to bring the benefits of data provenance to commercial EDR tools. We introduce the notion of Tactical Provenance Graphs (TPGs) that, rather than encoding low-level system event dependencies, reason about causal dependencies between EDR-generated threat alerts. TPGs provide compact visualization of multi-stage attacks to analysts, accelerating investigation. To address EDR\u2019s false alarm problem, we introduce a threat scoring methodology that assesses risk based on the temporal ordering between individual threat alerts present in the TPG. In contrast to the retention of unwieldy system logs, we maintain a minimally-sufficient skeleton graph that can provide linkability between existing and future threat alerts. We evaluate our system, RapSheet, using the Symantec EDR tool in an enterprise environment. Results show that our approach can rank truly malicious TPGs higher than false alarm TPGs. Moreover, our skeleton graph reduces the long-term burden of log retention by up to 87%.",
            "keywords": [
                "Endpoint Detection and Response",
                "Tactical Provenance Graphs",
                "Threat Scoring",
                "False Alarms",
                "Log Retention"
            ]
        },
        "url": "URL#2326656",
        "sema_paperId": "670f07252b9936b3a8b3d3b3c5ad3602c3550210"
    },
    {
        "@score": "1",
        "@id": "2326658",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "227/8935",
                        "text": "Yuyu He"
                    },
                    {
                        "@pid": "97/8704-96",
                        "text": "Lei Zhang 0096"
                    },
                    {
                        "@pid": "55/11040",
                        "text": "Zhemin Yang"
                    },
                    {
                        "@pid": "28/8733",
                        "text": "Yinzhi Cao"
                    },
                    {
                        "@pid": "272/8304",
                        "text": "Keke Lian"
                    },
                    {
                        "@pid": "57/2281-6",
                        "text": "Shuai Li 0006"
                    },
                    {
                        "@pid": "03/1094-13",
                        "text": "Wei Yang 0013"
                    },
                    {
                        "@pid": "191/1165",
                        "text": "Zhibo Zhang"
                    },
                    {
                        "@pid": "02/1640-2",
                        "text": "Min Yang 0002"
                    },
                    {
                        "@pid": "48/2168-9",
                        "text": "Yuan Zhang 0009"
                    },
                    {
                        "@pid": "36/5143",
                        "text": "Haixin Duan"
                    }
                ]
            },
            "title": "TextExerciser: Feedback-driven Text Input Exercising for Android Applications.",
            "venue": "SP",
            "pages": "1071-1087",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/HeZYCLLYZYZD20",
            "doi": "10.1109/SP40000.2020.00071",
            "ee": "https://doi.org/10.1109/SP40000.2020.00071",
            "url": "https://dblp.org/rec/conf/sp/HeZYCLLYZYZD20",
            "abstract": "Dynamic analysis of Android apps is often used together with an exerciser to increase its code coverage. One big obstacle in designing such Android app exercisers comes from the existence of text-based inputs, which are often constrained by the nature of the input field, such as the length and character restrictions.In this paper, we propose TextExerciser, an iterative, feedback-driven text input exerciser, which generates text inputs for Android apps. Our key insight is that Android apps often provide feedback, called hints, for malformed inputs so that our system can utilize such hints to improve the input generation.We implemented a prototype of TextExerciser and evaluated it by comparing TextExerciser with state-of-the-art exercisers, such as The Monkey and DroidBot. Our evaluation shows that TextExerciser can achieve significantly higher code coverage and trigger more sensitive behaviors than these tools. We also combine TextExerciser with dynamic analysis tools and show they are able to detect more privacy leaks and vulnerabilities with TextExerciser than with existing exercisers. Particularly, existing tools, under the help of TextExerciser, find several new vulnerabilities, such as one user credential leak in a popular social app with more than 10,000,000 downloads.",
            "keywords": [
                "Android Application Testing",
                "Dynamic Analysis",
                "Text Input Generation",
                "Code Coverage",
                "Privacy Vulnerabilities"
            ]
        },
        "url": "URL#2326658",
        "sema_paperId": "82aca4f4edce8908eeecbad61f114ee0b059235c"
    },
    {
        "@score": "1",
        "@id": "2326660",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "188/6160",
                        "text": "Md Nahid Hossain"
                    },
                    {
                        "@pid": "175/8252",
                        "text": "Sanaz Sheikhi"
                    },
                    {
                        "@pid": "90/1136-1",
                        "text": "R. Sekar 0001"
                    }
                ]
            },
            "title": "Combating Dependence Explosion in Forensic Analysis Using Alternative Tag Propagation Semantics.",
            "venue": "SP",
            "pages": "1139-1155",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/HossainSS20",
            "doi": "10.1109/SP40000.2020.00064",
            "ee": "https://doi.org/10.1109/SP40000.2020.00064",
            "url": "https://dblp.org/rec/conf/sp/HossainSS20",
            "abstract": "We are witnessing a rapid escalation in targeted cyber-attacks called Advanced and Persistent Threats (APTs). Carried out by skilled adversaries, these attacks take place over extended time periods, and remain undetected for months. A common approach for retracing the attacker\u2019s steps is to start with one or more suspicious events from system logs, and perform a dependence analysis to uncover the rest of attacker\u2019s actions. The accuracy of this analysis suffers from the dependence explosion problem, which causes a very large number of benign events to be flagged as part of the attack. In this paper, we propose two novel techniques, tag attenuation and tag decay, to mitigate dependence explosion. Our techniques take advantage of common behaviors of benign processes, while providing a conservative treatment of processes and data with suspicious provenance. Our system, called Morse, is able to construct a compact scenario graph that summarizes attacker activity by sifting through millions of system events in a matter of seconds. Our experimental evaluation, carried out using data from two government-agency sponsored red team exercises, demonstrates that our techniques are (a) effective in identifying stealthy attack campaigns, (b) reduce the false alarm rates by more than an order of magnitude, and (c) yield compact scenario graphs that capture the vast majority of the attack, while leaving out benign background activity.",
            "keywords": [
                "Forensic Analysis",
                "Advanced Persistent Threats (APTs)",
                "Dependence Explosion",
                "Tag Propagation",
                "False Alarm Reduction"
            ]
        },
        "url": "URL#2326660",
        "sema_paperId": "1c7387623086430222b03a399f298a5387b92e9a"
    },
    {
        "@score": "1",
        "@id": "2326662",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "78/7690-2",
                        "text": "Heqing Huang 0002"
                    },
                    {
                        "@pid": "269/8140",
                        "text": "Peisen Yao"
                    },
                    {
                        "@pid": "92/9102",
                        "text": "Rongxin Wu"
                    },
                    {
                        "@pid": "145/3943",
                        "text": "Qingkai Shi"
                    },
                    {
                        "@pid": "51/7008-1",
                        "text": "Charles Zhang 0001"
                    }
                ]
            },
            "title": "Pangolin: Incremental Hybrid Fuzzing with Polyhedral Path Abstraction.",
            "venue": "SP",
            "pages": "1613-1627",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/HuangYWSZ20",
            "doi": "10.1109/SP40000.2020.00063",
            "ee": "https://doi.org/10.1109/SP40000.2020.00063",
            "url": "https://dblp.org/rec/conf/sp/HuangYWSZ20",
            "abstract": "Hybrid fuzzing, which combines the merits of both fuzzing and concolic execution, has become one of the most important trends in coverage-guided fuzzing techniques. Despite the tremendous research on hybrid fuzzers, we observe that existing techniques are still inefficient. One important reason is that these techniques, which we refer to as non-incremental fuzzers, cache and reuse few computation results and, thus, lose many optimization opportunities. To be incremental, we propose \"polyhedral path abstraction\", which preserves the exploration state in the concolic execution stage and allows more effective mutation and constraint solving over existing techniques. We have implemented our idea as a tool, namely Pangolin, and evaluated it using LAVA-M as well as nine real-world programs. The evaluation results showed that Pangolin outperforms the state-of-the-art fuzzing techniques with the improvement of coverage rate ranging from 10% to 30%. Moreover, Pangolin found 400 more bugs in LAVA-M and discovered 41 unseen bugs with 8 of them assigned with the CVE IDs.",
            "keywords": [
                "Hybrid Fuzzing",
                "Concolic Execution",
                "Path Abstraction",
                "Coverage Improvement",
                "Bug Detection"
            ]
        },
        "url": "URL#2326662",
        "sema_paperId": "aca36be9e5e7a6ce8b4ae4a2f1d1a6e2f3358392"
    },
    {
        "@score": "1",
        "@id": "2326665",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "08/8604-2",
                        "text": "Umar Iqbal 0002"
                    },
                    {
                        "@pid": "139/5540",
                        "text": "Peter Snyder"
                    },
                    {
                        "@pid": "155/8420",
                        "text": "Shitong Zhu"
                    },
                    {
                        "@pid": "46/2924",
                        "text": "Benjamin Livshits"
                    },
                    {
                        "@pid": "31/8302",
                        "text": "Zhiyun Qian"
                    },
                    {
                        "@pid": "83/9528",
                        "text": "Zubair Shafiq"
                    }
                ]
            },
            "title": "AdGraph: A Graph-Based Approach to Ad and Tracker Blocking.",
            "venue": "SP",
            "pages": "763-776",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/IqbalSZLQS20",
            "doi": "10.1109/SP40000.2020.00005",
            "ee": "https://doi.org/10.1109/SP40000.2020.00005",
            "url": "https://dblp.org/rec/conf/sp/IqbalSZLQS20",
            "abstract": "User demand for blocking advertising and tracking online is large and growing. Existing tools, both deployed and described in research, have proven useful, but lack either the completeness or robustness needed for a general solution. Existing detection approaches generally focus on only one aspect of advertising or tracking (e.g. URL patterns, code structure), making existing approaches susceptible to evasion.In this work we present AdGraph, a novel graph-based machine learning approach for detecting advertising and tracking resources on the web. AdGraph differs from existing approaches by building a graph representation of the HTML structure, network requests, and JavaScript behavior of a webpage, and using this unique representation to train a classifier for identifying advertising and tracking resources. Because AdGraph considers many aspects of the context a network request takes place in, it is less susceptible to the single-factor evasion techniques that flummox existing approaches.We evaluate AdGraph on the Alexa top-10K websites, and find that it is highly accurate, able to replicate the labels of human-generated filter lists with 95.33% accuracy, and can even identify many mistakes in filter lists. We implement AdGraph as a modification to Chromium. AdGraph adds only minor overhead to page loading and execution, and is actually faster than stock Chromium on 42% of websites and AdBlock Plus on 78% of websites. Overall, we conclude that AdGraph is both accurate enough and performant enough for online use, breaking comparable or fewer websites than popular filter list based approaches.",
            "keywords": [
                "Ad Blocking",
                "Tracker Blocking",
                "Graph-Based Detection",
                "Web Resource Classification",
                "Evasion Techniques"
            ]
        },
        "url": "URL#2326665",
        "sema_paperId": "c39eaaa858877e78bb19d55eb27a4533d5de1767"
    },
    {
        "@score": "1",
        "@id": "2326667",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "175/5282",
                        "text": "Steve T. K. Jan"
                    },
                    {
                        "@pid": "254/0865",
                        "text": "Qingying Hao"
                    },
                    {
                        "@pid": "204/2957",
                        "text": "Tianrui Hu"
                    },
                    {
                        "@pid": "198/9527",
                        "text": "Jiameng Pu"
                    },
                    {
                        "@pid": "272/8268",
                        "text": "Sonal Oswal"
                    },
                    {
                        "@pid": "71/4292-11",
                        "text": "Gang Wang 0011"
                    },
                    {
                        "@pid": "24/604",
                        "text": "Bimal Viswanath"
                    }
                ]
            },
            "title": "Throwing Darts in the Dark? Detecting Bots with Limited Data using Neural Data Augmentation.",
            "venue": "SP",
            "pages": "1190-1206",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/JanHHPO0V20",
            "doi": "10.1109/SP40000.2020.00079",
            "ee": "https://doi.org/10.1109/SP40000.2020.00079",
            "url": "https://dblp.org/rec/conf/sp/JanHHPO0V20",
            "abstract": "Machine learning has been widely applied to building security applications. However, many machine learning models require the continuous supply of representative labeled data for training, which limits the models\u2019 usefulness in practice. In this paper, we use bot detection as an example to explore the use of data synthesis to address this problem. We collected the network traffic from 3 online services in three different months within a year (23 million network requests). We develop a stream-based feature encoding scheme to support machine learning models for detecting advanced bots. The key novelty is that our model detects bots with extremely limited labeled data. We propose a data synthesis method to synthesize unseen (or future) bot behavior distributions. The synthesis method is distribution-aware, using two different generators in a Generative Adversarial Network to synthesize data for the clustered regions and the outlier regions in the feature space. We evaluate this idea and show our method can train a model that outperforms existing methods with only 1% of the labeled data. We show that data synthesis also improves the model\u2019s sustainability over time and speeds up the retraining. Finally, we compare data synthesis and adversarial retraining and show they can work complementary with each other to improve the model generalizability.",
            "keywords": [
                "Bot Detection",
                "Data Synthesis",
                "Generative Adversarial Networks",
                "Limited Labeled Data",
                "Model Generalizability"
            ]
        },
        "url": "URL#2326667",
        "sema_paperId": "55997973b25f7fff3dc1ceb7d7c6a2faee492988"
    },
    {
        "@score": "1",
        "@id": "2326670",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "230/3262",
                        "text": "Yan Jia"
                    },
                    {
                        "@pid": "34/8412",
                        "text": "Luyi Xing"
                    },
                    {
                        "@pid": "63/9426",
                        "text": "Yuhang Mao"
                    },
                    {
                        "@pid": "272/7105",
                        "text": "Dongfang Zhao 0010"
                    },
                    {
                        "@pid": "06/6268",
                        "text": "XiaoFeng Wang 0001"
                    },
                    {
                        "@pid": "253/1264",
                        "text": "Shangru Zhao"
                    },
                    {
                        "@pid": "83/6530-1",
                        "text": "Yuqing Zhang 0001"
                    }
                ]
            },
            "title": "Burglars&apos; IoT Paradise: Understanding and Mitigating Security Risks of General Messaging Protocols on IoT Clouds.",
            "venue": "SP",
            "pages": "465-481",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/JiaXMZ0ZZ20",
            "doi": "10.1109/SP40000.2020.00051",
            "ee": "https://doi.org/10.1109/SP40000.2020.00051",
            "url": "https://dblp.org/rec/conf/sp/JiaXMZ0ZZ20",
            "abstract": "With the increasing popularity of the Internet of Things (IoT), many IoT cloud platforms have emerged to help the IoT manufacturers connect their devices to their users. Serving the device-user communication is general messaging protocol deployed on the platforms. Less clear, however, is whether such protocols, which are not designed to work in the adversarial environment of IoT, introduce new risks. In this paper, we report the first systematic study on the protection of major IoT clouds (e.g., AWS, Microsoft, IBM) put in place for the arguably most popular messaging protocol - MQTT. We found that these platforms\u2019 security additions to the protocol are all vulnerable, allowing the adversary to gain control of the device, launch a large-scale denial-of-service attack, steal the victim\u2019s secrets data and fake the victim\u2019s device status for deception. We successfully performed end-to-end attacks on these popular IoT clouds and further conducted a measurement study, which demonstrates that the security impacts of our attacks are real, severe and broad. We reported our findings to related parties, which all acknowledged the importance. We further propose new design principles and an enhanced access model MOUCON. We implemented our protection on a popular open-source MQTT server. Our evaluation shows its high effectiveness and negligible performance overhead.",
            "keywords": [
                "IoT Security",
                "Messaging Protocols",
                "MQTT Vulnerabilities",
                "Denial-of-Service Attacks",
                "Access Control Model"
            ]
        },
        "url": "URL#2326670",
        "sema_paperId": "54715065db35ecbd0474bc39fce7fad39d5f0f29"
    },
    {
        "@score": "1",
        "@id": "2326671",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "64/8561",
                        "text": "Jiao Jiao"
                    },
                    {
                        "@pid": "153/5355",
                        "text": "Shuanglong Kan"
                    },
                    {
                        "@pid": "55/4730-1",
                        "text": "Shang-Wei Lin 0001"
                    },
                    {
                        "@pid": "22/111",
                        "text": "David San\u00e1n"
                    },
                    {
                        "@pid": "51/3710-3",
                        "text": "Yang Liu 0003"
                    },
                    {
                        "@pid": "s/JunSun1",
                        "text": "Jun Sun 0001"
                    }
                ]
            },
            "title": "Semantic Understanding of Smart Contracts: Executable Operational Semantics of Solidity.",
            "venue": "SP",
            "pages": "1695-1712",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/JiaoK0S0020",
            "doi": "10.1109/SP40000.2020.00066",
            "ee": "https://doi.org/10.1109/SP40000.2020.00066",
            "url": "https://dblp.org/rec/conf/sp/JiaoK0S0020",
            "abstract": "Bitcoin has been a popular research topic recently. Ethereum (ETH), a second generation of cryptocurrency, extends Bitcoin\u2019s design by offering a Turing-complete programming language called Solidity to develop smart contracts. Smart contracts allow creditable execution of contracts on EVM (Ethereum Virtual Machine) without third parties. Developing correct and secure smart contracts is challenging due to the decentralized computation nature of the blockchain. Buggy smart contracts may lead to huge financial loss. Furthermore, smart contracts are very hard, if not impossible, to patch once they are deployed. Thus, there is a recent surge of interest in analyzing and verifying smart contracts. While most of the existing works either focus on EVM bytecode or translate Solidity smart contracts into programs in intermediate languages, we argue that it is important and necessary to understand and formally define the semantics of Solidity since programmers write and reason about smart contracts at the level of source code. In this work, we develop a formal semantics for Solidity which provides a formal specification of smart contracts to define semantic-level security properties for the high-level verification. Furthermore, the proposed semantics defines correct and secure high-level execution behaviours of smart contracts to reason about compiler bugs and assist developers in writing secure smart contracts.",
            "keywords": [
                "Smart Contracts",
                "Solidity",
                "Formal Semantics",
                "Security Properties",
                "High-Level Verification"
            ]
        },
        "url": "URL#2326671",
        "sema_paperId": "0a8388d08f03018eeb471bd5455c8abaa03d6763"
    },
    {
        "@score": "1",
        "@id": "2326673",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "248/1646",
                        "text": "Ranjita Pai Kasturi"
                    },
                    {
                        "@pid": "15/8685",
                        "text": "Yiting Sun"
                    },
                    {
                        "@pid": "117/4491",
                        "text": "Ruian Duan"
                    },
                    {
                        "@pid": "127/7110",
                        "text": "Omar Alrawi"
                    },
                    {
                        "@pid": "272/8301",
                        "text": "Ehsan Asdar"
                    },
                    {
                        "@pid": "272/8311",
                        "text": "Victor Zhu"
                    },
                    {
                        "@pid": "139/7034",
                        "text": "Yonghwi Kwon 0001"
                    },
                    {
                        "@pid": "150/5240",
                        "text": "Brendan Saltaformaggio"
                    }
                ]
            },
            "title": "TARDIS: Rolling Back The Clock On CMS-Targeting Cyber Attacks.",
            "venue": "SP",
            "pages": "1156-1171",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/KasturiSDAAZKS20",
            "doi": "10.1109/SP40000.2020.00116",
            "ee": "https://doi.org/10.1109/SP40000.2020.00116",
            "url": "https://dblp.org/rec/conf/sp/KasturiSDAAZKS20",
            "abstract": "Over 55% of the world\u2019s websites run on Content Management Systems (CMS). Unfortunately, this huge user population has made CMS-based websites a high-profile target for hackers. Worse still, the vast majority of the website hosting industry has shifted to a \"backup and restore\" model of security, which relies on error-prone AV scanners to prompt users to roll back to a pre-infection nightly snapshot. This research had the opportunity to study these nightly backups for over 300,000 unique production websites. In doing so, we measured the attack landscape of CMS-based websites and assessed the effectiveness of the backup and restore protection scheme. To our surprise, we found that the evolution of tens of thousands of attacks exhibited clear long-lived multi-stage attack patterns. We now propose TARDIS, an automated provenance inference technique, which enables the investigation and remediation of CMS-targeting attacks based on only the nightly backups already being collected by website hosting companies. With the help of our industry collaborator, we applied TARDIS to the nightly backups of those 300K websites and found 20,591 attacks which lasted from 6 to 1,694 days, some of which were still yet to be detected.",
            "keywords": [
                "CMS Security",
                "Cyber Attacks",
                "Backup and Restore",
                "Attack Patterns",
                "Provenance Inference"
            ]
        },
        "url": "URL#2326673",
        "sema_paperId": "a48a640d9df4de2db3034bf7fd29c6e53adca327"
    },
    {
        "@score": "1",
        "@id": "2326676",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "272/8278",
                        "text": "Brian Kondracki"
                    },
                    {
                        "@pid": "241/4280",
                        "text": "Assel Aliyeva"
                    },
                    {
                        "@pid": "27/3108",
                        "text": "Manuel Egele"
                    },
                    {
                        "@pid": "47/8412",
                        "text": "Jason Polakis"
                    },
                    {
                        "@pid": "04/8280",
                        "text": "Nick Nikiforakis"
                    }
                ]
            },
            "title": "Meddling Middlemen: Empirical Analysis of the Risks of Data-Saving Mobile Browsers.",
            "venue": "SP",
            "pages": "810-824",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/KondrackiAEPN20",
            "doi": "10.1109/SP40000.2020.00077",
            "ee": "https://doi.org/10.1109/SP40000.2020.00077",
            "url": "https://dblp.org/rec/conf/sp/KondrackiAEPN20",
            "abstract": "Mobile browsers have become one of the main mediators of our online activities. However, as web pages continue to increase in size and streaming media on-the-go has become commonplace, mobile data plan constraints remain a significant concern for users. As a result, data-saving features can be a differentiating factor when selecting a mobile browser. In this paper, we present a comprehensive exploration of the security and privacy threat that data-saving functionality presents to users. We conduct the first analysis of Android\u2019s data-saving browser (DSB) ecosystem across multiple dimensions, including the characteristics of the various browsers\u2019 infrastructure, their application and protocol-level behavior, and their effect on users\u2019 browsing experience. Our research unequivocally demonstrates that enabling data-saving functionality in major browsers results in significant degradation of the user\u2019s security posture by introducing severe vulnerabilities that are not otherwise present in the browser during normal operation. In summary, our experiments show that enabling data savings exposes users to (i) proxy servers running outdated software, (ii) man-in-the-middle attacks due to problematic validation of TLS certificates, (iii) weakened TLS cipher suite selection, (iv) lack of support of security headers like HSTS, and (v) a higher likelihood of being labelled as bots. While the discovered issues can be addressed, we argue that data-saving functionality presents inherent risks in an increasingly-encrypted Web, and users should be alerted of the critical savings-vs-security trade-off that they implicitly accept every time they enable such functionality.",
            "keywords": [
                "Mobile Browsers",
                "Data-Saving Features",
                "Security Risks",
                "Privacy Threats",
                "TLS Vulnerabilities"
            ]
        },
        "url": "URL#2326676",
        "sema_paperId": "debcd41eb7e93e91196a284f3211628da949ffe9"
    },
    {
        "@score": "1",
        "@id": "2326677",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "89/10042",
                        "text": "Evgenios M. Kornaropoulos"
                    },
                    {
                        "@pid": "p/CharalamposPapamanthou",
                        "text": "Charalampos Papamanthou"
                    },
                    {
                        "@pid": "t/RobertoTamassia",
                        "text": "Roberto Tamassia"
                    }
                ]
            },
            "title": "The State of the Uniform: Attacks on Encrypted Databases Beyond the Uniform Query Distribution.",
            "venue": "SP",
            "pages": "1223-1240",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/KornaropoulosPT20",
            "doi": "10.1109/SP40000.2020.00029",
            "ee": "https://doi.org/10.1109/SP40000.2020.00029",
            "url": "https://dblp.org/rec/conf/sp/KornaropoulosPT20",
            "abstract": "Recent foundational work on leakage-abuse attacks on encrypted databases has broadened our understanding of what an adversary can accomplish with a standard leakage profile. Nevertheless, all known value reconstruction attacks succeed under strong assumptions that may not hold in the real world. The most prevalent assumption is that queries are issued uniformly at random by the client. We present the first value reconstruction attacks that succeed without any knowledge about the query or data distribution. Our approach uses the search-pattern leakage, which exists in all known structured encryption schemes but has not been fully exploited so far. At the core of our method lies a support size estimator, a technique that utilizes the repetition of search tokens with the same response to estimate distances between encrypted values without any assumptions about the underlying distribution. We develop distribution-agnostic reconstruction attacks for both range queries and k-nearest-neighbor (k-NN) queries based on information extracted from the search-pattern leakage. Our new range attack follows a different algorithmic approach than state-of-the-art attacks, which are fine-tuned to succeed under the uniformly distributed queries. Instead, we reconstruct plaintext values under a variety of skewed query distributions and even outperform the accuracy of previous approaches under the uniform query distribution. Our new k-NN attack succeeds with far fewer samples than previous attacks and scales to much larger values of k. We demonstrate the effectiveness of our attacks by experimentally testing them on a wide range of query distributions and database densities, both unknown to the adversary.",
            "keywords": [
                "Encrypted Databases",
                "Leakage-Abuse Attacks",
                "Value Reconstruction",
                "Search-Pattern Leakage",
                "Query Distribution"
            ]
        },
        "url": "URL#2326677",
        "sema_paperId": "264750e22189230b5777ed07d9fc8052e1e5275a"
    },
    {
        "@score": "1",
        "@id": "2326678",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "222/1569",
                        "text": "Esmaeil Mohammadian Koruyeh"
                    },
                    {
                        "@pid": "242/8308",
                        "text": "Shirin Haji Amin Shirazi"
                    },
                    {
                        "@pid": "169/7381",
                        "text": "Khaled N. Khasawneh"
                    },
                    {
                        "@pid": "69/6818",
                        "text": "Chengyu Song"
                    },
                    {
                        "@pid": "86/2654",
                        "text": "Nael B. Abu-Ghazaleh"
                    }
                ]
            },
            "title": "SpecCFI: Mitigating Spectre Attacks using CFI Informed Speculation.",
            "venue": "SP",
            "pages": "39-53",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/KoruyehSKSA20",
            "doi": "10.1109/SP40000.2020.00033",
            "ee": "https://doi.org/10.1109/SP40000.2020.00033",
            "url": "https://dblp.org/rec/conf/sp/KoruyehSKSA20",
            "abstract": "Spectre attacks and their many subsequent variants are a new vulnerability class affecting modern CPUs. The attacks rely on the ability to misguide speculative execution, generally by exploiting the branch prediction structures, to execute a vulnerable code sequence speculatively. In this paper, we propose to use Control-Flow Integrity (CFI), a security technique used to stop control-flow hijacking attacks, on the committed path, to prevent speculative control-flow from being hijacked to launch the most dangerous variants of the Spectre attacks (Spectre-BTB and Spectre-RSB). Specifically, CFI attempts to constrain the possible targets of an indirect branch to a set of legal targets defined by a pre-calculated control-flow graph (CFG). As CFI is being adopted by commodity software (e.g., Windows and Android) and commodity hardware (e.g., Intel\u2019s CET and ARM\u2019s BTI), the CFI information becomes readily available through the hardware CFI extensions. With the CFI information, we apply CFI principles to also constrain illegal control-flow during speculative execution. Specifically, our proposed defense, SpecCFI, ensures that control flow instructions target legal destinations to constrain dangerous speculation on forward control-flow paths (indirect calls and branches). We augment this protection with a precise speculation-aware hardware stack to constrain speculation on backward control-flow edges (returns). We combine this solution with existing solutions against branch target predictor attacks (Spectre-PHT) to close all known non-vendor-specific Spectre vulnerabilities. We show that SpecCFI results in small overheads both in terms of performance and additional hardware complexity.",
            "keywords": [
                "Control-Flow Integrity",
                "Speculative Execution",
                "Spectre Attacks",
                "SpecCFI Defense",
                "Hardware Security"
            ]
        },
        "url": "URL#2326678",
        "sema_paperId": "09aebdef84766b8477c9134ebf49918b31cbc3f0"
    },
    {
        "@score": "1",
        "@id": "2326679",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "232/1891",
                        "text": "Christiane Kuhn"
                    },
                    {
                        "@pid": "70/2640",
                        "text": "Martin Beck"
                    },
                    {
                        "@pid": "69/2809",
                        "text": "Thorsten Strufe"
                    }
                ]
            },
            "title": "Breaking and (Partially) Fixing Provably Secure Onion Routing.",
            "venue": "SP",
            "pages": "168-185",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/KuhnBS20",
            "doi": "10.1109/SP40000.2020.00039",
            "ee": "https://doi.org/10.1109/SP40000.2020.00039",
            "url": "https://dblp.org/rec/conf/sp/KuhnBS20",
            "abstract": "After several years of research on onion routing, Camenisch and Lysyanskaya, in an attempt at rigorous analysis, defined an ideal functionality in the universal composability model, together with properties that protocols have to meet to achieve provable security. A whole family of systems based their security proofs on this work. However, analyzing HORNET and Sphinx, two instances from this family, we show that this proof strategy is broken. We discover a previously unknown vulnerability that breaks anonymity completely, and explain a known one. Both should not exist if privacy is proven correctly.In this work, we analyze and fix the proof strategy used for this family of systems. After proving the efficacy of the ideal functionality, we show how the original properties are flawed and suggest improved, effective properties in their place. Finally, we discover another common mistake in the proofs. We demonstrate how to avoid it by showing our improved properties for one protocol, thus partially fixing the family of provably secure onion routing protocols.",
            "pdf_url": "",
            "keywords": [
                "Onion Routing",
                "Provable Security",
                "Anonymity Vulnerability",
                "Universal Composability",
                "Protocol Analysis"
            ]
        },
        "url": "URL#2326679"
    },
    {
        "@score": "1",
        "@id": "2326681",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "55/9843",
                        "text": "Michael Kurth"
                    },
                    {
                        "@pid": "68/86",
                        "text": "Ben Gras"
                    },
                    {
                        "@pid": "131/5092",
                        "text": "Dennis Andriesse"
                    },
                    {
                        "@pid": "75/8194",
                        "text": "Cristiano Giuffrida"
                    },
                    {
                        "@pid": "91/800",
                        "text": "Herbert Bos"
                    },
                    {
                        "@pid": "121/2685",
                        "text": "Kaveh Razavi"
                    }
                ]
            },
            "title": ": Practical Cache Attacks from the Network.",
            "venue": "SP",
            "pages": "20-38",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/KurthGAGBR20",
            "doi": "10.1109/SP40000.2020.00082",
            "ee": "https://doi.org/10.1109/SP40000.2020.00082",
            "url": "https://dblp.org/rec/conf/sp/KurthGAGBR20",
            "abstract": "Increased peripheral performance is causing strain on the memory subsystem of modern processors. For example, available DRAM throughput can no longer sustain the traffic of a modern network card. Scrambling to deliver the promised performance, instead of transferring peripheral data to and from DRAM, modern Intel processors perform I/O operations directly on the Last Level Cache (LLC). While Direct Cache Access (DCA) instead of Direct Memory Access (DMA) is a sensible performance optimization, it is unfortunately implemented without care for security, as the LLC is now shared between the CPU and all the attached devices, including the network card.In this paper, we reverse engineer the behavior of DCA, widely referred to as Data-Direct I/O (DDIO), on recent Intel processors and present its first security analysis. Based on our analysis, we present NetCAT, the first Network-based PRIME+PROBE Cache Attack on the processor\u2019s LLC of a remote machine. We show that NetCAT not only enables attacks in cooperative settings where an attacker can build a covert channel between a network client and a sandboxed server process (without network), but more worryingly, in general adversarial settings. In such settings, NetCAT can enable disclosure of network timing-based sensitive information. As an example, we show a keystroke timing attack on a victim SSH connection belonging to another client on the target server. Our results should caution processor vendors against unsupervised sharing of (additional) microarchitectural components with peripherals exposed to malicious input.",
            "keywords": [
                "Cache Attacks",
                "Direct Cache Access",
                "Data-Direct I/O",
                "Network-based Attacks",
                "Keystroke Timing Attack"
            ]
        },
        "url": "URL#2326681",
        "sema_paperId": "6e2e752fc61b082405ce488acc41f6ac3eb33049"
    },
    {
        "@score": "1",
        "@id": "2326682",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "176/8068",
                        "text": "Andrew Kwong"
                    },
                    {
                        "@pid": "98/8283",
                        "text": "Daniel Genkin"
                    },
                    {
                        "@pid": "166/1494",
                        "text": "Daniel Gruss"
                    },
                    {
                        "@pid": "90/10901",
                        "text": "Yuval Yarom"
                    }
                ]
            },
            "title": "RAMBleed: Reading Bits in Memory Without Accessing Them.",
            "venue": "SP",
            "pages": "695-711",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/KwongGGY20",
            "doi": "10.1109/SP40000.2020.00020",
            "ee": "https://doi.org/10.1109/SP40000.2020.00020",
            "url": "https://dblp.org/rec/conf/sp/KwongGGY20",
            "abstract": "The Rowhammer bug is a reliability issue in DRAM cells that can enable an unprivileged adversary to flip the values of bits in neighboring rows on the memory module. Previous work has exploited this for various types of fault attacks across security boundaries, where the attacker flips inaccessible bits, often resulting in privilege escalation. It is widely assumed however, that bit flips within the adversary\u2019s own private memory have no security implications, as the attacker can already modify its private memory via regular write operations.We demonstrate that this assumption is incorrect, by employing Rowhammer as a read side channel. More specifically, we show how an unprivileged attacker can exploit the data dependence between Rowhammer induced bit flips and the bits in nearby rows to deduce these bits, including values belonging to other processes and the kernel. Thus, the primary contribution of this work is to show that Rowhammer is a threat to not only integrity, but to confidentiality as well.Furthermore, in contrast to Rowhammer write side channels, which require persistent bit flips, our read channel succeeds even when ECC memory detects and corrects every bit flip. Thus, we demonstrate the first security implication of successfully-corrected bit flips, which were previously considered benign.To demonstrate the implications of this read side channel, we present an end-to-end attack on OpenSSH 7.9 that extracts an RSA-2048 key from the root level SSH daemon. To accomplish this, we develop novel techniques for massaging memory from user space into an exploitable state, and use the DRAM rowbuffer timing side channel to locate physically contiguous memory necessary for double-sided Rowhammering. Unlike previous Rowhammer attacks, our attack does not require the use of huge pages, and it works on Ubuntu Linux under its default configuration settings.",
            "keywords": [
                "Rowhammer",
                "Memory Attacks",
                "Confidentiality",
                "Read Side Channel",
                "Bit Flips"
            ]
        },
        "url": "URL#2326682",
        "sema_paperId": "1ecf956d4077d095af60021805fd51e27c11f5ed"
    },
    {
        "@score": "1",
        "@id": "2326684",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "30/3557-3",
                        "text": "Jonathan Lee 0003"
                    },
                    {
                        "@pid": "203/4231",
                        "text": "Kirill Nikitin 0001"
                    },
                    {
                        "@pid": "68/8463",
                        "text": "Srinath T. V. Setty"
                    }
                ]
            },
            "title": "Replicated state machines without replicated execution.",
            "venue": "SP",
            "pages": "119-134",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/Lee0S20",
            "doi": "10.1109/SP40000.2020.00068",
            "ee": "https://doi.org/10.1109/SP40000.2020.00068",
            "url": "https://dblp.org/rec/conf/sp/Lee0S20",
            "abstract": "This paper introduces a new approach to reduce end-to-end costs in large-scale replicated systems built under a Byzantine fault model. Specifically, our approach transforms a given replicated state machine (RSM) to another RSM where nodes incur lower costs by delegating state machine execution: an untrusted prover produces succinct cryptographic proofs of correct state transitions along with state changes, which nodes in the transformed RSM verify and apply respectively.To realize our approach, we build Piperine, a system that makes the proof machinery profitable in the context of RSMs. Specifically, Piperine reduces the costs of both proving and verifying the correctness of state machine execution while retaining liveness\u2014a distinctive requirement in the context of RSMs. Our experimental evaluation demonstrates that, for a payment service, employing Piperine is more profitable than naive reexecution of transactions as long as there are > 104 nodes. When we apply Piperine to ERC-20 transactions in Ethereum (a real-world RSM with up to 105 nodes), it reduces per-transaction costs by 5.4\u00d7 and network costs by 2.7\u00d7.",
            "keywords": [
                "Replicated State Machines",
                "Byzantine Fault Tolerance",
                "Cryptographic Proofs",
                "Transaction Cost Reduction",
                "Piperine"
            ]
        },
        "url": "URL#2326684",
        "sema_paperId": "1b008d38fb73c6e348dc3fccf1b3838cd346e7d3"
    },
    {
        "@score": "1",
        "@id": "2326685",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "183/1273",
                        "text": "Patrick Leu"
                    },
                    {
                        "@pid": "157/2295",
                        "text": "Mridula Singh"
                    },
                    {
                        "@pid": "121/9557",
                        "text": "Marc Roeschlin"
                    },
                    {
                        "@pid": "39/780",
                        "text": "Kenneth G. Paterson"
                    },
                    {
                        "@pid": "51/1639",
                        "text": "Srdjan Capkun"
                    }
                ]
            },
            "title": "Message Time of Arrival Codes: A Fundamental Primitive for Secure Distance Measurement.",
            "venue": "SP",
            "pages": "500-516",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/LeuSRPC20",
            "doi": "10.1109/SP40000.2020.00010",
            "ee": "https://doi.org/10.1109/SP40000.2020.00010",
            "url": "https://dblp.org/rec/conf/sp/LeuSRPC20",
            "abstract": "Secure distance measurement and therefore secure Time-of-Arrival (ToA) measurement is critical for applications such as contactless payments, passive-keyless entry and start systems, and navigation systems. This paper initiates the study of Message Time of Arrival Codes (MTACs) and their security. MTACs represent a core primitive in the construction of systems for secure ToA measurement. By surfacing MTACs in this way, we are able for the first time to formally define the security requirements of physical-layer measures that protect ToA measurement systems against attacks. Our viewpoint also enables us to provide a unified presentation of existing MTACs (such as those proposed in distance-bounding protocols and in a secure distance measurement standard) and to propose basic principles for protecting ToA measurement systems against attacks that remain unaddressed by existing mechanisms. We also use our perspective to systematically explore the tradeoffs between security and performance that apply to all signal modulation techniques enabling ToA measurements.",
            "keywords": [
                "Secure Distance Measurement",
                "Message Time of Arrival Codes",
                "Time-of-Arrival Measurement",
                "Physical-layer Security",
                "Signal Modulation Techniques"
            ]
        },
        "url": "URL#2326685",
        "sema_paperId": "5dc033addf48c19a82e72ad076989fb3fb14765a"
    },
    {
        "@score": "1",
        "@id": "2326686",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "217/8466",
                        "text": "Zhengxiong Li"
                    },
                    {
                        "@pid": "85/10856",
                        "text": "Fenglong Ma"
                    },
                    {
                        "@pid": "184/5705",
                        "text": "Aditya Singh Rathore"
                    },
                    {
                        "@pid": "152/4206",
                        "text": "Zhuolin Yang"
                    },
                    {
                        "@pid": "134/1201",
                        "text": "Baicheng Chen"
                    },
                    {
                        "@pid": "63/4152-1",
                        "text": "Lu Su 0001"
                    },
                    {
                        "@pid": "11/6689",
                        "text": "Wenyao Xu"
                    }
                ]
            },
            "title": "WaveSpy: Remote and Through-wall Screen Attack via mmWave Sensing.",
            "venue": "SP",
            "pages": "217-232",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/LiMRYCSX20",
            "doi": "10.1109/SP40000.2020.00004",
            "ee": "https://doi.org/10.1109/SP40000.2020.00004",
            "url": "https://dblp.org/rec/conf/sp/LiMRYCSX20",
            "abstract": "Digital screens, such as liquid crystal displays (LCDs), are vulnerable to attacks (e.g., \"shoulder surfing\") that can bypass security protection services (e.g., firewall) to steal confidential information from intended victims. The conventional practice to mitigate these threats is isolation. An isolated zone, without accessibility, proximity, and line-of-sight, seems to bring personal devices to a truly secure place.In this paper, we revisit this historical topic and re-examine the security risk of screen attacks in an isolation scenario mentioned above. Specifically, we identify and validate a new and practical side-channel attack for screen content via liquid crystal nematic state estimation using a low-cost radio-frequency sensor. By leveraging the relationship between the screen content and the states of liquid crystal arrays in displays, we develop WaveSpy, an end-to-end portable through-wall screen attack system. WaveSpy comprises a low-cost, energy-efficient and light-weight millimeter-wave (mmWave) probe which can remotely collect the liquid crystal state response to a set of mmWave stimuli and facilitate screen content inference, even when the victim\u2019s screen is placed in an isolated zone. We intensively evaluate the performance and practicality of WaveSpy in screen attacks, including over 100 different types of content on 30 digital screens of modern electronic devices. WaveSpy achieves an accuracy of 99% in screen content type recognition and a success rate of 87.77% in Top-3 sensitive information retrieval under real-world scenarios, respectively. Furthermore, we discuss several potential defense mechanisms to mitigate screen eavesdropping similar to WaveSpy.",
            "keywords": [
                "mmWave Sensing",
                "Screen Content Inference",
                "Side-Channel Attack",
                "Liquid Crystal Displays",
                "Through-Wall Eavesdropping"
            ]
        },
        "url": "URL#2326686",
        "sema_paperId": "d4e3c1b0f1742633ed9ae5e6f8c8a64c2b4cdf11"
    },
    {
        "@score": "1",
        "@id": "2326689",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "211/8100",
                        "text": "Sanam Ghorbani Lyastani"
                    },
                    {
                        "@pid": "40/1587",
                        "text": "Michael Schilling 0001"
                    },
                    {
                        "@pid": "272/8299",
                        "text": "Michaela Neumayr"
                    },
                    {
                        "@pid": "b/MichaelBackes1",
                        "text": "Michael Backes 0001"
                    },
                    {
                        "@pid": "31/7561",
                        "text": "Sven Bugiel"
                    }
                ]
            },
            "title": "Is FIDO2 the Kingslayer of User Authentication? A Comparative Usability Study of FIDO2 Passwordless Authentication.",
            "venue": "SP",
            "pages": "268-285",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/LyastaniSN0B20",
            "doi": "10.1109/SP40000.2020.00047",
            "ee": "https://doi.org/10.1109/SP40000.2020.00047",
            "url": "https://dblp.org/rec/conf/sp/LyastaniSN0B20",
            "abstract": "The newest contender for succeeding passwords as the incumbent web authentication scheme is the FIDO2 standard. Jointly developed and backed by the FIDO Alliance and the W3C, FIDO2 has found support in virtually every browser, finds increasing support by service providers, and has adoptions beyond browser-software on its way. While it supports MFA and 2FA, its single-factor, passwordless authentication with security tokens has received the bulk of attention and was hailed by its supporters and the media as the solution that will replace text-passwords on the web. Despite its obvious security and deployability benefits\u2014a setting that no prior solution had in this strong combination\u2014the paradigm shift from a familiar knowledge factor to purely a possession factor raises questions about the acceptance of passwordless authentication by end-users.This paper presents the first large-scale lab study of FIDO2 single-factor authentication to collect insights about end-users\u2019 perception, acceptance, and concerns about passwordless authentication. Through hands-on tasks our participants gather first-hand experience with passwordless authentication using a security key, which they afterwards reflect on in a survey. Our results show that users are willing to accept a direct replacement of text-based passwords with a security key for single-factor authentication. That is an encouraging result in the quest to replace passwords. But, our results also identify new concerns that can potentially hinder the widespread adoption of FIDO2 passwordless authentication. In order to mitigate these factors, we derive concrete recommendations to try to help in the ongoing proliferation of passwordless authentication on the web.",
            "keywords": [
                "FIDO2 Authentication",
                "Passwordless Authentication",
                "User Acceptance",
                "Security Tokens",
                "Usability Concerns"
            ]
        },
        "url": "URL#2326689",
        "sema_paperId": "b267b1f914377772b25e2abc3fb024fcde2115c9"
    },
    {
        "@score": "1",
        "@id": "2326691",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "133/8188",
                        "text": "Aravind Machiry"
                    },
                    {
                        "@pid": "155/6800",
                        "text": "Nilo Redini"
                    },
                    {
                        "@pid": "272/8302",
                        "text": "Eric Camellini"
                    },
                    {
                        "@pid": "k/ChristopherKruegel",
                        "text": "Christopher Kruegel"
                    },
                    {
                        "@pid": "v/GiovanniVigna",
                        "text": "Giovanni Vigna"
                    }
                ]
            },
            "title": "SPIDER: Enabling Fast Patch Propagation In Related Software Repositories.",
            "venue": "SP",
            "pages": "1562-1579",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/MachiryRCKV20",
            "doi": "10.1109/SP40000.2020.00038",
            "ee": "https://doi.org/10.1109/SP40000.2020.00038",
            "url": "https://dblp.org/rec/conf/sp/MachiryRCKV20",
            "abstract": "Despite the effort of software maintainers, patches to open-source repositories are propagated from the main codebase to all the related projects (e.g., forks) with a significant delay. Previous work shows that this is true also for security patches, which represents a critical problem. Vulnerability databases, such as the CVE database, were born to speed-up the application of critical patches; however, patches associated with CVE entries (i.e., CVE patches) are still applied with a delay, and some security fixes lack the corresponding CVE entries. Because of this, project maintainers could miss security patches when upgrading software.In this paper, we are the first to define safe patches (sps). An sp is a patch that does not disrupt the intended functionality of the program (on valid inputs), meaning that it can be applied with no testing; we argue that most security fixes fall into this category. Furthermore, we show a technique to identify sps, and implement SPIDER 1, a tool based on such a technique that works by analyzing the source code of the original and patched versions of a file. We performed a large-scale evaluation on 341,767 patches from 32 large and popular source code repositories as well as on 809 CVE patches. Results show that SPIDER was able to identify 67,408 sps and that most of the CVE patches are sps. In addition, SPIDER identified 2,278 patches that fix vulnerabilities lacking a CVE; 229 of these are still unpatched in different vendor kernels, which can be considered as potential unfixed vulnerabilities.",
            "keywords": [
                "Patch Propagation",
                "Open-Source Software",
                "Safe Patches",
                "Security Vulnerabilities",
                "CVE Database"
            ]
        },
        "url": "URL#2326691",
        "sema_paperId": "1809e02ce992a054c94ff05af5d7d8ba39d5554a"
    },
    {
        "@score": "1",
        "@id": "2326692",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "232/2235",
                        "text": "Sunil Manandhar"
                    },
                    {
                        "@pid": "151/7453",
                        "text": "Kevin Moran"
                    },
                    {
                        "@pid": "222/2853",
                        "text": "Kaushal Kafle"
                    },
                    {
                        "@pid": "244/2204",
                        "text": "Ruhao Tang"
                    },
                    {
                        "@pid": "02/320",
                        "text": "Denys Poshyvanyk"
                    },
                    {
                        "@pid": "136/8334",
                        "text": "Adwait Nadkarni"
                    }
                ]
            },
            "title": "Towards a Natural Perspective of Smart Homes for Practical Security and Safety Analyses.",
            "venue": "SP",
            "pages": "482-499",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/ManandharMKTPN20",
            "doi": "10.1109/SP40000.2020.00062",
            "ee": "https://doi.org/10.1109/SP40000.2020.00062",
            "url": "https://dblp.org/rec/conf/sp/ManandharMKTPN20",
            "abstract": "Designing practical security systems for the smart home is challenging without the knowledge of realistic home usage. This paper describes the design and implementation of H\u03b5lion, a framework that generates natural home automation scenarios by identifying the regularities in user-driven home automation sequences, which are in turn generated from routines created by end-users. Our key hypothesis is that smart home event sequences created by users exhibit inherent semantic patterns, or naturalness that can be modeled and used to generate valid and useful scenarios. To evaluate our approach, we first empirically demonstrate that this naturalness hypothesis holds, with a corpus of 30,518 home automation events, constructed from 273 routines collected from 40 users. We then demonstrate that the scenarios generated by H\u03b5lion seem valid to end-users, through two studies with 16 external evaluators. We further demonstrate the usefulness of H\u03b5lion\u2019s scenarios by addressing the challenge of policy specification, and using H\u03b5lion to generate 17 security/safety policies with minimal effort. We distill 16 key findings from our results that demonstrate the strengths of our approach, surprising aspects of home automation, as well as challenges and opportunities in this rapidly growing domain.",
            "keywords": [
                "Smart Home Automation",
                "User-Driven Scenarios",
                "Home Security Policies",
                "Naturalness Hypothesis",
                "Routine Analysis"
            ]
        },
        "url": "URL#2326692",
        "sema_paperId": "8f5b34da3f9d33c55c12ffe89f484e63806167c6"
    },
    {
        "@score": "1",
        "@id": "2326693",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "260/6737",
                        "text": "Philipp Markert"
                    },
                    {
                        "@pid": "70/4808",
                        "text": "Daniel V. Bailey"
                    },
                    {
                        "@pid": "177/0313",
                        "text": "Maximilian Golla"
                    },
                    {
                        "@pid": "36/3665",
                        "text": "Markus D\u00fcrmuth"
                    },
                    {
                        "@pid": "94/1554",
                        "text": "Adam J. Aviv"
                    }
                ]
            },
            "title": "This PIN Can Be Easily Guessed: Analyzing the Security of Smartphone Unlock PINs.",
            "venue": "SP",
            "pages": "286-303",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/MarkertBGDA20",
            "doi": "10.1109/SP40000.2020.00100",
            "ee": "https://doi.org/10.1109/SP40000.2020.00100",
            "url": "https://dblp.org/rec/conf/sp/MarkertBGDA20",
            "abstract": "We provide the first comprehensive study of user-chosen 4- and 6-digit PINs (n = 1220) collected on smartphones with participants being explicitly primed for device unlocking. We find that against a throttled attacker (with 10, 30, or 100 guesses, matching the smartphone unlock setting), using 6-digit PINs instead of 4-digit PINs provides little to no increase in security, and surprisingly may even decrease security. We also study the effects of blacklists, where a set of \"easy to guess\" PINs is disallowed during selection. Two such blacklists are in use today by iOS, for 4-digits (274 PINs) as well as 6-digits (2910 PINs). We extracted both blacklists compared them with four other blacklists, including a small 4-digit (27 PINs), a large 4-digit (2740 PINs), and two placebo blacklists for 4- and 6-digit PINs that always excluded the first-choice PIN. We find that relatively small blacklists in use today by iOS offer little or no benefit against a throttled guessing attack. Security gains are only observed when the blacklists are much larger, which in turn comes at the cost of increased user frustration. Our analysis suggests that a blacklist at about 10 % of the PIN space may provide the best balance between usability and security.",
            "pdf_url": "",
            "keywords": [
                "Smartphone Security",
                "User-chosen PINs",
                "PIN Guessing Attacks",
                "Blacklist Effectiveness",
                "Usability vs Security"
            ]
        },
        "url": "URL#2326693"
    },
    {
        "@score": "1",
        "@id": "2326694",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "164/7366",
                        "text": "C\u00e9lestin Matte"
                    },
                    {
                        "@pid": "85/150",
                        "text": "Nataliia Bielova"
                    },
                    {
                        "@pid": "141/7040",
                        "text": "Cristiana Santos"
                    }
                ]
            },
            "title": "Do Cookie Banners Respect my Choice? : Measuring Legal Compliance of Banners from IAB Europe&apos;s Transparency and Consent Framework.",
            "venue": "SP",
            "pages": "791-809",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/MatteBS20",
            "doi": "10.1109/SP40000.2020.00076",
            "ee": "https://doi.org/10.1109/SP40000.2020.00076",
            "url": "https://dblp.org/rec/conf/sp/MatteBS20",
            "abstract": "As a result of the GDPR and the ePrivacy Directive, European users encounter cookie banners on almost every website. Many of such banners are implemented by Consent Management Providers (CMPs), who respect IAB Europe's Transparency and Consent Framework (TCF). Via cookie banners, CMPs collect and disseminate user consent to third parties. In this work, we systematically study IAB Europe's TCF and analyze consent stored behind the user interface of TCF cookie banners. We analyze the GDPR and the ePrivacy Directive to identify potential legal violations in implementations of cookie banners based on the storage of consent and detect such suspected violations by crawling 1 426 websites that contains TCF banners, found among 28 257 crawled European websites. With two automatic and semi-automatic crawl campaigns, we detect suspected violations, and we find that: 141 websites register positive consent even if the user has not made their choice; 236 websites nudge the users towards accepting consent by pre-selecting options; and 27 websites store a positive consent even if the user has explicitly opted out. Performing extensive tests on 560 websites, we find at least one suspected violation in 54% of them. Finally, we provide a browser extension to facilitate manual detection of suspected violations for regular users and Data Protection Authorities.",
            "pdf_url": "",
            "keywords": [
                "Cookie Banners",
                "GDPR Compliance",
                "User Consent",
                "IAB Transparency and Consent Framework",
                "ePrivacy Directive Violations"
            ]
        },
        "url": "URL#2326694"
    },
    {
        "@score": "1",
        "@id": "2326697",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "180/3872",
                        "text": "Philipp Morgner"
                    },
                    {
                        "@pid": "88/4796",
                        "text": "Christoph Mai"
                    },
                    {
                        "@pid": "243/5885",
                        "text": "Nicole Koschate-Fischer"
                    },
                    {
                        "@pid": "f/FCFreiling",
                        "text": "Felix C. Freiling"
                    },
                    {
                        "@pid": "b/ZBenenson",
                        "text": "Zinaida Benenson"
                    }
                ]
            },
            "title": "Security Update Labels: Establishing Economic Incentives for Security Patching of IoT Consumer Products.",
            "venue": "SP",
            "pages": "429-446",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/MorgnerMKFB20",
            "doi": "10.1109/SP40000.2020.00021",
            "ee": "https://doi.org/10.1109/SP40000.2020.00021",
            "url": "https://dblp.org/rec/conf/sp/MorgnerMKFB20",
            "abstract": "With the expansion of the Internet of Things (IoT), the number of security incidents due to insecure and misconfigured IoT devices is increasing. Especially on the consumer market, manufacturers focus on new features and early releases at the expense of a comprehensive security strategy. Hence, experts have started calling for regulation of the IoT consumer market, while policymakers are seeking for suitable regulatory approaches. We investigate how manufacturers can be incentivized to increase sustainable security efforts for IoT products. We propose mandatory security update labels that inform consumers during buying decisions about the willingness of the manufacturer to provide security updates in the future. Mandatory means that the labels explicitly state when security updates are not guaranteed. We conducted a user study with more than 1,400 participants to assess the importance of security update labels for the consumer choice by means of a conjoint analysis. The results show that the availability of security updates (until which date the updates are guaranteed) accounts for 8% to 35% impact on overall consumers' choice, depending on the perceived security risk of the product category. For products with a high perceived security risk, this availability is twice as important as other high-ranked product attributes. Moreover, provisioning time for security updates (how quickly the product will be patched after a vulnerability is discovered) additionally accounts for 7% to 25% impact on consumers' choices. The proposed labels are intuitively understood by consumers, do not require product assessments by third parties before release, and have a potential to incentivize manufacturers to provide sustainable security support.",
            "pdf_url": "",
            "keywords": [
                "IoT Security",
                "Consumer Products",
                "Security Update Labels",
                "Sustainable Security Efforts",
                "Incentives for Manufacturers"
            ]
        },
        "url": "URL#2326697"
    },
    {
        "@score": "1",
        "@id": "2326699",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "272/8308",
                        "text": "Kit Murdock"
                    },
                    {
                        "@pid": "190/2073",
                        "text": "David F. Oswald"
                    },
                    {
                        "@pid": "42/1707",
                        "text": "Flavio D. Garcia"
                    },
                    {
                        "@pid": "167/1573",
                        "text": "Jo Van Bulck"
                    },
                    {
                        "@pid": "166/1494",
                        "text": "Daniel Gruss"
                    },
                    {
                        "@pid": "85/6647",
                        "text": "Frank Piessens"
                    }
                ]
            },
            "title": "Plundervolt: Software-based Fault Injection Attacks against Intel SGX.",
            "venue": "SP",
            "pages": "1466-1482",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/MurdockOGBGP20",
            "doi": "10.1109/SP40000.2020.00057",
            "ee": "https://doi.org/10.1109/SP40000.2020.00057",
            "url": "https://dblp.org/rec/conf/sp/MurdockOGBGP20",
            "abstract": "Dynamic frequency and voltage scaling features have been introduced to manage ever-growing heat and power consumption in modern processors. Design restrictions ensure frequency and voltage are adjusted as a pair, based on the current load, because for each frequency there is only a certain voltage range where the processor can operate correctly. For this purpose, many processors (including the widespread Intel Core series) expose privileged software interfaces to dynamically regulate processor frequency and operating voltage.In this paper, we demonstrate that these privileged interfaces can be reliably exploited to undermine the system\u2019s security. We present the Plundervolt attack, in which a privileged software adversary abuses an undocumented Intel Core voltage scaling interface to corrupt the integrity of Intel SGX enclave computations. Plundervolt carefully controls the processor\u2019s supply voltage during an enclave computation, inducing predictable faults within the processor package. Consequently, even Intel SGX\u2019s memory encryption/authentication technology cannot protect against Plundervolt. In multiple case studies, we show how the induced faults in enclave computations can be leveraged in real-world attacks to recover keys from cryptographic algorithms (including the AES-NI instruction set extension) or to induce memory safety vulnerabilities into bug-free enclave code. We finally discuss why mitigating Plundervolt is not trivial, requiring trusted computing base recovery through microcode updates or hardware changes.",
            "keywords": [
                "Intel SGX",
                "Plundervolt Attack",
                "Fault Injection",
                "Voltage Scaling",
                "Cryptographic Vulnerabilities"
            ]
        },
        "url": "URL#2326699",
        "sema_paperId": "0ba8a0d11c6ab10c43593627740c11d6ef447a4f"
    },
    {
        "@score": "1",
        "@id": "2326700",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "199/3074",
                        "text": "Pardis Emami Naeini"
                    },
                    {
                        "@pid": "84/1053",
                        "text": "Yuvraj Agarwal"
                    },
                    {
                        "@pid": "03/1595",
                        "text": "Lorrie Faith Cranor"
                    },
                    {
                        "@pid": "118/1575",
                        "text": "Hanan Hibshi"
                    }
                ]
            },
            "title": "Ask the Experts: What Should Be on an IoT Privacy and Security Label?",
            "venue": "SP",
            "pages": "447-464",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/NaeiniACH20",
            "doi": "10.1109/SP40000.2020.00043",
            "ee": "https://doi.org/10.1109/SP40000.2020.00043",
            "url": "https://dblp.org/rec/conf/sp/NaeiniACH20",
            "abstract": "Information about the privacy and security of Internet of Things (IoT) devices is not readily available to consumers who want to consider it before making purchase decisions. While legislators have proposed adding succinct, consumer accessible, labels, they do not provide guidance on the content of these labels. In this paper, we report on the results of a series of interviews and surveys with privacy and security experts, as well as consumers, where we explore and test the design space of the content to include on an IoT privacy and security label. We conduct an expert elicitation study by following a three-round Delphi process with 22 privacy and security experts to identify the factors that experts believed are important for consumers when comparing the privacy and security of IoT devices to inform their purchase decisions. Based on how critical experts believed each factor is in conveying risk to consumers, we distributed these factors across two layers\u2014a primary layer to display on the product package itself or prominently on a website, and a secondary layer available online through a web link or a QR code. We report on the experts\u2019 rationale and arguments used to support their choice of factors. Moreover, to study how consumers would perceive the privacy and security information specified by experts, we conducted a series of semi-structured interviews with 15 participants, who had purchased at least one IoT device (smart home device or wearable). Based on the results of our expert elicitation and consumer studies, we propose a prototype privacy and security label to help consumers make more informed IoT-related purchase decisions.",
            "keywords": [
                "IoT Privacy",
                "Security Labeling",
                "Consumer Awareness",
                "Expert Elicitation",
                "Purchase Decision Factors"
            ]
        },
        "url": "URL#2326700",
        "sema_paperId": "3e8a7edbfb5d5a1b37c0f98ad832062bc2a5244c"
    },
    {
        "@score": "1",
        "@id": "2326701",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "208/4182",
                        "text": "Arian Akhavan Niaki"
                    },
                    {
                        "@pid": "157/1128",
                        "text": "Shinyoung Cho"
                    },
                    {
                        "@pid": "58/10074",
                        "text": "Zachary Weinberg"
                    },
                    {
                        "@pid": "179/2240",
                        "text": "Nguyen Phong Hoang"
                    },
                    {
                        "@pid": "149/9322",
                        "text": "Abbas Razaghpanah"
                    },
                    {
                        "@pid": "c/NicolasChristin",
                        "text": "Nicolas Christin"
                    },
                    {
                        "@pid": "52/2893",
                        "text": "Phillipa Gill"
                    }
                ]
            },
            "title": "ICLab: A Global, Longitudinal Internet Censorship Measurement Platform.",
            "venue": "SP",
            "pages": "135-151",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/NiakiCWHRCG20",
            "doi": "10.1109/SP40000.2020.00014",
            "ee": "https://doi.org/10.1109/SP40000.2020.00014",
            "url": "https://dblp.org/rec/conf/sp/NiakiCWHRCG20",
            "abstract": "Researchers have studied Internet censorship for nearly as long as attempts to censor contents have taken place. Most studies have however been limited to a short period of time and / or a few countries; the few exceptions have traded off detail for breadth of coverage. Collecting enough data for a comprehensive, global, longitudinal perspective remains challenging.In this work, we present ICLab, an Internet measurement platform specialized for censorship research. It achieves a new balance between breadth of coverage and detail of measurements, by using commercial VPNs as vantage points distributed around the world. ICLab has been operated continuously since late 2016. It can currently detect DNS manipulation and TCP packet injection, and overt \"block pages\" however they are delivered. ICLab records and archives raw observations in detail, making retrospective analysis with new techniques possible. At every stage of processing, ICLab seeks to minimize false positives and manual validation.Within 53,906,532 measurements of individual web pages, collected by ICLab in 2017 and 2018, we observe blocking of 3,602 unique URLs in 60 countries. Using this data, we compare how different blocking techniques are deployed in different regions and/or against different types of content. Our longitudinal monitoring pinpoints changes in censorship in India and Turkey concurrent with political shifts, and our clustering techniques discover 48 previously unknown block pages. ICLab's broad and detailed measurements also expose other forms of network interference, such as surveillance and malware injection.",
            "pdf_url": "",
            "keywords": [
                "Internet Censorship",
                "Measurement Platform",
                "Longitudinal Analysis",
                "Network Interference",
                "Censorship Techniques"
            ]
        },
        "url": "URL#2326701"
    },
    {
        "@score": "1",
        "@id": "2326702",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "160/7732",
                        "text": "Kyndylan Nienhuis"
                    },
                    {
                        "@pid": "189/1762",
                        "text": "Alexandre Joannou"
                    },
                    {
                        "@pid": "95/8429",
                        "text": "Thomas Bauereiss"
                    },
                    {
                        "@pid": "36/1661",
                        "text": "Anthony C. J. Fox"
                    },
                    {
                        "@pid": "21/5870",
                        "text": "Michael Roe"
                    },
                    {
                        "@pid": "58/4171-1",
                        "text": "Brian Campbell 0001"
                    },
                    {
                        "@pid": "80/2682",
                        "text": "Matthew Naylor"
                    },
                    {
                        "@pid": "233/0169",
                        "text": "Robert M. Norton"
                    },
                    {
                        "@pid": "m/SimonWMoore",
                        "text": "Simon W. Moore"
                    },
                    {
                        "@pid": "n/PeterGNeumann",
                        "text": "Peter G. Neumann"
                    },
                    {
                        "@pid": "08/3395",
                        "text": "Ian Stark"
                    },
                    {
                        "@pid": "70/2118",
                        "text": "Robert N. M. Watson"
                    },
                    {
                        "@pid": "74/185",
                        "text": "Peter Sewell"
                    }
                ]
            },
            "title": "Rigorous engineering for hardware security: Formal modelling and proof in the CHERI design and implementation process.",
            "venue": "SP",
            "pages": "1003-1020",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/NienhuisJBFR0NN20",
            "doi": "10.1109/SP40000.2020.00055",
            "ee": "https://doi.org/10.1109/SP40000.2020.00055",
            "url": "https://dblp.org/rec/conf/sp/NienhuisJBFR0NN20",
            "abstract": "The root causes of many security vulnerabilities include a pernicious combination of two problems, often regarded as inescapable aspects of computing. First, the protection mechanisms provided by the mainstream processor architecture and C/C++ language abstractions, dating back to the 1970s and before, provide only coarse-grain virtual-memory-based protection. Second, mainstream system engineering relies almost exclusively on test-and-debug methods, with (at best) prose specifications. These methods have historically sufficed commercially for much of the computer industry, but they fail to prevent large numbers of exploitable bugs, and the security problems that this causes are becoming ever more acute.In this paper we show how more rigorous engineering methods can be applied to the development of a new security-enhanced processor architecture, with its accompanying hardware implementation and software stack. We use formal models of the complete instruction-set architecture (ISA) at the heart of the design and engineering process, both in lightweight ways that support and improve normal engineering practice - as documentation, in emulators used as a test oracle for hardware and for running software, and for test generation - and for formal verification. We formalise key intended security properties of the design, and establish that these hold with mechanised proof. This is for the same complete ISA models (complete enough to boot operating systems), without idealisation.We do this for CHERI, an architecture with hardware capabilities that supports fine-grained memory protection and scalable secure compartmentalisation, while offering a smooth adoption path for existing software. CHERI is a maturing research architecture, developed since 2010, with work now underway on an Arm industrial prototype to explore its possible adoption in mass-market commercial processors. The rigorous engineering work described here has been an integral part of its development to date, enabling more rapid and confident experimentation, and boosting confidence in the design.",
            "keywords": [
                "Hardware Security",
                "Formal Verification",
                "CHERI Architecture",
                "Memory Protection",
                "Security Properties"
            ]
        },
        "url": "URL#2326702",
        "sema_paperId": "3e698bd33e438570a171de6b78e01506a1245110"
    },
    {
        "@score": "1",
        "@id": "2326703",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "71/7816",
                        "text": "Xudong Pan"
                    },
                    {
                        "@pid": "84/2519-1",
                        "text": "Mi Zhang 0001"
                    },
                    {
                        "@pid": "07/8388",
                        "text": "Shouling Ji"
                    },
                    {
                        "@pid": "02/1640-2",
                        "text": "Min Yang 0002"
                    }
                ]
            },
            "title": "Privacy Risks of General-Purpose Language Models.",
            "venue": "SP",
            "pages": "1314-1331",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/PanZJY20",
            "doi": "10.1109/SP40000.2020.00095",
            "ee": "https://doi.org/10.1109/SP40000.2020.00095",
            "url": "https://dblp.org/rec/conf/sp/PanZJY20",
            "abstract": "Recently, a new paradigm of building general-purpose language models (e.g., Google\u2019s Bert and OpenAI\u2019s GPT-2) in Natural Language Processing (NLP) for text feature extraction, a standard procedure in NLP systems that converts texts to vectors (i.e., embeddings) for downstream modeling, has arisen and starts to find its application in various downstream NLP tasks and real world systems (e.g., Google\u2019s search engine [6]). To obtain general-purpose text embeddings, these language models have highly complicated architectures with millions of learnable parameters and are usually pretrained on billions of sentences before being utilized. As is widely recognized, such a practice indeed improves the state-of-the-art performance of many downstream NLP tasks. However, the improved utility is not for free. We find the text embeddings from general-purpose language models would capture much sensitive information from the plain text. Once being accessed by the adversary, the embeddings can be reverse-engineered to disclose sensitive information of the victims for further harassment. Although such a privacy risk can impose a real threat to the future leverage of these promising NLP tools, there are neither published attacks nor systematic evaluations by far for the mainstream industry-level language models. To bridge this gap, we present the first systematic study on the privacy risks of 8 state-of-the-art language models with 4 diverse case studies. By constructing 2 novel attack classes, our study demonstrates the aforementioned privacy risks do exist and can impose practical threats to the application of general-purpose language models on sensitive data covering identity, genome, healthcare and location. For example, we show the adversary with nearly no prior knowledge can achieve about 75% accuracy when inferring the precise disease site from Bert embeddings of patients\u2019 medical descriptions. As possible countermeasures, we propose 4 different defenses (via rounding, differential privacy, adversarial training and subspace projection) to obfuscate the unprotected embeddings for mitigation purpose. With extensive evaluations, we also provide a preliminary analysis on the utility-privacy trade-off brought by each defense, which we hope may foster future mitigation researches.",
            "keywords": [
                "General-Purpose Language Models",
                "Natural Language Processing",
                "Privacy Risks",
                "Sensitive Information Disclosure",
                "Text Embeddings"
            ]
        },
        "url": "URL#2326703",
        "sema_paperId": "b3c73de96640ee858f83c3f0eda2a3d15d59b847"
    },
    {
        "@score": "1",
        "@id": "2326704",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "03/6317",
                        "text": "Soyeon Park"
                    },
                    {
                        "@pid": "42/1870-2",
                        "text": "Wen Xu 0002"
                    },
                    {
                        "@pid": "119/7670",
                        "text": "Insu Yun"
                    },
                    {
                        "@pid": "249/5571",
                        "text": "Daehee Jang"
                    },
                    {
                        "@pid": "38/8882",
                        "text": "Taesoo Kim"
                    }
                ]
            },
            "title": "Fuzzing JavaScript Engines with Aspect-preserving Mutation.",
            "venue": "SP",
            "pages": "1629-1642",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/ParkXYJK20",
            "doi": "10.1109/SP40000.2020.00067",
            "ee": "https://doi.org/10.1109/SP40000.2020.00067",
            "url": "https://dblp.org/rec/conf/sp/ParkXYJK20",
            "abstract": "Fuzzing is a practical, widely-deployed technique to find bugs in complex, real-world programs like JavaScript engines. We observed, however, that existing fuzzing approaches, either generative or mutational, fall short in fully harvesting high-quality input corpora such as known proof of concept (PoC) exploits or unit tests. Existing fuzzers tend to destruct subtle semantics or conditions encoded in the input corpus in order to generate new test cases because this approach helps in discovering new code paths of the program. Nevertheless, for JavaScript-like complex programs, such a conventional design leads to test cases that tackle only shallow parts of the complex codebase and fails to reach deep bugs effectively due to the huge input space.In this paper, we advocate a new technique, called an aspect-preserving mutation, that stochastically preserves the desirable properties, called aspects, that we prefer to be maintained across mutation. We demonstrate the aspect preservation with two mutation strategies, namely, structure and type preservation, in our fully-fledged JavaScript fuzzer, called Die. Our evaluation shows that Die\u2019s aspect-preserving mutation is more effective in discovering new bugs (5.7\u00d7 more unique crashes) and producing valid test cases (2.4\u00d7 fewer runtime errors) than the state-of-the-art JavaScript fuzzers. Die newly discovered 48 high-impact bugs in ChakraCore, JavaScriptCore, and V8 (38 fixed with 12 CVEs assigned as of today). The source code of Die is publicly available as an open-source project.1",
            "keywords": [
                "JavaScript Fuzzing",
                "Aspect-preserving Mutation",
                "Bug Discovery",
                "Input Corpus",
                "Mutation Strategies"
            ]
        },
        "url": "URL#2326704",
        "sema_paperId": "4c11f562a395ca8cf3af2f5a24e101564211e440"
    },
    {
        "@score": "1",
        "@id": "2326705",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "241/1447",
                        "text": "James Pavur"
                    },
                    {
                        "@pid": "140/4942",
                        "text": "Daniel Moser"
                    },
                    {
                        "@pid": "117/8959",
                        "text": "Martin Strohmeier"
                    },
                    {
                        "@pid": "75/5939",
                        "text": "Vincent Lenders"
                    },
                    {
                        "@pid": "87/2623",
                        "text": "Ivan Martinovic"
                    }
                ]
            },
            "title": "A Tale of Sea and Sky On the Security of Maritime VSAT Communications.",
            "venue": "SP",
            "pages": "1384-1400",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/PavurMSLM20",
            "doi": "10.1109/SP40000.2020.00056",
            "ee": "https://doi.org/10.1109/SP40000.2020.00056",
            "url": "https://dblp.org/rec/conf/sp/PavurMSLM20",
            "abstract": "Very Small Aperture Terminals (VSAT) have revolutionized maritime operations. However, the security dimensions of maritime VSAT services are not well understood. Historically, high equipment costs have acted as a barrier to entry for both researchers and attackers. In this paper we demonstrate a substantial change in threat model, proving practical attacks against maritime VSAT networks with less than $400 of widely-available television equipment. This is achieved through GSExtract, a purpose-built forensic tool which enables the extraction of IP traffic from highly corrupted VSAT data streams.The implications of this threat are assessed experimentally through the analysis of more than 1.3 TB of real-world maritime VSAT recordings encompassing 26 million square kilometers of coverage area. The underlying network platform employed in these systems is representative of more than 60% of the global maritime VSAT services market. We find that sensitive data belonging to some of the world's largest maritime companies is regularly leaked over VSAT ship-to-shore communications. This threat is contextualized through illustrative case studies ranging from the interception and alteration of navigational charts to theft of passport and credit card details. Beyond this, we demonstrate the ability to arbitrarily intercept and modify TCP sessions under certain network configurations, enabling man-in-the-middle and denial of service attacks against ships at sea. The paper concludes with a brief discussion of the unique requirements and challenges for encryption in VSAT environments.",
            "keywords": [
                "Maritime Communications",
                "VSAT Security",
                "Data Leakage",
                "Man-in-the-Middle Attacks",
                "TCP Session Interception"
            ]
        },
        "url": "URL#2326705",
        "sema_paperId": "49d45de0a9b2f5a2125e82dce11b6e8e38cadf5a"
    },
    {
        "@score": "1",
        "@id": "2326706",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "272/8284",
                        "text": "Anton Permenev"
                    },
                    {
                        "@pid": "44/4685-2",
                        "text": "Dimitar K. Dimitrov 0002"
                    },
                    {
                        "@pid": "40/9612",
                        "text": "Petar Tsankov"
                    },
                    {
                        "@pid": "155/1628",
                        "text": "Dana Drachsler-Cohen"
                    },
                    {
                        "@pid": "93/2189",
                        "text": "Martin T. Vechev"
                    }
                ]
            },
            "title": "VerX: Safety Verification of Smart Contracts.",
            "venue": "SP",
            "pages": "1661-1677",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/PermenevDTDV20",
            "doi": "10.1109/SP40000.2020.00024",
            "ee": "https://doi.org/10.1109/SP40000.2020.00024",
            "url": "https://dblp.org/rec/conf/sp/PermenevDTDV20",
            "abstract": "We present VerX, the first automated verifier able to prove functional properties of Ethereum smart contracts. VerX addresses an important problem as all real-world contracts must satisfy custom functional specifications.VerX is based on a careful combination of three techniques, enabling it to automatically verify temporal properties of infinite- state smart contracts: (i) reduction of temporal property verification to reachability checking, (ii) a new symbolic execution engine for the Ethereum Virtual Machine that is precise and efficient for a practical fragment of Ethereum contracts, and (iii) delayed predicate abstraction which uses symbolic execution during transactions and abstraction at transaction boundaries.Our extensive experimental evaluation on 83 temporal properties and 12 real-world projects, including popular crowdsales and libraries, demonstrates that VerX is practically effective.",
            "keywords": [
                "Smart Contract Verification",
                "Ethereum",
                "Temporal Properties",
                "Symbolic Execution",
                "Predicate Abstraction"
            ]
        },
        "url": "URL#2326706",
        "sema_paperId": "a937d4140c289faf03eb5a4046e24351c81b9670"
    },
    {
        "@score": "1",
        "@id": "2326707",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "149/1452",
                        "text": "Fabio Pierazzi"
                    },
                    {
                        "@pid": "223/5655",
                        "text": "Feargus Pendlebury"
                    },
                    {
                        "@pid": "184/5990",
                        "text": "Jacopo Cortellazzi"
                    },
                    {
                        "@pid": "95/5162",
                        "text": "Lorenzo Cavallaro"
                    }
                ]
            },
            "title": "Intriguing Properties of Adversarial ML Attacks in the Problem Space.",
            "venue": "SP",
            "pages": "1332-1349",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/PierazziPCC20",
            "doi": "10.1109/SP40000.2020.00073",
            "ee": "https://doi.org/10.1109/SP40000.2020.00073",
            "url": "https://dblp.org/rec/conf/sp/PierazziPCC20",
            "abstract": "Recent research efforts on adversarial ML have investigated problem-space attacks, focusing on the generation of real evasive objects in domains where, unlike images, there is no clear inverse mapping to the feature space (e.g., software). However, the design, comparison, and real-world implications of problem-space attacks remain underexplored.This paper makes two major contributions. First, we propose a novel formalization for adversarial ML evasion attacks in the problem-space, which includes the definition of a comprehensive set of constraints on available transformations, preserved semantics, robustness to preprocessing, and plausibility. We shed light on the relationship between feature space and problem space, and we introduce the concept of side-effect features as the byproduct of the inverse feature-mapping problem. This enables us to define and prove necessary and sufficient conditions for the existence of problem-space attacks. We further demonstrate the expressive power of our formalization by using it to describe several attacks from related literature across different domains.Second, building on our formalization, we propose a novel problem-space attack on Android malware that overcomes past limitations. Experiments on a dataset with 170K Android apps from 2017 and 2018 show the practical feasibility of evading a state-of-the-art malware classifier along with its hardened version. Our results demonstrate that \"adversarial-malware as a service\" is a realistic threat, as we automatically generate thousands of realistic and inconspicuous adversarial applications at scale, where on average it takes only a few minutes to generate an adversarial app. Yet, out of the 1600+ papers on adversarial ML published in the past six years, roughly 40 focus on malware [15]\u2014and many remain only in the feature space.Our formalization of problem-space attacks paves the way to more principled research in this domain. We responsibly release the code and dataset of our novel attack to other researchers, to encourage future work on defenses in the problem space.",
            "keywords": [
                "Adversarial Machine Learning",
                "Problem-Space Attacks",
                "Android Malware",
                "Evasion Techniques",
                "Adversarial Applications"
            ]
        },
        "url": "URL#2326707",
        "sema_paperId": "6869701819f920af9c9a54e7287c01738286f6ba"
    },
    {
        "@score": "1",
        "@id": "2326709",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "177/5861",
                        "text": "Sergej Proskurin"
                    },
                    {
                        "@pid": "231/1935",
                        "text": "Marius Momeu"
                    },
                    {
                        "@pid": "238/1681",
                        "text": "Seyedhamed Ghavamnia"
                    },
                    {
                        "@pid": "87/1029",
                        "text": "Vasileios P. Kemerlis"
                    },
                    {
                        "@pid": "09/1231",
                        "text": "Michalis Polychronakis"
                    }
                ]
            },
            "title": "xMP: Selective Memory Protection for Kernel and User Space.",
            "venue": "SP",
            "pages": "563-577",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/ProskurinMGKP20",
            "doi": "10.1109/SP40000.2020.00041",
            "ee": "https://doi.org/10.1109/SP40000.2020.00041",
            "url": "https://dblp.org/rec/conf/sp/ProskurinMGKP20",
            "abstract": "Attackers leverage memory corruption vulnerabilities to establish primitives for reading from or writing to the address space of a vulnerable process. These primitives form the foundation for code-reuse and data-oriented attacks. While various defenses against the former class of attacks have proven effective, mitigation of the latter remains an open problem. In this paper, we identify various shortcomings of the x86 architecture regarding memory isolation, and leverage virtualization to build an effective defense against data-oriented attacks. Our approach, called xMP, provides (in-guest) selective memory protection primitives that allow VMs to isolate sensitive data in user or kernel space in disjoint xMP domains. We interface the Xen altp2m subsystem with the Linux memory management system, lending VMs the flexibility to define custom policies. Contrary to conventional approaches, xMP takes advantage of virtualization extensions, but after initialization, it does not require any hypervisor intervention. To ensure the integrity of in-kernel management information and pointers to sensitive data within isolated domains, xMP protects pointers with HMACs bound to an immutable context, so that integrity validation succeeds only in the right context. We have applied xMP to protect the page tables and process credentials of the Linux kernel, as well as sensitive data in various user-space applications. Overall, our evaluation shows that xMP introduces minimal overhead for real-world workloads and applications, and offers effective protection against data-oriented attacks.",
            "keywords": [
                "Memory Protection",
                "Data-Oriented Attacks",
                "Virtualization",
                "Kernel and User Space Isolation",
                "Selective Memory Protection Primitives"
            ]
        },
        "url": "URL#2326709",
        "sema_paperId": "63c7863fcba665bb8b87ee7f204ec79dcd60ba9a"
    },
    {
        "@score": "1",
        "@id": "2326710",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "132/3972",
                        "text": "Jonathan Protzenko"
                    },
                    {
                        "@pid": "49/6324",
                        "text": "Bryan Parno"
                    },
                    {
                        "@pid": "193/3445",
                        "text": "Aymeric Fromherz"
                    },
                    {
                        "@pid": "22/3053",
                        "text": "Chris Hawblitzel"
                    },
                    {
                        "@pid": "244/8751",
                        "text": "Marina Polubelova"
                    },
                    {
                        "@pid": "80/3503",
                        "text": "Karthikeyan Bhargavan"
                    },
                    {
                        "@pid": "165/5515",
                        "text": "Benjamin Beurdouche"
                    },
                    {
                        "@pid": "205/7063",
                        "text": "Joonwon Choi"
                    },
                    {
                        "@pid": "121/1113",
                        "text": "Antoine Delignat-Lavaud"
                    },
                    {
                        "@pid": "f/CedricFournet",
                        "text": "C\u00e9dric Fournet"
                    },
                    {
                        "@pid": "219/9026",
                        "text": "Natalia Kulatova"
                    },
                    {
                        "@pid": "04/10",
                        "text": "Tahina Ramananandro"
                    },
                    {
                        "@pid": "81/10809",
                        "text": "Aseem Rastogi"
                    },
                    {
                        "@pid": "11/5568",
                        "text": "Nikhil Swamy"
                    },
                    {
                        "@pid": "17/3100",
                        "text": "Christoph M. Wintersteiger"
                    },
                    {
                        "@pid": "70/2200",
                        "text": "Santiago Zanella B\u00e9guelin"
                    }
                ]
            },
            "title": "EverCrypt: A Fast, Verified, Cross-Platform Cryptographic Provider.",
            "venue": "SP",
            "pages": "983-1002",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/ProtzenkoPFHPBB20",
            "doi": "10.1109/SP40000.2020.00114",
            "ee": "https://doi.org/10.1109/SP40000.2020.00114",
            "url": "https://dblp.org/rec/conf/sp/ProtzenkoPFHPBB20",
            "abstract": "We present EverCrypt: a comprehensive collection of verified, high-performance cryptographic functionalities available via a carefully designed API. The API provably supports agility (choosing between multiple algorithms for the same functionality) and multiplexing (choosing between multiple implementations of the same algorithm). Through abstraction and zero-cost generic programming, we show how agility can simplify verification without sacrificing performance, and we demonstrate how C and assembly can be composed and verified against shared specifications. We substantiate the effectiveness of these techniques with new verified implementations (including hashes, Curve25519, and AES-GCM) whose performance matches or exceeds the best unverified implementations. We validate the API design with two high-performance verified case studies built atop EverCrypt, resulting in line-rate performance for a secure network protocol and a Merkle-tree library, used in a production blockchain, that supports 2.7 million insertions/sec. Altogether, EverCrypt consists of over 124K verified lines of specs, code, and proofs, and it produces over 29K lines of C and 14K lines of assembly code.",
            "keywords": [
                "Cryptographic Provider",
                "Verified Implementations",
                "Performance Optimization",
                "Agility and Multiplexing",
                "Cross-Platform Cryptography"
            ]
        },
        "url": "URL#2326710",
        "sema_paperId": "eb6f31b212e36d090a434491c013057181aafc4a"
    },
    {
        "@score": "1",
        "@id": "2326711",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "47/8436",
                        "text": "Ivan Pustogarov"
                    },
                    {
                        "@pid": "61/591",
                        "text": "Qian Wu"
                    },
                    {
                        "@pid": "l/DavidLie",
                        "text": "David Lie"
                    }
                ]
            },
            "title": "Ex-vivo dynamic analysis framework for Android device drivers.",
            "venue": "SP",
            "pages": "1088-1105",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/PustogarovWL20",
            "doi": "10.1109/SP40000.2020.00094",
            "ee": "https://doi.org/10.1109/SP40000.2020.00094",
            "url": "https://dblp.org/rec/conf/sp/PustogarovWL20",
            "abstract": "The ability to execute and analyze code makes many security tasks such as exploit development, reverse engineering, and vulnerability detection much easier. However, on embedded devices such as Android smartphones, executing code in-vivo, on the device, for analysis is limited by the need to acquire such devices, the speed of the device, and in some cases the need to flash custom code onto the devices. The other option is to execute the code ex-vivo, off the device, but this approach either requires porting or complex hardware emulation.In this paper, we take advantage of the observation that many execution paths in drivers are only superficially dependent on both the hardware and kernel on which the driver executes, to create an ex-vivo dynamic driver analysis framework for Android devices that requires neither porting nor emulation. We achieve this by developing a generic evasion framework that enables driver initialization by evading hardware and kernel dependencies instead of precisely emulating them, and then developing a novel Ex-vivo AnalySIs framEwoRk (EASIER) that enables off-device analysis with the initialized driver state. Compared to on-device analysis, our approach enables the use of userspace tools and scales with the number of available commodity CPU\u2019s, not the number of smartphones.We demonstrate the usefulness of our framework by targeting privilege escalation vulnerabilities in system call handlers in platform device drivers. We find it can load 48/62 (77%) drivers from three different Android kernels: MSM, Xiaomi, and Huawei. We then confirm that it is able to reach and detect 21 known vulnerabilities. Finally, we have discovered 12 new bugs which we have reported and confirmed.",
            "keywords": [
                "Ex-vivo Analysis",
                "Android Device Drivers",
                "Dynamic Analysis Framework",
                "Privilege Escalation Vulnerabilities",
                "Driver Initialization Evasion"
            ]
        },
        "url": "URL#2326711",
        "sema_paperId": "1bc28445e45f96dafc3e14ca71f2c96e153ae895"
    },
    {
        "@score": "1",
        "@id": "2326713",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "155/6800",
                        "text": "Nilo Redini"
                    },
                    {
                        "@pid": "133/8188",
                        "text": "Aravind Machiry"
                    },
                    {
                        "@pid": "127/9829",
                        "text": "Ruoyu Wang 0001"
                    },
                    {
                        "@pid": "30/7555",
                        "text": "Chad Spensky"
                    },
                    {
                        "@pid": "190/9885",
                        "text": "Andrea Continella"
                    },
                    {
                        "@pid": "119/7712",
                        "text": "Yan Shoshitaishvili"
                    },
                    {
                        "@pid": "k/ChristopherKruegel",
                        "text": "Christopher Kruegel"
                    },
                    {
                        "@pid": "v/GiovanniVigna",
                        "text": "Giovanni Vigna"
                    }
                ]
            },
            "title": "Karonte: Detecting Insecure Multi-binary Interactions in Embedded Firmware.",
            "venue": "SP",
            "pages": "1544-1561",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/RediniM0SCSKV20",
            "doi": "10.1109/SP40000.2020.00036",
            "ee": "https://doi.org/10.1109/SP40000.2020.00036",
            "url": "https://dblp.org/rec/conf/sp/RediniM0SCSKV20",
            "abstract": "Low-power, single-purpose embedded devices (e.g., routers and IoT devices) have become ubiquitous. While they automate and simplify many aspects of users\u2019 lives, recent large-scale attacks have shown that their sheer number poses a severe threat to the Internet infrastructure. Unfortunately, the software on these systems is hardware-dependent, and typically executes in unique, minimal environments with non-standard configurations, making security analysis particularly challenging. Many of the existing devices implement their functionality through the use of multiple binaries. This multi-binary service implementation renders current static and dynamic analysis techniques either ineffective or inefficient, as they are unable to identify and adequately model the communication between the various executables. In this paper, we present Karonte, a static analysis approach capable of analyzing embedded-device firmware by modeling and tracking multi-binary interactions. Our approach propagates taint information between binaries to detect insecure interactions and identify vulnerabilities. We first evaluated Karonte on 53 firmware samples from various vendors, showing that our prototype tool can successfully track and constrain multi-binary interactions. This led to the discovery of 46 zero-day bugs. Then, we performed a large-scale experiment on 899 different samples, showing that Karonte scales well with firmware samples of different size and complexity.",
            "keywords": [
                "Embedded Firmware Security",
                "Multi-binary Analysis",
                "Static Analysis",
                "Vulnerability Detection",
                "Taint Propagation"
            ]
        },
        "url": "URL#2326713",
        "sema_paperId": "6486dea4c8b71e652d091e287927a5e0a17b97a4"
    },
    {
        "@score": "1",
        "@id": "2326714",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "36/8412",
                        "text": "Kevin A. Roundy"
                    },
                    {
                        "@pid": "272/8310",
                        "text": "Paula Barmaimon Mendelberg"
                    },
                    {
                        "@pid": "75/11301",
                        "text": "Nicola Dell"
                    },
                    {
                        "@pid": "58/4016",
                        "text": "Damon McCoy"
                    },
                    {
                        "@pid": "272/8280",
                        "text": "Daniel Nissani"
                    },
                    {
                        "@pid": "26/3399",
                        "text": "Thomas Ristenpart"
                    },
                    {
                        "@pid": "79/9389",
                        "text": "Acar Tamersoy"
                    }
                ]
            },
            "title": "The Many Kinds of Creepware Used for Interpersonal Attacks.",
            "venue": "SP",
            "pages": "626-643",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/RoundyMDMNRT20",
            "doi": "10.1109/SP40000.2020.00069",
            "ee": "https://doi.org/10.1109/SP40000.2020.00069",
            "url": "https://dblp.org/rec/conf/sp/RoundyMDMNRT20",
            "abstract": "Technology increasingly facilitates interpersonal attacks such as stalking, abuse, and other forms of harassment. While prior studies have examined the ecosystem of software designed for stalking, there exists an unstudied, larger landscape of apps\u2014what we call creepware\u2014used for interpersonal attacks. In this paper, we initiate a study of creepware using access to a dataset detailing the mobile apps installed on over 50 million Android devices. We develop a new algorithm, CreepRank, that uses the principle of guilt by association to help surface previously unknown examples of creepware, which we then characterize through a combination of quantitative and qualitative methods. We discovered apps used for harassment, impersonation, fraud, information theft, concealment, and even apps that purport to defend victims against such threats. As a result of our work, the Google Play Store has already removed hundreds of apps for policy violations. More broadly, our findings and techniques improve understanding of the creepware ecosystem, and will inform future efforts that aim to mitigate interpersonal attacks.",
            "keywords": [
                "Creepware",
                "Interpersonal Attacks",
                "Stalking",
                "Harassment",
                "Mobile Apps"
            ]
        },
        "url": "URL#2326714",
        "sema_paperId": "f52b9ea6325d1089ddb606e152672bab7448d73b"
    },
    {
        "@score": "1",
        "@id": "2326715",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "170/0259",
                        "text": "Philipp Schindler"
                    },
                    {
                        "@pid": "178/3737",
                        "text": "Aljosha Judmayer"
                    },
                    {
                        "@pid": "202/7551",
                        "text": "Nicholas Stifter"
                    },
                    {
                        "@pid": "w/EdgarRWeippl",
                        "text": "Edgar R. Weippl"
                    }
                ]
            },
            "title": "HydRand: Efficient Continuous Distributed Randomness.",
            "venue": "SP",
            "pages": "73-89",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/SchindlerJSW20",
            "doi": "10.1109/SP40000.2020.00003",
            "ee": "https://doi.org/10.1109/SP40000.2020.00003",
            "url": "https://dblp.org/rec/conf/sp/SchindlerJSW20",
            "abstract": "A reliable source of randomness is not only an essential building block in various cryptographic, security, and distributed systems protocols, but also plays an integral part in the design of many new blockchain proposals. Consequently, the topic of publicly-verifiable, bias-resistant and unpredictable randomness has recently enjoyed increased attention. In particular random beacon protocols, aimed at continuous operation, can be a vital component for current Proof-of-Stake based distributed ledger proposals. We improve upon previous random beacon approaches with HydRand, a novel distributed protocol based on publicly-verifiable secret sharing (PVSS) to ensure unpredictability, bias-resistance, and public-verifiability of a continuous sequence of random beacon values. Furthermore, HydRand provides guaranteed output delivery of randomness at regular and predictable intervals in the presence of adversarial behavior and does not rely on a trusted dealer for the initial setup. Compared to existing PVSS based approaches that strive to achieve similar properties, our solution improves scalability by lowering the communication complexity from $\\mathcal{O}\\left( {{n^3}} \\right)$ to $\\mathcal{O}\\left( {{n^2}} \\right)$ . Furthermore, we are the first to present a detailed comparison of recently described schemes and protocols that can be used for implementing random beacons.",
            "keywords": [
                "Distributed Randomness",
                "Random Beacon Protocols",
                "Publicly-Verifiable Secret Sharing",
                "Bias-Resistance",
                "Scalability"
            ]
        },
        "url": "URL#2326715",
        "sema_paperId": "8f29b98629afb8fa0bb753fc8d53e4c28560fb5c"
    },
    {
        "@score": "1",
        "@id": "2326716",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "180/8190",
                        "text": "Roei Schuster"
                    },
                    {
                        "@pid": "190/7491",
                        "text": "Tal Schuster"
                    },
                    {
                        "@pid": "256/5342",
                        "text": "Yoav Meri"
                    },
                    {
                        "@pid": "46/6275",
                        "text": "Vitaly Shmatikov"
                    }
                ]
            },
            "title": "Humpty Dumpty: Controlling Word Meanings via Corpus Poisoning.",
            "venue": "SP",
            "pages": "1295-1313",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/SchusterSMS20",
            "doi": "10.1109/SP40000.2020.00115",
            "ee": "https://doi.org/10.1109/SP40000.2020.00115",
            "url": "https://dblp.org/rec/conf/sp/SchusterSMS20",
            "abstract": "Word embeddings, i.e., low-dimensional vector representations such as GloVe and SGNS, encode word \"meaning\" in the sense that distances between words' vectors correspond to their semantic proximity. This enables transfer learning of semantics for a variety of natural language processing tasks.Word embeddings are typically trained on large public corpora such as Wikipedia or Twitter. We demonstrate that an attacker who can modify the corpus on which the embedding is trained can control the \"meaning\" of new and existing words by changing their locations in the embedding space. We develop an explicit expression over corpus features that serves as a proxy for distance between words and establish a causative relationship between its values and embedding distances. We then show how to use this relationship for two adversarial objectives: (1) make a word a top-ranked neighbor of another word, and (2) move a word from one semantic cluster to another.An attack on the embedding can affect diverse downstream tasks, demonstrating for the first time the power of data poisoning in transfer learning scenarios. We use this attack to manipulate query expansion in information retrieval systems such as resume search, make certain names more or less visible to named entity recognition models, and cause new words to be translated to a particular target word regardless of the language. Finally, we show how the attacker can generate linguistically likely corpus modifications, thus fooling defenses that attempt to filter implausible sentences from the corpus using a language model.",
            "pdf_url": "",
            "keywords": [
                "Word Embeddings",
                "Corpus Poisoning",
                "Semantic Manipulation",
                "Transfer Learning",
                "Adversarial Attacks"
            ]
        },
        "url": "URL#2326716"
    },
    {
        "@score": "1",
        "@id": "2326719",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "168/9537",
                        "text": "Dongdong She"
                    },
                    {
                        "@pid": "09/7487-1",
                        "text": "Yizheng Chen 0001"
                    },
                    {
                        "@pid": "162/8000",
                        "text": "Abhishek Shah"
                    },
                    {
                        "@pid": "74/1969",
                        "text": "Baishakhi Ray"
                    },
                    {
                        "@pid": "74/28",
                        "text": "Suman Jana"
                    }
                ]
            },
            "title": "Neutaint: Efficient Dynamic Taint Analysis with Neural Networks.",
            "venue": "SP",
            "pages": "1527-1543",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/SheCSRJ20",
            "doi": "10.1109/SP40000.2020.00022",
            "ee": "https://doi.org/10.1109/SP40000.2020.00022",
            "url": "https://dblp.org/rec/conf/sp/SheCSRJ20",
            "abstract": "Dynamic taint analysis (DTA) is widely used by various applications to track information flow during runtime execution. Existing DTA techniques use rule-based taint-propagation, which is neither accurate (i.e., high false positive rate) nor efficient (i.e., large runtime overhead). It is hard to specify taint rules for each operation while covering all corner cases correctly. Moreover, the overtaint and undertaint errors can accumulate during the propagation of taint information across multiple operations. Finally, rule-based propagation requires each operation to be inspected before applying the appropriate rules resulting in prohibitive performance overhead on large real-world applications.In this work, we propose Neutaint, a novel end-to-end approach to track information flow using neural program embeddings. The neural program embeddings model the target's programs computations taking place between taint sources and sinks, which automatically learns the information flow by observing a diverse set of execution traces. To perform lightweight and precise information flow analysis, we utilize saliency maps to reason about most influential sources for different sinks. Neutaint constructs two saliency maps, a popular machine learning approach to influence analysis, to summarize both coarse-grained and fine-grained information flow in the neural program embeddings.We compare Neutaint with 3 state-of-the-art dynamic taint analysis tools. The evaluation results show that Neutaint can achieve 68% accuracy, on average, which is 10% improvement while reducing 40\u00d7 runtime overhead over the second-best taint tool Libdft on 6 real world programs. Neutaint also achieves 61% more edge coverage when used for taint-guided fuzzing indicating the effectiveness of the identified influential bytes. We also evaluate Neutaint's ability to detect real world software attacks. The results show that Neutaint can successfully detect different types of vulnerabilities including buffer/heap/integer overflows, division by zero, etc. Lastly, Neutaint can detect 98.7% of total flows, the highest among all taint analysis tools.",
            "pdf_url": "",
            "keywords": [
                "Dynamic Taint Analysis",
                "Information Flow Tracking",
                "Neural Program Embeddings",
                "Runtime Overhead Reduction",
                "Vulnerability Detection"
            ]
        },
        "url": "URL#2326719"
    },
    {
        "@score": "1",
        "@id": "2326720",
        "info": {
            "authors": {
                "author": {
                    "@pid": "80/4580",
                    "text": "Elaine Shi"
                }
            },
            "title": "Path Oblivious Heap: Optimal and Practical Oblivious Priority Queue.",
            "venue": "SP",
            "pages": "842-858",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/Shi20",
            "doi": "10.1109/SP40000.2020.00037",
            "ee": "https://doi.org/10.1109/SP40000.2020.00037",
            "url": "https://dblp.org/rec/conf/sp/Shi20",
            "abstract": "We propose Path Oblivious Heap, an extremely simple, practical, and optimal oblivious priority queue. Our construction also implies a practical and optimal oblivious sorting algorithm which we call Path Oblivious Sort. Not only are our algorithms asymptotically optimal, we show that their practical performance is only a small constant factor worse than insecure baselines. More specificially, assuming roughly logarithmic client private storage, Path Oblivious Heap consumes 2\u00d7 to 7\u00d7 more bandwidth than the ordinary insecure binary heap; and Path Oblivious Sort consumes 4.5\u00d7 to 6\u00d7 more bandwidth than the insecure Merge Sort. We show that these performance results improve existing works by 1-2 orders of magnitude. Finally, we evaluate our algorithm for a multi-party computation scenario and show 7x to 8x reduction in the number of symmetric encryptions relative to the state of the art<sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</sup>.",
            "pdf_url": "",
            "keywords": [
                "Oblivious Priority Queue",
                "Path Oblivious Heap",
                "Oblivious Sorting",
                "Bandwidth Efficiency",
                "Multi-Party Computation"
            ]
        },
        "url": "URL#2326720"
    },
    {
        "@score": "1",
        "@id": "2326723",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "187/9138",
                        "text": "Sunbeom So"
                    },
                    {
                        "@pid": "61/107",
                        "text": "Myungho Lee"
                    },
                    {
                        "@pid": "207/8774",
                        "text": "Jisu Park"
                    },
                    {
                        "@pid": "75/4485",
                        "text": "Heejo Lee"
                    },
                    {
                        "@pid": "13/7537",
                        "text": "Hakjoo Oh"
                    }
                ]
            },
            "title": "VERISMART: A Highly Precise Safety Verifier for Ethereum Smart Contracts.",
            "venue": "SP",
            "pages": "1678-1694",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/SoLPLO20",
            "doi": "10.1109/SP40000.2020.00032",
            "ee": "https://doi.org/10.1109/SP40000.2020.00032",
            "url": "https://dblp.org/rec/conf/sp/SoLPLO20",
            "abstract": "We present VERISMART, a highly precise verifier for ensuring arithmetic safety of Ethereum smart contracts. Writing safe smart contracts without unintended behavior is critically important because smart contracts are immutable and even a single flaw can cause huge financial damage. In particular, ensuring that arithmetic operations are safe is one of the most important and common security concerns of Ethereum smart contracts nowadays. In response, several safety analyzers have been proposed over the past few years, but state-of-the-art is still unsatisfactory; no existing tools achieve high precision and recall at the same time, inherently limited to producing annoying false alarms or missing critical bugs. By contrast, VERISMART aims for an uncompromising analyzer that performs exhaustive verification without compromising precision or scalability, thereby greatly reducing the burden of manually checking undiscovered or incorrectly-reported issues. To achieve this goal, we present a new domain-specific algorithm for verifying smart contracts, which is able to automatically discover and leverage transaction invariants that are essential for precisely analyzing smart contracts. Evaluation with real-world smart contracts shows that VERISMART can detect all arithmetic bugs with a negligible number of false alarms, far outperforming existing analyzers.",
            "pdf_url": "",
            "keywords": [
                "Ethereum Smart Contracts",
                "Arithmetic Safety",
                "Safety Verification",
                "False Alarms",
                "Transaction Invariants"
            ]
        },
        "url": "URL#2326723"
    },
    {
        "@score": "1",
        "@id": "2326726",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "184/5980",
                        "text": "Zhichuang Sun"
                    },
                    {
                        "@pid": "25/13-2",
                        "text": "Bo Feng 0002"
                    },
                    {
                        "@pid": "81/7428",
                        "text": "Long Lu"
                    },
                    {
                        "@pid": "j/SomeshJha",
                        "text": "Somesh Jha"
                    }
                ]
            },
            "title": "OAT: Attesting Operation Integrity of Embedded Devices.",
            "venue": "SP",
            "pages": "1433-1449",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/SunFLJ20",
            "doi": "10.1109/SP40000.2020.00042",
            "ee": "https://doi.org/10.1109/SP40000.2020.00042",
            "url": "https://dblp.org/rec/conf/sp/SunFLJ20",
            "abstract": "Due to the wide adoption of IoT/CPS systems, embedded devices (IoT frontends) become increasingly connected and mission-critical, which in turn has attracted advanced attacks (e.g., control-flow hijacks and data-only attacks). Unfortunately, IoT backends (e.g., remote controllers or in-cloud services) are unable to detect if such attacks have happened while receiving data, service requests, or operation status from IoT devices (remotely deployed embedded devices). As a result, currently, IoT backends are forced to blindly trust the IoT devices that they interact with.To fill this void, we first formulate a new security property for embedded devices, called \"Operation Execution Integrity\" or OEI. We then design and build a system, OAT, that enables remote OEI attestation for ARM-based bare-metal embedded devices. Our formulation of OEI captures the integrity of both control flow and critical data involved in an operation execution. Therefore, satisfying OEI entails that an operation execution is free of unexpected control and data manipulations, which existing attestation methods cannot check. Our design of OAT strikes a balance between prover\u2019s constraints (embedded devices\u2019 limited computing power and storage) and verifier\u2019s requirements (complete verifiability and forensic assistance). OAT uses a new control-flow measurement scheme, which enables lightweight and space-efficient collection of measurements (97% space reduction from the trace-based approach). OAT performs the remote control-flow verification through abstract execution, which is fast and deterministic. OAT also features lightweight integrity checking for critical data (74% less instrumentation needed than previous work). Our security analysis shows that OAT allows remote verifiers or IoT backends to detect both controlflow hijacks and data-only attacks that affect the execution of operations on IoT devices. In our evaluation using real embedded programs, OAT incurs a runtime overhead of 2.7%.",
            "keywords": [
                "Embedded Device Security",
                "Remote Attestation",
                "Operation Execution Integrity",
                "Control-Flow Hijacks",
                "Data-Only Attacks"
            ]
        },
        "url": "URL#2326726",
        "sema_paperId": "58bc50566eaae8d023129cd131f54b7bfd05e20f"
    },
    {
        "@score": "1",
        "@id": "2326728",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "119/7737",
                        "text": "Alin Tomescu"
                    },
                    {
                        "@pid": "35/8919",
                        "text": "Robert Chen"
                    },
                    {
                        "@pid": "133/3928",
                        "text": "Yiming Zheng"
                    },
                    {
                        "@pid": "36/5720",
                        "text": "Ittai Abraham"
                    },
                    {
                        "@pid": "31/1735",
                        "text": "Benny Pinkas"
                    },
                    {
                        "@pid": "29/1487",
                        "text": "Guy Golan-Gueta"
                    },
                    {
                        "@pid": "14/3973",
                        "text": "Srinivas Devadas"
                    }
                ]
            },
            "title": "Towards Scalable Threshold Cryptosystems.",
            "venue": "SP",
            "pages": "877-893",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/TomescuCZAPGD20",
            "doi": "10.1109/SP40000.2020.00059",
            "ee": "https://doi.org/10.1109/SP40000.2020.00059",
            "url": "https://dblp.org/rec/conf/sp/TomescuCZAPGD20",
            "abstract": "The resurging interest in Byzantine fault tolerant systems will demand more scalable threshold cryptosystems. Unfortunately, current systems scale poorly, requiring time quadratic in the number of participants. In this paper, we present techniques that help scale threshold signature schemes (TSS), verifiable secret sharing (VSS) and distributed key generation (DKG) protocols to hundreds of thousands of participants and beyond. First, we use efficient algorithms for evaluating polynomials at multiple points to speed up computing Lagrange coefficients when aggregating threshold signatures. As a result, we can aggregate a 130,000 out of 260,000 BLS threshold signature in just 6 seconds (down from 30 minutes). Second, we show how \"authenticating\" such multipoint evaluations can speed up proving polynomial evaluations, a key step in communication-efficient VSS and DKG protocols. As a result, we reduce the asymptotic (and concrete) computational complexity of VSS and DKG protocols from quadratic time to quasilinear time, at a small increase in communication complexity. For example, using our DKG protocol, we can securely generate a key for the BLS scheme above in 2.3 hours (down from 8 days). Our techniques improve performance for thresholds as small as 255 and generalize to any Lagrange-based threshold scheme, not just threshold signatures. Our work has certain limitations: we require a trusted setup, we focus on synchronous VSS and DKG protocols and we do not address the worst-case complaint overhead in DKGs. Nonetheless, we hope it will spark new interest in designing large-scale distributed systems.",
            "keywords": [
                "Threshold Cryptography",
                "Scalable Systems",
                "Threshold Signature Schemes",
                "Verifiable Secret Sharing",
                "Distributed Key Generation"
            ]
        },
        "url": "URL#2326728",
        "sema_paperId": "6089a986ac614a4942dad7ee7b813e0036b0742c"
    },
    {
        "@score": "1",
        "@id": "2326729",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "239/5173",
                        "text": "Chau Tran"
                    },
                    {
                        "@pid": "239/5267",
                        "text": "Kaylea Champion"
                    },
                    {
                        "@pid": "03/5594",
                        "text": "Andrea Forte"
                    },
                    {
                        "@pid": "87/3900",
                        "text": "Benjamin Mako Hill"
                    },
                    {
                        "@pid": "93/655",
                        "text": "Rachel Greenstadt"
                    }
                ]
            },
            "title": "Are anonymity-seekers just like everybody else? An analysis of contributions to Wikipedia from Tor.",
            "venue": "SP",
            "pages": "186-202",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/TranCFHG20",
            "doi": "10.1109/SP40000.2020.00053",
            "ee": "https://doi.org/10.1109/SP40000.2020.00053",
            "url": "https://dblp.org/rec/conf/sp/TranCFHG20",
            "abstract": "User-generated content sites routinely block contributions from users of privacy-enhancing proxies like Tor because of a perception that proxies are a source of vandalism, spam, and abuse. Although these blocks might be effective, collateral damage in the form of unrealized valuable contributions from anonymity seekers is invisible. One of the largest and most important user-generated content sites, Wikipedia, has attempted to block contributions from Tor users since as early as 2005. We demonstrate that these blocks have been imperfect and that thousands of attempts to edit on Wikipedia through Tor have been successful. We draw upon several data sources and analytical techniques to measure and describe the history of Tor editing on Wikipedia over time and to compare contributions from Tor users to those from other groups of Wikipedia users. Our analysis suggests that although Tor users who slip through Wikipedia\u2019s ban contribute content that is more likely to be reverted and to revert others, their contributions are otherwise similar in quality to those from other unregistered participants and to the initial contributions of registered users.",
            "keywords": [
                "Wikipedia Contributions",
                "Anonymity Seekers",
                "Tor Users",
                "User-Generated Content",
                "Content Quality Comparison"
            ]
        },
        "url": "URL#2326729",
        "sema_paperId": "9c0af5f102ff017ff88f72558c8cae0d1ec83212"
    },
    {
        "@score": "1",
        "@id": "2326730",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "216/6267",
                        "text": "Muoi Tran"
                    },
                    {
                        "@pid": "77/3578",
                        "text": "Inho Choi"
                    },
                    {
                        "@pid": "271/9731",
                        "text": "Gi Jun Moon"
                    },
                    {
                        "@pid": "249/1830",
                        "text": "Anh V. Vu"
                    },
                    {
                        "@pid": "75/8333",
                        "text": "Min Suk Kang"
                    }
                ]
            },
            "title": "A Stealthier Partitioning Attack against Bitcoin Peer-to-Peer Network.",
            "venue": "SP",
            "pages": "894-909",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/TranCMVK20",
            "doi": "10.1109/SP40000.2020.00027",
            "ee": "https://doi.org/10.1109/SP40000.2020.00027",
            "url": "https://dblp.org/rec/conf/sp/TranCMVK20",
            "abstract": "Network adversaries, such as malicious transit autonomous systems (ASes), have been shown to be capable of partitioning the Bitcoin\u2019s peer-to-peer network via routing-level attacks; e.g., a network adversary exploits a BGP vulnerability and performs a prefix hijacking attack (viz. Apostolaki et al. [3]). Due to the nature of BGP operation, such a hijacking is globally observable and thus enables immediate detection of the attack and the identification of the perpetrator. In this paper, we present a stealthier attack, which we call the EREBUS attack, that partitions the Bitcoin network without any routing manipulations, which makes the attack undetectable to control-plane and even to data-plane detectors. The novel aspect of EREBUS is that it makes the adversary AS a natural man-in-the-middle network of all the peer connections of one or more targeted Bitcoin nodes by patiently influencing the targeted nodes\u2019 peering decision. We show that affecting the peering decision of a Bitcoin node, which is believed to be infeasible after a series of bug patches against the earlier Eclipse attack [29], is possible for the network adversary that can use abundant network address resources (e.g., spoofing millions of IP addresses in many other ASes) reliably for an extended period of time at a negligible cost. The EREBUS attack is readily available for large ASes, such as Tier-1 and large Tier-2 ASes, against the vast majority of 10K public Bitcoin nodes with only about 520 bit/s of attack traffic rate per targeted Bitcoin node and a modest (e.g., 5\u20136 weeks) attack execution period. The EREBUS attack can be mounted by nation-state adversaries who would be willing to execute sophisticated attack strategies patiently to compromise cryptocurrencies (e.g., control the consensus, take down a cryptocurrency, censor transactions). As the attack exploits the topological advantage of being a network adversary but not the specific vulnerabilities of Bitcoin core, no quick patches seem to be available. We discuss that some naive solutions (e.g., whitelisting, rate-limiting) are ineffective and third-party proxy solutions may worsen the Bitcoin\u2019s centralization problem. We provide some suggested modifications to the Bitcoin core and show that they effectively make the EREBUS attack significantly harder; yet, their non-trivial changes to the Bitcoin\u2019s network operation (e.g., peering dynamics, propagation delays) should be examined thoroughly before their wide deployment.",
            "keywords": [
                "Bitcoin Network",
                "Peer-to-Peer Network",
                "Eclipse Attack",
                "Network Partitioning",
                "EREBUS Attack"
            ]
        },
        "url": "URL#2326730",
        "sema_paperId": "6dd8e944da8955a7ab066f7f4e1d054486f05cf5"
    },
    {
        "@score": "1",
        "@id": "2326731",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "202/7675",
                        "text": "Timothy Trippel"
                    },
                    {
                        "@pid": "s/KangGShin",
                        "text": "Kang G. Shin"
                    },
                    {
                        "@pid": "178/8969",
                        "text": "Kevin B. Bush"
                    },
                    {
                        "@pid": "09/2334",
                        "text": "Matthew Hicks"
                    }
                ]
            },
            "title": "ICAS: an Extensible Framework for Estimating the Susceptibility of IC Layouts to Additive Trojans.",
            "venue": "SP",
            "pages": "1742-1759",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/TrippelSBH20",
            "doi": "10.1109/SP40000.2020.00083",
            "ee": "https://doi.org/10.1109/SP40000.2020.00083",
            "url": "https://dblp.org/rec/conf/sp/TrippelSBH20",
            "abstract": "The transistors used to construct Integrated Circuits (ICs) continue to shrink. While this shrinkage improves performance and density, it also reduces trust: the price to build leading-edge fabrication facilities has skyrocketed, forcing even nation states to outsource the fabrication of high-performance ICs. Outsourcing fabrication presents a security threat because the black-box nature of a fabricated IC makes comprehensive inspection infeasible. Since prior work shows the feasibility of fabrication-time attackers\u2019 evasion of existing post-fabrication defenses, IC designers must be able to protect their physical designs before handing them off to an untrusted foundry. To this end, recent work suggests methods to harden IC layouts against attack. Unfortunately, no tool exists to assess the effectiveness of the proposed defenses, thus leaving defensive gaps.This paper presents an extensible IC layout security analysis tool called IC Attack Surface (ICAS) that quantifies defensive coverage. For researchers, ICAS identifies gaps for future defenses to target, and enables the quantitative comparison of existing and future defenses. For practitioners, ICAS enables the exploration of the impact of design decisions on an IC\u2019s resilience to fabrication-time attack. ICAS takes a set of metrics that encode the challenge of inserting a hardware Trojan into an IC layout, a set of attacks that the defender cares about, and a completed IC layout and reports the number of ways an attacker can add each attack to the design. While the ideal score is zero, practically, we find that lower scores correlate with increased attacker effort.To demonstrate ICAS\u2019 ability to reveal defensive gaps, we analyze over 60 layouts of three real-world hardware designs (a processor, AES and DSP accelerators), protected with existing defenses. We evaluate the effectiveness of each circuit\u2013defense combination against three representative attacks from the literature. Results show that some defenses are ineffective and others, while effective at reducing the attack surface, leave 10\u2019s to 1000\u2019s of unique attack implementations that an attacker can exploit.",
            "keywords": [
                "IC Layout Security",
                "Hardware Trojans",
                "Defensive Coverage",
                "Fabrication-time Attacks",
                "Attack Surface Analysis"
            ]
        },
        "url": "URL#2326731",
        "sema_paperId": "cc04be19417146e55b7e7323512c157b39b0c431"
    },
    {
        "@score": "1",
        "@id": "2326732",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "45/1247",
                        "text": "Michael Carl Tschantz"
                    },
                    {
                        "@pid": "154/3380",
                        "text": "Shayak Sen"
                    },
                    {
                        "@pid": "d/AnupamDatta",
                        "text": "Anupam Datta"
                    }
                ]
            },
            "title": "SoK: Differential Privacy as a Causal Property.",
            "venue": "SP",
            "pages": "354-371",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/TschantzSD20",
            "doi": "10.1109/SP40000.2020.00012",
            "ee": "https://doi.org/10.1109/SP40000.2020.00012",
            "url": "https://dblp.org/rec/conf/sp/TschantzSD20",
            "abstract": "We present formal models of the associative and causal views of differential privacy. Under the associative view, the possibility of dependencies between data points precludes a simple statement of differential privacy's guarantee as conditioning upon a single changed data point. However, we show that a simple characterization of differential privacy as limiting the effect of a single data point does exist under the causal view, without independence assumptions about data points. We believe this characterization resolves disagreement and confusion in prior work about the consequences of differential privacy. The associative view needing assumptions boils down to the contrapositive of the maxim that correlation doesn't imply causation: differential privacy ensuring a lack of (strong) causation does not imply a lack of (strong) association. Our characterization also opens up the possibility of applying results from statistics, experimental design, and science about causation while studying differential privacy.",
            "keywords": [
                "Differential Privacy",
                "Causal Inference",
                "Associative View",
                "Causal View",
                "Data Dependencies"
            ]
        },
        "url": "URL#2326732",
        "sema_paperId": "724ac94ee4de1f8d7a645a9b7df5d1a7f710d571"
    },
    {
        "@score": "1",
        "@id": "2326733",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "130/3608",
                        "text": "Mathy Vanhoef"
                    },
                    {
                        "@pid": "180/7297",
                        "text": "Eyal Ronen"
                    }
                ]
            },
            "title": "Dragonblood: Analyzing the Dragonfly Handshake of WPA3 and EAP-pwd.",
            "venue": "SP",
            "pages": "517-533",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/VanhoefR20",
            "doi": "10.1109/SP40000.2020.00031",
            "ee": "https://doi.org/10.1109/SP40000.2020.00031",
            "url": "https://dblp.org/rec/conf/sp/VanhoefR20",
            "abstract": "The WPA3 certification aims to secure home networks, while EAP-pwd is used by certain enterprise Wi-Fi networks to authenticate users. Both use the Dragonfly handshake to provide forward secrecy and resistance to dictionary attacks. In this paper, we systematically evaluate Dragonfly\u2019s security. First, we audit implementations, and present timing leaks and authentication bypasses in EAP-pwd and WPA3 daemons. We then study Dragonfly\u2019s design and discuss downgrade and denial-of-service attacks. Our next and main results are side-channel attacks against Dragonfly\u2019s password encoding method (e.g. hash-to-curve). We believe that these side-channel leaks are inherent to Dragonfly. For example, after our initial disclosure, patched software was still affected by a novel side-channel leak. We also analyze the complexity of using the leaked information to brute-force the password. For instance, brute-forcing a dictionary of size 1010 requires less than $1 in Amazon EC2 instances. These results are also of general interest due to ongoing standardization efforts on Dragonfly as a TLS handshake, Password-Authenticated Key Exchanges (PAKEs), and hash-to-curve. Finally, we discuss backwards-compatible defenses, and propose protocol fixes that prevent attacks. Our work resulted in a new draft of the protocols incorporating our proposed design changes.",
            "keywords": [
                "WPA3",
                "EAP-pwd",
                "Dragonfly Handshake",
                "Side-Channel Attacks",
                "Password Encoding Vulnerabilities"
            ]
        },
        "url": "URL#2326733",
        "sema_paperId": "2bf063c5944d51ea654c52a29407f8b70c71bdee"
    },
    {
        "@score": "1",
        "@id": "2326734",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "228/7035",
                        "text": "Elisabet Lobo Vesga"
                    },
                    {
                        "@pid": "48/5534",
                        "text": "Alejandro Russo"
                    },
                    {
                        "@pid": "84/3396",
                        "text": "Marco Gaboardi"
                    }
                ]
            },
            "title": "A Programming Framework for Differential Privacy with Accuracy Concentration Bounds.",
            "venue": "SP",
            "pages": "411-428",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/VesgaRG20",
            "doi": "10.1109/SP40000.2020.00086",
            "ee": "https://doi.org/10.1109/SP40000.2020.00086",
            "url": "https://dblp.org/rec/conf/sp/VesgaRG20",
            "abstract": "Differential privacy offers a formal framework for reasoning about privacy and accuracy of computations on private data. It also offers a rich set of building blocks for constructing private data analyses. When carefully calibrated, these analyses simultaneously guarantee the privacy of the individuals contributing their data, and the accuracy of the data analyses results, inferring useful properties about the population. The compositional nature of differential privacy has motivated the design and implementation of several programming languages aimed at helping a data analyst in programming differentially private analyses. However, most of the programming languages for differential privacy proposed so far provide support for reasoning about privacy but not for reasoning about the accuracy of data analyses. To overcome this limitation, in this work we present DPella, a programming framework providing data analysts with support for reasoning about privacy, accuracy and their trade-offs. The distinguishing feature of DPella is a novel component which statically tracks the accuracy of different data analyses. In order to make tighter accuracy estimations, this component leverages taint analysis for automatically inferring statistical independence of the different noise quantities added for guaranteeing privacy. We evaluate our approach by implementing several classical queries from the literature and showing how data analysts can figure out the best manner to calibrate privacy to meet the accuracy requirements.",
            "keywords": [
                "Differential Privacy",
                "Accuracy Estimation",
                "Privacy-Accuracy Trade-offs",
                "Taint Analysis",
                "DPella Framework"
            ]
        },
        "url": "URL#2326734",
        "sema_paperId": "820a7da0868c40b85035de0c83c7d786b13e4523"
    },
    {
        "@score": "1",
        "@id": "2326735",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "75/3158-17",
                        "text": "Zhe Wang 0017"
                    },
                    {
                        "@pid": "51/3529-2",
                        "text": "Chenggang Wu 0002"
                    },
                    {
                        "@pid": "190/5112",
                        "text": "Mengyao Xie"
                    },
                    {
                        "@pid": "77/3503",
                        "text": "Yinqian Zhang"
                    },
                    {
                        "@pid": "67/10639",
                        "text": "Kangjie Lu"
                    },
                    {
                        "@pid": "61/3976",
                        "text": "Xiaofeng Zhang"
                    },
                    {
                        "@pid": "198/8150",
                        "text": "Yuanming Lai"
                    },
                    {
                        "@pid": "32/1654-2",
                        "text": "Yan Kang 0002"
                    },
                    {
                        "@pid": "02/1640-2",
                        "text": "Min Yang 0002"
                    }
                ]
            },
            "title": "SEIMI: Efficient and Secure SMAP-Enabled Intra-process Memory Isolation.",
            "venue": "SP",
            "pages": "592-607",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/Wang0XZLZLKY20",
            "doi": "10.1109/SP40000.2020.00087",
            "ee": "https://doi.org/10.1109/SP40000.2020.00087",
            "url": "https://dblp.org/rec/conf/sp/Wang0XZLZLKY20",
            "abstract": "Memory-corruption attacks such as code-reuse attacks and data-only attacks have been a key threat to systems security. To counter these threats, researchers have proposed a variety of defenses, including control-flow integrity (CFI), code-pointer integrity (CPI), and code (re-)randomization. All of them, to be effective, require a security primitive\u2014intra-process protection of confidentiality and/or integrity for sensitive data (such as CFI\u2019s shadow stack and CPI\u2019s safe region).In this paper, we propose SEIMI, a highly efficient intra-process memory isolation technique for memory-corruption defenses to protect their sensitive data. The core of SEIMI is to use the efficient Supervisor-mode Access Prevention (SMAP), a hardware feature that is originally used for preventing the kernel from accessing the user space, to achieve intra-process memory isolation. To leverage SMAP, SEIMI creatively executes the user code in the privileged mode. In addition to enabling the new design of the SMAP-based memory isolation, we further develop multiple new techniques to ensure secure escalation of user code, e.g., using the descriptor caches to capture the potential segment operations and configuring the Virtual Machine Control Structure (VMCS) to invalidate the execution result of the control registers related operations. Extensive experimental results show that SEIMI outperforms existing isolation mechanisms, including both the Memory Protection Keys (MPK) based scheme and the Memory Protection Extensions (MPX) based scheme, while providing secure memory isolation.",
            "keywords": [
                "Intra-process Memory Isolation",
                "Memory-corruption Attacks",
                "Supervisor-mode Access Prevention (SMAP)",
                "Control-flow Integrity (CFI)",
                "Code-pointer Integrity (CPI)"
            ]
        },
        "url": "URL#2326735",
        "sema_paperId": "812607001031f55e2245f1d67377c873e331fa1e"
    },
    {
        "@score": "1",
        "@id": "2326736",
        "info": {
            "authors": {
                "author": {
                    "@pid": "12/5838-12",
                    "text": "Tao Wang 0012"
                }
            },
            "title": "High Precision Open-World Website Fingerprinting.",
            "venue": "SP",
            "pages": "152-167",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/Wang20",
            "doi": "10.1109/SP40000.2020.00015",
            "ee": "https://doi.org/10.1109/SP40000.2020.00015",
            "url": "https://dblp.org/rec/conf/sp/Wang20",
            "abstract": "Traffic analysis attacks to identify which web page a client is browsing, using only her packet metadata \u2014 known as website fingerprinting (WF) \u2014 has been proven effective in closed-world experiments against privacy technologies like Tor. We want to investigate their usefulness in the real open world. Several WF attacks claim to have high recall and low false positive rate, but they have only been shown to succeed against high base rate pages. We explicitly incorporate the base rate into precision and call it r-precision. Using this metric, we show that the best previous attacks have poor precision when the base rate is realistically low; we study such a scenario (r = 1000), where the maximum r-precision achieved was only 0.14.To improve r-precision, we propose three novel classes of precision optimizers that can be applied to any classifier to increase precision. For r = 1000, our best optimized classifier can achieve a precision of at least 0.86, representing a precision increase by more than 6 times. For the first time, we show a WF classifier that can scale to any open world set size. We also investigate the use of precise classifiers to tackle realistic objectives in website fingerprinting, including different types of websites, identification of sensitive clients, and defeating website fingerprinting defenses.",
            "keywords": [
                "Website Fingerprinting",
                "Traffic Analysis",
                "Precision Optimization",
                "Open-World Classification",
                "r-Precision"
            ]
        },
        "url": "URL#2326736",
        "sema_paperId": "679df4ad0c0556d409c5a23b39108f76093f1280"
    },
    {
        "@score": "1",
        "@id": "2326737",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "263/7337",
                        "text": "Luca Wilke"
                    },
                    {
                        "@pid": "225/5356",
                        "text": "Jan Wichelmann"
                    },
                    {
                        "@pid": "170/1847",
                        "text": "Mathias Morbitzer"
                    },
                    {
                        "@pid": "72/817",
                        "text": "Thomas Eisenbarth 0001"
                    }
                ]
            },
            "title": "SEVurity: No Security Without Integrity : Breaking Integrity-Free Memory Encryption with Minimal Assumptions.",
            "venue": "SP",
            "pages": "1483-1496",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/WilkeWM020",
            "doi": "10.1109/SP40000.2020.00080",
            "ee": "https://doi.org/10.1109/SP40000.2020.00080",
            "url": "https://dblp.org/rec/conf/sp/WilkeWM020",
            "abstract": "One reason for not adopting cloud services is the required trust in the cloud provider: As they control the hypervisor, any data processed in the system is accessible to them. Full memory encryption for Virtual Machines (VM) protects against curious cloud providers as well as otherwise compromised hypervisors. AMD Secure Encrypted Virtualization (SEV) is the most prevalent hardware-based full memory encryption for VMs. Its newest extension, SEV-ES, also protects the entire VM state during context switches, aiming to ensure that the host neither learns anything about the data that is processed inside the VM, nor is able to modify its execution state. Several previous works have analyzed the security of SEV and have shown that, by controlling I/O, it is possible to exfiltrate data or even gain control over the VM\u2019s execution. In this work, we introduce two new methods that allow us to inject arbitrary code into SEV-ES secured virtual machines. Due to the lack of proper integrity protection, it is sufficient to reuse existing ciphertext to build a high-speed encryption oracle. As a result, our attack no longer depends on control over the I/O, which is needed by prior attacks. As I/O manipulation is highly detectable, our attacks are stealthier. In addition, we reverse-engineer the previously unknown, improved Xor-Encrypt-Xor (XEX) based encryption mode, that AMD is using on updated processors, and show, for the first time, how it can be overcome by our new attacks.",
            "keywords": [
                "Cloud Security",
                "Memory Encryption",
                "AMD Secure Encrypted Virtualization (SEV)",
                "Integrity Protection",
                "Code Injection Attacks"
            ]
        },
        "url": "URL#2326737",
        "sema_paperId": "f2a57390a54b877f5d78c0f0c9811f7bafa24eef"
    },
    {
        "@score": "1",
        "@id": "2326739",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "58/2484",
                        "text": "Nan Wu"
                    },
                    {
                        "@pid": "60/11141",
                        "text": "Farhad Farokhi"
                    },
                    {
                        "@pid": "47/3219",
                        "text": "David B. Smith 0001"
                    },
                    {
                        "@pid": "71/5612",
                        "text": "Mohamed Ali K\u00e2afar"
                    }
                ]
            },
            "title": "The Value of Collaboration in Convex Machine Learning with Differential Privacy.",
            "venue": "SP",
            "pages": "304-317",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/WuFSK20",
            "doi": "10.1109/SP40000.2020.00025",
            "ee": "https://doi.org/10.1109/SP40000.2020.00025",
            "url": "https://dblp.org/rec/conf/sp/WuFSK20",
            "abstract": "In this paper, we apply machine learning to distributed private data owned by multiple data owners, entities with access to non-overlapping training datasets. We use noisy, differentially-private gradients to minimize the fitness cost of the machine learning model using stochastic gradient descent. We quantify the quality of the trained model, using the fitness cost, as a function of privacy budget and size of the distributed datasets to capture the trade-off between privacy and utility in machine learning. This way, we can predict the outcome of collaboration among privacy-aware data owners prior to executing potentially computationally-expensive machine learning algorithms. Particularly, we show that the difference between the fitness of the trained machine learning model using differentially-private gradient queries and the fitness of the trained machine model in the absence of any privacy concerns is inversely proportional to the size of the training datasets squared and the privacy budget squared. We successfully validate the performance prediction with the actual performance of the proposed privacy-aware learning algorithms, applied to: financial datasets for determining interest rates of loans using regression; and detecting credit card frauds using support vector machines.",
            "pdf_url": "",
            "keywords": [
                "Differential Privacy",
                "Distributed Data",
                "Collaborative Learning",
                "Privacy-Utility Trade-off",
                "Fitness Cost"
            ]
        },
        "url": "URL#2326739"
    },
    {
        "@score": "1",
        "@id": "2326740",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "71/1116",
                        "text": "Feng Xiao"
                    },
                    {
                        "@pid": "45/3214",
                        "text": "Jinquan Zhang"
                    },
                    {
                        "@pid": "312/6561",
                        "text": "Jianwei Huang"
                    },
                    {
                        "@pid": "64/1147",
                        "text": "Guofei Gu"
                    },
                    {
                        "@pid": "54/2696",
                        "text": "Dinghao Wu"
                    },
                    {
                        "@pid": "21/6121-5",
                        "text": "Peng Liu 0005"
                    }
                ]
            },
            "title": "Unexpected Data Dependency Creation and Chaining: A New Attack to SDN.",
            "venue": "SP",
            "pages": "1512-1526",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/XiaoZHGWL20",
            "doi": "10.1109/SP40000.2020.00017",
            "ee": "https://doi.org/10.1109/SP40000.2020.00017",
            "url": "https://dblp.org/rec/conf/sp/XiaoZHGWL20",
            "abstract": "Software-Defined Networking (SDN) is an emerging network architecture that provides programmable networking through a logically centralized controller. As SDN becomes more prominent, its security vulnerabilities become more evident than ever. Serving as the \"brain\" of a software-defined network, how the control plane (of the network) is exposed to external inputs (i.e., data plane messages) is directly correlated with how secure the network is. Fortunately, due to some unique SDN design choices (e.g., control plane and data plane separation), attackers often struggle to find a reachable path to those vulnerable logic hidden deeply within the control plane.In this paper, we demonstrate that it is possible for a weak adversary who only controls a commodity network device (host or switch) to attack previously unreachable control plane components by maliciously increasing reachability in the control plane. We introduce D2C2 (data dependency creation and chaining) attack, which leverages some widely-used SDN protocol features (e.g., custom fields) to create and chain unexpected data dependencies in order to achieve greater reachability. We have developed a novel tool, SVHunter, which can effectively identify D2C2 vulnerabilities. Till now we have evaluated SVHunter on three mainstream open-source SDN controllers (i.e., ONOS, Floodlight, and Opendaylight) as well as one security-enhanced controller (i.e., SE-Floodlight). SVHunter detects 18 previously unknown vulnerabilities, all of which can be exploited remotely to launch serious attacks such as executing arbitrary commands, exfiltrating confidential files, and crashing SDN services.",
            "keywords": [
                "Software-Defined Networking",
                "Control Plane Security",
                "Data Dependency Creation",
                "D2C2 Attack",
                "SVHunter Tool"
            ]
        },
        "url": "URL#2326740",
        "sema_paperId": "578d110c763120e23bc55805ee836bdd16b713eb"
    },
    {
        "@score": "1",
        "@id": "2326741",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "162/1393",
                        "text": "Aiping Xiong"
                    },
                    {
                        "@pid": "145/3288-1",
                        "text": "Tianhao Wang 0001"
                    },
                    {
                        "@pid": "l/NinghuiLi",
                        "text": "Ninghui Li"
                    },
                    {
                        "@pid": "j/SomeshJha",
                        "text": "Somesh Jha"
                    }
                ]
            },
            "title": "Towards Effective Differential Privacy Communication for Users&apos; Data Sharing Decision and Comprehension.",
            "venue": "SP",
            "pages": "392-410",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/Xiong0LJ20",
            "doi": "10.1109/SP40000.2020.00088",
            "ee": "https://doi.org/10.1109/SP40000.2020.00088",
            "url": "https://dblp.org/rec/conf/sp/Xiong0LJ20",
            "abstract": "Differential privacy protects an individual's privacy by perturbing data on an aggregated level (DP) or individual level (LDP). We report four online human-subject experiments investigating the effects of using different approaches to communicate differential privacy techniques to laypersons in a health app data collection setting. Experiments 1 and 2 investigated participants' data disclosure decisions for low-sensitive and high-sensitive personal information when given different DP or LDP descriptions. Experiments 3 and 4 uncovered reasons behind participants' data sharing decisions, and examined participants' subjective and objective comprehensions of these DP or LDP descriptions. When shown descriptions that explain the implications instead of the definition/processes of DP or LDP technique, participants demonstrated better comprehension and showed more willingness to share information with LDP than with DP, indicating their understanding of LDP's stronger privacy guarantee compared with DP.",
            "pdf_url": "",
            "keywords": [
                "Differential Privacy",
                "Local Differential Privacy",
                "Data Sharing Decisions",
                "User Comprehension",
                "Privacy Communication"
            ]
        },
        "url": "URL#2326741"
    },
    {
        "@score": "1",
        "@id": "2326742",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "75/4287-1",
                        "text": "Meng Xu 0001"
                    },
                    {
                        "@pid": "145/0912",
                        "text": "Sanidhya Kashyap"
                    },
                    {
                        "@pid": "68/2099",
                        "text": "Hanqing Zhao"
                    },
                    {
                        "@pid": "38/8882",
                        "text": "Taesoo Kim"
                    }
                ]
            },
            "title": "Krace: Data Race Fuzzing for Kernel File Systems.",
            "venue": "SP",
            "pages": "1643-1660",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/XuKZK20",
            "doi": "10.1109/SP40000.2020.00078",
            "ee": "https://doi.org/10.1109/SP40000.2020.00078",
            "url": "https://dblp.org/rec/conf/sp/XuKZK20",
            "abstract": "Data races occur when two threads fail to use proper synchronization when accessing shared data. In kernel file systems, which are highly concurrent by design, data races are common mistakes and often wreak havoc on the users, causing inconsistent states or data losses. Prior fuzzing practices on file systems have been effective in uncovering hundreds of bugs, but they mostly focus on the sequential aspect of file system execution and do not comprehensively explore the concurrency dimension and hence, forgo the opportunity to catch data races.In this paper, we bring coverage-guided fuzzing to the concurrency dimension with three new constructs: 1) a new coverage tracking metric, alias coverage, specially designed to capture the exploration progress in the concurrency dimension; 2) an evolution algorithm for generating, mutating, and merging multi-threaded syscall sequences as inputs for concurrency fuzzing; and 3) a comprehensive lockset and happens-before modeling for kernel synchronization primitives for precise data race detection. These components are integrated into Krace, an end-to-end fuzzing framework that has discovered 23 data races in ext4, btrfs, and the VFS layer so far, and 9 are confirmed to be harmful.",
            "keywords": [
                "Kernel File Systems",
                "Concurrency Fuzzing",
                "Data Races",
                "Coverage-Guided Fuzzing",
                "Synchronization Primitives"
            ]
        },
        "url": "URL#2326742",
        "sema_paperId": "7d1c27333f37db261bd0b716e1bfebaa347c35e1"
    },
    {
        "@score": "1",
        "@id": "2326743",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "46/1162-1",
                        "text": "Chen Yan 0001"
                    },
                    {
                        "@pid": "140/4350",
                        "text": "Hocheol Shin"
                    },
                    {
                        "@pid": "170/2513",
                        "text": "Connor Bolton"
                    },
                    {
                        "@pid": "10/3878-1",
                        "text": "Wenyuan Xu 0001"
                    },
                    {
                        "@pid": "20/6892",
                        "text": "Yongdae Kim"
                    },
                    {
                        "@pid": "f/KevinFu",
                        "text": "Kevin Fu"
                    }
                ]
            },
            "title": "SoK: A Minimalist Approach to Formalizing Analog Sensor Security.",
            "venue": "SP",
            "pages": "233-248",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/YanSBXKF20",
            "doi": "10.1109/SP40000.2020.00026",
            "ee": "https://doi.org/10.1109/SP40000.2020.00026",
            "url": "https://dblp.org/rec/conf/sp/YanSBXKF20",
            "abstract": "Over the last six years, several papers demonstrated how intentional analog interference based on acoustics, RF, lasers, and other physical modalities could induce faults, influence, or even control the output of sensors. Damage to the availability and integrity of sensor output carries significant risks to safety-critical systems that make automated decisions based on trusted sensor measurement. Established signal processing models use transfer functions to express reliability and dependability characteristics of sensors, but existing models do not provide a deliberate way to express and capture security properties meaningfully.Our work begins to fill this gap by systematizing knowledge of analog attacks against sensor circuitry and defenses. Our primary contribution is a simple sensor security model such that sensor engineers can better express analog security properties of sensor circuitry without needing to learn significantly new notation. Our model introduces transfer functions and a vector of adversarial noise to represent adversarial capabilities at each stage of a sensor\u2019s signal conditioning chain. The primary goals of the systematization are (1) to enable more meaningful quantification of risk for the design and evaluation of past and future sensors, (2) to better predict new attack vectors, and (3) to establish defensive design patterns that make sensors more resistant to analog attacks.",
            "keywords": [
                "Analog Sensor Security",
                "Signal Conditioning",
                "Adversarial Noise",
                "Analog Attacks",
                "Sensor Integrity"
            ]
        },
        "url": "URL#2326743",
        "sema_paperId": "3ddb4f6574e6b1b838a959e7c5de96e997342b01"
    },
    {
        "@score": "1",
        "@id": "2326745",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "87/6465",
                        "text": "Wei You"
                    },
                    {
                        "@pid": "16/1234-2",
                        "text": "Zhuo Zhang 0002"
                    },
                    {
                        "@pid": "139/7034",
                        "text": "Yonghwi Kwon 0001"
                    },
                    {
                        "@pid": "138/6356",
                        "text": "Yousra Aafer"
                    },
                    {
                        "@pid": "34/5165",
                        "text": "Fei Peng"
                    },
                    {
                        "@pid": "55/4736",
                        "text": "Yu Shi"
                    },
                    {
                        "@pid": "272/8286",
                        "text": "Carson Harmon"
                    },
                    {
                        "@pid": "95/3760-1",
                        "text": "Xiangyu Zhang 0001"
                    }
                ]
            },
            "title": "PMP: Cost-effective Forced Execution with Probabilistic Memory Pre-planning.",
            "venue": "SP",
            "pages": "1121-1138",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/You0KAPSHZ20",
            "doi": "10.1109/SP40000.2020.00035",
            "ee": "https://doi.org/10.1109/SP40000.2020.00035",
            "url": "https://dblp.org/rec/conf/sp/You0KAPSHZ20",
            "abstract": "Malware is a prominent security threat and exposing malware behavior is a critical challenge. Recent malware often has payload that is only released when certain conditions are satisfied. It is hence difficult to fully disclose the payload by simply executing the malware. In addition, malware samples may be equipped with cloaking techniques such as VM detectors that stop execution once detecting that the malware is being monitored. Forced execution is a highly effective method to penetrate malware self-protection and expose hidden behavior, by forcefully setting certain branch outcomes. However, an existing state-of-the-art forced execution technique X-Force is very heavyweight, requiring tracing individual instructions, reasoning about pointer alias relations on-the-fly, and repairing invalid pointers by on-demand memory allocation. We develop a light-weight and practical forced execution technique. Without losing analysis precision, it avoids tracking individual instructions and on-demand allocation. Under our scheme, a forced execution is very similar to a native one. It features a novel memory pre-planning phase that pre-allocates a large memory buffer, and then initializes the buffer, and variables in the subject binary, with carefully crafted values in a random fashion before the real execution. The pre-planning is designed in such a way that dereferencing an invalid pointer has a very large chance to fall into the pre-allocated region and hence does not cause any exception, and semantically unrelated invalid pointer dereferences highly likely access disjoint (pre-allocated) memory regions, avoiding state corruptions with probabilistic guarantees. Our experiments show that our technique is 84 times faster than X-Force, has 6.5X and 10% fewer false positives and negatives for program dependence detection, respectively, and can expose 98% more malicious behaviors in 400 recent malware samples.",
            "keywords": [
                "Malware Analysis",
                "Forced Execution",
                "Memory Pre-planning",
                "Malicious Behavior Exposure",
                "Probabilistic Guarantees"
            ]
        },
        "url": "URL#2326745",
        "sema_paperId": "bc56c45cd7e540c8ae41c81e05a36ceaade1c9ac"
    },
    {
        "@score": "1",
        "@id": "2326746",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "69/1249",
                        "text": "Haifeng Yu"
                    },
                    {
                        "@pid": "18/2551",
                        "text": "Ivica Nikolic"
                    },
                    {
                        "@pid": "227/7172",
                        "text": "Ruomu Hou"
                    },
                    {
                        "@pid": "90/105",
                        "text": "Prateek Saxena"
                    }
                ]
            },
            "title": "OHIE: Blockchain Scaling Made Simple.",
            "venue": "SP",
            "pages": "90-105",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/YuNHS20",
            "doi": "10.1109/SP40000.2020.00008",
            "ee": "https://doi.org/10.1109/SP40000.2020.00008",
            "url": "https://dblp.org/rec/conf/sp/YuNHS20",
            "abstract": "Many blockchain consensus protocols have been proposed recently to scale the throughput of a blockchain with available bandwidth. However, these protocols are becoming increasingly complex, making it more and more difficult to produce proofs of their security guarantees. We propose a novel permissionless blockchain protocol OHIE which explicitly aims for simplicity. OHIE composes as many parallel instances of Bitcoin's original (and simple) backbone protocol as needed to achieve excellent throughput. We formally prove the safety and liveness properties of OHIE. We demonstrate its performance with a prototype implementation and large-scale experiments with up to 50,000 nodes. In our experiments, OHIE achieves linear scaling with available bandwidth, providing about 4-10Mbps transaction throughput (under 8-20Mbps per-node available bandwidth configurations) and at least about 20x better decentralization over prior works.",
            "pdf_url": "",
            "keywords": [
                "Blockchain Protocols",
                "Scalability",
                "Throughput",
                "Decentralization",
                "Safety and Liveness Properties"
            ]
        },
        "url": "URL#2326746"
    },
    {
        "@score": "1",
        "@id": "2326747",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "226/1138",
                        "text": "Youqian Zhang"
                    },
                    {
                        "@pid": "01/4779",
                        "text": "Kasper Rasmussen"
                    }
                ]
            },
            "title": "Detection of Electromagnetic Interference Attacks on Sensor Systems.",
            "venue": "SP",
            "pages": "203-216",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/ZhangR20",
            "doi": "10.1109/SP40000.2020.00001",
            "ee": "https://doi.org/10.1109/SP40000.2020.00001",
            "url": "https://dblp.org/rec/conf/sp/ZhangR20",
            "abstract": "Sensor systems are used every time a microcontroller needs to interact with the physical world. They are abundant in home automation, factory control systems, critical infrastructure, transport systems and many, many other things.In a sensor system, a sensor transforms a physical quantity into an analog signal which is sent to an ADC and a microcontroller for digitization and further processing. Once the measurement is in digital form, the microcontroller can execute tasks according to the measurement. Electromagnetic interference (EMI) can affect a measurement as it is transferred to the microcontroller. An attacker can manipulate the sensor output by intentionally inducing EMI in the wire between the sensor and the microcontroller. The nature of the analog channel between the sensor and the microcontroller means that the microcontroller cannot authenticate whether the measurement is from the sensor or the attacker. If the microcontroller includes incorrect measurements in its control decisions, it could have disastrous consequences.We present a novel detection system for these low-level electromagnetic interference attacks. Our system is based on the idea that if the sensor is turned off, the signal read by the microcontroller should be 0V (or some other known value). We use this idea to modulate the sensor output in a way that is unpredictable to the adversary. If the microcontroller detects fluctuations in the sensor output, the attacking signal can be detected. Our proposal works with a minimal amount of extra components and is thus cheap and easy to implement.We present the working mechanism of our detection method and prove the detection guarantee in the context of a strong attacker model. We implement our approach in order to detect adversarial EMI signals, both in a microphone system and a temperature sensor system, and we show that our detection mechanism is both effective and robust.",
            "keywords": [
                "Electromagnetic Interference",
                "Sensor Systems",
                "Detection Mechanism",
                "Adversarial Attacks",
                "Microcontroller Security"
            ]
        },
        "url": "URL#2326747",
        "sema_paperId": "996e47b0e572fbed0cf1341f098643f2650a304c"
    },
    {
        "@score": "1",
        "@id": "2326748",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "60/2536-68",
                        "text": "Rui Zhang 0068"
                    },
                    {
                        "@pid": "54/7563",
                        "text": "Cynthia Sturton"
                    }
                ]
            },
            "title": "Transys: Leveraging Common Security Properties Across Hardware Designs.",
            "venue": "SP",
            "pages": "1713-1727",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/ZhangS20",
            "doi": "10.1109/SP40000.2020.00030",
            "ee": "https://doi.org/10.1109/SP40000.2020.00030",
            "url": "https://dblp.org/rec/conf/sp/ZhangS20",
            "abstract": "This paper presents Transys, a tool for translating security critical properties written for one hardware design to analogous properties suitable for a second design. Transys works in three passes adjusting the variable names, arithmetic expressions, logical preconditions, and timing constraints of the original property to retain the intended semantics of the property while making it valid for the second design. We evaluate Transys by translating 27 assertions written in a temporal logic and 9 properties written for use with gate level information flow tracking across 38 AES designs, 3 RSA designs, and 5 RISC processor designs. Transys successfully translates 96% of the properties. Among these, the translation of 23 (64%) of the properties achieved a semantic equivalence rate of above 60%. The average translation time per property is about 70 seconds.",
            "keywords": [
                "Hardware Security",
                "Property Translation",
                "Temporal Logic",
                "Information Flow Tracking",
                "Semantic Equivalence"
            ]
        },
        "url": "URL#2326748",
        "sema_paperId": "3b219202f3d96c9f27f93a0c6416a4ed904ca36e"
    },
    {
        "@score": "1",
        "@id": "2326749",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "203/8611",
                        "text": "Jiaheng Zhang"
                    },
                    {
                        "@pid": "216/6422",
                        "text": "Tiancheng Xie"
                    },
                    {
                        "@pid": "82/4816-1",
                        "text": "Yupeng Zhang 0001"
                    },
                    {
                        "@pid": "s/DXSong",
                        "text": "Dawn Song"
                    }
                ]
            },
            "title": "Transparent Polynomial Delegation and Its Applications to Zero Knowledge Proof.",
            "venue": "SP",
            "pages": "859-876",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/ZhangX0S20",
            "doi": "10.1109/SP40000.2020.00052",
            "ee": "https://doi.org/10.1109/SP40000.2020.00052",
            "url": "https://dblp.org/rec/conf/sp/ZhangX0S20",
            "abstract": "We present a new succinct zero knowledge argument scheme for layered arithmetic circuits without trusted setup. The prover time is O(C + nlogn) and the proof size is O(D logC +log2 n) for a D-depth circuit with n inputs and C gates. The verification time is also succinct, O(D logC + log2 n), if the circuit is structured. Our scheme only uses lightweight cryptographic primitives such as collision-resistant hash functions and is plausibly post-quantum secure. We implement a zero knowledge argument system, Virgo, based on our new scheme and compare its performance to existing schemes. Experiments show that it only takes 53 seconds to generate a proof for a circuit computing a Merkle tree with 256 leaves, at least an order of magnitude faster than all other succinct zero knowledge argument schemes. The verification time is 50ms, and the proof size is 253KB, both competitive to existing systems.Underlying Virgo is a new transparent zero knowledge verifiable polynomial delegation scheme with logarithmic proof size and verification time. The scheme is in the interactive oracle proof model and may be of independent interest.",
            "keywords": [
                "Zero Knowledge Proofs",
                "Transparent Polynomial Delegation",
                "Layered Arithmetic Circuits",
                "Succinct Argument Scheme",
                "Post-Quantum Security"
            ]
        },
        "url": "URL#2326749",
        "sema_paperId": "8745f1dae425690e57ed89587ad50d770efc1ec7"
    },
    {
        "@score": "1",
        "@id": "2326751",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "117/0017",
                        "text": "Zhenkai Zhang"
                    },
                    {
                        "@pid": "195/9266",
                        "text": "Zihao Zhan"
                    },
                    {
                        "@pid": "42/5805",
                        "text": "Daniel Balasubramanian"
                    },
                    {
                        "@pid": "50/3402-26",
                        "text": "Bo Li 0026"
                    },
                    {
                        "@pid": "83/2615",
                        "text": "P\u00e9ter V\u00f6lgyesi"
                    },
                    {
                        "@pid": "11/5453",
                        "text": "Xenofon D. Koutsoukos"
                    }
                ]
            },
            "title": "Leveraging EM Side-Channel Information to Detect Rowhammer Attacks.",
            "venue": "SP",
            "pages": "729-746",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/ZhangZBLVK20",
            "doi": "10.1109/SP40000.2020.00060",
            "ee": "https://doi.org/10.1109/SP40000.2020.00060",
            "url": "https://dblp.org/rec/conf/sp/ZhangZBLVK20",
            "abstract": "The rowhammer bug belongs to software-induced hardware faults, and has been exploited to form a wide range of powerful rowhammer attacks. Yet, how to effectively detect such attacks remains a challenging problem. In this paper, we propose a novel approach named RADAR (Rowhammer Attack Detection via A Radio) that leverages certain electromagnetic (EM) signals to detect rowhammer attacks. In particular, we have found that there are recognizable hammering-correlated sideband patterns in the spectrum of the DRAM clock signal. As such patterns are inevitable physical side effects of hammering the DRAM, they can \"expose\" any potential rowhammer attacks including the extremely elusive ones hidden inside encrypted and isolated environments like Intel SGX enclaves. However, the patterns of interest may become unapparent due to the common use of spread-spectrum clocking (SSC) in computer systems. We propose a de-spreading method that can reassemble the hammering-correlated sideband patterns scattered by SSC. Using a common classification technique, we can achieve both effective and robust detection-based defense against rowhammer attacks, as evaluated on a RADAR prototype under various scenarios. In addition, our RADAR does not impose any performance overhead on the protected system. There has been little prior work that uses physical side-channel information to perform rowhammer defenses, and to the best of our knowledge, this is the first investigation on leveraging EM side-channel information for this purpose.",
            "keywords": [
                "Rowhammer Attacks",
                "EM Side-Channel",
                "DRAM Faults",
                "Attack Detection",
                "De-spreading Method"
            ]
        },
        "url": "URL#2326751",
        "sema_paperId": "9ec00374e09a8a6c0e3d72a4173c3af2d580b186"
    },
    {
        "@score": "1",
        "@id": "2326752",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "156/1033",
                        "text": "Qingchuan Zhao"
                    },
                    {
                        "@pid": "149/8302",
                        "text": "Chaoshun Zuo"
                    },
                    {
                        "@pid": "94/7563",
                        "text": "Brendan Dolan-Gavitt"
                    },
                    {
                        "@pid": "35/9056",
                        "text": "Giancarlo Pellegrino"
                    },
                    {
                        "@pid": "49/4102-1",
                        "text": "Zhiqiang Lin 0001"
                    }
                ]
            },
            "title": "Automatic Uncovering of Hidden Behaviors From Input Validation in Mobile Apps.",
            "venue": "SP",
            "pages": "1106-1120",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/ZhaoZDPL20",
            "doi": "10.1109/SP40000.2020.00072",
            "ee": "https://doi.org/10.1109/SP40000.2020.00072",
            "url": "https://dblp.org/rec/conf/sp/ZhaoZDPL20",
            "abstract": "Mobile applications (apps) have exploded in popularity, with billions of smartphone users using millions of apps available through markets such as the Google Play Store or the Apple App Store. While these apps have rich and useful functionality that is publicly exposed to end users, they also contain hidden behaviors that are not disclosed, such as backdoors and blacklists designed to block unwanted content. In this paper, we show that the input validation behavior\u2014the way the mobile apps process and respond to data entered by users\u2014can serve as a powerful tool for uncovering such hidden functionality. We therefore have developed a tool, InputScope, that automatically detects both the execution context of user input validation and also the content involved in the validation, to automatically expose the secrets of interest. We have tested InputScope with over 150,000 mobile apps, including popular apps from major app stores and preinstalled apps shipped with the phone, and found 12,706 mobile apps with backdoor secrets and 4,028 mobile apps containing blacklist secrets.",
            "keywords": [
                "Mobile App Security",
                "Input Validation",
                "Hidden Behaviors",
                "Backdoors",
                "Blacklists"
            ]
        },
        "url": "URL#2326752",
        "sema_paperId": "6d6b0c988aab29e57abc8b9fe7664b2c506ebd89"
    },
    {
        "@score": "1",
        "@id": "2326753",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "68/6322",
                        "text": "Jianping Zhu"
                    },
                    {
                        "@pid": "79/3631-1",
                        "text": "Rui Hou 0001"
                    },
                    {
                        "@pid": "06/6268",
                        "text": "XiaoFeng Wang 0001"
                    },
                    {
                        "@pid": "57/9813-1",
                        "text": "Wenhao Wang 0001"
                    },
                    {
                        "@pid": "239/5225",
                        "text": "Jiangfeng Cao"
                    },
                    {
                        "@pid": "178/3210",
                        "text": "Boyan Zhao"
                    },
                    {
                        "@pid": "239/4846",
                        "text": "Zhongpu Wang"
                    },
                    {
                        "@pid": "77/1630",
                        "text": "Yuhui Zhang"
                    },
                    {
                        "@pid": "272/8290",
                        "text": "Jiameng Ying"
                    },
                    {
                        "@pid": "52/5615-2",
                        "text": "Lixin Zhang 0002"
                    },
                    {
                        "@pid": "01/2538",
                        "text": "Dan Meng"
                    }
                ]
            },
            "title": "Enabling Rack-scale Confidential Computing using Heterogeneous Trusted Execution Environment.",
            "venue": "SP",
            "pages": "1450-1465",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "closed",
            "key": "conf/sp/ZhuH0WCZWZYZM20",
            "doi": "10.1109/SP40000.2020.00054",
            "ee": "https://doi.org/10.1109/SP40000.2020.00054",
            "url": "https://dblp.org/rec/conf/sp/ZhuH0WCZWZYZM20",
            "abstract": "With its huge real-world demands, large-scale confidential computing still cannot be supported by today\u2019s Trusted Execution Environment (TEE), due to the lack of scalable and effective protection of high-throughput accelerators like GPUs, FPGAs, and TPUs etc. Although attempts have been made recently to extend the CPU-like enclave to GPUs, these solutions require change to the CPU or GPU chips, may introduce new security risks due to the side-channel leaks in CPU-GPU communication and are still under the resource constraint of today\u2019s CPU TEE.To address these problems, we present the first Heterogeneous TEE design that can truly support large-scale compute or data intensive (CDI) computing, without any chip-level change. Our approach, called HETEE, is a device for centralized management of all computing units (e.g., GPUs and other accelerators) of a server rack. It is uniquely designed to work with today\u2019s data centres and clouds, leveraging modern resource pooling technologies to dynamically compartmentalize computing tasks, and enforce strong isolation and reduce TCB through hardware support. More specifically, HETEE utilizes the PCIe ExpressFabric to allocate its accelerators to the server node on the same rack for a non-sensitive CDI task, and move them back into a secure enclave in response to the demand for confidential computing. Our design runs a thin TCB stack for security management on a security controller (SC), while leaving a large set of software (e.g., AI runtime, GPU driver, etc.) to the integrated microservers that operate enclaves. An enclaves is physically isolated from others through hardware and verified by the SC at its inception. Its microserver and computing units are restored to a secure state upon termination.We implemented HETEE on a real hardware system, and evaluated it with popular neural network inference and training tasks. Our evaluations show that HETEE can easily support the CDI tasks on the real-world scale and incurred a maximal throughput overhead of 2.17% for inference and 0.95% for training on ResNet152.",
            "keywords": [
                "Heterogeneous Trusted Execution Environment",
                "Confidential Computing",
                "Centralized Management",
                "Resource Pooling",
                "PCIe ExpressFabric"
            ]
        },
        "url": "URL#2326753",
        "sema_paperId": "16e1422ea88883c164bd8f97c9cd82a66a7f22a6"
    },
    {
        "@score": "1",
        "@id": "2345201",
        "info": {
            "title": "2020 IEEE Symposium on Security and Privacy, SP 2020, San Francisco, CA, USA, May 18-21, 2020",
            "venue": "SP",
            "publisher": "IEEE",
            "year": "2020",
            "type": "Editorship",
            "key": "conf/sp/2020",
            "ee": "https://ieeexplore.ieee.org/xpl/conhome/9144328/proceeding",
            "url": "https://dblp.org/rec/conf/sp/2020",
            "abstract": null
        },
        "url": "URL#2345201",
        "sema_paperId": "ec4263f82ee73b3eb6ebf6d2e3c0b1054e181393"
    }
]