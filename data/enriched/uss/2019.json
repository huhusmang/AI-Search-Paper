[
    {
        "@score": "1",
        "@id": "2767710",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "99/4292-2",
                        "text": "Ding Wang 0002"
                    },
                    {
                        "@pid": "37/1304-3",
                        "text": "Ping Wang 0003"
                    },
                    {
                        "@pid": "87/7765",
                        "text": "Debiao He"
                    },
                    {
                        "@pid": "39/5423-1",
                        "text": "Yuan Tian 0001"
                    }
                ]
            },
            "title": "Birthday, Name and Bifacial-security: Understanding Passwords of Chinese Web Users.",
            "venue": "USENIX Security Symposium",
            "pages": "1537-1555",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/00020HT19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/wang-ding",
            "url": "https://dblp.org/rec/conf/uss/00020HT19",
            "abstract": "Much attention has been paid to passwords chosen by English speaking users, yet only a few studies have examined how non-English speaking users select passwords. In this paper, we perform an extensive, empirical analysis of 73.1 million real-world Chinese web passwords in comparison with 33.2 million English counterparts. We highlight a number of interesting structural and semantic characteristics in Chinese passwords. We further evaluate the security of these passwords by employing two state-of-the-art cracking techniques. In particular, our cracking results reveal the bifacialsecurity nature of Chinese passwords. They are weaker against online guessing attacks (i.e., when the allowed guess number is small, 1\u223c104) than English passwords. But out of the remaining Chinese passwords, they are stronger against offline guessing attacks (i.e., when the guess number is large, >105) than their English counterparts. This reconciles two conflicting claims about the strength of Chinese passwords made by Bonneau (IEEE S&P\u201912) and Li et al. (Usenix Security\u201914 and IEEE TIFS\u201916). At 107 guesses, the success rate of our improved PCFG-based attack against the Chinese datasets is 33.2%\u223c49.8%, indicating that our attack can crack 92% to 188% more passwords than the state of the art. We also discuss the implications of our findings for password policies, strength meters and cracking.",
            "keywords": [
                "Chinese Passwords",
                "Password Cracking",
                "Bifacial Security",
                "Online Guessing Attacks",
                "Offline Guessing Attacks"
            ]
        },
        "url": "URL#2767710",
        "sema_paperId": "a9602e8243e4820b89b3f472dbd1f8b099afe79d"
    },
    {
        "@score": "1",
        "@id": "2767711",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "30/1250-3",
                        "text": "Poulami Das 0003"
                    },
                    {
                        "@pid": "203/4287",
                        "text": "Lisa Eckey"
                    },
                    {
                        "@pid": "189/1758",
                        "text": "Tommaso Frassetto"
                    },
                    {
                        "@pid": "164/2771",
                        "text": "David Gens"
                    },
                    {
                        "@pid": "201/6463",
                        "text": "Kristina Host\u00e1kov\u00e1"
                    },
                    {
                        "@pid": "224/9363",
                        "text": "Patrick Jauernig"
                    },
                    {
                        "@pid": "71/4369",
                        "text": "Sebastian Faust"
                    },
                    {
                        "@pid": "s/AhmadRezaSadeghi",
                        "text": "Ahmad-Reza Sadeghi"
                    }
                ]
            },
            "title": "FastKitten: Practical Smart Contracts on Bitcoin.",
            "venue": "USENIX Security Symposium",
            "pages": "801-818",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0003EFGHJFS19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/das",
            "url": "https://dblp.org/rec/conf/uss/0003EFGHJFS19",
            "abstract": "Smart contracts are envisioned to be one of the killer applications of decentralized cryptocurrencies. They enable self-enforcing payments between users depending on complex program logic. Unfortunately, Bitcoin \u2013 the largest and by far most widely used cryptocurrency \u2013 does not offer support for complex smart contracts. Moreover, simple contracts that can be executed on Bitcoin are often cumbersome to design and very costly to execute. In this work we present FastKitten, a practical framework for executing arbitrarily complex smart contracts at low costs over decentralized cryptocurrencies which are designed to only support simple transactions. To this end, FastKitten leverages the power of trusted computing environments (TEEs), in which contracts are run off-chain to enable efficient contract execution at low cost. We formally prove that FastKitten satisfies strong security properties when all but one party are malicious. Finally, we report on a prototype implementation which supports arbitrary contracts through a scripting engine, and evaluate performance through benchmarking a provably fair online poker game. Our implementation illustrates that FastKitten is practical for complex multi-round applications with a very small latency. Combining these features, FastKitten is the first truly practical framework for complex smart contract execution over Bitcoin.",
            "pdf_url": "",
            "keywords": [
                "Smart Contracts",
                "Bitcoin",
                "Trusted Computing Environments",
                "Off-chain Execution",
                "Low-cost Contract Execution"
            ]
        },
        "url": "URL#2767711"
    },
    {
        "@score": "1",
        "@id": "2767712",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "80/1239-7",
                        "text": "Jens M\u00fcller 0007"
                    },
                    {
                        "@pid": "76/6564",
                        "text": "Marcus Brinkmann"
                    },
                    {
                        "@pid": "216/6088",
                        "text": "Damian Poddebniak"
                    },
                    {
                        "@pid": "161/6292",
                        "text": "Hanno B\u00f6ck"
                    },
                    {
                        "@pid": "43/11495",
                        "text": "Sebastian Schinzel"
                    },
                    {
                        "@pid": "27/8331",
                        "text": "Juraj Somorovsky"
                    },
                    {
                        "@pid": "58/5730",
                        "text": "J\u00f6rg Schwenk"
                    }
                ]
            },
            "title": "&quot;Johnny, you are fired!&quot; - Spoofing OpenPGP and S/MIME Signatures in Emails.",
            "venue": "USENIX Security Symposium",
            "pages": "1011-1028",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0007BPBSSS19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/muller",
            "url": "https://dblp.org/rec/conf/uss/0007BPBSSS19",
            "abstract": "OpenPGP and S/MIME are the two major standards to en-crypt and digitally sign emails. Digital signatures are sup-posed to guarantee authenticity and integrity of messages. Inthis work we show practical forgery attacks against variousimplementations of OpenPGP and S/MIME email signatureverification in five attack classes: (1) We analyze edge casesin S/MIME\u2019s container format. (2) We exploit in-band sig-naling in the GnuPG API, the most widely used OpenPGPimplementation. (3) We apply MIME wrapping attacks thatabuse the email clients\u2019 handling of partially signed mes-sages. (4) We analyze weaknesses in the binding of signedmessages to the sender identity. (5) We systematically testemail clients for UI redressing attacks.Our attacks allow the spoofing of digital signatures for ar-bitrary messages in 14 out of 20 tested OpenPGP-capableemail clients and 15 out of 22 email clients supportingS/MIME signatures. While the attacks do not target the un-derlying cryptographic primitives of digital signatures, theyraise concerns about the actual security of OpenPGP andS/MIME email applications. Finally, we propose mitigationstrategies to counter these attacks.",
            "keywords": [
                "Email Security",
                "Digital Signatures",
                "OpenPGP",
                "S/MIME",
                "Signature Forgery Attacks"
            ]
        },
        "url": "URL#2767712",
        "sema_paperId": "61553db250f9407d920ea15da2082d5b2893ac05"
    },
    {
        "@score": "1",
        "@id": "2767713",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "13/4585-8",
                        "text": "Richard Baker 0008"
                    },
                    {
                        "@pid": "87/2623",
                        "text": "Ivan Martinovic"
                    }
                ]
            },
            "title": "Losing the Car Keys: Wireless PHY-Layer Insecurity in EV Charging.",
            "venue": "USENIX Security Symposium",
            "pages": "407-424",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0008M19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/baker",
            "url": "https://dblp.org/rec/conf/uss/0008M19",
            "abstract": "Electric vehicles (EVs) are proliferating quickly, along with the charging infrastructure for them. A new generation of charger technologies is emerging, handling more sensitive data and undertaking more complex interactions, while using the charging cable as the communication channel. This channel is used not only for charging control, but will soon handle billing, vehicle-to-grid operation, internet access and provide a platform for third-party apps \u2014 all with a public interface to the world. We highlight the threat posed by wireless attacks on the physical-layer of the Combined Charging System (CCS), a major standard for EV charging that is deployed in many thousands of locations worldwide and used by seven of the ten largest auto manufacturers globally. We show that design choices in the use of power-line communication (PLC) make the system particularly prone to popular electromagnetic side-channel attacks. We implement the first wireless eavesdropping tool for PLC networks and use it to observe the ISO 15118 network implementation underlying CCS, in a measurement campaign of 54 real charging sessions, using modern electric vehicles and state-of-the-art CCS chargers. We find that the unintentional wireless channel is sufficient to recover messages in the vast majority of cases, with traffic intercepted from an adjacent parking bay showing 91.8% of messages validating their CRC32 checksum. By examining the recovered traffic, we further find a host of privacy and security issues in existing charging infrastructure including plaintext MAC-layer traffic recovery, widespread absence of TLS in public locations and leakage of private information, including long-term unique identifiers. Of particular concern, elements of the recovered data are being used to authorise billing in existing charging implementations. We discuss the implications of pervasive susceptibility to known electromagnetic eavesdropping techniques, extract lessons learnt for future development and propose specific improvements to mitigate the problems in existing chargers. Local Site Grid",
            "keywords": [
                "Electric Vehicle Charging",
                "Power-Line Communication",
                "Wireless Eavesdropping",
                "Privacy Issues",
                "Billing Authorization Vulnerabilities"
            ]
        },
        "url": "URL#2767713",
        "sema_paperId": "783e16d3418a204b17e779d9ae4cc993041dfa91"
    },
    {
        "@score": "1",
        "@id": "2767714",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "42/1503-11",
                        "text": "Shuai Wang 0011"
                    },
                    {
                        "@pid": "167/6624",
                        "text": "Yuyan Bao"
                    },
                    {
                        "@pid": "82/1364-25",
                        "text": "Xiao Liu 0025"
                    },
                    {
                        "@pid": "83/4555-7",
                        "text": "Pei Wang 0007"
                    },
                    {
                        "@pid": "23/3719",
                        "text": "Danfeng Zhang"
                    },
                    {
                        "@pid": "54/2696",
                        "text": "Dinghao Wu"
                    }
                ]
            },
            "title": "Identifying Cache-Based Side Channels through Secret-Augmented Abstract Interpretation.",
            "venue": "USENIX Security Symposium",
            "pages": "657-674",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0011BL0ZW19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/wang-shuai",
            "url": "https://dblp.org/rec/conf/uss/0011BL0ZW19",
            "abstract": "Cache-based side channels enable a dedicated attacker to reveal program secrets by measuring the cache access patterns. Practical attacks have been shown against real-world crypto algorithm implementations such as RSA, AES, and ElGamal. By far, identifying information leaks due to cache-based side channels, either in a static or dynamic manner, remains a challenge: the existing approaches fail to offer high precision, full coverage, and good scalability simultaneously, thus impeding their practical use in real-world scenarios. \nIn this paper, we propose a novel static analysis method on binaries to detect cache-based side channels. We use abstract interpretation to reason on program states with respect to abstract values at each program point. To make such abstract interpretation scalable to real-world cryptosystems while offering high precision and full coverage, we propose a novel abstract domain called the Secret-Augmented Symbolic domain (SAS). SAS tracks program secrets and dependencies on them for precision, while it tracks only coarse-grained public information for scalability. \nWe have implemented the proposed technique into a practical tool named CacheS and evaluated it on the implementations of widely-used cryptographic algorithms in real-world crypto libraries, including Libgcrypt, OpenSSL, and mbedTLS. CacheS successfully confirmed a total of 154 information leaks reported by previous research and 54 leaks that were previously unknown. We have reported our findings to the developers. And they confirmed that many of those unknown information leaks do lead to potential side channels.",
            "keywords": [
                "Cache-Based Side Channels",
                "Static Analysis",
                "Abstract Interpretation",
                "Information Leaks",
                "Secret-Augmented Symbolic Domain (SAS)"
            ]
        },
        "url": "URL#2767714",
        "sema_paperId": "4795782bbe3de0849ad2c1ba9a19d04e31373b33"
    },
    {
        "@score": "1",
        "@id": "2767715",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "69/5011-26",
                        "text": "Wei Zhou 0026"
                    },
                    {
                        "@pid": "230/3262",
                        "text": "Yan Jia"
                    },
                    {
                        "@pid": "07/4410",
                        "text": "Yao Yao"
                    },
                    {
                        "@pid": "168/0918",
                        "text": "Lipeng Zhu"
                    },
                    {
                        "@pid": "137/5266",
                        "text": "Le Guan"
                    },
                    {
                        "@pid": "63/9426",
                        "text": "Yuhang Mao"
                    },
                    {
                        "@pid": "21/6121-5",
                        "text": "Peng Liu 0005"
                    },
                    {
                        "@pid": "83/6530-1",
                        "text": "Yuqing Zhang 0001"
                    }
                ]
            },
            "title": "Discovering and Understanding the Security Hazards in the Interactions between IoT Devices, Mobile Apps, and Clouds on Smart Home Platforms.",
            "venue": "USENIX Security Symposium",
            "pages": "1133-1150",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0026JYZGM0Z19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/zhou",
            "url": "https://dblp.org/rec/conf/uss/0026JYZGM0Z19",
            "abstract": "A smart home connects tens of home devices to the Internet, where an IoT cloud runs various home automation applications. While bringing unprecedented convenience and accessibility, it also introduces various security hazards to users. Prior research studied smart home security from several aspects. However, we found that the complexity of the interactions among the participating entities (i.e., devices, IoT clouds, and mobile apps) has not yet been systematically investigated. In this work, we conducted an in-depth analysis of five widely-used smart home platforms. Combining firmware analysis, network traffic interception, and blackbox testing, we reverse-engineered the details of the interactions among the participating entities. Based on the details, we inferred three legitimate state transition diagrams for the three entities, respectively. Using these state machines as a reference model, we identified a set of unexpected state transitions. To confirm and trigger the unexpected state transitions, we implemented a set of phantom devices to mimic a real device. By instructing the phantom devices to intervene in the normal entity-entity interactions, we have discovered several new vulnerabilities and a spectrum of attacks against real-world smart home platforms.",
            "keywords": [
                "Smart Home Security",
                "IoT Device Interactions",
                "Vulnerability Discovery",
                "State Transition Analysis",
                "Phantom Device Attacks"
            ]
        },
        "url": "URL#2767715",
        "sema_paperId": "40420d3f41a4af566ba426e4aa50c03b7dae5a50"
    },
    {
        "@score": "1",
        "@id": "2767716",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "127/7110",
                        "text": "Omar Alrawi"
                    },
                    {
                        "@pid": "149/8302",
                        "text": "Chaoshun Zuo"
                    },
                    {
                        "@pid": "117/4491",
                        "text": "Ruian Duan"
                    },
                    {
                        "@pid": "248/1646",
                        "text": "Ranjita Pai Kasturi"
                    },
                    {
                        "@pid": "49/4102-1",
                        "text": "Zhiqiang Lin 0001"
                    },
                    {
                        "@pid": "150/5240",
                        "text": "Brendan Saltaformaggio"
                    }
                ]
            },
            "title": "The Betrayal At Cloud City: An Empirical Analysis Of Cloud-Based Mobile Backends.",
            "venue": "USENIX Security Symposium",
            "pages": "551-566",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AlrawiZDKLS19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/alrawi",
            "url": "https://dblp.org/rec/conf/uss/AlrawiZDKLS19",
            "abstract": "Cloud backends provide essential features to the mobile app ecosystem, such as content delivery, ad networks, analytics, and more. Unfortunately, app developers often disregard or have no control over prudent security practices when choosing or managing these services. Our preliminary study of the top 5,000 Google Play Store free apps identified 983 instances of N-day and 655 instances of 0-day vulnerabilities spanning across the software layers (OS, software services, communication, and web apps) of cloud backends. The mobile apps using these cloud backends represent between 1M and 500M installs each and can potentially affect hundreds of thousands of users. Further, due to the widespread use of third-party SDKs, app developers are often unaware of the backends affecting their apps and where to report vulnerabilities. This paper presents SkyWalker, a pipeline to automatically vet the backends that mobile apps contact and provide actionable remediation. For an input APK, SkyWalker extracts an enumeration of backend URLs, uses remote vetting techniques to identify software vulnerabilities and responsible parties, and reports mitigation strategies to the app developer. Our findings suggest that developers and cloud providers do not have a clear understanding of responsibilities and liabilities in regards to mobile app backends that leave many vulnerabilities exposed.",
            "keywords": [
                "Cloud-Based Mobile Backends",
                "Mobile App Security",
                "Vulnerability Assessment",
                "Third-Party SDKs",
                "SkyWalker"
            ]
        },
        "url": "URL#2767716",
        "sema_paperId": "e6ea352463e0fa5d1ef9ac72a510475293a79453"
    },
    {
        "@score": "1",
        "@id": "2767718",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "161/6189",
                        "text": "Michael P. Andersen"
                    },
                    {
                        "@pid": "173/8201",
                        "text": "Sam Kumar"
                    },
                    {
                        "@pid": "10/8870",
                        "text": "Moustafa AbdelBaky"
                    },
                    {
                        "@pid": "145/2150",
                        "text": "Gabe Fierro"
                    },
                    {
                        "@pid": "158/5947",
                        "text": "John Kolb"
                    },
                    {
                        "@pid": "05/9097",
                        "text": "Hyung-Sin Kim"
                    },
                    {
                        "@pid": "c/DavidECuller",
                        "text": "David E. Culler"
                    },
                    {
                        "@pid": "91/275",
                        "text": "Raluca Ada Popa"
                    }
                ]
            },
            "title": "WAVE: A Decentralized Authorization Framework with Transitive Delegation.",
            "venue": "USENIX Security Symposium",
            "pages": "1375-1392",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AndersenKAFKKCP19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/andersen",
            "url": "https://dblp.org/rec/conf/uss/AndersenKAFKKCP19",
            "abstract": "Most deployed authorization systems rely on a central trusted service whose compromise can lead to the breach of millions of user accounts and permissions. We present WAVE, an authorization framework offering decentralized trust: no central services can modify or see permissions and any participant can delegate a portion of their permissions autonomously. To achieve this goal, WAVE adopts an expressive authorization model, enforces it cryptographically, protects permissions via a novel encryption protocol while enabling discovery of permissions, and stores them in an untrusted scalable storage solution. WAVE provides competitive performance to traditional authorization systems relying on central trust. It is an open-source artifact and has been used for two years for controlling 800 IoT devices.",
            "keywords": [
                "Decentralized Authorization",
                "Transitive Delegation",
                "Cryptographic Enforcement",
                "Permission Management",
                "IoT Device Control"
            ]
        },
        "url": "URL#2767718",
        "sema_paperId": "ad6f10d3fde274d530f6c72005a23c31875ad144"
    },
    {
        "@score": "1",
        "@id": "2767719",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "167/0165",
                        "text": "Benjamin Andow"
                    },
                    {
                        "@pid": "248/1724",
                        "text": "Samin Yaseer Mahmud"
                    },
                    {
                        "@pid": "80/6234",
                        "text": "Wenyu Wang"
                    },
                    {
                        "@pid": "248/1643",
                        "text": "Justin Whitaker"
                    },
                    {
                        "@pid": "22/4463",
                        "text": "William Enck"
                    },
                    {
                        "@pid": "117/3983",
                        "text": "Bradley Reaves"
                    },
                    {
                        "@pid": "87/6804",
                        "text": "Kapil Singh"
                    },
                    {
                        "@pid": "x/TaoXie",
                        "text": "Tao Xie 0001"
                    }
                ]
            },
            "title": "PolicyLint: Investigating Internal Privacy Policy Contradictions on Google Play.",
            "venue": "USENIX Security Symposium",
            "pages": "585-602",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AndowMWWERS019",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/andow",
            "url": "https://dblp.org/rec/conf/uss/AndowMWWERS019",
            "abstract": "Privacy policies are the primary mechanism by which companies inform users about data collection and sharing practices. To help users better understand these long and complex legal documents, recent research has proposed tools that summarize collection and sharing. However, these tools have a signi\ufb01-cant oversight: they do not account for contradictions that may occur within an individual policy. In this paper, we present PolicyLint, a privacy policy analysis tool that identi\ufb01es such contradictions by simultaneously considering negation and varying semantic levels of data objects and entities. To do so, PolicyLint automatically generates ontologies from a large corpus of privacy policies and uses sentence-level natural language processing to capture both positive and negative statements of data collection and sharing. We use PolicyLint to analyze the policies of 11,430 apps and \ufb01nd that 14.2% of these policies contain contradictions that may be indicative of misleading statements. We manually verify 510 contradictions, identifying concerning trends that include the use of misleading presentation, attempted rede\ufb01nition of common understandings of terms, con\ufb02icts in regulatory de\ufb01nitions (e.g., US and EU), and \u201claundering\u201d of tracking information facilitated by sharing or collecting data that can be used to derive sensitive information. In doing so, PolicyLint signi\ufb01-cantly advances automated analysis of privacy policies.",
            "keywords": [
                "Privacy Policy Analysis",
                "Contradictions Detection",
                "Data Collection Practices",
                "Misleading Statements",
                "Automated Ontology Generation"
            ]
        },
        "url": "URL#2767719",
        "sema_paperId": "b88cfca52af2d71ed886f94c7458022d811aec8a"
    },
    {
        "@score": "1",
        "@id": "2767720",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "133/5077",
                        "text": "Daniele Antonioli"
                    },
                    {
                        "@pid": "32/7125",
                        "text": "Nils Ole Tippenhauer"
                    },
                    {
                        "@pid": "01/4779",
                        "text": "Kasper Bonne Rasmussen"
                    }
                ]
            },
            "title": "The KNOB is Broken: Exploiting Low Entropy in the Encryption Key Negotiation Of Bluetooth BR/EDR.",
            "venue": "USENIX Security Symposium",
            "pages": "1047-1061",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AntonioliTR19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/antonioli",
            "url": "https://dblp.org/rec/conf/uss/AntonioliTR19",
            "abstract": "We present an attack on the encryption key negotiation protocol of Bluetooth BR/EDR. The attack allows a third party, without knowledge of any secret material (such as link and encryption keys), to make two (or more) victims agree on an encryption key with only 1 byte (8 bits) of entropy. Such low entropy enables the attacker to easily brute force the negotiated encryption keys, decrypt the eavesdropped ciphertext, and inject valid encrypted messages (in real-time). The attack is stealthy because the encryption key negotiation is transparent to the Bluetooth users. The attack is standard-compliant because all Bluetooth BR/EDR versions require to support encryption keys with entropy between 1 and 16 bytes and do not secure the key negotiation protocol. As a result, the attacker completely breaks Bluetooth BR/EDR security without being detected. We call our attack Key Negotiation Of Bluetooth (KNOB) attack. \n \nThe attack targets the firmware of the Bluetooth chip because the firmware (Bluetooth controller) implements all the security features of Bluetooth BR/EDR. As a standard-compliant attack, it is expected to be effective on any firmware that follows the specification and on any device using a vulnerable firmware. We describe how to perform the KNOB attack, and we implement it. We evaluate our implementation on more than 14 Bluetooth chips from popular manufacturers such as Intel, Broadcom, Apple, and Qualcomm. Our results demonstrate that all tested devices are vulnerable to the KNOB attack. We discuss countermeasures to fix the Bluetooth specification and its implementation.",
            "keywords": [
                "Bluetooth Security",
                "Key Negotiation",
                "KNOB Attack",
                "Low Entropy Vulnerability",
                "Encryption Key Compromise"
            ]
        },
        "url": "URL#2767720",
        "sema_paperId": "e9f0b242e89431382197485d81debbc18699e843"
    },
    {
        "@score": "1",
        "@id": "2767722",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "200/7871",
                        "text": "Noah J. Apthorpe"
                    },
                    {
                        "@pid": "238/0023",
                        "text": "Sarah Varghese"
                    },
                    {
                        "@pid": "87/840",
                        "text": "Nick Feamster"
                    }
                ]
            },
            "title": "Evaluating the Contextual Integrity of Privacy Regulation: Parents&apos; IoT Toy Privacy Norms Versus COPPA.",
            "venue": "USENIX Security Symposium",
            "pages": "123-140",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ApthorpeVF19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/apthorpe",
            "url": "https://dblp.org/rec/conf/uss/ApthorpeVF19",
            "abstract": "Increased concern about data privacy has prompted new and updated data protection regulations worldwide. However, there has been no rigorous way to test whether the practices mandated by these regulations actually align with the privacy norms of affected populations. Here, we demonstrate that surveys based on the theory of contextual integrity provide a quantifiable and scalable method for measuring the conformity of specific regulatory provisions to privacy norms. We apply this method to the U.S. Children's Online Privacy Protection Act (COPPA), surveying 195 parents and providing the first data that COPPA's mandates generally align with parents' privacy expectations for Internet-connected \"smart\" children's toys. Nevertheless, variations in the acceptability of data collection across specific smart toys, information types, parent ages, and other conditions emphasize the importance of detailed contextual factors to privacy norms, which may not be adequately captured by COPPA.",
            "keywords": [
                "Privacy Regulation",
                "Contextual Integrity",
                "Children's Privacy",
                "IoT Toys",
                "COPPA Compliance"
            ]
        },
        "url": "URL#2767722",
        "sema_paperId": "4d2f4e229d66f51a7a99d0444139ee6edd158a69"
    },
    {
        "@score": "1",
        "@id": "2767724",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "248/1647",
                        "text": "Babak Amin Azad"
                    },
                    {
                        "@pid": "167/2160",
                        "text": "Pierre Laperdrix"
                    },
                    {
                        "@pid": "04/8280",
                        "text": "Nick Nikiforakis"
                    }
                ]
            },
            "title": "Less is More: Quantifying the Security Benefits of Debloating Web Applications.",
            "venue": "USENIX Security Symposium",
            "pages": "1697-1714",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AzadLN19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/azad",
            "url": "https://dblp.org/rec/conf/uss/AzadLN19",
            "abstract": "As software becomes increasingly complex, its attack surface expands enabling the exploitation of a wide range of vulnerabilities. Web applications are no exception since modern HTML5 standards and the ever-increasing capabilities of JavaScript are utilized to build rich web applications, often subsuming the need for traditional desktop applications. One possible way of handling this increased complexity is through the process of software debloating, i.e., the removal not only of dead code but also of code corresponding to features that a specific set of users do not require. Even though debloating has been successfully applied on operating systems, libraries, and compiled programs, its applicability on web applications has not yet been investigated. In this paper, we present the first analysis of the security benefits of debloating web applications. We focus on four popular PHP applications and we dynamically exercise them to obtain information about the server-side code that executes as a result of client-side requests. We evaluate two different debloating strategies (file-level debloating and function-level debloating) and we show that we can produce functional web applications that are 46% smaller than their original versions and exhibit half their original cyclomatic complexity. Moreover, our results show that the process of debloating removes code associated with tens of historical vulnerabilities and further shrinks a web application\u2019s attack surface by removing unnecessary external packages and abusable PHP gadgets.",
            "keywords": [
                "Web Application Debloating",
                "Security Benefits",
                "PHP Applications",
                "Code Complexity Reduction",
                "Vulnerability Mitigation"
            ]
        },
        "url": "URL#2767724",
        "sema_paperId": "43e9ecdd1d05a8bac6b4d5e338659af4dabed092"
    },
    {
        "@score": "1",
        "@id": "2767727",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "67/1939",
                        "text": "Lejla Batina"
                    },
                    {
                        "@pid": "94/7837",
                        "text": "Shivam Bhasin"
                    },
                    {
                        "@pid": "163/8627",
                        "text": "Dirmanto Jap"
                    },
                    {
                        "@pid": "50/10230",
                        "text": "Stjepan Picek"
                    }
                ]
            },
            "title": "CSI NN: Reverse Engineering of Neural Network Architectures Through Electromagnetic Side Channel.",
            "venue": "USENIX Security Symposium",
            "pages": "515-532",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BatinaBJP19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/batina",
            "url": "https://dblp.org/rec/conf/uss/BatinaBJP19",
            "abstract": "Machine learning has become mainstream across industries. Numerous examples prove the validity of it for security applications. In this work, we investigate how to reverse engineer a neural network by using side-channel information such as timing and electromagnetic (EM) emanations. To this end, we consider multilayer perceptron and convolutional neural networks as the machine learning architectures of choice and assume a non-invasive and passive attacker capable of measuring those kinds of leakages. We conduct all experiments on real data and commonly used neural network architectures in order to properly assess the applicability and extendability of those attacks. Practical results are shown on an ARM Cortex-M3 microcontroller, which is a platform often used in pervasive applications using neural networks such as wearables, surveillance cameras, etc. Our experiments show that a side-channel attacker is capable of obtaining the following information: the activation functions used in the architecture, the number of layers and neurons in the layers, the number of output classes, and weights in the neural network. Thus, the attacker can effectively reverse engineer the network using merely side-channel information such as timing or EM.",
            "keywords": [
                "Electromagnetic Side Channel",
                "Reverse Engineering",
                "Neural Network Architecture",
                "Non-invasive Attacks",
                "Timing Leakage"
            ]
        },
        "url": "URL#2767727",
        "sema_paperId": "b12c15503435cffee16bdd156766dcf390eeb8f8"
    },
    {
        "@score": "1",
        "@id": "2767728",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "248/1634",
                        "text": "Nishant Bhaskar"
                    },
                    {
                        "@pid": "248/1655",
                        "text": "Maxwell Bland"
                    },
                    {
                        "@pid": "l/KirillLevchenko",
                        "text": "Kirill Levchenko"
                    },
                    {
                        "@pid": "77/3626",
                        "text": "Aaron Schulman"
                    }
                ]
            },
            "title": "Please Pay Inside: Evaluating Bluetooth-based Detection of Gas Pump Skimmers.",
            "venue": "USENIX Security Symposium",
            "pages": "373-388",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BhaskarBLS19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/bhaskar",
            "url": "https://dblp.org/rec/conf/uss/BhaskarBLS19",
            "abstract": "Gas pump skimming is one of the most pervasive forms of payment card attacks in the U.S. today. Gas pump skimmers are easy to install and difficult to detect: criminals can open gas pump enclosures and hide a skimmer in internal payment wiring. As a result, officials have resorted to detecting skimmers by performing laborious manual inspections of the wiring inside gas pumps. In addition, criminals can also avoid being caught using skimmers: many gas pump skimmers have Bluetooth connectivity, allowing criminals to collect payment data safely from inside their car. In this work, we evaluate if the use of Bluetooth in skimmers also creates an opportunity for officials to detect them without opening gas pumps. We performed a large-scale study where we collected Bluetooth scans at 1,185 gas stations in six states. We detected a total of 64 Bluetooth-based skimmers across four U.S. states\u2014all of which were recovered by law enforcement. We discovered that these skimmers were clearly distinguishable from legitimate devices in Bluetooth scans at gas stations. We also observed the nature of gas station skimming: skimmers can be installed for months without detection, and MAC addresses of skimmers may reveal the criminal entity installing or manufacturing them.",
            "keywords": [
                "Gas Pump Skimming",
                "Bluetooth Detection",
                "Payment Card Fraud",
                "Skimmer Identification",
                "Criminal Activity Monitoring"
            ]
        },
        "url": "URL#2767728",
        "sema_paperId": "485703baf40c9bc14a0fcd0ae6a1cde3d9de99d5"
    },
    {
        "@score": "1",
        "@id": "2767729",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "248/1645",
                        "text": "Hugo L. J. Bijmans"
                    },
                    {
                        "@pid": "248/1711",
                        "text": "Tim M. Booij"
                    },
                    {
                        "@pid": "d/ChristianDoerr",
                        "text": "Christian Doerr"
                    }
                ]
            },
            "title": "Inadvertently Making Cyber Criminals Rich: A Comprehensive Study of Cryptojacking Campaigns at Internet Scale.",
            "venue": "USENIX Security Symposium",
            "pages": "1627-1644",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BijmansBD19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/bijmans",
            "url": "https://dblp.org/rec/conf/uss/BijmansBD19",
            "abstract": "Cryptojacking, a phenomenon also known as drive-by cryptomining, involves stealing computing power from others to be used in illicit cryptomining. While first observed as host-based infections with low activity, the release of an efficient browser-based cryptomining application -- as introduced by Coinhive in 2017 -- has skyrocketed cryptojacking activity in recent years. This novel method of monetizing Web activity attracted both website owners and cybercriminals seeking new methods to profit from. Website owners installed a cryptominer on their domains, while cybercriminals deployed cryptominers in large campaigns spread over numerous domains. Several studies developed detection methods to identify these browser-based cryptominers on websites, but none of these studies focused on the extent and coordination of campaigns deployed by adversaries. Furthermore, the prevalence of cryptojacking on websites is not well estimated yet and the potentially largest attack vector -- a man-in-the-middle attack -- has never been researched before. In this thesis, we perform multiple large studies on cryptojacking to fill these gaps. After crawling a random sample of 49M domains, 20% of the Internet, we conclude that cryptojacking is present on 0.011% of all domains and that adult content is the most prevalent category of websites affected. We show that this percentage is significantly larger in the popular part of the Internet. This led to the conclusion that surveying solely domains listed in the Alexa Top 1M to estimate cryptojacking prevalence results in an overestimation of the problem. Furthermore, we show that infection rates on different Top Level Domains (TLDs) differ widely, as the Russian zone is home to a disproportionate number of cryptojacking domains, while other large TLDs -- such as .com -- show a significantly lower number of infections. In another crawl, we have identified 204 cryptojacking campaigns on websites, an order of magnitude more than previous work, which indicates that the extent of these campaigns is heavily underestimated. The results of the two crawls combined reveal that 48% of all cryptojacking activity on websites is organized. The identified campaigns ranged in sizes from only 5 to 987 websites and we discovered that cybercriminals have chosen third-party software -- such as WordPress and Drupal -- as their method of choice for spreading cryptojacking infections efficiently. With a novel method of using NetFlow data recorded in a Tier 1 network, we estimated the popularity of mining applications, which showed that while Coinhive has a larger installed base, CoinImp WebSocket proxies were digesting significantly more traffic in the second half of 2018. We have reported about a new attack vector that drastically overshadows all other cryptojacking activity. Through a firmware vulnerability in MikroTik routers, cybercriminals are able to rewrite outgoing user traffic and embed cryptomining code in every outgoing Web connection. Thus, every Web page visited by any user behind an infected router would mine to profit the adversaries. Based on the aforementioned NetFlow data, weekly third-party crawls and network telescope traffic, we were able to follow their activities over a period of 10 months. We report on the modus operandi and coordinating infrastructure of the perpetrators, which were during this period in control of up to 1.4M routers, which is approximately 70% of all MikroTik devices deployed in the world. During the peak of this attack, more than 440K routers were infected concurrently. We have discovered that half of the infected routers are patched within 18 days after compromise, but 30% of the infections last longer than 50 days. Additionally, we observed different levels of sophistication among adversaries, ranging from individual installations to campaigns involving large numbers of routers. The combination of datasets allowed us to link tens of seemingly different infections to one actor. Our analysis of cryptojacking with a focus on organized campaigns has shown that cybercriminals have successfully discovered a new method for monetary gain. With the discontinuation of Coinhive due to decreased Monero prices in March 2019, the cryptojacking landscape has changed enormously, and we are curious who will fill this power vacuum. As browser-based mining is not anywhere near as profitable as it was in early 2018, we believe that singular cryptojacking activity -- by individual website owners -- will decrease. However, we expect adversaries to find possibilities of deploying cryptojacking at an even larger scale to still be profitable. This stresses the importance of researching campaigns, as the reuse of techniques, tactics and procedures in deploying them provides an effective angle to detect and mitigate these malicious activities. With prices decreasing throughout 2018, one would expect that this problem will eventually solve itself. Apart from the discontinuation of Coinhive, there is no clear indication that this is the case, as Monero prices have started to recover in the first months of 2019. If this trend continues, we expect to experience another outbreak of large cryptojacking campaigns, as robust defenses are still not widely implemented.",
            "keywords": [
                "Cryptojacking",
                "Drive-by Cryptomining",
                "Cybercrime Campaigns",
                "Web Infections",
                "MikroTik Router Vulnerability"
            ]
        },
        "url": "URL#2767729",
        "sema_paperId": "6a33a97a06fc9b7f30524d1bbb50d0b80cce252f"
    },
    {
        "@score": "1",
        "@id": "2767730",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "205/2079",
                        "text": "Tim Blazytko"
                    },
                    {
                        "@pid": "160/7844",
                        "text": "Cornelius Aschermann"
                    },
                    {
                        "@pid": "207/4015",
                        "text": "Moritz Schl\u00f6gel"
                    },
                    {
                        "@pid": "73/2297-2",
                        "text": "Ali Abbasi 0002"
                    },
                    {
                        "@pid": "205/2072",
                        "text": "Sergej Schumilo"
                    },
                    {
                        "@pid": "248/1623",
                        "text": "Simon W\u00f6rner"
                    },
                    {
                        "@pid": "h/ThorstenHolz",
                        "text": "Thorsten Holz"
                    }
                ]
            },
            "title": "GRIMOIRE: Synthesizing Structure while Fuzzing.",
            "venue": "USENIX Security Symposium",
            "pages": "1985-2002",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BlazytkoASASWH19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/blazytko",
            "url": "https://dblp.org/rec/conf/uss/BlazytkoASASWH19",
            "abstract": "In the past few years, fuzzing has received significant attention from the research community. However, most of this attention was directed towards programs without a dedicated parsing stage. In such cases, fuzzers which leverage the input structure of a program can achieve a significantly higher code coverage compared to traditional fuzzing approaches. This advancement in coverage is achieved by applying large-scale mutations in the application\u2019s input space. However, this improvement comes at the cost of requiring expert domain knowledge, as these fuzzers depend on structure input specifications (e. g., grammars). Grammar inference, a technique which can automatically generate such grammars for a given program, can be used to address this shortcoming. Such techniques usually infer a program\u2019s grammar in a pre-processing step and can miss important structures that are uncovered only later during normal fuzzing. In this paper, we present the design and implementation of GRIMOIRE, a fully automated coverage-guided fuzzer which works without any form of human interaction or preconfiguration; yet, it is still able to efficiently test programs that expect highly structured inputs. We achieve this by performing large-scale mutations in the program input space using grammar-like combinations to synthesize new highly structured inputs without any pre-processing step. Our evaluation shows that GRIMOIRE outperforms other coverageguided fuzzers when fuzzing programs with highly structured inputs. Furthermore, it improves upon existing grammarbased coverage-guided fuzzers. Using GRIMOIRE, we identified 19 distinct memory corruption bugs in real-world programs and obtained 11 new CVEs.",
            "keywords": [
                "Fuzzing",
                "Grammar Inference",
                "Coverage-Guided Fuzzing",
                "Structured Inputs",
                "Memory Corruption Bugs"
            ]
        },
        "url": "URL#2767730",
        "sema_paperId": "c046a9505ddca98eb9ca1bbf40dd3678f29c0c6c"
    },
    {
        "@score": "1",
        "@id": "2767731",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "176/5717",
                        "text": "Spyros Boukoros"
                    },
                    {
                        "@pid": "83/8816",
                        "text": "Mathias Humbert"
                    },
                    {
                        "@pid": "66/3585-1",
                        "text": "Stefan Katzenbeisser 0001"
                    },
                    {
                        "@pid": "01/4825",
                        "text": "Carmela Troncoso"
                    }
                ]
            },
            "title": "On (The Lack Of) Location Privacy in Crowdsourcing Applications.",
            "venue": "USENIX Security Symposium",
            "pages": "1859-1876",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BoukorosH0T19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/boukoros",
            "url": "https://dblp.org/rec/conf/uss/BoukorosH0T19",
            "abstract": "Crowdsourcing enables application developers to benefit from large and diverse datasets at a low cost. Specifically, mobile crowdsourcing (MCS) leverages users' devices as sensors to perform geo-located data collection. The collection of geo-located data though, raises serious privacy concerns for users. Yet, despite the large research body on location privacy-preserving mechanisms (LPPMs), MCS developers implement little to no protection for data collection or publication. To understand this mismatch, we study the performance of existing LPPMs on publicly available data from two mobile crowdsourcing projects. Our results show that well-established defenses are either not applicable or offer little protection in the MCS setting. Furthermore, they have a much stronger impact on applications' utility than foreseen in the literature. This is because existing LPPMs, designed with location-based services (LBSs) in mind, are optimized for utility functions based on users' locations, while MCS utility functions depend on the values (e.g., measurements) associated with those locations. We finally outline possible research avenues to facilitate the development of new location privacy solutions that fit the needs of MCS so that the increasing number of such applications do not jeopardize their users' privacy.",
            "keywords": [
                "Mobile Crowdsourcing",
                "Location Privacy",
                "Privacy-Preserving Mechanisms",
                "Geo-located Data Collection",
                "Utility Functions in MCS"
            ]
        },
        "url": "URL#2767731",
        "sema_paperId": "aef01b4238932ded1775447856229a374d529678"
    },
    {
        "@score": "1",
        "@id": "2767733",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "230/4065",
                        "text": "Claudio Canella"
                    },
                    {
                        "@pid": "167/1573",
                        "text": "Jo Van Bulck"
                    },
                    {
                        "@pid": "08/1117-1",
                        "text": "Michael Schwarz 0001"
                    },
                    {
                        "@pid": "172/1127",
                        "text": "Moritz Lipp"
                    },
                    {
                        "@pid": "230/4060",
                        "text": "Benjamin von Berg"
                    },
                    {
                        "@pid": "230/4020",
                        "text": "Philipp Ortner"
                    },
                    {
                        "@pid": "85/6647",
                        "text": "Frank Piessens"
                    },
                    {
                        "@pid": "17/10107",
                        "text": "Dmitry Evtyushkin"
                    },
                    {
                        "@pid": "166/1494",
                        "text": "Daniel Gruss"
                    }
                ]
            },
            "title": "A Systematic Evaluation of Transient Execution Attacks and Defenses.",
            "venue": "USENIX Security Symposium",
            "pages": "249-266",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CanellaB0LBOPEG19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/canella",
            "url": "https://dblp.org/rec/conf/uss/CanellaB0LBOPEG19",
            "abstract": "Research on transient execution attacks including Spectre and Meltdown showed that exception or branch misprediction events might leave secret-dependent traces in the CPU\u2019s microarchitectural state. This observation led to a proliferation of new Spectre and Meltdown attack variants and even more ad-hoc defenses (e.g., microcode and software patches). Both the industry and academia are now focusing on finding effective defenses for known issues. However, we only have limited insight on residual attack surface and the completeness of the proposed defenses.\nIn this paper, we present a systematization of transient execution attacks. Our systematization uncovers 6 (new) transient execution attacks that have been overlooked and not been investigated so far: 2 new exploitable Meltdown effects: Meltdown-PK (Protection Key Bypass) on Intel, and Meltdown-BND (Bounds Check Bypass) on Intel and AMD; and 4 new Spectre mistraining strategies. We evaluate the attacks in our classification tree through proof-of-concept implementations on 3 major CPU vendors (Intel, AMD, ARM). Our systematization yields a more complete picture of the attack surface and allows for a more systematic evaluation of defenses. Through this systematic evaluation, we discover that most defenses, including deployed ones, cannot fully mitigate all attack variants.",
            "pdf_url": "",
            "keywords": [
                "Transient Execution Attacks",
                "Spectre",
                "Meltdown",
                "Microarchitectural Vulnerabilities",
                "Attack Surface Evaluation"
            ]
        },
        "url": "URL#2767733"
    },
    {
        "@score": "1",
        "@id": "2767734",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "218/8811",
                        "text": "Jiahao Cao"
                    },
                    {
                        "@pid": "181/2688-2",
                        "text": "Qi Li 0002"
                    },
                    {
                        "@pid": "191/1022",
                        "text": "Renjie Xie"
                    },
                    {
                        "@pid": "30/3530-1",
                        "text": "Kun Sun 0001"
                    },
                    {
                        "@pid": "64/1147",
                        "text": "Guofei Gu"
                    },
                    {
                        "@pid": "18/6055",
                        "text": "Mingwei Xu"
                    },
                    {
                        "@pid": "25/1439-1",
                        "text": "Yuan Yang 0001"
                    }
                ]
            },
            "title": "The CrossPath Attack: Disrupting the SDN Control Channel via Shared Links.",
            "venue": "USENIX Security Symposium",
            "pages": "19-36",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Cao0XSGX019",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/cao",
            "url": "https://dblp.org/rec/conf/uss/Cao0XSGX019",
            "abstract": "Software-Defined Networking (SDN) enables network innovations with a centralized controller controlling the whole network through the control channel. Because the control channel delivers all network control traffic, its security and reliability are of great importance. For the first time in the literature, we propose the CrossPath attack that disrupts the SDN control channel by exploiting the shared links in paths of control traffic and data traffic. In this attack, crafted data traffic can implicitly disrupt the forwarding of control traffic in the shared links. As the data traffic does not enter the control channel, the attack is stealthy and cannot be easily perceived by the controller. In order to identify the target paths containing the shared links to attack, we develop a novel technique called adversarial path reconnaissance. Both theoretic analysis and experimental results demonstrate its feasibility and efficiency of identifying the target paths. We systematically study the impacts of the attack on various network applications in a real SDN testbed. Experiments show the attack significantly degrades the performance of existing network applications and causes serious network anomalies, e.g., routing blackhole, flow table resetting, and even network-wide DoS.",
            "keywords": [
                "Software-Defined Networking",
                "Control Channel Security",
                "CrossPath Attack",
                "Adversarial Path Reconnaissance",
                "Network Anomalies"
            ]
        },
        "url": "URL#2767734",
        "sema_paperId": "09a2ec674dfe84ac81bee0fdf937868cea438ca3"
    },
    {
        "@score": "1",
        "@id": "2767735",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "145/1806",
                        "text": "Nicholas Carlini"
                    },
                    {
                        "@pid": "52/5716-21",
                        "text": "Chang Liu 0021"
                    },
                    {
                        "@pid": "e/UErlingsson",
                        "text": "\u00dalfar Erlingsson"
                    },
                    {
                        "@pid": "167/6349",
                        "text": "Jernej Kos"
                    },
                    {
                        "@pid": "s/DXSong",
                        "text": "Dawn Song"
                    }
                ]
            },
            "title": "The Secret Sharer: Evaluating and Testing Unintended Memorization in Neural Networks.",
            "venue": "USENIX Security Symposium",
            "pages": "267-284",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Carlini0EKS19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/carlini",
            "url": "https://dblp.org/rec/conf/uss/Carlini0EKS19",
            "abstract": "This paper describes a testing methodology for quantitatively assessing the risk that rare or unique training-data sequences are unintentionally memorized by generative sequence models---a common type of machine-learning model. Because such models are sometimes trained on sensitive data (e.g., the text of users' private messages), this methodology can benefit privacy by allowing deep-learning practitioners to select means of training that minimize such memorization. \nIn experiments, we show that unintended memorization is a persistent, hard-to-avoid issue that can have serious consequences. Specifically, for models trained without consideration of memorization, we describe new, efficient procedures that can extract unique, secret sequences, such as credit card numbers. We show that our testing strategy is a practical and easy-to-use first line of defense, e.g., by describing its application to quantitatively limit data exposure in Google's Smart Compose, a commercial text-completion neural network trained on millions of users' email messages.",
            "keywords": [
                "Generative Sequence Models",
                "Data Memorization",
                "Privacy Risks",
                "Sensitive Data Exposure",
                "Testing Methodology"
            ]
        },
        "url": "URL#2767735",
        "sema_paperId": "520ec00dc35475e0554dbb72f27bd2eeb6f4191d"
    },
    {
        "@score": "1",
        "@id": "2767737",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "239/8680-1",
                        "text": "Dhiman Chakraborty 0001"
                    },
                    {
                        "@pid": "119/3581",
                        "text": "Lucjan Hanzlik"
                    },
                    {
                        "@pid": "31/7561",
                        "text": "Sven Bugiel"
                    }
                ]
            },
            "title": "simTPM: User-centric TPM for Mobile Devices.",
            "venue": "USENIX Security Symposium",
            "pages": "533-550",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChakrabortyHB19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/chakraborty",
            "url": "https://dblp.org/rec/conf/uss/ChakrabortyHB19",
            "abstract": "Trusted Platform Modules are valuable building blocks for security solutions and have also been recognized as beneficial for security on mobile platforms, like smartphones and tablets. However, strict space, cost, and power constraints of mobile devices prohibit an implementation as dedicated on-board chip and the incumbent implementations are software TPMs protected by Trusted Execution Environments. In this paper, we present simTPM, an alternative implementation of a mobile TPM based on the SIM card available in mobile platforms. We solve the technical challenge of implementing a TPM2.0 in the resource-constrained SIM card environment and integrate our simTPM into the secure boot chain of the ARM Trusted Firmware on a HiKey960 reference board. Most notably, we address the challenge of how a removable TPM can be bound to the host device\u2019s root of trust for measurement. As such, our solution not only provides a mobile TPM that avoids additional hardware while using a dedicated, strongly protected environment, but also offers promising synergies with co-existing TEE-based TPMs. In particular, simTPM offers a user-centric trusted module. Using performance benchmarks, we show that our simTPM has competitive speed with a reported TEE-based TPM and a hardware-based TPM.",
            "keywords": [
                "Mobile Security",
                "Trusted Platform Module",
                "SIM Card Integration",
                "Resource-Constrained Environments",
                "User-Centric Trusted Module"
            ]
        },
        "url": "URL#2767737",
        "sema_paperId": "fccec38562b19314001695dee87ea9baca628044"
    },
    {
        "@score": "1",
        "@id": "2767738",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "217/3726",
                        "text": "Yuanliang Chen"
                    },
                    {
                        "@pid": "21/4633-1",
                        "text": "Yu Jiang 0001"
                    },
                    {
                        "@pid": "237/8603",
                        "text": "Fuchen Ma"
                    },
                    {
                        "@pid": "51/239-6",
                        "text": "Jie Liang 0006"
                    },
                    {
                        "@pid": "64/9796",
                        "text": "Mingzhe Wang"
                    },
                    {
                        "@pid": "228/5716",
                        "text": "Chijin Zhou"
                    },
                    {
                        "@pid": "117/5478",
                        "text": "Xun Jiao"
                    },
                    {
                        "@pid": "02/10578-5",
                        "text": "Zhuo Su 0005"
                    }
                ]
            },
            "title": "EnFuzz: Ensemble Fuzzing with Seed Synchronization among Diverse Fuzzers.",
            "venue": "USENIX Security Symposium",
            "pages": "1967-1983",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Chen0MLWZJS19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/chen-yuanliang",
            "url": "https://dblp.org/rec/conf/uss/Chen0MLWZJS19",
            "abstract": "Fuzzing is widely used for software vulnerability detection. There are various kinds of fuzzers with different fuzzing strategies, and most of them perform well on their targets. However, in industry practice and empirical study, the performance and generalization ability of those well-designed fuzzing strategies are challenged by the complexity and diversity of real-world applications. \nIn this paper, inspired by the idea of ensemble learning, we first propose an ensemble fuzzing approach EnFuzz, that integrates multiple fuzzing strategies to obtain better performance and generalization ability than that of any constituent fuzzer alone. First, we define the diversity of the base fuzzers and choose those most recent and well-designed fuzzers as base fuzzers. Then, EnFuzz ensembles those base fuzzers with seed synchronization and result integration mechanisms. For evaluation, we implement EnFuzz , a prototype basing on four strong open-source fuzzers (AFL, AFLFast, AFLGo, FairFuzz), and test them on Google's fuzzing test suite, which consists of widely used real-world applications. The 24-hour experiment indicates that, with the same resources usage, these four base fuzzers perform variously on different applications, while EnFuzz shows better generalization ability and always outperforms others in terms of path coverage, branch coverage and crash discovery. Even compared with the best cases of AFL, AFLFast, AFLGo and FairFuzz, EnFuzz discovers 26.8%, 117%, 38.8% and 39.5% more unique crashes, executes 9.16%, 39.2%, 19.9% and 20.0% more paths and covers 5.96%, 12.0%, 21.4% and 11.1% more branches respectively.",
            "keywords": [
                "Fuzzing",
                "Software Vulnerability Detection",
                "Ensemble Learning",
                "Seed Synchronization",
                "Path and Branch Coverage"
            ]
        },
        "url": "URL#2767738",
        "sema_paperId": "8754951ba8bbb42ff10e100fa853a5ce86af5ab1"
    },
    {
        "@score": "1",
        "@id": "2767739",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "86/9924",
                        "text": "Christine Chen"
                    },
                    {
                        "@pid": "75/11301",
                        "text": "Nicola Dell"
                    },
                    {
                        "@pid": "23/2758",
                        "text": "Franziska Roesner"
                    }
                ]
            },
            "title": "Computer Security and Privacy in the Interactions Between Victim Service Providers and Human Trafficking Survivors.",
            "venue": "USENIX Security Symposium",
            "pages": "89-104",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChenDR19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/chen",
            "url": "https://dblp.org/rec/conf/uss/ChenDR19",
            "abstract": "A victim service provider, or VSP, is a crucial partner in a human trafficking survivor's recovery. VSPs provide or connect survivors to resources such as medical care, legal services, employment opportunities, etc. In this work, we study VSP-survivor interactions from a computer security and privacy perspective. Through 17 semi-structured interviews with staff members at VSPs and survivors of trafficking, we surface the role technology plays in VSP-survivor interactions as well as related computer security and privacy concerns and mitigations. Our results highlight various tensions that VSPs must balance, including building trust with their clients (often by giving them as much autonomy as possible) while attempting to guide their use of technology to mitigate risks around revictimization. We conclude with concrete recommendations for computer security and privacy technologists who wish to partner with VSPs to support and empower trafficking survivors.",
            "keywords": [
                "Human Trafficking",
                "Victim Service Providers",
                "Computer Security",
                "Privacy Concerns",
                "Survivor Empowerment"
            ]
        },
        "url": "URL#2767739",
        "sema_paperId": "a4ee9f4aa9c5adf0055c133caf227ee34d699a99"
    },
    {
        "@score": "1",
        "@id": "2767740",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "49/6574",
                        "text": "Yi Chen"
                    },
                    {
                        "@pid": "34/8412",
                        "text": "Luyi Xing"
                    },
                    {
                        "@pid": "142/1169",
                        "text": "Yue Qin"
                    },
                    {
                        "@pid": "129/1113",
                        "text": "Xiaojing Liao"
                    },
                    {
                        "@pid": "06/6268",
                        "text": "XiaoFeng Wang 0001"
                    },
                    {
                        "@pid": "c/KaiChen12",
                        "text": "Kai Chen 0012"
                    },
                    {
                        "@pid": "10/328",
                        "text": "Wei Zou"
                    }
                ]
            },
            "title": "Devils in the Guidance: Predicting Logic Vulnerabilities in Payment Syndication Services through Automated Documentation Analysis.",
            "venue": "USENIX Security Symposium",
            "pages": "747-764",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChenXQL00Z19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/chen-yi",
            "url": "https://dblp.org/rec/conf/uss/ChenXQL00Z19",
            "abstract": "Finding logic \ufb02aws today relies on the program analysis that leverages the functionality information reported in the program\u2019s documentation. Our research, however, shows that the documentation alone may already contain information for predicting the presence of some logic \ufb02aws, even before the code is analyzed. Our \ufb01rst step on this direction focuses on emerging syndication services that facilitate integration of multiple payment services (e.g., Alipay, Wechat Pay, PayPal, etc.) into merchant systems. We look at whether a syndication service will cause some security requirements (e.g., checking payment against price) to become unenforceable due to losing visibility of some key parameters (e.g., payment, price) to the parties involved in the syndication, or bring in implementation errors when required security checks fail to be communicated to the developer. For this purpose, we developed a suite of Natural Language Processing techniques that enables automatic inspection of the syndication developer\u2019s guide, based upon the payment models and security requirements from the payment service. Our approach is found to be effective in identifying these potential problems from the guide, and leads to the discovery of 5 new security-critical \ufb02aws in popular Chinese merchant systems that can cause circumvention of payment once exploited.",
            "keywords": [
                "Payment Syndication Services",
                "Logic Flaws",
                "Natural Language Processing",
                "Security Requirements",
                "Automated Documentation Analysis"
            ]
        },
        "url": "URL#2767740",
        "sema_paperId": "f354daee6da3dcd4f8ce20cb56d895ac613cc82e"
    },
    {
        "@score": "1",
        "@id": "2767741",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "180/8231",
                        "text": "Haibo Cheng"
                    },
                    {
                        "@pid": "214/0266",
                        "text": "Zhixiong Zheng"
                    },
                    {
                        "@pid": "29/4801-2",
                        "text": "Wenting Li 0002"
                    },
                    {
                        "@pid": "37/1304-3",
                        "text": "Ping Wang 0003"
                    },
                    {
                        "@pid": "02/4329",
                        "text": "Chao-Hsien Chu"
                    }
                ]
            },
            "title": "Probability Model Transforming Encoders Against Encoding Attacks.",
            "venue": "USENIX Security Symposium",
            "pages": "1573-1590",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChengZL0C19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/cheng",
            "url": "https://dblp.org/rec/conf/uss/ChengZL0C19",
            "abstract": "Honey encryption (HE) is a novel encryption scheme for resisting brute-force attacks even using low-entropy keys (e.g., passwords). HE introduces a distribution transforming encoder (DTE) to yield plausible-looking decoy messages for incorrect keys. Several HE applications were proposed for specific messages with specially designed probability model transforming encoders (PMTEs), DTEs transformed from probability models which are used to characterize the intricate message distributions. We propose attacks against three typical PMTE schemes. Using a simple machine learning algorithm, we propose a distribution difference attack against genomic data PMTEs, achieving 76.54%\u2013100.00% accuracy in distinguishing real data from decoy one. We then propose a new type of attack\u2014 encoding attacks\u2014against two password vault PMTEs, achieving 98.56%\u201399.52% accuracy. Different from distribution difference attacks, encoding attacks do not require any knowledge (statistics) about the real message distribution. We also introduce a generic conceptual probability model\u2014 generative probability model (GPM)\u2014to formalize probability models and design a generic method for transforming an arbitrary GPM to a PMTE. We prove that our PMTEs are information-theoretically indistinguishable from the corresponding GPMs. Accordingly, they can resist encoding attacks. For our PMTEs transformed from existing password vault models, encoding attacks cannot achieve more than 52.56% accuracy, which is slightly better than the randomly guessing attack (50% accuracy).",
            "keywords": [
                "Honey Encryption",
                "Probability Model Transforming Encoders",
                "Encoding Attacks",
                "Decoy Messages",
                "Genomic Data PMTEs"
            ]
        },
        "url": "URL#2767741",
        "sema_paperId": "bbe5197e83a48da244b7814ed4c5cbfda91d1b5e"
    },
    {
        "@score": "1",
        "@id": "2767742",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "35/10805",
                        "text": "Asaf Cidon"
                    },
                    {
                        "@pid": "55/10443",
                        "text": "Lior Gavish"
                    },
                    {
                        "@pid": "248/1664",
                        "text": "Itay Bleier"
                    },
                    {
                        "@pid": "248/1651",
                        "text": "Nadia Korshun"
                    },
                    {
                        "@pid": "248/1694",
                        "text": "Marco Schweighauser"
                    },
                    {
                        "@pid": "152/4695",
                        "text": "Alexey Tsitkin"
                    }
                ]
            },
            "title": "High Precision Detection of Business Email Compromise.",
            "venue": "USENIX Security Symposium",
            "pages": "1291-1307",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CidonGBKST19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/cidon",
            "url": "https://dblp.org/rec/conf/uss/CidonGBKST19",
            "abstract": "Business email compromise (BEC) and employee impersonation have become one of the most costly cyber-security threats, causing over $12 billion in reported losses. Impersonation emails take several forms: for example, some ask for a wire transfer to the attacker\u2019s account, while others lead the recipient to following a link, which compromises their credentials. Email security systems are not effective in detecting these attacks, because the attacks do not contain a clearly malicious payload, and are personalized to the recipient. We present BEC-Guard, a detector used at Barracuda Networks that prevents business email compromise attacks in real-time using supervised learning. BEC-Guard has been in production since July 2017, and is part of the Barracuda Sentinel email security product. BEC-Guard detects attacks by relying on statistics about the historical email patterns that can be accessed via cloud email provider APIs. The two main challenges when designing BEC-Guard are the need to label millions of emails to train its classifiers, and to properly train the classifiers when the occurrence of employee impersonation emails is very rare, which can bias the classification. Our key insight is to split the classification problem into two parts, one analyzing the header of the email, and the second applying natural language processing to detect phrases associated with BEC or suspicious links in the email body. BEC-Guard utilizes the public APIs of cloud email providers both to automatically learn the historical communication patterns of each organization, and to quarantine emails in real-time. We evaluated BEC-Guard on a commercial dataset containing more than 4,000 attacks, and show it achieves a precision of 98.2% and a false positive rate of less than one in five million emails.",
            "keywords": [
                "Business Email Compromise",
                "Email Security",
                "Impersonation Detection",
                "Natural Language Processing",
                "Real-time Quarantine"
            ]
        },
        "url": "URL#2767742",
        "sema_paperId": "057e59cef6deef4220740c05ec058165344391b1"
    },
    {
        "@score": "1",
        "@id": "2767743",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "184/4259",
                        "text": "R. Joseph Connor"
                    },
                    {
                        "@pid": "54/8732",
                        "text": "Max Schuchard"
                    }
                ]
            },
            "title": "Blind Bernoulli Trials: A Noninteractive Protocol For Hidden-Weight Coin Flips.",
            "venue": "USENIX Security Symposium",
            "pages": "1483-1500",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ConnorS19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/connor",
            "url": "https://dblp.org/rec/conf/uss/ConnorS19",
            "abstract": "We introduce the concept of a \u201cBlind Bernoulli Trial,\u201d a noninteractive protocol that allows a set of remote, disconnected users to individually compute one random bit each with probability p defined by the sender, such that no receiver learns any more information about p than strictly necessary. We motivate the problem by discussing several possible applications in secure distributed systems. We then formally define the problem in terms of correctness and security definitions and explore possible solutions using existing cryptographic primitives. We prove the security of an efficient solution in the standard model. Finally, we implement the solution and give performance results that show it is practical with current hardware.",
            "keywords": [
                "Blind Bernoulli Trials",
                "Noninteractive Protocols",
                "Random Bit Generation",
                "Secure Distributed Systems",
                "Hidden-Weight Coin Flips"
            ]
        },
        "url": "URL#2767743",
        "sema_paperId": "170298eaf704bbf2752b76ad1413d0370e2436aa"
    },
    {
        "@score": "1",
        "@id": "2767748",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "167/0815",
                        "text": "Ambra Demontis"
                    },
                    {
                        "@pid": "18/485",
                        "text": "Marco Melis"
                    },
                    {
                        "@pid": "227/3373",
                        "text": "Maura Pintor"
                    },
                    {
                        "@pid": "218/5156",
                        "text": "Matthew Jagielski"
                    },
                    {
                        "@pid": "29/1830",
                        "text": "Battista Biggio"
                    },
                    {
                        "@pid": "35/3425",
                        "text": "Alina Oprea"
                    },
                    {
                        "@pid": "n/CristinaNitaRotaru",
                        "text": "Cristina Nita-Rotaru"
                    },
                    {
                        "@pid": "28/896",
                        "text": "Fabio Roli"
                    }
                ]
            },
            "title": "Why Do Adversarial Attacks Transfer? Explaining Transferability of Evasion and Poisoning Attacks.",
            "venue": "USENIX Security Symposium",
            "pages": "321-338",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DemontisMPJBONR19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/demontis",
            "url": "https://dblp.org/rec/conf/uss/DemontisMPJBONR19",
            "abstract": "Transferability captures the ability of an attack against a machine-learning model to be effective against a different, potentially unknown, model. Empirical evidence for transferability has been shown in previous work, but the underlying reasons why an attack transfers or not are not yet well understood. In this paper, we present a comprehensive analysis aimed to investigate the transferability of both test-time evasion and training-time poisoning attacks. We provide a unifying optimization framework for evasion and poisoning attacks, and a formal definition of transferability of such attacks. We highlight two main factors contributing to attack transferability: the intrinsic adversarial vulnerability of the target model, and the complexity of the surrogate model used to optimize the attack. Based on these insights, we define three metrics that impact an attack's transferability. Interestingly, our results derived from theoretical analysis hold for both evasion and poisoning attacks, and are confirmed experimentally using a wide range of linear and non-linear classifiers and datasets.",
            "keywords": [
                "Adversarial Attacks",
                "Transferability",
                "Evasion Attacks",
                "Poisoning Attacks",
                "Adversarial Vulnerability"
            ]
        },
        "url": "URL#2767748",
        "sema_paperId": "8bac2716cd208cb8041650a001ab72ba81b559cd"
    },
    {
        "@score": "1",
        "@id": "2767749",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "153/0574",
                        "text": "Ghada Dessouky"
                    },
                    {
                        "@pid": "164/2771",
                        "text": "David Gens"
                    },
                    {
                        "@pid": "232/2405",
                        "text": "Patrick Haney"
                    },
                    {
                        "@pid": "232/2300",
                        "text": "Garrett Persyn"
                    },
                    {
                        "@pid": "83/9640",
                        "text": "Arun K. Kanuparthi"
                    },
                    {
                        "@pid": "68/1555",
                        "text": "Hareesh Khattri"
                    },
                    {
                        "@pid": "205/6407",
                        "text": "Jason M. Fung"
                    },
                    {
                        "@pid": "s/AhmadRezaSadeghi",
                        "text": "Ahmad-Reza Sadeghi"
                    },
                    {
                        "@pid": "79/9006",
                        "text": "Jeyavijayan Rajendran"
                    }
                ]
            },
            "title": "HardFails: Insights into Software-Exploitable Hardware Bugs.",
            "venue": "USENIX Security Symposium",
            "pages": "213-230",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DessoukyGHPKKFS19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/dessouky",
            "url": "https://dblp.org/rec/conf/uss/DessoukyGHPKKFS19",
            "abstract": ".",
            "keywords": [
                "Hardware Vulnerabilities",
                "Software Exploitation",
                "Bug Detection",
                "System Security",
                "Exploitable Hardware Bugs"
            ]
        },
        "url": "URL#2767749",
        "sema_paperId": "7183927e2027578a54b43c41b1556b135ea63ac4"
    },
    {
        "@score": "1",
        "@id": "2767750",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "55/5645",
                        "text": "Ying Dong"
                    },
                    {
                        "@pid": "144/1238-2",
                        "text": "Wenbo Guo 0002"
                    },
                    {
                        "@pid": "16/6884-1",
                        "text": "Yueqi Chen 0001"
                    },
                    {
                        "@pid": "40/6431",
                        "text": "Xinyu Xing"
                    },
                    {
                        "@pid": "83/6530",
                        "text": "Yuqing Zhang"
                    },
                    {
                        "@pid": "71/4292-11",
                        "text": "Gang Wang 0011"
                    }
                ]
            },
            "title": "Towards the Detection of Inconsistencies in Public Security Vulnerability Reports.",
            "venue": "USENIX Security Symposium",
            "pages": "869-885",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DongGCXZ019",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/dong",
            "url": "https://dblp.org/rec/conf/uss/DongGCXZ019",
            "abstract": "Public vulnerability databases such as the Common Vulnerabilities and Exposures (CVE) and the National Vulnerability Database (NVD) have achieved great success in promoting vulnerability disclosure and mitigation. While these databases have accumulated massive data, there is a growing concern for their information quality and consistency. In this paper, we propose an automated system VIEM to detect inconsistent information between the fully standardized NVD database and the unstructured CVE descriptions and their referenced vulnerability reports. VIEM allows us, for the first time, to quantify the information consistency at a massive scale, and provides the needed tool for the community to keep the CVE/NVD databases up-to-date. VIEM is developed to extract vulnerable software names and vulnerable versions from unstructured text. We introduce customized designs to deep-learning-based named entity recognition (NER) and relation extraction (RE) so that VIEM can recognize previous unseen software names and versions based on sentence structure and contexts. Ground-truth evaluation shows the system is highly accurate (0.941 precision and 0.993 recall). Using VIEM, we examine the information consistency using a large dataset of 78,296 CVE IDs and 70,569 vulnerability reports in the past 20 years. Our result suggests that inconsistent vulnerable software versions are highly prevalent. Only 59.82% of the vulnerability reports/CVE summaries strictly match the standardized NVD entries, and the inconsistency level increases over time. Case studies confirm the erroneous information of NVD that either overclaims or underclaims the vulnerable software versions.",
            "keywords": [
                "Vulnerability Databases",
                "Information Consistency",
                "CVE",
                "NVD",
                "Vulnerability Reports"
            ]
        },
        "url": "URL#2767750",
        "sema_paperId": "7d5eee58523e0066057c4008a9afb03b0b6d224d"
    },
    {
        "@score": "1",
        "@id": "2767752",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "09/8674",
                        "text": "Xuan Feng"
                    },
                    {
                        "@pid": "129/1113",
                        "text": "Xiaojing Liao"
                    },
                    {
                        "@pid": "06/6268",
                        "text": "XiaoFeng Wang 0001"
                    },
                    {
                        "@pid": "81/4036-1",
                        "text": "Haining Wang 0001"
                    },
                    {
                        "@pid": "72/872-7",
                        "text": "Qiang Li 0007"
                    },
                    {
                        "@pid": "17/2247",
                        "text": "Kai Yang"
                    },
                    {
                        "@pid": "57/5368",
                        "text": "Hongsong Zhu"
                    },
                    {
                        "@pid": "37/4705-1",
                        "text": "Limin Sun 0001"
                    }
                ]
            },
            "title": "Understanding and Securing Device Vulnerabilities through Automated Bug Report Analysis.",
            "venue": "USENIX Security Symposium",
            "pages": "887-903",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/FengL0W0YZS19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/feng",
            "url": "https://dblp.org/rec/conf/uss/FengL0W0YZS19",
            "abstract": "Recent years have witnessed the rise of Internet-of-Things (IoT) based cyber attacks. These attacks, as expected, are launched from compromised IoT devices by exploiting security \ufb02aws already known. Less clear, however, are the fundamental causes of the pervasiveness of IoT device vulnerabilities and their security implications, particularly in how they affect ongoing cybercrimes. To better understand the problems and seek effective means to suppress the wave of IoT-based attacks, we conduct a comprehensive study based on a large number of real-world attack traces collected from our honeypots, attack tools purchased from the underground, and information collected from high-pro\ufb01le IoT attacks. This study sheds new light on the device vulnerabilities of today\u2019s IoT systems and their security implications: ongoing cyber attacks heavily rely on these known vulnerabilities and the attack code released through their reports; on the other hand, such a reliance on known vulnerabilities can actually be used against adversaries. The same bug reports that enable the development of an attack at an exceedingly low cost can also be leveraged to extract vulnerability-speci\ufb01c features that help stop the attack. In particular, we leverage Natural Language Processing (NLP) to automatically collect and analyze more than 7,500 security reports (with 12,286 security critical IoT \ufb02aws in total) scattered across bug-reporting blogs, forums, and mailing lists on the Internet. We show that signatures can be automatically generated through an NLP-based report",
            "keywords": [
                "IoT Security",
                "Device Vulnerabilities",
                "Automated Bug Report Analysis",
                "Natural Language Processing",
                "Cyber Attacks"
            ]
        },
        "url": "URL#2767752",
        "sema_paperId": "5ab8276f1cf4cd4bdb0d935b934e0a8e63038e35"
    },
    {
        "@score": "1",
        "@id": "2767753",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "f/FelixFischer-1",
                        "text": "Felix Fischer 0001"
                    },
                    {
                        "@pid": "51/8434",
                        "text": "Huang Xiao"
                    },
                    {
                        "@pid": "236/3738",
                        "text": "Ching-yu Kao"
                    },
                    {
                        "@pid": "248/1633",
                        "text": "Yannick Stachelscheid"
                    },
                    {
                        "@pid": "84/2126-1",
                        "text": "Benjamin Johnson 0001"
                    },
                    {
                        "@pid": "248/1715",
                        "text": "Danial Razar"
                    },
                    {
                        "@pid": "248/1719",
                        "text": "Paul Fawkesley"
                    },
                    {
                        "@pid": "248/1612",
                        "text": "Nat Buckley"
                    },
                    {
                        "@pid": "122/3548",
                        "text": "Konstantin B\u00f6ttinger"
                    },
                    {
                        "@pid": "161/9270",
                        "text": "Paul Muntean 0001"
                    },
                    {
                        "@pid": "28/3855",
                        "text": "Jens Grossklags"
                    }
                ]
            },
            "title": "Stack Overflow Considered Helpful! Deep Learning Security Nudges Towards Stronger Cryptography.",
            "venue": "USENIX Security Symposium",
            "pages": "339-356",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/FischerXKSJRFBB19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/fischer",
            "url": "https://dblp.org/rec/conf/uss/FischerXKSJRFBB19",
            "abstract": ",",
            "keywords": [
                "Cryptographic Strength",
                "Deep Learning Security",
                "Vulnerability Mitigation",
                "Security Nudges",
                "Cryptographic Protocols"
            ]
        },
        "url": "URL#2767753",
        "sema_paperId": "47d2de6f6b38096b21e77d8910a99721b34f0adf"
    },
    {
        "@score": "1",
        "@id": "2767755",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "218/6805",
                        "text": "Andrea Gadotti"
                    },
                    {
                        "@pid": "217/2259",
                        "text": "Florimond Houssiau"
                    },
                    {
                        "@pid": "203/7256",
                        "text": "Luc Rocher"
                    },
                    {
                        "@pid": "46/2924",
                        "text": "Benjamin Livshits"
                    },
                    {
                        "@pid": "75/7560",
                        "text": "Yves-Alexandre de Montjoye"
                    }
                ]
            },
            "title": "When the Signal is in the Noise: Exploiting Diffix&apos;s Sticky Noise.",
            "venue": "USENIX Security Symposium",
            "pages": "1081-1098",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GadottiHRLM19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/gadotti",
            "url": "https://dblp.org/rec/conf/uss/GadottiHRLM19",
            "abstract": "Anonymized data is highly valuable to both businesses and researchers. A large body of research has however shown the strong limits of the de-identification release-and-forget model, where data is anonymized and shared. This has led to the development of privacy-preserving query-based systems. Based on the idea of \"sticky noise\", Diffix has been recently proposed as a novel query-based mechanism satisfying alone the EU Article~29 Working Party's definition of anonymization. According to its authors, Diffix adds less noise to answers than solutions based on differential privacy while allowing for an unlimited number of queries. \nThis paper presents a new class of noise-exploitation attacks, exploiting the noise added by the system to infer private information about individuals in the dataset. Our first differential attack uses samples extracted from Diffix in a likelihood ratio test to discriminate between two probability distributions. We show that using this attack against a synthetic best-case dataset allows us to infer private information with 89.4% accuracy using only 5 attributes. Our second cloning attack uses dummy conditions that conditionally strongly affect the output of the query depending on the value of the private attribute. Using this attack on four real-world datasets, we show that we can infer private attributes of at least 93% of the users in the dataset with accuracy between 93.3% and 97.1%, issuing a median of 304 queries per user. We show how to optimize this attack, targeting 55.4% of the users and achieving 91.7% accuracy, using a maximum of only 32 queries per user. \nOur attacks demonstrate that adding data-dependent noise, as done by Diffix, is not sufficient to prevent inference of private attributes. We furthermore argue that Diffix alone fails to satisfy Art. 29 WP's definition of anonymization. [...]",
            "keywords": [
                "Anonymization",
                "Privacy-Preserving Systems",
                "Sticky Noise",
                "Inference Attacks",
                "Differential Attack"
            ]
        },
        "url": "URL#2767755",
        "sema_paperId": "16f393b4d90d0de7cf1ba100f307ad2f6856edb8"
    },
    {
        "@score": "1",
        "@id": "2767756",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "86/10265",
                        "text": "Klaus von Gleissenthall"
                    },
                    {
                        "@pid": "182/4711",
                        "text": "Rami G\u00f6khan Kici"
                    },
                    {
                        "@pid": "91/6118",
                        "text": "Deian Stefan"
                    },
                    {
                        "@pid": "47/4244",
                        "text": "Ranjit Jhala"
                    }
                ]
            },
            "title": "IODINE: Verifying Constant-Time Execution of Hardware.",
            "venue": "USENIX Security Symposium",
            "pages": "1411-1428",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GleissenthallKS19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/von-gleissenthall",
            "url": "https://dblp.org/rec/conf/uss/GleissenthallKS19",
            "abstract": "To be secure, cryptographic algorithms crucially rely on the underlying hardware to avoid inadvertent leakage of secrets through timing side channels. Unfortunately, such timing channels are ubiquitous in modern hardware, due to its labyrinthine fast-paths and optimizations. A promising way to avoid timing vulnerabilities is to devise \u2013 and verify \u2013 conditions under which a hardware design is free of timing variability, i.e., executes in constant-time. In this paper, we present IODINE: a clock-precise, constant-time approach to eliminating timing side channels in hardware. IODINE succeeds in verifying various open source hardware designs in seconds and with little developer effort. IODINE also discovered two constant-time violations: one in a floating-point unit and another one in an RSA encryption module.",
            "pdf_url": "",
            "keywords": [
                "Hardware Security",
                "Timing Side Channels",
                "Constant-Time Execution",
                "Verification Methodology",
                "Cryptographic Algorithms"
            ]
        },
        "url": "URL#2767756"
    },
    {
        "@score": "1",
        "@id": "2767759",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "248/1578",
                        "text": "Emre G\u00fcler"
                    },
                    {
                        "@pid": "160/7844",
                        "text": "Cornelius Aschermann"
                    },
                    {
                        "@pid": "73/2297-2",
                        "text": "Ali Abbasi 0002"
                    },
                    {
                        "@pid": "h/ThorstenHolz",
                        "text": "Thorsten Holz"
                    }
                ]
            },
            "title": "AntiFuzz: Impeding Fuzzing Audits of Binary Executables.",
            "venue": "USENIX Security Symposium",
            "pages": "1931-1947",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GulerAAH19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/guler",
            "url": "https://dblp.org/rec/conf/uss/GulerAAH19",
            "abstract": "A general defense strategy in computer security is to increase the cost of successful attacks in both computational resources as well as human time. In the area of binary security, this is commonly done by using obfuscation methods to hinder reverse engineering and the search for software vulnerabilities. However, recent trends in automated bug finding changed the modus operandi. Nowadays it is very common for bugs to be found by various fuzzing tools. Due to ever-increasing amounts of automation and research on better fuzzing strategies, large-scale, dragnet-style fuzzing of many hundreds of targets becomes viable. As we show, current obfuscation techniques are aimed at increasing the cost of human understanding and do little to slow down fuzzing. In this paper, we introduce several techniques to protect a binary executable against an analysis with automated bug finding approaches that are based on fuzzing, symbolic/concolic execution, and taint-assisted fuzzing (commonly known as hybrid fuzzing). More specifically, we perform a systematic analysis of the fundamental assumptions of bug finding tools and develop general countermeasures for each assumption. Note that these techniques are not designed to target specific implementations of fuzzing tools, but address general assumptions that bug finding tools necessarily depend on. Our evaluation demonstrates that these techniques effectively impede fuzzing audits, while introducing a negligible performance overhead. Just as obfuscation techniques increase the amount of human labor needed to find a vulnerability, our techniques render automated fuzzing-based approaches futile.",
            "keywords": [
                "Binary Security",
                "Fuzzing Audits",
                "Obfuscation Techniques",
                "Automated Bug Finding",
                "Hybrid Fuzzing"
            ]
        },
        "url": "URL#2767759",
        "sema_paperId": "4b2df28049f8d50001a02e0cd835b98c57f6e7f3"
    },
    {
        "@score": "1",
        "@id": "2767760",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "144/1238-2",
                        "text": "Wenbo Guo 0002"
                    },
                    {
                        "@pid": "187/8991",
                        "text": "Dongliang Mu"
                    },
                    {
                        "@pid": "40/6431",
                        "text": "Xinyu Xing"
                    },
                    {
                        "@pid": "78/1658-3",
                        "text": "Min Du 0003"
                    },
                    {
                        "@pid": "s/DXSong",
                        "text": "Dawn Song"
                    }
                ]
            },
            "title": "DEEPVSA: Facilitating Value-set Analysis with Deep Learning for Postmortem Program Analysis.",
            "venue": "USENIX Security Symposium",
            "pages": "1787-1804",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GuoMXDS19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/guo",
            "url": "https://dblp.org/rec/conf/uss/GuoMXDS19",
            "abstract": "Value set analysis (VSA) is one of the most powerful binary analysis tools, which has been broadly adopted in many use cases, ranging from verifying software properties (e.g., variable range analysis) to identifying software vulnerabilities (e.g., buffer overflow detection). Using it to facilitate data flow analysis in the context of postmortem program analysis, it however exhibits an insufficient capability in handling memory alias identification. Technically speaking, this is due to the fact that VSA needs to infer memory reference based on the context of a control flow, but accidental termination of a running program left behind incomplete control flow information, making memory alias analysis clueless.To address this issue, we propose a new technical approach. At the high level, this approach first employs a layer of instruction embedding along with a  bi-directional sequence-to-sequence neural network to learn the machine code pattern pertaining to memory region accesses. Then, it utilizes the network to infer the memory region that VSA fails to recognize. Since the memory references to different regions naturally indicate the non-alias relationship, the proposed neural architecture can facilitate the ability of VSA to perform better alias analysis.  Different from previous research that utilizes deep learning for other binary analysis tasks, the neural network proposed in this work is fundamentally novel. Instead of simply using off-the-shelf neural networks, we introduce a new neural network architecture which could capture the data dependency between and within instructions. %machine code. In this work, we implement our deep neural architecture as DEEPVSA, a neural network assisted alias analysis tool. To demonstrate the utility of  this tool, we use it to analyze software crashes corresponding to 40 memory corruption vulnerabilities archived in Offensive Security Exploit Database. We show that, DEEPVSA can significantly improve VSA with respect to its capability in analyzing memory alias and thus escalate the ability of security analysts to pinpoint the root cause  of software crashes. In addition, we demonstrate that our proposed neural network outperforms state-of-the-art neural architectures broadly adopted in other binary analysis tasks. Last but not least, we show that DEEPVSA exhibits nearly no false positives when performing alias analysis.",
            "pdf_url": "",
            "keywords": [
                "Value Set Analysis",
                "Postmortem Program Analysis",
                "Memory Alias Identification",
                "Data Flow Analysis",
                "Software Vulnerabilities"
            ]
        },
        "url": "URL#2767760",
        "sema_paperId": "f4f02891ffe70b71c8f5e05dbfbd591611767b33"
    },
    {
        "@score": "1",
        "@id": "2767761",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "224/2332",
                        "text": "Sam Havron"
                    },
                    {
                        "@pid": "175/1690",
                        "text": "Diana Freed"
                    },
                    {
                        "@pid": "03/9962",
                        "text": "Rahul Chatterjee 0001"
                    },
                    {
                        "@pid": "58/4016",
                        "text": "Damon McCoy"
                    },
                    {
                        "@pid": "75/11301",
                        "text": "Nicola Dell"
                    },
                    {
                        "@pid": "26/3399",
                        "text": "Thomas Ristenpart"
                    }
                ]
            },
            "title": "Clinical Computer Security for Victims of Intimate Partner Violence.",
            "venue": "USENIX Security Symposium",
            "pages": "105-122",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HavronF0MDR19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/havron",
            "url": "https://dblp.org/rec/conf/uss/HavronF0MDR19",
            "abstract": "Digital insecurity in the face of targeted, persistent attacks increasingly leaves victims in debilitating or even life-threatening situations. We propose an approach to helping victims, what we call clinical computer security , and explore it in the context of intimate partner violence (IPV). IPV is widespread and abusers exploit technology to track, harass, intimidate, and otherwise harm their victims. We report on the iterative design, re\ufb01nement, and deployment of a consultation service that we created to help IPV victims obtain in-person security help from a trained technologist. To do so we created and tested a range of new technical and non-technical tools that systematize the discovery and investigation of the complicated, multimodal digital attacks seen in IPV. An initial \ufb01eld study with 44 IPV survivors showed how our procedures and tools help victims discover account compromise, exploitable miscon\ufb01gurations, and potential spyware.",
            "keywords": [
                "Clinical Computer Security",
                "Intimate Partner Violence",
                "Digital Insecurity",
                "Victim Support",
                "Technology Exploitation"
            ]
        },
        "url": "URL#2767761",
        "sema_paperId": "df8120eecb03a59ae6f94bd48e4adfaad1a699f0"
    },
    {
        "@score": "1",
        "@id": "2767762",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "227/5266",
                        "text": "Amber van der Heijden"
                    },
                    {
                        "@pid": "37/9766",
                        "text": "Luca Allodi"
                    }
                ]
            },
            "title": "Cognitive Triaging of Phishing Attacks.",
            "venue": "USENIX Security Symposium",
            "pages": "1309-1326",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HeijdenA19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/van-der-heijden",
            "url": "https://dblp.org/rec/conf/uss/HeijdenA19",
            "abstract": "In this paper we employ quantitative measurements of cognitive vulnerability triggers in phishing emails to predict the degree of success of an attack. To achieve this we rely on the cognitive psychology literature and develop an automated and fully quantitative method based on machine learning and econometrics to construct a triaging mechanism built around the cognitive features of a phishing email; we showcase our approach relying on data from the anti-phishing division of a large financial organization in Europe. Our evaluation shows empirically that an effective triaging mechanism for phishing success can be put in place by response teams to effectively prioritize remediation efforts (e.g. domain takedowns), by first acting on those attacks that are more likely to collect high response rates from potential victims.",
            "pdf_url": "",
            "keywords": [
                "Phishing Attacks",
                "Cognitive Vulnerability",
                "Triaging Mechanism",
                "Automated Detection",
                "Response Prioritization"
            ]
        },
        "url": "URL#2767762"
    },
    {
        "@score": "1",
        "@id": "2767763",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "150/5927",
                        "text": "Grant Ho"
                    },
                    {
                        "@pid": "35/10805",
                        "text": "Asaf Cidon"
                    },
                    {
                        "@pid": "55/10443",
                        "text": "Lior Gavish"
                    },
                    {
                        "@pid": "248/1694",
                        "text": "Marco Schweighauser"
                    },
                    {
                        "@pid": "p/VernPaxson",
                        "text": "Vern Paxson"
                    },
                    {
                        "@pid": "s/StefanSavage",
                        "text": "Stefan Savage"
                    },
                    {
                        "@pid": "v/GeoffreyMVoelker",
                        "text": "Geoffrey M. Voelker"
                    },
                    {
                        "@pid": "42/5626",
                        "text": "David A. Wagner 0001"
                    }
                ]
            },
            "title": "Detecting and Characterizing Lateral Phishing at Scale.",
            "venue": "USENIX Security Symposium",
            "pages": "1273-1290",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HoCGSPSV019",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/ho",
            "url": "https://dblp.org/rec/conf/uss/HoCGSPSV019",
            "abstract": "Author(s): Ho, G; Cidon, A; Gavish, L; Schweighauser, M; Paxson, V; Savage, S; Voelker, GM; Wagner, D | Abstract: \u00a9 2019 by The USENIX Association. All rights reserved. We present the first large-scale characterization of lateral phishing attacks, based on a dataset of 113 million employee-sent emails from 92 enterprise organizations. In a lateral phishing attack, adversaries leverage a compromised enterprise account to send phishing emails to other users, benefit-ting from both the implicit trust and the information in the hijacked user's account. We develop a classifier that finds hundreds of real-world lateral phishing emails, while generating under four false positives per every one-million employee-sent emails. Drawing on the attacks we detect, as well as a corpus of user-reported incidents, we quantify the scale of lateral phishing, identify several thematic content and recipient targeting strategies that attackers follow, illuminate two types of sophisticated behaviors that attackers exhibit, and estimate the success rate of these attacks. Collectively, these results expand our mental models of the 'enterprise attacker' and shed light on the current state of enterprise phishing attacks.",
            "keywords": [
                "Lateral Phishing",
                "Enterprise Security",
                "Phishing Attacks",
                "Email Compromise",
                "Trust Exploitation"
            ]
        },
        "url": "URL#2767763",
        "sema_paperId": "eb901db319736a9b4f3a2be86735df393ef569bd"
    },
    {
        "@score": "1",
        "@id": "2767765",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "135/8991",
                        "text": "Sanghyun Hong 0001"
                    },
                    {
                        "@pid": "224/2335",
                        "text": "Pietro Frigo"
                    },
                    {
                        "@pid": "217/2488",
                        "text": "Yigitcan Kaya"
                    },
                    {
                        "@pid": "75/8194",
                        "text": "Cristiano Giuffrida"
                    },
                    {
                        "@pid": "01/4921",
                        "text": "Tudor Dumitras"
                    }
                ]
            },
            "title": "Terminal Brain Damage: Exposing the Graceless Degradation in Deep Neural Networks Under Hardware Fault Attacks.",
            "venue": "USENIX Security Symposium",
            "pages": "497-514",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HongFKGD19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/hong",
            "url": "https://dblp.org/rec/conf/uss/HongFKGD19",
            "abstract": "Deep neural networks (DNNs) have been shown to tolerate \"brain damage\": cumulative changes to the network's parameters (e.g., pruning, numerical perturbations) typically result in a graceful degradation of classification accuracy. However, the limits of this natural resilience are not well understood in the presence of small adversarial changes to the DNN parameters' underlying memory representation, such as bit-flips that may be induced by hardware fault attacks. We study the effects of bitwise corruptions on 19 DNN models\u2014six architectures on three image classification tasks\u2014and we show that most models have at least one parameter that, after a specific bit-flip in their bitwise representation, causes an accuracy loss of over 90%. For large models, we employ simple heuristics to identify the parameters likely to be vulnerable and estimate that 40\u201350% of the parameters in a model might lead to an accuracy drop greater than 10% when individually subjected to such single-bit perturbations. To demonstrate how an adversary could take advantage of this vulnerability, we study the impact of an exemplary hardware fault attack, Rowhammer, on DNNs. Specifically, we show that a Rowhammer-enabled attacker co-located in the same physical machine can inflict significant accuracy drops (up to 99%) even with single bit corruptions and no knowledge of the model. Our results expose the limits of DNNs' resilience against parameter perturbations induced by real-world fault attacks. We conclude by discussing possible mitigations and future research directions towards fault attack-resilient DNNs.",
            "pdf_url": "",
            "keywords": [
                "Hardware Fault Attacks",
                "Bit-flips",
                "Deep Neural Network Vulnerability",
                "Rowhammer Attack",
                "Accuracy Degradation"
            ]
        },
        "url": "URL#2767765"
    },
    {
        "@score": "1",
        "@id": "2767766",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "09/7009",
                        "text": "Bing Huang"
                    },
                    {
                        "@pid": "48/6119",
                        "text": "Alvaro A. C\u00e1rdenas"
                    },
                    {
                        "@pid": "30/351",
                        "text": "Ross Baldick"
                    }
                ]
            },
            "title": "Not Everything is Dark and Gloomy: Power Grid Protections Against IoT Demand Attacks.",
            "venue": "USENIX Security Symposium",
            "pages": "1115-1132",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HuangCB19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/huang",
            "url": "https://dblp.org/rec/conf/uss/HuangCB19",
            "abstract": "Author(s): Huang, B; Cardenas, AA; Baldick, R | Abstract: Devices with high energy consumption such as air conditioners, water heaters, and electric vehicles are increasingly becoming Internet-connected. This new connectivity exposes the control of new electric loads to attackers in what is known as Manipulation of demand via IoT (MadIoT) attacks. In this paper we investigate the impact of MadIoT attacks on power transmission grids. Our analysis leverages a novel cascading outage analysis tool that focuses on how the protection equipment in the power grid as well as how protection algorithms react to cascading events that can lead to a power blackout. In particular, we apply our tool to a large North American regional transmission interconnection system consisting of more than 5,000 buses, and study how MadIoT attacks can affect this power system. To help assess the effects of such cyber attacks, we develop numerical experiments and define new and stronger types of IoT demand attacks to study cascading failures on transmission lines and their effects on the system frequency. Our results show that MadIoT attacks can cause a partition of the bulk power system, and can also result in controlled load shedding, but the protections embedded in the operation of the transmission grid can allow the system to withstand a large variety of MadIoT attacks and can avoid a system blackout.",
            "keywords": [
                "Power Grid Protection",
                "IoT Demand Attacks",
                "Cascading Outages",
                "MadIoT Attacks",
                "System Blackout Prevention"
            ]
        },
        "url": "URL#2767766",
        "sema_paperId": "12c2421a7a0a45e2cc0bdc5e834e99127a25fea6"
    },
    {
        "@score": "1",
        "@id": "2767767",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "23/7549",
                        "text": "Saad Islam"
                    },
                    {
                        "@pid": "241/6242",
                        "text": "Ahmad Moghimi"
                    },
                    {
                        "@pid": "237/9564",
                        "text": "Ida Bruhns"
                    },
                    {
                        "@pid": "197/5182",
                        "text": "Moritz Krebbel"
                    },
                    {
                        "@pid": "165/2661",
                        "text": "Berk G\u00fclmezoglu"
                    },
                    {
                        "@pid": "72/817",
                        "text": "Thomas Eisenbarth 0001"
                    },
                    {
                        "@pid": "91/465",
                        "text": "Berk Sunar"
                    }
                ]
            },
            "title": "SPOILER: Speculative Load Hazards Boost Rowhammer and Cache Attacks.",
            "venue": "USENIX Security Symposium",
            "pages": "621-637",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/IslamMBKG0S19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/islam",
            "url": "https://dblp.org/rec/conf/uss/IslamMBKG0S19",
            "abstract": "Modern microarchitectures incorporate optimization techniques such as speculative loads and store forwarding to improve the memory bottleneck. The processor executes the load speculatively before the stores, and forwards the data of a preceding store to the load if there is a potential dependency. This enhances performance since the load does not have to wait for preceding stores to complete. However, the dependency prediction relies on partial address information, which may lead to false dependencies and stall hazards. \nIn this work, we are the first to show that the dependency resolution logic that serves the speculative load can be exploited to gain information about the physical page mappings. Microarchitectural side-channel attacks such as Rowhammer and cache attacks like Prime+Probe rely on the reverse engineering of the virtual-to-physical address mapping. We propose the SPOILER attack which exploits this leakage to speed up this reverse engineering by a factor of 256. Then, we show how this can improve the Prime+Probe attack by a 4096 factor speed up of the eviction set search, even from sandboxed environments like JavaScript. Finally, we improve the Rowhammer attack by showing how SPOILER helps to conduct DRAM row conflicts deterministically with up to 100% chance, and by demonstrating a double-sided Rowhammer attack with normal user's privilege. The later is due to the possibility of detecting contiguous memory pages using the SPOILER leakage.",
            "keywords": [
                "Microarchitectural Attacks",
                "Speculative Execution",
                "Rowhammer",
                "Cache Attacks",
                "Physical Page Mapping"
            ]
        },
        "url": "URL#2767767",
        "sema_paperId": "ef22e8c45ae91405bfa72ea77dfff0cfd5cb9c5e"
    },
    {
        "@score": "1",
        "@id": "2767768",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "14/7561",
                        "text": "Rob Jansen"
                    },
                    {
                        "@pid": "162/9041",
                        "text": "Tavish Vaidya"
                    },
                    {
                        "@pid": "57/3752",
                        "text": "Micah Sherr"
                    }
                ]
            },
            "title": "Point Break: A Study of Bandwidth Denial-of-Service Attacks against Tor.",
            "venue": "USENIX Security Symposium",
            "pages": "1823-1840",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/JansenVS19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/jansen",
            "url": "https://dblp.org/rec/conf/uss/JansenVS19",
            "abstract": "As the Tor network has grown in popularity and importance as a tool for privacy-preserving online communication, it has increasingly become a target for disruption, censorship, and attack. A large body of existing work examines Tor's susceptibility to attacks that attempt to block Tor users' access to information (e.g., via traffic filtering), identify Tor users' communication content (e.g., via traffic fingerprinting), and de-anonymize Tor users (e.g., via traffic correlation). This paper focuses on the relatively understudied threat of denialof-service (DoS) attacks against Tor, and specifically, DoS attacks that intelligently utilize bandwidth as a means to significantly degrade Tor network performance and reliability. \n \nWe demonstrate the feasibility of several bandwidth DoS attacks through live-network experimentation and highfidelity simulation while quantifying the cost of each attack and its effect on Tor performance. First, we explore an attack against Tor's most commonly used default bridges (for censorship circumvention) and estimate that flooding those that are operational would cost $17K/mo. and could reduce client throughput by 44% while more than doubling bridge maintenance costs. Second, we explore attacks against the TorFlow bandwidth measurement system and estimate that a constant attack against all TorFlow scanners would cost $2.8K/mo. and reduce the median client download rate by 80%. Third, we explore how an adversary could use Tor to congest itself and estimate that such a congestion attack against all Tor relays would cost $1.6K/mo. and increase the median client download time by 47%. Finally, we analyze the effects of Sybil DoS and deanonymization attacks that have costs comparable to those of our attacks.",
            "keywords": [
                "Tor Network",
                "Denial-of-Service Attacks",
                "Bandwidth Attacks",
                "Censorship Circumvention",
                "Network Performance Degradation"
            ]
        },
        "url": "URL#2767768",
        "sema_paperId": "7f43de5d43da299894ea8652c0eeda526d81ea8a"
    },
    {
        "@score": "1",
        "@id": "2767769",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "165/8210",
                        "text": "Bargav Jayaraman"
                    },
                    {
                        "@pid": "e/DavidEvans",
                        "text": "David Evans 0001"
                    }
                ]
            },
            "title": "Evaluating Differentially Private Machine Learning in Practice.",
            "venue": "USENIX Security Symposium",
            "pages": "1895-1912",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Jayaraman019",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/jayaraman",
            "url": "https://dblp.org/rec/conf/uss/Jayaraman019",
            "abstract": "Differential privacy is a strong notion for privacy that can be used to prove formal guarantees, in terms of a privacy budget, $\\epsilon$, about how much information is leaked by a mechanism. However, implementations of privacy-preserving machine learning often select large values of $\\epsilon$ in order to get acceptable utility of the model, with little understanding of the impact of such choices on meaningful privacy. Moreover, in scenarios where iterative learning procedures are used, differential privacy variants that offer tighter analyses are used which appear to reduce the needed privacy budget but present poorly understood trade-offs between privacy and utility. In this paper, we quantify the impact of these choices on privacy in experiments with logistic regression and neural network models. Our main finding is that there is a huge gap between the upper bounds on privacy loss that can be guaranteed, even with advanced mechanisms, and the effective privacy loss that can be measured using current inference attacks. Current mechanisms for differentially private machine learning rarely offer acceptable utility-privacy trade-offs with guarantees for complex learning tasks: settings that provide limited accuracy loss provide meaningless privacy guarantees, and settings that provide strong privacy guarantees result in useless models. Code for the experiments can be found here: this https URL",
            "keywords": [
                "Differential Privacy",
                "Privacy Budget",
                "Utility-Privacy Trade-offs",
                "Inference Attacks",
                "Privacy Loss Measurement"
            ]
        },
        "url": "URL#2767769",
        "sema_paperId": "8f8542a6aa8c76e8a4441d1ca722e230aa5d6c9e"
    },
    {
        "@score": "1",
        "@id": "2767770",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "40/2431-1",
                        "text": "Jinho Jung 0001"
                    },
                    {
                        "@pid": "70/2543-4",
                        "text": "Hong Hu 0004"
                    },
                    {
                        "@pid": "248/1689",
                        "text": "David Solodukhin"
                    },
                    {
                        "@pid": "248/1652",
                        "text": "Daniel Pagan"
                    },
                    {
                        "@pid": "31/9698",
                        "text": "Kyu Hyung Lee"
                    },
                    {
                        "@pid": "38/8882",
                        "text": "Taesoo Kim"
                    }
                ]
            },
            "title": "Fuzzification: Anti-Fuzzing Techniques.",
            "venue": "USENIX Security Symposium",
            "pages": "1913-1930",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/JungHSPLK19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/jung",
            "url": "https://dblp.org/rec/conf/uss/JungHSPLK19",
            "abstract": "Fuzzing is a software testing technique that quickly and automatically explores the input space of a program without knowing its internals. Therefore, developers commonly use fuzzing as part of test integration throughout the software development process. Unfortunately, it also means that such a blackbox and the automatic natures of fuzzing are appealing to adversaries who are looking for zero-day vulnerabilities. To solve this problem, we propose a new mitigation approach, called FUZZIFICATION, that helps developers protect the released, binary-only software from attackers who are capable of applying state-of-the-art fuzzing techniques. Given a performance budget, this approach aims to hinder the fuzzing process from adversaries as much as possible. We propose three FUZZIFICATION techniques: 1) SpeedBump, which amplifies the slowdown in normal executions by hundreds of times to the fuzzed execution, 2) BranchTrap, interfering with feedback logic by hiding paths and polluting coverage maps, and 3) AntiHybrid, hindering taint-analysis and symbolic execution. Each technique is designed with best-effort, defensive measures that attempt to hinder adversaries from bypassing FUZZIFICATION. Our evaluation on popular fuzzers and real-world applications shows that FUZZIFICATION effectively reduces the number of discovered paths by 70.3% and decreases the number of identified crashes by 93.0% from real-world binaries, and decreases the number of detected bugs by 67.5% from LAVA-M dataset while under user-specified overheads for common workloads. We discuss the robustness of FUZZIFICATION techniques against adversarial analysis techniques. We opensource our FUZZIFICATION system to foster future research.",
            "keywords": [
                "Fuzzing Techniques",
                "Software Testing",
                "Vulnerability Mitigation",
                "Binary Protection",
                "Adversarial Analysis"
            ]
        },
        "url": "URL#2767770",
        "sema_paperId": "da77afb97ed313c1815530f2a077cb0b2003c68e"
    },
    {
        "@score": "1",
        "@id": "2767771",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "197/1637",
                        "text": "Daniel Kales"
                    },
                    {
                        "@pid": "39/16",
                        "text": "Christian Rechberger"
                    },
                    {
                        "@pid": "06/3872-3",
                        "text": "Thomas Schneider 0003"
                    },
                    {
                        "@pid": "164/2769",
                        "text": "Matthias Senker"
                    },
                    {
                        "@pid": "157/4432",
                        "text": "Christian Weinert"
                    }
                ]
            },
            "title": "Mobile Private Contact Discovery at Scale.",
            "venue": "USENIX Security Symposium",
            "pages": "1447-1464",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KalesR0SW19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/kales",
            "url": "https://dblp.org/rec/conf/uss/KalesR0SW19",
            "abstract": "Mobile messengers like WhatsApp perform contact discovery by uploading the user's entire address book to the service provider. This allows the service provider to determine which of the user's contacts are registered to the messaging service. However, such a procedure poses significant privacy risks and legal challenges. As we find, even messengers with privacy in mind currently do not deploy proper mechanisms to perform contact discovery privately.\nThe most promising approaches addressing this problem revolve around private set intersection (PSI) protocols. Unfortunately, even in a weak security model where clients are assumed to follow the protocol honestly, previous protocols and implementations turned out to be far from practical when used at scale. This is due to their high computation and/or communication complexity as well as lacking optimization for mobile devices. In our work, we remove most obstacles for large-scale global deployment by significantly improving two promising protocols by Kiss et al. (PoPETS'17) while also allowing for malicious clients.\nConcretely, we present novel precomputation techniques for correlated oblivious transfers (reducing the online communication by factor 2x), Cuckoo filter compression (with a compression ratio of 70%), as well as 4.3x smaller Cuckoo filter updates. In a protocol performing oblivious PRF evaluations via garbled circuits, we replace AES as the evaluated PRF with a variant of LowMC (Albrecht et al., EUROCRYPT'15) for which we determine optimal parameters, thereby reducing the communication by factor 8.2x. Furthermore, we implement both protocols with security against malicious clients in C/C++ and utilize the ARM Cryptography Extensions available in most recent smartphones. Compared to previous smartphone implementations, this yields a performance improvement of factor 1000x for circuit evaluations. The online phase of our fastest protocol takes only 2.92s measured on a real WiFi connection (6.53s on LTE) to check 1024 client contacts against a large-scale database with 228 entries. As a proof-of-concept, we integrate our protocols in the client application of the open-source messenger Signal.",
            "pdf_url": "",
            "keywords": [
                "Mobile Messaging Privacy",
                "Contact Discovery",
                "Private Set Intersection",
                "Oblivious Transfers",
                "Cuckoo Filter Compression"
            ]
        },
        "url": "URL#2767771"
    },
    {
        "@score": "1",
        "@id": "2767773",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "198/6813",
                        "text": "Mustakimur Khandaker"
                    },
                    {
                        "@pid": "31/2872",
                        "text": "Wenqing Liu"
                    },
                    {
                        "@pid": "247/7555",
                        "text": "Abu Naser"
                    },
                    {
                        "@pid": "95/6543-4",
                        "text": "Zhi Wang 0004"
                    },
                    {
                        "@pid": "12/1198-3",
                        "text": "Jie Yang 0003"
                    }
                ]
            },
            "title": "Origin-sensitive Control Flow Integrity.",
            "venue": "USENIX Security Symposium",
            "pages": "195-211",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KhandakerLN0Y19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/khandaker",
            "url": "https://dblp.org/rec/conf/uss/KhandakerLN0Y19",
            "abstract": "CFI is an e\ufb00ective, generic defense against control-\ufb02ow hijacking attacks, especially for C/C++ programs. However, most previous CFI systems have poor security as demonstrated by their large equivalence class (EC) sizes. An EC is a set of targets that are indistinguishable from each other in the CFI policy; i.e., an attacker can \u201cbend\u201d the control \ufb02ow within an EC without being detected. As such, the large ECs denote the weakest link in a CFI system and should be broken down in order to improve security. An approach to improve the security of CFI is to use contextual information, such as the last branches taken, to re\ufb01ne the CFI policy, the so-called context-sensitive CFI. However, contexts based on the recent execution history are often inadequate in breaking down large ECs due to the limited number of incoming execution paths to an indirect control transfer instruction (ICT). 1 In this paper, we propose a new context for CFI, origin sensitivity, that can e\ufb00ectively break down large ECs and reduce the average and largest EC size. Origin-sensitive CFI (OS-CFI) takes the origin of the code pointer called by an ICT as the context and constrains the targets of the ICT with this context. It supports both C-style indirect calls and C++ virtual calls. Additionally, we leverage common hardware features in the commodity Intel processors (MPX and TSX) to improve both security and performance of OS-CFI. Our evaluation shows that OS-CFI can substantially reduce the largest and average EC sizes (by 98% in some cases) and has strong performance \u2013 7 . 6% overhead on average for all C/C++ benchmarks of SPEC",
            "keywords": [
                "Control Flow Integrity",
                "Origin-Sensitive CFI",
                "Equivalence Class Reduction",
                "Indirect Control Transfer",
                "Context-Sensitive Security"
            ]
        },
        "url": "URL#2767773",
        "sema_paperId": "3181798f71ba2b2694b1b66dd9e479909cafe5ff"
    },
    {
        "@score": "1",
        "@id": "2767774",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "157/5259",
                        "text": "Taegyu Kim"
                    },
                    {
                        "@pid": "122/2010",
                        "text": "Chung Hwan Kim"
                    },
                    {
                        "@pid": "27/5932",
                        "text": "Junghwan Rhee"
                    },
                    {
                        "@pid": "61/7710-2",
                        "text": "Fan Fei 0002"
                    },
                    {
                        "@pid": "203/5343",
                        "text": "Zhan Tu"
                    },
                    {
                        "@pid": "248/1730",
                        "text": "Gregory Walkup"
                    },
                    {
                        "@pid": "95/3760-1",
                        "text": "Xiangyu Zhang 0001"
                    },
                    {
                        "@pid": "33/2032",
                        "text": "Xinyan Deng"
                    },
                    {
                        "@pid": "59/5539",
                        "text": "Dongyan Xu"
                    }
                ]
            },
            "title": "RVFuzzer: Finding Input Validation Bugs in Robotic Vehicles through Control-Guided Testing.",
            "venue": "USENIX Security Symposium",
            "pages": "425-442",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KimKRFTW0DX19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/kim",
            "url": "https://dblp.org/rec/conf/uss/KimKRFTW0DX19",
            "abstract": "Robotic vehicles (RVs) are being adopted in a variety of application domains. Despite their increasing deployment, many security issues with RVs have emerged, limiting their wider deployment. In this paper, we address a new type of vulnerability in RV control programs, called input validation bugs, which involve missing or incorrect validation checks on control parameter inputs. Such bugs can be exploited to cause physical disruptions to RVs which may result in mission failures and vehicle damages or crashes. Furthermore, attacks exploiting such bugs have a very small footprint: just one innocent-looking ground control command, requiring no code injection, control flow hijacking or sensor spoofing. To prevent such attacks, we propose RVFUZZER, a vetting system for finding input validation bugs in RV control programs through control-guided input mutation. The key insight behind RVFUZZER is that the RV control model, which is the generic theoretical model for a broad range of RVs, provides helpful semantic guidance to improve bug-discovery accuracy and efficiency. Specifically, RVFUZZER involves a control instability detector that detects control program misbehavior, by observing (simulated) physical operations of the RV based on the control model. In addition, RVFUZZER steers the input generation for finding input validation bugs more efficiently, by leveraging results from the control instability detector as feedback. In our evaluation of RVFUZZER on two popular RV control programs, a total of 89 input validation bugs are found, with 87 of them being zero-day bugs.",
            "keywords": [
                "Robotic Vehicles",
                "Input Validation Bugs",
                "Control-Guided Testing",
                "Control Program Vulnerabilities",
                "Control Instability Detection"
            ]
        },
        "url": "URL#2767774",
        "sema_paperId": "716997e084d6011fe7dc225af5bea7d3035beeec"
    },
    {
        "@score": "1",
        "@id": "2767775",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "98/3396",
                        "text": "Amit Klein 0001"
                    },
                    {
                        "@pid": "31/1735",
                        "text": "Benny Pinkas"
                    }
                ]
            },
            "title": "From IP ID to Device ID and KASLR Bypass.",
            "venue": "USENIX Security Symposium",
            "pages": "1063-1080",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KleinP19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/klein",
            "url": "https://dblp.org/rec/conf/uss/KleinP19",
            "abstract": "IP headers include a 16-bit ID field. Our work examines the generation of this field in Windows (versions 8 and higher), Linux and Android, and shows that the IP ID field enables remote servers to assign a unique ID to each device and thus be able to identify subsequent transmissions sent from that device. This identification works across all browsers and over network changes. In modern Linux and Android versions, this field leaks a kernel address, thus we also break KASLR. \nOur work includes reverse-engineering of the Windows IP ID generation code, and a cryptanalysis of this code and of the Linux kernel IP ID generation code. It provides practical techniques to partially extract the key used by each of these algorithms, overcoming different implementation issues, and observing that this key can identify individual devices. We deployed a demo (for Windows) showing that key extraction and machine fingerprinting works in the wild, and tested it from networks around the world.",
            "keywords": [
                "IP ID Generation",
                "Device Fingerprinting",
                "KASLR Bypass",
                "Kernel Address Leakage",
                "Remote Identification"
            ]
        },
        "url": "URL#2767775",
        "sema_paperId": "be486d6fef38e3cffd7a7fc92248aac5573069bf"
    },
    {
        "@score": "1",
        "@id": "2767776",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "183/6700",
                        "text": "Sekar Kulandaivel"
                    },
                    {
                        "@pid": "248/1687",
                        "text": "Tushar Goyal"
                    },
                    {
                        "@pid": "192/7526",
                        "text": "Arnav Kumar Agrawal"
                    },
                    {
                        "@pid": "45/4044",
                        "text": "Vyas Sekar"
                    }
                ]
            },
            "title": "CANvas: Fast and Inexpensive Automotive Network Mapping.",
            "venue": "USENIX Security Symposium",
            "pages": "389-405",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KulandaivelGAS19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/kulandaivel",
            "url": "https://dblp.org/rec/conf/uss/KulandaivelGAS19",
            "abstract": "Modern vehicles contain tens of Electronic Control Units (ECUs), several of which communicate over the Controller Area Network (CAN) protocol. As such, in-vehicle networks have become a prime target for automotive network attacks. To understand the security of these networks, we argue that we need tools analogous to network mappers for traditional networks that provide an in-depth understanding of a network\u2019s structure. To this end, our goal is to develop an automotive network mapping tool that assists in identifying a vehicle\u2019s ECUs and their communication with each other. A significant challenge in designing this tool is the broadcast nature of the CAN protocol, as network messages contain no information about their sender or recipients. To address this challenge, we design and implement CANvas, an automotive network mapper that identifies transmitting ECUs with a pairwise clock offset tracking algorithm and identifies receiving ECUs with a forced ECU isolation technique. CANvas generates network maps in under an hour that identify a previously unknown ECU in a 2009 Toyota Prius and identify lenient message filters in a 2017 Ford Focus.",
            "keywords": [
                "Automotive Network Mapping",
                "Controller Area Network (CAN)",
                "Electronic Control Units (ECUs)",
                "Network Security Assessment",
                "Message Filtering"
            ]
        },
        "url": "URL#2767776",
        "sema_paperId": "61fd3a037b03baacdf81ee7a4d08d5703cd93191"
    },
    {
        "@score": "1",
        "@id": "2767777",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "173/8201",
                        "text": "Sam Kumar"
                    },
                    {
                        "@pid": "241/9318",
                        "text": "Yuncong Hu"
                    },
                    {
                        "@pid": "161/6189",
                        "text": "Michael P. Andersen"
                    },
                    {
                        "@pid": "91/275",
                        "text": "Raluca Ada Popa"
                    },
                    {
                        "@pid": "c/DavidECuller",
                        "text": "David E. Culler"
                    }
                ]
            },
            "title": "JEDI: Many-to-Many End-to-End Encryption and Key Delegation for IoT.",
            "venue": "USENIX Security Symposium",
            "pages": "1519-1536",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KumarHAPC19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/kumar-sam",
            "url": "https://dblp.org/rec/conf/uss/KumarHAPC19",
            "abstract": "As the Internet of Things (IoT) emerges over the next decade, developing secure communication for IoT devices is of paramount importance. Achieving end-to-end encryption for large-scale IoT systems, like smart buildings or smart cities, is challenging because multiple principals typically interact indirectly via intermediaries, meaning that the recipient of a message is not known in advance. This paper proposes JEDI (Joining Encryption and Delegation for IoT), a many-to-many end-to-end encryption protocol for IoT. JEDI encrypts and signs messages end-to-end, while conforming to the decoupled communication model typical of IoT systems. JEDI's keys support expiry and fine-grained access to data, common in IoT. Furthermore, JEDI allows principals to delegate their keys, restricted in expiry or scope, to other principals, thereby granting access to data and managing access control in a scalable, distributed way. Through careful protocol design and implementation, JEDI can run across the spectrum of IoT devices, including ultra low-power deeply embedded sensors severely constrained in CPU, memory, and energy consumption. We apply JEDI to an existing IoT messaging system and demonstrate that its overhead is modest.",
            "keywords": [
                "IoT Security",
                "End-to-End Encryption",
                "Key Delegation",
                "Decoupled Communication",
                "Many-to-Many Protocol"
            ]
        },
        "url": "URL#2767777",
        "sema_paperId": "b949458c0db1d3d362929e603142521ea774795d"
    },
    {
        "@score": "1",
        "@id": "2767778",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "66/3984-6",
                        "text": "Deepak Kumar 0006"
                    },
                    {
                        "@pid": "188/9108",
                        "text": "Kelly Shen"
                    },
                    {
                        "@pid": "248/1600",
                        "text": "Benton Case"
                    },
                    {
                        "@pid": "248/1639",
                        "text": "Deepali Garg"
                    },
                    {
                        "@pid": "248/1631",
                        "text": "Galina Alperovich"
                    },
                    {
                        "@pid": "77/4589",
                        "text": "Dmitry Kuznetsov"
                    },
                    {
                        "@pid": "33/3678",
                        "text": "Rajarshi Gupta"
                    },
                    {
                        "@pid": "143/5673",
                        "text": "Zakir Durumeric"
                    }
                ]
            },
            "title": "All Things Considered: An Analysis of IoT Devices on Home Networks.",
            "venue": "USENIX Security Symposium",
            "pages": "1169-1185",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KumarSCGAKGD19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/kumar-deepak",
            "url": "https://dblp.org/rec/conf/uss/KumarSCGAKGD19",
            "abstract": "In this paper, we provide the first large-scale empirical analysis of IoT devices in real-world homes by leveraging data collected from user-initiated network scans of 83M devices in 16M households. We find that IoT adoption is widespread: on several continents, more than half of households already have at least one IoT device. Device types and manufacturer popularity vary dramatically across regions. For example, while nearly half of North American homes have an Internet-connected television or streaming device, less than three percent do in South Asia where the majority of devices are surveillance cameras. We investigate the security posture of devices, detailing their open services, weak default credentials, and vulnerability to known attacks. Device security similarly varies geographically, even for specific manufacturers. For example, while less than 17% of TP-Link home routers in North America have guessable passwords, nearly half do in Eastern Europe and Central Asia. We argue that IoT devices are here, but for most homes, the types of devices adopted are not the ones actively discussed. We hope that by shedding light on this complex ecosystem, we help the security community develop solutions that are applicable to today\u2019s homes.",
            "keywords": [
                "IoT Device Adoption",
                "Home Networks",
                "Device Security",
                "Geographical Variability",
                "Vulnerability Assessment"
            ]
        },
        "url": "URL#2767778",
        "sema_paperId": "0b9f3d3a921dea4cd869208dc2a2aff6b48200c3"
    },
    {
        "@score": "1",
        "@id": "2767779",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "130/9723",
                        "text": "Donghyun Kwon"
                    },
                    {
                        "@pid": "187/8338",
                        "text": "Jangseop Shin"
                    },
                    {
                        "@pid": "222/5178",
                        "text": "Giyeol Kim"
                    },
                    {
                        "@pid": "45/7986",
                        "text": "Byoungyoung Lee"
                    },
                    {
                        "@pid": "130/9710",
                        "text": "Yeongpil Cho"
                    },
                    {
                        "@pid": "65/3751",
                        "text": "Yunheung Paek"
                    }
                ]
            },
            "title": "uXOM: Efficient eXecute-Only Memory on ARM Cortex-M.",
            "venue": "USENIX Security Symposium",
            "pages": "231-247",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KwonSKLCP19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/kwon",
            "url": "https://dblp.org/rec/conf/uss/KwonSKLCP19",
            "abstract": "Code disclosure attacks are one of the major threats to a computer system, considering that code often contains security sensitive information, such as intellectual properties (e.g., secret algorithm), sensitive data (e.g., cryptographic keys) and the gadgets for launching code reuse attacks. To stymie this class of attacks, security researchers have devised a strong memory protection mechanism, called eXecute-OnlyMemory (XOM), that defines special memory regions where instruction execution is permitted but data reads and writes are prohibited. Reflecting the value of XOM, many recent high-end processors have added support for XOM in their hardware. Unfortunately, however, low-end embedded processors have yet to provide hardware support for XOM. In this paper, we propose a novel technique, named uXOM, that realizes XOM in a way that is secure and highly optimized to work on Cortex-M, which is a prominent processor series used in low-end embedded devices. uXOM achieves its security and efficiency by using special architectural features in Cortex-M: unprivileged memory instructions and an MPU. We present several challenges in making XOM nonbypassable under strong attackers and introduce our code analysis and instrumentation to solve these challenges. Our evaluation reveals that uXOM successfully realizes XOM in Cortex-M processor with much better efficiency in terms of execution time, code size and energy consumption compared to a software-only XOM implementation for Cortex-M.",
            "keywords": [
                "eXecute-Only Memory (XOM)",
                "Cortex-M",
                "Embedded Systems Security",
                "Code Disclosure Attacks",
                "Memory Protection Mechanism"
            ]
        },
        "url": "URL#2767779",
        "sema_paperId": "f44fed9b97ef14fc72b5732a12209b9a2131b04a"
    },
    {
        "@score": "1",
        "@id": "2767780",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "153/5787",
                        "text": "Yeonjoon Lee"
                    },
                    {
                        "@pid": "60/8494",
                        "text": "Xueqiang Wang"
                    },
                    {
                        "@pid": "248/1609",
                        "text": "Kwangwuk Lee"
                    },
                    {
                        "@pid": "129/1113",
                        "text": "Xiaojing Liao"
                    },
                    {
                        "@pid": "06/6268",
                        "text": "XiaoFeng Wang 0001"
                    },
                    {
                        "@pid": "140/7353",
                        "text": "Tongxin Li"
                    },
                    {
                        "@pid": "192/2270",
                        "text": "Xianghang Mi"
                    }
                ]
            },
            "title": "Understanding iOS-based Crowdturfing Through Hidden UI Analysis.",
            "venue": "USENIX Security Symposium",
            "pages": "765-781",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LeeWLL0LM19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/lee",
            "url": "https://dblp.org/rec/conf/uss/LeeWLL0LM19",
            "abstract": "A new type of malicious crowdsourcing (a.k.a., crowdtur\ufb01ng) clients, mobile apps with hidden crowdtur\ufb01ng user interface (UI), is increasingly being utilized by miscreants to coordinate crowdtur\ufb01ng workers and publish mobile-based crowdtur\ufb01ng tasks (e.g., app ranking manipulation) even on the strictly controlled Apple App Store. These apps hide their crowdtur\ufb01ng content behind innocent-looking UIs to bypass app vetting and in\ufb01ltrate the app store. To the best of our knowledge, little has been done so far to understand this new abusive service, in terms of its scope, impact and techniques, not to mention any effort to identify such stealthy crowdtur\ufb01ng apps on a large scale, particularly on the Apple platform. In this paper, we report the \ufb01rst measurement study on iOS apps with hidden crowdtur\ufb01ng UIs. Our \ufb01ndings bring to light the mobile-based crowdtur\ufb01ng ecosystem (e.g., app promotion for worker recruitment, campaign identi\ufb01cation) and the un-derground developer\u2019s tricks (e.g., scheme, logic bomb) for evading app vetting.",
            "keywords": [
                "Crowdturfing",
                "iOS Apps",
                "Hidden User Interface",
                "Malicious Crowdsourcing",
                "App Store Manipulation"
            ]
        },
        "url": "URL#2767780",
        "sema_paperId": "3a9d73dd1d3f0f8ed51efbcab58d9d2086cffb18"
    },
    {
        "@score": "1",
        "@id": "2767781",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "181/1557",
                        "text": "Hemi Leibowitz"
                    },
                    {
                        "@pid": "178/2737",
                        "text": "Ania M. Piotrowska"
                    },
                    {
                        "@pid": "11/1148",
                        "text": "George Danezis"
                    },
                    {
                        "@pid": "62/3150",
                        "text": "Amir Herzberg"
                    }
                ]
            },
            "title": "No Right to Remain Silent: Isolating Malicious Mixes.",
            "venue": "USENIX Security Symposium",
            "pages": "1841-1858",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LeibowitzPDH19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/leibowitz",
            "url": "https://dblp.org/rec/conf/uss/LeibowitzPDH19",
            "abstract": "Mix networks are a key technology to achieve network anonymity and private messaging, voting and database lookups. However, simple mix network designs are vulnerable to malicious mixes, which may drop or delay packets to facilitate traffic analysis attacks. Mix networks with provable robustness address this drawback through complex and expensive proofs of correct shuffling but come at a great cost and make limiting or unrealistic systems assumptions.  We present Miranda, an efficient mix-net design, which mitigates active attacks by malicious mixes.  Miranda uses both the detection of corrupt mixes, as well as detection of faults related to a pair of mixes, without detection of the faulty one among the two.  Each active attack -- including dropping packets -- leads to reduced connectivity for corrupt mixes and reduces their ability to attack, and, eventually, to detection of corrupt mixes. We show, through experiments, the effectiveness of Miranda, by demonstrating how malicious mixes are detected and that attacks are neutralized early.",
            "pdf_url": "",
            "keywords": [
                "Mix Networks",
                "Network Anonymity",
                "Malicious Mixes",
                "Active Attacks",
                "Packet Dropping Detection"
            ]
        },
        "url": "URL#2767781"
    },
    {
        "@score": "1",
        "@id": "2767782",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "224/2345",
                        "text": "Vector Guo Li"
                    },
                    {
                        "@pid": "160/6485",
                        "text": "Matthew Dunn"
                    },
                    {
                        "@pid": "61/1749",
                        "text": "Paul Pearce"
                    },
                    {
                        "@pid": "58/4016",
                        "text": "Damon McCoy"
                    },
                    {
                        "@pid": "v/GeoffreyMVoelker",
                        "text": "Geoffrey M. Voelker"
                    },
                    {
                        "@pid": "s/StefanSavage",
                        "text": "Stefan Savage"
                    }
                ]
            },
            "title": "Reading the Tea leaves: A Comparative Analysis of Threat Intelligence.",
            "venue": "USENIX Security Symposium",
            "pages": "851-867",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiDPMVS19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/li",
            "url": "https://dblp.org/rec/conf/uss/LiDPMVS19",
            "abstract": "The term \u201cthreat intelligence\u201d has swiftly become a staple buzzword in the computer security industry. The entirely reasonable premise is that, by compiling up-to-date information about known threats (i.e., IP addresses, domain names, file hashes, etc.), recipients of such information may be able to better defend their systems from future attacks. Thus, today a wide array of public and commercial sources distribute threat intelligence data feeds to support this purpose. However, our understanding of this data, its characterization and the extent to which it can meaningfully support its intended uses, is still quite limited. In this paper, we address these gaps by formally defining a set of metrics for characterizing threat intelligence data feeds and using these measures to systematically characterize a broad range of public and commercial sources. Further, we ground our quantitative assessments using external measurements to qualitatively investigate issues of coverage and accuracy. Unfortunately, our measurement results suggest that there are significant limitations and challenges in using existing threat intelligence data for its purported goals.",
            "keywords": [
                "Threat Intelligence",
                "Data Feeds",
                "Threat Characterization",
                "Coverage and Accuracy",
                "Measurement Limitations"
            ]
        },
        "url": "URL#2767782",
        "sema_paperId": "c71408ff0493358a48e7b5fd24b794eb1fd07d50"
    },
    {
        "@score": "1",
        "@id": "2767783",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "184/8320",
                        "text": "Shih-Wei Li"
                    },
                    {
                        "@pid": "237/7555",
                        "text": "John S. Koh"
                    },
                    {
                        "@pid": "n/JasonNieh",
                        "text": "Jason Nieh"
                    }
                ]
            },
            "title": "Protecting Cloud Virtual Machines from Hypervisor and Host Operating System Exploits.",
            "venue": "USENIX Security Symposium",
            "pages": "1357-1374",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiKN19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/li-shih-wei",
            "url": "https://dblp.org/rec/conf/uss/LiKN19",
            "abstract": "Hypervisors are widely deployed by cloud computing providers to support virtual machines, but their growing complexity poses a security risk as large codebases contain many vulnerabilities. We have created HypSec, a new hypervisor design for retrofitting an existing commodity hypervisor using microkernel principles to reduce its trusted computing base while protecting the confidentiality and integrity of virtual machines. HypSec partitions the hypervisor into an untrusted host that performs most complex hypervisor functionality without access to virtual machine data, and a trusted core that provides access control to virtual machine data and performs basic CPU and memory virtualization. Hardware virtualization support is used to isolate and protect the trusted core and execute it at a higher privilege level so it can mediate virtual machine exceptions and protect VM data in CPU and memory. HypSec takes an end-to-end approach to securing I/O to simplify its design, with applications increasingly using secure network connections in the cloud. We have used HypSec to retrofit KVM, showing how our approach can support a widely-used full-featured hypervisor integrated with a commodity operating system. The implementation has a trusted computing base of only a few thousand lines of code, many orders of magnitude less than KVM. We show that HypSec protects the confidentiality and integrity of virtual machines running unmodified guest operating systems while only incurring modest performance overhead for real application workloads.",
            "keywords": [
                "Cloud Computing Security",
                "Hypervisor Design",
                "Trusted Computing Base",
                "Virtual Machine Protection",
                "KVM Retrofitting"
            ]
        },
        "url": "URL#2767783",
        "sema_paperId": "6c5c5be93b58e417220e0841ed5da62d1e8c7b5b"
    },
    {
        "@score": "1",
        "@id": "2767784",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "157/4437",
                        "text": "Mengyuan Li"
                    },
                    {
                        "@pid": "77/3503",
                        "text": "Yinqian Zhang"
                    },
                    {
                        "@pid": "49/4102-1",
                        "text": "Zhiqiang Lin 0001"
                    },
                    {
                        "@pid": "11/2624",
                        "text": "Yan Solihin"
                    }
                ]
            },
            "title": "Exploiting Unprotected I/O Operations in AMD&apos;s Secure Encrypted Virtualization.",
            "venue": "USENIX Security Symposium",
            "pages": "1257-1272",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiZLS19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/li-mengyuan",
            "url": "https://dblp.org/rec/conf/uss/LiZLS19",
            "abstract": "AMD\u2019s Secure Encrypted Virtualization (SEV) is an emerging technology to secure virtual machines (VM) even in the presence of malicious hypervisors. However, the lack of trust in the privileged software also introduces an assortment of new attack vectors to SEV-enabled VMs that were mostly unexplored in the literature. This paper studies the insecurity of SEV from the perspective of the unprotected I/O operations in the SEV-enabled VMs. The results are alerting: not only have we discovered attacks that breach the confidentiality and integrity of these I/O operations\u2014which we find very difficult to mitigate by existing approaches\u2014but more significantly we demonstrate the construction of two attack primitives against SEV\u2019s memory encryption schemes, namely a memory decryption oracle and a memory encryption oracle, which enables an adversary to decrypt and encrypt arbitrary messages using the memory encryption keys of the VMs. We evaluate the proposed attacks and discuss potential solutions to the underlying problems.",
            "keywords": [
                "Secure Encrypted Virtualization",
                "I/O Operations",
                "Memory Encryption",
                "Attack Vectors",
                "Confidentiality and Integrity Breach"
            ]
        },
        "url": "URL#2767784",
        "sema_paperId": "d9dfc43c970e6f1298fb6957ce7121af16b2e5b3"
    },
    {
        "@score": "1",
        "@id": "2767785",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "188/5871",
                        "text": "Hans Liljestrand"
                    },
                    {
                        "@pid": "149/2426",
                        "text": "Thomas Nyman"
                    },
                    {
                        "@pid": "55/6416",
                        "text": "Kui Wang"
                    },
                    {
                        "@pid": "230/7972",
                        "text": "Carlos Chinea Perez"
                    },
                    {
                        "@pid": "48/6310",
                        "text": "Jan-Erik Ekberg"
                    },
                    {
                        "@pid": "39/2508",
                        "text": "N. Asokan"
                    }
                ]
            },
            "title": "PAC it up: Towards Pointer Integrity using ARM Pointer Authentication.",
            "venue": "USENIX Security Symposium",
            "pages": "177-194",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiljestrandNWPE19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/liljestrand",
            "url": "https://dblp.org/rec/conf/uss/LiljestrandNWPE19",
            "abstract": "Run-time attacks against programs written in memory-unsafe programming languages (e.g., C and C++) remain a prominent threat against computer systems. The prevalence of techniques like return-oriented programming (ROP) in attacking real-world systems has prompted major processor manufacturers to design hardware-based countermeasures against specific classes of run-time attacks. An example is the recently added support for pointer authentication (PA) in the ARMv8-A processor architecture, commonly used in devices like smartphones. PA is a low-cost technique to authenticate pointers so as to resist memory vulnerabilities. It has been shown to enable practical protection against memory vulnerabilities that corrupt return addresses or function pointers. However, so far, PA has received very little attention as a general purpose protection mechanism to harden software against various classes of memory attacks. In this paper, we use PA to build novel defenses against various classes of run-time attacks, including the first PA-based mechanism for data pointer integrity. We present PARTS, an instrumentation framework that integrates our PA-based defenses into the LLVM compiler and the GNU/Linux operating system and show, via systematic evaluation, that PARTS provides better protection than current solutions at a reasonable performance overhead",
            "keywords": [
                "Pointer Authentication",
                "Memory Safety",
                "Run-time Attacks",
                "Data Pointer Integrity",
                "LLVM Compiler Integration"
            ]
        },
        "url": "URL#2767785",
        "sema_paperId": "ba6734ddfcd831e9b45b27a12af44ef17447fe17"
    },
    {
        "@score": "1",
        "@id": "2767786",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "67/10639",
                        "text": "Kangjie Lu"
                    },
                    {
                        "@pid": "248/1695",
                        "text": "Aditya Pakki"
                    },
                    {
                        "@pid": "248/1662",
                        "text": "Qiushi Wu"
                    }
                ]
            },
            "title": "Detecting Missing-Check Bugs via Semantic- and Context-Aware Criticalness and Constraints Inferences.",
            "venue": "USENIX Security Symposium",
            "pages": "1769-1786",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LuPW19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/lu",
            "url": "https://dblp.org/rec/conf/uss/LuPW19",
            "abstract": "Missing a security check is a class of semantic bugs in software programs where erroneous execution states are not validated. Missing-check bugs are particularly common in OS kernels because they frequently interact with external untrusted user space and hardware, and carry out error-prone computation. Missing-check bugs may cause a variety of critical security consequences, including permission bypasses, out-of-bound accesses, and system crashes. While missingcheck bugs are common and critical, only a few research works have attempted to detect them, which is arguably because of the inherent challenges in the detection\u2014whether a variable requires a security check depends on its semantics, contexts and developer logic, and understanding them is a hard problem. In this paper, we present CRIX, a system for detecting missing-check bugs in OS kernels. CRIX can scalably and precisely evaluate whether any security checks are missing for critical variables, using an inter-procedural, semanticand context-aware analysis. In particular, CRIX\u2019s modeling and cross-checking of the semantics of conditional statements in the peer slices of critical variables infer their criticalness, which allows CRIX to effectively detect missing-check bugs. Evaluation results show that CRIX finds missing-check bugs with reasonably low false-report rates. Using CRIX, we have found 278 new missing-check bugs in the Linux kernel that can cause security issues. We submitted patches for all these bugs; Linux maintainers have accepted 151 of them. The promising results show that missing-check bugs are a common occurrence, and CRIX is effective and scalable in detecting missing-check bugs in OS kernels.",
            "keywords": [
                "OS Kernel Security",
                "Missing-Check Bugs",
                "Semantic Bugs",
                "Context-Aware Analysis",
                "Critical Variables"
            ]
        },
        "url": "URL#2767786",
        "sema_paperId": "378b1f6c3f818e075b6486fbbbc462aa1ef676c9"
    },
    {
        "@score": "1",
        "@id": "2767787",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "248/1663",
                        "text": "Chenyang Lyu"
                    },
                    {
                        "@pid": "07/8388",
                        "text": "Shouling Ji"
                    },
                    {
                        "@pid": "94/3019-8",
                        "text": "Chao Zhang 0008"
                    },
                    {
                        "@pid": "156/2830",
                        "text": "Yuwei Li"
                    },
                    {
                        "@pid": "168/2469",
                        "text": "Wei-Han Lee"
                    },
                    {
                        "@pid": "54/1216",
                        "text": "Yu Song"
                    },
                    {
                        "@pid": "12/6354",
                        "text": "Raheem Beyah"
                    }
                ]
            },
            "title": "MOPT: Optimized Mutation Scheduling for Fuzzers.",
            "venue": "USENIX Security Symposium",
            "pages": "1949-1966",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LyuJZLLSB19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/lyu",
            "url": "https://dblp.org/rec/conf/uss/LyuJZLLSB19",
            "abstract": "Mutation-based fuzzing is one of the most popular vulnerability discovery solutions. Its performance of generating interesting test cases highly depends on the mutation scheduling strategies. However, existing fuzzers usually follow a specific distribution to select mutation operators, which is inefficient in finding vulnerabilities on general programs. Thus, in this paper, we present a novel mutation scheduling scheme MOPT, which enables mutation-based fuzzers to discover vulnerabilities more efficiently. MOPT utilizes a customized Particle Swarm Optimization (PSO) algorithm to find the optimal selection probability distribution of operators with respect to fuzzing effectiveness, and provides a pacemaker fuzzing mode to accelerate the convergence speed of PSO. We applied MOPT to the state-of-the-art fuzzers AFL, AFLFast and VUzzer, and implemented MOPT-AFL, -AFLFast and -VUzzer respectively, and then evaluated them on 13 real world open-source programs. The results showed that, MOPT-AFL could find 170% more security vulnerabilities and 350% more crashes than AFL. MOPT-AFLFast and MOPT-VUzzer also outperform their counterparts. Furthermore, the extensive evaluation also showed that MOPT provides a good rationality, compatibility and steadiness, while introducing negligible costs.",
            "pdf_url": "",
            "keywords": [
                "Mutation-based Fuzzing",
                "Vulnerability Discovery",
                "Mutation Scheduling",
                "Particle Swarm Optimization",
                "Fuzzing Effectiveness"
            ]
        },
        "url": "URL#2767787"
    },
    {
        "@score": "1",
        "@id": "2767789",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "120/1940",
                        "text": "Sinisa Matetic"
                    },
                    {
                        "@pid": "181/1565",
                        "text": "Karl W\u00fcst"
                    },
                    {
                        "@pid": "155/4732-1",
                        "text": "Moritz Schneider 0001"
                    },
                    {
                        "@pid": "42/2366",
                        "text": "Kari Kostiainen"
                    },
                    {
                        "@pid": "36/1531",
                        "text": "Ghassan Karame"
                    },
                    {
                        "@pid": "51/1639",
                        "text": "Srdjan Capkun"
                    }
                ]
            },
            "title": "BITE: Bitcoin Lightweight Client Privacy using Trusted Execution.",
            "venue": "USENIX Security Symposium",
            "pages": "783-800",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MateticWSKKC19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/matetic",
            "url": "https://dblp.org/rec/conf/uss/MateticWSKKC19",
            "abstract": "Blockchains offer attractive advantages over traditional payments such as the ability to operate without a trusted authority and increased user privacy. However, the verification of blockchain payments requires the user to download and process the entire chain which can be infeasible for resource-constrained devices like mobile phones. To address this problem, most major blockchain systems support so called lightweight clients that outsource most of the computational and storage burden to full blockchain nodes. However, such verification leaks critical information about clients\u2019 transactions, thus defeating user privacy that is often considered one of the main goals of decentralized cryptocurrencies.In this paper, we propose a new approach to protect the privacy of light clients in Bitcoin. Our main idea is to leverage the trusted execution capabilities of commonly available SGX enclaves. We design and implement a system called BITE where enclaves on full nodes serve privacy-preserving requests from light clients. However, as we will show, naive processing of client requests from within SGX enclaves still leaks client\u2019s addresses and transactions. BITE therefore integrates several private information retrieval and side-channel protection techniques at critical parts of the system. We show that BITE provides significantly improved privacy protection for light clients without compromising the performance of the assisting full nodes.",
            "pdf_url": "",
            "keywords": [
                "Bitcoin",
                "Lightweight Clients",
                "Privacy Protection",
                "Trusted Execution",
                "SGX Enclaves"
            ]
        },
        "url": "URL#2767789"
    },
    {
        "@score": "1",
        "@id": "2767790",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "248/1716",
                        "text": "Robert Merget"
                    },
                    {
                        "@pid": "27/8331",
                        "text": "Juraj Somorovsky"
                    },
                    {
                        "@pid": "18/1188",
                        "text": "Nimrod Aviram"
                    },
                    {
                        "@pid": "198/9685",
                        "text": "Craig Young"
                    },
                    {
                        "@pid": "248/1572",
                        "text": "Janis Fliegenschmidt"
                    },
                    {
                        "@pid": "58/5730",
                        "text": "J\u00f6rg Schwenk"
                    },
                    {
                        "@pid": "83/1922",
                        "text": "Yuval Shavitt"
                    }
                ]
            },
            "title": "Scalable Scanning and Automatic Classification of TLS Padding Oracle Vulnerabilities.",
            "venue": "USENIX Security Symposium",
            "pages": "1029-1046",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MergetSAYFSS19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/merget",
            "url": "https://dblp.org/rec/conf/uss/MergetSAYFSS19",
            "abstract": "The TLS protocol provides encryption, data integrity, and authentication on the modern Internet. Despite the protocol\u2019s importance, currently-deployed TLS versions use obsolete cryptographic algorithms which have been broken using various attacks. One prominent class of such attacks is CBC padding oracle attacks. These attacks allow an adversary to decrypt TLS traf\ufb01c by observing different server behaviors which depend on the validity of CBC padding. We present the \ufb01rst large-scale scan for CBC padding oracle vulnerabilities in TLS implementations on the modern Internet. Our scan revealed vulnerabilities in 1.83% of the Alexa Top Million websites, detecting nearly 100 different vulnerabilities. Our scanner observes subtle differences in server behavior, such as responding with different TLS alerts, or with different TCP header \ufb02ags. We used a novel scanning methodology consisting of three steps. First, we created a large set of probes that detect vulnerabilities at a considerable scanning cost. We then reduced the number of probes using a preliminary scan, such that a smaller set of probes has the same detection rate but is small enough to be used in large-scale scans. Finally, we used the reduced set to scan at scale, and clustered our \ufb01ndings with a novel approach using graph drawing algorithms. Contrary to common wisdom, exploiting CBC padding or-acles does not necessarily require performing precise timing measurements. We detected vulnerabilities that can be exploited simply by observing the content of different server responses. These vulnerabilities pose a signi\ufb01cantly larger threat in practice than previously assumed.",
            "keywords": [
                "TLS Protocol",
                "CBC Padding Oracle",
                "Vulnerability Detection",
                "Large-Scale Scanning",
                "Server Response Analysis"
            ]
        },
        "url": "URL#2767790",
        "sema_paperId": "26e1064d467a73773e3c6da3f35c26ae5d5d0ea0"
    },
    {
        "@score": "1",
        "@id": "2767791",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "160/6851",
                        "text": "Yisroel Mirsky"
                    },
                    {
                        "@pid": "213/7957",
                        "text": "Tom Mahler"
                    },
                    {
                        "@pid": "116/3831",
                        "text": "Ilan Shelef"
                    },
                    {
                        "@pid": "38/4086",
                        "text": "Yuval Elovici"
                    }
                ]
            },
            "title": "CT-GAN: Malicious Tampering of 3D Medical Imagery using Deep Learning.",
            "venue": "USENIX Security Symposium",
            "pages": "461-478",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MirskyMSE19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/mirsky",
            "url": "https://dblp.org/rec/conf/uss/MirskyMSE19",
            "abstract": "In 2018, clinics and hospitals were hit with numerous attacks leading to significant data breaches and interruptions in medical services. An attacker with access to medical records can do much more than hold the data for ransom or sell it on the black market. \n\t\t\nIn this paper, we show how an attacker can use deep-learning to add or remove evidence of medical conditions from volumetric (3D) medical scans. An attacker may perform this act in order to stop a political candidate, sabotage research, commit insurance fraud, perform an act of terrorism, or even commit murder. We implement the attack using a 3D conditional GAN and show how the framework (CT-GAN) can be automated. Although the body is complex and 3D medical scans are very large, CT-GAN achieves realistic results which can be executed in milliseconds.\n\t\t\nTo evaluate the attack, we focused on injecting and removing lung cancer from CT scans. We show how three expert radiologists and a state-of-the-art deep learning AI are highly susceptible to the attack. We also explore the attack surface of a modern radiology network and demonstrate one attack vector: we intercepted and manipulated CT scans in an active hospital network with a covert penetration test.",
            "pdf_url": "",
            "keywords": [
                "3D Medical Imaging",
                "Malicious Tampering",
                "Conditional GAN",
                "Lung Cancer Manipulation",
                "Radiology Network Vulnerabilities"
            ]
        },
        "url": "URL#2767791"
    },
    {
        "@score": "1",
        "@id": "2767792",
        "info": {
            "authors": {
                "author": {
                    "@pid": "119/2077",
                    "text": "John V. Monaco"
                }
            },
            "title": "What Are You Searching For? A Remote Keylogging Attack on Search Engine Autocomplete.",
            "venue": "USENIX Security Symposium",
            "pages": "959-976",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Monaco19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/monaco",
            "url": "https://dblp.org/rec/conf/uss/Monaco19",
            "abstract": "Many search engines have an autocomplete feature that presents a list of suggested queries to the user as they type. Autocomplete induces network traffic from the client upon changes to the query in a web page. We describe a remote keylogging attack on search engine autocomplete. The attack integrates information leaked by three independent sources: the timing of keystrokes manifested in packet inter-arrival times, percent-encoded Space characters in a URL, and the static Huffman code used in HTTP2 header compression. While each source is a relatively weak predictor in its own right, combined, and by leveraging the relatively low entropy of English language, up to 15% of search queries are identified among a list of 50 hypothesis queries generated from a dictionary with over 12k words. The attack succeeds despite network traffic being encrypted. We demonstrate the attack on two popular search engines and discuss some countermeasures to mitigate attack success.",
            "keywords": [
                "Keylogging Attack",
                "Search Engine Autocomplete",
                "Network Traffic Analysis",
                "Packet Inter-Arrival Times",
                "HTTP2 Header Compression"
            ]
        },
        "url": "URL#2767792",
        "sema_paperId": "aa5ac5fd69bf8a24f30962a1c54854c9fd849ebe"
    },
    {
        "@score": "1",
        "@id": "2767793",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "37/9269",
                        "text": "Takao Murakami"
                    },
                    {
                        "@pid": "13/8409",
                        "text": "Yusuke Kawamoto 0001"
                    }
                ]
            },
            "title": "Utility-Optimized Local Differential Privacy Mechanisms for Distribution Estimation.",
            "venue": "USENIX Security Symposium",
            "pages": "1877-1894",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Murakami019",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/murakami",
            "url": "https://dblp.org/rec/conf/uss/Murakami019",
            "abstract": "LDP (Local Differential Privacy) has been widely studied to estimate statistics of personal data (e.g., distribution underlying the data) while protecting users' privacy. Although LDP does not require a trusted third party, it regards all personal data equally sensitive, which causes excessive obfuscation hence the loss of utility. In this paper, we introduce the notion of ULDP (Utility-optimized LDP), which provides a privacy guarantee equivalent to LDP only for sensitive data. We first consider the setting where all users use the same obfuscation mechanism, and propose two mechanisms providing ULDP: utility-optimized randomized response and utility-optimized RAPPOR. We then consider the setting where the distinction between sensitive and non-sensitive data can be different from user to user. For this setting, we propose a personalized ULDP mechanism with semantic tags to estimate the distribution of personal data with high utility while keeping secret what is sensitive for each user. We show theoretically and experimentally that our mechanisms provide much higher utility than the existing LDP mechanisms when there are a lot of non-sensitive data. We also show that when most of the data are non-sensitive, our mechanisms even provide almost the same utility as non-private mechanisms in the low privacy regime.",
            "keywords": [
                "Local Differential Privacy",
                "Utility-Optimized Privacy",
                "Distribution Estimation",
                "Sensitive Data Protection",
                "Personalized Privacy Mechanisms"
            ]
        },
        "url": "URL#2767793",
        "sema_paperId": "c96f48f67796a02259076d2c50f913877c3480d5"
    },
    {
        "@score": "1",
        "@id": "2767794",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "124/9890",
                        "text": "Arman Noroozian"
                    },
                    {
                        "@pid": "248/1573",
                        "text": "Jan Koenders"
                    },
                    {
                        "@pid": "248/1574",
                        "text": "Eelco van Veldhuizen"
                    },
                    {
                        "@pid": "22/7256",
                        "text": "Carlos Hernandez Ga\u00f1\u00e1n"
                    },
                    {
                        "@pid": "123/3274",
                        "text": "Sumayah A. Alrwais"
                    },
                    {
                        "@pid": "58/4016",
                        "text": "Damon McCoy"
                    },
                    {
                        "@pid": "17/7444",
                        "text": "Michel van Eeten"
                    }
                ]
            },
            "title": "Platforms in Everything: Analyzing Ground-Truth Data on the Anatomy and Economics of Bullet-Proof Hosting.",
            "venue": "USENIX Security Symposium",
            "pages": "1341-1356",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/NoroozianKVGAME19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/noroozian",
            "url": "https://dblp.org/rec/conf/uss/NoroozianKVGAME19",
            "abstract": "This paper presents the first empirical study based on ground-truth data of a major Bullet-Proof Hosting (BPH) provider, a company called Maxided. BPH allows miscreants to host criminal activities in support of various cybercrime business models such as phishing, botnets, DDoS, spam, and counterfeit pharmaceutical websites. Maxided was legally taken down by law enforcement and its backend servers were seized. We analyze data extracted from its backend databases and connect it to various external data sources to characterize Maxided's business model, supply chain, customers and finances. We reason about what the ``inside'' view reveals about potential chokepoints for disrupting BPH providers. We demonstrate the BPH landscape to have further shifted from agile resellers towards marketplace platforms with an oversupply of resources originating from hundreds of legitimate upstream hosting providers. We find the BPH provider to have few choke points in the supply chain amendable to intervention, though profit margins are very slim, so even a marginal increase in operating costs might already have repercussions that render the business unsustainable. The other intervention option would be to take down the platform itself.",
            "keywords": [
                "Bullet-Proof Hosting",
                "Cybercrime Business Models",
                "Supply Chain Analysis",
                "Chokepoints for Disruption",
                "Maxided"
            ]
        },
        "url": "URL#2767794",
        "sema_paperId": "7c41a124f57997bc3c885344efa987a668e66d90"
    },
    {
        "@score": "1",
        "@id": "2767795",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "173/5375",
                        "text": "Ivan De Oliveira Nunes"
                    },
                    {
                        "@pid": "01/4656",
                        "text": "Karim Eldefrawy"
                    },
                    {
                        "@pid": "198/1339",
                        "text": "Norrathep Rattanavipanon"
                    },
                    {
                        "@pid": "64/5301-1",
                        "text": "Michael Steiner 0001"
                    },
                    {
                        "@pid": "08/1183",
                        "text": "Gene Tsudik"
                    }
                ]
            },
            "title": "VRASED: A Verified Hardware/Software Co-Design for Remote Attestation.",
            "venue": "USENIX Security Symposium",
            "pages": "1429-1446",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/NunesERST19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/de-oliveira-nunes",
            "url": "https://dblp.org/rec/conf/uss/NunesERST19",
            "abstract": "Remote Attestation (RA) is a distinct security service that allows a trusted verifier (V rf) to measure the software state of an untrusted remote prover (P rv). If correctly implemented, RA allows V rf to remotely detect if P rv is in an illegal or compromised state. Although several RA approaches have been explored (including hardware-based, software-based, and hybrid) and many concrete methods have been proposed, comparatively little attention has been devoted to formal verification. In particular, thus far, no RA designs and no implementations have been formally verified with respect to claimed security properties. In this work, we take the first step towards formal verification of RA by designing and verifying an architecture called VRASED: Verifiable Remote Attestation for Simple Embedded Devices. VRASED instantiates a hybrid (HW/SW) RA codesign aimed at low-end embedded systems, e.g., simple IoT devices. VRASED provides a level of security comparable to HW-based approaches, while relying on SW to minimize additional HW costs. Since security properties must be jointly guaranteed by HW and SW, verification is a challenging task, which has never been attempted before in the context ofRA. We believe that VRASED is the first formally verified RA scheme. To the best of our knowledge, it is also the first formal verification of a HW/SW co-design implementation of any security service. To demonstrate VRASED\u2019s practicality and low overhead, we instantiate and evaluate it on a commodity platform (TI MSP430). VRASED was deployed using the Basys3 Artix-7 FPGA and its implementation is publicly available.",
            "keywords": [
                "Remote Attestation",
                "Formal Verification",
                "Hybrid Hardware/Software Co-Design",
                "Embedded Systems Security",
                "IoT Device Integrity"
            ]
        },
        "url": "URL#2767795",
        "sema_paperId": "5ca23a1d379972ec05f37efb45180f5cabab1923"
    },
    {
        "@score": "1",
        "@id": "2767796",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "123/3252",
                        "text": "Fabio Pagani"
                    },
                    {
                        "@pid": "56/490",
                        "text": "Davide Balzarotti"
                    }
                ]
            },
            "title": "Back to the Whiteboard: a Principled Approach for the Assessment and Design of Memory Forensic Techniques.",
            "venue": "USENIX Security Symposium",
            "pages": "1751-1768",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PaganiB19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/pagani",
            "url": "https://dblp.org/rec/conf/uss/PaganiB19",
            "abstract": "Today memory analysis plays a fundamental role in computer forensics and is a very active area of research. However, the field is still largely driven by custom rules and heuristics handpicked by human experts. These rules describe how to overcome the semantic gap to associate high level structures to individual bytes contained in a physical memory dump. Structures are then traversed by following pointers to other objects, and the process is repeated until the required information is located and extracted from the memory image. A fundamental problem with this approach is that we have no way to measure these heuristics to know precisely how well they work, under which circumstances, how prone they are to evasions or to errors, and how stable they are over different versions of the OS kernel. In addition, without a method to measure the quality and effectiveness of a given heuristic, it is impossible to compare one approach against the others. If a tool adopts a certain heuristic to list the sockets associated to a program, how do we know if that is the only possible way to extract this information? Maybe other, even better, solutions exist, just waiting to be \u201cdiscovered\u201d by human analysts. For this reason, we believe we need to go back to the drawing board and rethink memory forensics from its foundations. In this paper we propose a framework and a set of metrics we can use as a basis to assess existing methodologies,understand their characteristics and limitations, and propose new techniques in a principled way. The memory of a modern operating system is a very large and very complex network of interconnected objects. Because of this, we argue that automated algorithms, rather than human intuition, should play a fundamental role in evaluating and designing future memory forensics techniques.",
            "keywords": [
                "Memory Forensics",
                "Heuristics",
                "Semantic Gap",
                "Memory Analysis",
                "Automated Evaluation"
            ]
        },
        "url": "URL#2767796",
        "sema_paperId": "8a05082dc25b47dd5571efa987f10c92fb3952c9"
    },
    {
        "@score": "1",
        "@id": "2767797",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "223/5655",
                        "text": "Feargus Pendlebury"
                    },
                    {
                        "@pid": "149/1452",
                        "text": "Fabio Pierazzi"
                    },
                    {
                        "@pid": "160/9532",
                        "text": "Roberto Jordaney"
                    },
                    {
                        "@pid": "74/3780",
                        "text": "Johannes Kinder"
                    },
                    {
                        "@pid": "95/5162",
                        "text": "Lorenzo Cavallaro"
                    }
                ]
            },
            "title": "TESSERACT: Eliminating Experimental Bias in Malware Classification across Space and Time.",
            "venue": "USENIX Security Symposium",
            "pages": "729-746",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PendleburyPJKC19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/pendlebury",
            "url": "https://dblp.org/rec/conf/uss/PendleburyPJKC19",
            "abstract": "Is Android malware classification a solved problem? Published F1 scores of up to 0.99 appear to leave very little room for improvement. In this paper, we argue that results are commonly inflated due to two pervasive sources of experimental bias: \"spatial bias\" caused by distributions of training and testing data that are not representative of a real-world deployment; and \"temporal bias\" caused by incorrect time splits of training and testing sets, leading to impossible configurations. We propose a set of space and time constraints for experiment design that eliminates both sources of bias. We introduce a new metric that summarizes the expected robustness of a classifier in a real-world setting, and we present an algorithm to tune its performance. Finally, we demonstrate how this allows us to evaluate mitigation strategies for time decay such as active learning. We have implemented our solutions in TESSERACT, an open source evaluation framework for comparing malware classifiers in a realistic setting. We used TESSERACT to evaluate three Android malware classifiers from the literature on a dataset of 129K applications spanning over three years. Our evaluation confirms that earlier published results are biased, while also revealing counter-intuitive performance and showing that appropriate tuning can lead to significant improvements.",
            "keywords": [
                "Android Malware Classification",
                "Experimental Bias",
                "Spatial Bias",
                "Temporal Bias",
                "TESSERACT Framework"
            ]
        },
        "url": "URL#2767797",
        "sema_paperId": "7ab5a2b7d2caa8969c06e1f24dfda2a6f5c654f6"
    },
    {
        "@score": "1",
        "@id": "2767799",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "119/7710",
                        "text": "Giuseppe Petracca"
                    },
                    {
                        "@pid": "139/7955",
                        "text": "Yuqiong Sun"
                    },
                    {
                        "@pid": "174/7896",
                        "text": "Ahmad Atamli-Reineh"
                    },
                    {
                        "@pid": "m/PatrickDrewMcDaniel",
                        "text": "Patrick D. McDaniel"
                    },
                    {
                        "@pid": "28/3855",
                        "text": "Jens Grossklags"
                    },
                    {
                        "@pid": "45/576",
                        "text": "Trent Jaeger"
                    }
                ]
            },
            "title": "EnTrust: Regulating Sensor Access by Cooperating Programs via Delegation Graphs.",
            "venue": "USENIX Security Symposium",
            "pages": "567-584",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PetraccaSAMGJ19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/petracca",
            "url": "https://dblp.org/rec/conf/uss/PetraccaSAMGJ19",
            "abstract": "Modern operating systems support a cooperating program abstraction that, instead of placing all functionality into a single program, allows diverse programs to cooperate to complete tasks requested by users. However, untrusted programs may exploit such interactions to spy on users through device sensors by causing privileged system services to misuse their permissions, or to forward user requests to malicious programs inadvertently. Researchers have previously explored methods to restrict access to device sensors based on the state of the user interface that elicited the user input or based on the set of cooperating programs, but the former approach does not consider cooperating programs and the latter approach has been found to be too restrictive for many cases. In this paper, we propose EnTrust , an authorization system that tracks the processing of input events across programs for eliciting approvals from users for sensor operations. EnTrust constructs delegation graphs by linking input events to cooperation events among programs that lead to sensor operation requests, then uses such delegation graphs for eliciting authorization decisions from users. To demonstrate this approach, we implement the EnTrust authorization sys-tem for Android OS. In a laboratory study, we show that attacks can be prevented at a much higher rate (47-67% improvement) compared to the first-use approach. Our field study reveals that EnTrust only requires a user effort comparable to the first-use approach while incurring negligible performance (<1% slowdown) and memory overheads (5.5 KB per program)",
            "keywords": [
                "Sensor Access Control",
                "Cooperating Programs",
                "Authorization System",
                "Delegation Graphs",
                "User Approval for Sensor Operations"
            ]
        },
        "url": "URL#2767799",
        "sema_paperId": "aca23fa6de05bf0306f12ff7906f19b65ae20040"
    },
    {
        "@score": "1",
        "@id": "2767801",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "99/3569",
                        "text": "Anh Pham"
                    },
                    {
                        "@pid": "82/5414",
                        "text": "Italo Dacosta"
                    },
                    {
                        "@pid": "166/7925",
                        "text": "Eleonora Losiouk"
                    },
                    {
                        "@pid": "185/5372",
                        "text": "John Stephan"
                    },
                    {
                        "@pid": "10/3024",
                        "text": "K\u00e9vin Huguenin"
                    },
                    {
                        "@pid": "h/JPHubaux",
                        "text": "Jean-Pierre Hubaux"
                    }
                ]
            },
            "title": "HideMyApp: Hiding the Presence of Sensitive Apps on Android.",
            "venue": "USENIX Security Symposium",
            "pages": "711-728",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PhamDLSHH19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/pham",
            "url": "https://dblp.org/rec/conf/uss/PhamDLSHH19",
            "abstract": "Millions of users rely on mobile health (mHealth) apps to manage their wellness and medical conditions. Although the popularity of such apps continues to grow, several privacy and security challenges can hinder their potential. In particular, the simple fact that an mHealth app is installed on a user\u2019s phone can reveal sensitive information about the user\u2019s health. Due to Android\u2019s open design, any app, even without per- missions, can easily check for the presence of a specific app or collect the entire list of installed apps on the phone. Our analysis shows that Android apps expose a significant amount of metadata, which facilitates fingerprinting them. Many third parties are interested in such information: Our survey of 2917 popular apps in the Google Play Store shows that around 57% of these apps explicitly query for the list of installed apps. Therefore, we designed and implemented HideMyApp (HMA), an effective and practical solution for hiding the presence of sensitive apps from other apps. HMA does not require any changes to the Android operating system or to apps yet still supports their key functionalities. By using a diverse dataset of both free and paid mHealth apps, our experimental eval- uation shows that HMA supports the main functionalities in most apps and introduces acceptable overheads at runtime (i.e., several milliseconds); these findings were validated by our user-study (N = 30). In short, we show that the practice of collecting information about installed apps is widespread and that our solution, HMA, provides a robust protection against such a threat.",
            "keywords": [
                "Mobile Health Apps",
                "Privacy Protection",
                "App Fingerprinting",
                "Sensitive Information Disclosure",
                "HideMyApp (HMA)"
            ]
        },
        "url": "URL#2767801",
        "sema_paperId": "68e3874ede9a54af54ff24ca7a24885788aa11bb"
    },
    {
        "@score": "1",
        "@id": "2767803",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "147/2276",
                        "text": "Chenxiong Qian"
                    },
                    {
                        "@pid": "70/2543-4",
                        "text": "Hong Hu 0004"
                    },
                    {
                        "@pid": "248/1603",
                        "text": "Mansour Alharthi"
                    },
                    {
                        "@pid": "38/860",
                        "text": "Simon Pak Ho Chung"
                    },
                    {
                        "@pid": "38/8882",
                        "text": "Taesoo Kim"
                    },
                    {
                        "@pid": "29/5976",
                        "text": "Wenke Lee"
                    }
                ]
            },
            "title": "RAZOR: A Framework for Post-deployment Software Debloating.",
            "venue": "USENIX Security Symposium",
            "pages": "1733-1750",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/QianHACKL19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/qian",
            "url": "https://dblp.org/rec/conf/uss/QianHACKL19",
            "abstract": "Commodity software typically includes a large number of functionalities for a broad user population. However, each individual user usually only needs a small subset of all supported functionalities. The bloated code not only hinders optimal execution, but also leads to a larger attack surface. Recent works have explored program debloating as an emerging solution to this problem. Unfortunately, these works require program source code, limiting their real-world deployability. In this paper, we propose a practical debloating framework, RAZOR, that performs code reduction for deployed binaries. Based on users\u2019 specifications, our tool customizes the binary to generate a functional program with minimal code size. Instead of only supporting given test cases, RAZOR takes several control-flow heuristics to infer complementary code that is necessary to support user-expected functionalities. We evaluated RAZOR on commonly used benchmarks and realworld applications, including the web browser FireFox and the close-sourced PDF reader FoxitReader. The result shows that RAZOR is able to reduce over 70% of the code from the bloated binary. It produces functional programs and does not introduce any security issues. RAZOR is thus a practical framework for debloating real-world programs.",
            "keywords": [
                "Software Debloating",
                "Binary Code Reduction",
                "Post-deployment Optimization",
                "Control-flow Heuristics",
                "Functional Program Customization"
            ]
        },
        "url": "URL#2767803",
        "sema_paperId": "b3fd22d93ad5787c1cda0662e27b5a76da9ee26a"
    },
    {
        "@score": "1",
        "@id": "2767804",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "149/3695",
                        "text": "Erwin Quiring"
                    },
                    {
                        "@pid": "165/5503",
                        "text": "Alwin Maier"
                    },
                    {
                        "@pid": "64/4020",
                        "text": "Konrad Rieck"
                    }
                ]
            },
            "title": "Misleading Authorship Attribution of Source Code using Adversarial Learning.",
            "venue": "USENIX Security Symposium",
            "pages": "479-496",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/QuiringMR19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/quiring",
            "url": "https://dblp.org/rec/conf/uss/QuiringMR19",
            "abstract": "In this paper, we present a novel attack against authorship attribution of source code. \nWe exploit that recent attribution methods rest on machine learning and thus can be deceived by adversarial examples of source code. Our attack performs a series of semantics-preserving  code transformations that mislead learning-based attribution but appear  plausible to a developer.\nThe attack is guided by Monte-Carlo tree search that enables us to  operate in the discrete domain of source code.\nIn an empirical evaluation with source code from 204 programmers, we demonstrate that our attack has a substantial effect on two recent attribution methods, whose accuracy drops from over 88% to 1% under attack. Furthermore, we show that our attack can imitate the coding style of developers with high accuracy and thereby induce false attributions.\nWe conclude that current approaches for authorship attribution are inappropriate for practical application and there is a need for resilient analysis techniques.",
            "pdf_url": "",
            "keywords": [
                "Authorship Attribution",
                "Source Code Analysis",
                "Adversarial Learning",
                "Code Transformation",
                "False Attribution"
            ]
        },
        "url": "URL#2767804"
    },
    {
        "@score": "1",
        "@id": "2767805",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "04/10",
                        "text": "Tahina Ramananandro"
                    },
                    {
                        "@pid": "121/1113",
                        "text": "Antoine Delignat-Lavaud"
                    },
                    {
                        "@pid": "f/CedricFournet",
                        "text": "C\u00e9dric Fournet"
                    },
                    {
                        "@pid": "11/5568",
                        "text": "Nikhil Swamy"
                    },
                    {
                        "@pid": "141/9176",
                        "text": "Tej Chajed"
                    },
                    {
                        "@pid": "131/6696",
                        "text": "Nadim Kobeissi"
                    },
                    {
                        "@pid": "132/3972",
                        "text": "Jonathan Protzenko"
                    }
                ]
            },
            "title": "EverParse: Verified Secure Zero-Copy Parsers for Authenticated Message Formats.",
            "venue": "USENIX Security Symposium",
            "pages": "1465-1482",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RamananandroDFS19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/delignat-lavaud",
            "url": "https://dblp.org/rec/conf/uss/RamananandroDFS19",
            "abstract": "We present EverParse, a framework for generating parsers and serializers from tag-length-value binary message format descriptions. The resulting code is verified to be safe (no overflow, no use after free), correct (parsing is the inverse of serialization) and non-malleable (each message has a unique binary representation). These guarantees underpin the security of cryptographic message authentication, and they enable testing to focus on interoperability and performance issues. EverParse consists of two parts: LowParse, a library of parser combinators and their formal properties written in F*; and QuackyDucky, a compiler from a domain-specific language of RFC message formats down to low-level F* code that calls LowParse. While LowParse is fully verified, we do not formalize the semantics of the input language and keep QuackyDucky outside our trusted computing base. Instead, it also outputs a formal message specification, and F* automatically verifies our implementation against this specification. EverParse yields efficient zero-copy implementations, usable both in F* and in C. We evaluate it in practice by fully implementing the message formats of the Transport Layer Security standard and its extensions (TLS 1.0\u20131.3, 293 datatypes) and by integrating them into miTLS, an F* implementation of TLS. We illustrate its generality by implementing the Bitcoin block and transaction formats, and the ASN.1 DER payload of PKCS#1 RSA signatures. We integrate them into C applications and measure their runtime performance, showing significant improvements over prior handwritten libraries. EverParse is open-source and publicly available on GitHub. You can view Antoine Delignat-Lavaud\u2019s presentation at USENIX Security 2019.",
            "keywords": [
                "Zero-Copy Parsing",
                "Message Authentication",
                "Binary Message Formats",
                "Parser Verification",
                "Non-Malleability"
            ]
        },
        "url": "URL#2767805",
        "sema_paperId": "34114140b0395ee3e5a8529fdd2a6cc3ff86f451"
    },
    {
        "@score": "1",
        "@id": "2767806",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "04/8882",
                        "text": "Joel Reardon"
                    },
                    {
                        "@pid": "248/1636",
                        "text": "\u00c1lvaro Feal"
                    },
                    {
                        "@pid": "162/0214",
                        "text": "Primal Wijesekera"
                    },
                    {
                        "@pid": "219/1325",
                        "text": "Amit Elazari Bar On"
                    },
                    {
                        "@pid": "50/7563",
                        "text": "Narseo Vallina-Rodriguez"
                    },
                    {
                        "@pid": "07/1108",
                        "text": "Serge Egelman"
                    }
                ]
            },
            "title": "50 Ways to Leak Your Data: An Exploration of Apps&apos; Circumvention of the Android Permissions System.",
            "venue": "USENIX Security Symposium",
            "pages": "603-620",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ReardonFWOVE19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/reardon",
            "url": "https://dblp.org/rec/conf/uss/ReardonFWOVE19",
            "abstract": "Modern smartphone platforms implement permission-based models to protect access to sensitive data and system resources. However, apps can circumvent the permission model and gain access to protected data without user consent by using both covert and side channels. Side channels present in the implementation of the permission system allow apps to access protected data and system resources without permission; whereas covert channels enable communication between two colluding apps so that one app can share its permission-protected data with another app lacking those permissions. Both pose threats to user privacy. \n \nIn this work, we make use of our infrastructure that runs hundreds of thousands of apps in an instrumented environment. This testing environment includes mechanisms to monitor apps' runtime behaviour and network traffic. We look for evidence of side and covert channels being used in practice by searching for sensitive data being sent over the network for which the sending app did not have permissions to access it. We then reverse engineer the apps and third-party libraries responsible for this behaviour to determine how the unauthorized access occurred. We also use software fingerprinting methods to measure the static prevalence of the technique that we discover among other apps in our corpus. \n \nUsing this testing environment and method, we uncovered a number of side and covert channels in active use by hundreds of popular apps and third-party SDKs to obtain unauthorized access to both unique identifiers as well as geolocation data. We have responsibly disclosed our findings to Google and have received a bug bounty for our work.",
            "keywords": [
                "Android Permissions System",
                "Data Leakage",
                "Covert Channels",
                "Side Channels",
                "User Privacy Threats"
            ]
        },
        "url": "URL#2767806",
        "sema_paperId": "f55cd4f60127e0fda77f82c67c06e846f0af5954"
    },
    {
        "@score": "1",
        "@id": "2767807",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "17/697",
                        "text": "Charles Reis"
                    },
                    {
                        "@pid": "75/3815",
                        "text": "Alexander Moshchuk"
                    },
                    {
                        "@pid": "209/8378",
                        "text": "Nasko Oskov"
                    }
                ]
            },
            "title": "Site Isolation: Process Separation for Web Sites within the Browser.",
            "venue": "USENIX Security Symposium",
            "pages": "1661-1678",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ReisMO19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/reis",
            "url": "https://dblp.org/rec/conf/uss/ReisMO19",
            "abstract": "Current production web browsers are multi-process but place different web sites in the same renderer process, which is not sufficient to mitigate threats present on the web today. With the prevalence of private user data stored on web sites, the risk posed by compromised renderer processes, and the advent of transient execution attacks like Spectre and Meltdown that can leak data via microarchitectural state, it is no longer safe to render documents from different web sites in the same process. In this paper, we describe our successful deployment of the Site Isolation architecture to all desktop users of Google Chrome as a mitigation for process-wide attacks. Site Isolation locks each renderer process to documents from a single site and filters certain cross-site data from each process. We overcame performance and compatibility challenges to adapt a production browser to this new architecture. We find that this architecture offers the best path to protection against compromised renderer processes and same-process transient execution attacks, despite current limitations. Our performance results indicate it is practical to deploy this level of isolation while sufficiently preserving compatibility with existing web content. Finally, we discuss future directions and how the current limitations of Site Isolation might be addressed.",
            "keywords": [
                "Site Isolation",
                "Web Browser Security",
                "Renderer Process",
                "Cross-Site Data Protection",
                "Transient Execution Attacks"
            ]
        },
        "url": "URL#2767807",
        "sema_paperId": "8eb2a6b9e0d873d948e6de74fdb790c42c4c59db"
    },
    {
        "@score": "1",
        "@id": "2767808",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "181/9181",
                        "text": "M. Sadegh Riazi"
                    },
                    {
                        "@pid": "199/8745",
                        "text": "Mohammad Samragh"
                    },
                    {
                        "@pid": "175/3324-30",
                        "text": "Hao Chen 0030"
                    },
                    {
                        "@pid": "146/7941",
                        "text": "Kim Laine"
                    },
                    {
                        "@pid": "08/1510",
                        "text": "Kristin E. Lauter"
                    },
                    {
                        "@pid": "k/FarinazKoushanfar",
                        "text": "Farinaz Koushanfar"
                    }
                ]
            },
            "title": "XONN: XNOR-based Oblivious Deep Neural Network Inference.",
            "venue": "USENIX Security Symposium",
            "pages": "1501-1518",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RiaziS0LLK19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/riazi",
            "url": "https://dblp.org/rec/conf/uss/RiaziS0LLK19",
            "abstract": "Advancements in deep learning enable cloud servers to provide inference-as-a-service for clients. In this scenario, clients send their raw data to the server to run the deep learning model and send back the results. One standing challenge in this setting is to ensure the privacy of the clients' sensitive data. Oblivious inference is the task of running the neural network on the client's input without disclosing the input or the result to the server. This paper introduces XONN (pronounced /ZAn/), a novel end-to-end framework based on Yao's Garbled Circuits (GC) protocol, that provides a paradigm shift in the conceptual and practical realization of oblivious inference. In XONN, the costly matrix-multiplication operations of the deep learning model are replaced with XNOR operations that are essentially free in GC. We further provide a novel algorithm that customizes the neural network such that the runtime of the GC protocol is minimized without sacrificing the inference accuracy.\nWe design a user-friendly high-level API for XONN, allowing expression of the deep learning model architecture in an unprecedented level of abstraction. We further provide a compiler to translate the model description from high-level Python (i.e., Keras) to that of XONN. Extensive proof-of-concept evaluation on various neural network architectures demonstrates that XONN outperforms prior art such as Gazelle (USENIX Security'18) by up to 7\u00d7, MiniONN (ACM CCS'17) by 93\u00d7, and SecureML (IEEE S&P'17) by 37\u00d7. State-of-the-art frameworks require one round of interaction between the client and the server for each layer of the neural network, whereas, XONN requires a constant round of interactions for any number of layers in the model. XONN is first to perform oblivious inference on Fitnet architectures with up to 21 layers, suggesting a new level of scalability compared with state-of-the-art. Moreover, we evaluate XONN on four datasets to perform privacy-preserving medical diagnosis. The datasets include breast cancer, diabetes, liver disease, and Malaria.",
            "pdf_url": "",
            "keywords": [
                "Oblivious Inference",
                "Garbled Circuits",
                "Privacy-Preserving Computation",
                "XNOR Operations",
                "Deep Learning Model Customization"
            ]
        },
        "url": "URL#2767808"
    },
    {
        "@score": "1",
        "@id": "2767809",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "147/2743",
                        "text": "Ethan M. Rudd"
                    },
                    {
                        "@pid": "237/9698",
                        "text": "Felipe N. Ducau"
                    },
                    {
                        "@pid": "218/6259",
                        "text": "Cody Wild"
                    },
                    {
                        "@pid": "49/6295",
                        "text": "Konstantin Berlin"
                    },
                    {
                        "@pid": "119/2618",
                        "text": "Richard E. Harang"
                    }
                ]
            },
            "title": "ALOHA: Auxiliary Loss Optimization for Hypothesis Augmentation.",
            "venue": "USENIX Security Symposium",
            "pages": "303-320",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RuddDWBH19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/rudd",
            "url": "https://dblp.org/rec/conf/uss/RuddDWBH19",
            "abstract": "Malware detection is a popular application of Machine Learning for Information Security (ML-Sec), in which an ML classifier is trained to predict whether a given file is malware or benignware. Parameters of this classifier are typically optimized such that outputs from the model over a set of input samples most closely match the samples\u2019 true malicious/benign (1/0) target labels. However, there are often a number of other sources of contextual metadata for each malware sample, beyond an aggregate malicious/benign label, including multiple labeling sources and malware type information (e.g. ransomware, trojan, etc.),  which we can feed to the classifier as auxiliary prediction targets. In this work, we fit deep neural networks to multiple additional targets derived from metadata in a threat intelligence feed for Portable Executable (PE) malware and benignware, including a multi-source malicious/benign loss, a count loss on multi-source detections, and a semantic malware attribute tag loss. We find that incorporating multiple auxiliary loss terms yields a marked improvement in performance on the main detection task. We also demonstrate that these gains likely stem from a more informed neural network representation and are not due to a regularization artifact of multi-target learning. Our auxiliary loss architecture yields a significant reduction in detection error rate (false negatives) of 42.6% at a false positive rate (FPR) of 10-3 when compared to a similar model with only one target, and a decrease of 53.8% at 10-5 FPR.",
            "pdf_url": "",
            "keywords": [
                "Malware Detection",
                "Auxiliary Loss Optimization",
                "Threat Intelligence",
                "Portable Executable (PE)",
                "False Negative Reduction"
            ]
        },
        "url": "URL#2767809"
    },
    {
        "@score": "1",
        "@id": "2767810",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "201/9217",
                        "text": "Kimberly Ruth"
                    },
                    {
                        "@pid": "k/TadayoshiKohno",
                        "text": "Tadayoshi Kohno"
                    },
                    {
                        "@pid": "23/2758",
                        "text": "Franziska Roesner"
                    }
                ]
            },
            "title": "Secure Multi-User Content Sharing for Augmented Reality Applications.",
            "venue": "USENIX Security Symposium",
            "pages": "141-158",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RuthKR19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/ruth",
            "url": "https://dblp.org/rec/conf/uss/RuthKR19",
            "abstract": "Augmented reality (AR), which overlays virtual content on top of the user\u2019s perception of the real world, has now begun to enter the consumer market. Besides smartphone platforms, early-stage head-mounted displays such as the Microsoft HoloLens are under active development. Many compelling uses of these technologies are multi-user: e.g., inperson collaborative tools, multiplayer gaming, and telepresence. While prior work on AR security and privacy has studied potential risks from AR applications, new risks will also arise among multiple human users. In this work, we explore the challenges that arise in designing secure and private content sharing for multi-user AR. We analyze representative application case studies and systematize design goals for security and functionality that a multi-user AR platform should support. We design an AR content sharing control module that achieves these goals and build a prototype implementation (ShareAR) for the HoloLens. This work builds foundations for secure and private multi-user AR interactions.",
            "keywords": [
                "Augmented Reality",
                "Multi-User Interaction",
                "Content Sharing",
                "Privacy Challenges",
                "Security Design Goals"
            ]
        },
        "url": "URL#2767810",
        "sema_paperId": "7b3e6d78f15f161e98eb560fd2f3e5c6d83a9339"
    },
    {
        "@score": "1",
        "@id": "2767811",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "241/1422",
                        "text": "Harshad Sathaye"
                    },
                    {
                        "@pid": "198/6828",
                        "text": "Domien Schepers"
                    },
                    {
                        "@pid": "23/11190",
                        "text": "Aanjhan Ranganathan"
                    },
                    {
                        "@pid": "25/5432",
                        "text": "Guevara Noubir"
                    }
                ]
            },
            "title": "Wireless Attacks on Aircraft Instrument Landing Systems.",
            "venue": "USENIX Security Symposium",
            "pages": "357-372",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SathayeSRN19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/sathaye",
            "url": "https://dblp.org/rec/conf/uss/SathayeSRN19",
            "abstract": "Modern aircraft heavily rely on several wireless technologies for communications, control, and navigation. Researchers demonstrated vulnerabilities in many aviation systems. However, the resilience of the aircraft landing systems to adversarial wireless attacks have not yet been studied in the open literature, despite their criticality and the increasing availability of low-cost software-de\ufb01ned radio (SDR) platforms. In this paper, we investigate and demonstrate the vulnerability of aircraft instrument landing systems to wireless attacks. We analyze the instrument landing sys-tem (ILS) waveforms\u2019 and show the feasibility of spoo\ufb01ng such radio signals using commercially-available SDR, causing last-minute go around decisions, and even missing the landing zone in low-visibility scenarios. We \ufb01rst show that it is possible to fully and in \ufb01ne-grain control the course deviation indicator, as displayed by the ILS receiver, in real-time , and demonstrate it on aviation-grade ILS receivers. We analyze the potential of both an overshadowing attack, and a lower-power single-tone attack. In order to evaluate the complete attack, we develop a tightly-controlled closed-loop ILS spoofer. It adjusts the adversary\u2019s transmitted signals as a function of the aircraft GPS location, maintaining power and deviation consistent with the adversary\u2019s target position, causing an undetected off-runway landing. We demonstrate the integrated attack on an FAA certi\ufb01ed \ufb02ight-simulator (X-Plane)incorporating a spoo\ufb01ng region detection mechanism, that triggers the controlled spoo\ufb01ng on entering the landing zone to reduce detectability. We systematically evaluate the performance of the attack against X-Plane\u2019s AI-based au-toland feature, and demonstrate systematic success rate with offset touchdowns of 18 meters to over 50 meters. Finally, we discuss approaches towards secure and ef\ufb01cient aircraft landing systems",
            "keywords": [
                "Aircraft Landing Systems",
                "Wireless Attacks",
                "Signal Spoofing",
                "Software-Defined Radio (SDR)",
                "Instrument Landing System Vulnerabilities"
            ]
        },
        "url": "URL#2767811",
        "sema_paperId": "4d9432ed7989f78cddc4a7e0d50ced6f01b21e3c"
    },
    {
        "@score": "1",
        "@id": "2767814",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "14/4412",
                        "text": "Yun Shen"
                    },
                    {
                        "@pid": "86/8823",
                        "text": "Gianluca Stringhini"
                    }
                ]
            },
            "title": "ATTACK2VEC: Leveraging Temporal Word Embeddings to Understand the Evolution of Cyberattacks.",
            "venue": "USENIX Security Symposium",
            "pages": "905-921",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ShenS19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/shen",
            "url": "https://dblp.org/rec/conf/uss/ShenS19",
            "abstract": "Despite the fact that cyberattacks are constantly growing in complexity, the research community still lacks effective tools to easily monitor and understand them. In particular, there is a need for techniques that are able to not only track how prominently certain malicious actions, such as the exploitation of specific vulnerabilities, are exploited in the wild, but also (and more importantly) how these malicious actions factor in as attack steps in more complex cyberattacks. In this paper we present ATTACK2VEC, a system that uses temporal word embeddings to model how attack steps are exploited in the wild, and track how they evolve. We test ATTACK2VEC on a dataset of billions of security events collected from the customers of a commercial Intrusion Prevention System over a period of two years, and show that our approach is effective in monitoring the emergence of new attack strategies in the wild and in flagging which attack steps are often used together by attackers (e.g., vulnerabilities that are frequently exploited together). ATTACK2VEC provides a useful tool for researchers and practitioners to better understand cyberattacks and their evolution, and use this knowledge to improve situational awareness and develop proactive defenses.",
            "keywords": [
                "Cyberattack Evolution",
                "Temporal Word Embeddings",
                "Malicious Actions",
                "Intrusion Prevention Systems",
                "Attack Step Monitoring"
            ]
        },
        "url": "URL#2767814",
        "sema_paperId": "be9158c8c5bb550b4ba3721df16eb716565d5da6"
    },
    {
        "@score": "1",
        "@id": "2767816",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "230/4243",
                        "text": "Anatoly Shusterman"
                    },
                    {
                        "@pid": "157/6029",
                        "text": "Lachlan Kang"
                    },
                    {
                        "@pid": "230/4186",
                        "text": "Yarden Haskal"
                    },
                    {
                        "@pid": "230/4310",
                        "text": "Yosef Meltser"
                    },
                    {
                        "@pid": "39/6266",
                        "text": "Prateek Mittal"
                    },
                    {
                        "@pid": "69/39",
                        "text": "Yossi Oren"
                    },
                    {
                        "@pid": "90/10901",
                        "text": "Yuval Yarom"
                    }
                ]
            },
            "title": "Robust Website Fingerprinting Through the Cache Occupancy Channel.",
            "venue": "USENIX Security Symposium",
            "pages": "639-656",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ShustermanKHMMO19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/shusterman",
            "url": "https://dblp.org/rec/conf/uss/ShustermanKHMMO19",
            "abstract": "Website fingerprinting attacks, which use statistical analysis on network\ntraffic to compromise user privacy, have been shown to be effective even if\nthe traffic is sent over anonymity-preserving networks such as Tor.  The\nclassical attack model used to evaluate website fingerprinting attacks\nassumes an on-path adversary, who can observe all traffic traveling\nbetween the user's computer and the secure network.\nIn this work we investigate these attacks under a different attack model, in\nwhich the adversary is capable of sending a small amount of malicious JavaScript code\nto the target user's computer.\nThe malicious code mounts a\ncache side-channel attack, which exploits the effects of contention on the\nCPU's cache, to identify other websites being browsed.\nThe effectiveness of this\nattack scenario has never been systematically analyzed, especially in the\nopen-world model which assumes that the user is visiting a mix of both\nsensitive and non-sensitive sites.\nWe show that cache website fingerprinting attacks in JavaScript\nare highly feasible.\nSpecifically, we use machine learning\ntechniques to classify traces of cache activity.  Unlike prior works, which\ntry to identify cache conflicts, our work measures the overall occupancy of\nthe last-level cache.  We show that our approach achieves high classification\naccuracy in both the open-world and the closed-world models. We further show\nthat our attack is more resistant than network-based fingerprinting to the\neffects of response caching, and that our techniques are resilient both to\nnetwork-based defenses and to side-channel countermeasures introduced to\nmodern browsers as a response to the Spectre attack.\nTo protect against\ncache-based website fingerprinting, new defense mechanisms must be introduced\nto privacy-sensitive browsers and websites.\nWe investigate one such mechanism, and show that generating artificial cache\nactivity reduces the effectiveness of the attack and completely eliminates it\nwhen used in the Tor Browser.",
            "pdf_url": "",
            "keywords": [
                "Website Fingerprinting",
                "Cache Side-Channel Attack",
                "User Privacy",
                "Malicious JavaScript",
                "Tor Browser Defense"
            ]
        },
        "url": "URL#2767816"
    },
    {
        "@score": "1",
        "@id": "2767817",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "157/2295",
                        "text": "Mridula Singh"
                    },
                    {
                        "@pid": "183/1273",
                        "text": "Patrick Leu"
                    },
                    {
                        "@pid": "157/0157",
                        "text": "AbdelRahman Abdou"
                    },
                    {
                        "@pid": "51/1639",
                        "text": "Srdjan Capkun"
                    }
                ]
            },
            "title": "UWB-ED: Distance Enlargement Attack Detection in Ultra-Wideband.",
            "venue": "USENIX Security Symposium",
            "pages": "73-88",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SinghLAC19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/singh",
            "url": "https://dblp.org/rec/conf/uss/SinghLAC19",
            "abstract": "Mobile autonomous systems, robots, and cyber-physical systems rely on accurate positioning information. To conduct distance-measurement, two devices exchange signals and, knowing these signals propagate at the speed of light, the time of arrival is used for distance estimations. Existing distance-measurement techniques are incapable of protecting against adversarial distance enlargement---a highly devastating tactic in which the adversary reissues a delayed version of the signals transmitted between devices, after distorting the authentic signal to prevent the receiver from identifying it. The adversary need not break crypto, nor compromise any upper-layer security protocols for mounting this attack. No known solution currently exists to protect against distance enlargement. We present \\textit{Ultra-Wideband Enlargement Detection} (UWB-ED), a new modulation technique to detect distance enlargement attacks, and securely verify distances between two mutually trusted devices. We analyze UWB-ED under an adversary that injects signals to block/modify authentic signals. We show how UWB-ED is a good candidate for 802.15.4z Low Rate Pulse and the 5G standard.",
            "pdf_url": "",
            "keywords": [
                "Ultra-Wideband Technology",
                "Distance Measurement",
                "Distance Enlargement Attack",
                "Signal Modulation",
                "Adversarial Detection"
            ]
        },
        "url": "URL#2767817"
    },
    {
        "@score": "1",
        "@id": "2767818",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "216/4321",
                        "text": "Pallavi Sivakumaran"
                    },
                    {
                        "@pid": "27/7270",
                        "text": "Jorge Blasco"
                    }
                ]
            },
            "title": "A Study of the Feasibility of Co-located App Attacks against BLE and a Large-Scale Analysis of the Current Application-Layer Security Landscape.",
            "venue": "USENIX Security Symposium",
            "pages": "1-18",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SivakumaranB19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/sivakumaran",
            "url": "https://dblp.org/rec/conf/uss/SivakumaranB19",
            "abstract": "Bluetooth Low Energy (BLE) is a fast-growing wireless technology with a large number of potential use cases, particularly in the IoT domain. Increasingly, these use cases require the storage of sensitive user data or critical device controls on the BLE device, as well as the access of this data by an augmentative mobile application. Uncontrolled access to such data could violate user privacy, cause a device to malfunction, or even endanger lives. The BLE standard provides security mechanisms such as pairing and bonding to protect sensitive data such that only authenticated devices can access it. In this paper we show how unauthorized co-located Android applications can access pairing-protected BLE data, without the user's knowledge. We discuss mitigation strategies in terms of the various stakeholders involved in this ecosystem, and argue that at present, the only possible option for securing BLE data is for BLE developers to implement remedial measures in the form of application-layer security between the BLE device and the Android application. We introduce BLECryptracer, a tool for identifying the presence of such application-layer security, and present the results of a large-scale static analysis over 18,900+ BLE-enabled Android applications. Our findings indicate that over 45% of these applications do not implement measures to protect BLE data, and that cryptography is sometimes applied incorrectly in those that do. This implies that a potentially large number of corresponding BLE peripheral devices are vulnerable to unauthorized data access.",
            "keywords": [
                "Bluetooth Low Energy (BLE)",
                "IoT Security",
                "Application-Layer Security",
                "Data Protection",
                "Unauthorized Access"
            ]
        },
        "url": "URL#2767818",
        "sema_paperId": "9f8927cfbd4c4de91946444f1f0c236465319235"
    },
    {
        "@score": "1",
        "@id": "2767819",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "179/8624",
                        "text": "Cristian-Alexandru Staicu"
                    },
                    {
                        "@pid": "25/2188",
                        "text": "Michael Pradel"
                    }
                ]
            },
            "title": "Leaky Images: Targeted Privacy Attacks in the Web.",
            "venue": "USENIX Security Symposium",
            "pages": "923-939",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/StaicuP19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/staicu",
            "url": "https://dblp.org/rec/conf/uss/StaicuP19",
            "abstract": "Sharing files with specific users is a popular service provided by various widely used websites, e.g., Facebook, Twitter, Google, and Dropbox. A common way to ensure that a shared file can only be accessed by a specific user is to authenticate the user upon a request for the file. This paper shows a novel way of abusing shared image files for targeted privacy attacks. In our attack, called leaky images, an image shared with a particular user reveals whether the user is visiting a specific website. The basic idea is simple yet effective: an attacker-controlled website requests a privately shared image, which will succeed only for the targeted user whose browser is logged into the website through which the image was shared. In addition to targeted privacy attacks aimed at single users, we discuss variants of the attack that allow an attacker to track a group of users and to link user identities across different sites. Leaky images require neither JavaScript nor CSS, exposing even privacy-aware users, who disable scripts in their browser, to the leak. Studying the most popular websites shows that the privacy leak affects at least eight of the 30 most popular websites that allow sharing of images between users, including the three most popular of all sites. We disclosed the problem to the affected sites, and most of them have been fixing the privacy leak in reaction to our reports. In particular, the two most popular affected sites, Facebook and Twitter, have already fixed the leaky images problem. To avoid leaky images, we discuss potential mitigation techniques that address the problem at the level of the browser and of the image sharing website.",
            "keywords": [
                "Privacy Attacks",
                "Image Sharing",
                "Leaky Images",
                "User Tracking",
                "Website Vulnerabilities"
            ]
        },
        "url": "URL#2767819",
        "sema_paperId": "f087ad43dc97d7ff8d89bb9355cab960d066769f"
    },
    {
        "@score": "1",
        "@id": "2767820",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "183/6724",
                        "text": "Milan Stute"
                    },
                    {
                        "@pid": "148/4618",
                        "text": "Sashank Narain"
                    },
                    {
                        "@pid": "248/1676",
                        "text": "Alex Mariotto"
                    },
                    {
                        "@pid": "248/1693",
                        "text": "Alexander Heinrich"
                    },
                    {
                        "@pid": "225/4652",
                        "text": "David Kreitschmann"
                    },
                    {
                        "@pid": "25/5432",
                        "text": "Guevara Noubir"
                    },
                    {
                        "@pid": "95/1816",
                        "text": "Matthias Hollick"
                    }
                ]
            },
            "title": "A Billion Open Interfaces for Eve and Mallory: MitM, DoS, and Tracking Attacks on iOS and macOS Through Apple Wireless Direct Link.",
            "venue": "USENIX Security Symposium",
            "pages": "37-54",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/StuteNMHKNH19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/stute",
            "url": "https://dblp.org/rec/conf/uss/StuteNMHKNH19",
            "abstract": "Apple Wireless Direct Link (AWDL) is a key protocol in Apple's ecosystem used by over one billion iOS and macOS devices for device-to-device communications. AWDL is a proprietary extension of the IEEE 802.11 (Wi-Fi) standard and integrates with Bluetooth Low Energy (BLE) for providing services such as Apple AirDrop. We conduct the first security and privacy analysis of AWDL and its integration with BLE. We uncover several security and privacy vulnerabilities ranging from design flaws to implementation bugs leading to a man-in-the-middle (MitM) attack enabling stealthy modification of files transmitted via AirDrop, denial-of-service (DoS) attacks preventing communication, privacy leaks that enable user identification and long-term tracking undermining MAC address randomization, and DoS attacks enabling targeted or simultaneous crashing of all neighboring devices. The flaws span across AirDrop's BLE discovery mechanism, AWDL synchronization, UI design, and Wi-Fi driver implementation. Our analysis is based on a combination of reverse engineering of protocols and code supported by analyzing patents. We provide proof-of-concept implementations and demonstrate that the attacks can be mounted using a low-cost ($20) micro:bit device and an off-the-shelf Wi-Fi card. We propose practical and effective countermeasures. While Apple was able to issue a fix for a DoS attack vulnerability after our responsible disclosure, the other security and privacy vulnerabilities require the redesign of some of their services.",
            "keywords": [
                "Apple Wireless Direct Link",
                "Security Vulnerabilities",
                "Man-in-the-Middle Attacks",
                "Denial-of-Service Attacks",
                "Privacy Leaks"
            ]
        },
        "url": "URL#2767820",
        "sema_paperId": "07910933ee364aa77391dd90b543396a08db9e21"
    },
    {
        "@score": "1",
        "@id": "2767821",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "35/11083",
                        "text": "Pawel Szalachowski"
                    },
                    {
                        "@pid": "35/8864",
                        "text": "Dani\u00ebl Reijsbergen"
                    },
                    {
                        "@pid": "171/6536",
                        "text": "Ivan Homoliak"
                    },
                    {
                        "@pid": "94/10123",
                        "text": "Siwei Sun"
                    }
                ]
            },
            "title": "StrongChain: Transparent and Collaborative Proof-of-Work Consensus.",
            "venue": "USENIX Security Symposium",
            "pages": "819-836",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SzalachowskiRHS19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/szalachowski",
            "url": "https://dblp.org/rec/conf/uss/SzalachowskiRHS19",
            "abstract": "Bitcoin is the most successful cryptocurrency so far. This is mainly due to its novel consensus algorithm, which is based on proof-of-work combined with a cryptographically-protected data structure and a rewarding scheme that incentivizes nodes to participate. However, despite its unprecedented success Bitcoin suffers from many inefficiencies. For instance, Bitcoin's consensus mechanism has been proved to be incentive-incompatible, its high reward variance causes centralization, and its hardcoded deflation raises questions about its long-term sustainability.In this work, we revise the Bitcoin consensus mechanism by proposing StrongChain, a scheme that introduces transparency and incentivizes participants to collaborate rather than to compete. The core design of our protocol is to reflect and utilize the computing power aggregated on the blockchain which is invisible and \"wasted\" in Bitcoin today. Introducing relatively easy, although important changes to Bitcoin's design enables us to improve many crucial aspects of Bitcoin-like cryptocurrencies making it more secure, efficient, and profitable for participants. We thoroughly analyze our approach and we present an implementation of StrongChain. The obtained results confirm its efficiency, security, and deployability.",
            "pdf_url": "",
            "keywords": [
                "Blockchain Consensus",
                "Proof-of-Work",
                "Incentive Compatibility",
                "Centralization",
                "Collaborative Participation"
            ]
        },
        "url": "URL#2767821"
    },
    {
        "@score": "1",
        "@id": "2767822",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "68/8283",
                        "text": "Kurt Thomas"
                    },
                    {
                        "@pid": "248/1673",
                        "text": "Jennifer Pullman"
                    },
                    {
                        "@pid": "176/7649",
                        "text": "Kevin Yeo"
                    },
                    {
                        "@pid": "15/7563",
                        "text": "Ananth Raghunathan"
                    },
                    {
                        "@pid": "15/3631",
                        "text": "Patrick Gage Kelley"
                    },
                    {
                        "@pid": "57/9185",
                        "text": "Luca Invernizzi"
                    },
                    {
                        "@pid": "155/5754",
                        "text": "Borbala Benko"
                    },
                    {
                        "@pid": "153/5776",
                        "text": "Tadek Pietraszek"
                    },
                    {
                        "@pid": "04/773",
                        "text": "Sarvar Patel"
                    },
                    {
                        "@pid": "b/DanBoneh",
                        "text": "Dan Boneh"
                    },
                    {
                        "@pid": "20/7004",
                        "text": "Elie Bursztein"
                    }
                ]
            },
            "title": "Protecting accounts from credential stuffing with password breach alerting.",
            "venue": "USENIX Security Symposium",
            "pages": "1556-1571",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ThomasPYRKIBPPB19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/thomas",
            "url": "https://dblp.org/rec/conf/uss/ThomasPYRKIBPPB19",
            "abstract": "Protecting accounts from credential stuffing attacks remains burdensome due to an asymmetry of knowledge: attackers have wide-scale access to billions of stolen usernames and passwords, while users and identity providers remain in the dark as to which accounts require remediation. In this paper, we propose a privacy-preserving protocol whereby a client can query a centralized breach repository to determine whether a specific username and password combination is publicly exposed, but without revealing the information queried. Here, a client can be an end user, a password manager, or an identity provider. To demonstrate the feasibility of our protocol, we implement a cloud service that mediates access to over 4 billion credentials found in breaches and a Chrome extension serving as an initial client. Based on anonymous telemetry from nearly 670,000 users and 21 million logins, we find that 1.5% of logins on the web involve breached credentials. By alerting users to this breach status, 26% of our warnings result in users migrating to a new password, at least as strong as the original. Our study illustrates how secure, democratized access to password breach alerting can help mitigate one dimension of account hijacking.",
            "keywords": [
                "Credential Stuffing",
                "Password Breach Alerting",
                "Privacy-Preserving Protocol",
                "Account Hijacking",
                "User Remediation"
            ]
        },
        "url": "URL#2767822",
        "sema_paperId": "91e3a48464aa937e43d70a63f942dd0b9f03af7d"
    },
    {
        "@score": "1",
        "@id": "2767823",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "25/2118-2",
                        "text": "Christopher Thompson 0002"
                    },
                    {
                        "@pid": "129/2184",
                        "text": "Martin Shelton"
                    },
                    {
                        "@pid": "56/7708",
                        "text": "Emily Stark 0001"
                    },
                    {
                        "@pid": "183/8121",
                        "text": "Max Walker"
                    },
                    {
                        "@pid": "248/1614",
                        "text": "Emily Schechter"
                    },
                    {
                        "@pid": "52/8024",
                        "text": "Adrienne Porter Felt"
                    }
                ]
            },
            "title": "The Web&apos;s Identity Crisis: Understanding the Effectiveness of Website Identity Indicators.",
            "venue": "USENIX Security Symposium",
            "pages": "1715-1732",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ThompsonSSWSF19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/thompson",
            "url": "https://dblp.org/rec/conf/uss/ThompsonSSWSF19",
            "abstract": "Users must understand the identity of the website that they are visiting in order to make trust decisions. Web browsers indicate website identity via URLs and HTTPS certi\ufb01cates, but users must understand and act on these indicators for them to be effective. In this paper, we explore how browser identity indicators affect user behavior and understanding. First, we present a large-scale \ufb01eld experiment measuring the effects of the HTTPS Extended Validation (EV) certi\ufb01-cate UI on user behavior. Our experiment is many orders of magnitude larger than any prior study of EV indicators, and it is the \ufb01rst to examine the EV indicator in a naturalistic scenario. We \ufb01nd that most metrics of user behavior are unaffected by its removal, providing evidence that the EV indicator adds little value in its current form. Second, we conduct three experimental design surveys to understand how users perceive UI variations in identity indicators for login pages, looking at EV UI in Chrome and Safari and URL formatting designs in Chrome. In 14 iterations on browsers\u2019 EV and URL formats, no intervention signi\ufb01cantly impacted users\u2019 understanding of the security or identity of login pages. In-formed by our experimental results, we provide recommendations to build more effective website identity mechanisms.",
            "keywords": [
                "Website Identity Indicators",
                "User Trust Decisions",
                "HTTPS Extended Validation",
                "User Behavior Analysis",
                "Identity Perception in Browsers"
            ]
        },
        "url": "URL#2767823",
        "sema_paperId": "3710bbefb31d3a4efb8d2df52d1823330de60924"
    },
    {
        "@score": "1",
        "@id": "2767824",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "71/6379",
                        "text": "Liang Tong"
                    },
                    {
                        "@pid": "50/3402-26",
                        "text": "Bo Li 0026"
                    },
                    {
                        "@pid": "133/1819",
                        "text": "Chen Hajaj"
                    },
                    {
                        "@pid": "150/3317",
                        "text": "Chaowei Xiao"
                    },
                    {
                        "@pid": "181/2597-17",
                        "text": "Ning Zhang 0017"
                    },
                    {
                        "@pid": "70/2217",
                        "text": "Yevgeniy Vorobeychik"
                    }
                ]
            },
            "title": "Improving Robustness of ML Classifiers against Realizable Evasion Attacks Using Conserved Features.",
            "venue": "USENIX Security Symposium",
            "pages": "285-302",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Tong0HXZV19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/tong",
            "url": "https://dblp.org/rec/conf/uss/Tong0HXZV19",
            "abstract": "Machine learning (ML) techniques are increasingly common in security applications, such as malware and intrusion detection. However, ML models are often susceptible to evasion attacks, in which an adversary makes changes to the input (such as malware) in order to avoid being detected. A conventional approach to evaluate ML robustness to such attacks, as well as to design robust ML, is by considering simplified feature-space models of attacks, where the attacker changes ML features directly to effect evasion, while minimizing or constraining the magnitude of this change. We investigate the effectiveness of this approach to designing robust ML in the face of attacks that can be realized in actual malware (realizable attacks). We demonstrate that in the context of structure-based PDF malware detection, such techniques appear to have limited effectiveness, but they are effective with content-based detectors. In either case, we show that augmenting the feature space models with conserved features (those that cannot be unilaterally modified without compromising malicious functionality) significantly improves performance. Finally, we show that feature space models enable generalized robustness when faced with a variety of realizable attacks, as compared to classifiers which are tuned to be robust to a specific realizable attack.",
            "keywords": [
                "Evasion Attacks",
                "Malware Detection",
                "Feature Space Models",
                "Robustness Improvement",
                "Conserved Features"
            ]
        },
        "url": "URL#2767824",
        "sema_paperId": "9964797f0d3912912cace8a5ffe95c0db4efbd0b"
    },
    {
        "@score": "1",
        "@id": "2767825",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "185/1711",
                        "text": "Santiago Torres-Arias"
                    },
                    {
                        "@pid": "220/2550",
                        "text": "Hammad Afzali"
                    },
                    {
                        "@pid": "44/8573",
                        "text": "Trishank Karthik Kuppusamy"
                    },
                    {
                        "@pid": "c/RezaCurtmola",
                        "text": "Reza Curtmola"
                    },
                    {
                        "@pid": "27/5136",
                        "text": "Justin Cappos"
                    }
                ]
            },
            "title": "in-toto: Providing farm-to-table guarantees for bits and bytes.",
            "venue": "USENIX Security Symposium",
            "pages": "1393-1410",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Torres-AriasAKC19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/torres-arias",
            "url": "https://dblp.org/rec/conf/uss/Torres-AriasAKC19",
            "abstract": "The software development process is quite complex and involves a number of independent actors. Developers check source code into a version control system, the code is compiled into software at a build farm, and CI/CD systems run multiple tests to ensure the software\u2019s quality among a myriad of other operations. Finally, the software is packaged for distribution into a delivered product, to be consumed by end users. An attacker that is able to compromise any single step in the process can maliciously modify the software and harm any of the software\u2019s users. To address these issues, we designed in-toto, a framework that cryptographically ensures the integrity of the software supply chain. in-toto grants the end user the ability to verify the software\u2019s supply chain from the project\u2019s inception to its deployment. We demonstrate in-toto\u2019s effectiveness on 30 software supply chain compromises that affected hundreds of million of users and showcase in-toto\u2019s usage over cloud-native, hybrid-cloud and cloudagnostic applications. in-toto is integrated into products and open source projects that are used by millions of people daily. The project website is available at: https://in-toto.io.",
            "keywords": [
                "Software Supply Chain Integrity",
                "Cryptographic Assurance",
                "Supply Chain Compromise",
                "End User Verification",
                "Cloud-native Applications"
            ]
        },
        "url": "URL#2767825",
        "sema_paperId": "1399ede2b4c42fee1812f6f41215bd34d915c98d"
    },
    {
        "@score": "1",
        "@id": "2767826",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "169/2279",
                        "text": "Christof Ferreira Torres"
                    },
                    {
                        "@pid": "210/6374",
                        "text": "Mathis Steichen"
                    },
                    {
                        "@pid": "05/6228",
                        "text": "Radu State"
                    }
                ]
            },
            "title": "The Art of The Scam: Demystifying Honeypots in Ethereum Smart Contracts.",
            "venue": "USENIX Security Symposium",
            "pages": "1591-1607",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/TorresSS19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/ferreira",
            "url": "https://dblp.org/rec/conf/uss/TorresSS19",
            "abstract": "Modern blockchains, such as Ethereum, enable the execution of so-called smart contracts \u2013 programs that are executed across a decentralised network of nodes. As smart contracts become more popular and carry more value, they become more of an interesting target for attackers. In the past few years, several smart contracts have been exploited by attackers. However, a new trend towards a more proactive approach seems to be on the rise, where attackers do not search for vulnerable contracts anymore. Instead, they try to lure their victims into traps by deploying seemingly vulnerable contracts that contain hidden traps. This new type of contracts is commonly referred to as honeypots. In this paper, we present the first systematic analysis of honeypot smart contracts, by investigating their prevalence, behaviour and impact on the Ethereum blockchain. We develop a taxonomy of honeypot techniques and use this to build HoneyBadger \u2013 a tool that employs symbolic execution and well defined heuristics to expose honeypots. We perform a large-scale analysis on more than 2 million smart contracts and show that our tool not only achieves high precision, but is also highly efficient. We identify 690 honeypot smart contracts as well as 240 victims in the wild, with an accumulated profit of more than $90,000 for the honeypot creators. Our manual validation shows that 87% of the reported contracts are indeed honeypots.",
            "pdf_url": "",
            "keywords": [
                "Ethereum Smart Contracts",
                "Honeypots",
                "Smart Contract Exploitation",
                "Victim Analysis",
                "HoneyBadger Tool"
            ]
        },
        "url": "URL#2767826"
    },
    {
        "@score": "1",
        "@id": "2767827",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "196/8835",
                        "text": "Erik Trickel"
                    },
                    {
                        "@pid": "134/8950",
                        "text": "Oleksii Starov"
                    },
                    {
                        "@pid": "22/1459",
                        "text": "Alexandros Kapravelos"
                    },
                    {
                        "@pid": "04/8280",
                        "text": "Nick Nikiforakis"
                    },
                    {
                        "@pid": "28/8280",
                        "text": "Adam Doup\u00e9"
                    }
                ]
            },
            "title": "Everyone is Different: Client-side Diversification for Defending Against Extension Fingerprinting.",
            "venue": "USENIX Security Symposium",
            "pages": "1679-1696",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/TrickelSKND19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/trickel",
            "url": "https://dblp.org/rec/conf/uss/TrickelSKND19",
            "abstract": "Browser fingerprinting refers to the extraction of attributes from a user\u2019s browser which can be combined into a nearunique fingerprint. These fingerprints can be used to reidentify users without requiring the use of cookies or other stateful identifiers. Browser extensions enhance the clientside browser experience; however, prior work has shown that their website modifications are fingerprintable and can be used to infer sensitive information about users. In this paper we present CloakX, the first client-side antifingerprinting countermeasure that works without requiring browser modification or requiring extension developers to modify their code. CloakX uses client-side diversification to prevent extension detection using anchorprints (fingerprints comprised of artifacts directly accessible to any webpage) and to reduce the accuracy of extension detection using structureprints (fingerprints built from an extension\u2019s behavior). Despite the complexity of browser extensions, CloakX automatically incorporates client-side diversification into the extensions and maintains equivalent functionality through the use of static and dynamic program analysis. We evaluate the efficacy of CloakX on 18,937 extensions using large-scale automated analysis and in-depth manual testing. We conducted experiments to test the functionality equivalence, the detectability, and the performance of CloakX-enabled extensions. Beyond extension detection, we demonstrate that client-side modification of extensions is a viable method for the late-stage customization of browser extensions.",
            "keywords": [
                "Browser Fingerprinting",
                "Client-side Diversification",
                "Antifingerprinting",
                "Browser Extensions",
                "Extension Detection"
            ]
        },
        "url": "URL#2767827",
        "sema_paperId": "911655e27e50a02e46f01e7e3b78ee2c31d1873d"
    },
    {
        "@score": "1",
        "@id": "2767828",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "83/11208",
                        "text": "Shin-Yeh Tsai"
                    },
                    {
                        "@pid": "31/1273",
                        "text": "Mathias Payer"
                    },
                    {
                        "@pid": "64/3770-5",
                        "text": "Yiying Zhang 0005"
                    }
                ]
            },
            "title": "Pythia: Remote Oracles for the Masses.",
            "venue": "USENIX Security Symposium",
            "pages": "693-710",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/TsaiPZ19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/tsai",
            "url": "https://dblp.org/rec/conf/uss/TsaiPZ19",
            "abstract": "Remote Direct Memory Access (RDMA) is a technology that allows direct access from the network to a machine\u2019s main memory without involving its CPU. RDMA offers lowlatency, high-bandwidth performance and low CPU utilization. While RDMA provides massive performance boosts and has thus been adopted by several major cloud providers, security concerns have so far been neglected. The need for RDMA NICs to bypass CPU and directly access memory results in them storing various metadata like page table entries in their on-board SRAM. When the SRAM is full, RNICs swap metadata to main memory across the PCIe bus. We exploit the resulting timing difference to establish side channels and demonstrate that these side channels can leak access patterns of victim nodes to other nodes. We design Pythia, a set of RDMA-based remote sidechannel attacks that allow an attacker on one client machine to learn how victims on other client machines access data a server exports as an in-memory data service. We reverse engineer the memory architecture of the most widely used RDMA NIC and use this knowledge to improve the efficiency of Pythia. We further extend Pythia to build side-channel attacks on Crail, a real RDMA-based key-value store application. We evaluated Pythia on four different RDMA NICs both in a laboratory and in a public cloud setting. Pythia is fast (57 \u03bcs), accurate (97% accuracy), and can hide all its traces from the victim or the server.",
            "keywords": [
                "Remote Direct Memory Access (RDMA)",
                "Side-Channel Attacks",
                "Memory Architecture Exploitation",
                "Data Access Patterns",
                "Pythia"
            ]
        },
        "url": "URL#2767828",
        "sema_paperId": "b1e47fcc622f012a5b5bfbf24fff650f19e9b89f"
    },
    {
        "@score": "1",
        "@id": "2767829",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "184/6108",
                        "text": "Huahong Tu"
                    },
                    {
                        "@pid": "28/8280",
                        "text": "Adam Doup\u00e9"
                    },
                    {
                        "@pid": "11/7704-1",
                        "text": "Ziming Zhao 0001"
                    },
                    {
                        "@pid": "a/GailJoonAhn",
                        "text": "Gail-Joon Ahn"
                    }
                ]
            },
            "title": "Users Really Do Answer Telephone Scams.",
            "venue": "USENIX Security Symposium",
            "pages": "1327-1340",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/TuD0A19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/tu",
            "url": "https://dblp.org/rec/conf/uss/TuD0A19",
            "abstract": "As telephone scams become increasingly prevalent, it is crucial to understand what causes recipients to fall victim to these scams. Armed with this knowledge, effective countermeasures can be developed to challenge the key foundations of successful telephone phishing attacks. In this paper, we present the methodology, design, execution, results, and evaluation of an ethical telephone phishing scam. The study performed 10 telephone phishing experiments on 3,000 university participants without prior awareness over the course of a workweek. Overall, we were able to identify at least one key factor\u2014spoofed Caller ID\u2014that had a significant effect in tricking the victims into revealing their Social Security number.",
            "keywords": [
                "Telephone Scams",
                "Phishing Attacks",
                "Caller ID Spoofing",
                "Social Security Number Disclosure",
                "Ethical Experimentation"
            ]
        },
        "url": "URL#2767829",
        "sema_paperId": "56590833ba063cae1766cd82c6a3721a65784ce3"
    },
    {
        "@score": "1",
        "@id": "2767830",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "161/0161",
                        "text": "Anjo Vahldiek-Oberwagner"
                    },
                    {
                        "@pid": "13/10811",
                        "text": "Eslam Elnikety"
                    },
                    {
                        "@pid": "163/1553",
                        "text": "Nuno O. Duarte"
                    },
                    {
                        "@pid": "248/1613",
                        "text": "Michael Sammler"
                    },
                    {
                        "@pid": "d/PDruschel",
                        "text": "Peter Druschel"
                    },
                    {
                        "@pid": "45/6786-1",
                        "text": "Deepak Garg 0001"
                    }
                ]
            },
            "title": "ERIM: Secure, Efficient In-process Isolation with Protection Keys (MPK).",
            "venue": "USENIX Security Symposium",
            "pages": "1221-1238",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Vahldiek-Oberwagner19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/vahldiek-oberwagner",
            "url": "https://dblp.org/rec/conf/uss/Vahldiek-Oberwagner19",
            "abstract": "Isolating sensitive state and data can increase the security and robustness of many applications. Examples include protecting cryptographic keys against exploits like OpenSSL\u2019s Heartbleed bug or protecting a language runtime from native libraries written in unsafe languages. When runtime references across isolation boundaries occur relatively infrequently, then conventional page-based hardware isolation can be used, because the cost of kernelor hypervisormediated domain switching is tolerable. However, some applications, such as the isolation of cryptographic session keys in network-facing services, require very frequent domain switching. In such applications, the overhead of kernelor hypervisor-mediated domain switching is prohibitive. In this paper, we present ERIM, a novel technique that provides hardware-enforced isolation with low overhead on x86 CPUs, even at high switching rates (ERIM\u2019s measured overhead is less than 1% for 100,000 switches per second). The key idea is to combine protection keys (MPKs), a feature recently added to x86 that allows protection domain switches in userspace, with binary inspection to prevent circumvention. We show that ERIM can be applied with little effort to new and existing applications, doesn\u2019t require compiler changes, can run on a stock Linux kernel, and has low runtime overhead even at high domain switching rates.",
            "keywords": [
                "Hardware Isolation",
                "Protection Keys",
                "Domain Switching",
                "Runtime Security",
                "Low Overhead Isolation"
            ]
        },
        "url": "URL#2767830",
        "sema_paperId": "a8bfd78632a24974c5b40b4e4eb3bc15454984e1"
    },
    {
        "@score": "1",
        "@id": "2767831",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "60/8494",
                        "text": "Xueqiang Wang"
                    },
                    {
                        "@pid": "139/7955",
                        "text": "Yuqiong Sun"
                    },
                    {
                        "@pid": "07/1026",
                        "text": "Susanta Nanda"
                    },
                    {
                        "@pid": "06/6268",
                        "text": "XiaoFeng Wang 0001"
                    }
                ]
            },
            "title": "Looking from the Mirror: Evaluating IoT Device Security through Mobile Companion Apps.",
            "venue": "USENIX Security Symposium",
            "pages": "1151-1167",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WangSN019",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/wang-xueqiang",
            "url": "https://dblp.org/rec/conf/uss/WangSN019",
            "abstract": "Smart home IoT devices have increasingly become a favorite target for the cybercriminals due to their weak security designs. To identify these vulnerable devices, existing approaches rely on the analysis of either real devices or their firmware images. These approaches, unfortunately, are difficult to scale in the highly fragmented IoT market due to the unavailability of firmware images and the high cost involved in acquiring real-world devices for security analysis. In this paper, we present a platform that accelerates vulnerable device discovery and analysis, without requiring the presence of actual devices or firmware. Our approach is based on two key observations: First, IoT devices tend to reuse and customize others\u2019 components (e.g., software, hardware, protocol, and services), so vulnerabilities found in one device are often present in others. Second, reused components can be indirectly inferred from the mobile companion apps of the devices; so a cross analysis of mobile companion apps may allow us to approximate the similarity between devices. Using a suite of program analysis techniques, our platform analyzes mobile companion apps of smart home IoT devices on market and automatically discovers potentially vulnerable ones, allowing us to perform a large-scale analysis involving over 4,700 devices. Our study brings to light the sharing of vulnerable components across the smart home IoT devices (e.g., shared vulnerable protocol, backend services, device rebranding), and leads to the discovery of 324 devices from 73 different vendors that are likely to be vulnerable to a set of security issues.",
            "keywords": [
                "IoT Device Security",
                "Mobile Companion Apps",
                "Vulnerability Discovery",
                "Component Reuse",
                "Smart Home Devices"
            ]
        },
        "url": "URL#2767831",
        "sema_paperId": "11b331a79ed9ea8c634cd630ef184ee0c52f2be9"
    },
    {
        "@score": "1",
        "@id": "2767832",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "75/3158-17",
                        "text": "Zhe Wang 0017"
                    },
                    {
                        "@pid": "51/3529-2",
                        "text": "Chenggang Wu 0002"
                    },
                    {
                        "@pid": "77/3503",
                        "text": "Yinqian Zhang"
                    },
                    {
                        "@pid": "220/9587",
                        "text": "Bowen Tang"
                    },
                    {
                        "@pid": "y/PenChungYew",
                        "text": "Pen-Chung Yew"
                    },
                    {
                        "@pid": "190/5112",
                        "text": "Mengyao Xie"
                    },
                    {
                        "@pid": "198/8150",
                        "text": "Yuanming Lai"
                    },
                    {
                        "@pid": "32/1654-2",
                        "text": "Yan Kang 0002"
                    },
                    {
                        "@pid": "15/8296",
                        "text": "Yueqiang Cheng"
                    },
                    {
                        "@pid": "143/4573-2",
                        "text": "Zhiping Shi 0002"
                    }
                ]
            },
            "title": "SafeHidden: An Efficient and Secure Information Hiding Technique Using Re-randomization.",
            "venue": "USENIX Security Symposium",
            "pages": "1239-1256",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WangWZTYXLKCS19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/wang",
            "url": "https://dblp.org/rec/conf/uss/WangWZTYXLKCS19",
            "abstract": "Information hiding (IH) is an important building block for many defenses against code reuse attacks, such as codepointer integrity (CPI), control-flow integrity (CFI) and finegrained code (re-)randomization, because of its effectiveness and performance. It employs randomization to probabilistically \u201chide\u201d sensitive memory areas, called safe areas, from attackers and ensures their addresses are not leaked by any pointers directly. These defenses used safe areas to protect their critical data, such as jump targets and randomization secrets. However, recent works have shown that IH is vulnerable to various attacks. In this paper, we propose a new IH technique called SafeHidden. It continuously re-randomizes the locations of safe areas and thus prevents the attackers from probing and inferring the memory layout to find its location. A new threadprivate memory mechanism is proposed to isolate the threadlocal safe areas and prevent adversaries from reducing the randomization entropy. It also randomizes the safe areas after the TLB misses to prevent attackers from inferring the address of safe areas using cache side-channels. Existing IH-based defenses can utilize SafeHidden directly without any change. Our experiments show that SafeHidden not only prevents existing attacks effectively but also incurs low performance overhead.",
            "keywords": [
                "Information Hiding",
                "Memory Randomization",
                "Code Reuse Attacks",
                "Safe Areas",
                "Cache Side-Channels"
            ]
        },
        "url": "URL#2767832",
        "sema_paperId": "e6315c85d0e83727be327ea04ed3203a5c168530"
    },
    {
        "@score": "1",
        "@id": "2767833",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "59/8645",
                        "text": "Mario Werner"
                    },
                    {
                        "@pid": "138/3344",
                        "text": "Thomas Unterluggauer"
                    },
                    {
                        "@pid": "212/6725",
                        "text": "Lukas Giner"
                    },
                    {
                        "@pid": "08/1117-1",
                        "text": "Michael Schwarz 0001"
                    },
                    {
                        "@pid": "166/1494",
                        "text": "Daniel Gruss"
                    },
                    {
                        "@pid": "91/4831",
                        "text": "Stefan Mangard"
                    }
                ]
            },
            "title": "ScatterCache: Thwarting Cache Attacks via Cache Set Randomization.",
            "venue": "USENIX Security Symposium",
            "pages": "675-692",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WernerUG0GM19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/werner",
            "url": "https://dblp.org/rec/conf/uss/WernerUG0GM19",
            "abstract": "Cache side-channel attacks can be leveraged as a building block in attacks leaking secrets even in the absence of software bugs. Currently, there are no practical and generic mitigations with an acceptable performance overhead and strong security guarantees. The underlying problem is that caches are shared in a predictable way across security domains. In this paper, we eliminate this problem. We present SCATTERCACHE, a novel cache design to prevent cache attacks. SCATTERCACHE eliminates fixed cache-set congruences and, thus, makes eviction-based cache attacks unpractical. For this purpose, SCATTERCACHE retrofits skewed associative caches with a keyed mapping function, yielding a security-domaindependent cache mapping. Hence, it becomes virtually impossible to find fully overlapping cache sets, rendering current eviction-based attacks infeasible. Even theoretical statistical attacks become unrealistic, as the attacker cannot confine contention to chosen cache sets. Consequently, the attacker has to resort to eviction of the entire cache, making deductions over cache sets or lines impossible and fully preventing highfrequency attacks. Our security analysis reveals that even in the strongest possible attacker model (noise-free), the construction of a reliable eviction set for PRIME+PROBE in an 8way SCATTERCACHE with 16384 lines requires observation of at least 33.5 million victim memory accesses as compared to fewer than 103 on commodity caches. SCATTERCACHE requires hardware and software changes, yet is minimally invasive on the software level and is fully backward compatible with legacy software while still improving the security level over state-of-the-art caches. Finally, our evaluations show that the runtime performance of software is not curtailed and our design even outperforms state-of-the-art caches for certain realistic workloads.",
            "keywords": [
                "Cache Side-Channel Attacks",
                "Cache Design",
                "Cache Set Randomization",
                "Eviction-Based Attacks",
                "Skewed Associative Caches"
            ]
        },
        "url": "URL#2767833",
        "sema_paperId": "7d654a0b6fb6acced9fa87d2d385358f328e27bb"
    },
    {
        "@score": "1",
        "@id": "2767834",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "95/6985",
                        "text": "Wei Wu"
                    },
                    {
                        "@pid": "16/6884-1",
                        "text": "Yueqi Chen 0001"
                    },
                    {
                        "@pid": "40/6431",
                        "text": "Xinyu Xing"
                    },
                    {
                        "@pid": "10/328",
                        "text": "Wei Zou"
                    }
                ]
            },
            "title": "KEPLER: Facilitating Control-flow Hijacking Primitive Evaluation for Linux Kernel Vulnerabilities.",
            "venue": "USENIX Security Symposium",
            "pages": "1187-1204",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WuCXZ19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/wu-wei",
            "url": "https://dblp.org/rec/conf/uss/WuCXZ19",
            "abstract": "Automatic exploit generation is a challenging problem. A challenging part of the task is to connect an identified exploitable state (exploit primitive) to trigger execution of codereuse (e.g., ROP) payload. A control-flow hijacking primitive is one of the most common capabilities for exploitation. However, due to the challenges of widely deployed exploit mitigations, pitfalls along an exploit path, and ill-suited primitives, it is difficult to even manually craft an exploit with a control-flow hijacking primitive for an off-the-shelf modern Linux kernel. We propose KEPLER to facilitate exploit generation by automatically generating a \u201csingle-shot\u201d exploitation chain. KEPLER accepts as input a control-flow hijacking primitive and bootstraps any kernel ROP payload by symbolically stitching an exploit chain taking advantage of prevalent kernel coding style and corresponding gadgets. Comparisons with previous automatic exploit generation techniques and previous kernel exploit techniques show KEPLER effectively facilitates evaluation of control-flow hijacking primitives in the Linux kernel.",
            "keywords": [
                "Kernel Exploitation",
                "Control-flow Hijacking",
                "Automatic Exploit Generation",
                "ROP Payload",
                "Linux Kernel Vulnerabilities"
            ]
        },
        "url": "URL#2767834",
        "sema_paperId": "a3ab15f214e644947bf34a4689b6438cc477174e"
    },
    {
        "@score": "1",
        "@id": "2767835",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "205/3035",
                        "text": "Shujiang Wu"
                    },
                    {
                        "@pid": "67/2580-6",
                        "text": "Song Li 0006"
                    },
                    {
                        "@pid": "28/8733",
                        "text": "Yinzhi Cao"
                    },
                    {
                        "@pid": "232/2229",
                        "text": "Ningfei Wang"
                    }
                ]
            },
            "title": "Rendered Private: Making GLSL Execution Uniform to Prevent WebGL-based Browser Fingerprinting.",
            "venue": "USENIX Security Symposium",
            "pages": "1645-1660",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WuLCW19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/wu",
            "url": "https://dblp.org/rec/conf/uss/WuLCW19",
            "abstract": "Browser fingerprinting, a substitute of cookies-based tracking, extracts a list of client-side features and combines them as a unique identifier for the target browser. Among all these features, one that has the highest entropy and the ability for an even sneakier purpose, i.e., cross-browser fingerprinting, is the rendering of WebGL tasks, which produce different results across different installations of the same browser on different computers, thus being considered as fingerprintable. Such WebGL-based fingerprinting is hard to defend against, because the client browser executes a program written in OpenGL Shading Language (GLSL). To date, it remains unclear, in either the industry or the research community, about how and why the rendering of GLSL programs could lead to result discrepancies. Therefore, all the existing defenses, such as these adopted by Tor Browser, can only disable WebGL, i.e., a sacrifice of functionality over privacy, to prevent WebGL-based fingerprinting. In this paper, we propose a novel system, called UNIGL, to rewrite GLSL programs and make uniform WebGL rendering procedure with the support of existing WebGL functionalities. Particularly, we, being the first in the community, point out that such rendering discrepancies in state-of-the-art WebGLbased fingerprinting are caused by floating-point operations. After realizing the cause, we design UNIGL so that it redefines all the floating-point operations, either explicitly written in GLSL programs or implicitly invoked by WebGL, to mitigate the fingerprinting factors. We implemented a prototype of UNIGL as an open-source browser add-on (https://www.github.com/unigl/). We also created a demo website (http://test.unigl.org/), i.e., a modified version of an existing fingerprinting website, which directly integrates our add-on at the server-side to demonstrate the effectiveness of UNIGL. Our evaluation using crowdsourcing workers shows that UNIGL can prevent state-of-the-art WebGL-based fingerprinting with reasonable FPSes. \u2217The last author, Ningfei Wang, contributed to the paper when he was a master student financially supported and mentored by Dr. Yinzhi Cao.",
            "keywords": [
                "WebGL Fingerprinting",
                "GLSL Execution",
                "Privacy Protection",
                "Floating-Point Operations",
                "UNIGL System"
            ]
        },
        "url": "URL#2767835",
        "sema_paperId": "0db6eb66369dea0fba7ceadea88688c772fac76f"
    },
    {
        "@score": "1",
        "@id": "2767836",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "177/8598",
                        "text": "Qixue Xiao"
                    },
                    {
                        "@pid": "79/4489-1",
                        "text": "Yufei Chen 0001"
                    },
                    {
                        "@pid": "48/4825-1",
                        "text": "Chao Shen 0001"
                    },
                    {
                        "@pid": "87/1254-4",
                        "text": "Yu Chen 0004"
                    },
                    {
                        "@pid": "l/KangLi1",
                        "text": "Kang Li 0001"
                    }
                ]
            },
            "title": "Seeing is Not Believing: Camouflage Attacks on Image Scaling Algorithms.",
            "venue": "USENIX Security Symposium",
            "pages": "443-460",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/XiaoCS0019",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/xiao",
            "url": "https://dblp.org/rec/conf/uss/XiaoCS0019",
            "abstract": "Image scaling algorithms are intended to preserve the visual features before and after scaling, which is commonly used in numerous visual and image processing applications. In this paper, we demonstrate an automated attack against common scaling algorithms, i.e. to automatically generate camouflage images whose visual semantics change dramatically after scaling. To illustrate the threats from such camouflage attacks, we choose several computer vision applications as targeted victims, including multiple image classification applications based on popular deep learning frameworks, as well as mainstream web browsers. Our experimental results show that such attacks can cause different visual results after scaling and thus create evasion or data poisoning effect to these victim applications. We also present an algorithm that can successfully enable attacks against famous cloud-based image services (such as those from Microsoft Azure, Aliyun, Baidu, and Tencent) and cause obvious misclassification effects, even when the details of image processing (such as the exact scaling algorithm and scale dimension parameters) are hidden in the cloud. To defend against such attacks, this paper suggests a few potential countermeasures from attack prevention to detection.",
            "keywords": [
                "Image Scaling Algorithms",
                "Camouflage Attacks",
                "Visual Semantics",
                "Data Poisoning",
                "Evasion Techniques"
            ]
        },
        "url": "URL#2767836",
        "sema_paperId": "269c1bf9e9bd49e022453a2a72508fb57b7fc0db"
    },
    {
        "@score": "1",
        "@id": "2767838",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "59/8279",
                        "text": "Xiaoyang Xu"
                    },
                    {
                        "@pid": "248/1599",
                        "text": "Masoud Ghaffarinia"
                    },
                    {
                        "@pid": "57/9813",
                        "text": "Wenhao Wang"
                    },
                    {
                        "@pid": "60/1400",
                        "text": "Kevin W. Hamlen"
                    },
                    {
                        "@pid": "49/4102-1",
                        "text": "Zhiqiang Lin 0001"
                    }
                ]
            },
            "title": "CONFIRM: Evaluating Compatibility and Relevance of Control-flow Integrity Protections for Modern Software.",
            "venue": "USENIX Security Symposium",
            "pages": "1805-1821",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/XuGWHL19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/xu-xiaoyang",
            "url": "https://dblp.org/rec/conf/uss/XuGWHL19",
            "abstract": "Xiaoyang Xu, Masoud Ghaffarinia, Wenhao Wang, Kevin W. Hamlen, and Zhiqiang Lin. \u201cCONFIRM: Evaluating Compatibility and Relevance of Control-flow Integrity Protections for Modern Software.\u201d In Proc. 28th USENIX Security Symposium, August 2019. CONFIRM (CONtrol-Flow Integrity Relevance Metrics) is a new evaluation methodology and microbenchmarking suite for assessing compatibility, applicability, and relevance of control-flow integrity (CFI) protections for preserving the intended semantics of software while protecting it from abuse. Although CFI has become a mainstay of protecting certain classes of software from code-reuse attacks, and continues to be improved by ongoing research, its ability to preserve intended program functionalities (semantic transparency) of diverse, mainstream software products has been under-studied in the literature. This is in part because although CFI solutions are evaluated in terms of performance and security, there remains no standard regimen for assessing compatibility. Researchers must often therefore resort to anecdotal assessments, consisting of tests on homogeneous software collections with limited variety (e.g., GNU Coreutils), or on CPU benchmarks (e.g., SPEC) whose limited code features are not representative of large, mainstream software products. Reevaluation of CFI solutions using CONFIRM reveals that there remain significant unsolved challenges in securing many large classes of software products with CFI, including software for market-dominant OSes (e.g., Windows) and code employing certain ubiquitous coding idioms (e.g., eventdriven callbacks and exceptions). An estimated 47% of CFIrelevant code features with high compatibility impact remain incompletely supported by existing CFI algorithms, or receive weakened controls that leave prevalent threats unaddressed (e.g., return-oriented programming attacks). Discussion of these open problems highlights issues that future research must address to bridge these important gaps between CFI theory and practice.",
            "keywords": [
                "Control-Flow Integrity",
                "Software Compatibility",
                "Semantic Transparency",
                "Code-Reuse Attacks",
                "CFI Evaluation Metrics"
            ]
        },
        "url": "URL#2767838",
        "sema_paperId": "b4adca8938a7cca3b06064f1c0673a6b720dc905"
    },
    {
        "@score": "1",
        "@id": "2767839",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "200/0316",
                        "text": "Jiahua Xu"
                    },
                    {
                        "@pid": "46/2924",
                        "text": "Benjamin Livshits"
                    }
                ]
            },
            "title": "The Anatomy of a Cryptocurrency Pump-and-Dump Scheme.",
            "venue": "USENIX Security Symposium",
            "pages": "1609-1625",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/XuL19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/xu-jiahua",
            "url": "https://dblp.org/rec/conf/uss/XuL19",
            "abstract": "While pump-and-dump schemes have attracted the attention of cryptocurrency observers and regulators alike, this paper represents the first detailed empirical query of pump-and-dump activities in cryptocurrency markets. We present a case study of a recent pump-and-dump event, investigate 412 pump-and-dump activities organized in Telegram channels from June 17, 2018 to February 26, 2019, and discover patterns in crypto-markets associated with pump-and-dump schemes. We then build a model that predicts the pump likelihood of all coins listed in a crypto-exchange prior to a pump. The model exhibits high precision as well as robustness, and can be used to create a simple, yet very effective trading strategy, which we empirically demonstrate can generate a return as high as 60% on small retail investments within a span of two and half months. The study provides a proof of concept for strategic crypto-trading and sheds light on the application of machine learning for crime detection.",
            "pdf_url": "",
            "keywords": [
                "Cryptocurrency Markets",
                "Pump-and-Dump Schemes",
                "Telegram Channels",
                "Trading Strategy",
                "Machine Learning for Crime Detection"
            ]
        },
        "url": "URL#2767839"
    },
    {
        "@score": "1",
        "@id": "2767840",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "153/5855",
                        "text": "Guangliang Yang 0001"
                    },
                    {
                        "@pid": "68/4706-1",
                        "text": "Jeff Huang 0001"
                    },
                    {
                        "@pid": "64/1147",
                        "text": "Guofei Gu"
                    }
                ]
            },
            "title": "Iframes/Popups Are Dangerous in Mobile WebView: Studying and Mitigating Differential Context Vulnerabilities.",
            "venue": "USENIX Security Symposium",
            "pages": "977-994",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Yang0G19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/yang-guangliang",
            "url": "https://dblp.org/rec/conf/uss/Yang0G19",
            "abstract": "In this paper, we present a novel class of Android Web-View vulnerabilities (called Differential Context Vulnerabili-ties or DCVs ) associated with web iframe/popup behaviors. To demonstrate the security implications of DCVs, we devise several novel concrete attacks. We show an untrusted web iframe/popup inside WebView becomes dangerous that it can launch these attacks to open holes on existing defense solutions, and obtain risky privileges and abilities, such as breaking web messaging integrity, stealthily accessing sensitive mobile functionalities, and performing phishing attacks. Then, we study and assess the security impacts of DCVs on real-world apps. For this purpose, we develop a novel technique, DCV-Hunter , that can automatically vet Android apps against DCVs. By applying DCV-Hunter on a large number of most popular apps, we \ufb01nd DCVs are prevalent. Many high-pro\ufb01le apps are veri\ufb01ed to be impacted, such as Facebook, Instagram, Facebook Messenger, Google News, Skype, Uber, Yelp, and U.S. Bank. To mitigate DCVs, we design a multi-level solution that enhances the security of WebView. Our evaluation on real-world apps shows the mitigation solution is effective and scalable, with negligible overhead.",
            "keywords": [
                "Mobile WebView Security",
                "Differential Context Vulnerabilities",
                "Iframe Vulnerabilities",
                "Phishing Attacks",
                "Web Messaging Integrity"
            ]
        },
        "url": "URL#2767840",
        "sema_paperId": "4ae219e87d52ccacf67b55951303039ab49ad1f2"
    },
    {
        "@score": "1",
        "@id": "2767841",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "248/1637",
                        "text": "Hojoon Yang"
                    },
                    {
                        "@pid": "83/7954",
                        "text": "Sangwook Bae"
                    },
                    {
                        "@pid": "236/4147",
                        "text": "Mincheol Son"
                    },
                    {
                        "@pid": "122/8486",
                        "text": "Hongil Kim"
                    },
                    {
                        "@pid": "55/10607",
                        "text": "Song Min Kim"
                    },
                    {
                        "@pid": "20/6892",
                        "text": "Yongdae Kim"
                    }
                ]
            },
            "title": "Hiding in Plain Signal: Physical Signal Overshadowing Attack on LTE.",
            "venue": "USENIX Security Symposium",
            "pages": "55-72",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YangBSKKK19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/yang-hojoon",
            "url": "https://dblp.org/rec/conf/uss/YangBSKKK19",
            "abstract": "Long-Term Evolution (LTE) communication is based on an open medium; thus, a legitimate signal can potentially be counterfeited by a malicious signal. Although most LTE signaling messages are protected from modi\ufb01cation using cryptographic primitives, broadcast messages in LTE have never been integrity protected. In this paper, for the \ufb01rst time, we present a signal injection attack that exploits the fundamental weaknesses of broadcast messages in LTE and mod-i\ufb01es a transmitted signal over the air. This attack, which is referred to as signal overshadowing (named SigOver ) has several advantages and differences when compared with existing attacks using a fake base station. For example, with a 3 dB power difference from a legitimate signal, the SigOver attack demonstrated a 98% success rate when compared with the 80% success rate of attacks achieved using a fake base station, even with a 35 dB power difference. Given that the SigOver attack is a novel primitive attack, it yields \ufb01ve new attack scenarios and implications. Finally, a discussion on two potential countermeasures leaves practical and robust defense mechanism as a future work.",
            "keywords": [
                "LTE Communication",
                "Signal Injection Attack",
                "Signal Overshadowing",
                "Broadcast Message Vulnerabilities",
                "Counterfeit Signal"
            ]
        },
        "url": "URL#2767841",
        "sema_paperId": "4bb6c6ce91242c2daa15152134a88e88b36664aa"
    },
    {
        "@score": "1",
        "@id": "2767842",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "220/3348",
                        "text": "Haaroon Yousaf"
                    },
                    {
                        "@pid": "19/10126",
                        "text": "George Kappos"
                    },
                    {
                        "@pid": "94/8813",
                        "text": "Sarah Meiklejohn"
                    }
                ]
            },
            "title": "Tracing Transactions Across Cryptocurrency Ledgers.",
            "venue": "USENIX Security Symposium",
            "pages": "837-850",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YousafKM19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/yousaf",
            "url": "https://dblp.org/rec/conf/uss/YousafKM19",
            "abstract": "One of the defining features of a cryptocurrency is that its ledger, containing all transactions that have evertaken place, is globally visible. As one consequenceof this degree of transparency, a long line of recent re-search has demonstrated that even in cryptocurrenciesthat are specifically designed to improve anonymity it is often possible to track money as it changes hands,and in some cases to de-anonymize users entirely. With the recent proliferation of alternative cryptocurrencies, however, it becomes relevant to ask not only whether ornot money can be traced as it moves within the ledgerof a single cryptocurrency, but if it can in fact be tracedas it moves across ledgers. This is especially pertinent given the rise in popularity of automated trading platforms such as ShapeShift, which make it effortless to carry out such cross-currency trades. In this paper, weuse data scraped from ShapeShift over a thirteen-monthperiod and the data from eight different blockchains to explore this question. Beyond developing new heuristics and creating new types of links across cryptocurrency ledgers, we also identify various patterns of cross-currency trades and of the general usage of these platforms, with the ultimate goal of understanding whetherthey serve a criminal or a profit-driven agenda.",
            "keywords": [
                "Cryptocurrency Ledger",
                "Transaction Tracing",
                "Cross-Currency Trades",
                "Anonymity De-anonymization",
                "Automated Trading Platforms"
            ]
        },
        "url": "URL#2767842",
        "sema_paperId": "9d5044cc6502dac34e68151189990fd0ce775219"
    },
    {
        "@score": "1",
        "@id": "2767844",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "202/7659",
                        "text": "Eric Zeng"
                    },
                    {
                        "@pid": "23/2758",
                        "text": "Franziska Roesner"
                    }
                ]
            },
            "title": "Understanding and Improving Security and Privacy in Multi-User Smart Homes: A Design Exploration and In-Home User Study.",
            "venue": "USENIX Security Symposium",
            "pages": "159-176",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZengR19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/zeng",
            "url": "https://dblp.org/rec/conf/uss/ZengR19",
            "abstract": "Smart homes face unique security, privacy, and usability challenges because they are multi-user, multi-device systems that affect the physical environment of all inhabitants of the home. Current smart home technology is often not well designed for multiple users, sometimes lacking basic access control and other affordances for making the system intelligible and accessible for all users. While prior work has shed light on the problems and needs of smart home users, it is not obvious how to design and build solutions. Such questions have certainly not been answered for challenging adversarial situations (e.g., domestic abuse), but we observe that they have not even been answered for tensions in otherwise functional, non-adversarial households. In this work, we explore user behaviors, needs, and possible solutions to multi-user security and privacy issues in generally non-adversarial smart homes. Based on design principles grounded in prior work, we built a prototype smart home app that includes concrete features such as location-based access controls, supervisory access controls, and activity notifications, and we tested our prototype though a month-long in-home user study with seven households. From the results of the user study, we re-evaluate our initial design principles, we surface user feedback on security and privacy features, and we identify challenges and recommendations for smart home designers and researchers.",
            "keywords": [
                "Smart Home Security",
                "Multi-User Privacy",
                "User-Centered Design",
                "Access Control Mechanisms",
                "In-Home User Study"
            ]
        },
        "url": "URL#2767844",
        "sema_paperId": "d4a5b5127825f5e2bf282fa1c51d15aa52273bb6"
    },
    {
        "@score": "1",
        "@id": "2767845",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "227/7173-1",
                        "text": "Mingxue Zhang 0001"
                    },
                    {
                        "@pid": "05/3920-1",
                        "text": "Wei Meng 0001"
                    },
                    {
                        "@pid": "17/5702-1",
                        "text": "Sangho Lee 0001"
                    },
                    {
                        "@pid": "45/7986",
                        "text": "Byoungyoung Lee"
                    },
                    {
                        "@pid": "40/6431",
                        "text": "Xinyu Xing"
                    }
                ]
            },
            "title": "All Your Clicks Belong to Me: Investigating Click Interception on the Web.",
            "venue": "USENIX Security Symposium",
            "pages": "941-957",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhangM0LX19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/zhang",
            "url": "https://dblp.org/rec/conf/uss/ZhangM0LX19",
            "abstract": "Click is the prominent way that users interact with web applications. For example, we click hyperlinks to navigate among different pages on the Web, click form submission buttons to send data to websites, and click player controls to tune video playback. Clicks are also critical in online advertising, which fuels the revenue of billions of websites. Because of the critical role of clicks in the Web ecosystem, attackers aim to intercept genuine user clicks to either send malicious commands to another application on behalf of the user or fabricate realistic ad click traffic. However, existing studies mainly consider one type of click interceptions in the cross-origin settings via iframes, i.e., clickjacking. This does not comprehensively represent various types of click interceptions that can be launched by malicious third-party JavaScript code. In this paper, we therefore systematically investigate the click interception practices on the Web. We developed a browser-based analysis framework, Observer, to collect and analyze click related behaviors. Using Observer, we identified three different techniques to intercept user clicks on the Alexa top 250K websites, and detected 437 third-party scripts that intercepted user clicks on 613 websites, which in total receive around 43 million visits on a daily basis. We revealed that some websites collude with third-party scripts to hijack user clicks for monetization. In particular, our analysis demonstrated that more than 36% of the 3,251 unique click interception URLs were related to online advertising, which is the primary monetization approach on the Web. Further, we discovered that users can be exposed to malicious contents such as scamware through click interceptions. Our research demonstrated that click interception has become an emerging threat to web users.",
            "keywords": [
                "Click Interception",
                "Web Security",
                "User Interaction",
                "Malicious JavaScript",
                "Online Advertising"
            ]
        },
        "url": "URL#2767845",
        "sema_paperId": "f83823271988bbf9579f157ae5335094b390a775"
    },
    {
        "@score": "1",
        "@id": "2767846",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "07/4227",
                        "text": "Tong Zhang"
                    },
                    {
                        "@pid": "18/5040",
                        "text": "Wenbo Shen"
                    },
                    {
                        "@pid": "90/4053",
                        "text": "Dongyoon Lee"
                    },
                    {
                        "@pid": "85/2308",
                        "text": "Changhee Jung"
                    },
                    {
                        "@pid": "09/2166",
                        "text": "Ahmed M. Azab"
                    },
                    {
                        "@pid": "19/8917",
                        "text": "Ruowen Wang"
                    }
                ]
            },
            "title": "PeX: A Permission Check Analysis Framework for Linux Kernel.",
            "venue": "USENIX Security Symposium",
            "pages": "1205-1220",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhangSLJAW19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/zhang-tong",
            "url": "https://dblp.org/rec/conf/uss/ZhangSLJAW19",
            "abstract": "Permission checks play an essential role in operating system security by providing access control to privileged functionalities. However, it is particularly challenging for kernel developers to correctly apply new permission checks and to scalably verify the soundness of existing checks due to the large code base and complexity of the kernel. In fact, Linux kernel contains millions of lines of code with hundreds of permission checks, and even worse its complexity is fast-growing. This paper presents PeX, a static Permission check error detector for LinuX, which takes as input a kernel source code and reports any missing, inconsistent, and redundant permission checks. PeX uses KIRIN (Kernel InteRface based Indirect call aNalysis), a novel, precise, and scalable indirect call analysis technique, leveraging the common programming paradigm used in kernel abstraction interfaces. Over the interprocedural control flow graph built by KIRIN, PeX automatically identifies all permission checks and infers the mappings between permission checks and privileged functions. For each privileged function, PeX examines all possible paths to the function to check if necessary permission checks are correctly enforced before it is called. We evaluated PeX on the latest stable Linux kernel v4.18.5 for three types of permission checks: Discretionary Access Controls (DAC), Capabilities, and Linux Security Modules (LSM). PeX reported 36 new permission check errors, 14 of which have been confirmed by the kernel developers.",
            "keywords": [
                "Linux Kernel Security",
                "Permission Checks",
                "Static Analysis",
                "Access Control Verification",
                "KIRIN Analysis"
            ]
        },
        "url": "URL#2767846",
        "sema_paperId": "96d26d4e83180f3d7d34d8718c75c1d862412b20"
    },
    {
        "@score": "1",
        "@id": "2767847",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "190/2868",
                        "text": "Yaowen Zheng"
                    },
                    {
                        "@pid": "204/5761",
                        "text": "Ali Davanian"
                    },
                    {
                        "@pid": "77/6178-1",
                        "text": "Heng Yin 0001"
                    },
                    {
                        "@pid": "69/6818",
                        "text": "Chengyu Song"
                    },
                    {
                        "@pid": "57/5368",
                        "text": "Hongsong Zhu"
                    },
                    {
                        "@pid": "37/4705-1",
                        "text": "Limin Sun 0001"
                    }
                ]
            },
            "title": "FIRM-AFL: High-Throughput Greybox Fuzzing of IoT Firmware via Augmented Process Emulation.",
            "venue": "USENIX Security Symposium",
            "pages": "1099-1114",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhengDYSZS19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/zheng",
            "url": "https://dblp.org/rec/conf/uss/ZhengDYSZS19",
            "abstract": "Cyber attacks against IoT devices are a severe threat. These attacks exploit software vulnerabilities in IoT \ufb01rmware. Fuzzing is an effective software testing technique for vulnerability discovery. In this work, we present F IRM -AFL, the \ufb01rst high-throughput greybox fuzzer for IoT \ufb01rmware. F IRM - AFL addresses two fundamental problems in IoT fuzzing. First, it addresses compatibility issues by enabling fuzzing for POSIX-compatible \ufb01rmware that can be emulated in a system emulator. Second, it addresses the performance bottleneck caused by system-mode emulation with a novel technique called augmented process emulation. By combining system-mode emulation and user-mode emulation in a novel way, augmented process emulation provides high compatibility as system-mode emulation and high throughput as user-mode emulation. Our evaluation results show that (1) F IRM -AFL is fully functional and capable of \ufb01nding real-world vulnerabilities in IoT programs; (2) the throughput of F IRM -AFL is on average 8.2 times higher than system-mode emulation based fuzzing; and (3) F IRM -AFL is able to \ufb01nd 1-day vulnerabilities much faster than system-mode emulation based fuzzing, and is able to \ufb01nd 0-day vulnerabilities.",
            "keywords": [
                "IoT Firmware Fuzzing",
                "Greybox Fuzzing",
                "Augmented Process Emulation",
                "Vulnerability Discovery",
                "High-Throughput Testing"
            ]
        },
        "url": "URL#2767847",
        "sema_paperId": "e237c5686697c7714bf961d9c026169a0b5aae08"
    },
    {
        "@score": "1",
        "@id": "2767848",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "118/3183",
                        "text": "Markus Zimmermann"
                    },
                    {
                        "@pid": "179/8624",
                        "text": "Cristian-Alexandru Staicu"
                    },
                    {
                        "@pid": "236/6184",
                        "text": "Cam Tenny"
                    },
                    {
                        "@pid": "25/2188",
                        "text": "Michael Pradel"
                    }
                ]
            },
            "title": "Small World with High Risks: A Study of Security Threats in the npm Ecosystem.",
            "venue": "USENIX Security Symposium",
            "pages": "995-1010",
            "year": "2019",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZimmermannSTP19",
            "ee": "https://www.usenix.org/conference/usenixsecurity19/presentation/zimmerman",
            "url": "https://dblp.org/rec/conf/uss/ZimmermannSTP19",
            "abstract": "The popularity of JavaScript has lead to a large ecosystem of third-party packages available via the npm software package registry. The open nature of npm has boosted its growth, providing over 800,000 free and reusable software packages. Unfortunately, this open nature also causes security risks, as evidenced by recent incidents of single packages that broke or attacked software running on millions of computers. This paper studies security risks for users of npm by systematically analyzing dependencies between packages, the maintainers responsible for these packages, and publicly reported security issues. Studying the potential for running vulnerable or malicious code due to third-party dependencies, we find that individual packages could impact large parts of the entire ecosystem. Moreover, a very small number of maintainer accounts could be used to inject malicious code into the majority of all packages, a problem that has been increasing over time. Studying the potential for accidentally using vulnerable code, we find that lack of maintenance causes many packages to depend on vulnerable code, even years after a vulnerability has become public. Our results provide evidence that npm suffers from single points of failure and that unmaintained packages threaten large code bases. We discuss several mitigation techniques, such as trusted maintainers and total first-party security, and analyze their potential effectiveness.",
            "keywords": [
                "npm Ecosystem",
                "JavaScript Packages",
                "Security Risks",
                "Dependency Management",
                "Malicious Code Injection"
            ]
        },
        "url": "URL#2767848",
        "sema_paperId": "30c4476f6af1653874221b78a930a549a801e72c"
    },
    {
        "@score": "1",
        "@id": "2782285",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "12/3207",
                        "text": "Nadia Heninger"
                    },
                    {
                        "@pid": "14/3295",
                        "text": "Patrick Traynor"
                    }
                ]
            },
            "title": "28th USENIX Security Symposium, USENIX Security 2019, Santa Clara, CA, USA, August 14-16, 2019.",
            "venue": "USENIX Security Symposium",
            "publisher": "USENIX Association",
            "year": "2019",
            "type": "Editorship",
            "access": "open",
            "key": "conf/uss/2019",
            "ee": "https://www.usenix.org/conference/usenixsecurity19",
            "url": "https://dblp.org/rec/conf/uss/2019",
            "abstract": null
        },
        "url": "URL#2782285",
        "sema_paperId": "cc64e7cac0fb898826798d30bf1f23ee51d90476"
    }
]