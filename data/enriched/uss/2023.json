[
    {
        "@score": "1",
        "@id": "915147",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "119/1530-1",
                        "text": "Sangdon Park 0001"
                    },
                    {
                        "@pid": "21/11275",
                        "text": "Osbert Bastani"
                    },
                    {
                        "@pid": "38/8882",
                        "text": "Taesoo Kim"
                    }
                ]
            },
            "title": "ACon2: Adaptive Conformal Consensus for Provable Blockchain Oracles.",
            "venue": "USENIX Security Symposium",
            "pages": "3313-3330",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0001BK23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/park",
            "url": "https://dblp.org/rec/conf/uss/0001BK23",
            "abstract": "Blockchains with smart contracts are distributed ledger systems that achieve block-state consistency among distributed nodes by only allowing deterministic operations of smart contracts.  However, the power of smart contracts is enabled by interacting with stochastic off-chain data, which in turn opens the possibility to undermine the block-state consistency.  To address this issue, an oracle smart contract is used to provide a single consistent source of external data; but, simultaneously, this introduces a single point of failure, which is called the oracle problem.  To address the oracle problem, we propose an adaptive conformal consensus (ACon2) algorithm that derives a consensus set of data from multiple oracle contracts via the recent advance in online uncertainty quantification learning.  Interesting, the consensus set provides a desired correctness guarantee under distribution shift and Byzantine adversaries.  We demonstrate the efficacy of the proposed algorithm on two price datasets and an Ethereum case study.  In particular, the Solidity implementation of the proposed algorithm shows the potential practicality of the proposed algorithm, implying that online machine learning algorithms are applicable to address security issues in blockchains.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-park.pdf",
            "keywords": [
                "Blockchain Oracles",
                "Adaptive Conformal Consensus",
                "Data Consistency",
                "Byzantine Adversaries",
                "Oracle Problem"
            ]
        },
        "url": "URL#915147"
    },
    {
        "@score": "1",
        "@id": "915148",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "09/7487-1",
                        "text": "Yizheng Chen 0001"
                    },
                    {
                        "@pid": "336/3665",
                        "text": "Zhoujie Ding"
                    },
                    {
                        "@pid": "42/5626",
                        "text": "David A. Wagner 0001"
                    }
                ]
            },
            "title": "Continuous Learning for Android Malware Detection.",
            "venue": "USENIX Security Symposium",
            "pages": "1127-1144",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0001D023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/chen-yizheng",
            "url": "https://dblp.org/rec/conf/uss/0001D023",
            "abstract": "Machine learning methods can detect Android malware with very high accuracy. However, these classifiers have an Achilles heel, concept drift: they rapidly become out of date and ineffective, due to the evolution of malware apps and benign apps. Our research finds that, after training an Android malware classifier on one year's worth of data, the F1 score quickly dropped from 0.99 to 0.76 after 6 months of deployment on new test samples.In this paper, we propose new methods to combat the concept drift problem of Android malware classifiers. Since machine learning technique needs to be continuously deployed, we use active learning: we select new samples for analysts to label, and then add the labeled samples to the training set to retrain the classifier. Our key idea is, similarity-based uncertainty is more robust against concept drift. Therefore, we combine contrastive learning with active learning. We propose a new hierarchical contrastive learning scheme, and a new sample selection technique to continuously train the Android malware classifier. Our evaluation shows that this leads to significant improvements, compared to previously published methods for active learning. Our approach reduces the false negative rate from 14% (for the best baseline) to 9%, while also reducing the false positive rate (from 0.86% to 0.48%). Also, our approach maintains more consistent performance across a seven-year time period than past methods.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-chen-yizheng.pdf",
            "keywords": [
                "Android Malware Detection",
                "Concept Drift",
                "Active Learning",
                "Contrastive Learning",
                "Continuous Training"
            ]
        },
        "url": "URL#915148"
    },
    {
        "@score": "1",
        "@id": "915149",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "238/0043",
                        "text": "James Bell 0001"
                    },
                    {
                        "@pid": "90/3256",
                        "text": "Adri\u00e0 Gasc\u00f3n"
                    },
                    {
                        "@pid": "08/11136",
                        "text": "Tancr\u00e8de Lepoint"
                    },
                    {
                        "@pid": "42/8016",
                        "text": "Baiyu Li"
                    },
                    {
                        "@pid": "94/8813",
                        "text": "Sarah Meiklejohn"
                    },
                    {
                        "@pid": "07/5590-1",
                        "text": "Mariana Raykova 0001"
                    },
                    {
                        "@pid": "333/8627",
                        "text": "Cathie Yun"
                    }
                ]
            },
            "title": "ACORN: Input Validation for Secure Aggregation.",
            "venue": "USENIX Security Symposium",
            "pages": "4805-4822",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0001GLLM0Y23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/bell",
            "url": "https://dblp.org/rec/conf/uss/0001GLLM0Y23",
            "abstract": "Secure aggregation enables a server to learn the sum of client-held vectors in a privacy-preserving way, and has been applied to distributed statistical analysis and machine learning. In this paper, we both introduce a more efficient secure aggregation protocol and extend secure aggregation by enabling input validation, in which the server can check that clients' inputs satisfy constraints such as L0, L2, and Linfinity bounds. This prevents malicious clients from gaining disproportionate influence on the aggregate statistics or machine learning model. Our new secure aggregation protocol improves the computational efficiency of the state-of-the-art protocol of Bell et al. (CCS 2020) both asymptotically and concretely: we show via experimental evaluation that it results in 2-8X speedups in client computation in practical scenarios. Likewise, our extended protocol with input validation improves on prior work by more than 30X in terms of client communication (with comparable computation costs). Compared to the base protocols without input validation, the extended protocols incur only 0.1X additional communication, and can process binary indicator vectors of length 1M, or 16-bit dense vectors of length 250K, in under 80s of computation per client.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-bell.pdf",
            "keywords": [
                "Secure Aggregation",
                "Input Validation",
                "Client Constraints",
                "Privacy-Preserving Computation",
                "Malicious Client Prevention"
            ]
        },
        "url": "URL#915149"
    },
    {
        "@score": "1",
        "@id": "915150",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "03/8774-1",
                        "text": "Meng Shen 0001"
                    },
                    {
                        "@pid": "353/7532",
                        "text": "Kexin Ji"
                    },
                    {
                        "@pid": "262/9553",
                        "text": "Zhenbo Gao"
                    },
                    {
                        "@pid": "181/2688-2",
                        "text": "Qi Li 0002"
                    },
                    {
                        "@pid": "26/2546",
                        "text": "Liehuang Zhu"
                    },
                    {
                        "@pid": "181/2626-2",
                        "text": "Ke Xu 0002"
                    }
                ]
            },
            "title": "Subverting Website Fingerprinting Defenses with Robust Traffic Representation.",
            "venue": "USENIX Security Symposium",
            "pages": "607-624",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0001JG0Z023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/shen-meng",
            "url": "https://dblp.org/rec/conf/uss/0001JG0Z023",
            "abstract": "Anonymity networks, e.g., Tor, are vulnerable to various website fingerprinting (WF) attacks, which allows attackers to perceive user privacy on these networks. However, the defenses developed recently can effectively interfere with WF attacks, e.g., by simply injecting dummy packets. In this paper, we propose a novel WF attack called Robust Fingerprinting (RF), which enables an attacker to fingerprint the Tor traffic under various defenses. Specifically, we develop a robust traffic representation method that generates Traffic Aggregation Matrix (TAM) to fully capture key informative features leaked from Tor traces. By utilizing TAM, an attacker can train a CNN-based classifier that learns common high-level traffic features uncovered by different defenses. We conduct extensive experiments with public real-world datasets to compare RF with state-of-the-art (SOTA) WF attacks. The closed-and open-world evaluation results demonstrate that RF significantly outperforms the SOTA attacks. In particular, RF can effectively fingerprint Tor traffic under the SOTA defenses with an average accuracy improvement of 8.9% over the best existing attack (i.e., Tik-Tok).",
            "keywords": [
                "Website Fingerprinting",
                "Anonymity Networks",
                "Traffic Representation",
                "Robust Fingerprinting",
                "Tor Traffic Analysis"
            ]
        },
        "url": "URL#915150",
        "sema_paperId": "4308b1ee5821b6239b389d324a2096bf870f05f2"
    },
    {
        "@score": "1",
        "@id": "915151",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "80/6689-1",
                        "text": "Salman Ahmed 0001"
                    },
                    {
                        "@pid": "188/5871",
                        "text": "Hans Liljestrand"
                    },
                    {
                        "@pid": "45/1350",
                        "text": "Hani Jamjoom"
                    },
                    {
                        "@pid": "09/2334",
                        "text": "Matthew Hicks"
                    },
                    {
                        "@pid": "39/2508",
                        "text": "N. Asokan"
                    },
                    {
                        "@pid": "y/DanfengYao",
                        "text": "Danfeng Yao"
                    }
                ]
            },
            "title": "Not All Data are Created Equal: Data and Pointer Prioritization for Scalable Protection Against Data-Oriented Attacks.",
            "venue": "USENIX Security Symposium",
            "pages": "1433-1450",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0001LJHAY23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/ahmed-salman",
            "url": "https://dblp.org/rec/conf/uss/0001LJHAY23",
            "abstract": "Data-oriented attacks are becoming increasingly realistic and effective against the state-of-the-art defenses in most operating systems. These attacks manipulate memory-resident data objects (data and pointers) without changing the control \ufb02ow of a program. Software and hardware-based countermeasures for protecting data and pointers suffer from performance bottlenecks due to excessive instrumentation of all data objects. In this work, we propose a Data and Pointer Prioritization (DPP) framework utilizing rule-based heuristics to identify sensitive memory objects automatically from an application and protect only those sensitive data utilizing existing countermeasures. We evaluate the correctness of our framework using the Linux Flaw Project dataset, Juliet Test Suite, and \ufb01ve real-world programs (used for demonstrating data-oriented attacks). Our experiments show that DPP can identify vulnerable data objects from our tested applications by prioritizing as few as only 3\u20134% of total data objects. Our evaluation of the SPEC CPU2017 Integer benchmark suite shows that DPP-enabled AddressSanitizer (ASan) can improve performance (in terms of throughput) by \u223c 1.6x and reduce run-time overhead by \u223c 70% compared to the default ASan while protecting all the prioritized data objects.",
            "keywords": [
                "Data-Oriented Attacks",
                "Memory Protection",
                "Data and Pointer Prioritization",
                "Performance Optimization",
                "Vulnerable Data Objects"
            ]
        },
        "url": "URL#915151",
        "sema_paperId": "0f9bfb31f683d127cc2380d58f9a90938fcd48ef"
    },
    {
        "@score": "1",
        "@id": "915152",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "87/8700-1",
                        "text": "Yuhang Zhao 0001"
                    },
                    {
                        "@pid": "142/7931",
                        "text": "Yaxing Yao"
                    },
                    {
                        "@pid": "331/8079",
                        "text": "Jiaru Fu"
                    },
                    {
                        "@pid": "331/8373",
                        "text": "Nihan Zhou"
                    }
                ]
            },
            "title": "&quot;If sighted people know, I should be able to know: &quot; Privacy Perceptions of Bystanders with Visual Impairments around Camera-based Technology.",
            "venue": "USENIX Security Symposium",
            "pages": "4661-4678",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0001YFZ23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/zhao-yuhang",
            "url": "https://dblp.org/rec/conf/uss/0001YFZ23",
            "abstract": "Camera-based technology can be privacy-invasive, especially for bystanders who can be captured by the cameras but do not have direct control or access to the devices. The privacy threats become even more significant to bystanders with visual impairments (BVI) since they cannot visually discover the use of cameras nearby and effectively avoid being captured. While some prior research has studied visually impaired people's privacy concerns as direct users of camera-based assistive technologies, no research has explored their unique privacy perceptions and needs as bystanders. We conducted an in-depth interview study with 16 visually impaired participants to understand BVI's privacy concerns, expectations, and needs in different camera usage scenarios. A preliminary survey with 90 visually impaired respondents and 96 sighted controls was conducted to compare BVI and sighted bystanders' general attitudes towards cameras and elicit camera usage scenarios for the interview study. Our research revealed BVI's unique privacy challenges and perceptions around cameras, highlighting their needs for privacy awareness and protection. We summarized design considerations for future privacy-enhancing technologies to fulfill BVI's privacy needs.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-zhao-yuhang.pdf",
            "keywords": [
                "Camera-based Technology",
                "Visual Impairments",
                "Privacy Perceptions",
                "Bystander Privacy",
                "Privacy Awareness"
            ]
        },
        "url": "URL#915152"
    },
    {
        "@score": "1",
        "@id": "915153",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "121/4885-2",
                        "text": "Simone Colombo 0002"
                    },
                    {
                        "@pid": "203/4231",
                        "text": "Kirill Nikitin 0001"
                    },
                    {
                        "@pid": "87/8037",
                        "text": "Henry Corrigan-Gibbs"
                    },
                    {
                        "@pid": "32/10400-1",
                        "text": "David J. Wu 0001"
                    },
                    {
                        "@pid": "f/BryanFord",
                        "text": "Bryan Ford"
                    }
                ]
            },
            "title": "Authenticated private information retrieval.",
            "venue": "USENIX Security Symposium",
            "pages": "3835-3851",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/00020C0F23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/colombo",
            "url": "https://dblp.org/rec/conf/uss/00020C0F23",
            "abstract": "This paper introduces protocols for authenticated private information retrieval. These schemes enable a client to fetch a record from a remote database server such that (a) the server does not learn which record the client reads, and (b) the client either obtains the \"authentic\" record or detects server misbehavior and safely aborts. Both properties are crucial for many applications. Standard private-information-retrieval schemes either do not ensure this form of output authenticity, or they\nrequire multiple database replicas with an honest majority. In contrast, we offer multi-server schemes that protect security as long as at least one server is honest. Moreover, if the client can obtain a short digest of the database out of band, then our schemes require only a single server. Performing an authenticated private PGP-public-key lookup on an OpenPGP key server's database of 3.5 million keys (3 GiB), using two non-colluding servers, takes under 1.2 core-seconds of computation, essentially matching the time taken by unauthenticated private information retrieval. Our authenticated single-server schemes are 30-100\u00d7 more costly than state-of-the-art unauthenticated single-server schemes, though they achieve incomparably stronger integrity properties.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-colombo.pdf",
            "keywords": [
                "Authenticated Private Information Retrieval",
                "Output Authenticity",
                "Multi-Server Schemes",
                "Database Integrity",
                "Client-Server Security"
            ]
        },
        "url": "URL#915153"
    },
    {
        "@score": "1",
        "@id": "915154",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "251/5347-2",
                        "text": "Robert Dumitru 0002"
                    },
                    {
                        "@pid": "98/8283",
                        "text": "Daniel Genkin"
                    },
                    {
                        "@pid": "39/9878",
                        "text": "Andrew Wabnitz"
                    },
                    {
                        "@pid": "90/10901",
                        "text": "Yuval Yarom"
                    }
                ]
            },
            "title": "The Impostor Among US(B): Off-Path Injection Attacks on USB Communications.",
            "venue": "USENIX Security Symposium",
            "pages": "5863-5880",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0002GWY23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/dumitru",
            "url": "https://dblp.org/rec/conf/uss/0002GWY23",
            "abstract": "USB is the most prevalent peripheral interface in modern computer systems and its inherent insecurities make it an appealing attack vector. A well-known limitation of USB is that traffic is not encrypted. This allows on-path adversaries to trivially perform man-in-the-middle attacks. Off-path attacks that  compromise the confidentiality of communications have also been shown to be possible. However, so far no off-path attacks that breach USB communications integrity have been demonstrated. In this work we show that the integrity of USB communications is not guaranteed even against off-path attackers. Specifically, we design and build malicious devices that, even when placed outside of the path between a victim device and the host, can inject data to that path. Using our developed injectors we can falsify the provenance of data input as interpreted by a host computer system. By injecting on behalf of trusted victim devices we can circumvent any software-based authorisation policy defences that computer systems employ against common USB attacks. We demonstrate two concrete attacks. The first injects keystrokes allowing an attacker to execute commands. The second demonstrates file-contents replacement including during system install from a USB disk. We test the attacks on 29 USB 2.0 and USB 3.x hubs and find 14 of them to be vulnerable.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-dumitru.pdf",
            "keywords": [
                "USB Security",
                "Off-Path Attacks",
                "Data Integrity",
                "Malicious Device Injection",
                "Keystroke Injection"
            ]
        },
        "url": "URL#915154"
    },
    {
        "@score": "1",
        "@id": "915155",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "16/1234-2",
                        "text": "Zhuo Zhang 0002"
                    },
                    {
                        "@pid": "49/4102-1",
                        "text": "Zhiqiang Lin 0001"
                    },
                    {
                        "@pid": "353/7595",
                        "text": "Marcelo Morales"
                    },
                    {
                        "@pid": "95/3760-1",
                        "text": "Xiangyu Zhang 0001"
                    },
                    {
                        "@pid": "147/6644-2",
                        "text": "Kaiyuan Zhang 0002"
                    }
                ]
            },
            "title": "Your Exploit is Mine: Instantly Synthesizing Counterattack Smart Contract.",
            "venue": "USENIX Security Symposium",
            "pages": "1757-1774",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0002LM0023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/zhang-zhuo-exploit",
            "url": "https://dblp.org/rec/conf/uss/0002LM0023",
            "abstract": "Smart contracts are susceptible to exploitation due to their unique nature. Despite efforts to identify vulnerabilities using fuzzing, symbolic execution, formal verification, and manual auditing, exploitable vulnerabilities still exist and have led to billions of dollars in monetary losses. To address this issue, it is critical that runtime defenses are in place to minimize exploitation risk. In this paper, we present S TING , a novel run-time defense mechanism against smart contract exploits. The key idea is to instantly synthesize counterattack smart contracts from attacking transactions and leverage the power of Maximal Extractable Value (MEV) to front run attackers. Our evaluation with 62 real-world recent exploits demonstrates its effectiveness, successfully countering 54 of the exploits (i.e., intercepting all the funds stolen by the attacker). In comparison, a general front-runner defense could only handle 12 exploits. Our results provide a clear proof-of-concept that S TING is a viable defense mechanism against smart contract exploits and has the potential to significantly reduce the risk of exploitation in the smart contract ecosystem.",
            "keywords": [
                "Smart Contract Security",
                "Runtime Defense",
                "Exploit Mitigation",
                "Counterattack Synthesis",
                "Maximal Extractable Value (MEV)"
            ]
        },
        "url": "URL#915155",
        "sema_paperId": "41bbd1d0616379e667874d62c37f3ca6c1c22b2c"
    },
    {
        "@score": "1",
        "@id": "915156",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "190/3392-2",
                        "text": "Bingyu Shen 0002"
                    },
                    {
                        "@pid": "291/4993",
                        "text": "Tianyi Shan"
                    },
                    {
                        "@pid": "99/2747-1",
                        "text": "Yuanyuan Zhou 0001"
                    }
                ]
            },
            "title": "Improving Logging to Reduce Permission Over-Granting Mistakes.",
            "venue": "USENIX Security Symposium",
            "pages": "409-426",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0002S023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/shen-bingyu-logging",
            "url": "https://dblp.org/rec/conf/uss/0002S023",
            "abstract": "Access control con\ufb01gurations are gatekeepers to block un-welcome access to sensitive data. Unfortunately, system administrators (sysadmins) sometimes over-grant permissions when resolving unintended access-deny issues reported by legitimate users, which may open up security vulnerabilities for attackers. One of the primary reasons is that modern software does not provide informative logging to guide sysadmins to understand the reported problems. This paper makes one of the \ufb01rst attempts (to the best of our knowledge) to help developers improve log messages in order to help sysadmins correctly understand and \ufb01x access-deny issues without over-granting permissions. First, we conducted an observation study to understand the current practices of access-deny logging in the server software. Our study shows that many access-control program locations do not have any log messages; and a large percentage of existing log messages lack useful information to guide sysadmins to correctly understand and \ufb01x the issues. On top of our observations, we built S EC L OG , which uses static analysis to automatically help developers \ufb01nd missing access-deny log locations and identify relevant information at the log location. We evaluated S EC L OG with ten widely deployed server applications. Overall, S EC L OG identi\ufb01ed 380 new log statements for access-deny cases, and also enhanced 550 existing access-deny log messages with diagnostic information. We have reported 114 log statements to the developers of these applications, and so far 70 have been accepted into their main branches . We also conducted a user study with sysad-mins (n=32) on six real-world access-deny issues. S EC L OG can reduce the number of insecure \ufb01xes from 27 to 1, and also improve the diagnosis time by 64.2% on average.",
            "keywords": [
                "Access Control Logging",
                "Permission Over-Granting",
                "Sysadmin Practices",
                "Access-Deny Issues",
                "Diagnostic Information"
            ]
        },
        "url": "URL#915156",
        "sema_paperId": "6d1def3e96f8ad8813ea0805ab02586a034f6fae"
    },
    {
        "@score": "1",
        "@id": "915157",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "190/3392-2",
                        "text": "Bingyu Shen 0002"
                    },
                    {
                        "@pid": "291/4993",
                        "text": "Tianyi Shan"
                    },
                    {
                        "@pid": "99/2747-1",
                        "text": "Yuanyuan Zhou 0001"
                    }
                ]
            },
            "title": "Multiview: Finding Blind Spots in Access-Deny Issues Diagnosis.",
            "venue": "USENIX Security Symposium",
            "pages": "7499-7516",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0002S023a",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/shen-bingyu-multiview",
            "url": "https://dblp.org/rec/conf/uss/0002S023a",
            "abstract": "Access-deny issues are hard to \ufb01x because it implies both availability and security requirements. On one hand, system administrators (sysadmins) need to make a change quickly to enable legitimate access. On the other hand, sysadmins need to make sure the change does not allow excessive access. Ful\ufb01lling the second requirement on security is especially challenging because it highly requires the sysadmins\u2019 knowledge of the system environments and security context. Blind spots in knowledge and system settings may hinder sysadmins from \ufb01nding solutions that align with the security context. In-secure \ufb01xes can over-grant permissions, which may only get noticed after the security vulnerability gets exploited. This paper aims to help sysadmins reduce blind spots in diagnosis by providing multiple directions to resolve access-deny issues. We propose a system, called Multiview, that automatically mutates the con\ufb01gurations to explore possible directions to \ufb01x the access-deny issue and lets the con\ufb01g-uration changes in each direction grant as few permissions as possible. Multiview provides a detailed diagnosis report, including access-control con\ufb01gurations that are related to the denial, possible con\ufb01guration changes in different directions to allow the request, as well as the impact on the access-control state of the entire system. We conducted a user study to evaluate Multiview with 20 participants on \ufb01ve real-world access-deny issues. Multiview can reduce the percentage of insecure \ufb01xes from 44.0% to 2.0% and reduce the diagnosis time by 62.0% on average. We also evaluated Multiview on 112 real-world failure cases from eight different systems and server applications, and it can successfully diagnose 89 of them. Multiview accurately identi\ufb01es the failure-causing con\ufb01gurations and provides possible directions to each access-deny issue within one minute.",
            "keywords": [
                "Access-Deny Issues",
                "Configuration Management",
                "Security Context",
                "Diagnosis Report",
                "Blind Spots in Permissions"
            ]
        },
        "url": "URL#915157",
        "sema_paperId": "fe1d07ba5cf296560a5cc68a685e5cd43e83b487"
    },
    {
        "@score": "1",
        "@id": "915158",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "99/4292-2",
                        "text": "Ding Wang 0002"
                    },
                    {
                        "@pid": "154/4723",
                        "text": "Xuan Shan"
                    },
                    {
                        "@pid": "279/7825",
                        "text": "Qiying Dong"
                    },
                    {
                        "@pid": "221/6844",
                        "text": "Yaosheng Shen"
                    },
                    {
                        "@pid": "08/6314",
                        "text": "Chunfu Jia"
                    }
                ]
            },
            "title": "No Single Silver Bullet: Measuring the Accuracy of Password Strength Meters.",
            "venue": "USENIX Security Symposium",
            "pages": "947-964",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0002SDSJ23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/wang-ding-silver-bullet",
            "url": "https://dblp.org/rec/conf/uss/0002SDSJ23",
            "abstract": "To help users create stronger passwords, nearly every respectable web service adopts a password strength meter (PSM) to provide real-time strength feedback upon user registration and password change. Recent research has found that PSMs that provide accurate feedback can indeed effectively nudge users toward choosing stronger passwords. Thus, it is imperative to systematically evaluate existing PSMs to facilitate the selection of accurate ones. In this paper, we highlight that there is no single silver bullet metric for measuring the accuracy of PSMs: For each given guessing scenario and strategy, a speci\ufb01c metric is necessary. We investigate the intrinsic characteristics of online and of\ufb02ine guessing scenarios, and for the \ufb01rst time , propose a systematic evaluation framework that is composed of four different dimensioned criteria to rate PSM accuracy under these two password guessing scenarios (as well as various guessing strategies). More speci\ufb01cally, for online guessing , the strength misjudgments of passwords with different popularity would have varied effects on PSM accuracy, and we suggest the weighted Spearman metric and consider two typical attackers: The general attacker who is unaware of the target password distribution, and the knowledgeable attacker aware of it. For of\ufb02ine guessing , since the cracked passwords are generally weaker than the uncracked ones, and they correspond to two disparate distributions, we adopt the Kullback-Leibler divergence metric and investigate the four most typical guessing strategies: brute-force, dictionary-based, probability-based, and a combination of above three strategies. In particular, we propose the Precision metric to measure PSM accuracy when non-binned strength feedback (e.g., probability) is transformed into easy-to-understand bins/scores (e.g., [weak, medium, strong]). We further introduce a reconciled Precision metric to characterize the impacts of strength misjudgments in different directions (e.g., weak \u2192 strong and strong \u2192 weak) on PSM accuracy. The effectiveness and practicality of our evaluation framework are demonstrated by rating 12 leading PSMs, leveraging 14 real-world password datasets. Finally, we provide three recommendations to help improve the accuracy of PSMs.",
            "keywords": [
                "Password Strength Meters",
                "Password Security",
                "PSM Accuracy",
                "Password Guessing Scenarios",
                "Strength Misjudgments"
            ]
        },
        "url": "URL#915158",
        "sema_paperId": "946dd8d9ac7cac972fbc5226444e2ca58acd19fb"
    },
    {
        "@score": "1",
        "@id": "915159",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "16/1234-2",
                        "text": "Zhuo Zhang 0002"
                    },
                    {
                        "@pid": "88/10370-1",
                        "text": "Guanhong Tao 0001"
                    },
                    {
                        "@pid": "216/6403",
                        "text": "Guangyu Shen"
                    },
                    {
                        "@pid": "168/9413",
                        "text": "Shengwei An"
                    },
                    {
                        "@pid": "263/6785",
                        "text": "Qiuling Xu"
                    },
                    {
                        "@pid": "92/10048",
                        "text": "Yingqi Liu"
                    },
                    {
                        "@pid": "184/8303",
                        "text": "Yapeng Ye"
                    },
                    {
                        "@pid": "353/7588",
                        "text": "Yaoxuan Wu"
                    },
                    {
                        "@pid": "95/3760-1",
                        "text": "Xiangyu Zhang 0001"
                    }
                ]
            },
            "title": "PELICAN: Exploiting Backdoors of Naturally Trained Deep Learning Models In Binary Code Analysis.",
            "venue": "USENIX Security Symposium",
            "pages": "2365-2382",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0002TSAXLYW023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/zhang-zhuo-pelican",
            "url": "https://dblp.org/rec/conf/uss/0002TSAXLYW023",
            "abstract": "Deep Learning (DL) models are increasingly used in many cyber-security applications and achieve superior performance compared to traditional solutions. In this paper, we study backdoor vulnerabilities in naturally trained models used in binary analysis. These backdoors are not injected by attackers but rather products of defects in datasets and/or training processes. The attacker can exploit these vulnerabilities by injecting some small fixed input pattern (e.g., an instruction) called backdoor trigger to their input (e.g., a binary code snippet for a malware detection DL model) such that misclassification can be induced (e.g., the malware evades the detection). We focus on transformer models used in binary analysis. Given a model, we leverage a trigger inversion technique particularly designed for these models to derive trigger instructions that can induce misclassification. During attack, we utilize a novel trigger injection technique to insert the trigger instruction(s) to the input binary code snippet. The injection makes sure that the code snippets\u2019 original program semantics are preserved and the trigger becomes an integral part of such semantics and hence cannot be easily eliminated. We evaluate our prototype P ELICAN on 5 binary analysis tasks and 15 models. The results show that P ELICAN can effectively induce misclassification on all the evaluated models in both white-box and black-box scenarios. Our case studies demonstrate that P ELICAN can exploit the backdoor vulnerabilities of two closed-source commercial tools.",
            "keywords": [
                "Binary Code Analysis",
                "Backdoor Vulnerabilities",
                "Trigger Injection",
                "Transformer Models",
                "Misclassification Induction"
            ]
        },
        "url": "URL#915159",
        "sema_paperId": "994035b2328585975586dfecb912e686f9e2eb1b"
    },
    {
        "@score": "1",
        "@id": "915160",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "144/1238-2",
                        "text": "Wenbo Guo 0002"
                    },
                    {
                        "@pid": "03/5595",
                        "text": "Xian Wu"
                    },
                    {
                        "@pid": "130/1339-1",
                        "text": "Lun Wang 0001"
                    },
                    {
                        "@pid": "40/6431",
                        "text": "Xinyu Xing"
                    },
                    {
                        "@pid": "s/DXSong",
                        "text": "Dawn Song"
                    }
                ]
            },
            "title": "PATROL: Provable Defense against Adversarial Policy in Two-player Games.",
            "venue": "USENIX Security Symposium",
            "pages": "3943-3960",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0002WWXS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/guo-wenbo",
            "url": "https://dblp.org/rec/conf/uss/0002WWXS23",
            "abstract": "Recent advances in deep reinforcement learning (DRL) takes artificial intelligence to the next level, from making individual decisions to accomplishing sophisticated tasks via sequential decision makings, such as defeating world-class human players in various games and making real-time trading decisions in stock markets. Following these achievements, we have recently witnessed a new attack specifically designed against DRL. Recent research shows by learning and controlling an adversarial agent/policy, an attacker could quickly discover a victim agent\u2019s weaknesses and thus force it to fail its task. Due to differences in the threat model, most existing defenses proposed for deep neural networks (DNN) cannot be migrated to train robust policies against adversarial policy attacks. In this work, we draw insights from classical game theory and propose the first provable defense against such attacks in two-player competitive games. Technically, we first model the robust policy training problem as finding the nash equilibrium (NE) point in the entire policy space. Then, we design a novel policy training method to search for the NE point in complicated DRL tasks. Finally, we theoretically prove that our proposed method could guarantee the lower-bound performance of the trained agents against arbitrary adversarial policy attacks. Through extensive evaluations, we demonstrate that our method significantly outperforms existing policy training methods in adversarial robustness and performance in non-adversarial settings.",
            "keywords": [
                "Adversarial Policy",
                "Two-player Games",
                "Robust Policy Training",
                "Nash Equilibrium",
                "Adversarial Robustness"
            ]
        },
        "url": "URL#915160",
        "sema_paperId": "b5ed0c59058cc2d2fa14b442aa11c586d800d99f"
    },
    {
        "@score": "1",
        "@id": "915161",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "258/4274-2",
                        "text": "Shixuan Zhao 0002"
                    },
                    {
                        "@pid": "353/7667",
                        "text": "Pinshen Xu"
                    },
                    {
                        "@pid": "05/1884",
                        "text": "Guoxing Chen"
                    },
                    {
                        "@pid": "234/4023",
                        "text": "Mengya Zhang"
                    },
                    {
                        "@pid": "77/3503",
                        "text": "Yinqian Zhang"
                    },
                    {
                        "@pid": "49/4102-1",
                        "text": "Zhiqiang Lin 0001"
                    }
                ]
            },
            "title": "Reusable Enclaves for Confidential Serverless Computing.",
            "venue": "USENIX Security Symposium",
            "pages": "4015-4032",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0002XCZZL23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/zhao-shixuan",
            "url": "https://dblp.org/rec/conf/uss/0002XCZZL23",
            "abstract": "The recent development of Trusted Execution Environment has brought unprecedented opportunities for confidential computing within cloud-based systems. Among various popular cloud business models, serverless computing has gained dominance since its emergence, leading to a high demand for confidential serverless computing services based on trusted enclaves. However, the issue of cold start overhead significantly hinders its performance, as new enclaves need to be created to ensure a clean and verifiable execution environment. In this paper, we propose a novel approach for constructing reusable enclaves that enable rapid enclave reset and robust security with three key enabling techniques: enclave snapshot and rewinding , nested attestation , and multi-layer intra-enclave compartmentalisation . We have built a prototype system for confidential serverless computing, integrating OpenWhisk and a WebAssembly runtime, which significantly reduces the cold start overhead in an end-to-end serverless setting while imposing a reasonable performance impact on standard execution.",
            "keywords": [
                "Confidential Computing",
                "Serverless Computing",
                "Trusted Execution Environment",
                "Cold Start Overhead",
                "Reusable Enclaves"
            ]
        },
        "url": "URL#915161",
        "sema_paperId": "84f16962e10f45ae72a4d448accc2299133dee26"
    },
    {
        "@score": "1",
        "@id": "915162",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "99/4292-2",
                        "text": "Ding Wang 0002"
                    },
                    {
                        "@pid": "273/1791",
                        "text": "Yunkai Zou"
                    },
                    {
                        "@pid": "43/6524-3",
                        "text": "Zijian Zhang 0003"
                    },
                    {
                        "@pid": "353/7603",
                        "text": "Kedong Xiu"
                    }
                ]
            },
            "title": "Password Guessing Using Random Forest.",
            "venue": "USENIX Security Symposium",
            "pages": "965-982",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0002Z0X23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/wang-ding-password-guessing",
            "url": "https://dblp.org/rec/conf/uss/0002Z0X23",
            "abstract": "Passwords are the most widely used authentication method, and guessing attacks are the most effective method for pass-word strength evaluation. However, existing password guessing models are generally built on traditional statistics or deep learning, and there has been no research on password guessing that employs classical machine learning. To \ufb01ll this gap, this paper provides a brand new technical route for password guessing. More speci\ufb01cally, we re-encode the password characters and make it possible for a series of classical machine learning techniques that tackle multi-class classi\ufb01cation problems (such as random forest, boosting algorithms and their variants) to be used for password guessing. Further, we propose RFGuess , a random-forest based framework that characterizes the three most representative password guessing scenarios (i.e., trawling guessing, targeted guessing based on personally identi\ufb01able information (PII) and on users\u2019 password reuse behaviors). Besides its theoretical signi\ufb01cance, this work is also of practical value. Experiments using 13 large real-world password datasets demonstrate that our random-forest based guessing models are effective: (1) RFGuess for trawling guessing scenarios, whose guessing success rates are comparable to its foremost counterparts; (2) RFGuess -PII for targeted guessing based on PII, which guesses 20% \u223c 28% of common users within 100 guesses, outperforming its foremost counterpart by 7% \u223c 13%; (3) RFGuess -Reuse for targeted guessing based on users\u2019 password reuse/modi\ufb01cation behaviors, which performs the best or 2nd best among related models. We believe this work makes a substantial step toward introducing classical machine learning techniques into password guessing.",
            "keywords": [
                "Password Guessing",
                "Random Forest",
                "Authentication Methods",
                "Password Strength Evaluation",
                "Targeted Guessing"
            ]
        },
        "url": "URL#915162",
        "sema_paperId": "6dc06271198f36359c169881f488673f8f3b8a82"
    },
    {
        "@score": "1",
        "@id": "915163",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "99/4292-2",
                        "text": "Ding Wang 0002"
                    },
                    {
                        "@pid": "273/1791",
                        "text": "Yunkai Zou"
                    },
                    {
                        "@pid": "296/2070",
                        "text": "Yuan-an Xiao"
                    },
                    {
                        "@pid": "130/5642",
                        "text": "Siqi Ma"
                    },
                    {
                        "@pid": "c/XiaofengChen1",
                        "text": "Xiaofeng Chen 0001"
                    }
                ]
            },
            "title": "Pass2Edit: A Multi-Step Generative Model for Guessing Edited Passwords.",
            "venue": "USENIX Security Symposium",
            "pages": "983-1000",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0002ZXM023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/wang-ding-pass2edit",
            "url": "https://dblp.org/rec/conf/uss/0002ZXM023",
            "abstract": "While password stuf\ufb01ng attacks (that exploit the direct pass-word reuse behavior) have gained considerable attention, only a few studies have examined password tweaking attacks, where an attacker exploits users\u2019 indirect reuse behaviors (with edit operations like insertion, deletion, and substitution). For the \ufb01rst time , we model the password tweaking attack as a multi-class classi\ufb01cation problem for characterizing users\u2019 password edit/modi\ufb01cation processes, and propose a generative model coupled with the multi-step decision-making mechanism, called P ASS 2 EDIT , to accurately characterize users\u2019 password reuse/modi\ufb01cation behaviors. We demonstrate the effectiveness of P ASS 2 EDIT through extensive experiments, which consist of 12 practical attack scenarios and employ 4.8 billion real-world passwords. The experimental results show that P ASS 2 EDIT and its variant signi\ufb01cantly improve over the prior art. More speci\ufb01cally, when the victim\u2019s password at site A (namely pw A ) is known, within 100 guesses, the cracking success rate of P ASS 2 EDIT in guessing her password at site B ( pw B (cid:2) = pw A ) is 24.2% (for common users) and 11.7% (for security-savvy users), respectively, which is 18.2%-33.0% higher than its foremost counter-parts. Our results highlight that password tweaking is a much more damaging threat to password security than expected.",
            "keywords": [
                "Password Security",
                "Password Tweaking Attacks",
                "Password Reuse",
                "Generative Model",
                "Multi-Step Decision-Making"
            ]
        },
        "url": "URL#915163",
        "sema_paperId": "56e2c4a1fabc4810859cc7d2ce515c1eb72e2eeb"
    },
    {
        "@score": "1",
        "@id": "915164",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "43/3362-6",
                        "text": "Ming Xu 0006"
                    },
                    {
                        "@pid": "306/0786",
                        "text": "Jitao Yu"
                    },
                    {
                        "@pid": "04/4189",
                        "text": "Xinyi Zhang"
                    },
                    {
                        "@pid": "275/3599",
                        "text": "Chuanwang Wang"
                    },
                    {
                        "@pid": "191/1814",
                        "text": "Shenghao Zhang"
                    },
                    {
                        "@pid": "280/3416",
                        "text": "Haoqi Wu"
                    },
                    {
                        "@pid": "42/179",
                        "text": "Weili Han"
                    }
                ]
            },
            "title": "Improving Real-world Password Guessing Attacks via Bi-directional Transformers.",
            "venue": "USENIX Security Symposium",
            "pages": "1001-1018",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0006YZWZWH23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/xu-ming",
            "url": "https://dblp.org/rec/conf/uss/0006YZWZWH23",
            "abstract": "Password guessing attacks, prevalent issues in the real world, can be conceptualized as efforts to approximate the probability distribution of text tokens. Techniques in the natu-ral language processing (NLP) \ufb01eld naturally lend themselves to password guessing. Among them, bi-directional transformers stand out with their ability to utilize bi-directional contexts to capture the nuances in texts. To further improve password guessing attacks, we propose a bi-directional-transformer-based guessing framework, referred to as PassBERT , which applies the pre-training / \ufb01ne-tuning paradigm to password guessing attacks. We \ufb01rst prepare a pre-trained password model, which contains the knowledge of the general password distribution. Then, we design three attack-speci\ufb01c \ufb01ne-tuning approaches to tailor the pre-trained password model to the following real-world attack scenarios: (1) conditional password guessing, which recovers the complete password given a partial password; (2) targeted password guessing, which compromises the password(s) of a speci\ufb01c user using their personal information; (3) adaptive rule-based password guessing, which selects adaptive mangling rules for a word (i.e., base password) to generate rule-transformed password candidates. The experimental re-sults show that our \ufb01ne-tuned models can outperform the state-of-the-art models by 14.53%, 21.82% and 4.86% in the three attacks, respectively, demonstrating the effectiveness of bi-directional transformers on downstream guessing attacks. Finally, we propose a hybrid password strength meter to mitigate the risks from the three attacks.",
            "keywords": [
                "Password Guessing Attacks",
                "Bi-directional Transformers",
                "PassBERT",
                "Fine-tuning Approaches",
                "Password Strength Meter"
            ]
        },
        "url": "URL#915164",
        "sema_paperId": "886a174057a55b76e9ad13b90981570e3c236d2f"
    },
    {
        "@score": "1",
        "@id": "915165",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "02/3672-8",
                        "text": "Heng Li 0008"
                    },
                    {
                        "@pid": "72/5232",
                        "text": "Zhang Cheng"
                    },
                    {
                        "@pid": "220/9034",
                        "text": "Bang Wu"
                    },
                    {
                        "@pid": "315/5683",
                        "text": "Liheng Yuan"
                    },
                    {
                        "@pid": "231/3370",
                        "text": "Cuiying Gao"
                    },
                    {
                        "@pid": "67/2268",
                        "text": "Wei Yuan"
                    },
                    {
                        "@pid": "53/1565",
                        "text": "Xiapu Luo"
                    }
                ]
            },
            "title": "Black-box Adversarial Example Attack towards FCG Based Android Malware Detection under Incomplete Feature Information.",
            "venue": "USENIX Security Symposium",
            "pages": "1181-1198",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0008CWYGYL23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/li-heng",
            "url": "https://dblp.org/rec/conf/uss/0008CWYGYL23",
            "abstract": "The function call graph (FCG) based Android malware detection methods have recently attracted increasing attention due to their promising performance. However, these methods are susceptible to adversarial examples (AEs). In this paper, we design a novel black-box AE attack towards the FCG based malware detection system, called BagAmmo. To mislead its target system, BagAmmo purposefully perturbs the FCG feature of malware through inserting\"never-executed\"function calls into malware code. The main challenges are two-fold. First, the malware functionality should not be changed by adversarial perturbation. Second, the information of the target system (e.g., the graph feature granularity and the output probabilities) is absent. To preserve malware functionality, BagAmmo employs the try-catch trap to insert function calls to perturb the FCG of malware. Without the knowledge about feature granularity and output probabilities, BagAmmo adopts the architecture of generative adversarial network (GAN), and leverages a multi-population co-evolution algorithm (i.e., Apoem) to generate the desired perturbation. Every population in Apoem represents a possible feature granularity, and the real feature granularity can be achieved when Apoem converges. Through extensive experiments on over 44k Android apps and 32 target models, we evaluate the effectiveness, efficiency and resilience of BagAmmo. BagAmmo achieves an average attack success rate of over 99.9% on MaMaDroid, APIGraph and GCN, and still performs well in the scenario of concept drift and data imbalance. Moreover, BagAmmo outperforms the state-of-the-art attack SRL in attack success rate.",
            "keywords": [
                "Android Malware Detection",
                "Function Call Graph",
                "Adversarial Examples",
                "Black-box Attack",
                "Malware Functionality Preservation"
            ]
        },
        "url": "URL#915165",
        "sema_paperId": "d3b408c0c4a71b54cc794c723167dbe2ca7aff70"
    },
    {
        "@score": "1",
        "@id": "915166",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "14/1915-8",
                        "text": "Junjie Wang 0008"
                    },
                    {
                        "@pid": "84/19",
                        "text": "Zhiyi Zhang"
                    },
                    {
                        "@pid": "58/6609-7",
                        "text": "Shuang Liu 0007"
                    },
                    {
                        "@pid": "97/6476-1",
                        "text": "Xiaoning Du 0001"
                    },
                    {
                        "@pid": "04/4498-3",
                        "text": "Junjie Chen 0003"
                    }
                ]
            },
            "title": "FuzzJIT: Oracle-Enhanced Fuzzing for JavaScript Engine JIT Compiler.",
            "venue": "USENIX Security Symposium",
            "pages": "1865-1882",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0008ZL0C23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/wang-junjie",
            "url": "https://dblp.org/rec/conf/uss/0008ZL0C23",
            "abstract": "We present a novel fuzzing technique, FuzzJIT, for exposing JIT compiler bugs in JavaScript engines, based on our insight that JIT compilers shall only speed up the execution but never change the execution result of JavaScript code. FuzzJIT can activate the JIT compiler for every test case and acutely capture any execution discrepancy caused by JIT compilers. The key to success is the design of an input wrapping template, which proactively activates the JIT compiler and makes the generated samples oracle-aware themselves and the oracle is tested during execution spontaneously. We also design a set of mutation strategies to emphasize program elements promising in revealing JIT compiler bugs. FuzzJIT drills to JIT compilers and at the same time retains the high efficiency of fuzzing. We have implemented the design and applied the prototype to find new JIT compiler bugs in four mainstream JavaScript engines. In one month, ten, five, two, and 16 new bugs are exposed in JavaScriptCore, V8, SpiderMonkey, and ChakraCore, respectively, with three demonstrated exploitable.",
            "keywords": [
                "JavaScript Engine",
                "JIT Compiler",
                "Fuzzing Technique",
                "Execution Discrepancy",
                "Bug Detection"
            ]
        },
        "url": "URL#915166",
        "sema_paperId": "10a55301e6f3749e51d46e7cefc4852fa27bd0f0"
    },
    {
        "@score": "1",
        "@id": "915167",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "95/2446-17",
                        "text": "Qi Liu 0017"
                    },
                    {
                        "@pid": "82/9927",
                        "text": "Jieming Yin"
                    },
                    {
                        "@pid": "70/11466",
                        "text": "Wujie Wen"
                    },
                    {
                        "@pid": "06/4401",
                        "text": "Chengmo Yang"
                    },
                    {
                        "@pid": "72/10304",
                        "text": "Shi Sha"
                    }
                ]
            },
            "title": "NeuroPots: Realtime Proactive Defense against Bit-Flip Attacks in Neural Networks.",
            "venue": "USENIX Security Symposium",
            "pages": "6347-6364",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0017YWYS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/liu-qi",
            "url": "https://dblp.org/rec/conf/uss/0017YWYS23",
            "abstract": "Deep neural networks (DNNs) are becoming ubiquitous in various safety- and security-sensitive applications such as self-driving cars and financial systems. Recent studies revealed that bit-flip attacks (BFAs) can destroy DNNs' functionality via DRAM rowhammer\u2014by precisely injecting a few bit-flips into the quantized model parameters, attackers can either degrade the model accuracy to random guessing, or misclassify certain inputs into a target class. BFAs can cause catastrophic consequences if left undetected. However, detecting BFAs is challenging because bit-flips can occur on any weights in a DNN model, leading to a large detection surface. Unlike prior works that attempt to \"patch'' vulnerabilities of DNN models, our work is inspired by the idea of \"honeypot''. Specifically, we propose a proactive defense concept named NeuroPots, which embeds a few \"honey neurons'' as crafted vulnerabilities into the DNN model to lure the attacker into injecting faults in them, thus making detection and model recovery efficient. We utilize NeuroPots to develop a trapdoor-enabled defense framework. We design a honey neuron selection strategy, and propose two methods for embedding trapdoors into the DNN model. Furthermore, since the majority of injected bit flips will concentrate in the trapdoors, we use a checksum-based detection approach to efficiently detect faults in them, and rescue the model accuracy by \"refreshing'' those faulty trapdoors. Our experiments show that trapdoor-enabled defense achieves high detection performance and effectively recovers a compromised model at a low cost across a variety of DNN models and datasets.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-liu-qi.pdf",
            "keywords": [
                "Bit-Flip Attacks",
                "Neural Network Vulnerabilities",
                "Proactive Defense",
                "Honey Neurons",
                "Model Recovery"
            ]
        },
        "url": "URL#915167",
        "sema_paperId": "1b8223eeea1c1b7fe90b6a15ce16f8312538fd12"
    },
    {
        "@score": "1",
        "@id": "915168",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "50/6996-32",
                        "text": "Min Chen 0032"
                    },
                    {
                        "@pid": "90/545-1",
                        "text": "Zhikun Zhang 0001"
                    },
                    {
                        "@pid": "145/3288-1",
                        "text": "Tianhao Wang 0001"
                    },
                    {
                        "@pid": "b/MichaelBackes1",
                        "text": "Michael Backes 0001"
                    },
                    {
                        "@pid": "06/6785-16",
                        "text": "Yang Zhang 0016"
                    }
                ]
            },
            "title": "FACE-AUDITOR: Data Auditing in Facial Recognition Systems.",
            "venue": "USENIX Security Symposium",
            "pages": "7195-7212",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0032000023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/chen-min",
            "url": "https://dblp.org/rec/conf/uss/0032000023",
            "abstract": "Few-shot-based facial recognition systems have gained increasing attention due to their scalability and ability to work with a few face images during the model deployment phase. However, the power of facial recognition systems enables entities with moderate resources to canvas the Internet and build well-performed facial recognition models without people's awareness and consent. To prevent the face images from being misused, one straightforward approach is to modify the raw face images before sharing them, which inevitably destroys the semantic information, increases the difficulty of retroactivity, and is still prone to adaptive attacks. Therefore, an auditing method that does not interfere with the facial recognition model's utility and cannot be quickly bypassed is urgently needed. In this paper, we formulate the auditing process as a user-level membership inference problem and propose a complete toolkit FACE-AUDITOR that can carefully choose the probing set to query the few-shot-based facial recognition model and determine whether any of a user's face images is used in training the model. We further propose to use the similarity scores between the original face images as reference information to improve the auditing performance. Extensive experiments on multiple real-world face image datasets show that FACE-AUDITOR can achieve auditing accuracy of up to $99\\%$. Finally, we show that FACE-AUDITOR is robust in the presence of several perturbation mechanisms to the training images or the target models. The source code of our experiments can be found at \\url{https://github.com/MinChen00/Face-Auditor}.",
            "keywords": [
                "Facial Recognition Systems",
                "Data Auditing",
                "Membership Inference",
                "Few-Shot Learning",
                "Privacy Protection"
            ]
        },
        "url": "URL#915168",
        "sema_paperId": "35c5e3f1c5116698d0805350217a0d5067bc573a"
    },
    {
        "@score": "1",
        "@id": "915169",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "242/8231",
                        "text": "Tamer Abdelaziz"
                    },
                    {
                        "@pid": "26/3410",
                        "text": "Aquinas Hobor"
                    }
                ]
            },
            "title": "Smart Learning to Find Dumb Contracts.",
            "venue": "USENIX Security Symposium",
            "pages": "1775-1792",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AbdelazizH23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/abdelaziz",
            "url": "https://dblp.org/rec/conf/uss/AbdelazizH23",
            "abstract": "We introduce Deep Learning Vulnerability Analyzer (DLVA), a vulnerability detection tool for Ethereum smart contracts based on powerful deep learning techniques for sequential data adapted for bytecode. We train DLVA to judge bytecode even though the supervising oracle, Slither, can only judge source code. DLVA's training algorithm is general: we \u201cextend\u201d a source code analysis to bytecode without any manual feature engineering, predefined patterns, or expert rules. DLVA's training algorithm is also robust: it overcame a 1.25% error rate mislabeled contracts, and\u2014the student surpassing the teacher\u2014found vulnerable contracts that Slither mislabeled. In addition to extending a source code analyzer to bytecode, DLVA is much faster than conventional tools for smart contract vulnerability detection based on formal methods: DLVA checks contracts for 29 vulnerabilities in 0.2 seconds, a 10\u20131,000x speedup compared to traditional tools. DLVA has three key components. First, Smart Contract to Vector (SC2V) uses neural networks to map arbitrary smart contract bytecode to an high-dimensional floating-point vector. We benchmark SC2V against 4 state-of-the-art graph neural networks and show that it improves model differentiation by an average of 2.2%. Second, Sibling Detector (SD) classifies contracts when a target contract's vector is Euclidianclose to a labeled contract's vector in a training set; although only able to judge 55.7% of the contracts in our test set, it has an average Slither-predictive accuracy of 97.4% with a false positive rate of only 0.1%. Third, Core Classifier (CC) uses neural networks to infer vulnerable contracts regardless of vector distance. We benchmark DLVA's CC with 10 \u201coffthe-shelf\u201d machine learning techniques and show that the CC improves average accuracy by 11.3%. Overall, DLVA predicts Slither's labels with an overall accuracy of 92.7% and associated false positive rate of 7.2%. Lastly, we benchmark DLVA against nine well-known smart contract analysis tools. Despite using much less analysis time, DLVA completed every query, leading the pack with an average accuracy of 99.7%, pleasingly balancing high true positive rates with low false positive rates.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-abdelaziz.pdf",
            "keywords": [
                "Smart Contract Analysis",
                "Vulnerability Detection",
                "Ethereum",
                "Bytecode Analysis",
                "Deep Learning Vulnerability Analyzer (DLVA)"
            ]
        },
        "url": "URL#915169"
    },
    {
        "@score": "1",
        "@id": "915170",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "248/7979",
                        "text": "Sahar Abdelnabi"
                    },
                    {
                        "@pid": "07/5701",
                        "text": "Mario Fritz"
                    }
                ]
            },
            "title": "Fact-Saboteurs: A Taxonomy of Evidence Manipulation Attacks against Fact-Verification Systems.",
            "venue": "USENIX Security Symposium",
            "pages": "6719-6736",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AbdelnabiF23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/abdelnabi",
            "url": "https://dblp.org/rec/conf/uss/AbdelnabiF23",
            "abstract": "Mis- and disinformation are a substantial global threat to our security and safety. To cope with the scale of online misinformation, researchers have been working on automating fact-checking by retrieving and verifying against relevant evidence. However, despite many advances, a comprehensive evaluation of the possible attack vectors against such systems is still lacking. Particularly, the automated fact-verification process might be vulnerable to the exact disinformation campaigns it is trying to combat. In this work, we assume an adversary that automatically tampers with the online evidence in order to disrupt the fact-checking model via camouflaging the relevant evidence or planting a misleading one. We first propose an exploratory taxonomy that spans these two targets and the different threat model dimensions. Guided by this, we design and propose several potential attack methods. We show that it is possible to subtly modify claim-salient snippets in the evidence and generate diverse and claim-aligned evidence. Thus, we highly degrade the fact-checking performance under many different permutations of the taxonomy\u2019s dimensions. The attacks are also robust against post-hoc modifications of the claim. Our analysis further hints at potential limitations in models\u2019 inference when faced with contradicting evidence. We emphasize that these attacks can have harmful implications on the inspectable and human-in-the-loop usage scenarios of such models, and we conclude by discussing challenges and directions for future defenses.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-abdelnabi.pdf",
            "keywords": [
                "Fact-Verification Systems",
                "Misinformation",
                "Evidence Manipulation",
                "Disinformation Attacks",
                "Automated Fact-Checking"
            ]
        },
        "url": "URL#915170"
    },
    {
        "@score": "1",
        "@id": "915171",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "182/4659",
                        "text": "Svetlana Abramova"
                    },
                    {
                        "@pid": "52/6295",
                        "text": "Rainer B\u00f6hme"
                    }
                ]
            },
            "title": "Anatomy of a High-Profile Data Breach: Dissecting the Aftermath of a Crypto-Wallet Case.",
            "venue": "USENIX Security Symposium",
            "pages": "715-732",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AbramovaB23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/abramova",
            "url": "https://dblp.org/rec/conf/uss/AbramovaB23",
            "abstract": "Media reports show an alarming increase of data breaches at providers of cybersecurity products and services. Since the exposed records may reveal security-relevant data, such incidents cause undue burden and create the risk of re-victimization to individuals whose personal data gets exposed. In pursuit of examining a broad spectrum of the downstream effects on victims, we surveyed 104 persons who purchased specialized devices for the secure storage of crypto-assets and later fell victim to a breach of customer data. Our case study reveals common nuisances (i.e., spam, scams, phishing e-mails) as well as previously unseen attack vectors (e.g., involving tampered devices), which are possibly tied to the breach. A few victims report losses of digital assets as a form of the harm. We find that our participants exhibit heightened safety concerns, appear skeptical about litigation efforts, and demonstrate the ability to differentiate between the quality of the security product and the circumstances of the breach. We derive implications for the cybersecurity industry at large, and point out methodological challenges in data breach research.",
            "keywords": [
                "Data Breach",
                "Cybersecurity Products",
                "Crypto-Wallet",
                "Victim Impact",
                "Security Vulnerabilities"
            ]
        },
        "url": "URL#915171",
        "sema_paperId": "d4906b62c5de664d939c407861e416b3485158be"
    },
    {
        "@score": "1",
        "@id": "915172",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "a/YAfek",
                        "text": "Yehuda Afek"
                    },
                    {
                        "@pid": "b/ABremlerBarr",
                        "text": "Anat Bremler-Barr"
                    },
                    {
                        "@pid": "353/7615",
                        "text": "Shani Stajnrod"
                    }
                ]
            },
            "title": "NRDelegationAttack: Complexity DDoS attack on DNS Recursive Resolvers.",
            "venue": "USENIX Security Symposium",
            "pages": "3187-3204",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AfekBS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/afek",
            "url": "https://dblp.org/rec/conf/uss/AfekBS23",
            "abstract": "Malicious actors carrying out distributed denial-of-service (DDoS) attacks are interested in requests that consume a large amount of resources and provide them with ammunition. We present a severe complexity attack on DNS resolvers, where a single malicious query to a DNS resolver can significantly increase its CPU load. Even a few such concurrent queries can result in resource exhaustion and lead to a denial of its service to legitimate clients. This attack is unlike most recent DDoS attacks on DNS servers, which use communication amplification attacks where a single query generates a large number of message exchanges between DNS servers. The attack described here involves a malicious client whose request to a target resolver is sent to a collaborating malicious authoritative server; this server, in turn, generates a carefully crafted referral response back to the (victim) resolver. The chain reaction of requests continues, leading to the delegation of queries. These ultimately direct the resolver to a server that does not respond to DNS queries. The exchange generates a long sequence of cache and memory accesses that dramatically increase the CPU load on the target resolver. Hence the name non-responsive delegation attack, or NRDelegationAttack. We demonstrate that three major resolver implementations, BIND9, Unbound, and Knot, are affected by the NRDelegationAttack, and carry out a detailed analysis of the amplification factor on a BIND9 based resolver. As a result of this work, three common vulnerabilities and exposures (CVEs) regarding NRDelegationAttack were issued by these resolver implementations. We also carried out minimal testing on 16 open resolvers, confirming that the attack affects them as well.",
            "keywords": [
                "DNS Security",
                "DDoS Attacks",
                "Complexity Attack",
                "Resource Exhaustion",
                "NRDelegationAttack"
            ]
        },
        "url": "URL#915172",
        "sema_paperId": "21977af0e4dd5799434a8c92cdf3d8797de72fdd"
    },
    {
        "@score": "1",
        "@id": "915173",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "294/3240",
                        "text": "Dilawer Ahmed"
                    },
                    {
                        "@pid": "292/9805",
                        "text": "Aafaq Sabir"
                    },
                    {
                        "@pid": "84/5118-1",
                        "text": "Anupam Das 0001"
                    }
                ]
            },
            "title": "Spying through Your Voice Assistants: Realistic Voice Command Fingerprinting.",
            "venue": "USENIX Security Symposium",
            "pages": "2419-2436",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AhmedS023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/ahmed-dilawer",
            "url": "https://dblp.org/rec/conf/uss/AhmedS023",
            "abstract": "Voice assistants are becoming increasingly pervasive due to the convenience and automation they provide through the voice interface. However, such convenience often comes with unforeseen security and privacy risks. For example, encrypted traf\ufb01c from voice assistants can leak sensitive information about their users\u2019 habits and lifestyles. In this paper, we present a taxonomy of \ufb01ngerprinting voice commands on the most popular voice assistant platforms (Google, Alexa, and Siri). We also provide a deeper understanding of the feasibility of \ufb01ngerprinting third-party applications and streaming services over the voice interface. Our analysis not only improves the state-of-the-art technique but also studies a more realistic setup for \ufb01ngerprinting voice activities over encrypted traf\ufb01c. Our proposed technique considers a passive network eavesdropper observing encrypted traf\ufb01c from various devices within a home and, therefore, \ufb01rst detects the invocation/activation of voice assistants followed by what speci\ufb01c voice command is issued. Using an end-to-end system design, we show that it is possible to detect when a voice assistant is activated with 99% accuracy and then utilize the subsequent traf\ufb01c pattern to infer more \ufb01ne-grained user activities with around 77-80% accuracy.",
            "keywords": [
                "Voice Assistants",
                "Fingerprinting",
                "Encrypted Traffic",
                "User Activity Detection",
                "Voice Command Analysis"
            ]
        },
        "url": "URL#915173",
        "sema_paperId": "802a26b4ec5dda623f4eec28aeb0f1a554ded086"
    },
    {
        "@score": "1",
        "@id": "915174",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "207/6255",
                        "text": "Shimaa Ahmed"
                    },
                    {
                        "@pid": "313/2100",
                        "text": "Yash Wani"
                    },
                    {
                        "@pid": "198/1244",
                        "text": "Ali Shahin Shamsabadi"
                    },
                    {
                        "@pid": "175/1555",
                        "text": "Mohammad Yaghini"
                    },
                    {
                        "@pid": "213/8587",
                        "text": "Ilia Shumailov"
                    },
                    {
                        "@pid": "162/1405",
                        "text": "Nicolas Papernot"
                    },
                    {
                        "@pid": "97/535",
                        "text": "Kassem Fawaz"
                    }
                ]
            },
            "title": "Tubes Among Us: Analog Attack on Automatic Speaker Identification.",
            "venue": "USENIX Security Symposium",
            "pages": "265-282",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AhmedWSYSPF23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/ahmed-shimaa",
            "url": "https://dblp.org/rec/conf/uss/AhmedWSYSPF23",
            "abstract": "Recent years have seen a surge in the popularity of acoustics-enabled personal devices powered by machine learning. Yet, machine learning has proven to be vulnerable to adversarial examples. A large number of modern systems protect themselves against such attacks by targeting artificiality, i.e., they deploy mechanisms to detect the lack of human involvement in generating the adversarial examples. However, these defenses implicitly assume that humans are incapable of producing meaningful and targeted adversarial examples. In this paper, we show that this base assumption is wrong. In particular, we demonstrate that for tasks like speaker identification, a human is capable of producing analog adversarial examples directly with little cost and supervision: by simply speaking through a tube, an adversary reliably impersonates other speakers in the eyes of ML models for speaker identification. Our findings extend to a range of other acoustic-biometric tasks such as liveness detection, bringing into question their use in security-critical settings in real life, such as phone banking.",
            "keywords": [
                "Acoustic Biometrics",
                "Speaker Identification",
                "Analog Adversarial Examples",
                "Human-Generated Attacks",
                "Liveness Detection"
            ]
        },
        "url": "URL#915174",
        "sema_paperId": "bf7a7a2094ad2ded458094206c369b7d216f1cc0"
    },
    {
        "@score": "1",
        "@id": "915175",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "09/2245",
                        "text": "Adi Akavia"
                    },
                    {
                        "@pid": "316/4512",
                        "text": "Neta Oren"
                    },
                    {
                        "@pid": "316/3895",
                        "text": "Boaz Sapir"
                    },
                    {
                        "@pid": "68/11043",
                        "text": "Margarita Vald"
                    }
                ]
            },
            "title": "CSHER: A System for Compact Storage with HE-Retrieval.",
            "venue": "USENIX Security Symposium",
            "pages": "4751-4768",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AkaviaOSV23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/akavia",
            "url": "https://dblp.org/rec/conf/uss/AkaviaOSV23",
            "abstract": "Homomorphic encryption ( HE ) is a promising technology for protecting data in use, with considerable progress in recent years towards attaining practical runtime performance. However, the high storage overhead associated with HE remains an obstacle to its large-scale adoption. In this work we propose a new storage solution in the two-server model resolving the high storage overhead associated with HE , while preserving rigorous data confidentiality. We empirically evaluated our solution in a proof-of-concept system running on AWS EC2 instances with AWS S3 storage, demonstrating storage size with zero overhead over storing AES ciphertexts, and 10 \u00b5 s amortized end-to-end runtime. In addition, we performed experiments on multiple clouds, i.e., where each server resides on a different cloud, exhibiting similar results. As a central tool we introduce the first perfect secret sharing scheme with fast homomorphic reconstruction over the reals ; this may be of independent interest.",
            "keywords": [
                "Homomorphic Encryption",
                "Data Confidentiality",
                "Storage Overhead",
                "Secret Sharing Scheme",
                "Two-Server Model"
            ]
        },
        "url": "URL#915175",
        "sema_paperId": "3c1a206daa6265784790e62a7bf7f701ab2d0425"
    },
    {
        "@score": "1",
        "@id": "915176",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "198/9755",
                        "text": "Omer Akgul"
                    },
                    {
                        "@pid": "251/9099",
                        "text": "Taha Eghtesad"
                    },
                    {
                        "@pid": "337/9704",
                        "text": "Amit Elazari"
                    },
                    {
                        "@pid": "30/3112",
                        "text": "Omprakash Gnawali"
                    },
                    {
                        "@pid": "28/3855",
                        "text": "Jens Grossklags"
                    },
                    {
                        "@pid": "20/7983",
                        "text": "Michelle L. Mazurek"
                    },
                    {
                        "@pid": "61/11094",
                        "text": "Daniel Votipka"
                    },
                    {
                        "@pid": "54/10042",
                        "text": "Aron Laszka"
                    }
                ]
            },
            "title": "Bug Hunters&apos; Perspectives on the Challenges and Benefits of the Bug Bounty Ecosystem.",
            "venue": "USENIX Security Symposium",
            "pages": "2275-2291",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AkgulEEGGMVL23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/akgul",
            "url": "https://dblp.org/rec/conf/uss/AkgulEEGGMVL23",
            "abstract": "Although researchers have characterized the bug-bounty ecosystem from the point of view of platforms and programs, minimal effort has been made to understand the perspectives of the main workers: bug hunters. To improve bug bounties, it is important to understand hunters\u2019 motivating factors, challenges, and overall benefits. We address this research gap with three studies: identifying key factors through a free listing survey (n=56), rating each factor\u2019s importance with a larger-scale factor-rating survey (n=159), and conducting semi-structured interviews to uncover details (n=24). Of 54 factors that bug hunters listed, we find that rewards and learning opportunities are the most important benefits. Further, we find scope to be the top differentiator between programs. Surprisingly, we find earning reputation to be one of the least important motivators for hunters. Of the challenges we identify, communication problems, such as unresponsiveness and disputes, are the most substantial. We present recommendations to make the bug-bounty ecosystem accommodating to more bug hunters and ultimately increase participation in an underutilized market.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-akgul.pdf",
            "keywords": [
                "Bug Bounty Programs",
                "Bug Hunters",
                "Motivating Factors",
                "Communication Challenges",
                "Earning Reputation"
            ]
        },
        "url": "URL#915176"
    },
    {
        "@score": "1",
        "@id": "915177",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "190/6531",
                        "text": "Suood Abdulaziz Al-Roomi"
                    },
                    {
                        "@pid": "53/10825",
                        "text": "Frank Li 0001"
                    }
                ]
            },
            "title": "A Large-Scale Measurement of Website Login Policies.",
            "venue": "USENIX Security Symposium",
            "pages": "2061-2078",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Al-Roomi023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/al-roomi",
            "url": "https://dblp.org/rec/conf/uss/Al-Roomi023",
            "abstract": "Authenticating on a website using a password involves a multi-stage login process, where each stage entails critical policy and implementation decisions that impact login security and usability. While the security community has identified best practices for each stage of the login workflow, we currently lack a broad understanding of website login policies in practice. Prior work relied upon manual inspection of websites, producing evaluations of only a small population of sites skewed towards the most popular ones. In this work, we seek to provide a more comprehensive and systematic picture of real-world website login policies. We develop an automated method for inferring website login policies and apply it to domains across the Google CrUX Top 1 Million. We successfully evaluate the login policies on between 18K and 359K sites (varying depending on the login stage considered), providing characterization of a population two to three orders of magnitude larger than previous studies. Our findings reveal the extent to which insecure login policies exist and identify some underlying causes. Ultimately, our study provides the most comprehensive empirical grounding to date on the state of website login security, shedding light on directions for improving online authentication.",
            "keywords": [
                "Website Login Policies",
                "Authentication Security",
                "User Authentication",
                "Login Workflow",
                "Insecure Login Practices"
            ]
        },
        "url": "URL#915177",
        "sema_paperId": "9f30cd4c111ae2eabaec482fc482603c231a461c"
    },
    {
        "@score": "1",
        "@id": "915178",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "353/7519",
                        "text": "Abdullah AlHamdan"
                    },
                    {
                        "@pid": "179/8624",
                        "text": "Cristian-Alexandru Staicu"
                    }
                ]
            },
            "title": "SandDriller: A Fully-Automated Approach for Testing Language-Based JavaScript Sandboxes.",
            "venue": "USENIX Security Symposium",
            "pages": "3457-3474",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AlHamdanS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/alhamdan",
            "url": "https://dblp.org/rec/conf/uss/AlHamdanS23",
            "abstract": "Language-based isolation offers a cheap way to restrict the privileges of untrusted code. Previous work proposes a plethora of such techniques for isolating JavaScript code on the client-side, enabling the creation of web mashups. While these solutions are mostly out of fashion among practitioners, there is a growing trend to use analogous techniques for JavaScript code running outside of the browser, e.g., for protecting against supply chain attacks on the server-side. Irrespective of the use case, bugs in the implementation of language-based isolation can have devastating consequences. Hence, we propose S AND D RILLER , the \ufb01rst dynamic analysis-based approach for detecting sandbox escape vulnerabilities. Our core insight is to design testing oracles based on two main objectives of language-based sandboxes: Prevent writes outside the sandbox and restrict access to privileged operations. Using instrumentation, we interpose oracle checks on all the references exchanged between the host and the guest code to detect foreign references that allow the guest code to escape the sandbox. If at run time, a foreign reference is detected by an oracle, S AND D RILLER proceeds to synthe-size an exploit for it. We apply our approach to six sandbox systems and \ufb01nd eight unique zero-day sandbox breakout vulnerabilities and two crashes. We believe that S AND D RILLER can be integrated in the development process of sandboxes to detect security vulnerabilities in the pre-release phase.",
            "keywords": [
                "JavaScript Sandboxes",
                "Language-Based Isolation",
                "Sandbox Escape Vulnerabilities",
                "Dynamic Analysis",
                "Security Testing Oracles"
            ]
        },
        "url": "URL#915178",
        "sema_paperId": "d498bfdfc08978ae1d1dd70b34845454a327f8b5"
    },
    {
        "@score": "1",
        "@id": "915179",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "319/3364",
                        "text": "Wael S. Albayaydh"
                    },
                    {
                        "@pid": "57/3469",
                        "text": "Ivan Flechais"
                    }
                ]
            },
            "title": "Examining Power Dynamics and User Privacy in Smart Technology Use Among Jordanian Households.",
            "venue": "USENIX Security Symposium",
            "pages": "4643-4659",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AlbayaydhF23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/albayaydh",
            "url": "https://dblp.org/rec/conf/uss/AlbayaydhF23",
            "abstract": "Smart technologies continue to raise concerns about privacy protection of both households and bystanders who may be targets of incidental or intentional monitoring. Domestic workers are an example of bystanders in smart homes who experience complex power dynamics and can be subjected to exploitative practices that are further facilitated through smart technology. Such power dynamics are rooted in complex social norms and customs, religious beliefs, and economics. While past research has focused on Western contexts to explore how smart technologies and power dynamics affect privacy of households and smart home bystanders, there is a limited understanding of the impact of such factors within non-Western contexts. This paper presents the findings from 30 interviews with smart device users and bystanders (households, and domestic workers), policy makers, and human and civil rights activists to explore smart home power dynamics in the Muslim Arab Middle Eastern (MAME) context of Jordan. We uncover how asymmetric socio-economic power dynamics between households and domestic workers influence smart technology privacy concerns, practices, and rights perceptions. Drawing on the findings of this study, we present some recommendations for interventions to balance asymmetric power dynamics, to improve bystanders\u2019 agency and privacy protection, and to prevent technology exploitation.",
            "keywords": [
                "Smart Technology",
                "User Privacy",
                "Power Dynamics",
                "Domestic Workers",
                "Jordan"
            ]
        },
        "url": "URL#915179",
        "sema_paperId": "d4c0c078cea37df5e65327adda933efd74876e22"
    },
    {
        "@score": "1",
        "@id": "915180",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "64/5995-14",
                        "text": "Muhammad Ali 0014"
                    },
                    {
                        "@pid": "304/4364",
                        "text": "Angelica Goetzen"
                    },
                    {
                        "@pid": "31/3833",
                        "text": "Alan Mislove"
                    },
                    {
                        "@pid": "141/9244",
                        "text": "Elissa M. Redmiles"
                    },
                    {
                        "@pid": "130/0421",
                        "text": "Piotr Sapiezynski"
                    }
                ]
            },
            "title": "Problematic Advertising and its Disparate Exposure on Facebook.",
            "venue": "USENIX Security Symposium",
            "pages": "5665-5682",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AliGMRS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/ali",
            "url": "https://dblp.org/rec/conf/uss/AliGMRS23",
            "abstract": "Targeted advertising remains an important part of the free web browsing experience, where advertisers' targeting and personalization algorithms together find the most relevant audience for millions of ads every day. However, given the wide use of advertising, this also enables using ads as a vehicle for problematic content, such as scams or clickbait. Recent work that explores people's sentiments toward online ads, and the impacts of these ads on people's online experiences, has found evidence that online ads can indeed be problematic. Further, there is the potential for personalization to aid the delivery of such ads, even when the advertiser targets with low specificity. In this paper, we study Facebook -- one of the internet's largest ad platforms -- and investigate key gaps in our understanding of problematic online advertising: (a) What categories of ads do people find problematic? (b) Are there disparities in the distribution of problematic ads to viewers? and if so, (c) Who is responsible\u2014advertisers or advertising platforms? To answer these questions, we empirically measure a diverse sample of user experiences with Facebook ads via a 3-month longitudinal panel. We categorize over 32,000 ads collected from this panel (n=132); and survey participants' sentiments toward their own ads to identify four categories of problematic ads. Statistically modeling the distribution of problematic ads across demographics, we find that older people and minority groups are especially likely to be shown such ads. Further, given that 22% of problematic ads had no specific targeting from advertisers, we infer that ad delivery algorithms (advertising platforms themselves) played a significant role in the biased distribution of these ads.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-ali.pdf",
            "keywords": [
                "Online Advertising",
                "Problematic Content",
                "Targeted Ads",
                "Disparate Exposure",
                "Advertising Algorithms"
            ]
        },
        "url": "URL#915180"
    },
    {
        "@score": "1",
        "@id": "915181",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "277/9015",
                        "text": "Abderrahmen Amich"
                    },
                    {
                        "@pid": "37/7954",
                        "text": "Birhanu Eshete"
                    },
                    {
                        "@pid": "75/3570",
                        "text": "Vinod Yegneswaran"
                    },
                    {
                        "@pid": "179/2240",
                        "text": "Nguyen Phong Hoang"
                    }
                ]
            },
            "title": "DeResistor: Toward Detection-Resistant Probing for Evasion of Internet Censorship.",
            "venue": "USENIX Security Symposium",
            "pages": "2617-2633",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AmichEYH23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/amich",
            "url": "https://dblp.org/rec/conf/uss/AmichEYH23",
            "abstract": "The arms race between Internet freedom advocates and cen-sors has catalyzed the emergence of sophisticated blocking techniques and directed significant research emphasis toward the development of automated censorship measurement and evasion tools based on packet manipulation. However, we observe that the probing process of censorship middleboxes us-ing state-of-the-art evasion tools can be easily fingerprinted by censors, necessitating detection-resilient probing techniques. We validate our hypothesis by developing a real-time detection approach that utilizes Machine Learning (ML) to detect flow-level packet-manipulation and an algorithm for IP-level detection based on Threshold Random Walk (TRW). We then take the first steps toward detection-resilient censorship evasion by presenting DeResistor 1 , a system that facilitates detection-resilient probing for packet-manipulation-based censorship-evasion. DeResistor aims to defuse detection logic employed by censors by performing detection-guided pausing of censorship evasion attempts and interleaving them with normal user-driven network activity. We evaluate our techniques by leveraging Geneva , a state-of-the-art evasion strategy generator, and validate them against 11 simulated censors supplied by Geneva, while also testing them against real-world censors (i.e., China\u2019s Great Firewall (GFW), India and Kazakhstan). From an adversarial perspective, our proposed real-time detection method can quickly detect clients that attempt to probe censorship mid-dleboxes with manipulated packets after inspecting only two probing flows . From a defense perspective, DeResistor is effective at shielding Geneva training from detection while enabling it to narrow the search space to produce less detectable traffic. Importantly, censorship evasion strategies generated using DeResistor can attain a high success rate from different vantage points against the GFW (up to 98%) and 100% in India and Kazakhstan. Finally, we discuss detection countermeasures and extensibility of our approach to other censor-probing-based tools.",
            "keywords": [
                "Censorship Evasion",
                "Detection-Resistant Probing",
                "Packet Manipulation",
                "Censorship Measurement",
                "Threshold Random Walk (TRW)"
            ]
        },
        "url": "URL#915181",
        "sema_paperId": "c1e4cc780c2f30f142c6cc5af450bfda838f3bcd"
    },
    {
        "@score": "1",
        "@id": "915182",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "353/7664",
                        "text": "Ioannis Angelakopoulos"
                    },
                    {
                        "@pid": "86/8823",
                        "text": "Gianluca Stringhini"
                    },
                    {
                        "@pid": "27/3108",
                        "text": "Manuel Egele"
                    }
                ]
            },
            "title": "FirmSolo: Enabling dynamic analysis of binary Linux-based IoT kernel modules.",
            "venue": "USENIX Security Symposium",
            "pages": "5021-5038",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AngelakopoulosS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/angelakopoulos",
            "url": "https://dblp.org/rec/conf/uss/AngelakopoulosS23",
            "abstract": "The Linux-based firmware running on Internet of Things (IoT) devices is complex and consists of user level programs as well as kernel level code. Both components have been shown to have serious security vulnerabilities, and the risk linked to kernel vulnerabilities is particularly high, as these can lead to full system compromise. However, previous work only focuses on the user space component of embedded firmware. In this paper, we present Firm ware Sol uti o n ( FirmSolo ), a system designed to incorporate the kernel space into firmware analysis. FirmSolo features the Kernel Configuration Reverse Engineering (K.C.R.E.) process that leverages information (i.e., exported and required symbols and version magic) from the kernel modules found in firmware images to build a kernel that can load the modules within an emulated environment. This capability allows downstream analysis to broaden their scope into code executing in privileged mode. We evaluated FirmSolo on 1,470 images containing 56,688 kernel modules where it loaded 64% of the kernel modules. To demonstrate how FirmSolo aids downstream analysis, we integrate it with two representative analysis systems; the TriforceAFL kernel fuzzer and Firmadyne, a dynamic firmware analysis tool originally devoid of kernel mode analysis capabilities. Our TriforceAFL experiments on a subset of 75 kernel modules discovered 19 previously-unknown bugs in 11 distinct proprietary modules. Through Firmadyne we confirmed the presence of these previously-unknown bugs in 84 firmware images. Furthermore, by using FirmSolo , Firmadyne confirmed a previously-known memory corruption vulnerability in five different versions of the closed-source Kcodes\u2019 NetUSB module across 15 firmware images.",
            "keywords": [
                "IoT Firmware Analysis",
                "Kernel Module Vulnerabilities",
                "Dynamic Analysis",
                "Kernel Space Security",
                "Emulated Environment"
            ]
        },
        "url": "URL#915182",
        "sema_paperId": "a958f18e9a9fee4c749a8596e0beecc3859b8434"
    },
    {
        "@score": "1",
        "@id": "915183",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "195/0397",
                        "text": "Claudio Anliker"
                    },
                    {
                        "@pid": "224/9311",
                        "text": "Giovanni Camurati"
                    },
                    {
                        "@pid": "51/1639",
                        "text": "Srdjan Capkun"
                    }
                ]
            },
            "title": "Time for Change: How Clocks Break UWB Secure Ranging.",
            "venue": "USENIX Security Symposium",
            "pages": "19-36",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AnlikerCC23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/anliker",
            "url": "https://dblp.org/rec/conf/uss/AnlikerCC23",
            "abstract": "Due to its suitability for wireless ranging, Ultra-Wide Band (UWB) has gained traction over the past years. UWB chips have been integrated into consumer electronics and considered for security-relevant use cases, such as access control or contactless payments. However, several publications in the recent past have shown that it is difficult to protect the integrity of instance measurements on the physical layer. In this paper, we identify transceiver clock imperfections as a new, important parameter that has been widely ignored so far. We present Mix-Down and Stretch-and-Advance, two novel attacks against the current (IEEE 802.15.4z) and the upcoming (IEEE 802.15.4ab) UWB standard, respectively. We demonstrate Mix-Down on commercial chips and achieve distance reduction from 10 m to 0 m. For the Stretch-and-Advance attack, we show analytically that the current proposal of IEEE 802.15.4ab allows reductions of over 90 m. In order to prevent the attack, we propose and analyze an effective countermeasure.",
            "keywords": [
                "Ultra-Wide Band (UWB)",
                "Wireless Ranging",
                "Clock Imperfections",
                "Mix-Down Attack",
                "Stretch-and-Advance Attack"
            ]
        },
        "url": "URL#915183",
        "sema_paperId": "793eee0bc1341436117c3a258aa14a4b2311e295"
    },
    {
        "@score": "1",
        "@id": "915184",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "204/5152",
                        "text": "Simone Aonzo"
                    },
                    {
                        "@pid": "74/2507",
                        "text": "Yufei Han"
                    },
                    {
                        "@pid": "270/2295",
                        "text": "Alessandro Mantovani"
                    },
                    {
                        "@pid": "56/490",
                        "text": "Davide Balzarotti"
                    }
                ]
            },
            "title": "Humans vs. Machines in Malware Classification.",
            "venue": "USENIX Security Symposium",
            "pages": "1145-1162",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AonzoHMB23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/aonzo",
            "url": "https://dblp.org/rec/conf/uss/AonzoHMB23",
            "abstract": "Today, the classi\ufb01cation of a \ufb01le as either benign or malicious is performed by a combination of deterministic indicators (such as antivirus rules), Machine Learning classi\ufb01ers, and, more importantly, the judgment of human experts. However, to compare the difference between human and machine intelligence in malware analysis, it is \ufb01rst necessary to understand how human subjects approach malware classi\ufb01cation. In this direction, our work presents the \ufb01rst experimental study designed to capture which \u2018features\u2019 of a suspicious program (e.g., static properties or runtime behaviors) are prioritized for malware classi\ufb01cation according to humans and machines intelligence. For this purpose, we created a malware classi\ufb01cation game where 110 human players worldwide and with different seniority levels (72 novices and 38 experts) have competed to classify the highest number of unknown samples based on detailed sandbox reports. Surpris-ingly, we discovered that both experts and novices base their decisions on approximately the same features, even if there are clear differences between the two expertise classes. Furthermore, we implemented two state-of-the-art Machine Learning models for malware classi\ufb01cation and evaluated their performances on the same set of samples. The comparative analysis of the results unveiled a common set of features preferred by both Machine Learning models and helped better understand the difference in the feature extraction. This work re\ufb02ects the difference in the decision-making process of humans and computer algorithms and the different ways they extract information from the same data. Its \ufb01ndings serve multiple purposes, from training better malware analysts to improving feature encoding.",
            "keywords": [
                "Malware Classification",
                "Human-Machine Interaction",
                "Feature Extraction",
                "Decision-Making Process",
                "Sandbox Analysis"
            ]
        },
        "url": "URL#915184",
        "sema_paperId": "3e80abe5d2a940613b5f124b2e009354378a3218"
    },
    {
        "@score": "1",
        "@id": "915185",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "260/9262",
                        "text": "Md. Ishtiaq Ashiq"
                    },
                    {
                        "@pid": "213/7358",
                        "text": "Weitong Li"
                    },
                    {
                        "@pid": "150/5174",
                        "text": "Tobias Fiebig"
                    },
                    {
                        "@pid": "90/8396",
                        "text": "Taejoong Chung"
                    }
                ]
            },
            "title": "You&apos;ve Got Report: Measurement and Security Implications of DMARC Reporting.",
            "venue": "USENIX Security Symposium",
            "pages": "4123-4137",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AshiqLFC23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/ashiq",
            "url": "https://dblp.org/rec/conf/uss/AshiqLFC23",
            "abstract": "Email, since its invention, has become the most widely used communication system and SMTP is the standard for email transmission on the Internet. However, SMTP lacks built-in security features, such as sender authentication, making it vulnerable to attacks, including sender spoofing. To address the threat of spoofing, several security extensions, such as SPF or DKIM, have been proposed. Domain-based Message Authentication Reporting and Conformance (DMARC) was introduced in 2012 as a way for domain name owners to publish desired actions for email receivers to take through a DNS record if SPF or DKIM validation fails. The DMARC record can also request email receivers to send machine-generated reports back to the specified addresses to aid domain name owners in detecting and evaluating the risk of spoofed emails. However, DMARC\u2019s complexity creates opportunities for mismanagement that can be exploited by attackers. This paper presents a large-scale and comprehensive measurement study of DMARC reporting deployment and management. We collected data for all second-level domains under the .com , .net , .org , and .se TLDs over 13 months to analyze deployment and management from the domain name owner\u2019s perspective. Additionally, we investigated 7 popular email hosting services and 2 open-source DMARC reporting software to understand their reporting practices. Our study reveals pervasive mismanagement and missing security considerations in DMARC reporting. For example, we found that a single email from an attacker can make a victim SMTP server receive a large number of reports with a high amplification factor (e.g., 1,460 \u00d7 ) by exploiting mis-configured SMTP servers. Based on our findings of several operational misconfigurations for DMARC reporting, we provide recommendations for improvement.",
            "keywords": [
                "DMARC",
                "Email Authentication",
                "Spoofing Prevention",
                "Reporting Mismanagement",
                "SMTP Server Misconfiguration"
            ]
        },
        "url": "URL#915185",
        "sema_paperId": "18e8a5340eb74221f4dfe7f029e567b753221ed2"
    },
    {
        "@score": "1",
        "@id": "915186",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "295/0457",
                        "text": "Athanasios Avgetidis"
                    },
                    {
                        "@pid": "127/7110",
                        "text": "Omar Alrawi"
                    },
                    {
                        "@pid": "134/5637",
                        "text": "Kevin Valakuzhy"
                    },
                    {
                        "@pid": "134/8710",
                        "text": "Charles Lever"
                    },
                    {
                        "@pid": "353/7590",
                        "text": "Paul Burbage"
                    },
                    {
                        "@pid": "k/AngelosDKeromytis",
                        "text": "Angelos D. Keromytis"
                    },
                    {
                        "@pid": "50/6700",
                        "text": "Fabian Monrose"
                    },
                    {
                        "@pid": "26/216",
                        "text": "Manos Antonakakis"
                    }
                ]
            },
            "title": "Beyond The Gates: An Empirical Analysis of HTTP-Managed Password Stealers and Operators.",
            "venue": "USENIX Security Symposium",
            "pages": "5307-5324",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AvgetidisAVLBKM23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/avgetidis",
            "url": "https://dblp.org/rec/conf/uss/AvgetidisAVLBKM23",
            "abstract": "Password Stealers ( Stealers ) are commodity malware that specialize in credential theft. This work presents a large-scale longitudinal study of Stealers and their operators. Using a commercial dataset, we characterize the activity of over 4 , 586 distinct Stealer operators through their devices spanning 10 different Stealer families. Operators make heavy use of proxies, including traditional VPNs, residential proxies, mobile proxies, and the Tor network when managing their botnet. Our af\ufb01liation analysis unveils a strati\ufb01ed enterprise of cyber-criminals for each service offering and we identify privileged operators using graph analysis. We \ufb01nd several Stealer -as- a-Service providers that lower the economical and technical barrier for many cybercriminals. We estimate that service providers bene\ufb01t from high-pro\ufb01t margins (up to 98%) and a lower-bound pro\ufb01t estimate of $11 , 000 per month. We \ufb01nd high-pro\ufb01le targeting like the Social Security Administration, the U.S. House of Representatives, and the U.S. Senate. We share our \ufb01ndings with law enforcement and publish six months of the dataset, analysis artifact, and code.",
            "keywords": [
                "Password Stealers",
                "Credential Theft",
                "Cybercrime Operations",
                "Stealer-as-a-Service",
                "Botnet Management"
            ]
        },
        "url": "URL#915186",
        "sema_paperId": "ccf20c32f71441c021d9d091a2875b91020ace50"
    },
    {
        "@score": "1",
        "@id": "915187",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "132/9580",
                        "text": "Oshrat Ayalon"
                    },
                    {
                        "@pid": "319/3983",
                        "text": "Dana Turjeman"
                    },
                    {
                        "@pid": "141/9244",
                        "text": "Elissa M. Redmiles"
                    }
                ]
            },
            "title": "Exploring Privacy and Incentives Considerations in Adoption of COVID-19 Contact Tracing Apps.",
            "venue": "USENIX Security Symposium",
            "pages": "517-534",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AyalonTR23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/ayalon",
            "url": "https://dblp.org/rec/conf/uss/AyalonTR23",
            "abstract": "Mobile Health (mHealth) apps, such as COVID-19 contact tracing and other health-promoting technologies, help support personal and public health e ff orts in response to the pandemic and other health concerns. However, due to the sensitive data handled by mHealth apps, and their potential e ff ect on people\u2019s lives, their widespread adoption demands trust in a multitude of aspects of their design. In this work, we report on a series of conjoint analyses (N = 1,521) to investigate how COVID-19 contact tracing apps can be better designed and marketed to improve adoption. Specifically, with a novel design of randomization on top of a conjoint analysis, we investigate people\u2019s privacy considerations relative to other attributes when they are contemplating contact-tracing app adoption. We further explore how their adoption considerations are influenced by deployment factors such as o ff ering extrinsic incentives (money, healthcare) and user factors such as receptiveness to contact-tracing apps and sociodemographics. Our results, which we contextualize and synthesize with prior work, o ff er insight into the most desired digital contact-tracing products (e.g., app features) and how they should be deployed (e.g., with incentives) and targeted to di ff erent user groups who have heterogeneous preferences.",
            "keywords": [
                "COVID-19 Contact Tracing",
                "Mobile Health Apps",
                "Privacy Considerations",
                "User Adoption",
                "Incentives for Adoption"
            ]
        },
        "url": "URL#915187",
        "sema_paperId": "428e8bff424eeb1e957ab39cf2aa260af73283c8"
    },
    {
        "@score": "1",
        "@id": "915188",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "248/1647",
                        "text": "Babak Amin Azad"
                    },
                    {
                        "@pid": "220/2510",
                        "text": "Rasoul Jahanshahi"
                    },
                    {
                        "@pid": "353/7658",
                        "text": "Chris Tsoukaladelis"
                    },
                    {
                        "@pid": "27/3108",
                        "text": "Manuel Egele"
                    },
                    {
                        "@pid": "04/8280",
                        "text": "Nick Nikiforakis"
                    }
                ]
            },
            "title": "AnimateDead: Debloating Web Applications Using Concolic Execution.",
            "venue": "USENIX Security Symposium",
            "pages": "5575-5591",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AzadJTEN23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/azad",
            "url": "https://dblp.org/rec/conf/uss/AzadJTEN23",
            "abstract": "Year over year, modern web applications evolve to cater to the needs of many users and support various runtime environments. The ever-growing need to appeal to as many users as possible and the reliance on third-party dependencies comes at the price of code-bloat. Previous research has highlighted the benefits of debloating mechanisms which produce smaller applications, customized to the real needs of their users with significant security improvements. Recognizing the limitations of dynamic and static debloat-ing schemes (including high runtime overhead and lack of accuracy), we propose a hybrid approach based on concolic execution. We developed AnimateDead , a PHP emulator capable of concolic execution and designed a distributed analysis framework around it. By using the readily available web server logs as application entry points, we perform concolic reachability analysis and ex-tractthe code-coverage oftargetwebapplications in an abstract environment, which allows our results to generalize for all user inputs and database states. We demonstrate that debloating via concolic execution improves the security of web applications by shrinking the size of their code by an average of 47% and reducing critical API calls by 55%, while removing 35-65% of vulnerabilities for historic CVEs. We show that via concolic execution, we can debloat web applications with comparable security improvements of dynamic debloating schemes without suffering from the runtime overhead, and the need for a training phase. Moreover, AnimateDead -debloated web applications reduce the likelihood of breakage by allowing users to perform all actions reachable from the analyzed entry points.",
            "keywords": [
                "Web Application Debloating",
                "Concolic Execution",
                "Code Bloat",
                "Security Vulnerabilities",
                "API Call Reduction"
            ]
        },
        "url": "URL#915188",
        "sema_paperId": "ea753105a6f1c5fc289d1bb34aca9e4df3045297"
    },
    {
        "@score": "1",
        "@id": "915189",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "298/2788",
                        "text": "Yijie Bai"
                    },
                    {
                        "@pid": "50/10586",
                        "text": "Yanjiao Chen"
                    },
                    {
                        "@pid": "254/1852",
                        "text": "Hanlei Zhang"
                    },
                    {
                        "@pid": "10/3878-1",
                        "text": "Wenyuan Xu 0001"
                    },
                    {
                        "@pid": "169/7167",
                        "text": "Haiqin Weng"
                    },
                    {
                        "@pid": "243/2917",
                        "text": "Dou Goodman"
                    }
                ]
            },
            "title": "VILLAIN: Backdoor Attacks Against Vertical Split Learning.",
            "venue": "USENIX Security Symposium",
            "pages": "2743-2760",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BaiCZ0WG23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/bai",
            "url": "https://dblp.org/rec/conf/uss/BaiCZ0WG23",
            "abstract": "Vertical split learning is a new paradigm of federated learning for participants with vertically partitioned data. In this paper, we make the first attempt to explore the possibility of backdoor attacks by a malicious participant in vertical split learning. Different from conventional federated learning, vertical split learning poses new challenges for backdoor attacks, the most looming ones being a lack of access to the training data labels and the server model. To tackle these challenges, we propose V ILLAIN , a backdoor attack framework that features effective label inference and data poisoning strategies. V ILLAIN realizes high inference accuracy of the target label samples for the attacker. Furthermore, V ILLAIN intensifies the backdoor attack power by designing a stealthy additive trigger and introducing backdoor augmentation strategies to impose a larger influence on the server model. Our extensive evaluations on 6 datasets with comprehensive vertical split learning models and aggregation methods confirm the effectiveness of V ILLAIN . It is also demonstrated that V ILLAIN can resist the popular privacy inference defenses, backdoor detection or removal defenses, and adaptive defenses.",
            "keywords": [
                "Vertical Split Learning",
                "Backdoor Attacks",
                "Federated Learning",
                "Label Inference",
                "Data Poisoning"
            ]
        },
        "url": "URL#915189",
        "sema_paperId": "fb80f8d9fe785b7e5ae0716d311bfcfba3a95582"
    },
    {
        "@score": "1",
        "@id": "915190",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "294/0161",
                        "text": "David G. Balash"
                    },
                    {
                        "@pid": "331/2266",
                        "text": "Elena Korkes"
                    },
                    {
                        "@pid": "301/5815",
                        "text": "Miles Grant"
                    },
                    {
                        "@pid": "94/1554",
                        "text": "Adam J. Aviv"
                    },
                    {
                        "@pid": "281/6925",
                        "text": "Rahel A. Fainchtein"
                    },
                    {
                        "@pid": "57/3752",
                        "text": "Micah Sherr"
                    }
                ]
            },
            "title": "Educators&apos; Perspectives of Using (or Not Using) Online Exam Proctoring.",
            "venue": "USENIX Security Symposium",
            "pages": "5091-5108",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BalashKGAFS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/balash",
            "url": "https://dblp.org/rec/conf/uss/BalashKGAFS23",
            "abstract": "The onset of the COVID-19 pandemic changed the landscape of education and led to increased usage of remote proctoring tools that are designed to monitor students when they take assessments outside the classroom. While prior work has explored students' privacy and security concerns regarding online proctoring tools, the perspective of educators is under explored. Notably, educators are the decision makers in the classrooms and choose which remote proctoring services and the level of observations they deem appropriate. To explore how educators balance the security and privacy of  their students with the requirements of remote exams, we sent survey requests to over 3,400 instructors at a large private university that taught online classes during the 2020/21 academic year. We had n=125 responses: 21% of the educators surveyed used online exam proctoring services during the remote learning period, and of those, 35% plan to continue using the tools even when there is a full return to in-person learning. Educators who use exam proctoring services are often comfortable with their monitoring capabilities. However, educators are concerned about students sharing certain types of information with exam proctoring companies, particularly when proctoring services collect identifiable information to  validate students' identities. Our results suggest that many educators developed alternative assessments that did not require online proctoring and that those who did use online proctoring services often considered the tradeoffs between the potential risks to student privacy and the utility or necessity of exam proctoring services.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-balash.pdf",
            "keywords": [
                "Online Exam Proctoring",
                "Remote Learning",
                "Educator Perspectives",
                "Student Privacy",
                "Assessment Alternatives"
            ]
        },
        "url": "URL#915190"
    },
    {
        "@score": "1",
        "@id": "915191",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "305/9043",
                        "text": "David Balb\u00e1s"
                    },
                    {
                        "@pid": "44/5966-1",
                        "text": "Daniel Collins 0001"
                    },
                    {
                        "@pid": "v/SergeVaudenay",
                        "text": "Serge Vaudenay"
                    }
                ]
            },
            "title": "Cryptographic Administration for Secure Group Messaging.",
            "venue": "USENIX Security Symposium",
            "pages": "1253-1270",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Balbas0V23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/balbas",
            "url": "https://dblp.org/rec/conf/uss/Balbas0V23",
            "abstract": "Many real-world group messaging systems delegate group administration to the application level, failing to provide formal guarantees related to group membership. Taking a cryptographic approach to group administration can prevent both implementation and protocol design pitfalls that result in a loss of confidentiality and consistency for group members.In this work, we introduce a cryptographic framework for the design of group messaging protocols that offer strong security guarantees for group membership. To this end, we extend the continuous group key agreement (CGKA) paradigm used in the ongoing IETF MLS group messaging standardisation process and introduce the administrated CGKA (A-CGKA) primitive. Our primitive natively enables a subset of group members, the group admins, to control the addition and removal of parties and to update their own keying material in a secure manner. Notably, our security model prevents even corrupted (non-admin) members from forging messages that modify group membership. Moreover, we present two efficient and modular constructions of group administrators that are correct and secure with respect to our definitions. Finally, we propose, implement, and benchmark an efficient extension of MLS that integrates cryptographic administrators.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-balbas.pdf",
            "keywords": [
                "Group Messaging Protocols",
                "Cryptographic Framework",
                "Group Membership Administration",
                "Continuous Group Key Agreement",
                "Administrated CGKA"
            ]
        },
        "url": "URL#915191"
    },
    {
        "@score": "1",
        "@id": "915192",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "282/0221",
                        "text": "Inyoung Bang"
                    },
                    {
                        "@pid": "353/7547",
                        "text": "Martin Kayondo"
                    },
                    {
                        "@pid": "119/7680",
                        "text": "Hyungon Moon"
                    },
                    {
                        "@pid": "65/3751",
                        "text": "Yunheung Paek"
                    }
                ]
            },
            "title": "TRust: A Compilation Framework for In-process Isolation to Protect Safe Rust against Untrusted Code.",
            "venue": "USENIX Security Symposium",
            "pages": "6947-6964",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BangKMP23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/bang",
            "url": "https://dblp.org/rec/conf/uss/BangKMP23",
            "abstract": "Rust was invented to help developers build highly safe systems. It comes with a variety of programming constructs that put emphasis on safety and control of memory layout. Rust enforces strict discipline about a type system and ownership model to enable compile-time checks of all spatial and temporal safety errors. Despite this advantage in security, the restrictions imposed by Rust\u2019s type system make it dif\ufb01cult or inef\ufb01cient to express certain designs or computations. To ease or simplify their programming, developers thus often include untrusted code from unsafe Rust or external libraries written in other languages. Sadly, the programming practices embracing such untrusted code for \ufb02exibility or ef\ufb01ciency subvert the strong safety guarantees by safe Rust. This paper presents TR UST , a compilation framework which against untrusted code present in the program, provides trustworthy protection of safe Rust via in-process isolation. Its main strategy is allocating objects in an isolated memory region that is accessible to safe Rust but restricted from being written by the untrusted. To enforce this, TR UST employs software fault isolation and x86 protection keys. It can be applied directly to any Rust code without requiring manual changes. Our experiments reveal that TR UST is effective and ef\ufb01cient, incurring runtime overhead of only 7.55% and memory overhead of 13.30% on average when running 11 widely used crates in Rust.",
            "keywords": [
                "In-process Isolation",
                "Safe Rust",
                "Untrusted Code",
                "Memory Protection",
                "Software Fault Isolation"
            ]
        },
        "url": "URL#915192",
        "sema_paperId": "8bd2d17b3e135998914efa25e4cd3321fc59d88e"
    },
    {
        "@score": "1",
        "@id": "915193",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "331/2788",
                        "text": "Nils Bars"
                    },
                    {
                        "@pid": "207/4015",
                        "text": "Moritz Schloegel"
                    },
                    {
                        "@pid": "272/7190",
                        "text": "Tobias Scharnowski"
                    },
                    {
                        "@pid": "342/3697",
                        "text": "Nico Schiller"
                    },
                    {
                        "@pid": "h/ThorstenHolz",
                        "text": "Thorsten Holz"
                    }
                ]
            },
            "title": "Fuzztruction: Using Fault Injection-based Fuzzing to Leverage Implicit Domain Knowledge.",
            "venue": "USENIX Security Symposium",
            "pages": "1847-1864",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BarsSSSH23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/bars",
            "url": "https://dblp.org/rec/conf/uss/BarsSSSH23",
            "abstract": "Today\u2019s digital communication relies on complex protocols and speci\ufb01cations for exchanging structured messages and data. Communication naturally involves two endpoints: One generating data and one consuming it. Traditional fuzz testing approaches replace one endpoint, the generator , with a fuzzer and rapidly test many mutated inputs on the target program under test. While this fully automated approach works well for loosely structured formats, this does not hold for highly structured formats, especially those that go through complex transformations such as compression or encryption. In this work, we propose a novel perspective on generating inputs in highly complex formats without relying on heavy-weight program analysis techniques, coarse-grained grammar approximation, or a human domain expert. Instead of mutating the inputs for a target program, we inject faults into the data generation program so that this data is almost of the expected format. Such data bypasses the initial parsing stages in the consumer program and exercises deeper program states, where it triggers more interesting program behavior. To realize this concept, we propose a set of compile-time and run-time analyses to mutate the generator in a targeted manner, so that it remains intact and produces semi-valid outputs that satisfy the constraints of the complex format. We have implemented this approach in a prototype called F UZZ - TRUCTION and show that it outperforms the state-of-the-art fuzzers AFL++, S YM CC, and W EIZZ . F UZZTRUCTION \ufb01nds signi\ufb01cantly more coverage than existing methods, especially on targets that use cryptographic primitives. During our evaluation, F UZZTRUCTION uncovered 151 unique crashes (after automated deduplication). So far, we manually triaged and reported 27 bugs and 4 CVEs were assigned.",
            "keywords": [
                "Fault Injection",
                "Fuzzing",
                "Data Generation",
                "Complex Protocols",
                "Cryptographic Primitives"
            ]
        },
        "url": "URL#915193",
        "sema_paperId": "7eb5cc478291f52c126efcaabd5c256cb7303a0f"
    },
    {
        "@score": "1",
        "@id": "915194",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "353/7685",
                        "text": "Luca Di Bartolomeo"
                    },
                    {
                        "@pid": "353/7535",
                        "text": "Hossein Moghaddas"
                    },
                    {
                        "@pid": "31/1273",
                        "text": "Mathias Payer"
                    }
                ]
            },
            "title": "ARMore: Pushing Love Back Into Binaries.",
            "venue": "USENIX Security Symposium",
            "pages": "6311-6328",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BartolomeoMP23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/di-bartolomeo",
            "url": "https://dblp.org/rec/conf/uss/BartolomeoMP23",
            "abstract": "Static rewriting enables late-state code changes (e.g., to add mitigations, to remove unnecessary code, or to instrument for code coverage) at low overhead in security-critical environments. Most research on static rewriting has so far focused on the x86 architecture. However, the prevalence and proliferation of ARM-based devices along with a large amount of personal data (e.g., health and sensor data) that they process calls for e ffi cient introspection and analysis capabilities on the ARM platform. Addressing the unique challenges on aarch64, we introduce ARMore, the first e ffi cient, robust, and heuristic-free static binary rewriter for arbitrary aarch64 binaries that produces reassembleable assembly. The key improvements introduced by ARMore make the recovery of indirect control flow an option rather than a necessity. Instead of crashing, the cost of an uncovered target only causes the small overhead of an additional branch. ARMore can rewrite binaries from di ff erent languages and compilers (even arbitrary hand-written assembly),bothon PIC andnon-PIC code,withorwithoutsym-bols, including exception handling for C ++ and Go binaries, and also including binaries with mixed data and text. ARMore is sound as it does not rely on any assumptions about the input binary. ARMore is also e ffi cient: it does not employ any expensive dynamic translation techniques, incurring negligible overhead ( < 1% in our evaluated benchmarks). Our AFL ++ coverage instrumentation pass enables fuzzing of closed-source aarch64 binaries at three times the speed compared to the state-of-the-art (AFL-QEMU), and we found 58 unique crashes in closed-source software. ARMore is the only static rewriter whose rewritten binaries correctly pass all SQLite3 and core-utils test cases and autopkgtest of 97.5% Debian packages.",
            "keywords": [
                "Static Binary Rewriting",
                "ARM Architecture",
                "Code Instrumentation",
                "Indirect Control Flow",
                "Reassembleable Assembly"
            ]
        },
        "url": "URL#915194",
        "sema_paperId": "d464d22c08d902f5a283f6253441cc20b4499dd5"
    },
    {
        "@score": "1",
        "@id": "915195",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "b/DavidABasin",
                        "text": "David A. Basin"
                    },
                    {
                        "@pid": "38/4101",
                        "text": "Patrick Schaller"
                    },
                    {
                        "@pid": "180/7312",
                        "text": "Jorge Toro-Pozo"
                    }
                ]
            },
            "title": "Inducing Authentication Failures to Bypass Credit Card PINs.",
            "venue": "USENIX Security Symposium",
            "pages": "3065-3079",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BasinST23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/basin",
            "url": "https://dblp.org/rec/conf/uss/BasinST23",
            "abstract": "For credit card transactions using the EMV standard, the integrity of transaction information is protected cryptographically by the credit card. Integrity checks by the payment terminal use RSA signatures and are part of EMV\u2019s of\ufb02ine data authentication mechanism. Online integrity checks by the card issuer use a keyed MAC. One would expect that failures in either mechanism would always result in transaction failure, but this is not the case as of\ufb02ine authentication failures do not always result in declined transactions. Consequently, the integrity of transaction data that is not protected by the keyed MAC (online) cannot be guaranteed. We show how this missing integrity protection can be exploited to bypass PIN veri\ufb01cation for high-value Mastercard transactions. As a proof-of-concept, we have built an Android app that modi\ufb01es unprotected card-sourced data, including the data relevant for cardholder veri\ufb01cation. Using our app, we have tricked real-world terminals into downgrading from PIN veri\ufb01cation to either no cardholder veri\ufb01cation or (paper) signature veri\ufb01cation, for transactions of up to 500 Swiss Francs. Our \ufb01ndings have been disclosed to the vendor with the recommendation to decline any transaction where of\ufb02ine data authentication fails.",
            "keywords": [
                "EMV Standard",
                "Transaction Integrity",
                "Authentication Failure",
                "Credit Card PIN Bypass",
                "Cardholder Verification"
            ]
        },
        "url": "URL#915195",
        "sema_paperId": "ef607a6410f7302a603b24283439831cd7ee6db4"
    },
    {
        "@score": "1",
        "@id": "915196",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "217/9409",
                        "text": "Rosanna Bellini"
                    },
                    {
                        "@pid": "44/765",
                        "text": "Kevin Lee"
                    },
                    {
                        "@pid": "353/7554",
                        "text": "Megan A. Brown"
                    },
                    {
                        "@pid": "32/2635",
                        "text": "Jeremy Shaffer"
                    },
                    {
                        "@pid": "201/7550",
                        "text": "Rasika Bhalerao"
                    },
                    {
                        "@pid": "26/3399",
                        "text": "Thomas Ristenpart"
                    }
                ]
            },
            "title": "The Digital-Safety Risks of Financial Technologies for Survivors of Intimate Partner Violence.",
            "venue": "USENIX Security Symposium",
            "pages": "87-104",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BelliniLBSBR23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/bellini",
            "url": "https://dblp.org/rec/conf/uss/BelliniLBSBR23",
            "abstract": "Digital technologies play a growing role in exacerbating financial abuse for survivors of intimate partner violence (IPV). While abusers of IPV rarely employ advanced technological attacks that go beyond interacting via standard user interfaces, scant research has examined how consumer-facing financial technologies can facilitate or obstruct IPV-related attacks on a survivor\u2019s financial well-being. Through an audit of 13 mobile banking and 17 peer-to-peer payment smartphone applications and their associated usage policies, we simulated both close-range and remote attacks commonly used by IPV adversaries. We discover that mobile banking and peer-to-peer payment applications are generally ill-equipped to deal with user-interface bound (UI-bound) adversaries, permitting unauthorized access to logins, surreptitious surveillance, and, harassing messages and system prompts. To assess our discoveries, we interviewed 12 financial professionals who offer or oversee frontline services for vulnerable customers. While professionals expressed an interest in implementing mitigation strategies, they also highlight barriers to institutional approaches to intimate threats, and question professional responsibilities for digital safety. We conclude by providing recommendations for how digital financial service providers may better address UI-bound threats, and offer broader considerations for professional auditing and evaluation approaches to technology-facilitated abuse.",
            "keywords": [
                "Digital Financial Technologies",
                "Intimate Partner Violence",
                "Financial Abuse",
                "User Interface Vulnerabilities",
                "Digital Safety Risks"
            ]
        },
        "url": "URL#915196",
        "sema_paperId": "cd9d1dbccf9073ba12a5fbcbb6be5fff253ee556"
    },
    {
        "@score": "1",
        "@id": "915198",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "340/9951",
                        "text": "Mazal Bethany"
                    },
                    {
                        "@pid": "353/7606",
                        "text": "Andrew Seong"
                    },
                    {
                        "@pid": "243/2260",
                        "text": "Samuel Henrique Silva"
                    },
                    {
                        "@pid": "35/4103",
                        "text": "Nicole Beebe"
                    },
                    {
                        "@pid": "194/5621",
                        "text": "Nishant Vishwamitra"
                    },
                    {
                        "@pid": "263/1357",
                        "text": "Peyman Najafirad"
                    }
                ]
            },
            "title": "Towards Targeted Obfuscation of Adversarial Unsafe Images using Reconstruction and Counterfactual Super Region Attribution Explainability.",
            "venue": "USENIX Security Symposium",
            "pages": "643-660",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BethanySSBVN23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/bethany",
            "url": "https://dblp.org/rec/conf/uss/BethanySSBVN23",
            "abstract": "Online Social Networks (OSNs) are increasingly used by perpetrators to harass their targets via the exchange of un-safe images. Furthermore, perpetrators have resorted to us-ing advanced techniques like adversarial attacks to evade the detection of such images. To defend against this threat, OSNs use AI/ML-based detectors to flag unsafe images. However, these detectors cannot explain the regions of unsafe content for the obfuscation and inspection of such regions, and are also critically vulnerable to adversarial attacks that fool their detection. In this work, we first conduct an in-depth investigation into state-of-the-art explanation techniques and commercially-available unsafe image detectors and find that they are severely deficient against adversarial unsafe images. To address these deficiencies we design a new system that performs targeted obfuscation of unsafe adversarial images on social media using reconstruction to remove adversarial perturbations and counterfactual super region attribution ex-plainability to explain unsafe image segments, and created a prototype called U G UARD . We demonstrate the effectiveness of our system with a large-scale evaluation on three common unsafe images: Sexually Explicit, Cyberbullying, and Self-Harm. Our evaluations of U G UARD on more than 64,000 real-world unsafe OSN images, and unsafe images found in the wild such as sexually explicit celebrity deepfakes and self-harm images show that it significantly neutralizes the threat of adversarial unsafe images, by safely obfuscating 91.47% of such images.",
            "keywords": [
                "Adversarial Attacks",
                "Unsafe Image Detection",
                "Obfuscation Techniques",
                "Counterfactual Attribution",
                "Social Media Safety"
            ]
        },
        "url": "URL#915198",
        "sema_paperId": "8688f121e613895028373fc732f7489387307424"
    },
    {
        "@score": "1",
        "@id": "915199",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "275/2933",
                        "text": "Alexander Bienstock"
                    },
                    {
                        "@pid": "04/773",
                        "text": "Sarvar Patel"
                    },
                    {
                        "@pid": "175/1759",
                        "text": "Joon Young Seo"
                    },
                    {
                        "@pid": "176/7649",
                        "text": "Kevin Yeo"
                    }
                ]
            },
            "title": "Near-Optimal Oblivious Key-Value Stores for Efficient PSI, PSU and Volume-Hiding Multi-Maps.",
            "venue": "USENIX Security Symposium",
            "pages": "301-318",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BienstockPSY23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/bienstock",
            "url": "https://dblp.org/rec/conf/uss/BienstockPSY23",
            "abstract": "In this paper, we study oblivious key-value stores (OKVS) that enable encoding n key-value pairs into length m encodings while hiding the input keys. The goal is to obtain high rate, n/m, with efficient encoding and decoding algorithms. We present RB-OKVS built on random band matrices that obtains near-optimal rates as high as 0.97 whereas prior works could only achieve rates up to 0.81 with similar encoding times.Using RB-OKVS, we obtain state-of-the-art protocols for private set intersection (PSI) and union (PSU). Our semi-honest PSI has up to 12% smaller communication and 13% reductions in monetary cost with slightly larger computation. We also obtain similar improvements for both malicious and circuit PSI. For PSU, our protocol obtains improvements of up to 22% in communication, 40% in computation and 21% in monetary cost. In general, we obtain the most communication- and cost-efficient protocols for all the above primitives.Finally, we present the first connection between OKVS and volume-hiding encrypted multi-maps (VH-EMM) where the goal is to outsource storage of multi-maps while hiding the number of values associated with each key (i.e., volume). We present RB-MM with 16% smaller storage, 5x faster queries and 8x faster setup than prior works.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-bienstock.pdf",
            "keywords": [
                "Oblivious Key-Value Stores",
                "Private Set Intersection",
                "Volume-Hiding Multi-Maps",
                "Encoding Efficiency",
                "Communication Cost Reduction"
            ]
        },
        "url": "URL#915199"
    },
    {
        "@score": "1",
        "@id": "915200",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "224/4572",
                        "text": "Evangelos Bitsikas"
                    },
                    {
                        "@pid": "243/0418",
                        "text": "Theodor Schnitzler"
                    },
                    {
                        "@pid": "11/3019",
                        "text": "Christina P\u00f6pper"
                    },
                    {
                        "@pid": "23/11190",
                        "text": "Aanjhan Ranganathan"
                    }
                ]
            },
            "title": "Freaky Leaky SMS: Extracting User Locations by Analyzing SMS Timings.",
            "venue": "USENIX Security Symposium",
            "pages": "2151-2168",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BitsikasSPR23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/bitsikas",
            "url": "https://dblp.org/rec/conf/uss/BitsikasSPR23",
            "abstract": "Short Message Service (SMS) remains one of the most popular communication channels since its introduction in 2G cellular networks. In this paper, we demonstrate that merely receiving silent SMS messages regularly opens a stealthy side-channel that allows other regular network users to infer the whereabouts of the SMS recipient. The core idea is that receiving an SMS inevitably generates Delivery Reports whose reception bestows a timing attack vector at the sender. We conducted experiments across various countries, operators, and devices to show that an attacker can deduce the location of an SMS recipient by analyzing timing measurements from typical receiver locations. Our results show that, after training an ML model, the SMS sender can accurately determine multiple locations of the recipient. For example, our model achieves up to 96% accuracy for locations across different countries, and 86% for two locations within Belgium. Due to the way cellular networks are designed, it is difficult to prevent Delivery Reports from being returned to the originator making it challenging to thwart this covert attack without making fundamental changes to the network architecture.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-bitsikas.pdf",
            "keywords": [
                "SMS Communication",
                "Location Inference",
                "Timing Attack",
                "Delivery Reports",
                "Covert Channel"
            ]
        },
        "url": "URL#915200"
    },
    {
        "@score": "1",
        "@id": "915201",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "24/8243",
                        "text": "Olivier Blazy"
                    },
                    {
                        "@pid": "12/4955",
                        "text": "Ioana Boureanu"
                    },
                    {
                        "@pid": "l/PascalLafourcade",
                        "text": "Pascal Lafourcade 0001"
                    },
                    {
                        "@pid": "59/8243",
                        "text": "Cristina Onete"
                    },
                    {
                        "@pid": "263/7303",
                        "text": "L\u00e9o Robert"
                    }
                ]
            },
            "title": "How fast do you heal? A taxonomy for post-compromise security in secure-channel establishment.",
            "venue": "USENIX Security Symposium",
            "pages": "5917-5934",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BlazyB0OR23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/blazy",
            "url": "https://dblp.org/rec/conf/uss/BlazyB0OR23",
            "abstract": "Post-Compromise Security (PCS) is a property of secure-channel establishment schemes, which limits the security breach of an adversary that has compromised one of the endpoint to a certain number of messages, after which the channel heals. An attractive property, especially in view of Snowden\u2019s revelation of mass-surveillance, PCS was pioneered by the Signal messaging protocol, and is present in OTR. In this paper, we introduce a framework for quantifying and comparing PCS security, with respect to a broad taxonomy of adversaries. The generality and flexibility of our approach allows us to model the healing speed of a broad class of protocols, including Signal, but also an identity-based messaging protocol named SAID, and even a composition of 5G handover protocols.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-blazy.pdf",
            "keywords": [
                "Post-Compromise Security",
                "Secure-Channel Establishment",
                "Adversarial Models",
                "Healing Speed",
                "Messaging Protocols"
            ]
        },
        "url": "URL#915201"
    },
    {
        "@score": "1",
        "@id": "915202",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "353/7655",
                        "text": "Birk Blechschmidt"
                    },
                    {
                        "@pid": "136/8343",
                        "text": "Ben Stock"
                    }
                ]
            },
            "title": "Extended Hell(o): A Comprehensive Large-Scale Study on Email Confidentiality and Integrity Mechanisms in the Wild.",
            "venue": "USENIX Security Symposium",
            "pages": "4895-4912",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BlechschmidtS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/blechschmidt",
            "url": "https://dblp.org/rec/conf/uss/BlechschmidtS23",
            "abstract": "The core specifications of electronic mail as used today date back as early as the 1970s. At that time, security did not play a significant role in developing communication protocols. These shortcomings still manifest themselves today in the prevalence of phishing and the reliance on opportunistic encryption. Besides STARTTLS, various mechanisms such as SPF, DKIM, DMARC, DANE, and MTA-STS have been proposed. However, related work has shown that not all providers support them and that misconfigurations are common. In this work, we provide a comprehensive overview of the current state of email confidentiality and integrity measures, as well as the effectiveness of their deployment. On a positive note, support for incoming TLS connections has significantly increased over the years, with over 96% of reachable MXs in the top 10 million domains allowing for explicit TLS. Notably, 30% of presented certificates are invalid, though, with the majority of issues related to the presented hostnames. In light of this, all 47 providers we tested connect to hosts with expired, self-signed, non-matching certificates, making it trivial for at-tackers to intercept their connections. Our analysis also shows that still only around 40% of sites specify SPF, and even high-ranked providers like t-online.de do not enforce it. Similarly, while DNS lookups are performed for both DKIM and DANE, neither mechanism is validated or enforced by all providers. In addition, we show that MTA-STS is only slowly getting traction (six providers support it) and provide the first large-scale analysis into OPENPGPKEY and SMIMEA records. All in all, this still paints a grim yet slightly improving picture for the state of email security by late 2022.",
            "keywords": [
                "Email Security",
                "Confidentiality Mechanisms",
                "Integrity Mechanisms",
                "Email Authentication",
                "TLS Deployment Issues"
            ]
        },
        "url": "URL#915202",
        "sema_paperId": "e8ebaf40371633c00d65bf073b0683f77ab27afc"
    },
    {
        "@score": "1",
        "@id": "915203",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "344/4168",
                        "text": "William Edward Bodell III"
                    },
                    {
                        "@pid": "303/0378",
                        "text": "Sajad Meisami"
                    },
                    {
                        "@pid": "10/9994",
                        "text": "Yue Duan"
                    }
                ]
            },
            "title": "Proxy Hunting: Understanding and Characterizing Proxy-based Upgradeable Smart Contracts in Blockchains.",
            "venue": "USENIX Security Symposium",
            "pages": "1829-1846",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BodellMD23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/bodell",
            "url": "https://dblp.org/rec/conf/uss/BodellMD23",
            "abstract": "Upgradeable smart contracts (USCs) have become a key trend in smart contract development, bringing flexibility to otherwise immutable code. However, they also introduce security concerns. On the one hand, they require extensive security knowledge to implement in a secure fashion. On the other hand, they provide new strategic weapons for malicious activities. Thus, it is crucial to fully understand them, especially their security implications in the real-world. To this end, we conduct a large-scale study to systematically reveal the status quo of USCs in the wild. To achieve our goal, we develop a complete USC taxonomy to comprehensively characterize the unique behaviors of USCs and further develop U SC H UNT , an automated USC analysis framework for supporting our study. Our study aims to answer three sets of essential research questions regarding USC importance, design patterns, and security issues. Our results show that USCs are of great importance to today\u2019s blockchain as they hold billions of USD worth of digital assets. Moreover, our study summarizes eleven unique design patterns of USCs, and discovers a total of 2,546 real-world USC-related security and safety issues in six major categories.",
            "keywords": [
                "Upgradeable Smart Contracts",
                "Blockchain Security",
                "USC Taxonomy",
                "Security Vulnerabilities",
                "Automated USC Analysis"
            ]
        },
        "url": "URL#915203",
        "sema_paperId": "66f5445900d093f2a623a0d51be2ffac5dc78e7d"
    },
    {
        "@score": "1",
        "@id": "915204",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "295/8559",
                        "text": "Nicholas Boucher"
                    },
                    {
                        "@pid": "a/RJAnderson",
                        "text": "Ross Anderson 0001"
                    }
                ]
            },
            "title": "Trojan Source: Invisible Vulnerabilities.",
            "venue": "USENIX Security Symposium",
            "pages": "6507-6524",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Boucher023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/boucher",
            "url": "https://dblp.org/rec/conf/uss/Boucher023",
            "abstract": "We present a new type of attack in which source code is maliciously encoded so that it appears different to a compiler and to the human eye. This attack exploits subtleties in text-encoding standards such as Unicode to produce source code whose tokens are logically encoded in a different order from the one in which they are displayed, leading to vulnerabilities that cannot be perceived directly by human code reviewers. 'Trojan Source' attacks, as we call them, pose an immediate threat both to first-party software and of supply-chain compromise across the industry. We present working examples of Trojan Source attacks in C, C++, C#, JavaScript, Java, Rust, Go, Python SQL, Bash, Assembly, and Solidity. We propose definitive compiler-level defenses, and describe other mitigating controls that can be deployed in editors, repositories, and build pipelines while compilers are upgraded to block this attack. We document an industry-wide coordinated disclosure for these vulnerabilities; as they affect most compilers, editors, and repositories, the exercise teaches how different firms, open-source communities, and other stakeholders respond to vulnerability disclosure.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-boucher.pdf",
            "keywords": [
                "Trojan Source Attacks",
                "Source Code Vulnerabilities",
                "Text-Encoding Standards",
                "Compiler Defenses",
                "Supply-Chain Compromise"
            ]
        },
        "url": "URL#915204"
    },
    {
        "@score": "1",
        "@id": "915205",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "331/3095",
                        "text": "Oliver Broadrick"
                    },
                    {
                        "@pid": "p/PLVora",
                        "text": "Poorvi L. Vora"
                    },
                    {
                        "@pid": "64/35",
                        "text": "Filip Zag\u00f3rski"
                    }
                ]
            },
            "title": "PROVIDENCE: a Flexible Round-by-Round Risk-Limiting Audit.",
            "venue": "USENIX Security Symposium",
            "pages": "6753-6770",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BroadrickVZ23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/broadrick",
            "url": "https://dblp.org/rec/conf/uss/BroadrickVZ23",
            "abstract": "A Risk-Limiting Audit (RLA) is a statistical election tabulation audit with a rigorous error guarantee. We present ballot polling RLA PROVIDENCE, an audit with the efficiency of MINERVA and flexibility of BRAVO, and prove that it is risk-limiting in the presence of an adversary who can choose subsequent round sizes given knowledge of previous samples. We describe a measure of audit workload as a function of the number of rounds, precincts touched, and ballots drawn and quantify the problem of obtaining a misleading audit sample when rounds are too small, demonstrating the importance of the resulting constraint on audit planning. We describe an approach to planning audit round schedules using these measures and present simulation results demonstrating the superiority of PROVIDENCE.\nWe describe the use of PROVIDENCE by the Rhode Island Board of Elections in a tabulation audit of the 2021 election. Our implementation of PROVIDENCE in the open source R2B2 library has been integrated as an option in Arlo, the most commonly used RLA software.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-broadrick.pdf",
            "keywords": [
                "Risk-Limiting Audit",
                "Election Integrity",
                "Ballot Polling",
                "Audit Efficiency",
                "Audit Planning"
            ]
        },
        "url": "URL#915205"
    },
    {
        "@score": "1",
        "@id": "915206",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "353/7587",
                        "text": "Lina Brunken"
                    },
                    {
                        "@pid": "313/4504",
                        "text": "Annalina Buckmann"
                    },
                    {
                        "@pid": "296/3944",
                        "text": "Jonas Hielscher"
                    },
                    {
                        "@pid": "s/MASasse",
                        "text": "M. Angela Sasse"
                    }
                ]
            },
            "title": "&quot;To Do This Properly, You Need More Resources&quot;: The Hidden Costs of Introducing Simulated Phishing Campaigns.",
            "venue": "USENIX Security Symposium",
            "pages": "4105-4122",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BrunkenBHS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/brunken",
            "url": "https://dblp.org/rec/conf/uss/BrunkenBHS23",
            "abstract": "Many organizations use phishing simulation campaigns to raise and measure their employees\u2019 security awareness. They can create their own campaigns, or buy phishing-as-a-service from commercial providers; however, the evaluations of the effectiveness in reducing the vulnerability to such attacks have produced mixed results. Recently, researchers have pointed out \u201chidden costs\u201d \u2013 such as reduced productivity and employee trust. What has not been investigated is the cost involved in preparing an organization for a simulated phishing campaign. We present the first case study of an organization going through the process of selecting and purchasing a phishing simulation. We document and analyze the effort of different stakeholders involved, and present reflection from semi-structured interviews with 6 key actors at the end of the pro-curement process. Our data analysis shows that procuring such simulations can require significant effort from different stakeholders \u2013 in our case, at least 50,000C in person hours \u2013 and many hidden intangible costs. Evaluating if a product or service meets training requirements, is acceptable to employees, and preparing the technical infrastructure and operational processes for running such a product all require significant time and effort. The prevailing perception that phishing simulation campaigns are a quick and low-cost solu-tion to providing security training to employees thus needs to be challenged.",
            "keywords": [
                "Phishing Simulation",
                "Security Awareness Training",
                "Hidden Costs",
                "Employee Trust",
                "Resource Allocation"
            ]
        },
        "url": "URL#915206",
        "sema_paperId": "80c48bc060c631a56cd862b6ce2e877b2dff94da"
    },
    {
        "@score": "1",
        "@id": "915207",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "199/2102",
                        "text": "Zekun Cai"
                    },
                    {
                        "@pid": "162/1393",
                        "text": "Aiping Xiong"
                    }
                ]
            },
            "title": "Understand Users&apos; Privacy Perception and Decision of V2X Communication in Connected Autonomous Vehicles.",
            "venue": "USENIX Security Symposium",
            "pages": "2975-2992",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CaiX23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/cai-zekun",
            "url": "https://dblp.org/rec/conf/uss/CaiX23",
            "abstract": "Connected autonomous vehicles (CAVs) offer opportunities to improve road safety and enhance traffic efficiency. Vehicle-to-everything (V2X) communication allows CAVs to communicate with any entity that may affect, or may be affected by, the vehicles. The implementation of V2X in CAVs is in-separable from sharing and receiving a wide variety of data. Nevertheless, the public is not necessarily aware of such ubiquitous data exchange or does not understand their implications. We conducted an online study ( N = 595) examining drivers\u2019 privacy perceptions and decisions of four V2X application scenarios. Participants perceived more benefits but fewer risks of data sharing in the V2X scenarios where data collection is critical for driving than otherwise. They also showed more willingness to share data in those scenarios. In addition, we found that participants\u2019 awareness of privacy risks (priming) and their experience on driving assistance and connectivity functions impacted their data-sharing decisions. Qualitative data confirmed that benefits, especially safety, come first, indicating a privacy-safety tradeoff. Moreover, factors such as misconceptions and novel expectations about CAV data collection and use moderated participants\u2019 privacy decisions. We discuss implications of the obtained results to inform CAV privacy design and development.",
            "keywords": [
                "Connected Autonomous Vehicles",
                "V2X Communication",
                "Privacy Perception",
                "Data Sharing Decisions",
                "Privacy-Safety Tradeoff"
            ]
        },
        "url": "URL#915207",
        "sema_paperId": "0253d5c4baa156f845b3f6e30c37b465cb9a5b28"
    },
    {
        "@score": "1",
        "@id": "915208",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "295/3456",
                        "text": "Yuandao Cai"
                    },
                    {
                        "@pid": "269/8140",
                        "text": "Peisen Yao"
                    },
                    {
                        "@pid": "332/5984",
                        "text": "Chengfeng Ye"
                    },
                    {
                        "@pid": "51/7008-1",
                        "text": "Charles Zhang 0001"
                    }
                ]
            },
            "title": "Place Your Locks Well: Understanding and Detecting Lock Misuse Bugs.",
            "venue": "USENIX Security Symposium",
            "pages": "3727-3744",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CaiYYZ23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/cai-yuandao",
            "url": "https://dblp.org/rec/conf/uss/CaiYYZ23",
            "abstract": "Modern multi-threaded software systems commonly leverage locks to prevent concurrency bugs. Neverthe-less, due to the complexity of writing the correct concurrent code, using locks itself is often error-prone. In this work, we investigate a general variety of lock mis-uses. Our characteristic study of existing CVE IDs reveals that lock misuses can in\ufb02ict concurrency errors and even severe security issues, such as denial-of-service and memory corruption. To alleviate the threats, we present a practical static analysis framework, namely L OCK - PICK , which consists of two core stages to effectively detect misused locks. More speci\ufb01cally, L OCKPICK \ufb01rst conducts path-sensitive typestate analysis, tracking lock-state transitions and interactions to identify sequential typestate violations. Guided by the preceding results, L OCKPICK then performs concurrency-aware detection to pinpoint various lock misuse errors, effectively reasoning about the thread interleavings of interest. The results are encouraging \u2014 we have used L OCKPICK to uncover 203 unique and con\ufb01rmed lock misuses across a broad spectrum of impactful open-source systems, such as OpenSSL, the Linux kernel, PostgreSQL, MariaDB, FFmpeg, Apache HTTPd, and FreeBSD. Three exciting results are that those con\ufb01rmed lock misuses are long-latent, hiding for 7.4 years on average; in total, 16 CVE IDs have been assigned for the severe errors uncovered; and L OCKPICK can \ufb02ag many real bugs missed by the previous tools with signi\ufb01cantly fewer false positives.",
            "keywords": [
                "Lock Misuse",
                "Concurrency Bugs",
                "Static Analysis",
                "Typestate Analysis",
                "Concurrency-Aware Detection"
            ]
        },
        "url": "URL#915208",
        "sema_paperId": "7e30f5f5d821f549200ad7fdfbc1fa14fbfacd94"
    },
    {
        "@score": "1",
        "@id": "915209",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "353/7550",
                        "text": "Zechao Cai"
                    },
                    {
                        "@pid": "353/7626",
                        "text": "Jiaxun Zhu"
                    },
                    {
                        "@pid": "18/5040",
                        "text": "Wenbo Shen"
                    },
                    {
                        "@pid": "218/5245",
                        "text": "Yutian Yang"
                    },
                    {
                        "@pid": "61/1290",
                        "text": "Rui Chang"
                    },
                    {
                        "@pid": "02/5889",
                        "text": "Yu Wang"
                    },
                    {
                        "@pid": "06/8291",
                        "text": "Jinku Li"
                    },
                    {
                        "@pid": "20/6179-1",
                        "text": "Kui Ren 0001"
                    }
                ]
            },
            "title": "Demystifying Pointer Authentication on Apple M1.",
            "venue": "USENIX Security Symposium",
            "pages": "2833-2848",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CaiZSYCWL023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/cai-zechao",
            "url": "https://dblp.org/rec/conf/uss/CaiZSYCWL023",
            "abstract": "Pointer Authentication (PA) was introduced by ARMv8.3 to safeguard the integrity of pointers. While the ARM specification allows vendors to implement and customize PA, Apple has tailored it on their hardware to protect iPhones and Macs with M-series chips. Since its debut, Apple PA has been considered effective in defeating pointer corruption. However, its details have not been publicly disclosed.To shed light on Apple PA customization, this paper conducts an in-depth reverse engineering study focused on Apple PA's hardware implementation and usage on the M1 chip. We develop a reverse engineering framework and propose novel techniques to uncover and confirm our new findings.Our study uncovers that Apple PA has implemented several hardware-based diversifiers to counter pointer forgery attacks across various domains, which is previously unknown to researchers outside of Apple. We further discover that the XNU kernel (the kernel used by iOS and macOS) incorporates nine types of modifiers for signing and authenticating pointers and customized key management based on Apple PA hardware. Based on our in-depth understanding of Apple PA, we perform a security analysis of PA-based control-flow integrity and data-flow integrity in the XNU kernel, identifying four attack surfaces. Apple has fixed these issues in a security update and assigned us a new CVE.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-cai-zechao.pdf",
            "keywords": [
                "Pointer Authentication",
                "Apple M1",
                "Reverse Engineering",
                "Control-Flow Integrity",
                "Data-Flow Integrity"
            ]
        },
        "url": "URL#915209",
        "sema_paperId": "cca0ea2b2c2e24f4bf5bcfa577b739749dc077a2"
    },
    {
        "@score": "1",
        "@id": "915210",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "22/7530",
                        "text": "Matteo Campanelli"
                    },
                    {
                        "@pid": "225/9829",
                        "text": "Mathias Hall-Andersen"
                    },
                    {
                        "@pid": "261/5139",
                        "text": "Simon Holmgaard Kamp"
                    }
                ]
            },
            "title": "Curve Trees: Practical and Transparent Zero-Knowledge Accumulators.",
            "venue": "USENIX Security Symposium",
            "pages": "4391-4408",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CampanelliHK23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/campanelli",
            "url": "https://dblp.org/rec/conf/uss/CampanelliHK23",
            "abstract": "In this work we improve upon the state of the art for practical zero-knowledge for set membership, a building block at the core of several privacy-aware applications, such as anonymous payments, credentials and whitelists. This primitive allows a user to show knowledge of an element in a large set without leaking the specific element. One of the obstacles to its deployment is efficiency. Concretely efficient solutions exist, e.g., those deployed in Zcash Sapling, but they often work at the price of a strong trust assumption: an underlying setup that must be generated by a trusted third party.\nTo find alternative approaches we focus on a common building block: accumulators, a cryptographic data structure which compresses the underlying set. We propose novel, more efficient and fully transparent constructions (i.e., without a trusted setup) for accumulators supporting zero-knowledge proofs for set membership. Technically, we introduce new approaches inspired by \"commit-and-prove\" techniques to combine shallow Merkle trees and 2-cycles of elliptic curves into a highly practical construction. Our basic accumulator construction\u2014dubbed Curve Trees\u2014is completely transparent (does not require a trusted setup) and is based on simple and widely used assumptions (DLOG and Random Oracle Model). Ours is the first fully transparent construction that obtains concretely small proof/commitment sizes for large sets and a proving time one order of magnitude smaller than proofs over Merkle Trees with Pedersen hash. For a concrete instantiation targeting 128 bits of security we obtain: a commitment to a set of any size is 256 bits; for \u2223S\u2223=240 a zero-knowledge membership proof is 2.9KB, its proving takes 2s and its verification 40ms on an ordinary laptop.\nUsing our construction as a building block we can design a simple and concretely efficient anonymous cryptocurrency with full anonymity set, which we dub Vcash. Its transactions can be verified in \u224880ms or \u22485ms when batch-verifying multiple (>100) transactions; transaction sizes are 4KB. Our timings are competitive with those of the approach in Zcash Sapling and trade slightly larger proofs (transactions in Zcash Sapling are 2.8KB) for a completely transparent setup.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-campanelli.pdf",
            "keywords": [
                "Zero-Knowledge Proofs",
                "Set Membership",
                "Cryptographic Accumulators",
                "Transparent Setup",
                "Curve Trees"
            ]
        },
        "url": "URL#915210"
    },
    {
        "@score": "1",
        "@id": "915211",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "249/1159",
                        "text": "Michele Campobasso"
                    },
                    {
                        "@pid": "37/9766",
                        "text": "Luca Allodi"
                    }
                ]
            },
            "title": "Know Your Cybercriminal: Evaluating Attacker Preferences by Measuring Profile Sales on an Active, Leading Criminal Market for User Impersonation at Scale.",
            "venue": "USENIX Security Symposium",
            "pages": "553-570",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CampobassoA23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/campobasso",
            "url": "https://dblp.org/rec/conf/uss/CampobassoA23",
            "abstract": "In this paper we exploit market features proper of a leading Russian cybercrime market for user impersonation at scale to evaluate attacker preferences when purchasing stolen user profiles, and the overall economic activity of the market. We run our data collection over a period of $161$ days and collect data on a sample of $1'193$ sold user profiles out of $11'357$ advertised products in that period and their characteristics. We estimate a market trade volume of up to approximately $700$ profiles per day, corresponding to estimated daily sales of up to $4'000$ USD and an overall market revenue within the observation period between $540k$ and $715k$ USD. We find profile provision to be rather stable over time and mainly focused on European profiles, whereas actual profile acquisition varies significantly depending on other profile characteristics. Attackers' interests focus disproportionally on profiles of certain types, including those originating in North America and featuring Crypto resources.  We model and evaluate the relative importance of different profile characteristics in the final decision of an attacker to purchase a profile, and discuss implications for defenses and risk evaluation.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-campobasso.pdf",
            "keywords": [
                "Cybercrime Market",
                "User Impersonation",
                "Stolen User Profiles",
                "Attacker Preferences",
                "Market Revenue Analysis"
            ]
        },
        "url": "URL#915211"
    },
    {
        "@score": "1",
        "@id": "915212",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "296/3181",
                        "text": "Federico Canale"
                    },
                    {
                        "@pid": "50/6307",
                        "text": "Tim G\u00fcneysu"
                    },
                    {
                        "@pid": "90/4585",
                        "text": "Gregor Leander"
                    },
                    {
                        "@pid": "271/4264",
                        "text": "Jan Philipp Thoma"
                    },
                    {
                        "@pid": "44/10381",
                        "text": "Yosuke Todo"
                    },
                    {
                        "@pid": "147/7755",
                        "text": "Rei Ueno"
                    }
                ]
            },
            "title": "SCARF - A Low-Latency Block Cipher for Secure Cache-Randomization.",
            "venue": "USENIX Security Symposium",
            "pages": "1937-1954",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CanaleGLTTU23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/canale",
            "url": "https://dblp.org/rec/conf/uss/CanaleGLTTU23",
            "abstract": ",",
            "keywords": [
                "Block Cipher",
                "Cache Randomization",
                "Low-Latency Encryption",
                "Cryptographic Security",
                "Performance Optimization"
            ]
        },
        "url": "URL#915212",
        "sema_paperId": "d69a85bc2bda84c1683f39a9c7005fb359ed2564"
    },
    {
        "@score": "1",
        "@id": "915213",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "207/6576",
                        "text": "Yulong Cao"
                    },
                    {
                        "@pid": "331/5580",
                        "text": "S. Hrushikesh Bhupathiraju"
                    },
                    {
                        "@pid": "328/2151",
                        "text": "Pirouz Naghavi"
                    },
                    {
                        "@pid": "68/2734",
                        "text": "Takeshi Sugawara 0001"
                    },
                    {
                        "@pid": "91/584",
                        "text": "Z. Morley Mao"
                    },
                    {
                        "@pid": "135/7828",
                        "text": "Sara Rampazzi"
                    }
                ]
            },
            "title": "You Can&apos;t See Me: Physical Removal Attacks on LiDAR-based Autonomous Vehicles Driving Frameworks.",
            "venue": "USENIX Security Symposium",
            "pages": "2993-3010",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CaoBN0MR23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/cao",
            "url": "https://dblp.org/rec/conf/uss/CaoBN0MR23",
            "abstract": "Autonomous Vehicles (AVs) increasingly use LiDAR-based object detection systems to perceive other vehicles and pedestrians on the road. While existing attacks on LiDAR-based autonomous driving architectures focus on lowering the confidence score of AV object detection models to induce obstacle misdetection, our research discovers how to leverage laser-based spoofing techniques to selectively remove the LiDAR point cloud data of genuine obstacles at the sensor level before being used as input to the AV perception. The ablation of this critical LiDAR information causes autonomous driving obstacle detectors to fail to identify and locate obstacles and, consequently, induces AVs to make dangerous automatic driving decisions. In this paper, we present a method invisible to the human eye that hides objects and deceives autonomous vehicles' obstacle detectors by exploiting inherent automatic transformation and filtering processes of LiDAR sensor data integrated with autonomous driving frameworks. We call such attacks Physical Removal Attacks (PRA), and we demonstrate their effectiveness against three popular AV obstacle detectors (Apollo, Autoware, PointPillars), and we achieve 45{\\deg} attack capability. We evaluate the attack impact on three fusion models (Frustum-ConvNet, AVOD, and Integrated-Semantic Level Fusion) and the consequences on the driving decision using LGSVL, an industry-grade simulator. In our moving vehicle scenarios, we achieve a 92.7% success rate removing 90\\% of a target obstacle's cloud points. Finally, we demonstrate the attack's success against two popular defenses against spoofing and object hiding attacks and discuss two enhanced defense strategies to mitigate our attack.",
            "keywords": [
                "LiDAR-based Autonomous Vehicles",
                "Physical Removal Attacks",
                "Obstacle Detection",
                "Laser-based Spoofing",
                "Autonomous Driving Safety"
            ]
        },
        "url": "URL#915213",
        "sema_paperId": "c14543b043ef8d5956ef49d22518f12e0f3822f8"
    },
    {
        "@score": "1",
        "@id": "915214",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "145/1806",
                        "text": "Nicholas Carlini"
                    },
                    {
                        "@pid": "168/8164",
                        "text": "Jamie Hayes"
                    },
                    {
                        "@pid": "187/8997",
                        "text": "Milad Nasr"
                    },
                    {
                        "@pid": "218/5156",
                        "text": "Matthew Jagielski"
                    },
                    {
                        "@pid": "187/5613",
                        "text": "Vikash Sehwag"
                    },
                    {
                        "@pid": "158/7224",
                        "text": "Florian Tram\u00e8r"
                    },
                    {
                        "@pid": "06/8421",
                        "text": "Borja Balle"
                    },
                    {
                        "@pid": "192/2031",
                        "text": "Daphne Ippolito"
                    },
                    {
                        "@pid": "218/6165",
                        "text": "Eric Wallace"
                    }
                ]
            },
            "title": "Extracting Training Data from Diffusion Models.",
            "venue": "USENIX Security Symposium",
            "pages": "5253-5270",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CarliniHNJSTBIW23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/carlini",
            "url": "https://dblp.org/rec/conf/uss/CarliniHNJSTBIW23",
            "abstract": "Image diffusion models such as DALL-E 2, Imagen, and Stable Diffusion have attracted significant attention due to their ability to generate high-quality synthetic images. In this work, we show that diffusion models memorize individual images from their training data and emit them at generation time. With a generate-and-filter pipeline, we extract over a thousand training examples from state-of-the-art models, ranging from photographs of individual people to trademarked company logos. We also train hundreds of diffusion models in various settings to analyze how different modeling and data decisions affect privacy. Overall, our results show that diffusion models are much less private than prior generative models such as GANs, and that mitigating these vulnerabilities may require new advances in privacy-preserving training.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-carlini.pdf",
            "keywords": [
                "Image Diffusion Models",
                "Training Data Extraction",
                "Privacy Vulnerabilities",
                "Synthetic Image Generation",
                "Memorization of Training Data"
            ]
        },
        "url": "URL#915214"
    },
    {
        "@score": "1",
        "@id": "915215",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "322/1174",
                        "text": "Adam Caulfield"
                    },
                    {
                        "@pid": "198/1339",
                        "text": "Norrathep Rattanavipanon"
                    },
                    {
                        "@pid": "173/5375",
                        "text": "Ivan De Oliveira Nunes"
                    }
                ]
            },
            "title": "ACFA: Secure Runtime Auditing &amp; Guaranteed Device Healing via Active Control Flow Attestation.",
            "venue": "USENIX Security Symposium",
            "pages": "5827-5844",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CaulfieldRN23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/caulfield",
            "url": "https://dblp.org/rec/conf/uss/CaulfieldRN23",
            "abstract": "Embedded devices are increasingly used in a wide range of \u201csmart\u201d applications and spaces. At the lower-end of the scale, they are implemented under strict cost and energy budgets, using microcontroller units (MCUs) that lack security features akin to those available in general-purpose processors. In this context, Remote Attestation (RA) was proposed as an inexpensive security service that enables a verifier (Vrf) to remotely detect illegal modifications to the software binary installed on a prover MCU (Prv). Despite its effectiveness to validate Prv's binary integrity, attacks that hijack the software's control flow (potentially leading to privilege escalation or code reuse attacks) cannot be detected by classic RA.Control Flow Attestation (CFA) augments RA with information about the exact order in which instructions in the binary are executed. As such, CFA enables detection of the aforementioned control flow attacks. However, we observe that current CFA architectures cannot guarantee that Vrf ever receives control flow reports in case of attacks. In turn, while they support detection of exploits, they provide no means to pinpoint the exploit origin. Furthermore, existing CFA requires either (1) binary instrumentation, incurring significant runtime overhead and code size increase; or (2) relatively expensive hardware support, such as hash engines. In addition, current techniques are neither continuous (they are only meant to attest small and self-contained operations) nor active (once compromises are detected, they offer no secure means to remotely remediate the problem).To jointly address these challenges, we propose ACFA: a hybrid (hardware/software) architecture for Active CFA. ACFA enables continuous monitoring of all control flow transfers in the MCU and does not require binary instrumentation. It also leverages the recently proposed concept of \u201cactive roots-of-trust\u201d to enable secure auditing of vulnerability sources and guaranteed remediation, in case of compromise detection. We provide an open-source reference implementation of ACFA on top of a commodity low-end MCU (TI MSP430) and evaluate it to demonstrate its security and cost-effectiveness.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-caulfield.pdf",
            "keywords": [
                "Embedded Device Security",
                "Remote Attestation",
                "Control Flow Attestation",
                "Active Control Flow Auditing",
                "Vulnerability Remediation"
            ]
        },
        "url": "URL#915215"
    },
    {
        "@score": "1",
        "@id": "915216",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "353/7526",
                        "text": "Rose Ceccio"
                    },
                    {
                        "@pid": "325/3688",
                        "text": "Sophie Stephenson"
                    },
                    {
                        "@pid": "353/7541",
                        "text": "Varun Chadha"
                    },
                    {
                        "@pid": "77/8851",
                        "text": "Danny Yuxing Huang"
                    },
                    {
                        "@pid": "03/9962",
                        "text": "Rahul Chatterjee 0001"
                    }
                ]
            },
            "title": "Sneaky Spy Devices and Defective Detectors: The Ecosystem of Intimate Partner Surveillance with Covert Devices.",
            "venue": "USENIX Security Symposium",
            "pages": "123-140",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CeccioSCH023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/ceccio",
            "url": "https://dblp.org/rec/conf/uss/CeccioSCH023",
            "abstract": "Recent anecdotal evidence suggests that abusers have begun to use covert spy devices such as nanny cameras, item trackers, and audio recorders to spy on and stalk their partners. Currently, it is difficult to combat this type of intimate partner surveillance (IPS) because we lack an understanding of the prevalence and characteristics of commercial spy devices. Additionally, it is unclear whether existing devices, apps, and tools designed to detect covert devices are effective. We observe that many spy devices and detectors can be found on mainstream retailers. Thus, in this work, we perform a systematic survey of spy devices and detection tools sold through popular US retailers. We gather 2,228 spy devices, 1,313 detection devices, and 51 detection apps, then study a representative sample through qualitative analysis as well as in-lab evaluations. Our results show a bleak picture of the IPS ecosystem. Not only can commercial spy devices easily be used for IPS, but many of them are advertised for use in IPS and other covert surveillance. On the other hand, commercial detection devices and apps are all but defective, and while recent academic detection systems show promise, they require much refinement before they can be useful to survivors. We urge the security community to take action by designing practical, usable detection tools to detect hidden spy devices.",
            "keywords": [
                "Intimate Partner Surveillance",
                "Covert Devices",
                "Spy Devices",
                "Detection Tools",
                "Survivor Safety"
            ]
        },
        "url": "URL#915216",
        "sema_paperId": "83f1a892065a4a44d0a8f4c572289fd405ece622"
    },
    {
        "@score": "1",
        "@id": "915217",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "322/6258",
                        "text": "Federico Cernera"
                    },
                    {
                        "@pid": "223/6903",
                        "text": "Massimo La Morgia"
                    },
                    {
                        "@pid": "m/AlessandroMai",
                        "text": "Alessandro Mei"
                    },
                    {
                        "@pid": "265/6089",
                        "text": "Francesco Sassi"
                    }
                ]
            },
            "title": "Token Spammers, Rug Pulls, and Sniper Bots: An Analysis of the Ecosystem of Tokens in Ethereum and in the Binance Smart Chain (BNB).",
            "venue": "USENIX Security Symposium",
            "pages": "3349-3366",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CerneraMMS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/cernera",
            "url": "https://dblp.org/rec/conf/uss/CerneraMMS23",
            "abstract": "In this work, we perform a longitudinal analysis of the BNB Smart Chain and Ethereum blockchain from their inception to March 2022. We study the ecosystem of the tokens and liquidity pools, highlighting analogies and differences between the two blockchains. We discover that about 60% of tokens are active for less than one day. Moreover, we find that 1% of addresses create an anomalous number of tokens (between 20% and 25%). We discover that these tokens are used as disposable tokens to perform a particular type of rug pull, which we call 1-day rug pull. We quantify the presence of this operation on both blockchains discovering its prevalence on the BNB Smart Chain. We estimate that 1-day rug pulls generated $240 million in profits. Finally, we present sniper bots, a new kind of trader bot involved in these activities, and we detect their presence and quantify their activity in the rug pull operations.",
            "keywords": [
                "Token Ecosystem",
                "Rug Pulls",
                "BNB Smart Chain",
                "Ethereum Blockchain",
                "Sniper Bots"
            ]
        },
        "url": "URL#915217",
        "sema_paperId": "63853b63ef5f693be3d95e553a8341bda590c370"
    },
    {
        "@score": "1",
        "@id": "915218",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "157/8155",
                        "text": "Anrin Chakraborti"
                    },
                    {
                        "@pid": "141/9910",
                        "text": "Giulia Fanti"
                    },
                    {
                        "@pid": "r/MichaelKReiter",
                        "text": "Michael K. Reiter"
                    }
                ]
            },
            "title": "Distance-Aware Private Set Intersection.",
            "venue": "USENIX Security Symposium",
            "pages": "319-336",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChakrabortiFR23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/chakraborti-intersection",
            "url": "https://dblp.org/rec/conf/uss/ChakrabortiFR23",
            "abstract": "Private set intersection (PSI) allows two mutually untrusting parties to compute an intersection of their sets, without revealing information about items that are not in the intersection. This work introduces a PSI variant called distance-aware PSI (DA-PSI) for sets whose elements lie in a metric space. DAPSI returns pairs of items that are within a specified distance threshold of each other. This paper puts forward DA-PSI constructions for two metric spaces: (i) Minkowski distance of order 1 over the set of integers (i.e., for integers a and b, their distance is |a\u2212b|); and (ii) Hamming distance over the set of binary strings of length \u2113. In the Minkowski DA-PSI protocol, the communication complexity scales logarithmically in the distance threshold and linearly in the set size. In the Hamming DA-PSI protocol, the communication volume scales quadratically in the distance threshold and is independent of the dimensionality of string length \u2113. Experimental results with real applications confirm that DA-PSI provides more effective matching at lower cost than na\u00efve solutions.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-chakraborti-intersection.pdf",
            "keywords": [
                "Private Set Intersection",
                "Distance-Aware PSI",
                "Metric Space",
                "Minkowski Distance",
                "Hamming Distance"
            ]
        },
        "url": "URL#915218"
    },
    {
        "@score": "1",
        "@id": "915219",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "157/8155",
                        "text": "Anrin Chakraborti"
                    },
                    {
                        "@pid": "163/2618",
                        "text": "Darius Suciu"
                    },
                    {
                        "@pid": "s/RaduSion",
                        "text": "Radu Sion"
                    }
                ]
            },
            "title": "Wink: Deniable Secure Messaging.",
            "venue": "USENIX Security Symposium",
            "pages": "1271-1288",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChakrabortiSS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/chakraborti-wink",
            "url": "https://dblp.org/rec/conf/uss/ChakrabortiSS23",
            "abstract": "End-to-end encrypted (E2EE) messaging is an essential first step in providing message confidentiality. Unfortunately, all security guarantees of end-to-end encryption are lost when keys or plaintext are disclosed, either due to device compromise or (sometimes lawful) coercion by powerful adversaries. This work introduces Wink, the first plausibly-deniable messaging system protecting message confidentiality from partial device compromise and compelled key disclosure. Wink can surreptitiously inject hidden messages in standard random coins (e.g., salts, IVs) used by existing E2EE protocols. It does so as part of legitimate secure cryptographic functionality deployed inside the widely-available trusted execution environment (TEE) TrustZone. This results in hidden communication using virtually unchanged existing E2EE messaging apps, as well as strong plausible deniability. Wink has been demonstrated with multiple existing E2EE applications (including Telegram and Signal) with minimal (external) instrumentation, negligible overheads, and crucially, without changing on-wire message formats.",
            "keywords": [
                "End-to-End Encryption",
                "Plausible Deniability",
                "Secure Messaging",
                "Device Compromise",
                "Hidden Communication"
            ]
        },
        "url": "URL#915219",
        "sema_paperId": "102ebcec3116c71e18f03e255ce8afd9ad25a0de"
    },
    {
        "@score": "1",
        "@id": "915220",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "123/6988",
                        "text": "Ian Chang"
                    },
                    {
                        "@pid": "129/1428",
                        "text": "Katerina Sotiraki"
                    },
                    {
                        "@pid": "160/1002",
                        "text": "Weikeng Chen"
                    },
                    {
                        "@pid": "36/195",
                        "text": "Murat Kantarcioglu"
                    },
                    {
                        "@pid": "91/275",
                        "text": "Raluca A. Popa"
                    }
                ]
            },
            "title": "HOLMES: Efficient Distribution Testing for Secure Collaborative Learning.",
            "venue": "USENIX Security Symposium",
            "pages": "4823-4840",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChangSCKP23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/chang",
            "url": "https://dblp.org/rec/conf/uss/ChangSCKP23",
            "abstract": "Using secure multiparty computation (MPC) , organizations which own sensitive data (e.g., in healthcare, \ufb01nance or law enforcement) can train machine learning models over their joint dataset without revealing their data to each other. At the same time, secure computation restricts operations on the joint dataset, which impedes computation to assess its quality. Without such an assessment, deploying a jointly trained model is potentially illegal. Regulations, such as the European Union\u2019s General Data Protection Regulation (GDPR), require organizations to be legally responsible for the errors, bias, or discrimination caused by their machine learning models. Hence, testing data quality emerges as an indispensable step in secure collaborative learning. However, performing distribution testing is prohibitively expensive using current techniques, as shown in our experiments. We present HOLMES, a protocol for performing distribution testing ef\ufb01ciently . In our experiments, compared with three non-trivial baselines, HOLMES achieves a speedup of more than 10 \u00d7 for classical distribution tests and up to 10 4 \u00d7 for multidimensional tests. The core of HOLMES is a hybrid protocol that integrates MPC with zero-knowledge proofs and a new ZK-friendly and naturally oblivious sketching algo-rithm for multidimensional tests, both with signi\ufb01cantly lower computational complexity and concrete execution costs.",
            "keywords": [
                "Secure Multiparty Computation",
                "Collaborative Learning",
                "Distribution Testing",
                "Data Quality Assessment",
                "Zero-Knowledge Proofs"
            ]
        },
        "url": "URL#915220",
        "sema_paperId": "4a6ef9152daddd00b9884c13f1bcd93a64d0610e"
    },
    {
        "@score": "1",
        "@id": "915221",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "62/4375",
                        "text": "Hongbo Chen"
                    },
                    {
                        "@pid": "353/7676",
                        "text": "Haobin Hiroki Chen"
                    },
                    {
                        "@pid": "126/5031",
                        "text": "Mingshen Sun"
                    },
                    {
                        "@pid": "181/2763",
                        "text": "Kang Li"
                    },
                    {
                        "@pid": "50/10188",
                        "text": "Zhaofeng Chen"
                    },
                    {
                        "@pid": "06/6268",
                        "text": "XiaoFeng Wang 0001"
                    }
                ]
            },
            "title": "A Verified Confidential Computing as a Service Framework for Privacy Preservation.",
            "venue": "USENIX Security Symposium",
            "pages": "4733-4750",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChenCSLC023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/chen-hongbo",
            "url": "https://dblp.org/rec/conf/uss/ChenCSLC023",
            "abstract": "We propose a security protection principle for confidential computing, Proof of Being Forgotten (PoBF). It has two requirements: N O L EAKAGE and N O R ESIDUE . These properties are formalized and proven under an abstract model for Trusted Execution Environment (TEE) in Coq. On the other hand, we implement a prototype PoBF-Compliant Framework (PoCF), which provides a framework to conduct Confidential Computing as a Service (CCaaS). These prototypes come with a verifier that can prove some properties specified in PoBF are satisfied. Besides, PoCF can support various real-world applications and the protections introduced in PoCF incur minor runtime performance overhead.",
            "keywords": [
                "Confidential Computing",
                "Privacy Preservation",
                "Trusted Execution Environment",
                "Proof of Being Forgotten",
                "Confidential Computing as a Service (CCaaS)"
            ]
        },
        "url": "URL#915221",
        "sema_paperId": "3fb08f0420570d002c5dcc21335a7e770d4419c9"
    },
    {
        "@score": "1",
        "@id": "915222",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "65/4423",
                        "text": "Chen Chen"
                    },
                    {
                        "@pid": "295/3339",
                        "text": "Rahul Kande"
                    },
                    {
                        "@pid": "335/4483",
                        "text": "Nathan Nguyen"
                    },
                    {
                        "@pid": "85/5806",
                        "text": "Flemming Andersen"
                    },
                    {
                        "@pid": "255/3072",
                        "text": "Aakash Tyagi"
                    },
                    {
                        "@pid": "s/AhmadRezaSadeghi",
                        "text": "Ahmad-Reza Sadeghi"
                    },
                    {
                        "@pid": "79/9006",
                        "text": "Jeyavijayan Rajendran"
                    }
                ]
            },
            "title": "HyPFuzz: Formal-Assisted Processor Fuzzing.",
            "venue": "USENIX Security Symposium",
            "pages": "1361-1378",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChenKNATSR23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/chen-chen",
            "url": "https://dblp.org/rec/conf/uss/ChenKNATSR23",
            "abstract": "Recent research has shown that hardware fuzzers can effectively detect security vulnerabilities in modern processors. However, existing hardware fuzzers do not fuzz well the hard-to-reach design spaces. Consequently, these fuzzers cannot effectively fuzz security-critical control- and data-flow logic in the processors, hence missing security vulnerabilities. To tackle this challenge, we present HyPFuzz, a hybrid fuzzer that leverages formal verification tools to help fuzz the hard-to-reach part of the processors. To increase the effectiveness of HyPFuzz, we perform optimizations in time and space. First, we develop a scheduling strategy to prevent under- or over-utilization of the capabilities of formal tools and fuzzers. Second, we develop heuristic strategies to select points in the design space for the formal tool to target. We evaluate HyPFuzz on five widely-used open-source processors. HyPFuzz detected all the vulnerabilities detected by the most recent processor fuzzer and found three new vulnerabilities that were missed by previous extensive fuzzing and formal verification. This led to two new common vulnerabilities and exposures (CVE) entries. HyPFuzz also achieves 11.68\u00d7 faster coverage than the most recent processor fuzzer.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-chen-chen.pdf",
            "keywords": [
                "Processor Fuzzing",
                "Formal Verification",
                "Security Vulnerabilities",
                "Design Space Exploration",
                "Hybrid Fuzzer"
            ]
        },
        "url": "URL#915222"
    },
    {
        "@score": "1",
        "@id": "915223",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "198/6782",
                        "text": "Sanchuan Chen"
                    },
                    {
                        "@pid": "49/4102-1",
                        "text": "Zhiqiang Lin 0001"
                    },
                    {
                        "@pid": "77/3503",
                        "text": "Yinqian Zhang"
                    }
                ]
            },
            "title": "Controlled Data Races in Enclaves: Attacks and Detection.",
            "venue": "USENIX Security Symposium",
            "pages": "4069-4086",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChenLZ23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/chen-sanchuan",
            "url": "https://dblp.org/rec/conf/uss/ChenLZ23",
            "abstract": "This paper introduces controlled data race attacks , a new class of attacks against programs guarded by trusted execution environments such as Intel SGX. Controlled data race attacks are analog to controlled channel attacks, where the adversary controls the underlying operating system and manipulates the scheduling of enclave threads and handling of interrupts and exceptions. Controlled data race attacks are of particular interest for two reasons: First, traditionally non-deterministic data race bugs can be triggered deterministically and exploited for security violation in the context of SGX enclaves. Second, an intended single-threaded enclave can be concurrently invoked by the adversary, which triggers unique interleaving patterns that would not occur in traditional settings. To detect the controlled data race vulnerabilities in real-world enclave binaries (including the code linked with the SGX libraries), we present a lockset-based binary analysis detection algorithm. We have implemented our algorithm in a tool named SGXR ACER , and evaluated it with four SGX SDKs and eight open-source SGX projects, identifying 1 , 780 data races originated from 476 shared variables.",
            "keywords": [
                "Trusted Execution Environments",
                "Intel SGX",
                "Controlled Data Races",
                "Binary Analysis",
                "Vulnerability Detection"
            ]
        },
        "url": "URL#915223",
        "sema_paperId": "44608a47491c70ce61909b25a65e55d1b3cb9dbf"
    },
    {
        "@score": "1",
        "@id": "915224",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "277/8177",
                        "text": "Xingman Chen"
                    },
                    {
                        "@pid": "353/7645",
                        "text": "Yinghao Shi"
                    },
                    {
                        "@pid": "242/0794",
                        "text": "Zheyu Jiang"
                    },
                    {
                        "@pid": "86/6196",
                        "text": "Yuan Li"
                    },
                    {
                        "@pid": "127/9829",
                        "text": "Ruoyu Wang 0001"
                    },
                    {
                        "@pid": "36/5143",
                        "text": "Haixin Duan"
                    },
                    {
                        "@pid": "50/8499-1",
                        "text": "Haoyu Wang 0001"
                    },
                    {
                        "@pid": "94/3019-8",
                        "text": "Chao Zhang 0008"
                    }
                ]
            },
            "title": "MTSan: A Feasible and Practical Memory Sanitizer for Fuzzing COTS Binaries.",
            "venue": "USENIX Security Symposium",
            "pages": "841-858",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChenSJL0DW023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/chen-xingman",
            "url": "https://dblp.org/rec/conf/uss/ChenSJL0DW023",
            "abstract": "Fuzzing has been widely adopted for finding vulnerabilities in programs, especially when source code is not available. But the effectiveness and efficiency of binary fuzzing are cur-tailed by the lack of memory (safety) sanitizers. This lack of binary sanitizers is due to the information loss in compiling programs and challenges in binary instrumentation. In this paper, we present a feasible and practical hardware-assisted memory sanitizer, MTSan, for binary fuzzing. MT-San can detect both spatial and temporal memory safety violations at runtime. It adopts a novel progressive object recovery scheme to recover objects in binaries, and uses a customized binary rewriting solution to instrument binaries with the memory-tagging-based memory safety sanitizing policy. Further, MTSan uses a hardware feature, ARM Memory Tagging Extension (MTE) to significantly reduce its runtime overhead. We implemented a prototype of MT-San on AArch64 and systematically evaluated its effectiveness and performance. Our evaluation results show that MT-San could detect more memory safety violations than existing binary sanitizers whiling introducing much lower run-time and memory overhead.",
            "keywords": [
                "Binary Fuzzing",
                "Memory Sanitization",
                "Memory Safety Violations",
                "Hardware-Assisted Instrumentation",
                "ARM Memory Tagging Extension (MTE)"
            ]
        },
        "url": "URL#915224",
        "sema_paperId": "f1beed8559df92c6da8392437282de12b87251ac"
    },
    {
        "@score": "1",
        "@id": "915225",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "49/6574",
                        "text": "Yi Chen"
                    },
                    {
                        "@pid": "77/1147-1",
                        "text": "Di Tang 0001"
                    },
                    {
                        "@pid": "226/0656",
                        "text": "Yepeng Yao"
                    },
                    {
                        "@pid": "205/3769",
                        "text": "Mingming Zha"
                    },
                    {
                        "@pid": "06/6268",
                        "text": "XiaoFeng Wang 0001"
                    },
                    {
                        "@pid": "11/6389",
                        "text": "Xiaozhong Liu"
                    },
                    {
                        "@pid": "90/3951",
                        "text": "Haixu Tang"
                    },
                    {
                        "@pid": "10/8471",
                        "text": "Baoxu Liu"
                    }
                ]
            },
            "title": "Sherlock on Specs: Building LTE Conformance Tests through Automated Reasoning.",
            "venue": "USENIX Security Symposium",
            "pages": "3529-3545",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChenTYZ0LTL23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/chen-yi",
            "url": "https://dblp.org/rec/conf/uss/ChenTYZ0LTL23",
            "abstract": "Conformance tests are critical for finding security weaknesses in carrier network systems. However, building a conformance test procedure from specifications is challenging, as indicated by the slow progress made by the 3GPP, particularly in developing security-related tests, even with a large amount of resources already committed. A unique challenge in building the procedure is that a testing system often cannot directly invoke the condition event in a security requirement or directly observe the occurrence of the operation expected to be triggered by the event. Addressing this issue requires an event chain to be found, which once initiated leads to a chain reaction so the testing system can either indirectly triggers the target event or indirectly observe the occurrence of the expected event. To find a solution to this problem and make progress towards a fully automated conformance test generation, we developed a new approach called Contester , which utilizes natural language processing and machine learning to build an event dependency graph from a 3GPP specification, and further perform automated reasoning on the graph to discover the event chains for a given security requirement. Such event chains are further converted by Contester into a conformance test procedure, which is then executed by a testing system to evaluate the compliance of user equipment (UE) with the security requirement. Our evaluation shows that given 22 security requirements from the LTE NAS specification, Contester successfully generated over a hundred test procedures in just 25 minutes. After running these procedures on 22 popular UEs including iPhone 13, Pixel 5a and IoT",
            "keywords": [
                "LTE Conformance Testing",
                "Automated Reasoning",
                "Event Dependency Graph",
                "Security Requirements",
                "Test Procedure Generation"
            ]
        },
        "url": "URL#915225",
        "sema_paperId": "a00dcb6f2e9d833a0c9f1b0226d053a7f76b227c"
    },
    {
        "@score": "1",
        "@id": "915226",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "87/1254",
                        "text": "Yu Chen"
                    },
                    {
                        "@pid": "46/2181",
                        "text": "Yang Yu"
                    },
                    {
                        "@pid": "38/10035",
                        "text": "Lidong Zhai"
                    }
                ]
            },
            "title": "InfinityGauntlet: Expose Smartphone Fingerprint Authentication to Brute-force Attack.",
            "venue": "USENIX Security Symposium",
            "pages": "2027-2041",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChenYZ23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/chen-yu",
            "url": "https://dblp.org/rec/conf/uss/ChenYZ23",
            "abstract": "Billions of smartphone fingerprint authentications (SFA) occur daily for unlocking, privacy and payment. Existing threats to SFA include presentation attacks (PA) and some case-by-case vulnerabilities. The former need to know the victim\u2019s fingerprint information (e.g., latent fingerprints) and can be mitigated by liveness detection and security policies. The latter require additional conditions (e.g., third-party screen protector, root permission) and are only exploitable for individual smartphone models. In this paper, we conduct the first investigation on the general zero-knowledge attack towards SFA where no knowledge about the victim is needed. We propose a novelty fingerprint brute-force attack on off-the-shelf smartphones, named I N - FINITY G AUNTLET . Firstly, we discover design vulnerabilities in SFA systems across various manufacturers, operating systems, and fingerprint types to achieve unlimited authentication attempts. Then, we use SPI MITM to bypass liveness detection and make automatic attempts. Finally, we customize a synthetic fingerprint generator to get a valid brute-force fingerprint dictionary. We design and implement low-cost equipment to launch I NFINITY G AUNTLET . A proof-of-concept case study demonstrates that I NFINITY G AUNTLET can brute-force attack successfully in less than an hour without any knowledge of the victim. Additionally, empirical analysis on representative smartphones shows the scalability of our work.",
            "keywords": [
                "Smartphone Fingerprint Authentication",
                "Brute-force Attack",
                "Liveness Detection Bypass",
                "Design Vulnerabilities",
                "Synthetic Fingerprint Generation"
            ]
        },
        "url": "URL#915226",
        "sema_paperId": "3d8c6e300b66a210bab866711041b1c8bda12c78"
    },
    {
        "@score": "1",
        "@id": "915227",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "44/9048",
                        "text": "Yongheng Chen"
                    },
                    {
                        "@pid": "95/305",
                        "text": "Rui Zhong"
                    },
                    {
                        "@pid": "297/3970",
                        "text": "Yupeng Yang"
                    },
                    {
                        "@pid": "70/2543-4",
                        "text": "Hong Hu 0004"
                    },
                    {
                        "@pid": "54/2696",
                        "text": "Dinghao Wu"
                    },
                    {
                        "@pid": "29/5976",
                        "text": "Wenke Lee"
                    }
                ]
            },
            "title": "\u00b5FUZZ: Redesign of Parallel Fuzzing using Microservice Architecture.",
            "venue": "USENIX Security Symposium",
            "pages": "1325-1342",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChenZY0WL23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/chen-yongheng",
            "url": "https://dblp.org/rec/conf/uss/ChenZY0WL23",
            "abstract": "Fuzzing has been widely adopted as an effective testing technique for detecting software bugs. Researchers have explored many parallel fuzzing approaches to speed up bug detection. However, existing approaches are built on top of serial fuzzers and rely on periodic fuzzing state synchronization. Such a de-sign has two limitations. First, the synchronous serial design of the fuzzer might waste CPU power due to blocking I/O operations. Second, state synchronization is either too late so that we fuzz with a suboptimal strategy or too frequent so that it causes enormous overhead. In this paper, we redesign parallel fuzzing with microser-vice architecture and propose the prototype \u00b5 F UZZ . To better utilize CPU power in the existence of I/O, \u00b5 F UZZ breaks down the synchronous fuzzing loops into concurrent microser-vices, each with multiple workers. To avoid state synchronization, \u00b5 F UZZ partitions the state into different services and their workers so that they can work independently but still achieve a great aggregated result. Our experiments show that \u00b5 F UZZ outperforms the second-best existing fuzzers with 24% improvements in code coverage and 33% improvements in bug detection on average in 24 hours. Besides, \u00b5 F UZZ \ufb01nds 11 new bugs in well-tested real-world programs.",
            "keywords": [
                "Parallel Fuzzing",
                "Microservice Architecture",
                "Software Testing",
                "Bug Detection",
                "Code Coverage"
            ]
        },
        "url": "URL#915227",
        "sema_paperId": "6c91701fcea30c5a2c98a900ccf5889ed73db85b"
    },
    {
        "@score": "1",
        "@id": "915228",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "252/5255",
                        "text": "Guangke Chen"
                    },
                    {
                        "@pid": "230/8027",
                        "text": "Yedi Zhang"
                    },
                    {
                        "@pid": "28/6429-7",
                        "text": "Zhe Zhao 0007"
                    },
                    {
                        "@pid": "09/10016",
                        "text": "Fu Song"
                    }
                ]
            },
            "title": "QFA2SR: Query-Free Adversarial Transfer Attacks to Speaker Recognition Systems.",
            "venue": "USENIX Security Symposium",
            "pages": "2437-2454",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChenZZS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/chen-guangke",
            "url": "https://dblp.org/rec/conf/uss/ChenZZS23",
            "abstract": "Current adversarial attacks against speaker recognition systems (SRSs) require either white-box access or heavy black-box queries to the target SRS, thus still falling behind practical attacks against proprietary commercial APIs and voice-controlled devices. To fill this gap, we propose QFA2SR, an effective and imperceptible query-free black-box attack, by leveraging the transferability of adversarial voices. To improve transferability, we present three novel methods, tailored loss functions, SRS ensemble, and time-freq corrosion. The first one tailors loss functions to different attack scenarios. The latter two augment surrogate SRSs in two different ways. SRS ensemble combines diverse surrogate SRSs with new strategies, amenable to the unique scoring characteristics of SRSs. Time-freq corrosion augments surrogate SRSs by incorporating well-designed time-/frequency-domain modification functions, which simulate and approximate the decision boundary of the target SRS and distortions introduced during over-the-air attacks. QFA2SR boosts the targeted transferability by 20.9%-70.7% on four popular commercial APIs (Microsoft Azure, iFlytek, Jingdong, and TalentedSoft), significantly outperforming existing attacks in query-free setting, with negligible effect on the imperceptibility. QFA2SR is also highly effective when launched over the air against three wide-spread voice assistants (Google Assistant, Apple Siri, and TMall Genie) with 60%, 46%, and 70% targeted transferability, respectively.",
            "keywords": [
                "Speaker Recognition Systems",
                "Adversarial Attacks",
                "Query-Free Attacks",
                "Transferability",
                "Over-the-Air Attacks"
            ]
        },
        "url": "URL#915228",
        "sema_paperId": "115ae8b0ace627ea6cd23170f4b6173b2dbd77a6"
    },
    {
        "@score": "1",
        "@id": "915229",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "221/3017",
                        "text": "Binlin Cheng"
                    },
                    {
                        "@pid": "301/5851",
                        "text": "Erika A. Leal"
                    },
                    {
                        "@pid": "83/4184",
                        "text": "Haotian Zhang"
                    },
                    {
                        "@pid": "09/6585-2",
                        "text": "Jiang Ming 0002"
                    }
                ]
            },
            "title": "On the Feasibility of Malware Unpacking via Hardware-assisted Loop Profiling.",
            "venue": "USENIX Security Symposium",
            "pages": "7481-7498",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChengLZ023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/cheng-binlin",
            "url": "https://dblp.org/rec/conf/uss/ChengLZ023",
            "abstract": "Hardware Performance Counters (HPCs) are built-in registers of modern processors to count the occurrences of various micro-architectural events. Measuring HPCs values is a cost-effective way to characterize dynamic program behaviors. Because of the ease of use and tamper-resistant advantages, using HPCs coupled with machine learning models to address security problems is on the rise in recent years. However, lately the suitability of HPCs for security has been questioned in light of the non-determinism concerns: measurement errors caused by interrupt skid and time-division multiplexing can undermine the effectiveness of using HPCs in security applications.\nWith these cautions in mind, we explore ways to tame hardware event\u2019s non-determinism nature for malware unpacking, which is a long-standing challenge in malware analysis. Our research is motivated by two key observations. First, the unpacking process, which involves expensive iterations of decryption or decompression, can incur identifiable deviations in hardware events. Second, loop-centric HPCs profiling can minimize the imprecisions caused by interrupt skid and time-division multiplexing. Therefore, we utilize two mechanisms offered by Intel CPUs (i.e., Precise Event-Based Sampling (PEBS) and Last Branch Record) to develop a generic, hardware-assisted unpacking technique, called LoopHPCs. It offers a new, obfuscation-resilient solution to identify the original code from multiple \u201cwritten-then-executed\u201d layers. Our controlled experiments demonstrate that LoopHPCs can obtain precise and consistent HPCs values across different Intel CPU architectures and OSs.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-cheng-binlin.pdf",
            "keywords": [
                "Malware Analysis",
                "Hardware Performance Counters",
                "Unpacking Techniques",
                "Loop Profiling",
                "Non-determinism in Measurements"
            ]
        },
        "url": "URL#915229",
        "sema_paperId": "0e2ae6b0bef47b942e13a0504b09cd4a567568d1"
    },
    {
        "@score": "1",
        "@id": "915230",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "259/8951",
                        "text": "Kaiming Cheng"
                    },
                    {
                        "@pid": "353/7586",
                        "text": "Jeffery F. Tian"
                    },
                    {
                        "@pid": "k/TadayoshiKohno",
                        "text": "Tadayoshi Kohno"
                    },
                    {
                        "@pid": "23/2758",
                        "text": "Franziska Roesner"
                    }
                ]
            },
            "title": "Exploring User Reactions and Mental Models Towards Perceptual Manipulation Attacks in Mixed Reality.",
            "venue": "USENIX Security Symposium",
            "pages": "911-928",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChengTKR23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/cheng-kaiming",
            "url": "https://dblp.org/rec/conf/uss/ChengTKR23",
            "abstract": "Perceptual Manipulation Attacks (PMA) involve manipulating users\u2019 multi-sensory (e.g., visual, auditory, haptic) perceptions of the world through Mixed Reality (MR) content, in order to influence users\u2019 judgments and following actions. For example, a MR driving application that is expected to show safety-critical output might also (maliciously or unintentionally) overlay the wrong signal on a traffic sign, misleading the user into slamming on the brake. While current MR technology is sufficient to create such attacks, little research has been done to understand how users perceive, react to, and defend against such potential manipulations. To provide a foundation for understanding and addressing PMA in MR, we conducted an in-person study with 21 participants. We developed three PMA in which we focused on attacking three different perceptions: visual, auditory, and situational awareness. Our study first investigates how user reactions are affected by evaluating their performance on \u201cmicrobenchmark\u201d tasks under benchmark and different attack conditions. We observe both primary and secondary impacts from attacks, later impacting participants\u2019 performance even under non-attack conditions. We follow up with interviews, surfacing a range of user reactions and interpretations of PMA. Through qualitative data analysis of our observations and interviews, we identify various defensive strategies participants developed, and we observe how these strategies sometimes backfire. We derive recommendations for future investigation and defensive directions based on our findings.",
            "keywords": [
                "Mixed Reality",
                "Perceptual Manipulation Attacks",
                "User Reactions",
                "Multi-Sensory Perception",
                "Defensive Strategies"
            ]
        },
        "url": "URL#915230",
        "sema_paperId": "f2e2ac089cfb087406f0177e9f6ecf902a069482"
    },
    {
        "@score": "1",
        "@id": "915231",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "62/8336",
                        "text": "Vincent Cheval"
                    },
                    {
                        "@pid": "17/2282",
                        "text": "Cas Cremers"
                    },
                    {
                        "@pid": "240/8159",
                        "text": "Alexander Dax"
                    },
                    {
                        "@pid": "140/7281",
                        "text": "Lucca Hirschi"
                    },
                    {
                        "@pid": "195/3195",
                        "text": "Charlie Jacomme"
                    },
                    {
                        "@pid": "k/SteveKremer",
                        "text": "Steve Kremer"
                    }
                ]
            },
            "title": "Hash Gone Bad: Automated discovery of protocol attacks that exploit hash function weaknesses.",
            "venue": "USENIX Security Symposium",
            "pages": "5899-5916",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChevalCDHJK23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/cheval",
            "url": "https://dblp.org/rec/conf/uss/ChevalCDHJK23",
            "abstract": "Most cryptographic protocols use cryptographic hash functions as a building block. The security analyses of these protocols typically assume that the hash functions are perfect (such as in the random oracle model). However, in practice, most widely deployed hash functions are far from perfect -- and as a result, the analysis may miss attacks that exploit the gap between the model and the actual hash function used. We develop the first methodology to systematically discover attacks on security protocols that exploit weaknesses in widely deployed hash functions. We achieve this by revisiting the gap between theoretical properties of hash functions and the weaknesses of real-world hash functions, from which we develop a lattice of threat models. For all of these threat models, we develop fine-grained symbolic models.\nOur methodology's fine-grained models cannot be directly encoded in existing state-of-the-art analysis tools by just using their equational reasoning. We therefore develop extensions for the two leading tools, Tamarin and Proverif. In extensive case studies using our methodology, the extended tools rediscover all attacks that were previously reported for these protocols and discover several new variants.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-cheval.pdf",
            "keywords": [
                "Cryptographic Protocols",
                "Hash Function Weaknesses",
                "Security Analysis",
                "Automated Attack Discovery",
                "Symbolic Models"
            ]
        },
        "url": "URL#915231"
    },
    {
        "@score": "1",
        "@id": "915232",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "132/7795",
                        "text": "Haotian Chi"
                    },
                    {
                        "@pid": "81/583-1",
                        "text": "Qiang Zeng 0001"
                    },
                    {
                        "@pid": "22/5535",
                        "text": "Xiaojiang Du"
                    }
                ]
            },
            "title": "Detecting and Handling IoT Interaction Threats in Multi-Platform Multi-Control-Channel Smart Homes.",
            "venue": "USENIX Security Symposium",
            "pages": "1559-1576",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Chi0D23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/chi",
            "url": "https://dblp.org/rec/conf/uss/Chi0D23",
            "abstract": "A smart home involves a variety of entities, such as IoT devices, automation applications, humans, voice assistants, and companion apps. These entities interact in the same physical environment, which can yield undesirable and even hazardous results, called IoT interaction threats . Existing work on interaction threats is limited to considering automation apps, ignoring other IoT control channels, such as voice commands, companion apps, and physical operations. Second, it becomes increasingly common that a smart home utilizes multiple IoT platforms, each of which has a partial view of device states and may issue conflicting commands. Third, compared to detecting interaction threats, their handling is much less studied. Prior work uses generic handling policies, which are unlikely to fit all homes. We present I O TM EDIATOR , which provides accurate threat detection and threat-tailored handling in multi-platform multi-control-channel homes. Our evaluation in two real-world homes demonstrates that I O TM EDIATOR significantly outperforms prior state-of-the-art work.",
            "keywords": [
                "IoT Interaction Threats",
                "Smart Home Security",
                "Multi-Platform Systems",
                "Control Channels",
                "Threat Detection and Handling"
            ]
        },
        "url": "URL#915232",
        "sema_paperId": "14076b1b6a77ea7a53c04d2a55071c6dafe600da"
    },
    {
        "@score": "1",
        "@id": "915233",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "27/8534",
                        "text": "Alessandro Chiesa"
                    },
                    {
                        "@pid": "256/9139",
                        "text": "Ryan Lehmkuhl"
                    },
                    {
                        "@pid": "161/3103",
                        "text": "Pratyush Mishra"
                    },
                    {
                        "@pid": "90/7422",
                        "text": "Yinuo Zhang"
                    }
                ]
            },
            "title": "Eos: Efficient Private Delegation of zkSNARK Provers.",
            "venue": "USENIX Security Symposium",
            "pages": "6453-6469",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChiesaLMZ23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/chiesa",
            "url": "https://dblp.org/rec/conf/uss/ChiesaLMZ23",
            "abstract": "Succinct zero knowledge proofs (i.e. zkSNARKs) are powerful cryptographic tools that enable a prover to convince a verifier that a given statement is true without revealing any additional information. Their attractive privacy properties have led to much academic and industrial interest. Unfortunately, existing systems for generating zkSNARKs are expensive, which limits the applications in which these proofs can be used. One approach is to take advantage of powerful cloud servers to generate the proof. However, existing techniques for this (e.g., DIZK) sacrifice privacy by revealing secret information to the cloud machines. This is problematic for many applications of zkSNARKs, such as decentralized private currency and computation systems. In this work we design and implement privacy-preserving delegation protocols for zkSNARKs with universal setup. Our protocols enable a prover to outsource proof generation to a set of workers, so that if at least one worker does not col-lude with other workers, no private information is revealed to any worker. Our protocols achieve security against malicious workers without relying on heavyweight cryptographic tools. We implement and evaluate our delegation protocols for a state-of-the-art zkSNARK in a variety of computational and bandwidth settings, and demonstrate that our protocols are concretely efficient. When compared to local proving, using our protocols to delegate proof generation from a recent smartphone (a) reduces end-to-end latency by up to 26 \u00d7 , (b) lowers the delegator\u2019s active computation time by up to 1447 \u00d7 , and (c) enables proving up to 256 \u00d7 larger instances.",
            "keywords": [
                "zkSNARKs",
                "Privacy-Preserving Delegation",
                "Proof Generation",
                "Cloud Computing",
                "Malicious Workers"
            ]
        },
        "url": "URL#915233",
        "sema_paperId": "3375f284fa4f9253bd5d8cbf46a7e677fc7c9ea8"
    },
    {
        "@score": "1",
        "@id": "915234",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "248/7403",
                        "text": "Mingi Cho"
                    },
                    {
                        "@pid": "308/0156",
                        "text": "Dohyeon An"
                    },
                    {
                        "@pid": "307/9956",
                        "text": "Hoyong Jin"
                    },
                    {
                        "@pid": "14/2293-2",
                        "text": "Taekyoung Kwon 0002"
                    }
                ]
            },
            "title": "BoKASAN: Binary-only Kernel Address Sanitizer for Effective Kernel Fuzzing.",
            "venue": "USENIX Security Symposium",
            "pages": "4985-5002",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChoAJ023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/cho",
            "url": "https://dblp.org/rec/conf/uss/ChoAJ023",
            "abstract": "Kernel Address Sanitizer (KASAN), an invaluable tool for \ufb01nding use-after-free and out-of-bounds bugs in the Linux kernel, needs the kernel source for compile-time instrumentation. To apply KASAN to closed-source systems, we should develop a binary-only KASAN, which is challenging. A technique that uses binary rewriting and processor support to run KASAN for binary modules needs a KASAN-applied kernel, thereby still the kernel source. Dynamic instrumentation offers an alternative way to it but greatly increases the performance overhead, rendering the kernel fuzzing impractical. To address these problems, we present the \ufb01rst practical, binary-only KASAN named BoKASAN , which conducts address sanitization through dynamic instrumentation for the entire kernel binaries ef\ufb01ciently. Our key idea is selective sanitization , which identi\ufb01es target processes to sanitize and hooks the page fault mechanism for signi\ufb01cantly reducing the performance overhead of dynamic instrumentation. Our key insight is that the kernel bugs are most relevant to the processes created by a fuzzer. Thus, BoKASAN deliberately sani-tizes the target memory regions related to these processes and leaves the remains unsanitized for effective kernel fuzzing. Our evaluation results show that BoKASAN is practical on closed-source systems, achieving the compiler-level performance of KASAN even on binary-only kernels and modules. Compared to KASAN on the Linux kernel, BoKASAN detected slightly more bugs in the Janus dataset and slightly fewer bugs in the Syzkaller/SyzVegas dataset; and BoKASAN found the same number of unique bugs in the 5-day fuzzing and executed the similar number of basic blocks. For binary modules on the Windows kernel and the Linux kernel, resp., BoKASAN was effective in \ufb01nding bugs. An ablation result shows that selective sanitization affected these outcomes",
            "keywords": [
                "Kernel Fuzzing",
                "Binary-only KASAN",
                "Dynamic Instrumentation",
                "Selective Sanitization",
                "Kernel Bugs"
            ]
        },
        "url": "URL#915234",
        "sema_paperId": "0da9259d796bb6161e8b3d760de6457a24c6ef7f"
    },
    {
        "@score": "1",
        "@id": "915235",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "292/5588",
                        "text": "Minyeop Choi"
                    },
                    {
                        "@pid": "200/8331",
                        "text": "Gihyuk Ko"
                    },
                    {
                        "@pid": "49/8463",
                        "text": "Sang Kil Cha"
                    }
                ]
            },
            "title": "BotScreen: Trust Everybody, but Cut the Aimbots Yourself.",
            "venue": "USENIX Security Symposium",
            "pages": "481-498",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChoiKC23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/choi",
            "url": "https://dblp.org/rec/conf/uss/ChoiKC23",
            "abstract": "Aimbots, which assist players to kill opponents in First-Person Shooter (FPS) games, pose a significant threat to the game industry. Although there has been significant research effort to automatically detect aimbots, existing works suffer from either high server-side overhead or low detection accuracy. In this paper, we present a novel aimbot detection design and implementation that we refer to as BotScreen, which is a client-side aimbot detection solution for a popular FPS game, Counter-Strike: Global Offensive (CS:GO). BotScreen is the first in detecting aimbots in a distributed fashion, thereby minimizing the server-side overhead. It also leverages a novel deep learning model to precisely detect abnormal behaviors caused by using aimbots. We demonstrate the effectiveness of BotScreen in terms of both accuracy and performance on CS:GO. We make our tool as well as our dataset publicly available to support open science.",
            "keywords": [
                "Aimbot Detection",
                "Client-Side Solution",
                "Counter-Strike: Global Offensive",
                "Behavior Analysis",
                "Distributed Detection"
            ]
        },
        "url": "URL#915235",
        "sema_paperId": "9356553497a1f0792300660ad435decabdb29739"
    },
    {
        "@score": "1",
        "@id": "915236",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "277/2335",
                        "text": "Neophytos Christou"
                    },
                    {
                        "@pid": "67/1861",
                        "text": "Di Jin"
                    },
                    {
                        "@pid": "117/6972",
                        "text": "Vaggelis Atlidakis"
                    },
                    {
                        "@pid": "74/1969",
                        "text": "Baishakhi Ray"
                    },
                    {
                        "@pid": "87/1029",
                        "text": "Vasileios P. Kemerlis"
                    }
                ]
            },
            "title": "IvySyn: Automated Vulnerability Discovery in Deep Learning Frameworks.",
            "venue": "USENIX Security Symposium",
            "pages": "2383-2400",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChristouJARK23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/christou",
            "url": "https://dblp.org/rec/conf/uss/ChristouJARK23",
            "abstract": "We present IvySyn, the first fully-automated framework for discovering memory error vulnerabilities in Deep Learning (DL) frameworks. IvySyn leverages the statically-typed nature of native APIs in order to automatically perform type-aware mutation-based fuzzing on low-level kernel code. Given a set of offending inputs that trigger memory safety (and runtime) errors in low-level, native DL (C/C++) code, IvySyn automatically synthesizes code snippets in high-level languages (e.g., in Python), which propagate error-triggering input via high(er)-level APIs. Such code snippets essentially act as\"Proof of Vulnerability\", as they demonstrate the existence of bugs in native code that an attacker can target through various high-level APIs. Our evaluation shows that IvySyn significantly outperforms past approaches, both in terms of efficiency and effectiveness, in finding vulnerabilities in popular DL frameworks. Specifically, we used IvySyn to test TensorFlow and PyTorch. Although still an early prototype, IvySyn has already helped the TensorFlow and PyTorch framework developers to identify and fix 61 previously-unknown security vulnerabilities, and assign 39 unique CVEs.",
            "keywords": [
                "Automated Vulnerability Discovery",
                "Memory Error Vulnerabilities",
                "Type-aware Mutation-based Fuzzing",
                "Deep Learning Frameworks",
                "Proof of Vulnerability"
            ]
        },
        "url": "URL#915236",
        "sema_paperId": "58b1b17a04279361fb5d138f0cd8f8ab94029d69"
    },
    {
        "@score": "1",
        "@id": "915237",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "282/8466",
                        "text": "Grace H. Cimaszewski"
                    },
                    {
                        "@pid": "224/9340",
                        "text": "Henry Birge-Lee"
                    },
                    {
                        "@pid": "56/4499-54",
                        "text": "Liang Wang 0054"
                    },
                    {
                        "@pid": "r/JenniferRexford",
                        "text": "Jennifer Rexford"
                    },
                    {
                        "@pid": "39/6266",
                        "text": "Prateek Mittal"
                    }
                ]
            },
            "title": "How Effective is Multiple-Vantage-Point Domain Control Validation?",
            "venue": "USENIX Security Symposium",
            "pages": "5701-5718",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CimaszewskiB0RM23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/cimaszewski",
            "url": "https://dblp.org/rec/conf/uss/CimaszewskiB0RM23",
            "abstract": "Multiple-vantage-point domain control validation (multiVA) is an emerging defense for mitigating BGP hijacking attacks against certificate authorities. While the adoption of multiVA is on the rise, little work has quantified its effectiveness against BGP hijacks in the wild. We bridge the gap by presenting the first analysis framework that measures the security of a multiVA deployment under real-world network configurations (e.g., DNS and RPKI). Our framework accurately models the attack surface of multiVA by 1) considering the attacks on DNS nameservers involved in domain validation, 2) considering deployed practical security techniques such as RPKI, 3) performing fine-grained internet-scale analysis to compute multiVA resilience (i.e., how difficult it is to launch a BGP hijack against a domain and get a bogus certificate under multiVA). We use our framework to perform a rigorous security analysis of the multiVA deployment of Let's Encrypt, using a dataset that consists of about 1 million certificates and 31 billion DNS queries collected over four months. Our analysis shows while DNS does enlarge the attack surface of multiVA, the of Let's Encrypt's multiVA deployment still offers an 88% median resilience against BGP hijacks, a notable improvement over 76% offered by single-vantage-point validation. RPKI, even in its current state of partial deployment, effectively mitigates BGP attacks and improves the security of the deployment by 15% as compared to the case without considering RPKI. Exploring 11,000 different multiVA configurations, we find that Let's Encrypt's deployment can be further enhanced to achieve a resilience of over 99% by using a full quorum policy with only two additional vantage points in different public clouds.",
            "keywords": [
                "BGP Hijacking",
                "Domain Control Validation",
                "Multiple-Vantage-Point Validation",
                "Let's Encrypt",
                "RPKI"
            ]
        },
        "url": "URL#915237",
        "sema_paperId": "caf3b50881f366c072f32616c223fb91a438a59d"
    },
    {
        "@score": "1",
        "@id": "915238",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "303/0434",
                        "text": "Scott Constable"
                    },
                    {
                        "@pid": "167/1573",
                        "text": "Jo Van Bulck"
                    },
                    {
                        "@pid": "29/1059",
                        "text": "Xiang Cheng"
                    },
                    {
                        "@pid": "152/3962",
                        "text": "Yuan Xiao"
                    },
                    {
                        "@pid": "213/8021",
                        "text": "Cedric Xing"
                    },
                    {
                        "@pid": "151/7512",
                        "text": "Ilya Alexandrovich"
                    },
                    {
                        "@pid": "38/8882",
                        "text": "Taesoo Kim"
                    },
                    {
                        "@pid": "85/6647",
                        "text": "Frank Piessens"
                    },
                    {
                        "@pid": "47/9256",
                        "text": "Mona Vij"
                    },
                    {
                        "@pid": "94/2996",
                        "text": "Mark Silberstein"
                    }
                ]
            },
            "title": "AEX-Notify: Thwarting Precise Single-Stepping Attacks through Interrupt Awareness for Intel SGX Enclaves.",
            "venue": "USENIX Security Symposium",
            "pages": "4051-4068",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ConstableBCXXAK23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/constable",
            "url": "https://dblp.org/rec/conf/uss/ConstableBCXXAK23",
            "abstract": "Intel \u00ae Software Guard Extensions (Intel \u00ae SGX) supports the creation of shielded enclaves within unprivileged processes. While enclaves are architecturally protected against malicious system software, Intel SGX\u2019s privileged attacker model could potentially expose enclaves to new powerful side-channel attacks. In this paper, we consider hardware-software co-design countermeasures to an important class of single-stepping attacks that use privileged timer interrupts to precisely step through enclave execution exactly one instruction at a time, as supported, e.g., by the open-source SGX-Step framework. This is a powerful deterministic attack primitive that has been employed in a broad range of high-resolution Intel SGX attacks, but so far remains unmitigated. We propose AEX-Notify, a \ufb02exible hardware ISA extension that makes enclaves interrupt aware : enclaves can register a trusted handler to be run after an interrupt or exception. AEX-Notify can be used as a building block for implementing countermeasures against different types of interrupt-based attacks in software. With our primary goal to thwart deterministic single-stepping, we \ufb01rst diagnose the underlying hardware behavior to determine the root cause that enables it. We then apply the learned insights to remove this root cause by building an ef\ufb01cient software handler and constant-time dis-assembler to transparently determine and atomically prefetch the working set of the next enclave application instruction. The ISA extension we propose in this paper has been incorporated into a revised version of the Intel SGX speci\ufb01cation.",
            "keywords": [
                "Intel SGX",
                "Single-Stepping Attacks",
                "Interrupt Awareness",
                "AEX-Notify",
                "Side-Channel Attacks"
            ]
        },
        "url": "URL#915238",
        "sema_paperId": "e0102b43531b9efae55527bca64d79a672365fad"
    },
    {
        "@score": "1",
        "@id": "915239",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "146/6045",
                        "text": "Kovila P. L. Coopamootoo"
                    },
                    {
                        "@pid": "268/5744",
                        "text": "Magdalene Ng"
                    }
                ]
            },
            "title": "&quot;Un-Equal Online Safety?&quot; A Gender Analysis of Security and Privacy Protection Advice and Behaviour Patterns.",
            "venue": "USENIX Security Symposium",
            "pages": "5611-5628",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CoopamootooN23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/coopamootoo",
            "url": "https://dblp.org/rec/conf/uss/CoopamootooN23",
            "abstract": "There are indications in literature that women do not engage with security and privacy (SP) technologies, meant to keep them safe online, in the same way as men do. To better understand this gender gap, we conduct an online survey with N=604 U.K. participants, to elicit SP advice source preference and usage of SP methods and technologies. We find evidence of un-equal SP access and participation. In particular, advice from intimate and social connections (ISC) is more prevalent among women, while online content is preferred by men. ISC do not closely associate with nor predict the use of SP technologies, whereas online sources (such as online forums, reviews, specialist pages and technology adverts) and training do. Men are also more likely to use multiple advice sources, that enhances the likelihood of using SP technologies. Women are motivated to approach ISC due to their perceptions of the advisor (such as IT related expertise, experience and trustworthiness) while men approach ISC to evaluate options and seek reassurance for their own practices. This research reveals gender norms in SP practice, raises questions about the equity of online safety opportunities and makes recommendations.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-coopamootoo.pdf",
            "keywords": [
                "Online Safety",
                "Gender Analysis",
                "Security and Privacy Technologies",
                "Advice Source Preference",
                "Gender Norms in SP Practice"
            ]
        },
        "url": "URL#915239"
    },
    {
        "@score": "1",
        "@id": "915240",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "17/2282",
                        "text": "Cas Cremers"
                    },
                    {
                        "@pid": "240/8159",
                        "text": "Alexander Dax"
                    },
                    {
                        "@pid": "195/3195",
                        "text": "Charlie Jacomme"
                    },
                    {
                        "@pid": "270/6872",
                        "text": "Mang Zhao"
                    }
                ]
            },
            "title": "Automated Analysis of Protocols that use Authenticated Encryption: How Subtle AEAD Differences can impact Protocol Security.",
            "venue": "USENIX Security Symposium",
            "pages": "5935-5952",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CremersDJZ23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/cremers-protocols",
            "url": "https://dblp.org/rec/conf/uss/CremersDJZ23",
            "abstract": "Many modern security protocols such as TLS, WPA2, Wire-Guard, and Signal use a cryptographic primitive called Au-thenticated Encryption (optionally with Authenticated Data), also known as an AEAD scheme. AEAD is a variant of symmetric encryption that additionally provides authentication. While authentication may seem to be a straightforward additional requirement, it has in fact turned out to be complex: many different security notions for AEADs are still being proposed, and several recent protocol-level attacks exploit subtle behaviors that differ among real-world AEAD schemes. We provide the first automated analysis method for protocols that use AEADs that can systematically find attacks that exploit the subtleties of the specific type of AEAD used. This can then be used to analyze specific protocols with a fixed AEAD choice, or to provide guidance on which AEADs might be (in)sufficient to make a protocol design secure. We develop generic symbolic AEAD models, which we instantiate for the Tamarin prover. Our approach can automatically and efficiently discover protocol attacks that could previously only be found using manual inspection, such as the Salaman-der attack on Facebook\u2019s message franking, and attacks on SFrame and YubiHSM. Furthermore, our analysis reveals undesirable behaviors of several other protocols.",
            "keywords": [
                "Authenticated Encryption",
                "AEAD Schemes",
                "Protocol Security",
                "Automated Analysis",
                "Protocol Attacks"
            ]
        },
        "url": "URL#915240",
        "sema_paperId": "e59a1cb09b0fe3aa79a8cfd1eb1cbb1072a7a7c4"
    },
    {
        "@score": "1",
        "@id": "915241",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "17/2282",
                        "text": "Cas Cremers"
                    },
                    {
                        "@pid": "240/8159",
                        "text": "Alexander Dax"
                    },
                    {
                        "@pid": "277/8030",
                        "text": "Aurora Naska"
                    }
                ]
            },
            "title": "Formal Analysis of SPDM: Security Protocol and Data Model version 1.2.",
            "venue": "USENIX Security Symposium",
            "pages": "6611-6628",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CremersDN23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/cremers-spdm",
            "url": "https://dblp.org/rec/conf/uss/CremersDN23",
            "abstract": "DMTF is a standards organization by major industry players in IT infrastructure including AMD, Alibaba, Broadcom, Cisco, Dell, Google, Huawei, IBM, Intel, Lenovo, and NVIDIA, which aims to enable interoperability, e.g., including cloud, virtualization, network, servers and storage. It is currently standardizing a security protocol called SPDM, which aims to secure communication over the wire and to enable device attestation, notably also explicitly catering for communicating hardware components.\nThe SPDM protocol inherits requirements and design ideas from IETF\u2019s TLS 1.3. However, its state machines and transcript handling are substantially different and more complex. While architecture, specification, and open-source libraries of the current versions of SPDM are publicly available, these include no significant security analysis of any kind.\nIn this work we develop the first formal models of the three modes of the SPDM protocol version 1.2.1, and formally analyze their main security properties.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-cremers-spdm.pdf",
            "keywords": [
                "SPDM Protocol",
                "Formal Analysis",
                "Device Attestation",
                "Security Properties",
                "Interoperability Standards"
            ]
        },
        "url": "URL#915241"
    },
    {
        "@score": "1",
        "@id": "915242",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "17/2282",
                        "text": "Cas Cremers"
                    },
                    {
                        "@pid": "195/3195",
                        "text": "Charlie Jacomme"
                    },
                    {
                        "@pid": "277/8030",
                        "text": "Aurora Naska"
                    }
                ]
            },
            "title": "Formal Analysis of Session-Handling in Secure Messaging: Lifting Security from Sessions to Conversations.",
            "venue": "USENIX Security Symposium",
            "pages": "1235-1252",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CremersJN23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/cremers-session-handling",
            "url": "https://dblp.org/rec/conf/uss/CremersJN23",
            "abstract": "The building blocks for secure messaging apps, such as Signal\u2019s X3DH and Double Ratchet (DR) protocols, have received a lot of attention from the research community. They have notably been proved to meet strong security properties even in the case of compromise such as Forward Secrecy (FS) and Post-Compromise Security (PCS). However, there is a lack of formal study of these properties at the application level. Whereas the research works have studied such properties in the context of a single ratcheting chain, a conversation between two persons in a messaging application can in fact be the result of merging multiple ratcheting chains. \nIn this work, we initiate the formal analysis of secure messaging taking the session-handling layer into account, and apply our approach to Sesame, Signal\u2019s session management. We first experimentally show practical scenarios in which PCS can be violated in Signal by a clone attacker, despite its use of the Double Ratchet. We identify how this is enabled by Signal\u2019s session-handling layer. We then design a formal model of the session-handling layer of Signal that is tractable for automated verification with the Tamarin prover, and use this model to rediscover the PCS violation and propose two provably secure mechanisms to offer stronger guarantees.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-cremers-session-handling.pdf",
            "keywords": [
                "Secure Messaging",
                "Session Handling",
                "Post-Compromise Security",
                "Double Ratchet Protocol",
                "Clone Attacker"
            ]
        },
        "url": "URL#915242"
    },
    {
        "@score": "1",
        "@id": "915243",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "337/2524",
                        "text": "Santiago Cu\u00e9llar"
                    },
                    {
                        "@pid": "30/2834",
                        "text": "Bill Harris"
                    },
                    {
                        "@pid": "00/2904",
                        "text": "James Parker"
                    },
                    {
                        "@pid": "153/5794",
                        "text": "Stuart Pernsteiner"
                    },
                    {
                        "@pid": "t/EranTromer",
                        "text": "Eran Tromer"
                    }
                ]
            },
            "title": "Cheesecloth: Zero-Knowledge Proofs of Real World Vulnerabilities.",
            "venue": "USENIX Security Symposium",
            "pages": "6525-6540",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CuellarHPPT23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/cuellar",
            "url": "https://dblp.org/rec/conf/uss/CuellarHPPT23",
            "abstract": "Currently, when a security analyst discovers a vulnerability in critical software system, they must navigate a fraught dilemma: immediately disclosing the vulnerability to the public could harm the system's users; whereas disclosing the vulnerability only to the software's vendor lets the vendor disregard or deprioritize the security risk, to the detriment of unwittingly-affected users.A compelling recent line of work aims to resolve this by using Zero Knowledge (ZK) protocols that let analysts prove that they know a vulnerability in a program, without revealing the details of the vulnerability or the inputs that exploit it. In principle, this could be achieved by generic ZK techniques. In practice, ZK vulnerability proofs to date have been restricted in scope and expressibility, due to challenges related to generating proof statements that model real-world software at scale and to directly formulating violated properties.This paper presents Cheesecloth, a novel proof statement compiler, which proves practical vulnerabilities in ZK by soundly-but-aggressively preprocessing programs on public inputs, selectively revealing information about executed control segments, and formalizing information leakage using a novel storage-labeling scheme. Cheesecloth's practicality is demonstrated by generating ZK proofs of well-known vulnerabilities in (previous versions of) critical software, including the Heartbleed information leakage in OpenSSL and a memory vulnerability in the FFmpeg graphics framework.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-cuellar.pdf",
            "keywords": [
                "Zero-Knowledge Proofs",
                "Vulnerability Disclosure",
                "Software Security",
                "Information Leakage",
                "Cheesecloth"
            ]
        },
        "url": "URL#915243"
    },
    {
        "@score": "1",
        "@id": "915244",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "98/75",
                        "text": "Hao Cui"
                    },
                    {
                        "@pid": "117/6580",
                        "text": "Rahmadi Trimananda"
                    },
                    {
                        "@pid": "82/5866",
                        "text": "Athina Markopoulou"
                    },
                    {
                        "@pid": "82/2941",
                        "text": "Scott Jordan 0001"
                    }
                ]
            },
            "title": "PoliGraph: Automated Privacy Policy Analysis using Knowledge Graphs.",
            "venue": "USENIX Security Symposium",
            "pages": "1037-1054",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CuiTMJ23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/cui",
            "url": "https://dblp.org/rec/conf/uss/CuiTMJ23",
            "abstract": "Privacy policies disclose how an organization collects and handles personal information. Recent work has made progress in leveraging natural language processing (NLP) to automate privacy policy analysis and extract data collection statements from different sentences, considered in isolation from each other. In this paper, we view and analyze, for the first time, the entire text of a privacy policy in an integrated way. In terms of methodology: (1) we define PoliGraph, a type of knowledge graph that captures statements in a privacy policy as relations between different parts of the text; and (2) we develop an NLP-based tool, PoliGraph-er, to automatically extract PoliGraph from the text. In addition, (3) we revisit the notion of ontologies, previously defined in heuristic ways, to capture subsumption relations between terms. We make a clear distinction between local and global ontologies to capture the context of individual privacy policies, application domains, and privacy laws. Using a public dataset for evaluation, we show that PoliGraph-er identifies 40% more collection statements than prior state-of-the-art, with 97% precision. In terms of applications, PoliGraph enables automated analysis of a corpus of privacy policies and allows us to: (1) reveal common patterns in the texts across different privacy policies, and (2) assess the correctness of the terms as defined within a privacy policy. We also apply PoliGraph to: (3) detect contradictions in a privacy policy, where we show false alarms by prior work, and (4) analyze the consistency of privacy policies and network traffic, where we identify significantly more clear disclosures than prior work.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-cui.pdf",
            "keywords": [
                "Privacy Policy Analysis",
                "Knowledge Graphs",
                "Automated Extraction",
                "Data Collection Statements",
                "Contradiction Detection"
            ]
        },
        "url": "URL#915244"
    },
    {
        "@score": "1",
        "@id": "915245",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "303/6545",
                        "text": "Alaa Daffalla"
                    },
                    {
                        "@pid": "331/2515",
                        "text": "Marina Sanusi Bohuk"
                    },
                    {
                        "@pid": "75/11301",
                        "text": "Nicola Dell"
                    },
                    {
                        "@pid": "217/9409",
                        "text": "Rosanna Bellini"
                    },
                    {
                        "@pid": "26/3399",
                        "text": "Thomas Ristenpart"
                    }
                ]
            },
            "title": "Account Security Interfaces: Important, Unintuitive, and Untrustworthy.",
            "venue": "USENIX Security Symposium",
            "pages": "3601-3618",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DaffallaBDBR23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/daffalla",
            "url": "https://dblp.org/rec/conf/uss/DaffallaBDBR23",
            "abstract": "Online services increasingly rely on user-facing interfaces to communicate important security-related account information\u2014for example, which devices are logged into a user's account and when recent logins occurred. These are used to assess the security status of an account, which is particularly critical for at-risk users likely to be under active attack. To date, however, there has been no investigation into whether these interfaces work well.\nWe begin to fill this gap by partnering with a clinic that supports survivors of intimate partner violence (IPV). We investigated hundreds of transcripts to identify ones capturing interactions between clinic consultants and survivors seeking to infer the security status of survivor accounts, and we performed a qualitative analysis of 28 transcripts involving 19 consultants and 22 survivors. Our findings confirm the importance of these interfaces for assessing a user's security, but we also find that these interfaces suffer from a number of limitations that cause confusion and reduce their utility. \nWe go on to experimentally investigate the lack of integrity of information contained in device lists and session activity logs for four major services. For all the services investigated, we show how an attacker can either hide accesses entirely or spoof access details to hide illicit logins from victims.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-daffalla.pdf",
            "keywords": [
                "Account Security Interfaces",
                "Intimate Partner Violence",
                "User Trust",
                "Session Activity Logs",
                "Device Access Integrity"
            ]
        },
        "url": "URL#915245",
        "sema_paperId": "be946514fd7b40f54abd86feffeb6cda7060923e"
    },
    {
        "@score": "1",
        "@id": "915246",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "184/2500",
                        "text": "Rasmus Dahlberg"
                    },
                    {
                        "@pid": "72/11061",
                        "text": "Tobias Pulls"
                    }
                ]
            },
            "title": "Timeless Timing Attacks and Preload Defenses in Tor&apos;s DNS Cache.",
            "venue": "USENIX Security Symposium",
            "pages": "2635-2652",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DahlbergP23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/dahlberg",
            "url": "https://dblp.org/rec/conf/uss/DahlbergP23",
            "abstract": "We show that Tor\u2019s DNS cache is vulnerable to a timeless timing attack, allowing anyone to determine if a domain is cached or not without any false positives. The attack requires sending a single TLS record. It can be repeated to determine when a domain is no longer cached to leak the insertion time. Our evaluation in the Tor network shows no instances of cached domains being reported as uncached and vice versa after 12M repetitions while only targeting our own domains. This shifts DNS in Tor from an unreliable side-channel\u2014 using traditional timing attacks with network jitter\u2014to being perfectly reliable. We responsibly disclosed the attack and suggested two short-term mitigations. As a long-term defense for the DNS cache in Tor against all types of (timeless) timing attacks, we propose a redesign where only an allowlist of domains is preloaded to always be cached across circuits. We compare the performance of a preloaded DNS cache to Tor\u2019s current solution towards DNS by measuring aggregated statistics for four months from two exits (after engaging with the Tor Research Safety Board and our university ethical review process). The evaluated preload lists are variants of the following top-lists: Alexa, Cisco Um-brella, and Tranco. Our results show that four-months-old preload lists can be tuned to offer comparable performance under similar resource usage or to significantly improve shared cache-hit ratios (2\u20133x) with a modest increase in memory usage and resolver load compared to a 100 Mbit/s exit. We conclude that Tor\u2019s current DNS cache is mostly a privacy harm because the majority of cached domains are unlikely to lead to cache hits but remain there to be probed by attackers.",
            "keywords": [
                "Tor Network",
                "DNS Cache",
                "Timeless Timing Attack",
                "Privacy Vulnerability",
                "Preload Defense"
            ]
        },
        "url": "URL#915246",
        "sema_paperId": "88eb66c10762abf7bd52545d5be097b1fb50dbdb"
    },
    {
        "@score": "1",
        "@id": "915247",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "219/7484",
                        "text": "Savino Dambra"
                    },
                    {
                        "@pid": "15/6037",
                        "text": "Leyla Bilge"
                    },
                    {
                        "@pid": "44/10958",
                        "text": "Platon Kotzias"
                    },
                    {
                        "@pid": "14/4412",
                        "text": "Yun Shen"
                    },
                    {
                        "@pid": "35/3587",
                        "text": "Juan Caballero"
                    }
                ]
            },
            "title": "One Size Does not Fit All: Quantifying the Risk of Malicious App Encounters for Different Android User Profiles.",
            "venue": "USENIX Security Symposium",
            "pages": "5683-5700",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DambraBKSC23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/dambra",
            "url": "https://dblp.org/rec/conf/uss/DambraBKSC23",
            "abstract": "Previous work has investigated the particularities of security practices within specific user communities defined based on country of origin, age, prior tech abuse, and economic status. Their results highlight that current security solutions that adopt a one-size-fits-all-users approach ignore the differences and needs of particular user communities. However, those works focus on a single community or cluster users into hard-to-interpret sub-populations. In this work, we perform a large-scale quantitative analysis of the risk of encountering malware and other potentially unwanted applications (PUA) across user communities. At the core of our study is a dataset of app installation logs collected from 12M Android mobile devices. Leveraging user-installed apps, we define intuitive profiles based on users\u2019 interests (e.g., gamers and investors), and fit a subset of 5.4M devices to those profiles. Our analysis is structured in three parts. First, we perform risk analysis on the whole population to measure how the risk of malicious app encounters is affected by different factors. Next, we create different profiles to investigate whether risk differences across users may be due to their interests. Finally, we compare a per-profile approach for classifying clean and infected devices with the classical approach that considers the whole population. We observe that features such as the diversity of the app signers and the use of alternative markets highly correlate with the risk of malicious app encounters. We also discover that some profiles such as gamers and social-media users are exposed to more than twice the risks experienced by the average users. We also show that the classification outcome has a marked accuracy improvement when using a per-profile approach to train the prediction models. Overall, our results confirm the inadequacy of one-size-fits-all protection solutions.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-dambra.pdf",
            "keywords": [
                "Malicious Apps",
                "Android Security",
                "User Profiles",
                "Risk Analysis",
                "Potentially Unwanted Applications (PUA)"
            ]
        },
        "url": "URL#915247"
    },
    {
        "@score": "1",
        "@id": "915248",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "222/9411",
                        "text": "Lesly-Ann Daniel"
                    },
                    {
                        "@pid": "325/3751",
                        "text": "Marton Bognar"
                    },
                    {
                        "@pid": "119/6689",
                        "text": "Job Noorman"
                    },
                    {
                        "@pid": "b/SebastienBardin",
                        "text": "S\u00e9bastien Bardin"
                    },
                    {
                        "@pid": "42/6705",
                        "text": "Tamara Rezk"
                    },
                    {
                        "@pid": "85/6647",
                        "text": "Frank Piessens"
                    }
                ]
            },
            "title": "ProSpeCT: Provably Secure Speculation for the Constant-Time Policy.",
            "venue": "USENIX Security Symposium",
            "pages": "7161-7178",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DanielBNBRP23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/daniel",
            "url": "https://dblp.org/rec/conf/uss/DanielBNBRP23",
            "abstract": "We propose ProSpeCT, a generic formal processor model providing provably secure speculation for the constant-time policy. For constant-time programs under a non-speculative semantics, ProSpeCT guarantees that speculative and out-of-order execution cause no microarchitectural leaks. This guarantee is achieved by tracking secrets in the processor pipeline and ensuring that they do not influence the microarchitectural state during speculative execution. Our formalization covers a broad class of speculation mechanisms, generalizing prior work. As a result, our security proof covers all known Spectre attacks, including load value injection (LVI) attacks.\nIn addition to the formal model, we provide a prototype hardware implementation of ProSpeCT on a RISC-V processor and show evidence of its low impact on hardware cost, performance, and required software changes. In particular, the experimental evaluation confirms our expectation that for a compliant constant-time binary, enabling ProSpeCT incurs no performance overhead.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-daniel.pdf",
            "keywords": [
                "Processor Security",
                "Speculative Execution",
                "Constant-Time Policy",
                "Microarchitectural Leaks",
                "Spectre Attacks"
            ]
        },
        "url": "URL#915248"
    },
    {
        "@score": "1",
        "@id": "915249",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "31/6808-1",
                        "text": "Sourav Das 0001"
                    },
                    {
                        "@pid": "175/1673",
                        "text": "Zhuolun Xiang"
                    },
                    {
                        "@pid": "176/5301",
                        "text": "Lefteris Kokoris-Kogias"
                    },
                    {
                        "@pid": "30/10661",
                        "text": "Ling Ren 0001"
                    }
                ]
            },
            "title": "Practical Asynchronous High-threshold Distributed Key Generation and Distributed Polynomial Sampling.",
            "venue": "USENIX Security Symposium",
            "pages": "5359-5376",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DasXK023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/das",
            "url": "https://dblp.org/rec/conf/uss/DasXK023",
            "abstract": "Distributed Key Generation (DKG) is a technique to bootstrap threshold cryptosystems without a trusted party. DKG is an essential building block to many decentralized protocols such as randomness beacons, threshold signatures, Byzantine consensus, and multiparty computation. While significant progress has been made recently, existing asynchronous DKG constructions are inefficient when the reconstruction threshold is larger than one-third of the total nodes. In this paper, we present a simple and concretely efficient \\emph{asynchronous} DKG (ADKG) protocol among n = 3t + 1 nodes that can tolerate up to t malicious nodes and support any reconstruction threshold \u2113 \u2265 t. Our protocol has an expected O(\u03ban3) communication cost, where \u03ba is the security parameter, and only assumes the hardness of the Discrete Logarithm. The core ingredient of our ADKG protocol is an asynchronous protocol to secret share a random polynomial of degree \u2113 \u2265 t, which has other applications, such as asynchronous proactive secret sharing and asynchronous multiparty computation. We implement our high-threshold ADKG protocol and evaluate it using a network of up to 128 geographically distributed nodes. Our evaluation shows that our high-threshold ADKG protocol reduces the running time by 90% and bandwidth usage by 80% over the state-of-the-art.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-das.pdf",
            "keywords": [
                "Distributed Key Generation",
                "Asynchronous Protocols",
                "Threshold Cryptography",
                "Secret Sharing",
                "Polynomial Sampling"
            ]
        },
        "url": "URL#915249"
    },
    {
        "@score": "1",
        "@id": "915250",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "231/1869",
                        "text": "Alexandre Debant"
                    },
                    {
                        "@pid": "140/7281",
                        "text": "Lucca Hirschi"
                    }
                ]
            },
            "title": "Reversing, Breaking, and Fixing the French Legislative Election E-Voting Protocol.",
            "venue": "USENIX Security Symposium",
            "pages": "6737-6752",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DebantH23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/debant",
            "url": "https://dblp.org/rec/conf/uss/DebantH23",
            "abstract": "We conduct a security analysis of the e-voting protocol used for the largest political election using e-voting in the world, the 2022 French legislative election for the citizens overseas. Due to a lack of system and threat model specifications, we built and contributed such specifications by studying the French legal framework and by reverse-engineering the code base accessible to the voters. Our analysis reveals that this protocol is affected by two design-level and implementation-level vulnerabilities. We show how those allow a standard voting server attacker and even more so a channel attacker to defeat the election integrity and ballot privacy due to 5 attack variants. We propose and discuss 5 fixes to prevent those attacks. Our specifications, the attacks, and the fixes were acknowledged by the relevant stakeholders during our responsible disclosure. They implemented our fixes to prevent our attacks for future elections. Beyond this protocol, we draw general lessons, recommendations, and open questions from this instructive experience where an e-voting protocol meets the real-world constraints of a large-scale, political election.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-debant.pdf",
            "keywords": [
                "E-Voting Security",
                "Election Integrity",
                "Ballot Privacy",
                "Vulnerability Analysis",
                "French Legislative Election"
            ]
        },
        "url": "URL#915250"
    },
    {
        "@score": "1",
        "@id": "915251",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "243/3091",
                        "text": "Jiangyi Deng"
                    },
                    {
                        "@pid": "50/10586",
                        "text": "Yanjiao Chen"
                    },
                    {
                        "@pid": "341/1178",
                        "text": "Yinan Zhong"
                    },
                    {
                        "@pid": "341/1427",
                        "text": "Qianhao Miao"
                    },
                    {
                        "@pid": "268/5832",
                        "text": "Xueluan Gong"
                    },
                    {
                        "@pid": "10/3878-1",
                        "text": "Wenyuan Xu 0001"
                    }
                ]
            },
            "title": "Catch You and I Can: Revealing Source Voiceprint Against Voice Conversion.",
            "venue": "USENIX Security Symposium",
            "pages": "5163-5180",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DengCZMG023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/deng-jiangyi-voiceprint",
            "url": "https://dblp.org/rec/conf/uss/DengCZMG023",
            "abstract": "Voice conversion (VC) techniques can be abused by malicious parties to transform their audios to sound like a target speaker, making it hard for a human being or a speaker verification/identification system to trace the source speaker. In this paper, we make the first attempt to restore the source voiceprint from audios synthesized by voice conversion methods with high credit. However, unveiling the features of the source speaker from a converted audio is challenging since the voice conversion operation intends to disentangle the original features and infuse the features of the target speaker. To fulfill our goal, we develop Revelio, a representation learning model, which learns to effectively extract the voiceprint of the source speaker from converted audio samples. We equip Revelio with a carefully-designed differential rectification algorithm to eliminate the influence of the target speaker by removing the representation component that is parallel to the voiceprint of the target speaker. We have conducted extensive experiments to evaluate the capability of Revelio in restoring voiceprint from audios converted by VQVC, VQVC+, AGAIN, and BNE. The experiments verify that Revelio is able to rebuild voiceprints that can be traced to the source speaker by speaker verification and identification systems. Revelio also exhibits robust performance under inter-gender conversion, unseen languages, and telephony networks.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-deng-jiangyi-voiceprint.pdf",
            "keywords": [
                "Voice Conversion",
                "Source Voiceprint Restoration",
                "Speaker Verification",
                "Representation Learning",
                "Differential Rectification Algorithm"
            ]
        },
        "url": "URL#915251"
    },
    {
        "@score": "1",
        "@id": "915252",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "195/2914",
                        "text": "Sen Deng"
                    },
                    {
                        "@pid": "157/4437",
                        "text": "Mengyuan Li"
                    },
                    {
                        "@pid": "248/1563",
                        "text": "Yining Tang"
                    },
                    {
                        "@pid": "42/1503-11",
                        "text": "Shuai Wang 0011"
                    },
                    {
                        "@pid": "08/6611",
                        "text": "Shoumeng Yan"
                    },
                    {
                        "@pid": "77/3503",
                        "text": "Yinqian Zhang"
                    }
                ]
            },
            "title": "CipherH: Automated Detection of Ciphertext Side-channel Vulnerabilities in Cryptographic Implementations.",
            "venue": "USENIX Security Symposium",
            "pages": "6843-6860",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DengLTWYZ23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/deng-sen",
            "url": "https://dblp.org/rec/conf/uss/DengLTWYZ23",
            "abstract": "The ciphertext side channel is a new type of side channels that exploits deterministic memory encryption of trusted execution environments (TEE). It enables the adversary with read accesses to the ciphertext of the encrypted memory, either logically or physically, to compromise cryptographic implementations protected by TEEs with high \ufb01delity. Prior studies have concluded that the ciphertext side channel is a severe threat to not only AMD SEV-SNP, where the vulnerability was \ufb01rst discovered, but to all TEEs with deterministic memory encryption. In this paper, we propose C IPHER H, a practical framework for automating the analysis of cryptographic software and detecting program points vulnerable to ciphertext side channels. C IPHER H is designed to perform a practical hybrid analysis in production cryptographic software, with a speedy dynamic taint analysis to track the usage of secrets throughout the entire program and a static symbolic execution procedure on each \u201ctainted\u201d function to reason about ciphertext side-channel vulnerabilities using symbolic constraint. Empirical evaluation has led to the discovery of over 200 vulnerable program points from the state-of-the-art RSA and ECDSA/ECDH implementations from OpenSSL, MbedTLS, and WolfSSL. Representative cases have been reported to and con\ufb01rmed or patched by the developers.",
            "keywords": [
                "Ciphertext Side-channel",
                "Trusted Execution Environments",
                "Cryptographic Implementations",
                "Automated Vulnerability Detection",
                "Dynamic Taint Analysis"
            ]
        },
        "url": "URL#915252",
        "sema_paperId": "42949f11691add1d6ad161c5d05054673ee901bb"
    },
    {
        "@score": "1",
        "@id": "915253",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "272/7174",
                        "text": "Zizhuang Deng"
                    },
                    {
                        "@pid": "134/8681",
                        "text": "Guozhu Meng"
                    },
                    {
                        "@pid": "c/KaiChen12",
                        "text": "Kai Chen 0012"
                    },
                    {
                        "@pid": "36/5558",
                        "text": "Tong Liu"
                    },
                    {
                        "@pid": "121/7268",
                        "text": "Lu Xiang"
                    },
                    {
                        "@pid": "180/7246",
                        "text": "Chunyang Chen"
                    }
                ]
            },
            "title": "Differential Testing of Cross Deep Learning Framework APIs: Revealing Inconsistencies and Vulnerabilities.",
            "venue": "USENIX Security Symposium",
            "pages": "7393-7410",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DengM0LXC23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/deng-zizhuang",
            "url": "https://dblp.org/rec/conf/uss/DengM0LXC23",
            "abstract": "With the increasing adoption of deep learning (DL) in various applications, developers often reuse models by, for example, performing model conversion among frameworks to raise productivity. However, security bugs in model conversion may make models behave differently across DL frameworks, and cause unpredictable errors. Prior studies primarily focus on the security of individual DL frameworks, but few of them can cope with the inconsistencies and security bugs during cross-framework conversion. Furthermore, the impact of these issues on DL applications remains largely unexplored. To this end, we propose T ENSOR S COPE , a novel approach to test cross-framework APIs for security bugs. It takes as input a number of counterpart APIs that are supposed to be equivalent in functionality, then performs differential testing to identify the inconsistencies. We design novel strategies to boost testing efficiency, including 1) joint constraint analysis to raise the quality of test cases, and 2) error-guided test case fixing to refine the constraints for input. T ENSOR S COPE is extensively evaluated on 1,658 APIs of six popular DL frameworks. The results show that T ENSOR S COPE is more effective than FreeFuzz and DocTer by raising 28.7% and 24.3% code coverage, respectively. We find 257 bugs including 230 new bugs, and receive 8 CVEs and $1,100+ bounty with developers\u2019 ac-knowledgment. Most importantly, we make the first attempt to exploit these inconsistencies to make the accuracy of three models reduced",
            "keywords": [
                "Cross-Framework Testing",
                "API Inconsistencies",
                "Differential Testing",
                "Model Conversion Bugs",
                "Deep Learning Frameworks"
            ]
        },
        "url": "URL#915253",
        "sema_paperId": "7cebf9e48550f0b14ab741495aa6a8b496b6422c"
    },
    {
        "@score": "1",
        "@id": "915254",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "243/3091",
                        "text": "Jiangyi Deng"
                    },
                    {
                        "@pid": "74/1809",
                        "text": "Fei Teng"
                    },
                    {
                        "@pid": "50/10586",
                        "text": "Yanjiao Chen"
                    },
                    {
                        "@pid": "332/0660",
                        "text": "Xiaofu Chen"
                    },
                    {
                        "@pid": "22/6272",
                        "text": "Zhaohui Wang"
                    },
                    {
                        "@pid": "10/3878-1",
                        "text": "Wenyuan Xu 0001"
                    }
                ]
            },
            "title": "V-Cloak: Intelligibility-, Naturalness- &amp; Timbre-Preserving Real-Time Voice Anonymization.",
            "venue": "USENIX Security Symposium",
            "pages": "5181-5198",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DengTCCW023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/deng-jiangyi-v-cloak",
            "url": "https://dblp.org/rec/conf/uss/DengTCCW023",
            "abstract": "Voice data generated on instant messaging or social media applications contains unique user voiceprints that may be abused by malicious adversaries for identity inference or identity theft. Existing voice anonymization techniques, e.g., signal processing and voice conversion/synthesis, suffer from degradation of perceptual quality. In this paper, we develop a voice anonymization system, named V-Cloak, which attains real-time voice anonymization while preserving the intelligibility, naturalness and timbre of the audio. Our designed anonymizer features a one-shot generative model that modulates the features of the original audio at different frequency levels. We train the anonymizer with a carefully-designed loss function. Apart from the anonymity loss, we further incorporate the intelligibility loss and the psychoacoustics-based naturalness loss. The anonymizer can realize untargeted and targeted anonymization to achieve the anonymity goals of unidentifiability and unlinkability.\nWe have conducted extensive experiments on four datasets, i.e., LibriSpeech (English), AISHELL (Chinese), CommonVoice (French) and CommonVoice (Italian), five Automatic Speaker Verification (ASV) systems (including two DNN-based, two statistical and one commercial ASV), and eleven Automatic Speech Recognition (ASR) systems (for different languages). Experiment results confirm that V-Cloak outperforms five baselines in terms of anonymity performance. We also demonstrate that V-Cloak trained only on the VoxCeleb1 dataset against ECAPA-TDNN ASV and DeepSpeech2 ASR has transferable anonymity against other ASVs and cross-language intelligibility for other ASRs. Furthermore, we verify the robustness of V-Cloak against various de-noising techniques and adaptive attacks.\nHopefully, V-Cloak may provide a cloak for us in a prism world.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-deng-jiangyi-v-cloak.pdf",
            "keywords": [
                "Voice Anonymization",
                "Real-Time Processing",
                "Intelligibility Preservation",
                "Naturalness Preservation",
                "Timbre Preservation"
            ]
        },
        "url": "URL#915254"
    },
    {
        "@score": "1",
        "@id": "915255",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "236/9144",
                        "text": "Gelei Deng"
                    },
                    {
                        "@pid": "84/19-5",
                        "text": "Zhiyi Zhang 0005"
                    },
                    {
                        "@pid": "204/3729",
                        "text": "Yuekang Li"
                    },
                    {
                        "@pid": "97/4626-69",
                        "text": "Yi Liu 0069"
                    },
                    {
                        "@pid": "77/7902-4",
                        "text": "Tianwei Zhang 0004"
                    },
                    {
                        "@pid": "51/3710-3",
                        "text": "Yang Liu 0003"
                    },
                    {
                        "@pid": "11/5898",
                        "text": "Guo Yu"
                    },
                    {
                        "@pid": "151/7172",
                        "text": "Dongjin Wang"
                    }
                ]
            },
            "title": "NAUTILUS: Automated RESTful API Vulnerability Detection.",
            "venue": "USENIX Security Symposium",
            "pages": "5593-5609",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DengZLL00YW23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/deng-gelei",
            "url": "https://dblp.org/rec/conf/uss/DengZLL00YW23",
            "abstract": "RESTful APIs have become arguably the most prevalent end-point for accessing web services. Blackbox vulnerability scanners are a popular choice for detecting vulnerabilities in web services automatically. Unfortunately, they suffer from a number of limitations in RESTful API testing. Particularly, existing tools cannot effectively obtain the relations between API operations, and they lack the awareness of the correct sequence of API operations during testing. These drawbacks hinder the tools from requesting the API operations properly to detect potential vulnerabilities. To address this challenge, we propose N AUTILUS , which includes a novel speci\ufb01cation annotation strategy to uncover RESTful API vulnerabilities. The annotations encode the proper operation relations and parameter generation strategies for the RESTful service, which assist N AUTILUS to generate meaningful operation sequences and thus uncover vulnerabilities that require the execution of multiple API operations in the correct sequence. We experimentally compare N AUTILUS with four state-of-art vulnerability scanners and RESTful API testing tools on six RESTful services. Evaluation results demonstrate that N AUTILUS can successfully detect an average of 141% more vulnerabilities, and cover 104% more API operations. We also apply N AUTILUS to nine real-world RESTful services, and detected 23 unique 0-day vulnerabilities with 12 CVE",
            "keywords": [
                "RESTful API Security",
                "Vulnerability Detection",
                "Blackbox Scanners",
                "API Operation Relations",
                "Specification Annotation Strategy"
            ]
        },
        "url": "URL#915255",
        "sema_paperId": "88dbb1751eb748e2bf5588dc922a63127351cb34"
    },
    {
        "@score": "1",
        "@id": "915256",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "216/3907",
                        "text": "Dominic Deuber"
                    },
                    {
                        "@pid": "353/7650",
                        "text": "Michael Keuchen"
                    },
                    {
                        "@pid": "c/NicolasChristin",
                        "text": "Nicolas Christin"
                    }
                ]
            },
            "title": "Assessing Anonymity Techniques Employed in German Court Decisions: A De-Anonymization Experiment.",
            "venue": "USENIX Security Symposium",
            "pages": "5199-5216",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DeuberKC23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/deuber",
            "url": "https://dblp.org/rec/conf/uss/DeuberKC23",
            "abstract": "Democracy requires transparency. Consequently, courts of law must publish their decisions. At the same time, the interests of the persons involved in these court decisions must be protected. For this reason, court decisions in Europe are anonymized using a variety of techniques. To understand how well these techniques protect the persons involved, we conducted an empirical experiment with 54 law students, whom we asked to de-anonymize 50 German court decisions. We found that all anonymization techniques used in these court decisions were vulnerable, most notably the use of ini-tials. Since even supposedly secure anonymization techniques proved vulnerable, our work empirically reveals the complexity involved in the anonymization of court decisions, and thus calls for further research to increase anonymity while preserving comprehensibility. Toward that end, we provide recommendations for improving anonymization quality. Finally, we provide an empirical notion of \u201creasonable effort,\u201d to flesh out the definition of anonymity in the legal context. In doing so, we bridge the gap between the technical and the legal understandings of anonymity.",
            "keywords": [
                "Anonymization Techniques",
                "Court Decisions",
                "De-Anonymization",
                "Legal Privacy",
                "Empirical Experiment"
            ]
        },
        "url": "URL#915256",
        "sema_paperId": "6dafcec2e6ae112e694aecb0f4a56ac1f7df7306"
    },
    {
        "@score": "1",
        "@id": "915257",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "208/7376",
                        "text": "Komail Dharsee"
                    },
                    {
                        "@pid": "03/2122",
                        "text": "John Criswell"
                    }
                ]
            },
            "title": "Jinn: Hijacking Safe Programs with Trojans.",
            "venue": "USENIX Security Symposium",
            "pages": "6965-6982",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DharseeC23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/dharsee",
            "url": "https://dblp.org/rec/conf/uss/DharseeC23",
            "abstract": "Untrusted hardware supply chains enable malicious , powerful , and permanent alterations to processors known as hardware trojans. Such hardware trojans can undermine any software-enforced security policies deployed on top of the hardware. Existing defenses target a select set of hardware components, speci\ufb01cally those that implement hardware-enforced security mechanisms such as cryptographic cores, user/kernel privilege isolation, and memory protections. We observe that computing systems exercise general purpose processor logic to implement software-enforced security policies. This makes general purpose logic security critical since tampering with it could violate software-based security policies. Leveraging this insight, we develop a novel class of hardware trojans, which we dub Jinn trojans, that corrupt general-purpose hardware and can hide in many places within a processor to enable \ufb02exible and powerful high level attacks. Jinn trojans deactivate compiler-based security-enforcement mechanisms, making type-safe software vulnerable to memory-safety by compromising a single bit of architectural state. We show that Jinn trojans are effective even when planted in general purpose hardware, disjoint from any hardware-enforced security components. We show that protecting hardware-enforced security logic is insuf\ufb01cient to keep a system secure from hardware trojans.",
            "keywords": [
                "Hardware Trojans",
                "General Purpose Processors",
                "Software-Enforced Security",
                "Compiler-Based Security",
                "Memory Safety Vulnerabilities"
            ]
        },
        "url": "URL#915257",
        "sema_paperId": "75dec5fa7dd38bb7cae078668915fd726c4bf687"
    },
    {
        "@score": "1",
        "@id": "915258",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "252/4062",
                        "text": "Changchang Ding"
                    },
                    {
                        "@pid": "75/6434-1",
                        "text": "Yan Huang 0001"
                    }
                ]
            },
            "title": "Dubhe: Succinct Zero-Knowledge Proofs for Standard AES and related Applications.",
            "venue": "USENIX Security Symposium",
            "pages": "4373-4390",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Ding023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/ding-changchang",
            "url": "https://dblp.org/rec/conf/uss/Ding023",
            "abstract": "We explore a new approach to construct zero-knowledge proofs by combining ideas from the succinct proof system GKR, the Fully Linear PCP (FLPCP), and MPC-in-the-Head ZKPoK. Our discovery contributes to the state-of-the-art of ZKP in two aspects: (1) Methodology: We demonstrate a way to build transparent ZK proofs from simplified variant of FLPCP and KKW. The resulting proofs are practically efficient ( O ( | C | ) -time prover, O ( log ( | C | ) -time verifier, O ( log ( | C | )) -bandwidth where | C | is the number of polynomial gates), and work readily for circuits defined with polynomial gates over any finite field. (2) Applications: We present efficient (interactive) identification schemes, ring identification schemes, (non-interactive) digital signatures and ring signatures, all based on the standard AES ciphersuite. We also show the first practically efficient verifiable symmetric-key encryption scheme, based on counter-mode AES.",
            "keywords": [
                "Zero-Knowledge Proofs",
                "Succinct Proof Systems",
                "AES Encryption",
                "Identification Schemes",
                "Verifiable Encryption"
            ]
        },
        "url": "URL#915258",
        "sema_paperId": "c2bbf7ddf9f1ced83f695917e3e1f15bfaf44f35"
    },
    {
        "@score": "1",
        "@id": "915259",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "230/7753",
                        "text": "Hailun Ding"
                    },
                    {
                        "@pid": "154/5678",
                        "text": "Juan Zhai"
                    },
                    {
                        "@pid": "71/8700-1",
                        "text": "Dong Deng 0001"
                    },
                    {
                        "@pid": "172/8745",
                        "text": "Shiqing Ma"
                    }
                ]
            },
            "title": "The Case for Learned Provenance Graph Storage Systems.",
            "venue": "USENIX Security Symposium",
            "pages": "3277-3294",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DingZ0M23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/ding-hailun-provenance",
            "url": "https://dblp.org/rec/conf/uss/DingZ0M23",
            "abstract": "Cyberattacks are becoming more frequent and sophisticated, and investigating them becomes more challenging. Prove-nance graphs are the primary data source to support forensics analysis. Because of system complexity and long attack duration, provenance graphs can be huge, and ef\ufb01ciently storing them remains a challenging problem. Existing works typically use relational or graph databases to store provenance graphs. These solutions suffer from high storage overhead and low query ef\ufb01ciency. Recently, researchers leveraged Deep Neural Networks (DNNs) in storage system design and achieved promising results. We observe that DNNs can embed given inputs as context-aware numerical vector representations, which are compact and support parallel query operations. In this paper, we propose to learn a DNN as the storage system for provenance graphs to achieve storage and query ef\ufb01ciency. We also present novel designs that leverage domain knowledge to reduce provenance data redundancy and build fast-query processing with indexes. We built a prototype L EONARD and evaluated it on 12 datasets. Compared with the relational database Quickstep and the graph database Neo4j, L EONARD reduced the space overhead by up to 25.90x and boosted up to 99.6% query executions.",
            "keywords": [
                "Provenance Graphs",
                "Storage Systems",
                "Forensics Analysis",
                "Data Redundancy",
                "Query Efficiency"
            ]
        },
        "url": "URL#915259",
        "sema_paperId": "8089ec5f563c33edbc9d088bce410565ef55dde1"
    },
    {
        "@score": "1",
        "@id": "915260",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "230/7753",
                        "text": "Hailun Ding"
                    },
                    {
                        "@pid": "154/5678",
                        "text": "Juan Zhai"
                    },
                    {
                        "@pid": "167/0416",
                        "text": "Yuhong Nan"
                    },
                    {
                        "@pid": "172/8745",
                        "text": "Shiqing Ma"
                    }
                ]
            },
            "title": "AIRTAG: Towards Automated Attack Investigation by Unsupervised Learning with Log Texts.",
            "venue": "USENIX Security Symposium",
            "pages": "373-390",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DingZNM23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/ding-hailun-airtag",
            "url": "https://dblp.org/rec/conf/uss/DingZNM23",
            "abstract": "The success of deep learning (DL) techniques has led to their adoption in many fields, including attack investigation, which aims to recover the whole attack story from logged system provenance by analyzing the causality of system objects and subjects. Existing DL-based techniques, e.g., state-of-the-art one ATLAS, follow the design of traditional forensics analysis pipelines. They train a DL model with labeled causal graphs during offline training to learn benign and malicious patterns. During attack investigation, they first convert the log data to causal graphs and leverage the trained DL model to determine if an entity is part of the whole attack chain or not. This design does not fully release the power of DL. Existing works like BERT have demonstrated the superiority of leveraging unsupervised pre-trained models, achieving state-of-the-art results without costly and error-prone data labeling. Prior DL-based attacks investigation has overlooked this opportunity. Moreover, generating and operating the graphs are time-consuming and not necessary. Based on our study, these operations take around 96% of the total analysis time, resulting in low efficiency. In addition, abstracting individual log entries to graph nodes and edges makes the analysis more coarse-grained, leading to inaccurate and unstable results. We argue that log texts provide the same information as causal graphs but are fine-grained and easier to analyze. This paper presents A IR T AG , a novel attack investigation system. It is powered by unsupervised learning with log texts. Instead of training on labeled graphs, A IR T AG leverages un-supervised learning to train a DL model on the log texts. Thus, we do not require the heavyweight and error-prone process of manually labeling logs. During the investigation, the DL model directly takes log files as inputs and predicts entities related to the attack. We evaluated A IR T AG on 19 scenarios, including single-host and multi-host attacks. Our results show the superior efficiency and effectiveness of A IR T AG compared to existing solutions. By removing graph generation and operations, A IR T AG is 2.5x faster than the state-of-the-art method, ATLAS, with 9.0% fewer false positives and 16.5% more true positives on average.",
            "keywords": [
                "Automated Attack Investigation",
                "Unsupervised Learning",
                "Log Analysis",
                "Causal Graphs",
                "Attack Detection"
            ]
        },
        "url": "URL#915260",
        "sema_paperId": "b6cb3a15accff1228290da5ab03effb1e711afea"
    },
    {
        "@score": "1",
        "@id": "915261",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "217/9667",
                        "text": "Youngwook Do"
                    },
                    {
                        "@pid": "222/8822",
                        "text": "Nivedita Arora"
                    },
                    {
                        "@pid": "299/6734",
                        "text": "Ali Mirzazadeh"
                    },
                    {
                        "@pid": "299/9495",
                        "text": "Injoo Moon"
                    },
                    {
                        "@pid": "353/7630",
                        "text": "Eryue Xu"
                    },
                    {
                        "@pid": "245/8608",
                        "text": "Zhihan Zhang"
                    },
                    {
                        "@pid": "a/GDAbowd",
                        "text": "Gregory D. Abowd"
                    },
                    {
                        "@pid": "83/8570",
                        "text": "Sauvik Das"
                    }
                ]
            },
            "title": "Powering for Privacy: Improving User Trust in Smart Speaker Microphones with Intentional Powering and Perceptible Assurance.",
            "venue": "USENIX Security Symposium",
            "pages": "2473-2490",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DoAMMXZAD23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/do",
            "url": "https://dblp.org/rec/conf/uss/DoAMMXZAD23",
            "abstract": "Smart speakers come with always-on microphones to facilitate voice-based interaction. To address user privacy concerns, existing devices come with a number of privacy features: e.g., mute buttons and local trigger-word detection modules. But it is difficult for users to trust that these manufacturer-provided privacy features actually work given that there is a misalignment of incentives: Google, Meta, and Amazon benefit from collecting personal data and users know it. What\u2019s needed is perceptible assurance \u2014 privacy features that users can, through physical perception, verify actually work. To that end, we introduce, implement, and evaluate the idea of \u201cintentionally-powered\u201d microphones to provide users with perceptible assurance of privacy with smart speakers. We employed an iterative-design process to develop Candid Mic , a battery-free, wireless microphone that can only be powered by harvesting energy from intentional user interactions. More-over, users can visually inspect the (dis)connection between the energy harvesting module and the microphone. Through a within-subjects experiment, we found that Candid Mic provides users with perceptible assurance about whether the microphone is capturing audio or not, and improves user trust in using smart speakers relative to mute button interfaces.",
            "keywords": [
                "Smart Speaker Privacy",
                "User Trust",
                "Microphone Assurance",
                "Intentional Powering",
                "Candid Mic"
            ]
        },
        "url": "URL#915261",
        "sema_paperId": "da8cb0dbb139c57049057b8ef1e56959cde50675"
    },
    {
        "@score": "1",
        "@id": "915262",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "62/2555-8",
                        "text": "Feng Dong 0008"
                    },
                    {
                        "@pid": "10/3099-2",
                        "text": "Liu Wang 0002"
                    },
                    {
                        "@pid": "351/6810",
                        "text": "Xu Nie"
                    },
                    {
                        "@pid": "84/11310",
                        "text": "Fei Shao"
                    },
                    {
                        "@pid": "50/8499-1",
                        "text": "Haoyu Wang 0001"
                    },
                    {
                        "@pid": "95/7132-1",
                        "text": "Ding Li 0001"
                    },
                    {
                        "@pid": "53/1565",
                        "text": "Xiapu Luo"
                    },
                    {
                        "@pid": "13/9656",
                        "text": "Xusheng Xiao"
                    }
                ]
            },
            "title": "DISTDET: A Cost-Effective Distributed Cyber Threat Detection System.",
            "venue": "USENIX Security Symposium",
            "pages": "6575-6592",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Dong0NS0LLX23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/dong-feng",
            "url": "https://dblp.org/rec/conf/uss/Dong0NS0LLX23",
            "abstract": "Building provenance graph that considers causal relationships among software behaviors can better provide contextual information of cyber attacks, especially for advanced attacks such as Advanced Persistent Threat (APT) attacks. Despite its promises in assisting attack investigation, existing approaches that use provenance graphs to perform attack detection suffer from two fundamental limitations. First, existing approaches adopt a centralized detection architecture that sends all system auditing logs to the server for processing, incurring intolerable costs of data transmission, data storage, and computation. Second, they adopt either rule-based techniques that cannot detect unknown threats, or anomaly-detection techniques that produce numerous false alarms, failing to achieve a balance of precision and recall in APT detection. To address these fundamental challenges, we propose D IST D ET , a distributed detection system that detects APT attacks by (1) performing light weight detection based on the host model built in the client side, (2) filtering false alarms based on the semantics of the alarm proprieties, and (3) deriving global models to complement the local bias of the host models. Our experiments on a large-scale industrial environment (1,130 hosts, 14 days, \u223c 1.6 billion events) and the DARPA TC dataset show that D IST D ET is as effective as sate-of-the-art techniques in detecting attacks, while dramatically reducing network bandwidth from 11.28Mb/s to 17.08Kb/S (676.5 \u00d7 reduction), memory usages from 364MB to 5.523MB (66 \u00d7 reduction), and storage from 1.47GB to 130.34MB (11.6 \u00d7 reduction). By the",
            "keywords": [
                "Distributed Cyber Threat Detection",
                "Provenance Graph",
                "Advanced Persistent Threat (APT)",
                "False Alarm Reduction",
                "Lightweight Detection"
            ]
        },
        "url": "URL#915262",
        "sema_paperId": "5a4a05f38b95946b8228f9c266e8657966b4fab7"
    },
    {
        "@score": "1",
        "@id": "915263",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "37/5655",
                        "text": "Yutao Dong"
                    },
                    {
                        "@pid": "181/2689-6",
                        "text": "Qing Li 0006"
                    },
                    {
                        "@pid": "203/8761",
                        "text": "Kaidong Wu"
                    },
                    {
                        "@pid": "08/10026-3",
                        "text": "Ruoyu Li 0003"
                    },
                    {
                        "@pid": "10/3489-3",
                        "text": "Dan Zhao 0003"
                    },
                    {
                        "@pid": "85/85",
                        "text": "Gareth Tyson"
                    },
                    {
                        "@pid": "259/6237",
                        "text": "Junkun Peng"
                    },
                    {
                        "@pid": "74/1552-1",
                        "text": "Yong Jiang 0001"
                    },
                    {
                        "@pid": "34/3173",
                        "text": "Shutao Xia"
                    },
                    {
                        "@pid": "18/6055",
                        "text": "Mingwei Xu"
                    }
                ]
            },
            "title": "HorusEye: A Realtime IoT Malicious Traffic Detection Framework using Programmable Switches.",
            "venue": "USENIX Security Symposium",
            "pages": "571-588",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Dong0WLZTP0XX23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/dong-yutao",
            "url": "https://dblp.org/rec/conf/uss/Dong0WLZTP0XX23",
            "abstract": "The ever-growing volume of IoT traffic brings challenges to IoT anomaly detection systems. Existing anomaly detection systems perform all traffic detection on the control plane, which struggles to scale to the growing rates of traffic. In this paper, we propose HorusEye, a high throughput and accurate two-stage anomaly detection framework. In the first stage, preliminary burst-level anomaly detection is implemented on the data plane to exploit its high-throughput capability (e.g., 100Gbps). We design an algorithm that converts a trained iForest model into white list matching rules, and implement the first unsupervised model that can detect unseen attacks on the data plane. The suspicious traffic is then reported to the control plane for further investigation. To reduce the false-positive rate, the control plane carries out the second stage, where more thorough anomaly detection is performed over the reported suspicious traffic using flow-level features and a deep detection model. We implement a prototype of HorusEye and evaluate its performance through a comprehensive set of experiments. The experimental results illustrate that the data plane can detect 99% of the anomalies and offload 76% of the traffic from the control plane. Compared with the state-of-the-art schemes, our framework has superior throughput and detection performance.",
            "keywords": [
                "IoT Anomaly Detection",
                "Traffic Detection",
                "Programmable Switches",
                "High Throughput Detection",
                "False Positive Reduction"
            ]
        },
        "url": "URL#915263",
        "sema_paperId": "9b2f9555e6d0a753e4855b0be9cc85b081e8e364"
    },
    {
        "@score": "1",
        "@id": "915264",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "02/6435",
                        "text": "Changlai Du"
                    },
                    {
                        "@pid": "256/7594",
                        "text": "Hexuan Yu"
                    },
                    {
                        "@pid": "181/1848-10",
                        "text": "Yang Xiao 0010"
                    },
                    {
                        "@pid": "h/YTHou",
                        "text": "Y. Thomas Hou 0001"
                    },
                    {
                        "@pid": "k/AngelosDKeromytis",
                        "text": "Angelos D. Keromytis"
                    },
                    {
                        "@pid": "73/3673",
                        "text": "Wenjing Lou"
                    }
                ]
            },
            "title": "UCBlocker: Unwanted Call Blocking Using Anonymous Authentication.",
            "venue": "USENIX Security Symposium",
            "pages": "445-462",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DuY00KL23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/du",
            "url": "https://dblp.org/rec/conf/uss/DuY00KL23",
            "abstract": "Telephone users are receiving more and more unwanted calls including spam and scam calls because of the transfer-without-veri\ufb01cation nature of global telephone networks, which allows anyone to call any other numbers. To avoid unwanted calls, telephone users often ignore or block all in-coming calls from unknown numbers, resulting in the missing of legitimate calls from new callers. This paper takes an end-to-end perspective to present a solution to block unwanted calls while allowing users to de\ufb01ne the policies of acceptable calls. The proposed solution involves a new infrastructure based on anonymous credentials, which enables anonymous caller authentication and policy de\ufb01nition. Our design de-couples caller authentication and call session initiation and introduces a veri\ufb01cation code to interface and bind the two processes. This design minimizes changes to telephone networks, reduces latency to call initiation, and eliminates the need for a call-time data channel. A prototype of the system is implemented to evaluate its feasibility.",
            "keywords": [
                "Unwanted Call Blocking",
                "Anonymous Authentication",
                "Caller Authentication",
                "Call Policy Definition",
                "Spam and Scam Calls"
            ]
        },
        "url": "URL#915264",
        "sema_paperId": "bcea85964a0297139523493014fe8be865b2a583"
    },
    {
        "@score": "1",
        "@id": "915265",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "261/3603",
                        "text": "Thorsten Eisenhofer"
                    },
                    {
                        "@pid": "149/3695",
                        "text": "Erwin Quiring"
                    },
                    {
                        "@pid": "338/5209",
                        "text": "Jonas M\u00f6ller"
                    },
                    {
                        "@pid": "277/3602",
                        "text": "Doreen Riepel"
                    },
                    {
                        "@pid": "h/ThorstenHolz",
                        "text": "Thorsten Holz"
                    },
                    {
                        "@pid": "64/4020",
                        "text": "Konrad Rieck"
                    }
                ]
            },
            "title": "No more Reviewer #2: Subverting Automatic Paper-Reviewer Assignment using Adversarial Learning.",
            "venue": "USENIX Security Symposium",
            "pages": "5109-5126",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/EisenhoferQMRHR23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/eisenhofer",
            "url": "https://dblp.org/rec/conf/uss/EisenhoferQMRHR23",
            "abstract": "The number of papers submitted to academic conferences is steadily rising in many scientific disciplines. To handle this growth, systems for automatic paper-reviewer assignments are increasingly used during the reviewing process. These systems use statistical topic models to characterize the content of submissions and automate the assignment to reviewers. In this paper, we show that this automation can be manipulated using adversarial learning. We propose an attack that adapts a given paper so that it misleads the assignment and selects its own reviewers. Our attack is based on a novel optimization strategy that alternates between the feature space and problem space to realize unobtrusive changes to the paper. To evaluate the feasibility of our attack, we simulate the paper-reviewer assignment of an actual security conference (IEEE S&P) with 165 reviewers on the program committee. Our results show that we can successfully select and remove reviewers without access to the assignment system. Moreover, we demonstrate that the manipulated papers remain plausible and are often indistinguishable from benign submissions.",
            "keywords": [
                "Automatic Reviewer Assignment",
                "Adversarial Learning",
                "Paper Manipulation",
                "Reviewer Selection",
                "Conference Paper Submission"
            ]
        },
        "url": "URL#915265",
        "sema_paperId": "b1108a0e089db14b10eb44d343409c26430f1f24"
    },
    {
        "@score": "1",
        "@id": "915266",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "224/9173",
                        "text": "Nurullah Erinola"
                    },
                    {
                        "@pid": "331/2735",
                        "text": "Marcel Maehren"
                    },
                    {
                        "@pid": "248/1716",
                        "text": "Robert Merget"
                    },
                    {
                        "@pid": "27/8331",
                        "text": "Juraj Somorovsky"
                    },
                    {
                        "@pid": "58/5730",
                        "text": "J\u00f6rg Schwenk"
                    }
                ]
            },
            "title": "Exploring the Unknown DTLS Universe: Analysis of the DTLS Server Ecosystem on the Internet.",
            "venue": "USENIX Security Symposium",
            "pages": "4859-4876",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ErinolaMMSS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/erinola",
            "url": "https://dblp.org/rec/conf/uss/ErinolaMMSS23",
            "abstract": "DTLS aims to bring the same security guarantees as TLS to UDP. It is used for latency-sensitive applications such as VPN, VoIP, video conferencing, and online gaming that can suffer from the overhead of a reliable transport protocol like TCP. While researchers and developers invested significant effort in improving the security of TLS, DTLS implementations have not received the same scrutiny despite their importance and similarity. It is thus an open question whether vulnerabilities discovered in TLS have been fixed in DTLS and whether DTLS-specific features open possibilities for new attacks. To fill this gap, we extended the open-source tool TLS-Scanner with support for DTLS and implemented additional tests for DTLS-exclusive features. We evaluated twelve open-source DTLS server implementations and uncovered eleven security vulnerabilities, including a padding oracle vulnerability in PionDTLS and DoS amplification vulnerabilities in wolfSSL, Scandium, and JSSE. We then proceeded to scan publicly available servers. We discovered and analyzed more than 500,000 DTLS servers across eight ports providing detailed insights into the publicly accessible DTLS server landscape. Beyond cryptographic vulnerabilities and compatibility issues, our analysis showed that 4.4% of the evaluated servers could be used for DoS amplification attacks due to insufficient care when handling anti-DoS cookies.",
            "keywords": [
                "DTLS Security",
                "UDP Security",
                "Vulnerability Analysis",
                "DoS Amplification",
                "Padding Oracle Vulnerability"
            ]
        },
        "url": "URL#915266",
        "sema_paperId": "b13a7c2012b24c2316329f8c51504fb3b83aae73"
    },
    {
        "@score": "1",
        "@id": "915267",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "157/9161",
                        "text": "Kevin Eykholt"
                    },
                    {
                        "@pid": "60/10355",
                        "text": "Taesung Lee"
                    },
                    {
                        "@pid": "74/10805",
                        "text": "Douglas Lee Schales"
                    },
                    {
                        "@pid": "58/688",
                        "text": "Jiyong Jang"
                    },
                    {
                        "@pid": "17/2811",
                        "text": "Ian M. Molloy"
                    },
                    {
                        "@pid": "238/0235",
                        "text": "Masha Zorin"
                    }
                ]
            },
            "title": "URET: Universal Robustness Evaluation Toolkit (for Evasion).",
            "venue": "USENIX Security Symposium",
            "pages": "3817-3833",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/EykholtLSJMZ23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/eykholt",
            "url": "https://dblp.org/rec/conf/uss/EykholtLSJMZ23",
            "abstract": "Machine learning models are known to be vulnerable to adversarial evasion attacks as illustrated by image classification models. Thoroughly understanding such attacks is critical in order to ensure the safety and robustness of critical AI tasks. However, most evasion attacks are difficult to deploy against a majority of AI systems because they have focused on image domain with only few constraints. An image is composed of homogeneous, numerical, continuous, and independent features, unlike many other input types to AI systems used in practice. Furthermore, some input types include additional semantic and functional constraints that must be observed to generate realistic adversarial inputs. In this work, we propose a new framework to enable the generation of adversarial inputs irrespective of the input type and task domain. Given an input and a set of pre-defined input transformations, our framework discovers a sequence of transformations that result in a semantically correct and functional adversarial input. We demonstrate the generality of our approach on several diverse machine learning tasks with various input representations. We also show the importance of generating adversarial examples as they enable the deployment of mitigation techniques.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-eykholt.pdf",
            "keywords": [
                "Adversarial Evasion Attacks",
                "Robustness Evaluation",
                "Input Transformations",
                "Adversarial Inputs",
                "Mitigation Techniques"
            ]
        },
        "url": "URL#915267"
    },
    {
        "@score": "1",
        "@id": "915268",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "81/7083-1",
                        "text": "Muhammad Faisal 0001"
                    },
                    {
                        "@pid": "39/9312",
                        "text": "Jerry Zhang"
                    },
                    {
                        "@pid": "95/9170",
                        "text": "John Liagouris"
                    },
                    {
                        "@pid": "132/6943",
                        "text": "Vasiliki Kalavri"
                    },
                    {
                        "@pid": "59/6288",
                        "text": "Mayank Varia"
                    }
                ]
            },
            "title": "TVA: A multi-party computation system for secure and expressive time series analytics.",
            "venue": "USENIX Security Symposium",
            "pages": "5395-5412",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/FaisalZLKV23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/faisal",
            "url": "https://dblp.org/rec/conf/uss/FaisalZLKV23",
            "abstract": "We present TVA, a multi-party computation (MPC) system for secure analytics on secret-shared time series data. TVA achieves strong security guarantees in the semi-honest and malicious settings, and high expressivity by enabling complex analytics on inputs with unordered and irregular timestamps. TVA is the first system to support arbitrary composition of oblivious window operators, keyed aggregations, and multiple filter predicates, while keeping all data attributes private, including record timestamps and user-defined values in query predicates. At the core of the TVA system lie novel protocols for secure window assignment: (i) a tumbling window protocol that groups records into fixed-length time buckets and (ii) two session window protocols that identify periods of activity followed by periods of inactivity. We also contribute a new protocol for secure division with a public divisor, which may be of independent interest. We evaluate TVA on real LAN and WAN environments and show that it can efficiently compute complex window-based analytics on inputs of 222 records with modest use of resources. When compared to the state-of-the-art, TVA achieves up to 5.8\u00d7 lower latency in queries with multiple filters and two orders of magnitude better performance in window aggregation.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-faisal.pdf",
            "keywords": [
                "Multi-Party Computation",
                "Time Series Analytics",
                "Secure Data Sharing",
                "Window Operators",
                "Complex Query Processing"
            ]
        },
        "url": "URL#915268"
    },
    {
        "@score": "1",
        "@id": "915269",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "33/4721",
                        "text": "Brett Hemenway Falk"
                    },
                    {
                        "@pid": "o/RafailOstrovsky",
                        "text": "Rafail Ostrovsky"
                    },
                    {
                        "@pid": "328/2656",
                        "text": "Matan Shtepel"
                    },
                    {
                        "@pid": "348/6183",
                        "text": "Jacob Zhang"
                    }
                ]
            },
            "title": "GigaDORAM: Breaking the Billion Address Barrier.",
            "venue": "USENIX Security Symposium",
            "pages": "3871-3888",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/FalkOSZ23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/falk",
            "url": "https://dblp.org/rec/conf/uss/FalkOSZ23",
            "abstract": "We design and implement GigaDORAM, a novel 3-server Distributed Oblivious Random Access Memory (DORAM) protocol. Oblivious RAM allows a client to read and write to memory on an untrusted server, while ensuring the server itself learns nothing about the client's access pattern. Distributed Oblivious RAM (DORAM) allows a group of servers to efficiently access a secret-shared array at a secret-shared index.\nA recent generation of DORAM implementations (e.g. FLORAM, DuORAM) have focused on building DORAM protocols based on Function Secret-Sharing (FSS). These protocols have low communication complexity and low round complexity but linear computational complexity of the servers. Thus, they work for moderate size databases, but at a certain size these FSS-based protocols become computationally inefficient.\nIn this work, we introduce GigaDORAM, a hierarchical-solution-based DORAM featuring poly-logarithmic computation and communication, but with an over 100\u00d7 reduction in rounds per query compared to previous hierarchical DORAM protocols. In our implementation, we show that for moderate to large databases where FSS-based solutions become computation bound, our protocol is orders of magnitude more efficient than the best existing DORAM protocols. When N = 231, our DORAM is able to perform over 700 queries per second.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-falk.pdf",
            "keywords": [
                "Distributed Oblivious RAM",
                "Oblivious RAM",
                "Hierarchical DORAM",
                "Function Secret-Sharing",
                "Computational Efficiency"
            ]
        },
        "url": "URL#915269"
    },
    {
        "@score": "1",
        "@id": "915270",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "222/5923",
                        "text": "Habiba Farrukh"
                    },
                    {
                        "@pid": "158/9223-3",
                        "text": "Reham Mohamed 0003"
                    },
                    {
                        "@pid": "353/7686",
                        "text": "Aniket Nare"
                    },
                    {
                        "@pid": "99/3883",
                        "text": "Antonio Bianchi"
                    },
                    {
                        "@pid": "143/2298",
                        "text": "Z. Berkay Celik"
                    }
                ]
            },
            "title": "LocIn: Inferring Semantic Location from Spatial Maps in Mixed Reality.",
            "venue": "USENIX Security Symposium",
            "pages": "877-894",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Farrukh0NBC23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/farrukh",
            "url": "https://dblp.org/rec/conf/uss/Farrukh0NBC23",
            "abstract": "Mixed reality (MR) devices capture 3D spatial maps of users\u2019 surroundings to integrate virtual content into their physical environment. Existing permission models implemented in popular MR platforms allow all MR apps to access these 3D spatial maps without explicit permission. Unmonitored access of MR apps to these 3D spatial maps poses serious privacy threats to users as these maps capture detailed geometric and semantic characteristics of users\u2019 environments. In this paper, we present L OC I N , a new location inference attack that exploits these detailed characteristics embedded in 3D spatial maps to infer a user\u2019s indoor location type. L OC I N develops a multi-task approach to train an end-to-end encoder-decoder network that extracts a spatial feature representation for capturing contextual patterns of the user\u2019s environment. L OC I N leverages this representation to detect 3D objects and surfaces and integrates them into a classification network with a novel unified optimization function to predict the user\u2019s indoor location. We demonstrate L OC I N attack on spatial maps collected from three popular MR devices. We show that L OC I N infers a user\u2019s location type with an average 84 . 1% accuracy.",
            "keywords": [
                "Mixed Reality",
                "Spatial Maps",
                "Location Inference",
                "Privacy Threats",
                "Indoor Location Classification"
            ]
        },
        "url": "URL#915270",
        "sema_paperId": "9a1d5ced3e93325a49f97af6e87fe0ea07c54043"
    },
    {
        "@score": "1",
        "@id": "915271",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "241/1456",
                        "text": "Yuzhou Feng"
                    },
                    {
                        "@pid": "353/7598",
                        "text": "Ruyu Zhai"
                    },
                    {
                        "@pid": "s/RaduSion",
                        "text": "Radu Sion"
                    },
                    {
                        "@pid": "20/4777",
                        "text": "Bogdan Carbunar"
                    }
                ]
            },
            "title": "A Study of China&apos;s Censorship and Its Evasion Through the Lens of Online Gaming.",
            "venue": "USENIX Security Symposium",
            "pages": "2599-2616",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/FengZSC23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/feng",
            "url": "https://dblp.org/rec/conf/uss/FengZSC23",
            "abstract": "For the past 20 years, China has increasingly restricted the access of minors to online games using addiction prevention systems (APSes). At the same time, and through different means, i.e., the Great Firewall of China (GFW), it also restricts general population access to the international Internet. This paper studies how these restrictions impact young online gamers, and their evasion efforts. We present results from surveys (n = 2,415) and semi-structured interviews (n = 35) revealing viable commonly deployed APS evasion techniques and APS vulnerabilities. We conclude that the APS does not work as designed, even against very young online game players, and can act as a censorship evasion training ground for tomorrow's adults, by familiarization with and normalization of general evasion techniques, and desensitization to their dangers. Findings from these studies may further inform developers of censorship-resistant systems about the perceptions and evasion strategies of their prospective users, and help design tools that leverage services and platforms popular among the censored audience.",
            "keywords": [
                "Online Gaming Censorship",
                "Addiction Prevention Systems",
                "Censorship Evasion",
                "Great Firewall of China",
                "Youth Gaming Behavior"
            ]
        },
        "url": "URL#915271",
        "sema_paperId": "f2ffb1e8f66e4dbcf2538a43dbe395f1371d7de5"
    },
    {
        "@score": "1",
        "@id": "915272",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "353/7642",
                        "text": "Marius Fleischer"
                    },
                    {
                        "@pid": "90/3182-2",
                        "text": "Dipanjan Das 0002"
                    },
                    {
                        "@pid": "160/3848",
                        "text": "Priyanka Bose"
                    },
                    {
                        "@pid": "353/5181",
                        "text": "Weiheng Bai"
                    },
                    {
                        "@pid": "67/10639",
                        "text": "Kangjie Lu"
                    },
                    {
                        "@pid": "31/1273",
                        "text": "Mathias Payer"
                    },
                    {
                        "@pid": "k/ChristopherKruegel",
                        "text": "Christopher Kruegel"
                    },
                    {
                        "@pid": "v/GiovanniVigna",
                        "text": "Giovanni Vigna"
                    }
                ]
            },
            "title": "ACTOR: Action-Guided Kernel Fuzzing.",
            "venue": "USENIX Security Symposium",
            "pages": "5003-5020",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Fleischer0BBLPK23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/fleischer",
            "url": "https://dblp.org/rec/conf/uss/Fleischer0BBLPK23",
            "abstract": "Fuzzing reliably and efficiently finds bugs in software, including operating system kernels. In general, higher code coverage leads to the discovery of more bugs. This is why most existing kernel fuzzers adopt strategies to generate a series of inputs that attempt to greedily maximize the amount of code that they exercise. However, simply executing code may not be sufficient to reveal bugs that require specific sequences of actions. Synthesizing inputs to trigger such bugs depends on two aspects: (i) the actions the executed code takes, and (ii) the order in which those actions are taken. An action is a high-level operation, such as a heap allocation, that is performed by the executed code and has a specific semantic meaning. A CTOR , our action-guided kernel fuzzing framework, deviates from traditional methods. Instead of focusing on code coverage optimization, our approach generates fuzzer programs (inputs) that leverage our understanding of triggered actions and their temporal relationships. Specifically, we first capture actions that potentially operate on shared data structures at different times. Then, we synthesize programs using those actions as building blocks, guided by bug templates expressed in our domain-specific language. We evaluated A CTOR on four different versions of the Linux kernel, including two well-tested and frequently updated long-term (5 . 4 . 206, 5 . 10 . 131) versions, a stable (5 . 19), and the latest (6 . 2-rc5) release. Our evaluation revealed a total of 41 previously unknown bugs, of which 9 have already been fixed. Interestingly, 15 (36 . 59%) of them were discovered in less than a day",
            "keywords": [
                "Kernel Fuzzing",
                "Action-Guided Testing",
                "Bug Discovery",
                "Code Coverage Optimization",
                "Temporal Action Relationships"
            ]
        },
        "url": "URL#915272",
        "sema_paperId": "cfa6c78222a46d96b0dd0794a8eb238a2110a550"
    },
    {
        "@score": "1",
        "@id": "915273",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "224/9316",
                        "text": "Gertjan Franken"
                    },
                    {
                        "@pid": "147/2244",
                        "text": "Tom van Goethem"
                    },
                    {
                        "@pid": "51/1256",
                        "text": "Lieven Desmet"
                    },
                    {
                        "@pid": "13/86",
                        "text": "Wouter Joosen"
                    }
                ]
            },
            "title": "A Bug&apos;s Life: Analyzing the Lifecycle and Mitigation Process of Content Security Policy Bugs.",
            "venue": "USENIX Security Symposium",
            "pages": "3673-3690",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/FrankenGDJ23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/franken",
            "url": "https://dblp.org/rec/conf/uss/FrankenGDJ23",
            "abstract": "The constantly evolving Web exerts a chronic pressure on the development and maintenance of the Content Security Policy (CSP), which stands as one of the primary security policies to mitigate attacks such as cross-site scripting. Indeed, to attain comprehensiveness, the policy must account for virtually every newly introduced browser feature, and every existing browser feature must be scrutinized upon extension of CSP functionality. Unfortunately, this undertaking\u2019s complexity has already led to critical implementational shortcomings, resulting in the security subversion of all CSP-employing websites. In this paper, we present the first systematic analysis of CSP bug lifecycles, shedding new light on bug root causes. As such, we leverage our automated framework, B UG H OG , to evaluate the reproducibility of publicly disclosed bug proofs of concept in over 100 , 000 browser revisions. By considering the entire source code revision history since the introduction of CSP for Chromium and Firefox, we identified 123 unique introducing and fixing revisions for 75 CSP bugs. Our analysis shows that inconsistent handling of bugs led to the early public disclosure of three, and that the lifetime of several others could have been considerably decreased through adequate bug sharing between vendors. Finally, we propose solutions to improve current bug handling and response practices.",
            "keywords": [
                "Content Security Policy",
                "Web Security",
                "Bug Lifecycle",
                "CSP Vulnerabilities",
                "Cross-Site Scripting Mitigation"
            ]
        },
        "url": "URL#915273",
        "sema_paperId": "f8fb22ca7c6bd26c94803854d9e4afab4591e2cd"
    },
    {
        "@score": "1",
        "@id": "915274",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "30/6251",
                        "text": "Chong Fu"
                    },
                    {
                        "@pid": "139/6932-2",
                        "text": "Xuhong Zhang 0002"
                    },
                    {
                        "@pid": "07/8388",
                        "text": "Shouling Ji"
                    },
                    {
                        "@pid": "12/2633-6",
                        "text": "Ting Wang 0006"
                    },
                    {
                        "@pid": "43/5433",
                        "text": "Peng Lin"
                    },
                    {
                        "@pid": "06/8481",
                        "text": "Yanghe Feng"
                    },
                    {
                        "@pid": "74/3786",
                        "text": "Jianwei Yin"
                    }
                ]
            },
            "title": "FreeEagle: Detecting Complex Neural Trojans in Data-Free Cases.",
            "venue": "USENIX Security Symposium",
            "pages": "6399-6416",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Fu0J0LFY23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/fu-chong",
            "url": "https://dblp.org/rec/conf/uss/Fu0J0LFY23",
            "abstract": "Trojan attack on deep neural networks, also known as backdoor attack, is a typical threat to artificial intelligence. A trojaned neural network behaves normally with clean inputs. However, if the input contains a particular trigger, the trojaned model will have attacker-chosen abnormal behavior. Although many backdoor detection methods exist, most of them assume that the defender has access to a set of clean validation samples or samples with the trigger, which may not hold in some crucial real-world cases, e.g., the case where the defender is the maintainer of model-sharing platforms. Thus, in this paper, we propose FreeEagle, the first data-free backdoor detection method that can effectively detect complex backdoor attacks on deep neural networks, without relying on the access to any clean samples or samples with the trigger. The evaluation results on diverse datasets and model architectures show that FreeEagle is effective against various complex backdoor attacks, even outperforming some state-of-the-art non-data-free backdoor detection methods.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-fu-chong.pdf",
            "keywords": [
                "Backdoor Detection",
                "Trojan Attack",
                "Data-Free Detection",
                "Neural Trojan",
                "Complex Backdoor Attacks"
            ]
        },
        "url": "URL#915274"
    },
    {
        "@score": "1",
        "@id": "915275",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "252/4027",
                        "text": "Yu-Fu Fu"
                    },
                    {
                        "@pid": "65/1125",
                        "text": "Jae-Hyuk Lee"
                    },
                    {
                        "@pid": "38/8882",
                        "text": "Taesoo Kim"
                    }
                ]
            },
            "title": "autofz: Automated Fuzzer Composition at Runtime.",
            "venue": "USENIX Security Symposium",
            "pages": "1901-1918",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/FuLK23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/fu-yu-fu",
            "url": "https://dblp.org/rec/conf/uss/FuLK23",
            "abstract": "Fuzzing has gained in popularity for software vulnerability detection by virtue of the tremendous effort to develop a diverse set of fuzzers. Thanks to various fuzzing techniques, most of the fuzzers have been able to demonstrate great performance on their selected targets. However, paradoxically, this diversity in fuzzers also made it difficult to select fuzzers that are best suitable for complex real-world programs, which we call selection burden.  Communities attempted to address this problem by creating a set of standard benchmarks to compare and contrast the performance of fuzzers for a wide range of applications, but the result was always a suboptimal decision\u2014the best-performing fuzzer on average does not guarantee the best outcome for the target of a user's interest.\nTo overcome this problem, we propose an automated, yet non-intrusive meta-fuzzer, called autofz, to maximize the benefits of existing state-of-the-art fuzzers via dynamic composition.  To an end user, this means that, instead of spending time on selecting which fuzzer to adopt (similar in concept to hyperparameter tuning in ML), one can simply put all of the available fuzzers to autofz (similar in concept to AutoML), and achieve the best, optimal result.  The key idea is to monitor the runtime progress of the fuzzers, called trends (similar in concept to gradient descent), and make a fine-grained adjustment of resource allocation (e.g., CPU time) of each fuzzer.  This is a stark contrast to existing approaches that statically combine a set of fuzzers, or via exhaustive pre-training per target program - autofz deduces a suitable set of fuzzers of the active workload in a fine-grained manner at runtime.  Our evaluation shows that, given the same amount of computation resources, autofz outperforms any best-performing individual fuzzers in 11 out of 12 available benchmarks and beats the best, collaborative fuzzing approaches in 19 out of 20 benchmarks without any prior knowledge in terms of coverage.  Moreover, on average, autofz found 152% more bugs than individual fuzzers on UNIFUZZ and FTS, and 415% more bugs than collaborative fuzzing on UNIFUZZ.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-fu-yu-fu.pdf",
            "keywords": [
                "Fuzzing",
                "Automated Fuzzer Composition",
                "Vulnerability Detection",
                "Resource Allocation",
                "Dynamic Composition"
            ]
        },
        "url": "URL#915275"
    },
    {
        "@score": "1",
        "@id": "915277",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "152/4890",
                        "text": "Varun Gandhi"
                    },
                    {
                        "@pid": "224/8745",
                        "text": "Sarbartha Banerjee"
                    },
                    {
                        "@pid": "326/7146",
                        "text": "Aniket Agrawal"
                    },
                    {
                        "@pid": "205/3202",
                        "text": "Adil Ahmad"
                    },
                    {
                        "@pid": "17/5702-1",
                        "text": "Sangho Lee 0001"
                    },
                    {
                        "@pid": "56/6925",
                        "text": "Marcus Peinado"
                    }
                ]
            },
            "title": "Rethinking System Audit Architectures for High Event Coverage and Synchronous Log Availability.",
            "venue": "USENIX Security Symposium",
            "pages": "391-408",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GandhiBAA0P23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/gandhi",
            "url": "https://dblp.org/rec/conf/uss/GandhiBAA0P23",
            "abstract": "Once an attacker compromises the operating system, the integrity and availability of unprotected system audit logs still kept on the computer becomes uncertain. In this paper, we ask the question: can recently proposed audit systems aimed at tackling such an attacker provide enough information for forensic analysis? Our findings suggest that the answer is no, because the inefficient logging pipelines of existing audit systems prohibit generating log entries for a vast majority of attack events and protecting logs as soon as they are created (i.e., synchronously ). This leads to a low attack event coverage within generated logs, while allowing attackers to tamper with unprotected logs after a compromise. To counter these limitations, we present O MNI L OG , a system audit architecture that composes an end-to-end efficient logging pipeline where logs are rapidly generated and protected using a set of platform-agnostic security abstractions. This allows O MNI L OG to enable high attack event coverage and synchronous log availability, while even outperforming the state-of-the-art audit systems that achieve neither property.",
            "keywords": [
                "System Audit Architecture",
                "Event Logging",
                "Forensic Analysis",
                "Log Integrity",
                "Attack Event Coverage"
            ]
        },
        "url": "URL#915277",
        "sema_paperId": "e1e0bf993829da3b4274ae931dd16553d9eb579e"
    },
    {
        "@score": "1",
        "@id": "915278",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "306/8197",
                        "text": "Xinben Gao"
                    },
                    {
                        "@pid": "54/2752",
                        "text": "Lan Zhang"
                    }
                ]
            },
            "title": "PCAT: Functionality and Data Stealing from Split Learning by Pseudo-Client Attack.",
            "venue": "USENIX Security Symposium",
            "pages": "5271-5288",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GaoZ23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/gao",
            "url": "https://dblp.org/rec/conf/uss/GaoZ23",
            "abstract": "Split learning (SL) is a popular framework to protect a client\u2019s training data by splitting up a model among the client and the server. Previous efforts have shown that a semi-honest server can conduct a model inversion attack to recover the client\u2019s inputs and model parameters to some extent, as well as to infer the labels. However, those attacks require the knowledge of the client network structure and the performance deteriorates dramatically as the client network gets deeper ( \u2265 2 layers). In this work, we explore the attack on SL in a more general and challenging situation where the client model is unknown to the server and gets more complex and deeper. Different from the conventional model inversion, we investigate the inherent privacy leakage through the server model in SL and reveal that clients\u2019 functionality and private data can be easily stolen by the server model, and a series of intermediate server models during SL can even cause more leakage. Based on the insights, we propose a new attack on SL: P seudo-C lient AT tack (PCAT). To the best of our knowledge, this is the first attack for a semi-honest server to steal clients\u2019 functionality, reconstruct private inputs and infer private labels without any knowledge about the clients\u2019 model. The only requirement for the server is a tiny dataset (about 0.1% - 5% of the private training set) for the same learning task. What\u2019s more, the attack is transparent to clients, so a server can obtain clients\u2019 privacy without taking any risk of being detected by the client. We implement PCAT on various benchmark datasets and models. Extensive experiments testify that our attack significantly outperforms the state-of-the-art attack in various conditions, including more complex models and learning tasks, even in non-i.i.d. conditions. Moreover, our functionality stealing attack is resilient to the existing defensive mechanism.",
            "keywords": [
                "Split Learning",
                "Privacy Leakage",
                "Model Inversion Attack",
                "Functionality Theft",
                "Pseudo-Client Attack (PCAT)"
            ]
        },
        "url": "URL#915278",
        "sema_paperId": "39b899643b46651b92452f4c7bac72f3cf431b22"
    },
    {
        "@score": "1",
        "@id": "915279",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "33/5817",
                        "text": "Sanjam Garg"
                    },
                    {
                        "@pid": "172/0408",
                        "text": "Aarushi Goel"
                    },
                    {
                        "@pid": "34/3",
                        "text": "Abhishek Jain 0002"
                    },
                    {
                        "@pid": "276/0468",
                        "text": "Guru-Vamsi Policharla"
                    },
                    {
                        "@pid": "208/0806",
                        "text": "Sruthi Sekar"
                    }
                ]
            },
            "title": "zkSaaS: Zero-Knowledge SNARKs as a Service.",
            "venue": "USENIX Security Symposium",
            "pages": "4427-4444",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GargG0PS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/garg",
            "url": "https://dblp.org/rec/conf/uss/GargG0PS23",
            "abstract": "A decade of active research has led to practical constructions of zero-knowledge succinct non-interactive arguments of knowledge (zk-SNARKs) that are now being used in a wide variety of applications. Despite this astonishing progress, overheads in proof generation time remain significant. \nIn this work, we envision a world where consumers with low computational resources can outsource the task of proof generation to a group of untrusted servers in a privacy-preserving manner. The main requirement is that these servers should be able to collectively generate proofs at a faster speed (than the consumer). Towards this goal, we introduce a framework called zk-SNARKs-as-a-service (zkSaaS) for faster computation of zk-SNARKs. Our framework allows for distributing proof computation across multiple servers such that each server is expected to run for a shorter duration than a single prover. Moreover, the privacy of the prover's witness is ensured against any minority of colluding servers. \nWe design custom protocols in this framework that can be used to obtain faster runtimes for widely used zk-SNARKs, such as Groth16 [EUROCRYPT 2016], Marlin [EUROCRYPT 2020] and Plonk [EPRINT 2019]. We implement proof of concept zkSaaS for the Groth16 and Plonk provers. In comparison to generating these proofs on commodity hardware, we can not only generate proofs for a larger number of constraints (without memory exhaustion), but can also get \u224822\u00d7 speed-up when run with 128 parties for 225 constraints with Groth16 and 221 gates with Plonk.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-garg.pdf",
            "keywords": [
                "Zero-Knowledge Proofs",
                "zk-SNARKs",
                "Proof Generation",
                "Distributed Computing",
                "Privacy Preservation"
            ]
        },
        "url": "URL#915279"
    },
    {
        "@score": "1",
        "@id": "915280",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "331/2536",
                        "text": "Anthony Gavazzi"
                    },
                    {
                        "@pid": "202/1974",
                        "text": "Ryan Williams"
                    },
                    {
                        "@pid": "k/EnginKirda",
                        "text": "Engin Kirda"
                    },
                    {
                        "@pid": "81/7428",
                        "text": "Long Lu"
                    },
                    {
                        "@pid": "353/7620",
                        "text": "Andre King"
                    },
                    {
                        "@pid": "60/920",
                        "text": "Andy Davis"
                    },
                    {
                        "@pid": "74/4618",
                        "text": "Tim Leek"
                    }
                ]
            },
            "title": "A Study of Multi-Factor and Risk-Based Authentication Availability.",
            "venue": "USENIX Security Symposium",
            "pages": "2043-2060",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GavazziWKLKDL23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/gavazzi",
            "url": "https://dblp.org/rec/conf/uss/GavazziWKLKDL23",
            "abstract": "Password-based authentication (PBA) remains the most popular form of user authentication on the web despite its long-understood insecurity. Given the deficiencies of PBA, many online services support multi-factor authentication (MFA) and/or risk-based authentication (RBA) to better secure user accounts. The security, usability, and implementations of MFA and RBA have been studied extensively, but attempts to measure their availability among popular web services have lacked breadth. Additionally, no study has analyzed MFA and RBA prevalence together or how the presence of Single-Sign-On (SSO) providers affects the availability of MFA and RBA on the web. In this paper, we present a study of 208 popular sites in the Tranco top 5K that support account creation to understand the availability of MFA and RBA on the web, the additional authentication factors that can be used for MFA and RBA, and how logging into sites through more secure SSO providers changes the landscape of user authentication security. We find that only 42.31% of sites support any form of MFA, and only 22.12% of sites block an obvious account hijacking attempt. Though most sites do not offer MFA or RBA, SSO completely changes the picture. If one were to create an account for each site through an SSO provider that offers MFA and/or RBA, whenever available, 80.29% of sites would have access to MFA and 72.60% of sites would stop an obvious account hijacking attempt. However, this proliferation through SSO comes with a privacy trade-off, as nearly all SSO providers that support MFA and RBA are major third-party trackers.",
            "keywords": [
                "Multi-Factor Authentication",
                "Risk-Based Authentication",
                "User Authentication",
                "Account Security",
                "Single-Sign-On"
            ]
        },
        "url": "URL#915280",
        "sema_paperId": "d142ab94cc480191594ba0285cf86d29487e9073"
    },
    {
        "@score": "1",
        "@id": "915281",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "337/8159",
                        "text": "Gabriel K. Gegenhuber"
                    },
                    {
                        "@pid": "170/0100",
                        "text": "Wilfried Mayer"
                    },
                    {
                        "@pid": "w/EdgarRWeippl",
                        "text": "Edgar R. Weippl"
                    },
                    {
                        "@pid": "138/2614",
                        "text": "Adrian Dabrowski"
                    }
                ]
            },
            "title": "MobileAtlas: Geographically Decoupled Measurements in Cellular Networks for Security and Privacy Research.",
            "venue": "USENIX Security Symposium",
            "pages": "3493-3510",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GegenhuberMWD23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/gegenhuber",
            "url": "https://dblp.org/rec/conf/uss/GegenhuberMWD23",
            "abstract": "Cellular networks are not merely data access networks to the Internet. Their distinct services and ability to form large complex compounds for roaming purposes make them an attractive research target in their own right. Their promise of providing a consistent service with comparable privacy and security across roaming partners falls apart at close inspection. Thus, there is a need for controlled testbeds and measurement tools for cellular access networks doing justice to the technology's unique structure and global scope. Particularly, such measurements suffer from a combinatorial explosion of operators, mobile plans, and services. To cope with these challenges, we built a framework that geographically decouples the SIM from the cellular modem by selectively connecting both remotely. This allows testing any subscriber with any operator at any modem location within minutes without moving parts. The resulting GSM/UMTS/LTE measurement and testbed platform offers a controlled experimentation environment, which is scalable and cost-effective. The platform is extensible and fully open-sourced, allowing other researchers to contribute locations, SIM cards, and measurement scripts. Using the above framework, our international experiments in commercial networks revealed exploitable inconsistencies in traffic metering, leading to multiple phreaking opportunities, i.e., fare-dodging. We also expose problematic IPv6 firewall configurations, hidden SIM card communication to the home network, and fingerprint dial progress tones to track victims across different roaming networks and countries with voice calls.",
            "keywords": [
                "Cellular Network Security",
                "Geographically Decoupled Measurements",
                "Traffic Metering Inconsistencies",
                "SIM Card Communication",
                "Roaming Network Vulnerabilities"
            ]
        },
        "url": "URL#915281",
        "sema_paperId": "7972c151ba8131e9c41f355859b85402824d86b9"
    },
    {
        "@score": "1",
        "@id": "915282",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "353/7521",
                        "text": "Da\u00f1iel Gerhardt"
                    },
                    {
                        "@pid": "301/5910",
                        "text": "Alexander Ponticello"
                    },
                    {
                        "@pid": "138/2614",
                        "text": "Adrian Dabrowski"
                    },
                    {
                        "@pid": "128/4803",
                        "text": "Katharina Krombholz"
                    }
                ]
            },
            "title": "Investigating Verification Behavior and Perceptions of Visual Digital Certificates.",
            "venue": "USENIX Security Symposium",
            "pages": "3565-3582",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GerhardtPDK23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/gerhardt",
            "url": "https://dblp.org/rec/conf/uss/GerhardtPDK23",
            "abstract": "This paper presents a qualitative study to explore how individuals perceive and verify visual digital certificates with QR codes. During the COVID-19 pandemic, such certificates have been used in the EU to provide standardized proof of vaccination. We conducted semi-structured interviews with N = 17 participants responsible for verifying COVID-19 certificates as part of their job. Using a two-fold thematic analysis approach, we, among other things, identified and classified multiple behavioral patterns, including inadequate reliance on visual cues as a proxy for proper digital verification. We present design and structural recommendations based on our findings, including conceptual changes and improvements to storage and verification apps to limit shortcut opportunities. Our empirical findings are hence essential to improve the usability, robustness, and effectiveness of visual digital certificates and their verification.",
            "keywords": [
                "Visual Digital Certificates",
                "QR Codes",
                "Verification Behavior",
                "COVID-19 Certificates",
                "User Perceptions"
            ]
        },
        "url": "URL#915282",
        "sema_paperId": "ab7496c0ed244d5fd982cbc247da9448834ff9a7"
    },
    {
        "@score": "1",
        "@id": "915283",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "320/6437",
                        "text": "Matthias Gierlings"
                    },
                    {
                        "@pid": "76/6564",
                        "text": "Marcus Brinkmann"
                    },
                    {
                        "@pid": "58/5730",
                        "text": "J\u00f6rg Schwenk"
                    }
                ]
            },
            "title": "Isolated and Exhausted: Attacking Operating Systems via Site Isolation in the Browser.",
            "venue": "USENIX Security Symposium",
            "pages": "7037-7054",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GierlingsBS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/gierlings",
            "url": "https://dblp.org/rec/conf/uss/GierlingsBS23",
            "abstract": "Site Isolation [12,40] is a security architecture for browsers to protect against side-channel and renderer exploits by sep-arating content from different sites at the operating system (OS) process level. By aligning web and OS security boundaries, Site Isolation promises to defend against these attack classes systematically in a streamlined architecture. However, Site Isolation is a large-scale architectural change that also makes OS resources more accessible to web attackers, and thus exposes web users to new risks at the OS level . In this paper, we present the \ufb01rst systematic study of OS resource exhaustion attacks based on Site Isolation, in the web attacker model , in three steps: (1) \ufb01rst-level resources directly accessible with Site Isolation; (2) second-level resources whose direct use is protected by the browser sandbox; (3) an advanced, real-world attack. For (1) we show how to create a fork bomb , highlighting conceptual gaps in the Site Isolation architecture. For (2) we show how to block all UDP sockets in an OS, using a variety of advanced browser features. For (3), we implement a fully working DNS Cache Poisoning attack based on Site Isolation, building on (2) and bypassing a major security feature of DNS. Our results show that the interplay between modern browser features and older OS features is increasingly problematic and needs further research.",
            "keywords": [
                "Site Isolation",
                "Operating System Security",
                "Resource Exhaustion Attacks",
                "Browser Security Architecture",
                "DNS Cache Poisoning"
            ]
        },
        "url": "URL#915283",
        "sema_paperId": "a8b0a7d012aeb271d3697c705e711ba81fb80121"
    },
    {
        "@score": "1",
        "@id": "915284",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "273/5252",
                        "text": "Conor Gilsenan"
                    },
                    {
                        "@pid": "341/5644",
                        "text": "Fuzail Shakir"
                    },
                    {
                        "@pid": "151/6443",
                        "text": "Noura Alomar"
                    },
                    {
                        "@pid": "07/1108",
                        "text": "Serge Egelman"
                    }
                ]
            },
            "title": "Security and Privacy Failures in Popular 2FA Apps.",
            "venue": "USENIX Security Symposium",
            "pages": "2079-2096",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GilsenanSAE23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/gilsenan",
            "url": "https://dblp.org/rec/conf/uss/GilsenanSAE23",
            "abstract": "The Time-based One-Time Password (TOTP) algorithm is a 2FA method that is widely deployed because of its relatively low implementation costs and purported security benefits over SMS 2FA. However, users of TOTP 2FA apps face a critical usability challenge: maintain access to the secrets stored within the TOTP app, or risk getting locked out of their accounts. To help users avoid this fate, popular TOTP apps implement a wide range of backup mechanisms, each with varying security and privacy implications. In this paper, we define an assessment methodology for conducting systematic security and privacy analyses of the backup and recovery functionality of TOTP apps. We identified all general purpose Android TOTP apps in the Google Play Store with at least 100k installs that implemented a backup mechanism ( n = 22). Our findings show that most backup strategies end up placing trust in the same technologies that TOTP 2FA is meant to supersede: passwords, SMS, and email. Many backup implementations shared personal user information with third parties, had serious cryptographic flaws, and/or allowed the app developers to access the TOTP secrets in plaintext. We present our findings and recommend ways to improve the security and privacy of TOTP 2FA app backup mechanisms.",
            "keywords": [
                "Two-Factor Authentication",
                "TOTP Apps",
                "Backup Mechanisms",
                "Security Flaws",
                "Privacy Implications"
            ]
        },
        "url": "URL#915284",
        "sema_paperId": "3bb6d0136dd80e50c81969e027e051a7242d8e64"
    },
    {
        "@score": "1",
        "@id": "915285",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "297/6701",
                        "text": "Sindhu Reddy Kalathur Gopal"
                    },
                    {
                        "@pid": "149/2214",
                        "text": "Diksha Shukla"
                    },
                    {
                        "@pid": "353/7538",
                        "text": "James David Wheelock"
                    },
                    {
                        "@pid": "25/1169",
                        "text": "Nitesh Saxena"
                    }
                ]
            },
            "title": "Hidden Reality: Caution, Your Hand Gesture Inputs in the Immersive Virtual World are Visible to All!",
            "venue": "USENIX Security Symposium",
            "pages": "859-876",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GopalSWS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/gopal",
            "url": "https://dblp.org/rec/conf/uss/GopalSWS23",
            "abstract": "Text entry is an inevitable task while using Virtual Reality (VR) devices in a wide range of applications such as remote learning, gaming, and virtual meeting. VR users enter pass-words/pins to log in to their user accounts in various applications and type regular text to compose emails or browse the internet. The typing activity on VR devices is believed to be resistant to direct observation attacks as the virtual screen in an immersive environment is not directly visible to others present in physical proximity. This paper presents a video-based side-channel attack, Hidden Reality (HR) , that shows \u2013 although the virtual screen in VR devices is not in direct sight of adversaries, the indirect observations might get exploited to steal the user\u2019s private information. The Hidden Reality (HR) attack utilizes video clips of the user\u2019s hand gestures while they type on the virtual screen to decipher the typed text in various key entry scenarios on VR devices including typed pins and passwords. Experimental analysis performed on a large corpus of 368 video clips show that the Hidden Reality model can successfully decipher an average of over 75% of the text inputs. The high success rate of our attack model led us to conduct a user study to understand the user\u2019s behavior and perception of security in virtual reality. The analysis showed that over 95% of users were not aware of any security threats on VR devices and believed the immersive environments to be secure from digital attacks. Our attack model challenges users\u2019 false sense of security in immersive environments and emphasizes the need for more stringent security",
            "keywords": [
                "Virtual Reality Security",
                "Side-Channel Attack",
                "Hand Gesture Recognition",
                "User Awareness",
                "Information Leakage"
            ]
        },
        "url": "URL#915285",
        "sema_paperId": "fab080748625c5c245755674136663c765ebf339"
    },
    {
        "@score": "1",
        "@id": "915286",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "332/2961",
                        "text": "Floris Gorter"
                    },
                    {
                        "@pid": "247/4778",
                        "text": "Enrico Barberis"
                    },
                    {
                        "@pid": "232/2018",
                        "text": "Raphael Isemann"
                    },
                    {
                        "@pid": "142/7142",
                        "text": "Erik van der Kouwe"
                    },
                    {
                        "@pid": "75/8194",
                        "text": "Cristiano Giuffrida"
                    },
                    {
                        "@pid": "91/800",
                        "text": "Herbert Bos"
                    }
                ]
            },
            "title": "FloatZone: Accelerating Memory Error Detection using the Floating Point Unit.",
            "venue": "USENIX Security Symposium",
            "pages": "805-822",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GorterBIKGB23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/gorter",
            "url": "https://dblp.org/rec/conf/uss/GorterBIKGB23",
            "abstract": "Memory sanitizers are powerful tools to detect spatial and temporal memory errors, such as buffer overflows and use-after-frees. Fuzzers and software testers often rely on these tools to discover the presence of bugs. Sanitizers, however, incur significant runtime overhead. For example, Address-Sanitizer (ASan), the most widely used sanitizer, incurs a slowdown of 2x. The main source of this overhead consists of the sanitizer checks , which involve at least a memory lookup, a comparison, and a conditional branch instruction. Applying these checks to confirm the validity of the memory accesses in a program can greatly slow down the execution. We introduce FloatZone, a compiler-based sanitizer to detect spatial and temporal memory errors in C/C++ programs using lightweight checks that leverage the Floating Point Unit (FPU). We show that the combined effects of \u201clookup, compare, and branch\u201d can be achieved with a single floating point addition that triggers an underflow exception in the case of a memory violation. This novel method to detect illegal accesses greatly improves performance by avoiding the drawbacks of traditional comparisons: it prevents branch mispredictions, enables higher instruction-level parallelism due to offloading to the FPU, and also reduces the cache miss rate due to the lack of shadow memory. Our evaluation shows that FloatZone significantly outperforms existing systems, with just 37% runtime overhead on SPEC CPU2006 and CPU2017. Moreover, we measure an average 2.87x increase in fuzzing throughput compared to the state of the art. Finally, we confirm that FloatZone offers detection capabilities comparable with ASan on",
            "keywords": [
                "Memory Error Detection",
                "Floating Point Unit",
                "Runtime Overhead",
                "Spatial and Temporal Errors",
                "Compiler-based Sanitizer"
            ]
        },
        "url": "URL#915286",
        "sema_paperId": "eaaaf4397d6cd0cb0ba29534ae50406ede784bb4"
    },
    {
        "@score": "1",
        "@id": "915287",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "280/7837",
                        "text": "Philipp G\u00f6rz"
                    },
                    {
                        "@pid": "202/8379",
                        "text": "Bj\u00f6rn Mathis"
                    },
                    {
                        "@pid": "335/2439",
                        "text": "Keno Hassler"
                    },
                    {
                        "@pid": "248/1578",
                        "text": "Emre G\u00fcler"
                    },
                    {
                        "@pid": "h/ThorstenHolz",
                        "text": "Thorsten Holz"
                    },
                    {
                        "@pid": "z/AndreasZeller",
                        "text": "Andreas Zeller"
                    },
                    {
                        "@pid": "93/11109",
                        "text": "Rahul Gopinath"
                    }
                ]
            },
            "title": "Systematic Assessment of Fuzzers using Mutation Analysis.",
            "venue": "USENIX Security Symposium",
            "pages": "4535-4552",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GorzMHGHZG23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/gorz",
            "url": "https://dblp.org/rec/conf/uss/GorzMHGHZG23",
            "abstract": "Fuzzing is an important method to discover vulnerabilities in programs. Despite considerable progress in this area in the past years, measuring and comparing the effectiveness of fuzzers is still an open research question. In software testing, the gold standard for evaluating test quality is mutation analysis, which evaluates a test's ability to detect synthetic bugs: If a set of tests fails to detect such mutations, it is expected to also fail to detect real bugs. Mutation analysis subsumes various coverage measures and provides a large and diverse set of faults that can be arbitrarily hard to trigger and detect, thus preventing the problems of saturation and overfitting. Unfortunately, the cost of traditional mutation analysis is exorbitant for fuzzing, as mutations need independent evaluation. In this paper, we apply modern mutation analysis techniques that pool multiple mutations and allow us -- for the first time -- to evaluate and compare fuzzers with mutation analysis. We introduce an evaluation bench for fuzzers and apply it to a number of popular fuzzers and subjects. In a comprehensive evaluation, we show how we can use it to assess fuzzer performance and measure the impact of improved techniques. The required CPU time remains manageable: 4.09 CPU years are needed to analyze a fuzzer on seven subjects and a total of 141,278 mutations. We find that today's fuzzers can detect only a small percentage of mutations, which should be seen as a challenge for future research -- notably in improving (1) detecting failures beyond generic crashes (2) triggering mutations (and thus faults).",
            "keywords": [
                "Fuzzing",
                "Mutation Analysis",
                "Vulnerability Detection",
                "Fuzzer Evaluation",
                "Test Effectiveness"
            ]
        },
        "url": "URL#915287",
        "sema_paperId": "85fc1efb83a2d92fb50c0c4b022e53d67fd2a984"
    },
    {
        "@score": "1",
        "@id": "915288",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "201/9325",
                        "text": "Fabio Gritti"
                    },
                    {
                        "@pid": "218/0179",
                        "text": "Nicola Ruaro"
                    },
                    {
                        "@pid": "10/6810",
                        "text": "Robert McLaughlin"
                    },
                    {
                        "@pid": "160/3848",
                        "text": "Priyanka Bose"
                    },
                    {
                        "@pid": "90/3182-2",
                        "text": "Dipanjan Das 0002"
                    },
                    {
                        "@pid": "180/7263",
                        "text": "Ilya Grishchenko"
                    },
                    {
                        "@pid": "k/ChristopherKruegel",
                        "text": "Christopher Kruegel"
                    },
                    {
                        "@pid": "v/GiovanniVigna",
                        "text": "Giovanni Vigna"
                    }
                ]
            },
            "title": "Confusum Contractum: Confused Deputy Vulnerabilities in Ethereum Smart Contracts.",
            "venue": "USENIX Security Symposium",
            "pages": "1793-1810",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GrittiRMB0GKV23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/gritti",
            "url": "https://dblp.org/rec/conf/uss/GrittiRMB0GKV23",
            "abstract": "Smart contracts are immutable programs executed in the context of a globally distributed system known as a blockchain . They enable the decentralized implementation of many interesting applications, such as financial protocols, voting systems, and supply-chain management. In many cases, multiple smart contracts need to work together and communicate with one another to implement complex business logic. However, these smart contracts must take special care to guard against malicious interactions that might lead to the violation of a contract\u2019s security properties and possibly result in substantial financial losses. In this paper, we introduce a class of inter-program communication flaws that we call confused contract vulnerabilities . This type of bug is an instance of the confused deputy vulnerability, set in the new context of smart contract inter-communication. When exploiting a confused contract bug, an attacker is able to divert a remote (inter-contract) call in a confused (victim) contract to a target contract and function of the attacker\u2019s choosing. The call performs sensitive operations on behalf of the confused contract, which can result in financial loss or malicious modifications of the persistent storage of the involved contracts. To identify opportunities for confused contract attacks at scale, we implemented J ACKAL , a system that is able to automatically identify and exploit confused contracts and candidate target contracts on the Ethereum mainnet. We lever-aged J ACKAL to analyze a total of 2,335,193 smart contracts deployed in the past two years, and we identified 529 potential confused contracts for which we were able to generate 31 working exploits. When investigating the impact of our exploits, we discovered past and present opportunities for confused contract attacks that could have compromised digital assets worth more than one million US dollars.",
            "keywords": [
                "Ethereum Smart Contracts",
                "Inter-Contract Communication",
                "Confused Contract Vulnerabilities",
                "Attacker Exploits",
                "Financial Loss Risks"
            ]
        },
        "url": "URL#915288",
        "sema_paperId": "9edadbe1d33a697d2c88dd33b5218b15d2f8d189"
    },
    {
        "@score": "1",
        "@id": "915289",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "181/8259",
                        "text": "Lea Gr\u00f6ber"
                    },
                    {
                        "@pid": "353/7605",
                        "text": "Rafael Mrowczynski"
                    },
                    {
                        "@pid": "353/7609",
                        "text": "Nimisha Vijay"
                    },
                    {
                        "@pid": "353/7529",
                        "text": "Daphne A. Muller"
                    },
                    {
                        "@pid": "138/2614",
                        "text": "Adrian Dabrowski"
                    },
                    {
                        "@pid": "128/4803",
                        "text": "Katharina Krombholz"
                    }
                ]
            },
            "title": "To Cloud or not to Cloud: A Qualitative Study on Self-Hosters&apos; Motivation, Operation, and Security Mindset.",
            "venue": "USENIX Security Symposium",
            "pages": "2491-2508",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GroberMVMDK23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/grober",
            "url": "https://dblp.org/rec/conf/uss/GroberMVMDK23",
            "abstract": "Despite readily available cloud services, some people decide to self-host internal or external services for themselves or their organization. In doing so, a broad spectrum of commercial, institutional, and private self-hosters take responsibility for their data, security, and reliability of their operations. Currently, little is known about what motivates these self-hosters, how they operate and secure their services, and which challenges they face. To improve the understanding of self-hosters\u2019 security mindsets and practices, we conducted a large-scale survey ( N S =994) with users of a popular self-hosting suite and in-depth follow-up interviews with selected commercial, non-profit, and private users ( N I =41). We found exemplary behavior in all user groups; however, we also found a significant part of self-hosters who approach security in an unstructured way, regardless of social or organizational embeddedness. Vague catch-all concepts such as firewalls and backups dominate the landscape, without proper reflection on the threats they help mitigate. At times, self-hosters engage in creative tactics to compensate for a potential lack of expertise or experience.",
            "keywords": [
                "Self-Hosting",
                "Data Responsibility",
                "Security Mindset",
                "User Motivation",
                "Operational Challenges"
            ]
        },
        "url": "URL#915289",
        "sema_paperId": "cfe9e1b499067534875116a23373e21b66247e19"
    },
    {
        "@score": "1",
        "@id": "915290",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "251/1565",
                        "text": "Zichen Gui"
                    },
                    {
                        "@pid": "39/780",
                        "text": "Kenneth G. Paterson"
                    },
                    {
                        "@pid": "240/8179",
                        "text": "Tianxin Tang"
                    }
                ]
            },
            "title": "Security Analysis of MongoDB Queryable Encryption.",
            "venue": "USENIX Security Symposium",
            "pages": "7445-7462",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GuiPT23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/gui",
            "url": "https://dblp.org/rec/conf/uss/GuiPT23",
            "abstract": "In June 2022, MongoDB released Queryable Encryption (QE), an extension of their flagship database product, enabling keyword searches to be performed over encrypted data. This is the first integration of such searchable encryption technology into a widely-used database system. We provide an independent security analysis of QE. We show that certain logs, fundamental to the operation of QE and accessible to a real-world snapshot adversary, contain statistical information about the queries and data. This information can be extracted and exploited by our new inference attacks to recover both the queries and data, assuming adversarial access to an auxiliary dataset with a similar distribution to the original data. Our analysis highlights the challenges of integrating searchable encryption technology into modern, complex database systems. In particular, our attacks stem from the interplay between QE and MongoDB\u2019s existing logging system. They show how such interactions can compromise query and data privacy.",
            "keywords": [
                "Queryable Encryption",
                "MongoDB",
                "Searchable Encryption",
                "Inference Attacks",
                "Data Privacy"
            ]
        },
        "url": "URL#915290",
        "sema_paperId": "49511d1eee878f6deee7b81fcf9ae996852903ef"
    },
    {
        "@score": "1",
        "@id": "915291",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "234/0112",
                        "text": "Run Guo"
                    },
                    {
                        "@pid": "20/1036-5",
                        "text": "Jianjun Chen 0005"
                    },
                    {
                        "@pid": "161/4762",
                        "text": "Yihang Wang"
                    },
                    {
                        "@pid": "353/7649",
                        "text": "Keran Mu"
                    },
                    {
                        "@pid": "89/10754",
                        "text": "Baojun Liu"
                    },
                    {
                        "@pid": "40/1491-108",
                        "text": "Xiang Li 0108"
                    },
                    {
                        "@pid": "94/3019-8",
                        "text": "Chao Zhang 0008"
                    },
                    {
                        "@pid": "36/5143",
                        "text": "Haixin Duan"
                    },
                    {
                        "@pid": "82/4905",
                        "text": "Jianping Wu"
                    }
                ]
            },
            "title": "Temporal CDN-Convex Lens: A CDN-Assisted Practical Pulsing DDoS Attack.",
            "venue": "USENIX Security Symposium",
            "pages": "6185-6202",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Guo0WMLL0DW23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/guo-run",
            "url": "https://dblp.org/rec/conf/uss/Guo0WMLL0DW23",
            "abstract": "As one cornerstone of Internet infrastructure, Content Delivery Networks (CDNs) work as a globally distributed proxy platform between clients and websites, providing the functionalities of speeding up content delivery, offloading web traffic, and DDoS protection. In this paper, however, we reveal that inherent nature of CDN forwarding network can be exploited to compromise service availability.\nWe present a new class of pulsing denial of service attacks, named CDN-Convex attack. We explore the possibility of exploiting the CDN infrastructure as a converging lens, and concentrating low-rate attacking requests into short, high-bandwidth pulse waves, resulting in a pulsing DoS attack to saturate the targeted TCP services periodically. Through real-world experiments on five leading CDN vendors, we demonstrate that CDN-Convex is practical and flexible. We show that attackers can use it to achieve peak bandwidths over 1000 times  greater than their upload bandwidth, seriously degrading the performance and availability of target services. Following the responsible disclosure policy, we have reported our attack details to all affected CDN vendors and proposed possible mitigation solutions.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-guo-run.pdf",
            "keywords": [
                "Content Delivery Networks",
                "Denial of Service Attacks",
                "CDN-Convex Attack",
                "Pulsing DoS",
                "Service Availability"
            ]
        },
        "url": "URL#915291",
        "sema_paperId": "641cd0f703ff1990d7f15ba9d8992a989fb11fc7"
    },
    {
        "@score": "1",
        "@id": "915292",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "128/2249",
                        "text": "Wentao Guo"
                    },
                    {
                        "@pid": "119/7709",
                        "text": "Jason Walter"
                    },
                    {
                        "@pid": "20/7983",
                        "text": "Michelle L. Mazurek"
                    }
                ]
            },
            "title": "The Role of Professional Product Reviewers in Evaluating Security and Privacy.",
            "venue": "USENIX Security Symposium",
            "pages": "2563-2580",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GuoWM23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/guo-wentao",
            "url": "https://dblp.org/rec/conf/uss/GuoWM23",
            "abstract": "Consumers who use Internet-connected products are often exposed to security and privacy vulnerabilities that they lack time or expertise to evaluate themselves. Can professional product reviewers help by evaluating security and privacy on their behalf? We conducted 17 interviews with product reviewers about their procedures, incentives, and assumptions regarding security and privacy. We find that reviewers have some incentives to evaluate security and privacy, but they also face substantial disincentives and challenges, leading them to consider a limited set of relevant criteria and threat models. We recommend future work to help product reviewers provide useful advice to consumers in ways that align with reviewers\u2019 business models and incentives. These include developing usable resources and tools, as well as validating the heuristics they use to judge security and privacy expediently.",
            "keywords": [
                "Product Reviewers",
                "Security Evaluation",
                "Privacy Assessment",
                "Consumer Protection",
                "Threat Models"
            ]
        },
        "url": "URL#915292",
        "sema_paperId": "f175bdf9b8b15aa0a83a46c43b23dbe6872097ea"
    },
    {
        "@score": "1",
        "@id": "915293",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "175/6283",
                        "text": "Thomas Haines"
                    },
                    {
                        "@pid": "g/RajeevGore",
                        "text": "Rajeev Gor\u00e9"
                    },
                    {
                        "@pid": "02/8036",
                        "text": "Mukesh Tiwari"
                    }
                ]
            },
            "title": "Machine-checking Multi-Round Proofs of Shuffle: Terelius-Wikstrom and Bayer-Groth.",
            "venue": "USENIX Security Symposium",
            "pages": "6471-6488",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HainesGT23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/haines",
            "url": "https://dblp.org/rec/conf/uss/HainesGT23",
            "abstract": "Shuf\ufb02es are used in electronic voting in much the same way physical ballot boxes are used in paper systems: (encrypted) ballots are input into the shuf\ufb02e and (encrypted) ballots are output in a random order, thereby breaking the link between voter identities and ballots. To guarantee that no ballots are added, omitted or altered, zero-knowledge proofs, called proofs of shuf\ufb02e, are used to provide publicly veri\ufb01able transcripts that prove that the outputs are a re-encrypted per-mutation of the inputs. The most prominent proofs of shuf\ufb02e, in practice, are those due to Terelius and Wikstr\u00f6m (TW), and Bayer and Groth (BG). TW is simpler whereas BG is more ef\ufb01cient, both in terms of bandwidth and computation. Security for the simpler (TW) proof of shuf\ufb02e has already been machine-checked but several prominent vendors insist on using the more complicated BG proof of shuf\ufb02e. Here, we machine-check the security of the Bayer-Groth proof of shuf\ufb02e via the Coq proof-assistant. We then extract the veri-\ufb01er (software) required to check the transcripts produced by Bayer-Groth implementations and use it to check transcripts from the Swiss Post evoting system under development for national elections in Switzerland.",
            "keywords": [
                "Electronic Voting",
                "Proofs of Shuffle",
                "Zero-Knowledge Proofs",
                "Bayer-Groth Proof",
                "Transcript Verification"
            ]
        },
        "url": "URL#915293",
        "sema_paperId": "e4a90b2eaae331d741bb99e8e409cc0c9c38ede0"
    },
    {
        "@score": "1",
        "@id": "915294",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "267/5358",
                        "text": "Zhaokun Han"
                    },
                    {
                        "@pid": "116/4653",
                        "text": "Mohammed Shayan"
                    },
                    {
                        "@pid": "349/0269",
                        "text": "Aneesh Dixit"
                    },
                    {
                        "@pid": "226/6130",
                        "text": "Mustafa M. Shihab"
                    },
                    {
                        "@pid": "17/5884",
                        "text": "Yiorgos Makris"
                    },
                    {
                        "@pid": "79/9006",
                        "text": "Jeyavijayan Rajendran"
                    }
                ]
            },
            "title": "FuncTeller: How Well Does eFPGA Hide Functionality?",
            "venue": "USENIX Security Symposium",
            "pages": "5809-5826",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HanSDSMR23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/han-zhaokun",
            "url": "https://dblp.org/rec/conf/uss/HanSDSMR23",
            "abstract": "Hardware intellectual property (IP) piracy is an emerging threat to the global supply chain. Correspondingly, various countermeasures aim to protect hardware IPs, such as logic locking, camouflaging, and split manufacturing. However, these countermeasures cannot always guarantee IP security. A malicious attacker can access the layout/netlist of the hardware IP protected by these countermeasures and further retrieve the design. To eliminate/bypass these vulnerabilities, a recent approach redacts the design's IP to an embedded field-programmable gate array (eFPGA), disabling the attacker's access to the layout/netlist. eFPGAs can be programmed with arbitrary functionality. Without the bitstream, the attacker cannot recover the functionality of the protected IP. Consequently, state-of-the-art attacks are inapplicable to pirate the redacted hardware IP. In this paper, we challenge the assumed security of eFPGA-based redaction. We present an attack to retrieve the hardware IP with only black-box access to a programmed eFPGA. We observe the effect of modern electronic design automation (EDA) tools on practical hardware circuits and leverage the observation to guide our attack. Thus, our proposed method FuncTeller selects minterms to query, recovering the circuit function within a reasonable time. We demonstrate the effectiveness and efficiency of FuncTeller on multiple circuits, including academic benchmark circuits, Stanford MIPS processor, IBEX processor, Common Evaluation Platform GPS, and Cybersecurity Awareness Worldwide competition circuits. Our results show that FuncTeller achieves an average accuracy greater than 85% over these tested circuits retrieving the design's functionality.",
            "keywords": [
                "eFPGA",
                "Hardware IP Piracy",
                "Design Redaction",
                "FuncTeller",
                "Circuit Function Recovery"
            ]
        },
        "url": "URL#915294",
        "sema_paperId": "e798f32374c02f9485d8caa2b947c1ad988332da"
    },
    {
        "@score": "1",
        "@id": "915295",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "05/2143",
                        "text": "Xing Han"
                    },
                    {
                        "@pid": "70/6340",
                        "text": "Yuheng Zhang"
                    },
                    {
                        "@pid": "29/2362",
                        "text": "Xue Zhang"
                    },
                    {
                        "@pid": "191/1578",
                        "text": "Zeyuan Chen"
                    },
                    {
                        "@pid": "64/9796",
                        "text": "Mingzhe Wang"
                    },
                    {
                        "@pid": "86/1695",
                        "text": "Yiwei Zhang"
                    },
                    {
                        "@pid": "130/5642",
                        "text": "Siqi Ma"
                    },
                    {
                        "@pid": "33/0-1",
                        "text": "Yu Yu 0001"
                    },
                    {
                        "@pid": "b/ElisaBertino",
                        "text": "Elisa Bertino"
                    },
                    {
                        "@pid": "41/3261",
                        "text": "Juanru Li"
                    }
                ]
            },
            "title": "Medusa Attack: Exploring Security Hazards of In-App QR Code Scanning.",
            "venue": "USENIX Security Symposium",
            "pages": "4607-4624",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HanZZCWZMYBL23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/han-xing",
            "url": "https://dblp.org/rec/conf/uss/HanZZCWZMYBL23",
            "abstract": "Smartphone users are eliminating traditional QR codes as many apps have integrated QR code scanning as a built-in functionality. With the support of embedded QR code scanning components, apps can read QR codes and immediately execute relevant activities, such as boarding a flight. Handling QR codes in such an automated manner is obviously user-friendly. However, this automation also creates an opportunity for attackers to exploit apps through malicious QR codes if the apps fail to properly check these codes.In this paper, we systematize and contextualize attacks on mobile apps that use built-in QR code readers. We label these as MEDUSA attacks, which allow attackers to remotely exploit the in-app QR code scanning of a mobile app. Through a MEDUSA attack, remote attackers can invoke a specific type of app functions \u2013 Remotely Accessible Handlers (RAHs), and perform tasks such as sending authentication tokens or making a payment. We conducted an empirical study on 800 very popular Android and iOS apps with billions of users in the two largest mobile ecosystems, the US and mainland China mobile markets, to investigate the prevalence and severity of MEDUSA attack related security vulnerabilities. Based on our proposed vulnerability detection technique, we thoroughly examined the target apps and discovered that a wide range of them are affected. Among the 377/800 apps with in-app QR code scanning functionality, we found 123 apps containing 2,872 custom RAHs that were vulnerable to the MEDUSA attack. By constructing proof-of-concept exploits to test the severity, we confirmed 46 apps with critical or high-severity vulnerabilities, which allows attackers to access sensitive local resources or remotely modify the user data.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-han-xing.pdf",
            "keywords": [
                "Mobile App Security",
                "QR Code Scanning",
                "MEDUSA Attacks",
                "Remotely Accessible Handlers (RAHs)",
                "Vulnerability Detection"
            ]
        },
        "url": "URL#915295",
        "sema_paperId": "21ce0d57526a3830508b3911d31195436fa057b2"
    },
    {
        "@score": "1",
        "@id": "915296",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "65/425",
                        "text": "Yi He"
                    },
                    {
                        "@pid": "353/7583",
                        "text": "Roland Guo"
                    },
                    {
                        "@pid": "300/5803",
                        "text": "Yunlong Xing"
                    },
                    {
                        "@pid": "353/7618",
                        "text": "Xijia Che"
                    },
                    {
                        "@pid": "30/3530-1",
                        "text": "Kun Sun 0001"
                    },
                    {
                        "@pid": "69/11514",
                        "text": "Zhuotao Liu"
                    },
                    {
                        "@pid": "181/2626-2",
                        "text": "Ke Xu 0002"
                    },
                    {
                        "@pid": "181/2688-2",
                        "text": "Qi Li 0002"
                    }
                ]
            },
            "title": "Cross Container Attacks: The Bewildered eBPF on Clouds.",
            "venue": "USENIX Security Symposium",
            "pages": "5971-5988",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HeGXC0L0023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/he",
            "url": "https://dblp.org/rec/conf/uss/HeGXC0L0023",
            "abstract": "The extended Berkeley Packet Filter (eBPF) provides powerful and flexible kernel interfaces to extend the kernel functions for user space programs via running bytecode directly in the kernel space. It has been widely used by cloud services to enhance container security, network management, and system observability. However, we discover that the offensive eBPF that have been extensively discussed in Linux hosts can bring new attack surfaces to containers. With eBPF tracing features, attackers can break the container's isolation and attack the host, e.g., steal sensitive data, DoS, and even escape the container. In this paper, we study the eBPF-based cross container attacks and reveal their security impacts in real world services. With eBPF attacks, we successfully compromise five online Jupyter/Interactive Shell services and the Cloud Shell of Google Cloud Platform. Furthermore, we find that the Kubernetes services offered by three leading cloud vendors can be exploited to launch cross-node attacks after the attackers escape the container via eBPF. Specifically, in Alibaba's Kubernetes services, attackers can compromise the whole cluster by abusing their over-privileged cloud metrics or management Pods. Unfortunately, the eBPF attacks on containers are seldom known and can hardly be discovered by existing intrusion detection systems.\u00a0Also, the existing eBPF permission model cannot confine the eBPF and ensure secure usage in shared-kernel container environments. To this end, we propose a new eBPF permission model to counter the eBPF attacks in containers.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-he.pdf",
            "keywords": [
                "eBPF",
                "Container Security",
                "Cross Container Attacks",
                "Kubernetes Exploits",
                "Permission Model"
            ]
        },
        "url": "URL#915296",
        "sema_paperId": "9624ea16d06a82717b83ef304be6f0782834ad2b"
    },
    {
        "@score": "1",
        "@id": "915297",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "331/2250",
                        "text": "Sven Hebrok"
                    },
                    {
                        "@pid": "270/6915",
                        "text": "Simon Nachtigall"
                    },
                    {
                        "@pid": "331/2735",
                        "text": "Marcel Maehren"
                    },
                    {
                        "@pid": "224/9173",
                        "text": "Nurullah Erinola"
                    },
                    {
                        "@pid": "248/1716",
                        "text": "Robert Merget"
                    },
                    {
                        "@pid": "27/8331",
                        "text": "Juraj Somorovsky"
                    },
                    {
                        "@pid": "58/5730",
                        "text": "J\u00f6rg Schwenk"
                    }
                ]
            },
            "title": "We Really Need to Talk About Session Tickets: A Large-Scale Analysis of Cryptographic Dangers with TLS Session Tickets.",
            "venue": "USENIX Security Symposium",
            "pages": "4877-4894",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HebrokNMEMSS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/hebrok",
            "url": "https://dblp.org/rec/conf/uss/HebrokNMEMSS23",
            "abstract": "Session tickets improve the performance of the TLS protocol. They allow abbreviating the handshake by using secrets from a previous session. To this end, the server encrypts the secrets using a Session Ticket Encryption Key (STEK) only know to the server, which the client stores as a ticket and sends back upon resumption. The standard leaves details such as data formats, encryption algorithms, and key management to the server implementation. TLS session tickets have been criticized by security experts, for undermining the security guarantees of TLS. An adversary, who can guess or compromise the STEK, can passively record and decrypt TLS sessions and may impersonate the server. Thus, weak implementations of this mechanism may completely undermine TLS security guarantees. We performed the first systematic large-scale analysis of the cryptographic pitfalls of session ticket implementations. (1) We determined the data formats and cryptographic algorithms used by 12 open-source implementations and designed online and offline tests to identify vulnerable implementations. (2) We performed several large-scale scans and collected session tickets for extended offline analyses. We found significant differences in session ticket implementations and critical security issues in the analyzed servers. Vulnerable servers used weak keys or repeating keystreams in the used tickets, allowing for session ticket decryption. Among others, our analysis revealed a widespread implementation flaw within the Amazon AWS ecosystem that allowed for passive traffic decryption for at least 1.9% of the Tranco Top 100k servers.",
            "keywords": [
                "TLS Session Tickets",
                "Cryptographic Analysis",
                "Session Ticket Encryption Key (STEK)",
                "Implementation Vulnerabilities",
                "Traffic Decryption"
            ]
        },
        "url": "URL#915297",
        "sema_paperId": "88513c6d55e3383cbafbce6aa585b945e465520a"
    },
    {
        "@score": "1",
        "@id": "915298",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "279/5630",
                        "text": "Elias Heftrig"
                    },
                    {
                        "@pid": "94/7397",
                        "text": "Haya Schulmann"
                    },
                    {
                        "@pid": "90/308",
                        "text": "Michael Waidner"
                    }
                ]
            },
            "title": "Downgrading DNSSEC: How to Exploit Crypto Agility for Hijacking Signed Zones.",
            "venue": "USENIX Security Symposium",
            "pages": "7429-7444",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HeftrigSW23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/heftrig",
            "url": "https://dblp.org/rec/conf/uss/HeftrigSW23",
            "abstract": "Cryptographic algorithm agility is an important property for DNSSEC: it allows easy deployment of new algorithms if the existing ones are no longer secure. Significant operational and research efforts are dedicated to pushing the deployment of new algorithms in DNSSEC forward. Recent research shows that DNSSEC is gradually achieving algorithm agility: most DNSSEC supporting resolvers can validate a number of different algorithms and domains are increasingly signed with cryptographically strong ciphers. In this work we show for the first time that the cryptographic agility in DNSSEC, although critical for making DNS secure with strong cryptography, also introduces a severe vulnerability. We find that under certain conditions, when new, unsupported algorithms are listed in signed DNS responses, the resolvers do not validate DNSSEC. As a result, domains that deploy new ciphers, risk exposing the validating resolvers to cache poisoning attacks. We use this to develop DNSSEC-downgrade attacks and experimentally and ethically evaluate our attacks against popular DNS resolver implementations, public DNS providers, and DNS resolvers used by web clients. We validate the success of DNSSEC-downgrade attacks by poisoning the resolvers: we inject fake records, in signed domains, into the caches of validating resolvers. Our evaluations showed that during 2021 major DNS providers, such as Google Public DNS and Cloudflare, as well as 35% of DNS resolvers used by the web clients were vulnerable to our attacks. After coordinated disclosure with the affected operators, that number reduced to 5 . 03% in 2022. We trace the factors that led to this situation and provide recommendations.",
            "keywords": [
                "DNSSEC",
                "Cryptographic Agility",
                "Cache Poisoning",
                "DNS Downgrade Attacks",
                "Signed Zones Vulnerability"
            ]
        },
        "url": "URL#915298",
        "sema_paperId": "f6aff2d86ba5862839ab5ed6872f57d9e1c5c019"
    },
    {
        "@score": "1",
        "@id": "915299",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "215/4426",
                        "text": "Alexandra Henzinger"
                    },
                    {
                        "@pid": "279/6103",
                        "text": "Matthew M. Hong"
                    },
                    {
                        "@pid": "87/8037",
                        "text": "Henry Corrigan-Gibbs"
                    },
                    {
                        "@pid": "94/8813",
                        "text": "Sarah Meiklejohn"
                    },
                    {
                        "@pid": "v/VinodVaikuntanathan",
                        "text": "Vinod Vaikuntanathan"
                    }
                ]
            },
            "title": "One Server for the Price of Two: Simple and Fast Single-Server Private Information Retrieval.",
            "venue": "USENIX Security Symposium",
            "pages": "3889-3905",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HenzingerHCMV23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/henzinger",
            "url": "https://dblp.org/rec/conf/uss/HenzingerHCMV23",
            "abstract": "We present SimplePIR, the fastest single-server private information retrieval scheme known to date. SimplePIR\u2019s security holds under the learning-with-errors assumption. To answer a client\u2019s query, the SimplePIR server performs fewer than one 32-bit multiplication and one 32-bit addition per database byte. SimplePIR achieves 10 GB/s/core server throughput, which approaches the memory bandwidth of the machine and the performance of the fastest two-server private-information-retrieval schemes (which require non-colluding servers). SimplePIR has relatively large communication costs: to make queries to a 1 GB database, the client must download a 121 MB \"hint\" about the database contents; thereafter, the client may make an unbounded number of queries, each requiring 242 KB of communication. We present a second single-server scheme, DoublePIR, that shrinks the hint to 16 MB at the cost of slightly higher per-query communication (345 KB) and slightly lower throughput (7.4 GB/s/core). Finally, we apply our new private-information-retrieval schemes, together with a novel data structure for approximate set membership, to the task of private auditing in Certificate Transparency. We achieve a strictly stronger notion of privacy than Google Chrome\u2019s current approach with 13x more communication: 16 MB of download per week, along with 1.5 KB per TLS connection.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-henzinger.pdf",
            "keywords": [
                "Private Information Retrieval",
                "Single-Server Scheme",
                "Communication Efficiency",
                "Database Querying",
                "Certificate Transparency Auditing"
            ]
        },
        "url": "URL#915299"
    },
    {
        "@score": "1",
        "@id": "915300",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "146/7916",
                        "text": "Julia Hesse"
                    },
                    {
                        "@pid": "67/3470",
                        "text": "Nitin Singh"
                    },
                    {
                        "@pid": "66/2753",
                        "text": "Alessandro Sorniotti"
                    }
                ]
            },
            "title": "How to Bind Anonymous Credentials to Humans.",
            "venue": "USENIX Security Symposium",
            "pages": "3047-3064",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HesseSS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/hesse",
            "url": "https://dblp.org/rec/conf/uss/HesseSS23",
            "abstract": "Digital and paper-based authentication are the two predominant mechanisms that have been deployed in the real world to authenticate end-users. When verification of a digital credential is performed in person (e.g. the authentication that was often required to access facilities at the peak of the COVID global pandemic), the two mechanisms are often deployed together: the verifier checks government-issued ID to match the picture on the ID to the individual holding it, and then checks the digital credential to see that the personal details on it match those on the ID and to discover additional attributes of the holder. This pattern is extremely common and very likely to remain in place for the foreseeable future. However, it poses an interesting problem: if the digital credential is privacy-preserving (e.g. based on BBS+ on CL signatures), but the holder is still forced to show an ID card or a passport to verify that the presented credential was indeed issued to the holder, what is the point of deploying privacy-preserving digital credential? In this paper we address this problem by redefining what an ID card should show and force a minimal but mandatory involvement of the card in the digital interaction. Our approach permits verifiers to successfully authenticate holders and to determine if they are the rightful owners of the digital credential. At the same time, optimal privacy guarantees are preserved. We design our scheme, formally define and analyse its security in the Universal Composability (UC) framework, and implement the card component, showing the running time to be below 200ms irrespective of the number of certified attributes.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-hesse.pdf",
            "keywords": [
                "Privacy-Preserving Credentials",
                "Digital Authentication",
                "Identity Verification",
                "Universal Composability",
                "Credential Binding"
            ]
        },
        "url": "URL#915300"
    },
    {
        "@score": "1",
        "@id": "915301",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "296/3944",
                        "text": "Jonas Hielscher"
                    },
                    {
                        "@pid": "309/5253",
                        "text": "Uta Menges"
                    },
                    {
                        "@pid": "84/3561",
                        "text": "Simon Parkin"
                    },
                    {
                        "@pid": "27/8720",
                        "text": "Annette Kluge"
                    },
                    {
                        "@pid": "s/MASasse",
                        "text": "M. Angela Sasse"
                    }
                ]
            },
            "title": "&quot;Employees Who Don&apos;t Accept the Time Security Takes Are Not Aware Enough&quot;: The CISO View of Human-Centred Security.",
            "venue": "USENIX Security Symposium",
            "pages": "2311-2328",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HielscherMPKS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/hielscher",
            "url": "https://dblp.org/rec/conf/uss/HielscherMPKS23",
            "abstract": "In larger organisations, the security controls and policies that protect employees are typically managed by a Chief Information Security Officer (CISO). In research, industry, and policy, there are increasing efforts to relate principles of human behaviour interventions and influence to the practice of the CISO, despite these being complex disciplines in their own right. Here we explore how well the concepts of human-centred security (HCS) have survived exposure to the needs of practice: in an action research approach we engaged with n = 30 members of a Swiss-based community of CISOs in five workshop sessions over the course of 8 months, dedicated to discussing HCS. We coded and analysed over 25 hours of notes we took during the discussions. We found that CISOs far and foremost perceive HCS as what is available on the market, namely awareness and phishing simulations. While they regularly shift responsibility either to the management (by demanding more support) or to the employees (by blaming them) we see a lack of power but also silo-thinking that prevents CISOs from considering actual human behaviour and friction that security causes for employees. We conclude that industry best practices and the state-of-the-art in HCS research are not aligned.",
            "keywords": [
                "Human-Centred Security",
                "Chief Information Security Officer",
                "Employee Awareness",
                "Security Responsibility",
                "Silo Thinking"
            ]
        },
        "url": "URL#915301",
        "sema_paperId": "ba34e53a5823173206a94e6ed7c19c65efe34ebb"
    },
    {
        "@score": "1",
        "@id": "915302",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "277/0392",
                        "text": "Alden Hilton"
                    },
                    {
                        "@pid": "69/6101",
                        "text": "Casey T. Deccio"
                    },
                    {
                        "@pid": "204/0452",
                        "text": "Jacob Davis"
                    }
                ]
            },
            "title": "Fourteen Years in the Life: A Root Server&apos;s Perspective on DNS Resolver Security.",
            "venue": "USENIX Security Symposium",
            "pages": "3171-3186",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HiltonDD23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/hilton",
            "url": "https://dblp.org/rec/conf/uss/HiltonDD23",
            "abstract": "We consider how the DNS security and privacy landscape has evolved over time, using data collected annually at A-root between 2008 and 2021. We consider issues such as deployment of security and privacy mechanisms, including source port randomization, TXID randomization, DNSSEC, and QNAME minimization. We find that achieving general adoption of new security practices is a slow, ongoing process. Of particular note, we find a significant number of resolvers lacking nearly all of the security mechanisms we considered, even as late as 2021. Specifically, in 2021, over 4% of the resolvers analyzed were unprotected by either source port randomization, DNSSEC validation, DNS cookies, or 0x20 encoding. Encouragingly, we find that the volume of traffic from resolvers with secure practices is significantly higher than that of other resolvers.",
            "keywords": [
                "DNS Security",
                "Resolver Security",
                "Traffic Analysis",
                "Security Mechanisms",
                "Source Port Randomization"
            ]
        },
        "url": "URL#915302",
        "sema_paperId": "63d29af71d818f37bb7dc0c1e37324be30406919"
    },
    {
        "@score": "1",
        "@id": "915303",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "223/6748",
                        "text": "Tomas Hlavacek"
                    },
                    {
                        "@pid": "94/7397",
                        "text": "Haya Schulmann"
                    },
                    {
                        "@pid": "332/3113",
                        "text": "Niklas Vogel"
                    },
                    {
                        "@pid": "90/308",
                        "text": "Michael Waidner"
                    }
                ]
            },
            "title": "Keep Your Friends Close, but Your Routeservers Closer: Insights into RPKI Validation in the Internet.",
            "venue": "USENIX Security Symposium",
            "pages": "4841-4858",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HlavacekSVW23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/hlavacek",
            "url": "https://dblp.org/rec/conf/uss/HlavacekSVW23",
            "abstract": "IP prefix hijacks allow adversaries to redirect and intercept traffic, posing a threat to the stability and security of the Internet. To prevent prefix hijacks, networks should deploy RPKI and filter bogus BGP announcements with invalid routes. In this work we evaluate the impact of RPKI deployments on the security and resilience of the Internet. We aim to understand which networks filter invalid routes and how effective that filtering is in blocking prefix hijacks. We extend previous data acquisition and analysis methodologies to obtain more accurate identification of networks that filter invalid routes with RPKI. We find that more than 27% of networks enforce RPKI filtering and show for the first time that deployments follow the business incentives of inter-domain routing: providers have an increased motivation to filter in order to avoid losing customers' traffic. Analyzing the effectiveness of RPKI, we find that the current trend to deploy RPKI on routeservers of Internet Exchange Points (IXPs) only provides a localized protection against hijacks but has negligible impact on preventing their spread globally. In contrast, we show that RPKI filtering in Tier-1 providers greatly benefits the security of the Internet as it limits the spread of hijacks to a localized scope. Based on our observations, we provide recommendations on the future roadmap of RPKI deployment. We make our datasets available for public use [https://sit4.me/rpki].",
            "keywords": [
                "RPKI",
                "BGP",
                "Prefix Hijacks",
                "Internet Security",
                "Route Filtering"
            ]
        },
        "url": "URL#915303",
        "sema_paperId": "7f826ff6ab6ee0385494011f8a6118f8417d1fee"
    },
    {
        "@score": "1",
        "@id": "915304",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "246/5631",
                        "text": "Jana Hofmann"
                    },
                    {
                        "@pid": "262/3667",
                        "text": "Emanuele Vannacci"
                    },
                    {
                        "@pid": "f/CedricFournet",
                        "text": "C\u00e9dric Fournet"
                    },
                    {
                        "@pid": "10/3908",
                        "text": "Boris K\u00f6pf"
                    },
                    {
                        "@pid": "166/4142",
                        "text": "Oleksii Oleksenko"
                    }
                ]
            },
            "title": "Speculation at Fault: Modeling and Testing Microarchitectural Leakage of CPU Exceptions.",
            "venue": "USENIX Security Symposium",
            "pages": "7143-7160",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HofmannVFKO23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/hofmann",
            "url": "https://dblp.org/rec/conf/uss/HofmannVFKO23",
            "abstract": "Microarchitectural leakage models provide effective tools to prevent vulnerabilities such as Spectre and Meltdown via secure co-design: For software, they provide a foundation for secure compilation and verification; for hardware, they provide a target specification to test and verify against. Unfortunately, existing leakage models are severely limited: None of them covers CPU exceptions, which are essential to implement security abstractions such as virtualization and memory protection, and which are the source of critical vulnerabilities such as Meltdown, MDS, and Foreshadow. In this paper, we provide the first leakage models for CPU exceptions, together with new tools for testing black-box CPUs against them. We run extensive experiments and successively refine these models, until we precisely capture the leakage for a representative subset of exceptions on four different x86 microarchitectures. In the process, we contradict, refine, and corroborate a large number of findings from prior work, and we uncover three novel transient leaks affecting stores to non-canonical addresses, stores to read-only memory, and divisions by zero.",
            "keywords": [
                "Microarchitectural Leakage",
                "CPU Exceptions",
                "Security Vulnerabilities",
                "Transient Leaks",
                "x86 Microarchitectures"
            ]
        },
        "url": "URL#915304",
        "sema_paperId": "18b46fc9450abee2e39fee48204f00786733a9bb"
    },
    {
        "@score": "1",
        "@id": "915305",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "349/7794",
                        "text": "Sandra H\u00f6ltervennhoff"
                    },
                    {
                        "@pid": "322/5233",
                        "text": "Philip Klostermeyer"
                    },
                    {
                        "@pid": "325/3563",
                        "text": "Noah W\u00f6hler"
                    },
                    {
                        "@pid": "132/9687",
                        "text": "Yasemin Acar"
                    },
                    {
                        "@pid": "38/9378",
                        "text": "Sascha Fahl"
                    }
                ]
            },
            "title": "&quot;I wouldn&apos;t want my unsafe code to run my pacemaker&quot;: An Interview Study on the Use, Comprehension, and Perceived Risks of Unsafe Rust.",
            "venue": "USENIX Security Symposium",
            "pages": "2509-2525",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HoltervennhoffK23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/holtervennhoff",
            "url": "https://dblp.org/rec/conf/uss/HoltervennhoffK23",
            "abstract": "Modern software development still struggles with memory safety issues as a significant source of security bugs. The Rust programming language addresses memory safety and provides further security features. However, Rust offers developers the ability to opt out of some of these guarantees using unsafe Rust. Previous work found that the source of many security vulnerabilities is unsafe Rust. In this paper, we are the first to see behind the curtain and investigate developers\u2019 motivations for, experiences with, and risk assessment of using unsafe Rust in depth. Therefore, we conducted 26 semi-structured interviews with experienced Rust developers. We find that developers aim to use unsafe Rust sparingly and with caution. However, we also identify common misconceptions and tooling fatigue that can lead to security issues, find that security policies for using unsafe Rust are widely missing and that participants underestimate the security risks of using unsafe Rust. We conclude our work by discussing the findings and recommendations for making the future use of unsafe Rust more secure.",
            "keywords": [
                "Rust Programming Language",
                "Memory Safety",
                "Unsafe Rust",
                "Security Vulnerabilities",
                "Developer Risk Assessment"
            ]
        },
        "url": "URL#915305",
        "sema_paperId": "6ee05127f5b976af53bbf74755e56cfba038d3e6"
    },
    {
        "@score": "1",
        "@id": "915306",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "277/8277",
                        "text": "Peiwei Hu"
                    },
                    {
                        "@pid": "232/3062",
                        "text": "Ruigang Liang"
                    },
                    {
                        "@pid": "13/5716-6",
                        "text": "Ying Cao 0006"
                    },
                    {
                        "@pid": "c/KaiChen12",
                        "text": "Kai Chen 0012"
                    },
                    {
                        "@pid": "144/1374",
                        "text": "Runze Zhang"
                    }
                ]
            },
            "title": "AURC: Detecting Errors in Program Code and Documentation.",
            "venue": "USENIX Security Symposium",
            "pages": "1415-1432",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HuLC0Z23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/hu",
            "url": "https://dblp.org/rec/conf/uss/HuLC0Z23",
            "abstract": "Error detection in program code and documentation is a critical problem in computer security. Previous studies have shown promising vulnerability discovery performance by extensive code or document-guided analysis. However, the state-of-the-arts have the following significant limitations: (i) They assume the documents are correct and treat the code that violates documents as bugs, thus cannot find documents\u2019 defects and code\u2019s bugs if APIs have defective documents or no documents. (ii) They utilize majority voting to judge the inconsistent code snippets and treat the deviants as bugs, thus cannot cope with situations where correct usage is minor or all use cases are wrong. In this paper, we present AURC, a static framework for detecting code bugs of incorrect return checks and document defects. We observe that three objects participate in the API invocation, the document, the caller (code that invokes API), and the callee (the source code of API). Mutual corroboration of these three objects eliminates the reliance on the above assumptions. AURC contains a context-sensitive backward analysis to process callees, a pre-trained model-based document classifier, and a container that collects conditions of if statements from callers. After cross-checking the results from callees, callers, and documents, AURC delivers them to the correctness inference module to infer the defective one. We evaluated AURC on ten popular codebases. AURC discovered 529 new bugs that can lead to security issues like heap buffer overflow and sensitive information leakage, and 224 new document defects. Maintainers acknowledge our findings and have accepted 222 code patches and 76 document patches.",
            "keywords": [
                "API Invocation",
                "Error Detection",
                "Code Bugs",
                "Document Defects",
                "Static Analysis Framework"
            ]
        },
        "url": "URL#915306",
        "sema_paperId": "1295384feb9a363986fb3e3efd6e154ac5d73637"
    },
    {
        "@score": "1",
        "@id": "915307",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "353/7644",
                        "text": "Kong Huang"
                    },
                    {
                        "@pid": "196/6977",
                        "text": "Yutong Zhou"
                    },
                    {
                        "@pid": "20/4152",
                        "text": "Ke Zhang"
                    },
                    {
                        "@pid": "224/4836",
                        "text": "Jiacen Xu"
                    },
                    {
                        "@pid": "224/2480",
                        "text": "Jiongyi Chen"
                    },
                    {
                        "@pid": "77/1147-1",
                        "text": "Di Tang 0001"
                    },
                    {
                        "@pid": "66/6560",
                        "text": "Kehuan Zhang"
                    }
                ]
            },
            "title": "HOMESPY: The Invisible Sniffer of Infrared Remote Control of Smart TVs.",
            "venue": "USENIX Security Symposium",
            "pages": "4553-4570",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HuangZZXCTZ23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/huang",
            "url": "https://dblp.org/rec/conf/uss/HuangZZXCTZ23",
            "abstract": "Infrared (IR) remote control is a widely used technology at home due to its simplicity and low cost. Most considered it to be \u201csecure\u201d because of the line-of-sight usage within the home. In this paper, we revisit the security of IR remote control schemes and examine their security assumptions under the settings of internet-connected smart homes. We focus on two specific questions: (1) whether IR signals could be sniffed by an IoT device; and (2) what information could be leaked out through the sniffed IR control signals. To answer these questions, we design a sniff module using a commercial-off-the-shelf IR receiver on a Raspberry Pi and show that the Infrared (IR) signal emanating from the remote control of a Smart TV can be captured by one of the nearby IoT devices, for example, a smart air-conditioner, even the signal is not aimed at the air-conditioner. The IR signal range and receiving angle are larger than most have thought. We also developed algorithms to extract semantic information from the sniffed IR control signals, and evaluated with realworld applications. The results showed that lots of sensitive information could be leaked out through the sniffed IR control signals, including account name and password, PIN code, and even payment information.",
            "keywords": [
                "Infrared Remote Control",
                "Smart Home Security",
                "IoT Device Sniffing",
                "Information Leakage",
                "Sensitive Data Exposure"
            ]
        },
        "url": "URL#915307",
        "sema_paperId": "6612d9350fea99b06b9aa694291aae11eb2c793a"
    },
    {
        "@score": "1",
        "@id": "915308",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "277/3612",
                        "text": "Daniel Hugenroth"
                    },
                    {
                        "@pid": "29/361",
                        "text": "Alastair R. Beresford"
                    }
                ]
            },
            "title": "Powering Privacy: On the Energy Demand and Feasibility of Anonymity Networks on Smartphones.",
            "venue": "USENIX Security Symposium",
            "pages": "5431-5448",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HugenrothB23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/hugenroth",
            "url": "https://dblp.org/rec/conf/uss/HugenrothB23",
            "abstract": "Many different anonymity networks have been designed and implemented over the last 20 years. These networks protect communication and metadata through multi-layered encryption and cover traffic. However, there is little research on whether such networks are actually practical on smart-phones with limited battery power. This is important as these are the dominant computing devices today. Previous research suggests that cryptographic operations and background radio transmissions are the two main contributors to energy consumption when running such software on mobile devices. We develop and open-source a test setup that measures actual energy consumption, including side-effects that evade simple models. With this setup we explore the costs of cryptography, radio communication, and background scheduling. We find that radio communication dominates overall power consumption, while cryptographic operations (asymmetric and symmetric) are negligible for typical anonymity network workloads. We also investigate the feasibility of running anonymity networks continuously to protect the metadata of all communication. For a 12-hour usage period, a mobile Tor client on a 4G network requires an additional 4 percentage points of battery charge which appears practical and is at least as efficient as the commercial VPN clients that we tested. However, a mix network client that continuously sends cover traffic requires up to 30 percentage points for the same period. Such costs are unlikely to be acceptable to many users.",
            "keywords": [
                "Anonymity Networks",
                "Energy Consumption",
                "Mobile Devices",
                "Tor Client",
                "Cover Traffic"
            ]
        },
        "url": "URL#915308",
        "sema_paperId": "733cc44cf33947ff0cc50318e54a0aae58ec94ae"
    },
    {
        "@score": "1",
        "@id": "915310",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "224/9447",
                        "text": "Fabian Ising"
                    },
                    {
                        "@pid": "216/6088",
                        "text": "Damian Poddebniak"
                    },
                    {
                        "@pid": "262/3891",
                        "text": "Tobias Kappert"
                    },
                    {
                        "@pid": "271/4882",
                        "text": "Christoph Saatjohann"
                    },
                    {
                        "@pid": "43/11495",
                        "text": "Sebastian Schinzel"
                    }
                ]
            },
            "title": "Content-Type: multipart/oracle - Tapping into Format Oracles in Email End-to-End Encryption.",
            "venue": "USENIX Security Symposium",
            "pages": "4175-4192",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/IsingPKSS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/ising",
            "url": "https://dblp.org/rec/conf/uss/IsingPKSS23",
            "abstract": "S/MIME and OpenPGP use cryptographic constructions re-peatedly shown to be vulnerable to format oracle attacks in protocols like TLS, SSH, or IKE. However, format oracle attacks in the End-to-End Encryption (E2EE) email setting are considered impractical as victims would need to open many attacker-modified emails and communicate the decryption result to the attacker. But is this really the case? In this paper, we survey how an attacker may remotely learn the decryption state in email E2EE. We analyze the interplay of MIME and IMAP and describe side-channels emerging from network patterns that leak the decryption status in Mail User Agents (MUAs). Concretely, we introduce specific MIME trees that produce decryption-dependent network patterns when opened in a victim\u2019s email client. We survey 19 OpenPGP-and S/MIME-enabled email clients and four cryptographic libraries and uncover a side-channel leaking the decryption status of S/MIME messages in one client. Further, we discuss why the exploitation in the other clients is impractical and show that it is due to missing feature support and implementation quirks. These unintended defenses create an unfortunate conflict between usability and security. We present more rigid countermeasures for MUA developers and the standards to prevent exploitation.",
            "keywords": [
                "Email Encryption",
                "Format Oracle Attacks",
                "S/MIME",
                "OpenPGP",
                "Decryption Status Leakage"
            ]
        },
        "url": "URL#915310",
        "sema_paperId": "7183b0b78b8b45cbd087838b79a0f6b4748ea229"
    },
    {
        "@score": "1",
        "@id": "915311",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "208/1920-2",
                        "text": "Mazharul Islam 0002"
                    },
                    {
                        "@pid": "331/2515",
                        "text": "Marina Sanusi Bohuk"
                    },
                    {
                        "@pid": "58/5795",
                        "text": "Paul Chung"
                    },
                    {
                        "@pid": "26/3399",
                        "text": "Thomas Ristenpart"
                    },
                    {
                        "@pid": "03/9962",
                        "text": "Rahul Chatterjee 0001"
                    }
                ]
            },
            "title": "Ara\u00f1a: Discovering and Characterizing Password Guessing Attacks in Practice.",
            "venue": "USENIX Security Symposium",
            "pages": "1019-1036",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/IslamBCR023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/islam",
            "url": "https://dblp.org/rec/conf/uss/IslamBCR023",
            "abstract": "Remote password guessing attacks remain one of the largest sources of account compromise. Understanding and characterizing attacker strategies is critical to improving security, but doing so has been challenging thus far due to the sensitivity of login services and the lack of ground truth labels for benign and malicious login requests. We perform an in-depth measurement study of guessing attacks targeting two large universities. Using a rich dataset of more than 34 million login requests to the two universities as well as thousands of compromise reports, we were able to develop a new analysis pipeline to identify 29 attack clusters\u2014many of which involved compromises not previously known to security engineers. Our analysis provides the richest investigation to date of password guessing attacks as seen from login services. We believe our tooling will be useful in future efforts to develop real-time detection of attack campaigns, and our characterization of attack campaigns can help more broadly guide mitigation design.",
            "keywords": [
                "Password Guessing Attacks",
                "Account Compromise",
                "Attack Characterization",
                "Login Services",
                "Real-time Detection"
            ]
        },
        "url": "URL#915311",
        "sema_paperId": "1b1a54b8bb0eaf9b3624f7f014aa9bdfec4b0688"
    },
    {
        "@score": "1",
        "@id": "915312",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "195/3195",
                        "text": "Charlie Jacomme"
                    },
                    {
                        "@pid": "126/3380-2",
                        "text": "Elise Klein 0002"
                    },
                    {
                        "@pid": "k/SteveKremer",
                        "text": "Steve Kremer"
                    },
                    {
                        "@pid": "353/7545",
                        "text": "Ma\u00efwenn Racouchot"
                    }
                ]
            },
            "title": "A comprehensive, formal and automated analysis of the EDHOC protocol.",
            "venue": "USENIX Security Symposium",
            "pages": "5881-5898",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Jacomme0KR23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/jacomme",
            "url": "https://dblp.org/rec/conf/uss/Jacomme0KR23",
            "abstract": "EDHOC is a key exchange proposed by IETF\u2019s Lightweight Authenticated Key Exchange (LAKE) Working Group (WG). Its design focuses on small message sizes to be suitable for constrained IoT communication technologies. In this paper we provide an in-depth formal analysis of EDHOC\u2013draft version 12, taking into account the different proposed authentication methods and various options. For our analysis we use the SAPIC+ protocol platform that allows to compile a single specification to 3 state-of-the-art protocol verification tools (PROVERIF, TAMARIN and DEEPSEC) and take advantage of the strengths of each of the tools. In our analysis we consider a large variety of compromise scenarios, and also exploit recent results that allow to model existing weaknesses in cryptographic primitives, relaxing the perfect cryptography assumption, common in symbolic analysis. While our analysis confirmed security for the most basic threat models, a number of weaknesses were uncovered in the current design when more advanced threat models were taken into account. These weaknesses have been acknowledged by the LAKE WG and the mitigations we propose (and prove secure) have been included in version 14 of the draft.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-jacomme.pdf",
            "keywords": [
                "EDHOC Protocol",
                "Key Exchange",
                "Formal Analysis",
                "Cryptographic Weaknesses",
                "IoT Security"
            ]
        },
        "url": "URL#915312"
    },
    {
        "@score": "1",
        "@id": "915313",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "220/2510",
                        "text": "Rasoul Jahanshahi"
                    },
                    {
                        "@pid": "248/1647",
                        "text": "Babak Amin Azad"
                    },
                    {
                        "@pid": "04/8280",
                        "text": "Nick Nikiforakis"
                    },
                    {
                        "@pid": "27/3108",
                        "text": "Manuel Egele"
                    }
                ]
            },
            "title": "Minimalist: Semi-automated Debloating of PHP Web Applications through Static Analysis.",
            "venue": "USENIX Security Symposium",
            "pages": "5557-5573",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/JahanshahiANE23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/jahanshahi",
            "url": "https://dblp.org/rec/conf/uss/JahanshahiANE23",
            "abstract": "As web applications grow more complicated and rely on third-party libraries to deliver new features to their users, they become bloated with unnecessary code. This unnecessary code increases a web application\u2019s attack surface, which can be exploited to steal user data and compromise the underlying web server. One approach to deal with bloated code is the process of selectively removing features that users do not require \u2013 debloating. In this paper, we identify the current challenges with debloating web applications and propose a semi-automated static debloating scheme. We implement a prototype of our proposed method,called Minimalist that generates a call-graph for a given PHP web application. Minimalist performs a reachability analysis for the features users require and removes unreachable functions in the analyzed web application. Compared to prior work, Minimalist debloats web applications without relying on heavy runtime instrumentation. Furthermore, the call-graph generated by Minimalist can be reused (in combination with web server logs) to debloat different installations of the same web application. Due to the inherent complexity and highly dynamic nature of the PHP language, Minimalist cannot guarantee the soundness of its call-graph analysis. However, Minimalist follows a best-effort approach to model the majority of PHP features used by popular web applications, such as WordPress, phpMyAdmin, and others. We evaluated Minimalist on 12 versions of four popular PHP web applications with 45 recent security vulnerabilities. We show that Minimalist reduces the size of web applications in our dataset on average by 18% and removes 38% of known vulnerabilities. Our results demonstrate that the principled debloating of web applications can lead to signi\ufb01cant security gains without relying on instrumentation mechanisms that degrade the performance of the server.",
            "keywords": [
                "PHP Web Applications",
                "Static Analysis",
                "Debloating",
                "Call-Graph Analysis",
                "Security Vulnerabilities"
            ]
        },
        "url": "URL#915313",
        "sema_paperId": "bd814da7937340eade2bf205efe0c90f71c32115"
    },
    {
        "@score": "1",
        "@id": "915314",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "322/1323",
                        "text": "Jisoo Jang"
                    },
                    {
                        "@pid": "295/8206",
                        "text": "Minsuk Kang"
                    },
                    {
                        "@pid": "210/0976",
                        "text": "Dokyung Song"
                    }
                ]
            },
            "title": "ReUSB: Replay-Guided USB Driver Fuzzing.",
            "venue": "USENIX Security Symposium",
            "pages": "2921-2938",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/JangKS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/jang",
            "url": "https://dblp.org/rec/conf/uss/JangKS23",
            "abstract": "Vulnerabilities in device drivers are constantly threatening the security of OS kernels. USB drivers are particularly concerning due to their widespread use and the wide variety of their attack vectors. Recently, fuzzing has been shown to be effective at finding vulnerabilities in USB drivers. Numerous vulnerabilities in USB drivers have been discovered by existing fuzzers; however, the number of code paths and vulnerabilities found, unfortunately, has stagnated. A key obstacle is the statefulness of USB drivers; that is, most of their code can be covered only when given a specific sequence of inputs. We observe that record-and-replay defined at the trust boundary of USB drivers directly helps overcoming the obstacle; deep states can be reached by reproducing recorded executions, and, combined with fuzzing, deeper code paths and vulnerabilities can be found. We present ReUSB, a USB driver fuzzer that guides fuzzing along two-dimensional record-and-replay of USB drivers to enhance their fuzzing. We address two fundamental challenges: faithfully replaying USB driver executions, and amplifying the effect of replay in fuzzing. To this end, we first introduce a set of language-level constructs that are essential in faithfully describing concurrent, two-dimensional traces but missing in state-of-the-art kernel fuzzers, and propose time, concurrency, and context-aware replay that can reproduce recorded driver executions with high fidelity. We then amplify the effect of our high-fidelity replay by guiding fuzzing along the replay of recorded executions, while mitigating the slowdown and side effects induced by replay via replay checkpointing. We implemented ReUSB, and evaluated it using two-dimensional traces of 10 widely used USB drivers of 3 different classes. The results show that ReUSB can significantly enhance USB driver fuzzing; it improved the code coverage of these drivers by 76% over a strong baseline, and",
            "keywords": [
                "USB Driver Fuzzing",
                "Record-and-Replay",
                "Vulnerability Discovery",
                "Statefulness in Drivers",
                "Code Coverage Enhancement"
            ]
        },
        "url": "URL#915314",
        "sema_paperId": "a6b2787e1de3d025950d359163d8ecfcc461a8e3"
    },
    {
        "@score": "1",
        "@id": "915315",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "278/2709",
                        "text": "Deepak Sirone Jegan"
                    },
                    {
                        "@pid": "56/4499-23",
                        "text": "Liang Wang 0023"
                    },
                    {
                        "@pid": "278/3009",
                        "text": "Siddhant Bhagat"
                    },
                    {
                        "@pid": "s/MichaelMSwift",
                        "text": "Michael M. Swift"
                    }
                ]
            },
            "title": "Guarding Serverless Applications with Kalium.",
            "venue": "USENIX Security Symposium",
            "pages": "4087-4104",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Jegan0BS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/jegan",
            "url": "https://dblp.org/rec/conf/uss/Jegan0BS23",
            "abstract": "As an emerging application paradigm, serverless computing attracts attention from more and more adversaries. Unfor-tunately, security tools for conventional web applications cannot be easily ported to serverless computing due to its distributed nature, and existing serverless security solutions focus on enforcing user specified information flow policies which are unable to detect the manipulation of the order of functions in application control flow paths. In this paper, we present Kalium , an extensible security framework that leverages local function state and global application state to enforce control-flow integrity (CFI) in serverless applications. We evaluate the performance overhead and security of Kalium using realistic open-source applications; our results show that Kalium mitigates several classes of attacks with relatively low performance overhead and outperforms the state-of-the-art serverless information flow protection systems.",
            "keywords": [
                "Serverless Computing",
                "Control-Flow Integrity",
                "Security Framework",
                "Application Security",
                "Kalium"
            ]
        },
        "url": "URL#915315",
        "sema_paperId": "2a8d4b77525ce72e81f9a57657605bfde53e946f"
    },
    {
        "@score": "1",
        "@id": "915316",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "24/5124-1",
                        "text": "Jinyuan Jia 0001"
                    },
                    {
                        "@pid": "204/1178",
                        "text": "Yupei Liu"
                    },
                    {
                        "@pid": "267/1159",
                        "text": "Yuepeng Hu"
                    },
                    {
                        "@pid": "03/9437",
                        "text": "Neil Zhenqiang Gong"
                    }
                ]
            },
            "title": "PORE: Provably Robust Recommender Systems against Data Poisoning Attacks.",
            "venue": "USENIX Security Symposium",
            "pages": "1703-1720",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/JiaLHG23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/jia",
            "url": "https://dblp.org/rec/conf/uss/JiaLHG23",
            "abstract": "Data poisoning attacks spoof a recommender system to make arbitrary, attacker-desired recommendations via injecting fake users with carefully crafted rating scores into the recommender system. We envision a cat-and-mouse game for such data poisoning attacks and their defenses, i.e., new defenses are designed to defend against existing attacks and new attacks are designed to break them. To prevent such a cat-and-mouse game, we propose PORE, the first framework to build provably robust recommender systems in this work. PORE can transform any existing recommender system to be provably robust against any untargeted data poisoning attacks, which aim to reduce the overall performance of a recommender system. Suppose PORE recommends top-$N$ items to a user when there is no attack. We prove that PORE still recommends at least $r$ of the $N$ items to the user under any data poisoning attack, where $r$ is a function of the number of fake users in the attack. Moreover, we design an efficient algorithm to compute $r$ for each user. We empirically evaluate PORE on popular benchmark datasets.",
            "keywords": [
                "Recommender Systems",
                "Data Poisoning Attacks",
                "Provable Robustness",
                "Fake User Injection",
                "Performance Preservation"
            ]
        },
        "url": "URL#915316",
        "sema_paperId": "0db5e5108532201d68b94bdf8ecf10bfb05a087f"
    },
    {
        "@score": "1",
        "@id": "915317",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "262/3567",
                        "text": "Qinhong Jiang"
                    },
                    {
                        "@pid": "39/1697-1",
                        "text": "Xiaoyu Ji 0001"
                    },
                    {
                        "@pid": "46/1162-1",
                        "text": "Chen Yan 0001"
                    },
                    {
                        "@pid": "96/4620",
                        "text": "Zhixin Xie"
                    },
                    {
                        "@pid": "353/7548",
                        "text": "Haina Lou"
                    },
                    {
                        "@pid": "10/3878-1",
                        "text": "Wenyuan Xu 0001"
                    }
                ]
            },
            "title": "GlitchHiker: Uncovering Vulnerabilities of Image Signal Transmission with IEMI.",
            "venue": "USENIX Security Symposium",
            "pages": "7249-7266",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Jiang00XL023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/jiang-qinhong",
            "url": "https://dblp.org/rec/conf/uss/Jiang00XL023",
            "abstract": "Cameras have evolved into one of the most critical gadgets in various applications. In this paper, we identify a new class of vulnerabilities involving the hitherto disregarded image signal transmission phase and explain the underlying principles of camera glitches for the \ufb01rst time. Based on the vulnerabilities, we design the GlitchHiker attack that can actively induce controlled glitch images of a camera at various positions, widths, and numbers using intentional electromagnetic interference (IEMI). We successfully launch the GlitchHiker attack on 8 off-the-shelf camera systems in 5 categories in their original packages at a distance of up to 30 cm. Experiments with 2 case studies involving 4 object detectors and 2 face detectors show that injecting one ribboning suf\ufb01ces to hide, create or alter objects and persons with a maximum success rate of 98.5% and 80.4%, respectively. Then, we discuss real-world attack scenarios and perform preliminary investigations on the feasibility of targeted attacks. Finally, we propose hardware-and software-based countermeasures.",
            "keywords": [
                "Image Signal Transmission",
                "Intentional Electromagnetic Interference",
                "Camera Vulnerabilities",
                "GlitchHiker Attack",
                "Object Detection Manipulation"
            ]
        },
        "url": "URL#915317",
        "sema_paperId": "31d01efe53253c1204321a9ace3539a961b9023e"
    },
    {
        "@score": "1",
        "@id": "915318",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "237/8586",
                        "text": "Zu-Ming Jiang"
                    },
                    {
                        "@pid": "161/7805",
                        "text": "Jia-Ju Bai"
                    },
                    {
                        "@pid": "s/ZhendongSu",
                        "text": "Zhendong Su 0001"
                    }
                ]
            },
            "title": "DynSQL: Stateful Fuzzing for Database Management Systems with Complex and Valid SQL Query Generation.",
            "venue": "USENIX Security Symposium",
            "pages": "4949-4965",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/JiangB023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/jiang-zu-ming",
            "url": "https://dblp.org/rec/conf/uss/JiangB023",
            "abstract": "Database management systems (DBMSs) are essential parts of modern software. To ensure the security of DBMSs, recent approaches apply fuzzing to testing DBMSs by automatically generating SQL queries. However, existing DBMS fuzzers are limited in generating complex and valid queries, as they heavily rely on their prede\ufb01ned grammar models and \ufb01xed knowledge about DBMSs, but do not capture DBMS-speci\ufb01c state information. As a result, these approaches miss many deep bugs in DBMSs. In this paper, we propose a novel stateful fuzzing approach to effectively test DBMSs and \ufb01nd deep bugs. Our basic idea is that after DBMSs process each SQL statement, there is useful state information that can be dynamically collected to facilitate later query generation. Based on this idea, our approach performs dynamic query interaction to incrementally generate complex and valid SQL queries, using the captured state information. To further improve the validity of generated queries, our approach uses the error status of query processing to \ufb01lter out invalid test cases. We implement our approach as a fully automatic fuzzing framework, DynSQL. DynSQL is evaluated on 6 widely-used DBMSs (including SQLite, MySQL, MariaDB, PostgreSQL, MonetDB, and ClickHouse) and \ufb01nds 40 unique bugs. Among these bugs, 38 have been con\ufb01rmed, 21 have been \ufb01xed, and 19 have been assigned with CVE IDs. In our evaluation, DynSQL outperforms other state-of-the-art DBMS fuzzers, achieving 41% higher code coverage and \ufb01nding many bugs missed by other fuzzers.",
            "keywords": [
                "Database Management Systems",
                "Stateful Fuzzing",
                "SQL Query Generation",
                "Dynamic Query Interaction",
                "Deep Bugs Detection"
            ]
        },
        "url": "URL#915318",
        "sema_paperId": "3a7373bd891702ae93d7e058241a7e8be25e89eb"
    },
    {
        "@score": "1",
        "@id": "915319",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "92/1104-7",
                        "text": "Peng Jiang 0007"
                    },
                    {
                        "@pid": "131/4079",
                        "text": "Ruizhe Huang"
                    },
                    {
                        "@pid": "95/7132-1",
                        "text": "Ding Li 0001"
                    },
                    {
                        "@pid": "07/6300-1",
                        "text": "Yao Guo 0001"
                    },
                    {
                        "@pid": "49/628",
                        "text": "Xiangqun Chen"
                    },
                    {
                        "@pid": "330/8010",
                        "text": "Jianhai Luan"
                    },
                    {
                        "@pid": "162/7779-1",
                        "text": "Yuxin Ren 0001"
                    },
                    {
                        "@pid": "54/7910",
                        "text": "Xinwei Hu"
                    }
                ]
            },
            "title": "Auditing Frameworks Need Resource Isolation: A Systematic Study on the Super Producer Threat to System Auditing and Its Mitigation.",
            "venue": "USENIX Security Symposium",
            "pages": "355-372",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/JiangH00CLRH23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/jiang-peng",
            "url": "https://dblp.org/rec/conf/uss/JiangH00CLRH23",
            "abstract": "System auditing is a crucial technique for detecting APT attacks. However, attackers may try to compromise the system auditing frameworks to conceal their malicious activities. In this paper, we present a comprehensive and systematic study of the super producer threat in auditing frameworks, which enables attackers to either corrupt the auditing framework or paralyze the entire system. We analyze that the main cause of the super producer threat is the lack of data isolation in the centralized architecture of existing solutions. To address this threat, we propose a novel auditing framework, NODROP, which isolates provenance data generated by different processes with a threadlet-based architecture design. Our evaluation demonstrates that NODROP can ensure the integrity of the auditing frameworks while achieving an average 6.58% higher application overhead compared to vanilla Linux and\n6.30% lower application overhead compared to a state-ofthe-art commercial auditing framework, Sysdig across eight different hardware configurations.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-jiang-peng.pdf",
            "keywords": [
                "System Auditing",
                "Super Producer Threat",
                "Resource Isolation",
                "Auditing Frameworks",
                "NODROP"
            ]
        },
        "url": "URL#915319"
    },
    {
        "@score": "1",
        "@id": "915320",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "275/2899",
                        "text": "Kailani R. Jones"
                    },
                    {
                        "@pid": "224/0849",
                        "text": "Dalton A. Brucker-Hahn"
                    },
                    {
                        "@pid": "160/1133",
                        "text": "Bradley Fidler"
                    },
                    {
                        "@pid": "145/6877",
                        "text": "Alexandru G. Bardas"
                    }
                ]
            },
            "title": "Work-From-Home and COVID-19: Trajectories of Endpoint Security Management in a Security Operations Center.",
            "venue": "USENIX Security Symposium",
            "pages": "2293-2310",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/JonesBFB23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/jones",
            "url": "https://dblp.org/rec/conf/uss/JonesBFB23",
            "abstract": "The COVID-19 surge of \u201cWork From Home\u201d (WFH) Internet use incentivized many organizations to strengthen their endpoint security monitoring capabilities. This trend has significant implications for how Security Operations Centers (SOCs) manage these end devices on their enterprise networks: in their organizational roles, regulatory environment, and required skills. By intersecting historical analysis (starting in the 1970s) and ethnography (analyzed 352 field notes across 1,000+ hours in a SOC over 34 months) whilst complementing with quantitative interviews (covering 7 other SOCs), we uncover causal forces that have pushed network management toward endpoints. We further highlight the negative impacts on end user privacy and analyst burnout. As such, we assert that SOCs should consider preparing for a continual, long-term shift from managing the network perimeter and the associated devices to commanding the actual user endpoints while facing potential privacy challenges and more burnout.",
            "keywords": [
                "Endpoint Security Management",
                "Security Operations Center (SOC)",
                "Work From Home (WFH)",
                "User Privacy",
                "Analyst Burnout"
            ]
        },
        "url": "URL#915320",
        "sema_paperId": "c4fbe61a73f1ec7fa380f73ff3c988116b747954"
    },
    {
        "@score": "1",
        "@id": "915321",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "248/0540",
                        "text": "Feras Al Kassar"
                    },
                    {
                        "@pid": "c/LucaCompagna",
                        "text": "Luca Compagna"
                    },
                    {
                        "@pid": "56/490",
                        "text": "Davide Balzarotti"
                    }
                ]
            },
            "title": "WHIP: Improving Static Vulnerability Detection in Web Application by Forcing tools to Collaborate.",
            "venue": "USENIX Security Symposium",
            "pages": "6079-6096",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KassarCB23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/al-kassar",
            "url": "https://dblp.org/rec/conf/uss/KassarCB23",
            "abstract": "Improving the accuracy of static application security testing (SAST) is key to fight critical vulnerabilities and increase the security of the Web. However, even state-of-the-art commercial tools have many blind spots that limit their ability to properly analyze modern code and therefore to discover complex inter-procedural vulnerabilities. In this paper, we present W HIP , the first approach that enables SAST tools to \u2018 collaborate \u2019 by sharing information that can help them to overcome each other\u2019s limitations. Our technique only operates on the application source code by using different tools as oracle to search for signs of interrupted data flows. When we discover such obstacles we inject alternative paths that circumvent the piece of code that SAST tools were not able to handle correctly. We conducted extensive experiments by analyzing over 100 popular PHP projects with more than 1,000 stars on Github. Our experiments show that our approach enables two popular SAST tools to increase their coverage of the applications\u2019 source code, resulting in an increase of up to 25% in the number of high-severity alerts. We manually inspected 30% of the novel 9,226 new alerts obtained by W HIP and responsibly disclosed 35 zero days injection vulnerabilities over 14 applications.",
            "keywords": [
                "Static Application Security Testing",
                "Vulnerability Detection",
                "Collaborative Analysis",
                "Data Flow Interruption",
                "PHP Security Vulnerabilities"
            ]
        },
        "url": "URL#915321",
        "sema_paperId": "19cb1318ee33a18fc7a12155a7fc7055408fb40d"
    },
    {
        "@score": "1",
        "@id": "915322",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "353/7608",
                        "text": "Daniel Katzman"
                    },
                    {
                        "@pid": "175/2898",
                        "text": "William Kosasih"
                    },
                    {
                        "@pid": "124/1916",
                        "text": "Chitchanok Chuengsatiansup"
                    },
                    {
                        "@pid": "180/7297",
                        "text": "Eyal Ronen"
                    },
                    {
                        "@pid": "90/10901",
                        "text": "Yuval Yarom"
                    }
                ]
            },
            "title": "The Gates of Time: Improving Cache Attacks with Transient Execution.",
            "venue": "USENIX Security Symposium",
            "pages": "1955-1972",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KatzmanKCRY23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/katzman",
            "url": "https://dblp.org/rec/conf/uss/KatzmanKCRY23",
            "abstract": "For over two decades, cache attacks have been shown to pose a signi\ufb01cant risk to the security of computer systems. In particular, a large number of works show that cache attacks provide a stepping stone for implementing transient-execution attacks. However, much less effort has been expended investigating the reverse direction\u2014how transient execution can be exploited for cache attacks. In this work, we answer this question. We \ufb01rst show that using transient execution, we can perform arbitrary manipulations of the cache state. Speci\ufb01cally, we design versatile logical gates whose inputs and outputs are the caching state of memory addresses. Our gates are generic enough that we can implement them in WebAssembly. More-over, the gates work on processors from multiple vendors, including Intel, AMD, Apple, and Samsung. We demonstrate that these gates are Turing complete and allow arbitrary computation on cache states, without exposing the logical values to the architectural state of the program. We then show two use cases for our gates in cache attacks. The \ufb01rst use case is to amplify the cache state, allowing us to create timing differences of over 100 millisecond between the cases that a speci\ufb01c memory address is cached or not. We show how we can use this capability to build eviction sets in WebAssembly, using only a low-resolution (0.1 millisecond) timer. For the second use case, we present the Prime+Store attack, a variant of Prime+Probe that decouples the sampling of cache states from the measurement of said state. Prime+ Store is the \ufb01rst timing-based cache attack that can sample the cache state at a rate higher than the clock rate. We show how to use Prime+Store to obtain bits from a concurrently executing modular exponentiation, when the only timing signal is at a resolution of 0.1 millisecond.",
            "keywords": [
                "Cache Attacks",
                "Transient Execution",
                "WebAssembly",
                "Prime+Store Attack",
                "Timing-based Cache Attacks"
            ]
        },
        "url": "URL#915322",
        "sema_paperId": "76d928493f7f4603bf846fe63ff95a63d57e2a6c"
    },
    {
        "@score": "1",
        "@id": "915323",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "275/2625",
                        "text": "Rishabh Khandelwal"
                    },
                    {
                        "@pid": "318/1519",
                        "text": "Asmit Nayak"
                    },
                    {
                        "@pid": "17/9886",
                        "text": "Hamza Harkous"
                    },
                    {
                        "@pid": "97/535",
                        "text": "Kassem Fawaz"
                    }
                ]
            },
            "title": "Automated Cookie Notice Analysis and Enforcement.",
            "venue": "USENIX Security Symposium",
            "pages": "1109-1126",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KhandelwalNHF23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/khandelwal",
            "url": "https://dblp.org/rec/conf/uss/KhandelwalNHF23",
            "abstract": "Online websites use cookie notices to elicit consent from the users, as required by recent privacy regulations like the GDPR and the CCPA. Prior work has shown that these notices are designed in a way to manipulate users into making website-friendly choices which put users\u2019 privacy at risk. In this work, we present CookieEnforcer , a new system for automatically discovering cookie notices and extracting a set of instructions that result in disabling all non-essential cookies. In order to achieve this, we \ufb01rst build an automatic cookie notice detector that utilizes the rendering pattern of the HTML elements to identify the cookie notices. Next, we analyze the cookie notices and predict the set of actions required to disable all unnecessary cookies. This is done by modeling the problem as a sequence-to-sequence task, where the input is a machine-readable cookie notice and the output is the set of clicks to make. We demonstrate the ef\ufb01cacy of CookieEnforcer via an end-to-end accuracy evaluation, showing that it can generate the required steps in 93.7% of the cases. Via a user study, we also show that CookieEnforcer can signi\ufb01cantly reduce the user effort. Finally, we characterize the behavior of CookieEnforcer on the top 100k websites from the Tranco list, showcasing its stability and scalability.",
            "keywords": [
                "Cookie Consent Management",
                "Privacy Regulations",
                "User Privacy",
                "Cookie Notice Detection",
                "Automated Cookie Enforcement"
            ]
        },
        "url": "URL#915323",
        "sema_paperId": "4da4baab8422143cd8aa5af87ae2234ad087cd69"
    },
    {
        "@score": "1",
        "@id": "915324",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "353/7636",
                        "text": "Tae Eun Kim"
                    },
                    {
                        "@pid": "176/6203-2",
                        "text": "Jaeseung Choi 0002"
                    },
                    {
                        "@pid": "17/11515",
                        "text": "Kihong Heo"
                    },
                    {
                        "@pid": "49/8463",
                        "text": "Sang Kil Cha"
                    }
                ]
            },
            "title": "DAFL: Directed Grey-box Fuzzing guided by Data Dependency.",
            "venue": "USENIX Security Symposium",
            "pages": "4931-4948",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Kim0HC23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/kim-tae-eun",
            "url": "https://dblp.org/rec/conf/uss/Kim0HC23",
            "abstract": "Despite growing research interest, existing directed grey-box fuzzers do not scale well with program complexity. In this paper, we identify two major scalability challenges for current directed grey-box fuzzing. Particularly, we find that traditional coverage feedback does not always provide meaningful guidance for reaching the target program point(s), and the existing seed distance mechanism does not operate well with programs with complex control structures. To address these problems, we present a novel fuzzer, named DAFL. DAFL selects code parts that are relevant to the target location and obtains coverage feedback only from those parts. Furthermore, it computes precise seed distances considering the data-flow semantics of program executions. The results are promising. Out of 41 real-world bugs, DAFL was able to find 4, 6, 9, and 5 more bugs within the given time, compared to AFL, AFLGo, WindRanger, and Beacon, respectively. Furthermore, among the cases where all fuzzers produced a median TTE, DAFL was at least 4.99 times faster on average compared to 3 state-of-the-art directed fuzzers including AFLGo, WindRanger, and Beacon.",
            "keywords": [
                "Directed Grey-box Fuzzing",
                "Program Complexity",
                "Coverage Feedback",
                "Data Dependency",
                "Seed Distance Mechanism"
            ]
        },
        "url": "URL#915324",
        "sema_paperId": "6bd6ed919503eee1fe2f6e916c36fc3410b5b288"
    },
    {
        "@score": "1",
        "@id": "915325",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "185/1645",
                        "text": "Eunsoo Kim"
                    },
                    {
                        "@pid": "353/7687",
                        "text": "Min Woo Baek"
                    },
                    {
                        "@pid": "283/0238",
                        "text": "CheolJun Park"
                    },
                    {
                        "@pid": "62/10307-1",
                        "text": "Dongkwan Kim 0001"
                    },
                    {
                        "@pid": "20/6892",
                        "text": "Yongdae Kim"
                    },
                    {
                        "@pid": "119/7670",
                        "text": "Insu Yun"
                    }
                ]
            },
            "title": "BASECOMP: A Comparative Analysis for Integrity Protection in Cellular Baseband Software.",
            "venue": "USENIX Security Symposium",
            "pages": "3547-3563",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KimBPKKY23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/kim-eunsoo",
            "url": "https://dblp.org/rec/conf/uss/KimBPKKY23",
            "abstract": "Baseband software is an important component in cellular communication. Unfortunately, it is almost impossible to implement baseband software correctly due to the complexity and the large volume of cellular specifications. As a result, dynamic testing has been widely used to discover implementation bugs in them. However, this approach suffers from the reachability problem, resulting in many missed bugs. Recently, BaseSpec proposed a static approach for analyzing baseband. However, BaseSpec requires heavy manual analysis and is limited to message decoding, failing to support integrity protection, the most critical step in mobile communication. In this paper, we propose a novel, semi-automated approach, B ASE C OMP , for analyzing integrity protection. To tame the complexity of baseband firmware, B ASE C OMP utilizes probabilistic inference to identify the integrity protection function. In particular, B ASE C OMP builds a factor graph from the firmware based on specifications and discovers the most probable function for integrity protection. Then, with additional manual analysis, B ASE C OMP performs symbolic analysis to validate that its behavior conforms to the specification and reports any discrepancies. We applied B ASE C OMP to 16 firmware images from two vendors (Samsung and MediaTek) in addition to srsRAN, an open-source 4G and 5G software radio suite. As a result, we discovered 29 bugs, including a NAS AKA bypass vulnerability in Samsung which was assigned critical severity. Moreover, B ASE C OMP can narrow down the number of functions to be manually analyzed to 1.56 on average. This can significantly reduce manual efforts for analysis, the primary limitation of the previous static analysis approach for baseband.",
            "keywords": [
                "Cellular Baseband Software",
                "Integrity Protection",
                "Static Analysis",
                "Probabilistic Inference",
                "Firmware Vulnerabilities"
            ]
        },
        "url": "URL#915325",
        "sema_paperId": "ac8f4d0c21e53b01f4cd59c64a5da66460795907"
    },
    {
        "@score": "1",
        "@id": "915326",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "264/7581",
                        "text": "Yoonsang Kim"
                    },
                    {
                        "@pid": "241/1478",
                        "text": "Sanket Goutam"
                    },
                    {
                        "@pid": "125/0358",
                        "text": "Amir Rahmati"
                    },
                    {
                        "@pid": "k/ArieEKaufman",
                        "text": "Arie E. Kaufman"
                    }
                ]
            },
            "title": "Erebus: Access Control for Augmented Reality Systems.",
            "venue": "USENIX Security Symposium",
            "pages": "929-946",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KimGRK23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/kim-yoonsang",
            "url": "https://dblp.org/rec/conf/uss/KimGRK23",
            "abstract": "Augmented Reality (AR) is widely considered the next evolution in personal devices, enabling seamless integration of the digital world into our reality. Such integration, however, often requires unfettered access to sensor data, causing significant overprivilege for applications that run on these platforms. Through analysis of 17 AR systems and 45 popular AR applications, we explore existing mechanisms for access control in AR platforms, identify key trends in how AR applications use sensor data, and pinpoint unique threats users face in AR environments. Using these findings, we design and implement Erebus, an access control framework for AR platforms that enables fine-grained control over data used by AR applications. Erebus achieves the principle of least privileged through the creation of a domain-specific language (DSL) for permission control in AR platforms, allowing applications to specify data needed for their functionality. Using this DSL, Erebus further enables users to customize app permissions to apply under specific user conditions. We implement Erebus on Google\u2019s AR-Core SDK and port five existing AR applications to demonstrate the capability of Erebus to secure various classes of apps. Performance results using these applications and various microbenchmarks show that Erebus achieves its security goals while being practical,introducing negligible performance overhead to the AR system.",
            "keywords": [
                "Augmented Reality",
                "Access Control",
                "Sensor Data Privacy",
                "Permission Management",
                "Least Privilege Principle"
            ]
        },
        "url": "URL#915326",
        "sema_paperId": "32df89e03f29d835359a437a03c85fe4bfdcd200"
    },
    {
        "@score": "1",
        "@id": "915327",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "78/5052",
                        "text": "Kyungtae Kim"
                    },
                    {
                        "@pid": "145/6643-5",
                        "text": "Sungwoo Kim 0005"
                    },
                    {
                        "@pid": "82/1935",
                        "text": "Kevin R. B. Butler"
                    },
                    {
                        "@pid": "99/3883",
                        "text": "Antonio Bianchi"
                    },
                    {
                        "@pid": "60/4243",
                        "text": "Rick Kennell"
                    },
                    {
                        "@pid": "159/0537",
                        "text": "Dave Tian"
                    }
                ]
            },
            "title": "Fuzz The Power: Dual-role State Guided Black-box Fuzzing for USB Power Delivery.",
            "venue": "USENIX Security Symposium",
            "pages": "5845-5861",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KimKBBKT23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/kim-kyungtae",
            "url": "https://dblp.org/rec/conf/uss/KimKBBKT23",
            "abstract": "USB Power Delivery (USBPD) is a state-of-the-art charging protocol for advanced power supply. Thanks to its high volume of power supply, it has been widely adopted by consumer devices, such as smartphones and laptops, and has become the de facto USB charging standard in both EU and North America. Due to the low-level nature of charging and the complexity of the protocol, USBPD is often implemented as proprietary firmware running on a dedicated microcontroller unit (MCU) with a USBPD physical layer. Bugs within these implementations can not only lead to safety issues, e.g., over charging, but also cause security issues, such as allowing attackers to reflash USBPD firmware. This paper proposes F UZZ PD, the first black-box fuzzing technique with dual-role state guidance targeting off-the-shelf USBPD devices with closed-source USBPD firmware. F UZ - Z PD only requires a physical USB Type-C connection to operate in a plug-n-fuzz fashion. To facilitate the black-box fuzzing of USBPD firmware, F UZZ PD manually creates a dual-role state machine from the USBPD specification, which enables both state coverage and transitions from fuzzing inputs. F UZZ PD further provides a multi-level mutation strategy, allowing for fine-grained state-aware fuzzing with intra-and inter-state mutations. We implement F UZZ PD using a Chromebook as the fuzzing host and evaluate it against 12 USBPD mobile devices from 7 different vendors, 7 USB hubs from 7 different vendors, and 5 chargers from 5 different vendors. F UZZ PD has found 15 unique bugs, 9 of which have been confirmed by the corresponding vendors. We additionally conduct a comparison between F UZZ PD and multiple state-of-the-art black-box fuzzing techniques, demonstrating that F UZZ PD achieves code coverage that is 40% to 3x higher than other solutions. We then compare F UZZ PD with the USBPD compliance test suite from USBIF and show that F UZZ PD can find 7 more bugs with 2x higher code coverage. F UZZ PD is the first step towards secure and trustworthy USB charging.",
            "keywords": [
                "USB Power Delivery",
                "Fuzzing Technique",
                "Closed-source Firmware",
                "State Machine",
                "Bug Detection"
            ]
        },
        "url": "URL#915327",
        "sema_paperId": "dd729c182eeb8373084202cb8703490ef433d759"
    },
    {
        "@score": "1",
        "@id": "915328",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "16/6515-2",
                        "text": "Hyungseok Kim 0002"
                    },
                    {
                        "@pid": "145/5306-2",
                        "text": "Soomin Kim 0002"
                    },
                    {
                        "@pid": "324/1116",
                        "text": "Junoh Lee"
                    },
                    {
                        "@pid": "36/10085",
                        "text": "Kangkook Jee"
                    },
                    {
                        "@pid": "49/8463",
                        "text": "Sang Kil Cha"
                    }
                ]
            },
            "title": "Reassembly is Hard: A Reflection on Challenges and Strategies.",
            "venue": "USENIX Security Symposium",
            "pages": "1469-1486",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KimKLJC23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/kim-hyungseok",
            "url": "https://dblp.org/rec/conf/uss/KimKLJC23",
            "abstract": "Reassembly, a branch of static binary rewriting, has become a focus of research today. However, despite its widespread use and research interest, there have been no systematic investiga-tions on the techniques and challenges of reassemblers. In this paper, we formally de\ufb01ne different types of errors that occur in current existing reassemblers, and present an automated tool named R EASSESSOR to \ufb01nd such errors. We attempt to show through our tool and the large-scale benchmark we created the current challenges in the \ufb01eld and how they can be approached.",
            "keywords": [
                "Static Binary Rewriting",
                "Reassembly",
                "Error Detection",
                "Automated Tool",
                "R EASSESSOR"
            ]
        },
        "url": "URL#915328",
        "sema_paperId": "ff6e740807f7b1fba422b3ca79e2c0c655a3b9c1"
    },
    {
        "@score": "1",
        "@id": "915329",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "61/9605",
                        "text": "Young Min Kim"
                    },
                    {
                        "@pid": "45/7986",
                        "text": "Byoungyoung Lee"
                    }
                ]
            },
            "title": "Extending a Hand to Attackers: Browser Privilege Escalation Attacks via Extensions.",
            "venue": "USENIX Security Symposium",
            "pages": "7055-7071",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KimL23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/kim-young-min",
            "url": "https://dblp.org/rec/conf/uss/KimL23",
            "abstract": "Web browsers are attractive targets of attacks, whereby at-tackers can steal security-and privacy-sensitive data, such as online banking and social network credentials, from users. Thus, browsers adopt the principle of least privilege (PoLP) to minimize damage if compromised, namely, the multipro-cess architecture and site isolation. We focus on browser extensions, which are third-party programs that extend the features of modern browsers (Chrome, Firefox, and Safari). The browser also applies PoLP to the extension architecture; that is, two primary extension components are separated, where one component is granted higher privilege, and the other is granted lower privilege. In this paper, we first analyze the security aspect of extensions. The analysis reveals that the current extension architecture imposes strict security requirements on extension developers, which are difficult to satisfy. In particular, 59 vulnerabilities are found in 40 extensions caused by violated requirements, allowing the attacker to perform privilege escalation attacks, including UXSS (universal cross-site scripting) and stealing passwords or cryptocurrencies in the extensions. Alarmingly, extensions are used by more than half and a third of Chrome and Firefox users, respectively. Furthermore, many extensions in which vulnerabilities are found are extremely popular and have more than 10 million users. To address the security limitations of the current extension architecture, we present F IST B UMP , a new extension architecture to strengthen PoLP enforcement. F IST B UMP employs strong process isolation between the webpage and content script; thus, the aforementioned security requirements are satisfied by design, thereby eliminating all the identified vulnerabilities. Moreover, F IST B UMP \u2019s design maintains the backward compatibility of the extensions; therefore, the extensions can run with F IST B UMP without modification.",
            "keywords": [
                "Browser Extensions",
                "Privilege Escalation Attacks",
                "Security Vulnerabilities",
                "Process Isolation",
                "FISTBUMP Architecture"
            ]
        },
        "url": "URL#915329",
        "sema_paperId": "a99d7dd4369f19a25be433875a57cea218a0e312"
    },
    {
        "@score": "1",
        "@id": "915330",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "155/0040",
                        "text": "Hyungsub Kim"
                    },
                    {
                        "@pid": "202/6743",
                        "text": "Muslum Ozgur Ozmen"
                    },
                    {
                        "@pid": "143/2298",
                        "text": "Z. Berkay Celik"
                    },
                    {
                        "@pid": "99/3883",
                        "text": "Antonio Bianchi"
                    },
                    {
                        "@pid": "59/5539",
                        "text": "Dongyan Xu"
                    }
                ]
            },
            "title": "PatchVerif: Discovering Faulty Patches in Robotic Vehicles.",
            "venue": "USENIX Security Symposium",
            "pages": "3011-3028",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KimOCBX23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/kim-hyungsub",
            "url": "https://dblp.org/rec/conf/uss/KimOCBX23",
            "abstract": "Modern software is continuously patched to fix bugs and security vulnerabilities. Patching is particularly important in robotic vehicles (RVs), in which safety and security bugs can cause severe physical damages. However, existing automated methods struggle to identify faulty patches in RVs, due to their inability to systematically determine patch-introduced behavioral modifications, which affect how the RV interacts with the physical environment. In this paper, we introduce P ATCH V ERIF , an automated patch analysis framework. P ATCH V ERIF \u2019s goal is to evaluate whether a given patch introduces bugs in the patched RV control software. To this aim, P ATCH V ERIF uses a combination of static and dynamic analysis to measure how the analyzed patch affects the physical state of an RV. Specifically, P ATCH V ERIF uses a dedicated input mutation algorithm to generate RV inputs that maximize the behavioral differences (in the physical space) between the original code and the patched one. Using the collected information about patch-introduced behavioral modifications, P ATCH V ERIF employs support vector machines (SVMs) to infer whether a patch is faulty or correct. We evaluated P ATCH V ERIF on two popular RV control software (ArduPilot and PX4), and it successfully identified faulty patches with an average precision and recall of 97 . 9% and 92 . 1%, respectively. Moreover, P ATCH V ERIF discovered 115 previously unknown bugs, 103 of which have been acknowledged, and 51 of them have already been fixed.",
            "keywords": [
                "Robotic Vehicles",
                "Patch Analysis",
                "Faulty Patches",
                "Behavioral Modifications",
                "Automated Testing"
            ]
        },
        "url": "URL#915330",
        "sema_paperId": "dbbe2c72f67ead6d755bf891a7600ac5895cc207"
    },
    {
        "@score": "1",
        "@id": "915331",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "24/1630",
                        "text": "Jiwon Kim"
                    },
                    {
                        "@pid": "205/3765",
                        "text": "Benjamin E. Ujcich"
                    },
                    {
                        "@pid": "159/0537",
                        "text": "Dave Tian"
                    }
                ]
            },
            "title": "Intender: Fuzzing Intent-Based Networking with Intent-State Transition Guidance.",
            "venue": "USENIX Security Symposium",
            "pages": "4463-4480",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KimUT23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/kim-jiwon",
            "url": "https://dblp.org/rec/conf/uss/KimUT23",
            "abstract": "Intent-based networking (IBN) abstracts network con\ufb01gura-tion complexity from network operators by focusing on what operators want the network to do rather than how such con-\ufb01guration should be implemented. While such abstraction eases network management challenges, little attention to date has focused on IBN\u2019s new security concerns that adversely impact an entire network\u2019s correct operation. To motivate the prevalence of such security concerns, we systematize IBN\u2019s security challenges by studying existing bug reports from a representative IBN implementation within the ONOS network operating system. We \ufb01nd that 61% of IBN-related bugs are semantic bugs that are challenging, if not impossible, to detect ef\ufb01ciently by state-of-the-art vulnerability discovery tools. To tackle existing limitations, we present I NTENDER , the \ufb01rst semantically-aware fuzzing framework for IBN. I N - TENDER leverages network topology information and intent-operation dependencies (IOD) to ef\ufb01ciently generate testing inputs. I NTENDER introduces a new feedback mechanism, intent-state transition guidance (ISTG), which traces the history of transitions in intent states. We evaluate I NTENDER us-ing ONOS and \ufb01nd 12 bugs, 11 of which were CVE-assigned security-critical vulnerabilities affecting network-wide con-trol plane integrity and availability. Compared to state-of-the-art fuzzing tools AFL, Jazzer, Zest, and PAZZ, I NTENDER generates up to 78 . 7 \u00d7 more valid fuzzing input, achieves up to 2 . 2 \u00d7 better coverage, and detects up to 82 . 6 \u00d7 more unique errors. I NTENDER with IOD reduces 73 . 02% of redundant operations and spends 10 . 74% more time on valid operations. I NTENDER with ISTG leads to 1 . 8 \u00d7 more intent-state transitions compared to code-coverage guidance.",
            "keywords": [
                "Intent-Based Networking",
                "Fuzzing Framework",
                "Semantic Bugs",
                "Network Security Vulnerabilities",
                "Intent-State Transition Guidance"
            ]
        },
        "url": "URL#915331",
        "sema_paperId": "7fc7668199e36de1df53ec691ac6be7143f512b2"
    },
    {
        "@score": "1",
        "@id": "915332",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "211/4792",
                        "text": "Daniel Klischies"
                    },
                    {
                        "@pid": "207/4015",
                        "text": "Moritz Schloegel"
                    },
                    {
                        "@pid": "272/7190",
                        "text": "Tobias Scharnowski"
                    },
                    {
                        "@pid": "353/7611",
                        "text": "Mikhail Bogodukhov"
                    },
                    {
                        "@pid": "77/2192",
                        "text": "David Rupprecht"
                    },
                    {
                        "@pid": "20/11342",
                        "text": "Veelasha Moonsamy"
                    }
                ]
            },
            "title": "Instructions Unclear: Undefined Behaviour in Cellular Network Specifications.",
            "venue": "USENIX Security Symposium",
            "pages": "3475-3492",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KlischiesSSBRM23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/klischies",
            "url": "https://dblp.org/rec/conf/uss/KlischiesSSBRM23",
            "abstract": "Cellular networks are a cornerstone of modern communication and indispensable to our daily lives. Their specifications span thousands of pages, written primarily in natural language. The ensuing complexity and lack of explicitness lead to un-derspecification, where only subsets of possible interactions are properly specified, while other behaviour is left undefined and open to interpretation by developers. In practice, this causes weird, unintended interactions in smartphone modems implementing the specification that, in the worst case, lead to security vulnerabilities. In this work, we present the first generic approach for systematically discovering undefined behaviour in cellular specifications. Requiring solely a model of the behaviour defined in the specification, our technique extends this model to automatically reason about the presence of undefined behaviour. For each undefined behaviour, it automatically infers concrete examples as proof of existence. This not only allows improving the specification but also enables us to test smartphone modems. This way, we can verify whether an instance of undefined behaviour leads to a security vulnerability within modem firmware. With our approach, we identify 58 cases of undefined behaviour in LTE\u2019s Public Warning System, SMS, and Radio Resource Control specifications. Five of these cases resulted in previously unknown vulnerabilities that allow adversaries to read modem memory contents and perform remote Denial of Service attacks (in one case just via a single SMS) against commonly used smartphone modems. So far, two CVEs of high and one CVE of critical severity have been assigned.",
            "keywords": [
                "Cellular Network Specifications",
                "Undefined Behaviour",
                "Modem Security",
                "Vulnerability Discovery",
                "Public Warning System"
            ]
        },
        "url": "URL#915332",
        "sema_paperId": "cb8b44563c4d042a441c06c9614743f69b54d16e"
    },
    {
        "@score": "1",
        "@id": "915333",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "168/9554",
                        "text": "Simon Koch"
                    },
                    {
                        "@pid": "329/9173",
                        "text": "Benjamin Altpeter"
                    },
                    {
                        "@pid": "82/359",
                        "text": "Martin Johns"
                    }
                ]
            },
            "title": "The OK Is Not Enough: A Large Scale Study of Consent Dialogs in Smartphone Applications.",
            "venue": "USENIX Security Symposium",
            "pages": "5467-5484",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KochAJ23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/koch",
            "url": "https://dblp.org/rec/conf/uss/KochAJ23",
            "abstract": "Mobile applications leaking personal information is a well established observation pre and post GDPR. The legal requirements for personal data collection in the context of tracking are specified by GDPR and the common understanding is, that tracking must be based on proper consent. Studies of the consent dialogs on websites revealed severe issues including dark patterns. However, the mobile space is currently under-explored with initial observations pointing towards a similar state of affairs. To address this research gap we analyze a subset of possible consent dialogs, namely privacy consent di-alogs, in 3006 Android and 1773 iOS applications. We show that 22.3% of all apps have any form of dialog with only 11.9% giving the user some form of actionable choice, e.g., at least an accept button. However, this choice is limited as a large proportion of all such dialogs employ some form of dark pattern coercing the user to consent.",
            "keywords": [
                "Mobile Applications",
                "Consent Dialogs",
                "Privacy",
                "User Consent",
                "Dark Patterns"
            ]
        },
        "url": "URL#915333",
        "sema_paperId": "a6ec023309521e682eded4fdb08c985c9dbd98a2"
    },
    {
        "@score": "1",
        "@id": "915334",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "280/4649",
                        "text": "Andreas Kogler"
                    },
                    {
                        "@pid": "207/7615",
                        "text": "Jonas Juffinger"
                    },
                    {
                        "@pid": "212/6725",
                        "text": "Lukas Giner"
                    },
                    {
                        "@pid": "156/3555",
                        "text": "Lukas Gerlach 0001"
                    },
                    {
                        "@pid": "223/9857",
                        "text": "Martin Schwarzl"
                    },
                    {
                        "@pid": "08/1117-1",
                        "text": "Michael Schwarz 0001"
                    },
                    {
                        "@pid": "166/1494",
                        "text": "Daniel Gruss"
                    },
                    {
                        "@pid": "91/4831",
                        "text": "Stefan Mangard"
                    }
                ]
            },
            "title": "Collide+Power: Leaking Inaccessible Data with Software-based Power Side Channels.",
            "venue": "USENIX Security Symposium",
            "pages": "7285-7302",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KoglerJG0S0GM23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/kogler",
            "url": "https://dblp.org/rec/conf/uss/KoglerJG0S0GM23",
            "abstract": "Differential Power Analysis (DPA) measures single-bit differences between data values used in computer systems by statistical analysis of power traces. In this paper, we show that the mere co-location of data values, e.g., attacker and victim data in the same buffers and caches, leads to power leakage in modern CPUs that depends on a combination of both values, resulting in a novel attack, Collide+Power. We systematically analyze the power leakage of the CPU\u2019s memory hierarchy to derive precise leakage models enabling practical end-to-end attacks. These attacks can be conducted in software with any signal related to power consumption, e.g., power consumption interfaces or throttling-induced timing variations. Leakage due to throttling requires 133 . 3 times more samples than direct power measurements. We develop a novel differential measurement technique amplifying the exploitable leakage by a factor of 8 . 778 on average, compared to a straightforward DPA approach. We demonstrate that Collide+Power leaks single-bit differences from the CPU\u2019s memory hierarchy with fewer than 23 000 measurements. Collide+Power varies attacker-controlled data in our end-to-end DPA attacks. We present a Meltdown-style attack, leaking from attacker-chosen memory locations, and a faster MDS-style attack, which leaks 4 . 82 bit / h. Collide+Power is a generic attack applicable to any modern CPU, arbitrary memory locations, and victim applications and data. However, the Meltdown-style attack is not yet practical, as it is limited by the state of the art of prefetching victim data into the cache, leading to an unrealistic real-world attack runtime with throttling of more than a year for a single bit. Given the different variants and potentially more practical prefetching methods, we consider Collide",
            "keywords": [
                "Power Side Channels",
                "Differential Power Analysis",
                "Data Leakage",
                "CPU Memory Hierarchy",
                "Collide+Power Attack"
            ]
        },
        "url": "URL#915334",
        "sema_paperId": "edf16871f5ec76c4a4ff8648d1756d436bab1b63"
    },
    {
        "@score": "1",
        "@id": "915335",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "k/TadayoshiKohno",
                        "text": "Tadayoshi Kohno"
                    },
                    {
                        "@pid": "132/9687",
                        "text": "Yasemin Acar"
                    },
                    {
                        "@pid": "232/6346",
                        "text": "Wulf Loh"
                    }
                ]
            },
            "title": "Ethical Frameworks and Computer Security Trolley Problems: Foundations for Conversations.",
            "venue": "USENIX Security Symposium",
            "pages": "5145-5162",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KohnoAL23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/kohno",
            "url": "https://dblp.org/rec/conf/uss/KohnoAL23",
            "abstract": "The computer security research community regularly tackles ethical questions. The field of ethics / moral philosophy has for centuries considered what it means to be \"morally good\" or at least \"morally allowed / acceptable\". Among philosophy's contributions are (1) frameworks for evaluating the morality of actions\u2014including the well-established consequentialist and deontological frameworks\u2014and (2) scenarios (like trolley problems) featuring moral dilemmas that can facilitate discussion about and intellectual inquiry into different perspectives on moral reasoning and decision-making. In a classic trolley problem, consequentialist and deontological analyses may render different outcomes. In this research, we explicitly make and explore connections between moral questions in computer security research and ethics / moral philosophy through the creation and analysis of trolley problem-like computer security-themed moral dilemmas and, in doing so, we seek to contribute to conversations among security researchers about the morality of security research-related decisions. We explicitly do not seek to define what is morally right or wrong, nor do we argue for one framework over another. Indeed, the consequentialist and deontological frameworks that we center, in addition to coming to different conclusions for our scenarios, have significant limitations. Instead, by offering our scenarios and by comparing two different approaches to ethics, we strive to contribute to how the computer security research field considers and converses about ethical questions, especially when there are different perspectives on what is morally right or acceptable. Our vision is for this work to be broadly useful to the computer security community, including to researchers as they embark on (or choose not to embark on), conduct, and write about their research, to program committees as they evaluate submissions, and to educators as they teach about computer security and ethics.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-kohno.pdf",
            "keywords": [
                "Computer Security Ethics",
                "Moral Philosophy",
                "Trolley Problems",
                "Consequentialism",
                "Deontology"
            ]
        },
        "url": "URL#915335"
    },
    {
        "@score": "1",
        "@id": "915336",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "330/2866",
                        "text": "Moshe Kol"
                    },
                    {
                        "@pid": "98/3396",
                        "text": "Amit Klein 0001"
                    },
                    {
                        "@pid": "84/7357",
                        "text": "Yossi Gilad"
                    }
                ]
            },
            "title": "Device Tracking via Linux&apos;s New TCP Source Port Selection Algorithm.",
            "venue": "USENIX Security Symposium",
            "pages": "6167-6183",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Kol0G23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/kol",
            "url": "https://dblp.org/rec/conf/uss/Kol0G23",
            "abstract": "We describe a tracking technique for Linux devices, exploiting a new TCP source port generation mechanism recently introduced to the Linux kernel. This mechanism is based on an algorithm, standardized in RFC 6056, for boosting security by better randomizing port selection. Our technique detects collisions in a hash function used in the said algorithm, based on sampling TCP source ports generated in an attacker-prescribed manner. These hash collisions depend solely on a per-device key, and thus the set of collisions forms a device ID that allows tracking devices across browsers, browser privacy modes, containers, and IPv4/IPv6 networks (including some VPNs). It can distinguish among devices with identical hardware and software, and lasts until the device restarts. \nWe implemented this technique and then tested it using tracking servers in two different locations and with Linux devices on various networks. We also tested it on an Android device that we patched to introduce the new port selection algorithm. The tracking technique works in real-life conditions, and we report detailed findings about it, including its dwell time, scalability, and success rate in different network types. We worked with the Linux kernel team to mitigate the exploit, resulting in a security patch introduced in May 2022 to the Linux kernel, and we provide recommendations for better securing the port selection algorithm in the paper.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-kol.pdf",
            "keywords": [
                "Device Tracking",
                "TCP Source Port Selection",
                "Linux Kernel",
                "Hash Collisions",
                "Privacy Risks"
            ]
        },
        "url": "URL#915336"
    },
    {
        "@score": "1",
        "@id": "915337",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "278/0754",
                        "text": "Jakob Koschel"
                    },
                    {
                        "@pid": "239/8466",
                        "text": "Pietro Borrello"
                    },
                    {
                        "@pid": "32/9698",
                        "text": "Daniele Cono D&apos;Elia"
                    },
                    {
                        "@pid": "91/800",
                        "text": "Herbert Bos"
                    },
                    {
                        "@pid": "75/8194",
                        "text": "Cristiano Giuffrida"
                    }
                ]
            },
            "title": "Uncontained: Uncovering Container Confusion in the Linux Kernel.",
            "venue": "USENIX Security Symposium",
            "pages": "5055-5072",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KoschelBDBG23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/koschel",
            "url": "https://dblp.org/rec/conf/uss/KoschelBDBG23",
            "abstract": "In this artifact we provide the means to reproduce our main results. Specifically, we show that our framework, UNCON - TAINED , finds container confusion, both dynamically while fuzzing and statically with dataflow tracking. We have evaluated our artifact on an Ubuntu 22.04.1 (stock Linux kernel v.5.15) with 16 cores @2.3GHz (AMD EPYC 7643) using a total of 16 QEMU-KVM virtual machines with 4GB RAM. Our source code is available at: github.com/vusec/uncontained .",
            "keywords": [
                "Container Confusion",
                "Linux Kernel",
                "Dynamic Fuzzing",
                "Static Dataflow Tracking",
                "UNCONTAINED Framework"
            ]
        },
        "url": "URL#915337",
        "sema_paperId": "c1768aedb4b465adf4559fa2d80dadbcbc7970c0"
    },
    {
        "@score": "1",
        "@id": "915338",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "299/9010",
                        "text": "Cyrill Kr\u00e4henb\u00fchl"
                    },
                    {
                        "@pid": "227/7984",
                        "text": "Marc Wyss"
                    },
                    {
                        "@pid": "b/DavidABasin",
                        "text": "David A. Basin"
                    },
                    {
                        "@pid": "75/5939",
                        "text": "Vincent Lenders"
                    },
                    {
                        "@pid": "16/6873",
                        "text": "Adrian Perrig"
                    },
                    {
                        "@pid": "117/8959",
                        "text": "Martin Strohmeier"
                    }
                ]
            },
            "title": "FABRID: Flexible Attestation-Based Routing for Inter-Domain Networks.",
            "venue": "USENIX Security Symposium",
            "pages": "5755-5772",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KrahenbuhlWBLPS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/krahenbuhl",
            "url": "https://dblp.org/rec/conf/uss/KrahenbuhlWBLPS23",
            "abstract": "In its current state, the Internet does not provide end users with transparency and control regarding on-path forwarding devices. In particular, the lack of network device information reduces the trustworthiness of the forwarding path and prevents end-user applications requiring specific router capabilities from reaching their full potential. Moreover, the inability to influence the traffic's forwarding path results in applications communicating over undesired routes, while alternative paths with more desirable properties remain unusable. In this work, we present FABRID, a system that enables applications to forward traffic flexibly, potentially on multiple paths selected to comply with user-defined preferences, where information about forwarding devices is exposed and transparently attested by autonomous systems (ASes). The granularity of this information is chosen by each AS individually, protecting them from leaking sensitive network details, while the secrecy and authenticity of preferences embedded within the users' packets are protected through efficient cryptographic operations. We show the viability of FABRID by deploying it on a global SCION network test bed, and we demonstrate high throughput on commodity hardware.",
            "keywords": [
                "Inter-Domain Networks",
                "Traffic Forwarding",
                "Routing Transparency",
                "User Preferences",
                "Autonomous Systems (ASes)"
            ]
        },
        "url": "URL#915338",
        "sema_paperId": "c747c886eaa911fd89bc6d43e8e72c1db78c2fe3"
    },
    {
        "@score": "1",
        "@id": "915339",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "40/7792",
                        "text": "Alexander Krause"
                    },
                    {
                        "@pid": "325/3232",
                        "text": "Jan H. Klemmer"
                    },
                    {
                        "@pid": "213/7298",
                        "text": "Nicolas Huaman"
                    },
                    {
                        "@pid": "203/1800",
                        "text": "Dominik Wermke"
                    },
                    {
                        "@pid": "132/9687",
                        "text": "Yasemin Acar"
                    },
                    {
                        "@pid": "38/9378",
                        "text": "Sascha Fahl"
                    }
                ]
            },
            "title": "Pushed by Accident: A Mixed-Methods Study on Strategies of Handling Secret Information in Source Code Repositories.",
            "venue": "USENIX Security Symposium",
            "pages": "2527-2544",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KrauseKHWAF23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/krause",
            "url": "https://dblp.org/rec/conf/uss/KrauseKHWAF23",
            "abstract": "Version control systems for source code, such as Git, are key tools in modern software development. Many developers use services like GitHub or GitLab for collaborative software development. Many software projects include code secrets such as API keys or passwords that need to be managed securely. Previous research and blog posts found that developers struggle with secure code secret management and accidentally leaked code secrets to public Git repositories. Leaking code secrets to the public can have disastrous consequences, such as abusing services and systems or making sensitive user data available to attackers. In a mixed-methods study, we surveyed 109 developers with version control system experience. Additionally, we conducted 14 in-depth semi-structured interviews with developers who experienced secret leakage in the past. 30.3% of our participants encountered code secret leaks in the past. Most of them face several challenges with secret leakage prevention and remediation. Based on our findings, we discuss challenges, such as estimating the risks of leaked secrets, and the needs of developers in remediating and preventing code secret leaks, such as low adoption requirements. We conclude with recommendations for developers and source code platform providers to reduce the risk of secret leakage.",
            "keywords": [
                "Version Control Systems",
                "Code Secret Management",
                "Secret Leakage",
                "Developer Challenges",
                "Remediation Strategies"
            ]
        },
        "url": "URL#915339",
        "sema_paperId": "e0749602783d68d8283eaae06a5f8c64e7e23b10"
    },
    {
        "@score": "1",
        "@id": "915340",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "353/7542",
                        "text": "Lorenz Kustosch"
                    },
                    {
                        "@pid": "22/7256",
                        "text": "Carlos Ga\u00f1\u00e1n"
                    },
                    {
                        "@pid": "353/7594",
                        "text": "Mattis van &apos;t Schip"
                    },
                    {
                        "@pid": "17/7444",
                        "text": "Michel van Eeten"
                    },
                    {
                        "@pid": "84/3561",
                        "text": "Simon Parkin"
                    }
                ]
            },
            "title": "Measuring Up to (Reasonable) Consumer Expectations: Providing an Empirical Basis for Holding IoT Manufacturers Legally Responsible.",
            "venue": "USENIX Security Symposium",
            "pages": "1487-1504",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KustoschGSEP23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/kustosch",
            "url": "https://dblp.org/rec/conf/uss/KustoschGSEP23",
            "abstract": "With continued cases of security and privacy incidents with consumer Internet-of-Things (IoT) devices comes the need to identify which actors are in the best place to respond. Previous literature studied expectations of consumers regarding how security and privacy should be implemented and who should take on preventive efforts. But how do such normative consumer expectations differ from what is actually realistic, or reasonable to expect how security and privacy-related events will be handled? Using a vignette survey with 862 participants, we studied consumer expectations on how IoT manufacturers and users would and should respond when confronted with a potentially infected or privacy-invading IoT device. We find that expectations differ considerably between what is realistic and what is appropriate. Furthermore, security and privacy lead to different expectations around users\u2019 and manufacturers\u2019 actions, with a general diffusion of expectations on how to handle privacy-related events. We offer recommendations to IoT manufacturers and regulators on how to support users in addressing security and privacy issues.",
            "keywords": [
                "Internet of Things (IoT)",
                "Consumer Expectations",
                "Security and Privacy",
                "Manufacturer Responsibility",
                "Vignette Survey"
            ]
        },
        "url": "URL#915340",
        "sema_paperId": "7958275ea7328ffa877df7767a6ec56bb97ec077"
    },
    {
        "@score": "1",
        "@id": "915341",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "46/4109",
                        "text": "Jonghoon Kwon"
                    },
                    {
                        "@pid": "329/5155",
                        "text": "Jeonggyu Song"
                    },
                    {
                        "@pid": "21/1967",
                        "text": "Junbeom Hur"
                    },
                    {
                        "@pid": "16/6873",
                        "text": "Adrian Perrig"
                    }
                ]
            },
            "title": "Did the Shark Eat the Watchdog in the NTP Pool? Deceiving the NTP Pool&apos;s Monitoring System.",
            "venue": "USENIX Security Symposium",
            "pages": "6151-6166",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KwonSHP23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/kwon",
            "url": "https://dblp.org/rec/conf/uss/KwonSHP23",
            "abstract": "The NTP pool has become a critical infrastructure for modern Internet services and applications. With voluntarily joined thousands of timeservers, it supplies millions of distributed (heterogeneous) systems with time. While numerous efforts have been made to enhance NTP\u2019s accuracy, reliability, and security, unfortunately, the NTP pool attracts relatively little attention. In this paper, we provide a comprehensive analysis of NTP pool security, in particular the NTP pool monitoring system, which oversees the correctness and responsiveness of the participating servers. We \ufb01rst investigate strategic attacks that deceive the pool\u2019s health-check system to remove legitimate timeservers from the pool. Then, through empirical analysis using monitoring servers and timeservers injected into the pool, we demonstrate the feasibility of our approaches, show their effectiveness, and debate the implications. Finally, we discuss designing a new pool monitoring system to mitigate these attacks.",
            "keywords": [
                "NTP Pool",
                "Time Synchronization",
                "Monitoring System",
                "Security Attacks",
                "Server Deception"
            ]
        },
        "url": "URL#915341",
        "sema_paperId": "4f2c2bbc2d1f2b24f5ee5f48bf59d0d08e65445d"
    },
    {
        "@score": "1",
        "@id": "915342",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "176/8068",
                        "text": "Andrew Kwong"
                    },
                    {
                        "@pid": "58/3695",
                        "text": "Walter Wang"
                    },
                    {
                        "@pid": "325/3299",
                        "text": "Jason Kim 0007"
                    },
                    {
                        "@pid": "72/6104",
                        "text": "Jonathan Berger"
                    },
                    {
                        "@pid": "98/8283",
                        "text": "Daniel Genkin"
                    },
                    {
                        "@pid": "180/7297",
                        "text": "Eyal Ronen"
                    },
                    {
                        "@pid": "35/1061",
                        "text": "Hovav Shacham"
                    },
                    {
                        "@pid": "150/9448",
                        "text": "Riad S. Wahby"
                    },
                    {
                        "@pid": "90/10901",
                        "text": "Yuval Yarom"
                    }
                ]
            },
            "title": "Checking Passwords on Leaky Computers: A Side Channel Analysis of Chrome&apos;s Password Leak Detect Protocol.",
            "venue": "USENIX Security Symposium",
            "pages": "7107-7124",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KwongW0BGRSWY23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/kwong",
            "url": "https://dblp.org/rec/conf/uss/KwongW0BGRSWY23",
            "abstract": "The scale and frequency of password database compromises has led to widespread and persistent credential stuffing attacks, in which attackers attempt to use credentials leaked from one service to compromise accounts with other services. In response, browser vendors have integrated password leakage detection tools, which automatically check the user\u2019s credentials against a list of compromised accounts upon each login, warning the user to change their password if a match is found. In particular, Google Chrome uses a centralized leakage detection service designed by Thomas et al. (USENIX Security \u201919) that aims to both preserve the user\u2019s privacy and hide the server\u2019s list of compromised credentials. In this paper, we show that Chrome\u2019s implementation of this protocol is vulnerable to several microarchitectural side-channel attacks that violate its security properties. Specifically, we demonstrate attacks against Chrome\u2019s use of the memory-hard hash function scrypt , its hash-to-elliptic curve function, and its modular inversion algorithm. While prior work discussed the theoretical possibility of side-channel attacks on scrypt , we develop new techniques that enable this attack in practice, allowing an attacker to recover the user\u2019s password with a single guess when using a dictionary attack. For modular inversion, we present a novel cryptanalysis of the Binary Extended Euclidian Algorithm (BEEA) that",
            "keywords": [
                "Password Leakage Detection",
                "Side-Channel Attacks",
                "Microarchitectural Vulnerabilities",
                "Credential Stuffing",
                "scrypt Cryptanalysis"
            ]
        },
        "url": "URL#915342",
        "sema_paperId": "cc811ed773853ec40883aac5603797807f1266ba"
    },
    {
        "@score": "1",
        "@id": "915343",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "220/3453",
                        "text": "Lukas Lamster"
                    },
                    {
                        "@pid": "326/0603",
                        "text": "Martin Unterguggenberger"
                    },
                    {
                        "@pid": "272/7215",
                        "text": "David Schrammel"
                    },
                    {
                        "@pid": "91/4831",
                        "text": "Stefan Mangard"
                    }
                ]
            },
            "title": "HashTag: Hash-based Integrity Protection for Tagged Architectures.",
            "venue": "USENIX Security Symposium",
            "pages": "2797-2814",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LamsterUSM23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/lamster",
            "url": "https://dblp.org/rec/conf/uss/LamsterUSM23",
            "abstract": "Modern computing systems rely on error-correcting codes to ensure the integrity of DRAM data. Linear checksums allow for fast detection and correction of specific error patterns. However, they do not offer sufficient protection against complex errors distributed over multiple data words and chips. Depending on the code and the error pattern, linear codes may fail to detect or even miscorrect errors, thus leading to silent data corruption. In this work, we show how compact error-correcting codes based on low-latency hashing functions allow for strong probabilistic error detection and correction while facilitating ECC bit repurposing. Our proposed design drastically lowers the expected rate of undetected errors, regardless of the underlying error patterns. By tailoring the size of our codes to the required level of integrity protection, we are able to free bits that would otherwise be required to store ECC data. We showcase how our design facilitates the efficient implementation of tagged memory architectures such as CHERI, ARM MTE, and SPARC ADI by repurposing the freed bits in commodity ECC DRAM. Thus, we harden systems against data corruption due to DRAM faults while simultaneously allowing for memory tagging without introducing additional memory accesses. We present a systematic analysis of schemes that allow memory tagging on a cache line granularity while maintaining error detection and correction capabilities, even in multi-bit fault scenarios. We evaluate our integrity protection with tagging for different use cases and show that we can store 32 bits of additional tags per cache line, twice the amount needed to implement ARM's MTE, without significantly affecting error correction capabilities. We also show how up to 51 bits can be made available while maintaining single-bit error correction.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-lamster.pdf",
            "keywords": [
                "Error-Correcting Codes",
                "Memory Integrity",
                "Tagged Architectures",
                "Data Corruption",
                "DRAM Faults"
            ]
        },
        "url": "URL#915343",
        "sema_paperId": "ed46a64074ddc4d0b5484497ef49c5baa3f4520a"
    },
    {
        "@score": "1",
        "@id": "915344",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "148/9548",
                        "text": "Elaine Lau"
                    },
                    {
                        "@pid": "54/2978",
                        "text": "Zachary Peterson"
                    }
                ]
            },
            "title": "A Research Framework and Initial Study of Browser Security for the Visually Impaired.",
            "venue": "USENIX Security Symposium",
            "pages": "4679-4696",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LauP23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/lau",
            "url": "https://dblp.org/rec/conf/uss/LauP23",
            "abstract": "The growth of web-based malware and phishing attacks has catalyzed significant advances in the research and use of interstitial warning pages and modals by a browser prior to loading the content of a suspect site. These warnings commonly use visual cues to attract users\u2019 attention, including specialized iconography, color, and the placement and size of buttons to communicate the importance of the scenario. While the efficacy of visual techniques has improved safety for sighted users, these techniques are unsuitable for blind and visually impaired users. We attribute this not to a lack of interest or technical capability by browser manufactures, where universal design is a core tenet of their engineering practices, but instead a reflection of the very real dearth of research literature to inform their choices, exacerbated by a deficit of clear methodologies for conducting studies with this population. Indeed, the challenges are manifold. In this paper, we analyze and address the methodological challenges of conducting security and privacy research with a visually impaired population, and contribute a new set of methodological best practices when conducting a study of this kind. Using our methodology, we conduct a preliminary study analyzing the experiences of the visually impaired with browser security warnings, perform a thematic analysis identifying common challenges visually impaired users experience, and present some initial solutions that could improve security for this population.",
            "keywords": [
                "Browser Security",
                "Visually Impaired Users",
                "Security Warnings",
                "User Experience",
                "Methodological Best Practices"
            ]
        },
        "url": "URL#915344",
        "sema_paperId": "b1b10ffd2d5c4d2a0d71df8e29a37acd5d4cbabe"
    },
    {
        "@score": "1",
        "@id": "915345",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "123/2117-3",
                        "text": "Hieu Le 0003"
                    },
                    {
                        "@pid": "137/1409",
                        "text": "Salma Elmalaki"
                    },
                    {
                        "@pid": "82/5866",
                        "text": "Athina Markopoulou"
                    },
                    {
                        "@pid": "83/9528",
                        "text": "Zubair Shafiq"
                    }
                ]
            },
            "title": "AutoFR: Automated Filter Rule Generation for Adblocking.",
            "venue": "USENIX Security Symposium",
            "pages": "7535-7552",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LeEMS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/le",
            "url": "https://dblp.org/rec/conf/uss/LeEMS23",
            "abstract": "Adblocking relies on filter lists, which are manually curated and maintained by a community of filter list authors. Filter list curation is a laborious process that does not scale well to a large number of sites or over time. In this paper, we introduce AutoFR, a reinforcement learning framework to fully automate the process of filter rule creation and evaluation for sites of interest. We design an algorithm based on multi-arm bandits to generate filter rules that block ads while controlling the trade-off between blocking ads and avoiding visual breakage. We test AutoFR on thousands of sites and we show that it is efficient: it takes only a few minutes to generate filter rules for a site of interest. AutoFR is effective: it generates filter rules that can block 86% of the ads, as compared to 87% by EasyList, while achieving comparable visual breakage. Furthermore, AutoFR generates filter rules that generalize well to new sites. We envision that AutoFR can assist the adblocking community in filter rule generation at scale.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-le.pdf",
            "keywords": [
                "Adblocking",
                "Filter Rule Generation",
                "Reinforcement Learning",
                "Visual Breakage",
                "Multi-arm Bandits"
            ]
        },
        "url": "URL#915345"
    },
    {
        "@score": "1",
        "@id": "915346",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "49/8558-1",
                        "text": "Yongwoo Lee 0001"
                    },
                    {
                        "@pid": "317/3956",
                        "text": "Seonyoung Cheon"
                    },
                    {
                        "@pid": "62/10307-2",
                        "text": "Dongkwan Kim 0002"
                    },
                    {
                        "@pid": "90/4053",
                        "text": "Dongyoon Lee"
                    },
                    {
                        "@pid": "29/7934",
                        "text": "Hanjun Kim 0001"
                    }
                ]
            },
            "title": "ELASM: Error-Latency-Aware Scale Management for Fully Homomorphic Encryption.",
            "venue": "USENIX Security Symposium",
            "pages": "4697-4714",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LeeCKLK23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/lee-yongwoo",
            "url": "https://dblp.org/rec/conf/uss/LeeCKLK23",
            "abstract": "Thanks to its fixed-point arithmetic and SIMD-like vectorization, among fully homomorphic encryption (FHE) schemes that allow computation on encrypted data, RNS-CKKS is widely used for privacy-preserving machine learning services. Prior works have partly automated a daunting scale management task required for RNS-CKKS fixed-point arithmetic, yet none takes an output error into consideration, preventing users from exploring a better error-latency trade-off. This work proposes a new error-and latency-aware scale management (ELASM) scheme for the RNS-CKKS FHE scheme. By actively controlling the scale of a ciphertext, one can effectively make the impact of noise on an error smaller because an error is a scaled noise introduced by an RNS-CKKS operation. ELASM explores different scale management plans that repurpose an upscale operation as an error reduction operation, estimates the output error and latency of each plan, and iteratively finds the best plan that minimizes the error-latency cost function. In addition, this work proposes a new scale-to-noise ratio (SNR) parameter and introduces fine-grained noise-aware waterlines (a minimum scale requirement) for different RNS-CKKS operations, opening a new opportunity to further improve an error-latency trade-off. This work implements the proposed ideas in the ELASM compiler along with a new FHE language and type system that enforces the RNS-CKKS constraints including SNR-based noise-aware waterlines. For ten machine and deep learning benchmarks, ELASM finds the better error and latency trade-offs (lower Pareto curves) than the state-of-the-art solutions such as EVA and Hecate.",
            "keywords": [
                "Fully Homomorphic Encryption",
                "RNS-CKKS",
                "Scale Management",
                "Error-Latency Trade-off",
                "Noise-Aware Waterlines"
            ]
        },
        "url": "URL#915346",
        "sema_paperId": "d57162e0137894e2d3b9ee603a69dcc5a96f031a"
    },
    {
        "@score": "1",
        "@id": "915347",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "301/5818",
                        "text": "Yoochan Lee"
                    },
                    {
                        "@pid": "353/7677",
                        "text": "Jinhan Kwak"
                    },
                    {
                        "@pid": "353/7592",
                        "text": "Junesoo Kang"
                    },
                    {
                        "@pid": "125/8622",
                        "text": "Yuseok Jeon"
                    },
                    {
                        "@pid": "45/7986",
                        "text": "Byoungyoung Lee"
                    }
                ]
            },
            "title": "Pspray: Timing Side-Channel based Linux Kernel Heap Exploitation Technique.",
            "venue": "USENIX Security Symposium",
            "pages": "6825-6842",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LeeKKJL23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/lee-yoochan",
            "url": "https://dblp.org/rec/conf/uss/LeeKKJL23",
            "abstract": "The stealthiness of an attack is the most vital consideration for an attacker to reach their goals without being detected. Therefore, attackers put in a great deal of effort to increase the success rate of attacks in order not to expose information on the attacker and attack attempts resulting from failures. Exploitation of the kernel, which is a prime target for the attacker, usually takes advantage of heap-based vulnerabilities, and these exploits\u2019 success rates fortunately remain low (e.g., 56.1% on average) due to the operating principle of the default Linux kernel heap allocator, SLUB. This paper presents P SPRAY , a timing side-channel attack-based exploitation technique that significantly increases the success probability of exploitation. According to our evaluation, with 10 real-world vulnerabilities, P SPRAY significantly improves the success rate of all those vulnerabilities (e.g., from 56.1% to 97.92% on average). To prevent this exploitation technique from being abused by the attacker, we further introduce a new defense mechanism to mitigate the threat of P SPRAY . After applying mitigation, the overall success rate of P SPRAY becomes similar to that from before using P SPRAY with negligible performance overhead (0.25%) and memory overhead (0.52%).",
            "keywords": [
                "Kernel Exploitation",
                "Heap Vulnerabilities",
                "Timing Side-Channel Attack",
                "Exploitation Success Rate",
                "Defense Mechanism"
            ]
        },
        "url": "URL#915347",
        "sema_paperId": "b63c75a09e8901b32188f18752fe99dbb57bdce7"
    },
    {
        "@score": "1",
        "@id": "915348",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "272/7041",
                        "text": "Guoren Li"
                    },
                    {
                        "@pid": "49/6156-12",
                        "text": "Hang Zhang 0012"
                    },
                    {
                        "@pid": "179/8187",
                        "text": "Jinmeng Zhou"
                    },
                    {
                        "@pid": "18/5040",
                        "text": "Wenbo Shen"
                    },
                    {
                        "@pid": "58/10567",
                        "text": "Yulei Sui"
                    },
                    {
                        "@pid": "31/8302",
                        "text": "Zhiyun Qian"
                    }
                ]
            },
            "title": "A Hybrid Alias Analysis and Its Application to Global Variable Protection in the Linux Kernel.",
            "venue": "USENIX Security Symposium",
            "pages": "4211-4228",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Li0ZSSQ23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/li-guoren",
            "url": "https://dblp.org/rec/conf/uss/Li0ZSSQ23",
            "abstract": "Global variables in the Linux kernel have been a common target of memory corruption attacks to achieve privilege escalation. Several potential defense mechanisms can be employed to safeguard global variables. One approach involves placing global variables in read-only pages after kernel initialization ( ro_after_init ), while another involves employing software fault isolation (SFI) to dynamically block unintended writes to these variables. To deploy such solutions in practice, a key building block is a sound, precise, and scalable alias analysis that is capable of identifying all the pointer aliases of global variables, as any pointer alias may be used for intended writes to a global variable. Unfortunately, the two existing styles of data-flow-based ( e.g., Andersen-style) alias analysis and type-based alias analysis have serious limitations in scalability and precision when applied to the Linux kernel. This paper proposes a novel and general hybrid alias analysis that unifies the two complementary approaches in a graph reachability framework using context-free-language, also known as CFL-reachability. We show our hybrid alias analysis is extremely effective, significantly and simultaneously outperforming the data-flow-based alias analysis in scalability and the type-based alias analysis in precision. Under the same time budget, our hybrid analysis finds 42% of the Linux kernel global variables protectable as ro_after_init , whereas the two separate analyses find a combined 16% only.",
            "keywords": [
                "Linux Kernel",
                "Alias Analysis",
                "Memory Corruption",
                "Global Variable Protection",
                "CFL-Reachability"
            ]
        },
        "url": "URL#915348",
        "sema_paperId": "eb3faf1d777dbbac35a8cc60eb5b372decd44b05"
    },
    {
        "@score": "1",
        "@id": "915349",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "87/6284-10",
                        "text": "Yun Li 0010"
                    },
                    {
                        "@pid": "151/0274",
                        "text": "Yufei Duan"
                    },
                    {
                        "@pid": "128/9270",
                        "text": "Zhicong Huang"
                    },
                    {
                        "@pid": "78/10002",
                        "text": "Cheng Hong"
                    },
                    {
                        "@pid": "94/3019-8",
                        "text": "Chao Zhang 0008"
                    },
                    {
                        "@pid": "66/7929",
                        "text": "Yifan Song"
                    }
                ]
            },
            "title": "Efficient 3PC for Binary Circuits with Application to Maliciously-Secure DNN Inference.",
            "venue": "USENIX Security Symposium",
            "pages": "5377-5394",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiDHHZS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/li-yun",
            "url": "https://dblp.org/rec/conf/uss/LiDHHZS23",
            "abstract": "In this work, we focus on maliciously secure 3PC for binary circuits with honest majority. While the state-of-the-art (Boyle et al. CCS 2019) has already achieved the same amortized communication as the best-known semi-honest protocol (Araki et al. CCS 2016), they suffer from a large computation overhead: when comparing with the best-known implementation result (Furukawa et al. Eurocrypt 2017) which requires 9\u00d7 communication cost of Araki et al., the protocol by Boyle et al. is around 4.5\u00d7 slower than that of Furukawa et al.\nIn this paper, we design a maliciously secure 3PC protocol that matches the same communication as Araki et al. with comparable concrete efficiency as Furukawa et al. To obtain our result, we manage to apply the distributed zero-knowledge proofs (Boneh et al. Crypto 2019) for verifying computations over Z2 by using prime fields and explore the algebraic structure of prime fields to make the computation of our protocol friendly for native CPU computation.\nExperiment results show that our protocol is around 3.5\u00d7 faster for AES circuits than Boyle et al. We also applied our protocol to the binary part (e.g. comparison and truncation) of secure deep neural network inference, and results show that we could reduce the time cost of achieving malicious security in the binary part by more than 67%.\nBesides our main contribution, we also find a hidden security issue in many of the current probabilistic truncation protocols, which may be of independent interest.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-li-yun.pdf",
            "keywords": [
                "Maliciously Secure 3PC",
                "Binary Circuits",
                "Distributed Zero-Knowledge Proofs",
                "Secure DNN Inference",
                "Probabilistic Truncation Protocols"
            ]
        },
        "url": "URL#915349"
    },
    {
        "@score": "1",
        "@id": "915350",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "96/4282",
                        "text": "Rui Li"
                    },
                    {
                        "@pid": "149/2350",
                        "text": "Wenrui Diao"
                    },
                    {
                        "@pid": "322/7858",
                        "text": "Shishuai Yang"
                    },
                    {
                        "@pid": "45/63",
                        "text": "Xiangyu Liu"
                    },
                    {
                        "@pid": "47/401",
                        "text": "Shanqing Guo"
                    },
                    {
                        "@pid": "66/6560",
                        "text": "Kehuan Zhang"
                    }
                ]
            },
            "title": "Lost in Conversion: Exploit Data Structure Conversion with Attribute Loss to Break Android Systems.",
            "venue": "USENIX Security Symposium",
            "pages": "5503-5520",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiDYLGZ23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/li-rui",
            "url": "https://dblp.org/rec/conf/uss/LiDYLGZ23",
            "abstract": "Inside the operating system, the processing of configuration files tends to be complicated and involves various data operation procedures. On Android, the processing of manifest files (the principal configuration files of Android apps) correlates to multiple core system mechanisms, such as permission and component management. It is widely recognized that improperly configured manifest files can put apps at risk. Even worse, we find that vulnerable configuration data processing can be exploited by crafted manifest files to break the Android system mechanisms, even achieving privilege escalation. In this work, we systematically studied the Android manifest processing procedures and discovered a new category of vulnerabilities called the Evil Twins flaw. In brief, during the processing of twin manifest elements (with the same name but different attributes), the ill-considered data structure conversion (e.g., from List to Map without considering the duplication issue) merges them into one item with attribute loss, further resulting in system configuration inconsistency, i.e., potential security risks. To detect the Evil Twins flaw lying in the Android OS, we designed an automated analysis tool, T WIN D ROID , to identify the data structure conversions with attribute loss and then manually confirm the vulnerabilities. With T WIN D ROID , we assessed the code of AOSP Android 11 & 12. Finally, 47 suspicious methods were reported, and four vulnerabilities were identified, which can be exploited to achieve permission escalation and revoking prevention. All discovered vulnerabilities have been acknowledged by Google, and three CVE IDs have been assigned.",
            "keywords": [
                "Android Security",
                "Manifest File Processing",
                "Evil Twins Flaw",
                "Data Structure Conversion",
                "Privilege Escalation Vulnerabilities"
            ]
        },
        "url": "URL#915350",
        "sema_paperId": "8951647af8bb3bbe5c92519c570cc27143d7a1a0"
    },
    {
        "@score": "1",
        "@id": "915351",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "04/8388",
                        "text": "Xinfeng Li"
                    },
                    {
                        "@pid": "39/1697-1",
                        "text": "Xiaoyu Ji 0001"
                    },
                    {
                        "@pid": "46/1162-1",
                        "text": "Chen Yan 0001"
                    },
                    {
                        "@pid": "220/2509",
                        "text": "Chaohao Li"
                    },
                    {
                        "@pid": "27/2248",
                        "text": "Yichen Li"
                    },
                    {
                        "@pid": "147/1584",
                        "text": "Zhenning Zhang"
                    },
                    {
                        "@pid": "10/3878-1",
                        "text": "Wenyuan Xu 0001"
                    }
                ]
            },
            "title": "Learning Normality is Enough: A Software-based Mitigation against Inaudible Voice Attacks.",
            "venue": "USENIX Security Symposium",
            "pages": "2455-2472",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiJ0LLZX23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/li-xinfeng",
            "url": "https://dblp.org/rec/conf/uss/LiJ0LLZX23",
            "abstract": "Inaudible voice attacks silently inject malicious voice commands into voice assistants to manipulate voice-controlled devices such as smart speakers. To alleviate such threats for both existing and future devices, this paper proposes NormDetect, a software-based mitigation that can be instantly applied to a wide range of devices without requiring any hardware modification. To overcome the challenge that the attack patterns vary between devices, we design a universal detection model that does not rely on audio features or samples derived from specific devices. Unlike existing studies\u2019 supervised learning approach, we adopt unsupervised learning inspired by anomaly detection. Though the patterns of inaudible voice attacks are diverse, we find that benign audios share similar patterns in the time-frequency domain. Therefore, we can detect the attacks (the anomaly) by learning the patterns of benign audios (the normality). NormDetect maps spectrum features to a low-dimensional space, performs similarity queries, and replaces them with the standard feature embeddings for spectrum reconstruction. This results in a more significant reconstruction error for attacks than normality. Evaluation based on the 383,320 test samples we collected from 24 smart devices shows an average AUC of 99.48% and EER of 2.23%, suggesting the effectiveness of NormDetect in detecting inaudible voice attacks.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-li-xinfeng.pdf",
            "keywords": [
                "Inaudible Voice Attacks",
                "Voice Assistants",
                "Anomaly Detection",
                "Benign Audio Patterns",
                "NormDetect"
            ]
        },
        "url": "URL#915351",
        "sema_paperId": "a69d4f72133d1e7331b62c4a7ee09597910c1bed"
    },
    {
        "@score": "1",
        "@id": "915352",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "33/2805-13",
                        "text": "Ang Li 0013"
                    },
                    {
                        "@pid": "12/3242",
                        "text": "Jiawei Li"
                    },
                    {
                        "@pid": "227/8113",
                        "text": "Dianqi Han"
                    },
                    {
                        "@pid": "04/3348-91",
                        "text": "Yan Zhang 0091"
                    },
                    {
                        "@pid": "75/4601-42",
                        "text": "Tao Li 0042"
                    },
                    {
                        "@pid": "42/5105-1",
                        "text": "Ting Zhu 0001"
                    },
                    {
                        "@pid": "83/888",
                        "text": "Yanchao Zhang"
                    }
                ]
            },
            "title": "PhyAuth: Physical-Layer Message Authentication for ZigBee Networks.",
            "venue": "USENIX Security Symposium",
            "pages": "1-18",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiLH0L0Z23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/li-ang",
            "url": "https://dblp.org/rec/conf/uss/LiLH0L0Z23",
            "abstract": "ZigBee is a popular wireless communication standard for Internet of Things (IoT) networks. Since each ZigBee network uses hop-by-hop network-layer message authentication based on a common network key, it is highly vulnerable to packet-injection attacks, in which the adversary exploits the compromised network key to inject arbitrary fake packets from any spoofed address to disrupt network operations and consume the network/device resources. In this paper, we present PhyAuth, a PHY hop-by-hop message authentication framework to defend against packet-injection attacks in ZigBee networks. The key idea of PhyAuth is to let each ZigBee transmitter embed into its PHY signals a PHY one-time pass-word (called POTP) derived from a device-speci\ufb01c secret key and an ef\ufb01cient cryptographic hash function. An authentic POTP serves as the transmitter\u2019s PHY transmission permission for the corresponding packet. PhyAuth provides three schemes to embed, detect, and verify POTPs based on different features of ZigBee PHY signals. In addition, PhyAuth involves lightweight PHY signal processing and no change to the ZigBee protocol stack. Comprehensive USRP experiments con\ufb01rm that PhyAuth can ef\ufb01ciently detect fake packets with very low false-positive and false-negative rates while having a negligible negative impact on normal data transmissions.",
            "keywords": [
                "ZigBee Networks",
                "Message Authentication",
                "Packet-Injection Attacks",
                "PHY Signal Processing",
                "One-Time Password (POTP)"
            ]
        },
        "url": "URL#915352",
        "sema_paperId": "0e47f0a1800473c1d0778ab79c5c917f919c5dd9"
    },
    {
        "@score": "1",
        "@id": "915353",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "40/1491-108",
                        "text": "Xiang Li 0108"
                    },
                    {
                        "@pid": "223/6794",
                        "text": "Chaoyi Lu"
                    },
                    {
                        "@pid": "89/10754",
                        "text": "Baojun Liu"
                    },
                    {
                        "@pid": "44/8211",
                        "text": "Qifan Zhang"
                    },
                    {
                        "@pid": "62/4119-1",
                        "text": "Zhou Li 0001"
                    },
                    {
                        "@pid": "36/5143",
                        "text": "Haixin Duan"
                    },
                    {
                        "@pid": "181/2688-2",
                        "text": "Qi Li 0002"
                    }
                ]
            },
            "title": "The Maginot Line: Attacking the Boundary of DNS Caching Protection.",
            "venue": "USENIX Security Symposium",
            "pages": "3153-3170",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiLLZ0D023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/li-xiang",
            "url": "https://dblp.org/rec/conf/uss/LiLLZ0D023",
            "abstract": "In this paper, we report M AGINOT DNS, a powerful cache poisoning attack against DNS servers that simultaneously act as recursive resolvers and forwarders (termed as CDNS ). The attack is made possible through exploiting vulnerabilities in the bailiwick checking algorithms, one of the cornerstones of DNS security since the 1990s, and affects multiple versions of popular DNS software, including BIND and Microsoft DNS. Through \ufb01eld tests, we \ufb01nd that the attack is potent, allowing attackers to take over entire DNS zones, even including Top-Level Domains (e.g., .com and .net ). Through a large-scale measurement study, we also con\ufb01rm the extensive usage of CDNSes in real-world networks (up to 41.8% of our probed open DNS servers) and \ufb01nd that at least 35.5% of all CDNSes are vulnerable to M AGINOT DNS. After interviews with ISPs, we show a wide range of CDNS use cases and real-world attacks. We have reported all the discovered vulnerabilities to DNS software vendors and received acknowledgments from all of them. 3 CVE-ids have been published, and 2 vendors have \ufb01xed their software. Our study brings attention to the implementation inconsistency of security checking logic in different DNS software and server modes (i.e., recursive re-solvers and forwarders), and we call for standardization and agreements among",
            "keywords": [
                "DNS Security",
                "Cache Poisoning",
                "Bailiwick Checking",
                "Recursive Resolvers",
                "Forwarders Vulnerabilities"
            ]
        },
        "url": "URL#915353",
        "sema_paperId": "fba9779518b2973278ed490fd44804e3f697ad61"
    },
    {
        "@score": "1",
        "@id": "915354",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "46/1349",
                        "text": "Xiaoguang Li"
                    },
                    {
                        "@pid": "l/NinghuiLi",
                        "text": "Ninghui Li"
                    },
                    {
                        "@pid": "130/3626",
                        "text": "Wenhai Sun"
                    },
                    {
                        "@pid": "03/9437",
                        "text": "Neil Zhenqiang Gong"
                    },
                    {
                        "@pid": "l/HuiLi6",
                        "text": "Hui Li 0006"
                    }
                ]
            },
            "title": "Fine-grained Poisoning Attack to Local Differential Privacy Protocols for Mean and Variance Estimation.",
            "venue": "USENIX Security Symposium",
            "pages": "1739-1756",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiLSG023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/li-xiaoguang",
            "url": "https://dblp.org/rec/conf/uss/LiLSG023",
            "abstract": "Although local differential privacy (LDP) protects individual users' data from inference by an untrusted data curator, recent studies show that an attacker can launch a data poisoning attack from the user side to inject carefully-crafted bogus data into the LDP protocols in order to maximally skew the final estimate by the data curator. In this work, we further advance this knowledge by proposing a new fine-grained attack, which allows the attacker to fine-tune and simultaneously manipulate mean and variance estimations that are popular analytical tasks for many real-world applications. To accomplish this goal, the attack leverages the characteristics of LDP to inject fake data into the output domain of the local LDP instance. We call our attack the output poisoning attack (OPA). We observe a security-privacy consistency where a small privacy loss enhances the security of LDP, which contradicts the known security-privacy trade-off from prior work. We further study the consistency and reveal a more holistic view of the threat landscape of data poisoning attacks on LDP. We comprehensively evaluate our attack against a baseline attack that intuitively provides false input to LDP. The experimental results show that OPA outperforms the baseline on three real-world datasets. We also propose a novel defense method that can recover the result accuracy from polluted data collection and offer insight into the secure LDP design.",
            "keywords": [
                "Local Differential Privacy",
                "Data Poisoning Attack",
                "Mean Estimation",
                "Variance Estimation",
                "Output Poisoning Attack (OPA)"
            ]
        },
        "url": "URL#915354",
        "sema_paperId": "ce75872fa42fdd1afa5b5ee02334cbbfc4472c9b"
    },
    {
        "@score": "1",
        "@id": "915355",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "06/721-7",
                        "text": "Wen Li 0007"
                    },
                    {
                        "@pid": "353/7682",
                        "text": "Jinyang Ruan"
                    },
                    {
                        "@pid": "353/7616",
                        "text": "Guangbei Yi"
                    },
                    {
                        "@pid": "49/225-5",
                        "text": "Long Cheng 0005"
                    },
                    {
                        "@pid": "53/1565",
                        "text": "Xiapu Luo"
                    },
                    {
                        "@pid": "117/7062",
                        "text": "Haipeng Cai"
                    }
                ]
            },
            "title": "PolyFuzz: Holistic Greybox Fuzzing of Multi-Language Systems.",
            "venue": "USENIX Security Symposium",
            "pages": "1379-1396",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiRY0LC23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/li-wen",
            "url": "https://dblp.org/rec/conf/uss/LiRY0LC23",
            "abstract": "While offering many advantages during software process, the practice of using multiple programming languages in constructing one software system also introduces additional security vulnerabilities in the resulting code. As this practice becomes increasingly prevalent, securing multi-language systems is of pressing criticality. Fuzzing has been a powerful security testing technique, yet existing fuzzers are commonly limited to single-language software. In this paper, we present P OLY F UZZ , a greybox fuzzer that holistically fuzzes a given multi-language system through cross-language coverage feedback and explicit modeling of the semantic relationships between (various segments of) program inputs and branch predicates across languages. P OLY F UZZ is extensible for supporting multilingual code written in different language combinations and has been implemented for C, Python, Java, and their combinations. We evaluated P OLY F UZZ versus state-of-the-art single-language fuzzers for these languages as baselines against 15 real-world multi-language systems and 15 single-language benchmarks. P OLY F UZZ achieved 25.3\u201352.3% higher code coverage and found 1\u201310 more bugs than the baselines against the multi-lingual programs, and even 10-20% higher coverage against the single-language benchmarks. In total, P OLY F UZZ has enabled the discovery of 12 previously unknown multilingual vulnerabilities and 2 single-language ones, with 5 CVEs assigned. Our results show great promises of P OLY F UZZ for cross-language fuzzing, while justifying the strong need for",
            "keywords": [
                "Multi-Language Systems",
                "Greybox Fuzzing",
                "Cross-Language Coverage",
                "Security Vulnerabilities",
                "Fuzz Testing"
            ]
        },
        "url": "URL#915355",
        "sema_paperId": "84127fcaa4f0c089baa2bc512563634c3f2fa6fc"
    },
    {
        "@score": "1",
        "@id": "915356",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "10/1143-23",
                        "text": "Zheng Li 0023"
                    },
                    {
                        "@pid": "24/3024-6",
                        "text": "Ning Yu 0006"
                    },
                    {
                        "@pid": "41/506-1",
                        "text": "Ahmed Salem 0001"
                    },
                    {
                        "@pid": "b/MichaelBackes1",
                        "text": "Michael Backes 0001"
                    },
                    {
                        "@pid": "07/5701",
                        "text": "Mario Fritz"
                    },
                    {
                        "@pid": "06/6785-16",
                        "text": "Yang Zhang 0016"
                    }
                ]
            },
            "title": "UnGANable: Defending Against GAN-based Face Manipulation.",
            "venue": "USENIX Security Symposium",
            "pages": "7213-7230",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiY00F023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/li-zheng",
            "url": "https://dblp.org/rec/conf/uss/LiY00F023",
            "abstract": "Deepfakes pose severe threats of visual misinformation to our society. One representative deepfake application is face manipulation that modifies a victim's facial attributes in an image, e.g., changing her age or hair color. The state-of-the-art face manipulation techniques rely on Generative Adversarial Networks (GANs). In this paper, we propose the first defense system, namely UnGANable, against GAN-inversion-based face manipulation.  In specific, UnGANable focuses on defending GAN inversion, an essential step for face manipulation. Its core technique is to search for alternative images (called cloaked images) around the original images (called target images) in image space.  When posted online, these cloaked images can jeopardize the GAN inversion process. We consider two state-of-the-art inversion techniques including optimization-based inversion and hybrid inversion, and design five different defenses under five scenarios depending on the defender's background knowledge. Extensive experiments on four popular GAN models trained on two benchmark face datasets show that UnGANable achieves remarkable effectiveness and utility performance, and outperforms multiple baseline methods. We further investigate four adaptive adversaries to bypass UnGANable and show that some of them are slightly effective.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-li-zheng.pdf",
            "keywords": [
                "Deepfake Detection",
                "Face Manipulation",
                "GAN Inversion",
                "Cloaked Images",
                "Visual Misinformation"
            ]
        },
        "url": "URL#915356"
    },
    {
        "@score": "1",
        "@id": "915357",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "57/2281-6",
                        "text": "Shuai Li 0006"
                    },
                    {
                        "@pid": "55/11040",
                        "text": "Zhemin Yang"
                    },
                    {
                        "@pid": "153/5855",
                        "text": "Guangliang Yang 0001"
                    },
                    {
                        "@pid": "353/7601",
                        "text": "Hange Zhang"
                    },
                    {
                        "@pid": "28/5824",
                        "text": "Nan Hua"
                    },
                    {
                        "@pid": "343/3113",
                        "text": "Yurui Huang"
                    },
                    {
                        "@pid": "02/1640-2",
                        "text": "Min Yang 0002"
                    }
                ]
            },
            "title": "Notice the Imposter! A Study on User Tag Spoofing Attack in Mobile Apps.",
            "venue": "USENIX Security Symposium",
            "pages": "5485-5501",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiY0ZHH023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/li-shuai",
            "url": "https://dblp.org/rec/conf/uss/LiY0ZHH023",
            "abstract": "Recent years have witnessed the rapid development of mobile services, spanning almost every field. To characterize users and provide personalized and targeted services, user tag sharing, which labels users and shares their data, is becoming increasingly popular. Its security attracts more and more attention, and a series of privacy issues have been reported in several specific services. However, up to now, there still lacked a thorough and comprehensive understanding of the characteristics and security of user tag sharing. In this work, we conduct a systematic study of user tag sharing and its security. We first model user tag sharing with three phases, and discover that the privacy security issue commonly exists in practice. We generalize and formalize the privacy issue as user tag spoofing. Then, we propose a novel network-level smart fuzzing approach, called UTSFuzzer , against user tag spoofing. The key idea behind UTSFuzzer is to explore a large number of valid user tag values as input to imitate user tag spoofing against real-world mobile services. By applying UTSFuzzer on a large scale of real-world popular apps, we verify the effectiveness of UTSFuzzer and unveil that 100 mobile apps (including 115 mobile services) are vulnerable to user tag spoofing. The accumulated installations of all affected apps (users) reach more than 413 million. Additionally, UTSFuzzer shows user tag spoofing can cause serious attack efforts, including economic loss and user activity monitoring.",
            "keywords": [
                "User Tag Sharing",
                "Mobile App Security",
                "User Tag Spoofing",
                "Privacy Issues",
                "UTSFuzzer"
            ]
        },
        "url": "URL#915357",
        "sema_paperId": "1ed00753ad0ff89c8c018a0c556453660559db97"
    },
    {
        "@score": "1",
        "@id": "915358",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "353/7582",
                        "text": "Miaoqian Lin"
                    },
                    {
                        "@pid": "c/KaiChen12",
                        "text": "Kai Chen 0012"
                    },
                    {
                        "@pid": "181/1848-11",
                        "text": "Yang Xiao 0011"
                    }
                ]
            },
            "title": "Detecting API Post-Handling Bugs Using Code and Description in Patches.",
            "venue": "USENIX Security Symposium",
            "pages": "3709-3726",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Lin0023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/lin",
            "url": "https://dblp.org/rec/conf/uss/Lin0023",
            "abstract": "Program APIs must be used in accordance with their specifications. API post-handling (APH) is a common type of specification that deals with APIs\u2019 return checks, resource releases, etc. Violation of APH specifications (aka, APH bug) could cause serious security problems, including memory corruption, resource leaks, etc. API documents, as a good source of APH specifications, are often analyzed to extract specifications for APH bug detection. However, documents are not always complete, which makes many bugs fail to be detected. In this paper, we find that patches could be another good source of APH specifications. In addition to the code differences introduced by patches, patches also contain descriptions, which help to accurately extract APH specifications. In order to make bug detection accurate and efficient, we design API specification-based graph for reducing the number of paths to be analyzed and perform partial path-sensitive analysis. We implement a prototype named APHP (API Post-Handling bugs detector using Patches) for static detection of APH bugs. We evaluate APHP on four popular open-source programs, including the Linux kernel, QEMU, Git and Redis, and detect 410 new bugs, outperforming existing state-of-the-art work. 216 of the bugs have been confirmed by the maintainers, and 2 CVEs have been assigned. Some bugs have existed for more than 12 years. Till now, many submitted patches have been backported to long-term stable versions of the Linux kernel.",
            "keywords": [
                "API Post-Handling",
                "Bug Detection",
                "Static Analysis",
                "Patches",
                "Specification Violations"
            ]
        },
        "url": "URL#915358",
        "sema_paperId": "02ada67e4bd9715fda97867a1f30016ea2f0b63c"
    },
    {
        "@score": "1",
        "@id": "915359",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "301/5834",
                        "text": "Ruofan Liu"
                    },
                    {
                        "@pid": "77/1513-1",
                        "text": "Yun Lin 0001"
                    },
                    {
                        "@pid": "57/4707",
                        "text": "Yifan Zhang"
                    },
                    {
                        "@pid": "353/7604",
                        "text": "Penn Han Lee"
                    },
                    {
                        "@pid": "33/6517",
                        "text": "Jin Song Dong"
                    }
                ]
            },
            "title": "Knowledge Expansion and Counterfactual Interaction for Reference-Based Phishing Detection.",
            "venue": "USENIX Security Symposium",
            "pages": "4139-4156",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Liu0ZLD23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/liu-ruofan",
            "url": "https://dblp.org/rec/conf/uss/Liu0ZLD23",
            "abstract": "Phishing attacks have been increasingly prevalent in recent years, significantly eroding societal trust. As a state-of-the-art defense solution, reference-based phishing detection excels in terms of accuracy, timeliness, and explainability. A reference-based solution detects phishing webpages by analyzing their domain-brand consistencies, utilizing a predefined reference list of domains and brand representations such as logos and screenshots. However, the predefined references have limitations in differentiating between legitimate webpages and those of unknown brands. This issue is particularly pronounced when new and emerging brands become targets of attacks. In this work, we propose DynaPhish as a remedy for reference-based phishing detection, going beyond the predefined reference list. DynaPhish assumes a runtime deployment scenario and (1) actively expands a dynamic reference list, and (2) supports the detection of brandless webpages with convincing counterfactual explanations. For the former, we propose a legitimacy-validation technique for the genuine-ness of the added references. For the latter, we propose a counterfactual interaction technique to verify the webpage\u2019s legitimacy even without brand information. To evaluate Dy-naPhish, we constructed the largest dynamic phishing dataset consisting of 6344 interactable phishing webpages, to the best of our knowledge. Our experimental results demonstrate that DynaPhish significantly improves the recall of the state-of-the-art approach by 28% while maintaining a negligible cost in precision. Our controlled wild study on the emerging webpages further shows that DynaPhish significantly (1) improves the state-of-the-art by finding on average 9 times more real-world phishing webpages and (2) discovers many uncon-ventional brands as the phishing targets. Our code is available at https://github.com/code-philia/Dynaphish .",
            "keywords": [
                "Phishing Detection",
                "Reference-Based Detection",
                "Dynamic Reference List",
                "Legitimacy Validation",
                "Counterfactual Explanations"
            ]
        },
        "url": "URL#915359",
        "sema_paperId": "ed8f07f91c8dec70ec071cb24f6ff429dc61196b"
    },
    {
        "@score": "1",
        "@id": "915360",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "177/5658",
                        "text": "Aishan Liu"
                    },
                    {
                        "@pid": "73/273",
                        "text": "Jun Guo"
                    },
                    {
                        "@pid": "202/9216",
                        "text": "Jiakai Wang"
                    },
                    {
                        "@pid": "205/8767",
                        "text": "Siyuan Liang"
                    },
                    {
                        "@pid": "250/2018",
                        "text": "Renshuai Tao"
                    },
                    {
                        "@pid": "124/2075",
                        "text": "Wenbo Zhou"
                    },
                    {
                        "@pid": "95/6404-6",
                        "text": "Cong Liu 0006"
                    },
                    {
                        "@pid": "55/7901-1",
                        "text": "Xianglong Liu 0001"
                    },
                    {
                        "@pid": "46/3391",
                        "text": "Dacheng Tao"
                    }
                ]
            },
            "title": "X-Adv: Physical Adversarial Object Attacks against X-ray Prohibited Item Detection.",
            "venue": "USENIX Security Symposium",
            "pages": "3781-3798",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiuGWLTZL0T23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/liu-aishan",
            "url": "https://dblp.org/rec/conf/uss/LiuGWLTZL0T23",
            "abstract": "Adversarial attacks are valuable for evaluating the robustness of deep learning models. Existing attacks are primarily conducted on the visible light spectrum (e.g., pixel-wise texture perturbation). However, attacks targeting texture-free X-ray images remain underexplored, despite the widespread application of X-ray imaging in safety-critical scenarios such as the X-ray detection of prohibited items. In this paper, we take the first step toward the study of adversarial attacks targeted at X-ray prohibited item detection, and reveal the serious threats posed by such attacks in this safety-critical scenario. Specifically, we posit that successful physical adversarial attacks in this scenario should be specially designed to circumvent the challenges posed by color/texture fading and complex overlapping. To this end, we propose X-adv to generate physically printable metals that act as an adversarial agent capable of deceiving X-ray detectors when placed in luggage. To resolve the issues associated with color/texture fading, we develop a differentiable converter that facilitates the generation of 3D-printable objects with adversarial shapes, using the gradients of a surrogate model rather than directly generating adversarial textures. To place the printed 3D adversarial objects in luggage with complex overlapped instances, we design a policy-based reinforcement learning strategy to find locations eliciting strong attack performance in worst-case scenarios whereby the prohibited items are heavily occluded by other items. To verify the effectiveness of the proposed X-Adv, we conduct extensive experiments in both the digital and the physical world (employing a commercial X-ray security inspection system for the latter case). Furthermore, we present the physical-world X-ray adversarial attack dataset XAD.",
            "keywords": [
                "X-ray Imaging",
                "Adversarial Attacks",
                "Prohibited Item Detection",
                "Physical Adversarial Objects",
                "XAD Dataset"
            ]
        },
        "url": "URL#915360",
        "sema_paperId": "c5a3ae2370c773665f973da3d76dfc8086d42d28"
    },
    {
        "@score": "1",
        "@id": "915361",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "191/7789-1",
                        "text": "Sihang Liu 0001"
                    },
                    {
                        "@pid": "353/7568",
                        "text": "Suraaj Kanniwadi"
                    },
                    {
                        "@pid": "223/9857",
                        "text": "Martin Schwarzl"
                    },
                    {
                        "@pid": "280/4649",
                        "text": "Andreas Kogler"
                    },
                    {
                        "@pid": "166/1494",
                        "text": "Daniel Gruss"
                    },
                    {
                        "@pid": "01/9032",
                        "text": "Samira Manabi Khan"
                    }
                ]
            },
            "title": "Side-Channel Attacks on Optane Persistent Memory.",
            "venue": "USENIX Security Symposium",
            "pages": "6807-6824",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiuKSKGK23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/liu-sihang",
            "url": "https://dblp.org/rec/conf/uss/LiuKSKGK23",
            "abstract": "There is a constant evolution of technology for cloud environments, including the development of new memory storage technology, such as persistent memory. The newly-released Intel Optane persistent memory provides high-performance, persistent, and byte-addressable access for storage-class applications in data centers. While Optane\u2019s direct data management is fast and efficient, it is unclear whether it comes with undesirable security implications. This is problematic, as cloud tenants are physically co-located on the same hardware. In this paper, we present the first side-channel security analysis of Intel Optane persistent memory. We reverse-engineer the internal cache hierarchy, cache sizes, associativity, replacement policies, and wear-leveling mechanism of the Optane memory. Based on this reverse-engineering, we construct four new attack primitives on Optane\u2019s internal components. We then present four case studies using these attack primitives. First, we present local covert channels based on Optane\u2019s internal caching. Second, we demonstrate a keystroke side-channel attack on a remote user via Intel\u2019s Optane-optimized key-value store, pmemkv . Third, we study a fully remote covert channel through pmemkv . Fourth, we present our Note Board attack, also through pmemkv , enabling two parties to store and exchange messages covertly across long time gaps and even power cycles of the server. Finally, we discuss mitigations against our attacks.",
            "keywords": [
                "Persistent Memory",
                "Side-Channel Attacks",
                "Intel Optane",
                "Covert Channels",
                "Keystroke Side-Channel Attack"
            ]
        },
        "url": "URL#915361",
        "sema_paperId": "5eda7a05d6fb3eda26deaf909c827903b77b4127"
    },
    {
        "@score": "1",
        "@id": "915362",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "76/1820",
                        "text": "Xin Liu"
                    },
                    {
                        "@pid": "35/7092",
                        "text": "Wei Wang"
                    },
                    {
                        "@pid": "313/9155",
                        "text": "Guanqun Song"
                    },
                    {
                        "@pid": "42/5105",
                        "text": "Ting Zhu"
                    }
                ]
            },
            "title": "LightThief: Your Optical Communication Information is Stolen behind the Wall.",
            "venue": "USENIX Security Symposium",
            "pages": "5325-5339",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiuWSZ23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/liu-xin",
            "url": "https://dblp.org/rec/conf/uss/LiuWSZ23",
            "abstract": "Optical Wireless Communication (OWC) is a viable and promising alternative to traditional Radio Frequency (RF) based communication links. Especially for the security issue, since light does not penetrate through opaque objects, OWC is considered gaining certain intrinsic security benefits. The only related work eavesdrops on OWC by detecting the electromagnetic signal leaking from an open-source research platform for OWC. However, electromagnetic compatibility (EMC) regulations require Commercial Off-The-Shelf (COTS) OWC products to minimize electromagnetic leakage, securing OWC from the previous eavesdropping. In this paper, we propose a new class of eavesdropping, LightThief, that can directly convert optical signals into RF signals without complicated baseband processing circuits and power consumption, making it lightweight, unlimited lasting, and easy to disguise. Specifically, LightThief is constructed by coupling a photodiode (PD) to an antenna. Since OWC adopts intensity modulation to transmit data, light intensity change can modify the PD impedance, causing the antenna to reflect different amounts of RF signals to enable data breaches. The attacker outside the room can then detect and decode the RF signals without resistance by EMC regulations. We demonstrate the effectiveness of our attack on a Commercial Off-The-Shelf (COTS) OWC product, which shows successful eavesdropping through physical barriers such as walls. We also discuss potential defense strategies to secure OWC systems from LightThief.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-liu-xin.pdf",
            "keywords": [
                "Optical Wireless Communication",
                "Eavesdropping",
                "LightThief",
                "Data Breach",
                "RF Signal Detection"
            ]
        },
        "url": "URL#915362",
        "sema_paperId": "e68370d3c972757dbb22df385b6445c9fe1c0dd5"
    },
    {
        "@score": "1",
        "@id": "915363",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "45/4076",
                        "text": "Hongyi Liu"
                    },
                    {
                        "@pid": "217/0857",
                        "text": "Jiarong Xing"
                    },
                    {
                        "@pid": "246/5079",
                        "text": "Yibo Huang 0005"
                    },
                    {
                        "@pid": "151/7537",
                        "text": "Danyang Zhuo"
                    },
                    {
                        "@pid": "14/3973",
                        "text": "Srinivas Devadas"
                    },
                    {
                        "@pid": "59/146-1",
                        "text": "Ang Chen 0001"
                    }
                ]
            },
            "title": "Remote Direct Memory Introspection.",
            "venue": "USENIX Security Symposium",
            "pages": "6043-6060",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiuXHZD023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/liu-hongyi",
            "url": "https://dblp.org/rec/conf/uss/LiuXHZD023",
            "abstract": "This artifact appendix describes the workflow to setup and run RDMI. It includes an artifact check-list, description of hardware/software dependencies to install RDMI as well as setup instructions and experiment workflows. Please refer to the GitHub repository for further installation and execution details.",
            "keywords": [
                "Remote Direct Memory Introspection",
                "Memory Analysis",
                "Virtualization",
                "Hardware Dependencies",
                "Experiment Workflows"
            ]
        },
        "url": "URL#915363",
        "sema_paperId": "7901b79741d948195ae00c67afd3cda1f9b86dc2"
    },
    {
        "@score": "1",
        "@id": "915364",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "193/9286",
                        "text": "Zhibo Liu"
                    },
                    {
                        "@pid": "295/5277",
                        "text": "Yuanyuan Yuan"
                    },
                    {
                        "@pid": "42/1503-11",
                        "text": "Shuai Wang 0011"
                    },
                    {
                        "@pid": "127/0713",
                        "text": "Xiaofei Xie"
                    },
                    {
                        "@pid": "20/6534-3",
                        "text": "Lei Ma 0003"
                    }
                ]
            },
            "title": "Decompiling x86 Deep Neural Network Executables.",
            "venue": "USENIX Security Symposium",
            "pages": "7357-7374",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiuY0X023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/liu-zhibo",
            "url": "https://dblp.org/rec/conf/uss/LiuY0X023",
            "abstract": "Due to their widespread use on heterogeneous hardware devices, deep learning (DL) models are compiled into executables by DL compilers to fully leverage low-level hardware primitives. This approach allows DL computations to be undertaken at low cost across a variety of computing platforms, including CPUs, GPUs, and various hardware accelerators. We present BTD (Bin to DNN), a decompiler for deep neural network (DNN) executables. BTD takes DNN executables and outputs full model specifications, including types of DNN operators, network topology, dimensions, and parameters that are (nearly) identical to those of the input models. BTD delivers a practical framework to process DNN executables compiled by different DL compilers and with full optimizations enabled on x86 platforms. It employs learning-based techniques to infer DNN operators, dynamic analysis to reveal network architectures, and symbolic execution to facilitate inferring dimensions and parameters of DNN operators. Our evaluation reveals that BTD enables accurate recovery of full specifications of complex DNNs with millions of parameters (e.g., ResNet). The recovered DNN specifications can be re-compiled into a new DNN executable exhibiting identical behavior to the input executable. We show that BTD can boost two representative attacks, adversarial example generation and knowledge stealing, against DNN executables. We also demonstrate cross-architecture legacy code reuse using BTD, and envision BTD being used for other critical downstream tasks like DNN security hardening and patching.",
            "keywords": [
                "DNN Decompilation",
                "Executable Recovery",
                "Model Specification Extraction",
                "Dynamic Analysis",
                "Symbolic Execution"
            ]
        },
        "url": "URL#915364",
        "sema_paperId": "51c085badf6ef12573d5b80ba614d84aa809dcfd"
    },
    {
        "@score": "1",
        "@id": "915365",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "231/4234",
                        "text": "Wen-jie Lu"
                    },
                    {
                        "@pid": "128/9270",
                        "text": "Zhicong Huang"
                    },
                    {
                        "@pid": "04/6390",
                        "text": "Qizhi Zhang"
                    },
                    {
                        "@pid": "82/8599",
                        "text": "Yuchen Wang"
                    },
                    {
                        "@pid": "78/10002",
                        "text": "Cheng Hong"
                    }
                ]
            },
            "title": "Squirrel: A Scalable Secure Two-Party Computation Framework for Training Gradient Boosting Decision Tree.",
            "venue": "USENIX Security Symposium",
            "pages": "6435-6451",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LuHZWH23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/lu",
            "url": "https://dblp.org/rec/conf/uss/LuHZWH23",
            "abstract": "Gradient Boosting Decision Tree (GBDT) and its variants are widely used in industry, due to their high efficiency as well as strong interpretability. Secure multi-party computation allows multiple data owners to compute a function jointly while keeping their input private. In this work, we present Squirrel, a secure two-party GBDT training framework on a vertically split dataset, where two data owners each hold different features of the same data samples. Squirrel is private against semi-honest adversaries, and no sensitive intermediate information is revealed during the training process. Squirrel is also scalable to datasets with millions of samples even under a Wide Area Network (WAN).\nSquirrel achieves its high performance via several novel co-designs of the GBDT algorithms and advanced cryptography. Especially, 1) we propose a new mechanism to hide the sample distribution on each node using oblivious transfer. 2) We propose a highly optimized method for secure gradient aggregation using two lattice-based homomorphic encryption schemes. Our empirical results show that our method can be three orders of magnitude faster than the existing approaches. 3) We propose a novel protocol to evaluate the sigmoid function on secretly shared values, showing 19\u00d7-200\u00d7-fold improvements over two existing methods. Combining all these improvements, Squirrel costs less than 6 seconds per tree on a dataset with 50 thousands samples which outperforms Pivot (VLDB 2020) by more than 28\u00d7. We also show that Squirrel can scale up to datasets with more than one million samples, e.g., about 90 seconds per tree over a WAN.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-lu.pdf",
            "keywords": [
                "Secure Two-Party Computation",
                "Gradient Boosting Decision Tree",
                "Privacy Preservation",
                "Vertical Data Splitting",
                "Scalability in Machine Learning"
            ]
        },
        "url": "URL#915365"
    },
    {
        "@score": "1",
        "@id": "915366",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "250/5769",
                        "text": "Keane Lucas"
                    },
                    {
                        "@pid": "353/7643",
                        "text": "Samruddhi Pai"
                    },
                    {
                        "@pid": "68/4713",
                        "text": "Weiran Lin"
                    },
                    {
                        "@pid": "32/3440",
                        "text": "Lujo Bauer"
                    },
                    {
                        "@pid": "r/MichaelKReiter",
                        "text": "Michael K. Reiter"
                    },
                    {
                        "@pid": "136/8393",
                        "text": "Mahmood Sharif"
                    }
                ]
            },
            "title": "Adversarial Training for Raw-Binary Malware Classifiers.",
            "venue": "USENIX Security Symposium",
            "pages": "1163-1180",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LucasPLBRS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/lucas",
            "url": "https://dblp.org/rec/conf/uss/LucasPLBRS23",
            "abstract": "Machine learning (ML) models have shown promise in classifying  raw executable files (binaries) as malicious or benign with high accuracy. This has led to the increasing influence of ML-based classification methods in academic and real-world malware detection, a critical tool in cybersecurity. However, previous work provoked caution by creating variants of malicious binaries, referred to as adversarial examples, that are transformed in a functionality-preserving way to evade detection. In this work, we investigate the effectiveness of using adversarial training methods to create malware classification models that are more robust to some state-of-the-art attacks. To train our most robust models, we significantly increase the efficiency and scale of creating adversarial examples to make adversarial training practical, which has not been done before in raw-binary malware detectors. We then analyze the effects of varying the length of adversarial training, as well as analyze the effects of training with various types of attacks. We find that data augmentation does not deter state-of-the-art attacks, but that using a generic gradient-guided method, used in other discrete domains, does improve robustness. We also show that in most cases, models can be made more robust to malware-domain attacks by adversarially training them with lower-effort versions of the same attack. In the best case, we reduce one state-of-the-art attack's success rate from 90% to 5%. We also find that training with some types of attacks can increase robustness to other types of attacks. Finally, we discuss insights gained from our results, and how they can be used to more effectively train robust malware detectors.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-lucas.pdf",
            "keywords": [
                "Malware Detection",
                "Adversarial Training",
                "Raw Executable Files",
                "Adversarial Examples",
                "Robustness to Attacks"
            ]
        },
        "url": "URL#915366"
    },
    {
        "@score": "1",
        "@id": "915367",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "243/3102",
                        "text": "Nils Lukas"
                    },
                    {
                        "@pid": "26/5304",
                        "text": "Florian Kerschbaum"
                    }
                ]
            },
            "title": "PTW: Pivotal Tuning Watermarking for Pre-Trained Image Generators.",
            "venue": "USENIX Security Symposium",
            "pages": "2241-2258",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LukasK23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/lukas",
            "url": "https://dblp.org/rec/conf/uss/LukasK23",
            "abstract": "Deepfakes refer to content synthesized using deep generators, which, when misused, have the potential to erode trust in digital media. Synthesizing high-quality deepfakes requires access to large and complex generators only a few entities can train and provide. The threat is malicious users that exploit access to the provided model and generate harmful deepfakes without risking detection. Watermarking makes deepfakes detectable by embedding an identifiable code into the generator that is later extractable from its generated images. We propose Pivotal Tuning Watermarking (PTW), a method for watermarking pre-trained generators (i) three orders of magnitude faster than watermarking from scratch and (ii) without the need for any training data. We improve existing watermarking methods and scale to generators $4 \\times$ larger than related work. PTW can embed longer codes than existing methods while better preserving the generator's image quality. We propose rigorous, game-based definitions for robustness and undetectability and our study reveals that watermarking is not robust against an adaptive white-box attacker who has control over the generator's parameters. We propose an adaptive attack that can successfully remove any watermarking with access to only $200$ non-watermarked images. Our work challenges the trustworthiness of watermarking for deepfake detection when the parameters of a generator are available. Source code to reproduce our experiments is available at https://github.com/dnn-security/gan-watermark.",
            "keywords": [
                "Deepfake Detection",
                "Watermarking",
                "Image Generators",
                "Robustness",
                "Adaptive Attacks"
            ]
        },
        "url": "URL#915367",
        "sema_paperId": "21490e7bf9d501eff85cbac64352b7c93181005d"
    },
    {
        "@score": "1",
        "@id": "915368",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "352/6278",
                        "text": "Alan F. Luo"
                    },
                    {
                        "@pid": "239/0184",
                        "text": "Noel Warford"
                    },
                    {
                        "@pid": "215/5146",
                        "text": "Samuel Dooley"
                    },
                    {
                        "@pid": "93/655",
                        "text": "Rachel Greenstadt"
                    },
                    {
                        "@pid": "20/7983",
                        "text": "Michelle L. Mazurek"
                    },
                    {
                        "@pid": "128/9352",
                        "text": "Nora McDonald"
                    }
                ]
            },
            "title": "How Library IT Staff Navigate Privacy and Security Challenges and Responsibilities.",
            "venue": "USENIX Security Symposium",
            "pages": "5647-5664",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LuoWDGMM23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/luo-alan",
            "url": "https://dblp.org/rec/conf/uss/LuoWDGMM23",
            "abstract": "Libraries provide critical IT services to patrons who lack access to computational and internet resources. We conducted 12 semi-structured interviews with library IT staff to learn about their privacy and security protocols and policies, the challenges they face implementing them, and how this relates to their patrons. We frame our findings using Sen\u2019s capabilities approach and find that library IT staff are primarily concerned with protecting their patrons\u2019 privacy from threats outside their walls\u2014police, government authorities, and third parties. Despite their dedication to patron privacy, library IT staff frequently have to grapple with complex tradeoffs between providing easy, fluid, full-featured access to Internet technologies or third-party resources, protecting library infrastructure, and ensuring patron privacy.",
            "keywords": [
                "Library IT Services",
                "Patron Privacy",
                "Security Protocols",
                "Privacy Challenges",
                "Third-Party Threats"
            ]
        },
        "url": "URL#915368",
        "sema_paperId": "875279847120122110bec50b4f0bc9ac939f5fa1"
    },
    {
        "@score": "1",
        "@id": "915369",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "253/1632-2",
                        "text": "Zhengxiong Luo 0002"
                    },
                    {
                        "@pid": "265/9249",
                        "text": "Junze Yu"
                    },
                    {
                        "@pid": "253/1694",
                        "text": "Feilong Zuo"
                    },
                    {
                        "@pid": "21/5921",
                        "text": "Jianzhong Liu"
                    },
                    {
                        "@pid": "21/4633-1",
                        "text": "Yu Jiang 0001"
                    },
                    {
                        "@pid": "19/1766-2",
                        "text": "Ting Chen 0002"
                    },
                    {
                        "@pid": "04/5884",
                        "text": "Abhik Roychoudhury"
                    },
                    {
                        "@pid": "s/JiaGuangSun-1",
                        "text": "Jiaguang Sun 0001"
                    }
                ]
            },
            "title": "Bleem: Packet Sequence Oriented Fuzzing for Protocol Implementations.",
            "venue": "USENIX Security Symposium",
            "pages": "4481-4498",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LuoYZL00R023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/luo-zhengxiong",
            "url": "https://dblp.org/rec/conf/uss/LuoYZL00R023",
            "abstract": "Protocol implementations are essential components in network infrastructures. Flaws hidden in the implementations can easily render devices vulnerable to adversaries. Therefore, guaranteeing their correctness is important. However, commonly used vulnerability detection techniques, such as fuzz testing, face increasing challenges in testing these implementations due to ineffective feedback mechanisms and insuf\ufb01cient protocol state-space exploration techniques. This paper presents B LEEM , a packet-sequence-oriented black-box fuzzer for vulnerability detection of protocol implementations. Instead of focusing on individual packet generation, B LEEM generates packets on a sequence level. It provides an effective feedback mechanism by analyzing the sys-tem output sequence noninvasively, supports guided fuzzing by resorting to state-space tracking that encompasses all parties timely, and utilizes interactive traf\ufb01c information to generate protocol-logic-aware packet sequences. We evaluate B LEEM on 15 widely-used implementations of well-known protocols (e.g., TLS and QUIC). Results show that, compared to the state-of-the-art protocol fuzzers such as Peach, B LEEM achieves substantially higher branch coverage (up to 174.93% improvement) within 24 hours. Furthermore, B LEEM exposed 15 security-critical vulnerabilities in prominent protocol implementations, with 10 CVEs assigned.",
            "keywords": [
                "Protocol Fuzzing",
                "Vulnerability Detection",
                "Packet Sequence Generation",
                "State-Space Exploration",
                "Security-Critical Vulnerabilities"
            ]
        },
        "url": "URL#915369",
        "sema_paperId": "bc6d166815ef94299e562db71b12a3a7154086ee"
    },
    {
        "@score": "1",
        "@id": "915370",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "289/1355",
                        "text": "Peizhuo Lv"
                    },
                    {
                        "@pid": "303/6148",
                        "text": "Chang Yue"
                    },
                    {
                        "@pid": "232/3062",
                        "text": "Ruigang Liang"
                    },
                    {
                        "@pid": "180/3055",
                        "text": "Yunfei Yang"
                    },
                    {
                        "@pid": "65/3618",
                        "text": "Shengzhi Zhang"
                    },
                    {
                        "@pid": "307/2737",
                        "text": "Hualong Ma"
                    },
                    {
                        "@pid": "c/KaiChen12",
                        "text": "Kai Chen 0012"
                    }
                ]
            },
            "title": "A Data-free Backdoor Injection Approach in Neural Networks.",
            "venue": "USENIX Security Symposium",
            "pages": "2671-2688",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LvYLYZM023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/lv",
            "url": "https://dblp.org/rec/conf/uss/LvYLYZM023",
            "abstract": "Recently, the backdoor attack on deep neural networks (DNNs) has been extensively studied, which causes the back-doored models to behave well on benign samples, whereas performing maliciously on controlled samples (with triggers attached). Almost all existing backdoor attacks require access to the original training/testing dataset or data relevant to the main task to inject backdoors into the target models, which is unrealistic in many scenarios, e.g., private training data. In this paper, we propose a novel backdoor injection approach in a \u201cdata-free\u201d manner 1 . We collect substitute data irrelevant to the main task and reduce its volume by filtering out redundant samples to improve the efficiency of backdoor injection. We design a novel loss function for fine-tuning the original model into the backdoored one using the substitute data, and optimize the fine-tuning to balance the backdoor injection and the performance on the main task. We conduct extensive experiments on various deep learning scenarios, e.g., image classification, text classification, tabular classification, image generation, and multimodal, using different models, e.g., Convolutional Neural Networks (CNNs), Autoencoders, Transformer models, Tabular models, as well as Multimodal DNNs. The evaluation results demonstrate that our data-free backdoor injection approach can efficiently embed backdoors with a nearly 100% attack success rate, incurring an acceptable performance downgrade on the main task.",
            "keywords": [
                "Backdoor Attack",
                "Data-free Injection",
                "Model Fine-tuning",
                "Attack Success Rate",
                "Performance Downgrade"
            ]
        },
        "url": "URL#915370",
        "sema_paperId": "8b67e5744b71ba0ce370603150920522e9f5060b"
    },
    {
        "@score": "1",
        "@id": "915371",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "341/1888",
                        "text": "Allan Lyons"
                    },
                    {
                        "@pid": "220/5536",
                        "text": "Julien Gamba"
                    },
                    {
                        "@pid": "353/7680",
                        "text": "Austin Shawaga"
                    },
                    {
                        "@pid": "04/8882",
                        "text": "Joel Reardon"
                    },
                    {
                        "@pid": "98/3527",
                        "text": "Juan Tapiador"
                    },
                    {
                        "@pid": "07/1108",
                        "text": "Serge Egelman"
                    },
                    {
                        "@pid": "50/7563",
                        "text": "Narseo Vallina-Rodriguez"
                    }
                ]
            },
            "title": "Log: It&apos;s Big, It&apos;s Heavy, It&apos;s Filled with Personal Data! Measuring the Logging of Sensitive Information in the Android Ecosystem.",
            "venue": "USENIX Security Symposium",
            "pages": "2115-2132",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LyonsGSRTEV23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/lyons",
            "url": "https://dblp.org/rec/conf/uss/LyonsGSRTEV23",
            "abstract": "Android offers a shared system that multiplexes all logged data from all system components, including both the operating system and the console output of apps that run on it. A security mechanism ensures that user-space apps can only read the log entries that they create, though many \u201cprivileged\u201d apps are exempt from this restriction. This includes preloaded system apps provided by Google, the phone manufacturer, the cellular carrier, as well as those sharing the same signature. Consequently, Google advises developers to not log sensitive information to the system log. In this work, we examined the logging of sensitive data in the Android ecosystem. Using a field study, we show that most devices log some amount of user-identifying information. We show that the logging of \u201cactivity\u201d names can inadvertently reveal information about users through their app usage. We also tested whether different smartphones log personal identifiers by default, examined preinstalled apps that access the system logs, and analyzed the privacy policies of manufacturers that report collecting system logs.",
            "keywords": [
                "Android Ecosystem",
                "Sensitive Data Logging",
                "User Privacy",
                "System Logs",
                "Preinstalled Apps"
            ]
        },
        "url": "URL#915371",
        "sema_paperId": "74d408873fc48095b10448be9a9235ce6c543cf2"
    },
    {
        "@score": "1",
        "@id": "915372",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "248/1663",
                        "text": "Chenyang Lyu"
                    },
                    {
                        "@pid": "188/6025",
                        "text": "Jiacheng Xu"
                    },
                    {
                        "@pid": "07/8388",
                        "text": "Shouling Ji"
                    },
                    {
                        "@pid": "139/6932-2",
                        "text": "Xuhong Zhang 0002"
                    },
                    {
                        "@pid": "156/1247",
                        "text": "Qinying Wang"
                    },
                    {
                        "@pid": "79/7820",
                        "text": "Binbin Zhao"
                    },
                    {
                        "@pid": "269/2096",
                        "text": "Gaoning Pan"
                    },
                    {
                        "@pid": "54/6265",
                        "text": "Wei Cao"
                    },
                    {
                        "@pid": "76/185-1",
                        "text": "Peng Cheng 0001"
                    },
                    {
                        "@pid": "12/6354",
                        "text": "Raheem Beyah"
                    }
                ]
            },
            "title": "MINER: A Hybrid Data-Driven Approach for REST API Fuzzing.",
            "venue": "USENIX Security Symposium",
            "pages": "4517-4534",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LyuXJ0WZPC0B23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/lyu",
            "url": "https://dblp.org/rec/conf/uss/LyuXJ0WZPC0B23",
            "abstract": "In recent years, REST API fuzzing has emerged to explore errors on a cloud service. Its performance highly depends on the sequence construction and request generation. However, existing REST API fuzzers have trouble generating long sequences with well-constructed requests to trigger hard-to-reach states in a cloud service, which limits their performance of finding deep errors and security bugs. Further, they cannot find the specific errors caused by using undefined parameters during request generation. Therefore, in this paper, we propose a novel hybrid data-driven solution, named MINER, with three new designs working together to address the above limitations. First, MINER collects the valid sequences whose requests pass the cloud service's checking as the templates, and assigns more executions to long sequence templates. Second, to improve the generation quality of requests in a sequence template, MINER creatively leverages the state-of-the-art neural network model to predict key request parameters and provide them with appropriate parameter values. Third, MINER implements a new data-driven security rule checker to capture the new kind of errors caused by undefined parameters. We evaluate MINER against the state-of-the-art fuzzer RESTler on GitLab, Bugzilla, and WordPress via 11 REST APIs. The results demonstrate that the average pass rate of MINER is 23.42% higher than RESTler. MINER finds 97.54% more unique errors than RESTler on average and 142.86% more reproducible errors after manual analysis. We have reported all the newly found errors, and 7 of them have been confirmed as logic bugs by the corresponding vendors.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-lyu.pdf",
            "keywords": [
                "REST API Fuzzing",
                "Cloud Service Testing",
                "Error Detection",
                "Request Generation",
                "Undefined Parameters"
            ]
        },
        "url": "URL#915372"
    },
    {
        "@score": "1",
        "@id": "915373",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "174/4227",
                        "text": "Yanmao Man"
                    },
                    {
                        "@pid": "332/2911",
                        "text": "Raymond Muller"
                    },
                    {
                        "@pid": "l/MingLi3",
                        "text": "Ming Li 0003"
                    },
                    {
                        "@pid": "143/2298",
                        "text": "Z. Berkay Celik"
                    },
                    {
                        "@pid": "73/1832",
                        "text": "Ryan M. Gerdes"
                    }
                ]
            },
            "title": "That Person Moves Like A Car: Misclassification Attack Detection for Autonomous Systems Using Spatiotemporal Consistency.",
            "venue": "USENIX Security Symposium",
            "pages": "6929-6946",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ManM0CG23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/man",
            "url": "https://dblp.org/rec/conf/uss/ManM0CG23",
            "abstract": "Autonomous systems commonly rely on object detection and tracking (ODT) to perceive the environment and predict the trajectory of surrounding objects for planning purposes. An ODT\u2019s output contains object classes and tracks that are traditionally predicted independently. Recent studies have shown that ODT\u2019s output can be falsified by various perception attacks with well-crafted noise, but existing defenses are limited to specific noise injection methods and thus fail to generalize. In this work we propose PercepGuard for the detection of misclassification attacks against perception modules regardless of attack methodologies. PercepGuard exploits the spatiotemporal properties of a detected object (inherent in the tracks), and cross-checks the consistency between the track and class predictions. To improve adversarial robustness against defense-aware (adaptive) attacks, we additionally consider context data (such as ego-vehicle velocity) for contextual consistency verification, which dramatically increases the attack difficulty. Evaluations with both real-world and simulated datasets produce a FPR of 5% and a TPR of 99% against adaptive attacks. A baseline comparison confirms the advantage of leveraging temporal features. Real-world experiments with displayed and projected adversarial patches show that PercepGuard detects 96% of the attacks on average.",
            "keywords": [
                "Autonomous Systems",
                "Object Detection and Tracking",
                "Misclassification Attacks",
                "Spatiotemporal Consistency",
                "Adversarial Robustness"
            ]
        },
        "url": "URL#915373",
        "sema_paperId": "d8ce779bafc4a930230aa36721f93af7e8ca2ae1"
    },
    {
        "@score": "1",
        "@id": "915374",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "189/5385",
                        "text": "Alexander Marder"
                    },
                    {
                        "@pid": "214/6089",
                        "text": "Zesen Zhang"
                    },
                    {
                        "@pid": "68/9978",
                        "text": "Ricky K. P. Mok"
                    },
                    {
                        "@pid": "34/10957",
                        "text": "Ramakrishna Padmanabhan"
                    },
                    {
                        "@pid": "11/3626",
                        "text": "Bradley Huffaker"
                    },
                    {
                        "@pid": "12/4563",
                        "text": "Matthew Luckie"
                    },
                    {
                        "@pid": "28/5074",
                        "text": "Alberto Dainotti"
                    },
                    {
                        "@pid": "68/4966",
                        "text": "kc claffy"
                    },
                    {
                        "@pid": "s/AlexCSnoeren",
                        "text": "Alex C. Snoeren"
                    },
                    {
                        "@pid": "77/3626",
                        "text": "Aaron Schulman"
                    }
                ]
            },
            "title": "Access Denied: Assessing Physical Risks to Internet Access Networks.",
            "venue": "USENIX Security Symposium",
            "pages": "6877-6892",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MarderZMPHLDcSS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/marder",
            "url": "https://dblp.org/rec/conf/uss/MarderZMPHLDcSS23",
            "abstract": "Regional access networks play an essential role in connecting both wireline and mobile users to the Internet. Today\u2019s access networks support 5G cellular phones, cloud services, hospital and financial services, and remote work essential to the modern economy. Yet long-standing economic and architectural constraints produce points of limited redundancy that leave these networks exposed to targeted physical attacks resulting in widespread outages. This risk was dramatically shown in December 2020, when a bomb destroyed part of AT&T\u2019s regional access network in Nashville, Tennessee disabling 911 emergency dispatch, air traffic control, hospital networks, and credit card processing, among other services. We combine new techniques for analyzing access-network infrastructure deployments with measurements of large-scale outages to demonstrate the feasibility and quantify potential impacts of targeted attacks. Our study yields insights into physical attack surfaces and resiliency limits of regional access networks. We analyze potential approaches to mitigate the risks we identify and discuss drawbacks identified by network operators. We hope that our empirical evaluation will inform risk assessments and operational practices, as well as motivate further analyses of this critical infrastructure.",
            "keywords": [
                "Access Networks",
                "Physical Attacks",
                "Network Resiliency",
                "Infrastructure Vulnerabilities",
                "Targeted Outages"
            ]
        },
        "url": "URL#915374",
        "sema_paperId": "d794cdacc7f2b8668ce14cfcba63fbb50875cd54"
    },
    {
        "@score": "1",
        "@id": "915375",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "179/7489",
                        "text": "Karola Marky"
                    },
                    {
                        "@pid": "239/9770",
                        "text": "Shaun Alexander Macdonald"
                    },
                    {
                        "@pid": "210/8234",
                        "text": "Yasmeen Abdrabou"
                    },
                    {
                        "@pid": "129/9490",
                        "text": "Mohamed Khamis"
                    }
                ]
            },
            "title": "In the Quest to Protect Users from Side-Channel Attacks - A User-Centred Design Space to Mitigate Thermal Attacks on Public Payment Terminals.",
            "venue": "USENIX Security Symposium",
            "pages": "5235-5252",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MarkyMAK23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/marky",
            "url": "https://dblp.org/rec/conf/uss/MarkyMAK23",
            "abstract": "Thermal attacks are an emerging threat that enables the reconstruction of user input after interaction with a device by analysing heat traces. There are several ways to protect users from thermal attacks that require different degrees of user involvement. In this paper, we first present a structured literature review to identify 15 protection strategies. Then, we investigate user perceptions of these strategies in an online study ( N = 306). Our results show that users intuitively use protection strategies that also work against other side-channel attacks. Further, users are willing to sacrifice convenience for the sake of verifying a strategy\u2019s efficacy. Yet, an ideal holistic defence from thermal attacks is one that is readily integrated into user interfaces by manufacturers in a way that the user can verify it. Further, users like resourceless strategies that fit their habits. We use the literature review and study results to identify a user-centred design space for thermal attack protection. We conclude the paper with specific recommendations for users, device manufacturers and interface providers to better protect individuals from thermal attacks.",
            "keywords": [
                "Thermal Attacks",
                "Side-Channel Attacks",
                "User-Centred Design",
                "Protection Strategies",
                "User Perceptions"
            ]
        },
        "url": "URL#915375",
        "sema_paperId": "007d764cb4a21c3fa4240cecb283cfe7a3cf0b99"
    },
    {
        "@score": "1",
        "@id": "915376",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "331/6088",
                        "text": "Rachel McAmis"
                    },
                    {
                        "@pid": "k/TadayoshiKohno",
                        "text": "Tadayoshi Kohno"
                    }
                ]
            },
            "title": "The Writing on the Wall and 3D Digital Twins: Personal Information in (not so) Private Real Estate.",
            "venue": "USENIX Security Symposium",
            "pages": "2169-2186",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/McAmisK23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/mcamis",
            "url": "https://dblp.org/rec/conf/uss/McAmisK23",
            "abstract": "Online real estate companies are starting to offer 3D virtual tours of homes (3D digital twins). We qualitatively analyzed 44 3D home tours with personal artifacts visible on Zillow and assessed each home for the extent and type of personal information shared. Using a codebook we created, we analyzed three categories of personal information in each home: government-provided guidance of what not to share on the internet, identity information, and behavioral information. Our analysis unearthed a wide variety of sensitive information across all homes, including names, hobbies, employment and education history, product preferences (e.g., pantry items, types of cigarettes), medications, credit card numbers, passwords, and more. Based on our analysis, residents both employed privacy protections and had privacy oversights. We identify potential adversaries that might use 3D tour information, highlight additional sensitive sources of indoor space information, and discuss future tools and policy changes that could address these issues.",
            "keywords": [
                "3D Digital Twins",
                "Virtual Home Tours",
                "Personal Information Disclosure",
                "Privacy Oversights",
                "Sensitive Information in Real Estate"
            ]
        },
        "url": "URL#915376",
        "sema_paperId": "b39dbb072d2eada5f0ad3ef51a40b7ac681bbcf4"
    },
    {
        "@score": "1",
        "@id": "915377",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "345/1666",
                        "text": "Jessica McClearn"
                    },
                    {
                        "@pid": "217/9278",
                        "text": "Rikke Bjerg Jensen"
                    },
                    {
                        "@pid": "179/4692",
                        "text": "Reem Talhouk"
                    }
                ]
            },
            "title": "Othered, Silenced and Scapegoated: Understanding the Situated Security of Marginalised Populations in Lebanon.",
            "venue": "USENIX Security Symposium",
            "pages": "4625-4642",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/McClearnJT23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/mcclearn",
            "url": "https://dblp.org/rec/conf/uss/McClearnJT23",
            "abstract": "In this paper we explore the digital security experiences of marginalised populations in Lebanon such as LGBTQI+ identifying people, refugees and women. We situate our work in the post-conflict Lebanese context, which is shaped by sectarian divides, failing governance and economic collapse. We do so through an ethnographically informed study conducted in Beirut, Lebanon, in July 2022 and through interviews with 13 people with Lebanese digital and human rights expertise. Our research highlights how LGBTQI+ identifying people and refugees are scapegoated for the failings of the Lebanese government, while women who speak out against such failings are silenced. We show how government-supported incitements of violence aimed at transferring blame from the political leadership to these groups lead to amplified digital security risks for already at-risk populations. Positioning our work in broader sociological understandings of security, we discuss how the Lebanese context impacts identity and ontological security. We conclude by proposing to design for and with positive security in post-conflict settings.",
            "keywords": [
                "Digital Security",
                "Marginalised Populations",
                "LGBTQI+ Rights",
                "Post-Conflict Lebanon",
                "Identity and Ontological Security"
            ]
        },
        "url": "URL#915377",
        "sema_paperId": "43ebfcc3a705003241f8a9580507e58ffa78fa9c"
    },
    {
        "@score": "1",
        "@id": "915378",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "10/6810",
                        "text": "Robert McLaughlin"
                    },
                    {
                        "@pid": "k/ChristopherKruegel",
                        "text": "Christopher Kruegel"
                    },
                    {
                        "@pid": "v/GiovanniVigna",
                        "text": "Giovanni Vigna"
                    }
                ]
            },
            "title": "A Large Scale Study of the Ethereum Arbitrage Ecosystem.",
            "venue": "USENIX Security Symposium",
            "pages": "3295-3312",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/McLaughlinKV23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/mclaughlin",
            "url": "https://dblp.org/rec/conf/uss/McLaughlinKV23",
            "abstract": "The Ethereum blockchain rapidly became the epicenter of a complex financial ecosystem, powered by decentralized exchanges (DEXs). These exchanges form a diverse capital market where anyone can swap one type of token for another. Arbitrage trades are a normal and expected phenomenon in free capital markets, and, indeed, several recent works identify these transactions on decentralized exchanges. Unfortunately, existing studies leave significant knowledge gaps in our understanding of the system as a whole, which hinders research into the security, stability, and economic impacts of arbitrage. To address this issue, we perform two large-scale measurements over a 28-month period. First,we design a novel arbitrage identification strategy capable of analyzing over 10x more DEX applications than prior work. This uncovers 3 . 8 million arbitrages, which yield a total of $321 million in profit. Second, we design a novel arbitrage opportunity detection sys-tem, which is the first to support modern complex price models at scale. This system identifies 4 billion opportunities and would generate a weekly profit of 395 Ether (approximately $500 , 000, at the time of writing). We observe two key insights that demonstrate the usefulness of these measurements: (1) an increasing percentage of revenue is paid to the miners, which threatens consensus stability, and (2) arbitrage opportunities occasionallypersistforseveralblocks,whichimpliesthatprice-oraclemanipulationattacksmaybelesscostlythanexpected.",
            "keywords": [
                "Ethereum Arbitrage",
                "Decentralized Exchanges",
                "Arbitrage Identification",
                "Price Oracle Manipulation",
                "Consensus Stability"
            ]
        },
        "url": "URL#915378",
        "sema_paperId": "442ac10fc7b471f2cfd7eda3b3b343e26bcc687e"
    },
    {
        "@score": "1",
        "@id": "915379",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "353/7621",
                        "text": "Dino Mehmedagic"
                    },
                    {
                        "@pid": "218/1140",
                        "text": "Mohammad Rahmani Fadiheh"
                    },
                    {
                        "@pid": "85/6386-6",
                        "text": "Johannes M\u00fcller 0006"
                    },
                    {
                        "@pid": "305/9163",
                        "text": "Anna Lena Duque Ant\u00f3n"
                    },
                    {
                        "@pid": "95/2383",
                        "text": "Dominik Stoffel"
                    },
                    {
                        "@pid": "69/4734",
                        "text": "Wolfgang Kunz"
                    }
                ]
            },
            "title": "Design of Access Control Mechanisms in Systems-on-Chip with Formal Integrity Guarantees.",
            "venue": "USENIX Security Symposium",
            "pages": "2779-2796",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MehmedagicFMASK23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/mehmedagic",
            "url": "https://dblp.org/rec/conf/uss/MehmedagicFMASK23",
            "abstract": "Many SoCs employ system-level hardware access control mechanisms to ensure that security-critical operations cannot be tampered with by less trusted components of the circuit. While there are many design and veri\ufb01cation techniques for developing an access control system, continuous discoveries of new vulnerabilities in such systems suggest a need for an exhaustive veri\ufb01cation methodology to \ufb01nd and eliminate such weaknesses. This paper proposes UPEC-OI, a formal veri\ufb01cation methodology that exhaustively covers integrity vulnerabilities of an SoC-level access control system. The approach is based on iteratively checking a 2-safety interval property whose formulation does not require any explicit spec-i\ufb01cation of possible attack scenarios. The counterexamples returned by UPEC-OI can provide designers of access control hardware with valuable information on possible attack channels, allowing them to perform pinpoint \ufb01xes. We present a veri\ufb01cation-driven development methodology which formally guarantees the developed SoC\u2019s access control mechanism to be secure with respect to integrity. We evaluate the proposed approach in a case study on OpenTitan\u2019s Earl Grey SoC where we add an SoC-level access control mechanism alongside malicious IPs to model the threat. UPEC-OI was found vital to guarantee the integrity of the mechanism and was proven to be tractable for SoCs of realistic size.",
            "keywords": [
                "Systems-on-Chip",
                "Access Control Mechanisms",
                "Formal Verification",
                "Integrity Vulnerabilities",
                "UPEC-OI"
            ]
        },
        "url": "URL#915379",
        "sema_paperId": "98be319d46e9aa2ee099120305c6ff52880bc447"
    },
    {
        "@score": "1",
        "@id": "915380",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "168/2334",
                        "text": "Carlo Meijer"
                    },
                    {
                        "@pid": "150/7997",
                        "text": "Wouter Bokslag"
                    },
                    {
                        "@pid": "146/0907",
                        "text": "Jos Wetzels"
                    }
                ]
            },
            "title": "All cops are broadcasting: TETRA under scrutiny.",
            "venue": "USENIX Security Symposium",
            "pages": "7463-7479",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MeijerBW23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/meijer",
            "url": "https://dblp.org/rec/conf/uss/MeijerBW23",
            "abstract": "This paper presents the first public in-depth security analysis of TETRA (Terrestrial Trunked Radio): a European standard for trunked radio globally used by government agencies, police, prisons, emergency services and military operators. Additionally, it is widely deployed in industrial environments such as factory campuses, harbor container terminals and airports, as well as critical infrastructure such as SCADA telecontrol of oil rigs, pipelines, transportation and electric and water utilities. Authentication and encryption within TETRA are handled by secret, proprietary cryptographic cipher-suites. This secrecy thwarts public security assessments and independent academic scrutiny of the protection that TETRA claims to provide.The widespread adoption of TETRA, combined with the often sensitive nature of the communications, raises legitimate questions regarding its cryptographic resilience. In this light, we have set out to achieve two main goals. First, we demonstrate the feasibility of obtaining the underlying secret cryptographic primitives through reverse engineering. Second, we provide an initial assessment of the robustness of said primitives in the context of the protocols in which they are used.We present five serious security vulnerabilities pertaining to TETRA, two of which are deemed critical. Furthermore, we present descriptions and implementations of the primitives, enabling further academic scrutiny. Our findings have been validated in practice using a common-off-the-shelf radio on a TETRA network lab setup.More than a year ago, we started to communicate our preliminary findings through a coordinated disclosure process with several key stakeholders. During this process we have actively supported these stakeholders in the identification, development and deployment of possible mitigations.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-meijer.pdf",
            "keywords": [
                "TETRA Security",
                "Cryptographic Analysis",
                "Radio Communication",
                "Vulnerabilities Assessment",
                "Reverse Engineering"
            ]
        },
        "url": "URL#915380",
        "sema_paperId": "d13abb8ac945711e6cc6980086068523ed0e6978"
    },
    {
        "@score": "1",
        "@id": "915381",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "353/7555",
                        "text": "Jesse De Meulemeester"
                    },
                    {
                        "@pid": "237/4710",
                        "text": "Antoon Purnal"
                    },
                    {
                        "@pid": "242/0106",
                        "text": "Lennert Wouters"
                    },
                    {
                        "@pid": "183/5101",
                        "text": "Arthur Beckers"
                    },
                    {
                        "@pid": "92/16",
                        "text": "Ingrid Verbauwhede"
                    }
                ]
            },
            "title": "SpectrEM: Exploiting Electromagnetic Emanations During Transient Execution.",
            "venue": "USENIX Security Symposium",
            "pages": "6293-6310",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MeulemeesterPWB23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/de-meulemeester",
            "url": "https://dblp.org/rec/conf/uss/MeulemeesterPWB23",
            "abstract": "Modern processors implement sophisticated performance optimizations, such as out-of-order execution and speculation, that expose programs to so-called transient execution attacks. So far, such attacks rely on specific on-chip covert channels (e.g., cache timing), instilling the hope that they can be thwarted by closing or weakening these channels. In this paper, we consider the inevitable physical side effects of transient execution. We focus on electromagnetic (EM) emanations produced by the processor and develop two lightweight and accurate EM channels to extract secret bits from the transient window. We propose SpectrEM, a Spectre variant for embedded devices exposed to physical access by an attacker. While it assumes a physical adversary, it does not fundamentally require code execution, expanding its applicability in the embedded world. We evaluate SpectrEM on an Arm Cortex-A72, leaking up to 366 bits per second at a bit error rate as low as 0.008%. To our knowledge, this is the first practical demonstration of physical transient execution attacks.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-de-meulemeester.pdf",
            "keywords": [
                "Transient Execution Attacks",
                "Electromagnetic Emanations",
                "Spectre Variant",
                "Embedded Device Security",
                "Physical Side Channels"
            ]
        },
        "url": "URL#915381"
    },
    {
        "@score": "1",
        "@id": "915382",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "264/2681",
                        "text": "Fieke Miedema"
                    },
                    {
                        "@pid": "353/7524",
                        "text": "Kelvin Lubbertsen"
                    },
                    {
                        "@pid": "353/7576",
                        "text": "Verena Schrama"
                    },
                    {
                        "@pid": "224/9337",
                        "text": "Rolf van Wegberg"
                    }
                ]
            },
            "title": "Mixed Signals: Analyzing Ground-Truth Data on the Users and Economics of a Bitcoin Mixing Service.",
            "venue": "USENIX Security Symposium",
            "pages": "751-768",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MiedemaLSW23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/miedema",
            "url": "https://dblp.org/rec/conf/uss/MiedemaLSW23",
            "abstract": "Bitcoin mixing is a commodity, mostly offered in the under-ground economy, selling anonymity in the bitcoin ecosystem. Its popularity is rather remarkable, as transactions initiated by its users run through wallets of a centralized service where personal identifiable information is collected in the mixing process, without any prior knowledge of data retention policies. This leaves us to wonder if users resort to strategies to mitigate these risks \u2013 like the usage of IP proxy services \u2013 or test the service with smaller transactions to identify scam services at \u2018low\u2019 costs. In this paper, we explore unique ground-truth data capturing 15,574 mixing transactions, initiated by 8,838 users, totaling US $45M worth of bitcoins mixed through BestMixer between July 2018 and June 2019. We find that user adoption of risk mitigation strategies is limited, while transaction volumes users entrust BestMixer are high and usage is frequent and recurrent \u2013 with 23% of users returning. Our analysis shows that only 61% of all transactions used some form of IP address obfuscation \u2013 i.e., VPN or VPS usage. We discuss possible explanations for these findings, including how information asymmetries and the role of mixers in the process of cashing-out criminal proceeds might force users to accept the risks associated with bitcoin mixing. Furthermore, we address the implications of our findings for the broader cryptocurrency security ecosystem.",
            "keywords": [
                "Bitcoin Mixing",
                "Anonymity Services",
                "User Behavior",
                "Risk Mitigation Strategies",
                "Cryptocurrency Economics"
            ]
        },
        "url": "URL#915382",
        "sema_paperId": "c1192c35bc3efca9d058e618776a79580e00575d"
    },
    {
        "@score": "1",
        "@id": "915383",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "280/8210",
                        "text": "Jaron Mink"
                    },
                    {
                        "@pid": "139/0822",
                        "text": "Harjot Kaur"
                    },
                    {
                        "@pid": "327/7084",
                        "text": "Juliane Schm\u00fcser"
                    },
                    {
                        "@pid": "38/9378",
                        "text": "Sascha Fahl"
                    },
                    {
                        "@pid": "132/9687",
                        "text": "Yasemin Acar"
                    }
                ]
            },
            "title": "&quot;Security is not my field, I&apos;m a stats guy&quot;: A Qualitative Root Cause Analysis of Barriers to Adversarial Machine Learning Defenses in Industry.",
            "venue": "USENIX Security Symposium",
            "pages": "3763-3780",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MinkKSFA23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/mink",
            "url": "https://dblp.org/rec/conf/uss/MinkKSFA23",
            "abstract": "Adversarial machine learning (AML) has the potential to leak training data, force arbitrary classifications, and greatly degrade overall performance of machine learning models, all of which academics and companies alike consider as serious issues. Despite this, seminal work has found that most organizations insufficiently protect against such threats. While the lack of defenses to AML is most commonly attributed to missing knowledge, it is unknown why mitigations are unre-alized in industry projects. To better understand the reasons behind the lack of deployed AML defenses, we conduct semi-structured interviews (n=21) with data scientists and data engineers to explore what barriers impede the effective implementation of such defenses. We find that practitioners\u2019 ability to deploy defenses is hampered by three primary factors: a lack of institutional motivation and educational resources for these concepts, an inability to adequately assess their AML risk and make subsequent decisions, and organizational structures and goals that discourage implementation in favor of other objectives. We conclude by discussing practical recommendations for companies and practitioners to be made more aware of these risks, and better prepared to respond.",
            "keywords": [
                "Adversarial Machine Learning",
                "Risk Assessment",
                "Implementation Barriers",
                "Data Science Practices",
                "Organizational Motivation"
            ]
        },
        "url": "URL#915383",
        "sema_paperId": "4a19142b4613e1c95b107064e928defc9e186f75"
    },
    {
        "@score": "1",
        "@id": "915385",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "160/6851",
                        "text": "Yisroel Mirsky"
                    },
                    {
                        "@pid": "353/7610",
                        "text": "George Macon"
                    },
                    {
                        "@pid": "01/3339",
                        "text": "Michael D. Brown"
                    },
                    {
                        "@pid": "185/6250",
                        "text": "Carter Yagemann"
                    },
                    {
                        "@pid": "265/5563",
                        "text": "Matthew Pruett"
                    },
                    {
                        "@pid": "123/9696",
                        "text": "Evan Downing"
                    },
                    {
                        "@pid": "07/3234",
                        "text": "J. Sukarno Mertoguno"
                    },
                    {
                        "@pid": "29/5976",
                        "text": "Wenke Lee"
                    }
                ]
            },
            "title": "VulChecker: Graph-based Vulnerability Localization in Source Code.",
            "venue": "USENIX Security Symposium",
            "pages": "6557-6574",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MirskyMBYPDML23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/mirsky",
            "url": "https://dblp.org/rec/conf/uss/MirskyMBYPDML23",
            "abstract": "In software development, it is critical to detect vulnerabilities in a project as early as possible. Although, deep learning has shown promise in this task,currentstate-of-the-artmethods cannot classify and identify the line on which the vulnerability occurs. Instead, the developer is tasked with searching for an arbitrary bug in an entire function or even larger region of code. In this paper, we propose VulChecker: a tool that can precisely locate vulnerabilities in source code (down to the exact instruction) as well as classify their type (CWE). To accomplish this, we propose a new program representation, program slicing strategy, and the use of a message-passing graph neural networkto utilize allof code\u2019s semantics and improve the reach between a vulnerability\u2019s root cause and manifestation points. We also propose a novel data augmentation strategy for cheaply creating strong datasets for vulnerability detection in the wild, using free synthetic samples available online. With this training strategy,VulChecker was able to identify 24 CVEs (10 from 2019 & 2020) in 19 projects taken from the wild, with nearly zero false positives compared to a commercial tool that could only detect 4. VulChecker also discovered an exploitable zero-day vulnerability, which has been reported to developers for responsible disclosure.",
            "keywords": [
                "Vulnerability Localization",
                "Program Representation",
                "Graph Neural Networks",
                "CWE Classification",
                "Data Augmentation for Vulnerability Detection"
            ]
        },
        "url": "URL#915385",
        "sema_paperId": "95815e25579bfd944d648f2bb8189766502d27c3"
    },
    {
        "@score": "1",
        "@id": "915386",
        "info": {
            "authors": {
                "author": {
                    "@pid": "241/6242",
                    "text": "Daniel Moghimi"
                }
            },
            "title": "Title Redacted Due to Vulnerability Embargo.",
            "venue": "USENIX Security Symposium",
            "pages": "7179-7193",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Moghimi23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/moghimi",
            "url": "https://dblp.org/rec/conf/uss/Moghimi23",
            "abstract": "We introduce Downfall attacks, new transient execution attacks that undermine the security of computers running everywhere across the internet. We exploit the gather instruction on high-performance x86 CPUs to leak data across boundaries of user-kernel, processes, virtual machines, and trusted execution environments. We also develop practical and end-to-end attacks to steal cryptographic keys, program\u2019s runtime data, and even data at rest (arbitrary data). Our findings, exploitation techniques, and demonstrated attacks defeat all previous defenses, calling for critical hardware fixes and security updates for widely-used client and server computers.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-moghimi.pdf",
            "keywords": [
                "Transient Execution Attacks",
                "Data Leakage",
                "x86 CPUs",
                "Cryptographic Key Theft",
                "Hardware Vulnerabilities"
            ]
        },
        "url": "URL#915386",
        "sema_paperId": "70f9c67bbfeea0de8025203fea202fea26e071c7"
    },
    {
        "@score": "1",
        "@id": "915387",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "267/9482",
                        "text": "Kevin Morio"
                    },
                    {
                        "@pid": "220/5413",
                        "text": "Ilkan Esiyok"
                    },
                    {
                        "@pid": "242/3244",
                        "text": "Dennis Jackson"
                    },
                    {
                        "@pid": "89/11274",
                        "text": "Robert K\u00fcnnemann"
                    }
                ]
            },
            "title": "Automated Security Analysis of Exposure Notification Systems.",
            "venue": "USENIX Security Symposium",
            "pages": "6593-6610",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MorioEJK23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/morio",
            "url": "https://dblp.org/rec/conf/uss/MorioEJK23",
            "abstract": "We present the first formal analysis and comparison of the security of the two most widely deployed exposure notification systems, ROBERT and the Google and Apple Exposure Notification (GAEN) framework.\nROBERT is the most popular instalment of the centralised approach to exposure notification, in which the risk score is computed by a central server. GAEN, in contrast, follows the decentralised approach, where the user's phone calculates the risk. The relative merits of centralised and decentralised systems have proven to be a controversial question. The majority of the previous analyses have focused on the privacy implications of these systems, ours is the first formal analysis to evaluate the security of the deployed systems\u2014the absence of false risk alerts.\nWe model the French deployment of ROBERT and the most widely deployed GAEN variant, Germany's Corona-Warn-App. We isolate the precise conditions under which these systems prevent false alerts. We determine exactly how an adversary can subvert the system via network and Bluetooth sniffing, database leakage or the compromise of phones, back-end systems and health authorities. We also investigate the security of the original specification of the DP3T protocol, in order to identify gaps between the proposed scheme and its ultimate deployment. \nWe find a total of 27 attack patterns, including many that distinguish the centralised from the decentralised approach, as well as attacks on the authorisation procedure that differentiate all three protocols.  Our results suggest that ROBERT's centralised design is more vulnerable against both opportunistic and highly resourced attackers trying to perform mass-notification attacks.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-morio.pdf",
            "keywords": [
                "Exposure Notification Systems",
                "Security Analysis",
                "Centralized vs Decentralized",
                "False Risk Alerts",
                "Attack Patterns"
            ]
        },
        "url": "URL#915387"
    },
    {
        "@score": "1",
        "@id": "915388",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "260/3169",
                        "text": "Hamid Mozaffari"
                    },
                    {
                        "@pid": "243/3113",
                        "text": "Virat Shejwalkar"
                    },
                    {
                        "@pid": "22/1797",
                        "text": "Amir Houmansadr"
                    }
                ]
            },
            "title": "Every Vote Counts: Ranking-Based Training of Federated Learning to Resist Poisoning Attacks.",
            "venue": "USENIX Security Symposium",
            "pages": "1721-1738",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MozaffariSH23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/mozaffari",
            "url": "https://dblp.org/rec/conf/uss/MozaffariSH23",
            "abstract": "Federated learning (FL) allows untrusted clients to collaboratively train a common machine learning model, called global model , without sharing their private/proprietary training data. However, FL is susceptible to poisoning by malicious clients who aim to hamper the accuracy of the global model by contributing malicious updates during FL\u2019s training process. We argue that the key factor to the success of poisoning attacks against existing FL systems is the large space of model updates available to the clients to choose from. To address this, we propose Federated Rank Learning (FRL). FRL reduces the space of client updates from model parameter updates (a continuous space of float numbers) in standard FL to the space of parameter rankings (a discrete space of integer values). To be able to train the global model using parameter ranks (instead of parameter weights), FRL leverage ideas from recent supermasks training mechanisms. Specifically, FRL clients rank the parameters of a randomly initialized neural network (provided by the server) based on their local training data, and the FRL server uses a voting mechanism to aggregate the parameter rankings submitted by the clients. Intuitively, our voting-based aggregation mechanism prevents poisoning clients from making significant adversarial modifications to the global model, as each client will have a single vote! We demonstrate the robustness of FRL to poisoning through analytical proofs and experimentation, and we show its high communication efficiency. 1 .",
            "keywords": [
                "Federated Learning",
                "Poisoning Attacks",
                "Parameter Rankings",
                "Client Updates",
                "Voting Mechanism"
            ]
        },
        "url": "URL#915388",
        "sema_paperId": "7de5cbeb23852406e8d22f774a49d35844919015"
    },
    {
        "@score": "1",
        "@id": "915389",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "27/6354",
                        "text": "Kunal Mukherjee"
                    },
                    {
                        "@pid": "348/8917",
                        "text": "Joshua Wiedemeier"
                    },
                    {
                        "@pid": "348/9211",
                        "text": "Tianhao Wang 0026"
                    },
                    {
                        "@pid": "63/6253",
                        "text": "James Wei"
                    },
                    {
                        "@pid": "21/3047",
                        "text": "Feng Chen"
                    },
                    {
                        "@pid": "326/4554",
                        "text": "Muhyun Kim"
                    },
                    {
                        "@pid": "36/195",
                        "text": "Murat Kantarcioglu"
                    },
                    {
                        "@pid": "36/10085",
                        "text": "Kangkook Jee"
                    }
                ]
            },
            "title": "Evading Provenance-Based ML Detectors with Adversarial System Actions.",
            "venue": "USENIX Security Symposium",
            "pages": "1199-1216",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MukherjeeW0WCKK23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/mukherjee",
            "url": "https://dblp.org/rec/conf/uss/MukherjeeW0WCKK23",
            "abstract": "The artifact evaluation process is designed to validate the repeatability and usability of the results presented in the research paper \"Evading Provenance-Based ML Detectors with Adversarial System Actions.\" The paper introduces P ROV N-INJA , a novel framework designed to discover adversarial samples, also known as gadgets, specifically tailored for path-based Intrusion Detection Systems (IDS) and Graph Neural Network-based IDS. The primary objective of P ROV N INJA is to identify actions that can successfully evade state-of-the-art IDSs. The evaluation process comprises two main components: training and testing the IDS and generating adversarial examples to evade the IDSs. As a valuable resource, the authors provide a GitHub link that grants access to the source code, data, and scripts necessary for reproducing the results described in the paper. By offering these artifacts, the researchers enable fellow researchers and practitioners to replicate and build upon their work in provenance-based ML detectors. The artifacts include comprehensive software, data, and scripts employed to generate the findings presented in the paper. The accessibility of the GitHub repository ensures transparency. It fosters collaboration among researchers, facilitating advancements in the domain of provenance-based ML detectors and contributing to the overall improvement of security systems.",
            "keywords": [
                "Provenance-Based Detection",
                "Adversarial Samples",
                "Intrusion Detection Systems",
                "Graph Neural Networks",
                "Evading Detection"
            ]
        },
        "url": "URL#915389",
        "sema_paperId": "8a7dc1630911808ff2469f3b53038ddf62a661bc"
    },
    {
        "@score": "1",
        "@id": "915390",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "331/2359",
                        "text": "Siddharth Muralee"
                    },
                    {
                        "@pid": "295/1145",
                        "text": "Igibek Koishybayev"
                    },
                    {
                        "@pid": "331/2482",
                        "text": "Aleksandr Nahapetyan"
                    },
                    {
                        "@pid": "353/7634",
                        "text": "Greg Tystahl"
                    },
                    {
                        "@pid": "117/3983",
                        "text": "Bradley Reaves"
                    },
                    {
                        "@pid": "99/3883",
                        "text": "Antonio Bianchi"
                    },
                    {
                        "@pid": "22/4463",
                        "text": "William Enck"
                    },
                    {
                        "@pid": "22/1459",
                        "text": "Alexandros Kapravelos"
                    },
                    {
                        "@pid": "133/8188",
                        "text": "Aravind Machiry"
                    }
                ]
            },
            "title": "ARGUS: A Framework for Staged Static Taint Analysis of GitHub Workflows and Actions.",
            "venue": "USENIX Security Symposium",
            "pages": "6983-7000",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MuraleeKNTRBEKM23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/muralee",
            "url": "https://dblp.org/rec/conf/uss/MuraleeKNTRBEKM23",
            "abstract": "Millions of software projects leverage automated workflows, like GitHub Actions, for performing common build and deploy tasks. While GitHub Actions have greatly improved the software build process for developers, they pose significant risks to the software supply chain by adding more dependencies and code complexity that may introduce security bugs. This paper presents A RGUS , the first static taint analysis system for identifying code injection vulnerabilities in GitHub Actions. We used A RGUS to perform a large-scale evaluation on 2,778,483 Workflows referencing 31,725 Actions and discovered critical code injection vulnerabilities in 4,307 Workflows and 80 Actions . We also directly compared A RGUS to two existing pattern-based GitHub Actions vulnerability scanners, demonstrating that our system exhibits a marked improvement in terms of vulnerability detection, with a discovery rate more than seven times (7x) higher than the state-of-the-art approaches. These results demonstrate that command injection vulnerabilities in the GitHub Actions ecosystem are not only pervasive but also require taint analysis to be detected.",
            "keywords": [
                "GitHub Actions",
                "Static Taint Analysis",
                "Code Injection Vulnerabilities",
                "Software Supply Chain Security",
                "Vulnerability Detection"
            ]
        },
        "url": "URL#915390",
        "sema_paperId": "f133e893a8ef96c61a4f63525910c8c0350e1c6b"
    },
    {
        "@score": "1",
        "@id": "915391",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "199/3074",
                        "text": "Pardis Emami Naeini"
                    },
                    {
                        "@pid": "303/6459",
                        "text": "Janarth Dheenadhayalan"
                    },
                    {
                        "@pid": "84/1053",
                        "text": "Yuvraj Agarwal"
                    },
                    {
                        "@pid": "03/1595",
                        "text": "Lorrie Faith Cranor"
                    }
                ]
            },
            "title": "Are Consumers Willing to Pay for Security and Privacy of IoT Devices?",
            "venue": "USENIX Security Symposium",
            "pages": "1505-1522",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/NaeiniDAC23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/emami-naeini",
            "url": "https://dblp.org/rec/conf/uss/NaeiniDAC23",
            "abstract": "Internet of Things (IoT) device manufacturers provide little information to consumers about their security and data handling practices. Therefore, IoT consumers cannot make informed purchase choices around security and privacy. While prior research has found that consumers would likely consider security and privacy when purchasing IoT devices, past work lacks empirical evidence as to whether they would actually pay more to purchase devices with enhanced security and privacy. To fill this gap, we conducted a two-phase incentive-compatible online study with 180 Prolific participants. We measured the impact of five security and privacy factors (e.g., access control) on participants\u2019 purchase behaviors when presented individually or together on an IoT label. Participants were willing to pay a significant premium for devices with better security and privacy practices. The biggest price differential we found was for de-identified rather than identifiable cloud storage. Mainly due to its usability challenges, the least valuable improvement for participants was to have multi-factor authentication as opposed to passwords. Based on our findings, we provide recommendations on creating more effective IoT security and privacy labeling programs.",
            "keywords": [
                "Internet of Things (IoT)",
                "Security and Privacy Practices",
                "Consumer Willingness to Pay",
                "IoT Device Labeling",
                "Enhanced Security Features"
            ]
        },
        "url": "URL#915391",
        "sema_paperId": "cddb60f95b169cf90540d5ddabee19bb67d98e36"
    },
    {
        "@score": "1",
        "@id": "915392",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "185/0774",
                        "text": "Vivek Nair"
                    },
                    {
                        "@pid": "144/1238-2",
                        "text": "Wenbo Guo 0002"
                    },
                    {
                        "@pid": "317/0415",
                        "text": "Justus Mattern"
                    },
                    {
                        "@pid": "06/2293-110",
                        "text": "Rui Wang 0110"
                    },
                    {
                        "@pid": "96/5326",
                        "text": "James F. O&apos;Brien"
                    },
                    {
                        "@pid": "70/1694",
                        "text": "Louis B. Rosenberg"
                    },
                    {
                        "@pid": "s/DXSong",
                        "text": "Dawn Song"
                    }
                ]
            },
            "title": "Unique Identification of 50, 000+ Virtual Reality Users from Head &amp; Hand Motion Data.",
            "venue": "USENIX Security Symposium",
            "pages": "895-910",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Nair0MWORS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/nair-identification",
            "url": "https://dblp.org/rec/conf/uss/Nair0MWORS23",
            "abstract": "With the recent explosive growth of interest and investment in virtual reality (VR) and the so-called\"metaverse,\"public attention has rightly shifted toward the unique security and privacy threats that these platforms may pose. While it has long been known that people reveal information about themselves via their motion, the extent to which this makes an individual globally identifiable within virtual reality has not yet been widely understood. In this study, we show that a large number of real VR users (N=55,541) can be uniquely and reliably identified across multiple sessions using just their head and hand motion relative to virtual objects. After training a classification model on 5 minutes of data per person, a user can be uniquely identified amongst the entire pool of 50,000+ with 94.33% accuracy from 100 seconds of motion, and with 73.20% accuracy from just 10 seconds of motion. This work is the first to truly demonstrate the extent to which biomechanics may serve as a unique identifier in VR, on par with widely used biometrics such as facial or fingerprint recognition.",
            "keywords": [
                "Virtual Reality",
                "User Identification",
                "Motion Data",
                "Biomechanics",
                "Privacy Threats"
            ]
        },
        "url": "URL#915392",
        "sema_paperId": "c10d7db7fecfa578279267e5ac29ba0ee2e5651f"
    },
    {
        "@score": "1",
        "@id": "915393",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "185/0774",
                        "text": "Vivek Nair"
                    },
                    {
                        "@pid": "s/DXSong",
                        "text": "Dawn Song"
                    }
                ]
            },
            "title": "Multi-Factor Key Derivation Function (MFKDF) for Fast, Flexible, Secure, &amp; Practical Key Management.",
            "venue": "USENIX Security Symposium",
            "pages": "2097-2114",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/NairS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/nair-mfkdf",
            "url": "https://dblp.org/rec/conf/uss/NairS23",
            "abstract": "We present the first general construction of a Multi-Factor Key Derivation Function (MFKDF). Our function expands upon password-based key derivation functions (PBKDFs) with support for using other popular authentication factors like TOTP, HOTP, and hardware tokens in the key derivation process. In doing so, it provides an exponential security improvement over PBKDFs with less than 12 ms of additional computational overhead in a typical web browser. We further present a threshold MFKDF construction, allowing for client-side key recovery and reconstitution if a factor is lost. Finally, by \"stacking\" derived keys, we provide a means of cryptographically enforcing arbitrarily specific key derivation policies. The result is a paradigm shift toward direct cryptographic protection of user data using all available authentication factors, with no noticeable change to the user experience. We demonstrate the ability of our solution to not only significantly improve the security of existing systems implementing PBKDFs, but also to enable new applications where PBKDFs would not be considered a feasible approach.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-nair-mfkdf.pdf",
            "keywords": [
                "Key Derivation Function",
                "Multi-Factor Authentication",
                "Password-Based Key Derivation",
                "Cryptographic Key Management",
                "Threshold Key Recovery"
            ]
        },
        "url": "URL#915393"
    },
    {
        "@score": "1",
        "@id": "915394",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "167/0416",
                        "text": "Yuhong Nan"
                    },
                    {
                        "@pid": "60/8494",
                        "text": "Xueqiang Wang"
                    },
                    {
                        "@pid": "34/8412",
                        "text": "Luyi Xing"
                    },
                    {
                        "@pid": "129/1113",
                        "text": "Xiaojing Liao"
                    },
                    {
                        "@pid": "40/5102",
                        "text": "Ruoyu Wu"
                    },
                    {
                        "@pid": "16/5608",
                        "text": "Jianliang Wu"
                    },
                    {
                        "@pid": "57/4707-10",
                        "text": "Yifan Zhang 0010"
                    },
                    {
                        "@pid": "06/6268",
                        "text": "XiaoFeng Wang 0001"
                    }
                ]
            },
            "title": "Are You Spying on Me? Large-Scale Analysis on IoT Data Exposure through Companion Apps.",
            "venue": "USENIX Security Symposium",
            "pages": "6665-6682",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/NanWXLWW0023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/nan",
            "url": "https://dblp.org/rec/conf/uss/NanWXLWW0023",
            "abstract": "Recent research has highlighted privacy as a primary concern for IoT device users. However, due to the challenges in conducting a large-scale study to analyze thousands of devices, there has been less study on how pervasive unauthorized data exposure has actually become on today\u2019s IoT devices and the privacy implications of such exposure. To fill this gap, we leverage the observation that most IoT devices on the market today use their companion mobile apps as an intermediary to process, label and transmit the data they collect. As a result, the semantic information carried by these apps can be recovered and analyzed automatically to track the collection and sharing of IoT data. In this paper, we report the first of such a study, based upon a new framework IoTProfiler, which statically analyzes a large number of companion apps to infer and track the data collected by their IoT devices. Our approach utilizes machine learning to detect the code snippet in a companion app that handles IoT data and further recovers the semantics of the data from the snippet to evaluate whether their exposure has been properly communicated to the user. By running IoTProfiler on 6,208 companion apps, our research has led to the discovery of 1,973 apps that expose user data without proper disclosure, covering IoT devices from at least 1,559 unique vendors. Our findings include highly sensitive information, such as health status and home address, and the pervasiveness of unauthorized sharing of the data to third parties, including those in different countries. Our findings highlight the urgent need to regulate today\u2019s IoT industry to protect user privacy.",
            "keywords": [
                "IoT Privacy",
                "Companion Apps",
                "Data Exposure",
                "User Data Disclosure",
                "Unauthorized Data Sharing"
            ]
        },
        "url": "URL#915394",
        "sema_paperId": "21846bce9282db40f3d40da0897526cca161c335"
    },
    {
        "@score": "1",
        "@id": "915395",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "279/6393",
                        "text": "Priyanka Nanayakkara"
                    },
                    {
                        "@pid": "259/2777",
                        "text": "Mary Anne Smart"
                    },
                    {
                        "@pid": "56/9841",
                        "text": "Rachel Cummings"
                    },
                    {
                        "@pid": "185/1661",
                        "text": "Gabriel Kaptchuk"
                    },
                    {
                        "@pid": "141/9244",
                        "text": "Elissa M. Redmiles"
                    }
                ]
            },
            "title": "What Are the Chances? Explaining the Epsilon Parameter in Differential Privacy.",
            "venue": "USENIX Security Symposium",
            "pages": "1613-1630",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/NanayakkaraSCKR23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/nanayakkara",
            "url": "https://dblp.org/rec/conf/uss/NanayakkaraSCKR23",
            "abstract": "Differential privacy (DP) is a mathematical privacy notion increasingly deployed across government and industry. With DP, privacy protections are probabilistic: they are bounded by the privacy loss budget parameter, \u03b5. Prior work in health and computational science finds that people struggle to reason about probabilistic risks. Yet, communicating the implications of \u03b5 to people contributing their data is vital to avoiding privacy theater\u2014presenting meaningless privacy protection as meaningful\u2014and empowering more informed data-sharing decisions. Drawing on best practices in risk communication and usability, we develop three methods to convey probabilistic DP guarantees to end users: two that communicate odds and one offering concrete examples of DP outputs.We quantitatively evaluate these explanation methods in a vignette survey study (n = 963) via three metrics: objective risk comprehension, subjective privacy understanding of DP guarantees, and self-efficacy. We find that odds-based explanation methods are more effective than (1) output-based methods and (2) state-of-the-art approaches that gloss over information about \u03b5. Further, when offered information about \u03b5, respondents are more willing to share their data than when presented with a state-of-the-art DP explanation; this willingness to share is sensitive to \u03b5 values: as privacy protections weaken, respondents are less likely to share data.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-nanayakkara.pdf",
            "keywords": [
                "Differential Privacy",
                "Privacy Loss Budget",
                "Epsilon Parameter",
                "Risk Communication",
                "Data Sharing Decisions"
            ]
        },
        "url": "URL#915395"
    },
    {
        "@score": "1",
        "@id": "915396",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "187/8997",
                        "text": "Milad Nasr"
                    },
                    {
                        "@pid": "168/8164",
                        "text": "Jamie Hayes"
                    },
                    {
                        "@pid": "73/4025-2",
                        "text": "Thomas Steinke 0002"
                    },
                    {
                        "@pid": "06/8421",
                        "text": "Borja Balle"
                    },
                    {
                        "@pid": "158/7224",
                        "text": "Florian Tram\u00e8r"
                    },
                    {
                        "@pid": "218/5156",
                        "text": "Matthew Jagielski"
                    },
                    {
                        "@pid": "145/1806",
                        "text": "Nicholas Carlini"
                    },
                    {
                        "@pid": "12/6664",
                        "text": "Andreas Terzis"
                    }
                ]
            },
            "title": "Tight Auditing of Differentially Private Machine Learning.",
            "venue": "USENIX Security Symposium",
            "pages": "1631-1648",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/NasrH0BTJCT23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/nasr",
            "url": "https://dblp.org/rec/conf/uss/NasrH0BTJCT23",
            "abstract": "Auditing mechanisms for differential privacy use probabilistic means to empirically estimate the privacy level of an algorithm. For private machine learning, existing auditing mechanisms are tight: the empirical privacy estimate (nearly) matches the algorithm's provable privacy guarantee. But these auditing techniques suffer from two limitations. First, they only give tight estimates under implausible worst-case assumptions (e.g., a fully adversarial dataset). Second, they require thousands or millions of training runs to produce nontrivial statistical estimates of the privacy leakage.This work addresses both issues. We design an improved auditing scheme that yields tight privacy estimates for natural (not adversarially crafted) datasets\u2014if the adversary can see all model updates during training. Prior auditing works rely on the same assumption, which is permitted under the standard differential privacy threat model. This threat model is also applicable, e.g., in federated learning settings. Moreover, our auditing scheme requires only two training runs (instead of thousands) to produce tight privacy estimates, by adapting recent advances in tight composition theorems for differential privacy. We demonstrate the utility of our improved auditing schemes by surfacing implementation bugs in private machine learning code that eluded prior auditing techniques.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-nasr.pdf",
            "keywords": [
                "Differential Privacy",
                "Auditing Mechanisms",
                "Privacy Leakage",
                "Federated Learning",
                "Implementation Bugs"
            ]
        },
        "url": "URL#915396"
    },
    {
        "@score": "1",
        "@id": "915397",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "324/3125",
                        "text": "Shradha Neupane"
                    },
                    {
                        "@pid": "353/7633",
                        "text": "Grant Holmes"
                    },
                    {
                        "@pid": "320/8992",
                        "text": "Elizabeth Wyss"
                    },
                    {
                        "@pid": "37/5586",
                        "text": "Drew Davidson"
                    },
                    {
                        "@pid": "23/7380",
                        "text": "Lorenzo De Carli"
                    }
                ]
            },
            "title": "Beyond Typosquatting: An In-depth Look at Package Confusion.",
            "venue": "USENIX Security Symposium",
            "pages": "3439-3456",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/NeupaneHWDC23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/neupane",
            "url": "https://dblp.org/rec/conf/uss/NeupaneHWDC23",
            "abstract": "Package confusion incidents\u2014where a developer is misled into importing a package other than the intended one\u2014are one of the most severe issues in supply chain security with significant security implications, especially when the wrong package has malicious functionality. While the prevalence of the issue is generally well-documented, little work has studied the range of mechanisms by which confusion in a package name could arise or be employed by an adversary. In our work, we present the first comprehensive categorization of the mechanisms used to induce confusion, and we show how this understanding can be used for detection. First, we use qualitative analysis to identify and rigorously define 13 categories of confusion mechanisms based on a dataset of 1200+ documented attacks. Results show that, while package confusion is thought to mostly exploit typing errors, in practice attackers use a variety of mechanisms, many of which work at semantic, rather than syntactic, level. Equipped with our categorization, we then define detectors for the discovered attack categories, and we evaluate them on the entire npm package set. Evaluation of a sample, performed through an online survey, identifies a subset of highly effective detection rules which (i) return high-quality matches (77% matches marked as potentially or highly confusing, and 18% highly confusing) and (ii) generate low warning overhead (1 warning per 100M+ package pairs). Comparison with state-of-the-art reveals that the large majority of such pairs are not flagged by existing tools. Thus, our work has the potential to concretely improve the identification of confusable package names in the wild.",
            "keywords": [
                "Supply Chain Security",
                "Package Confusion",
                "Confusable Package Names",
                "Detection Mechanisms",
                "Malicious Functionality"
            ]
        },
        "url": "URL#915397",
        "sema_paperId": "c370fd8e55563cb7e020f750bf39a2de4bc4b1b9"
    },
    {
        "@score": "1",
        "@id": "915398",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "50/4043-3",
                        "text": "Tao Ni 0003"
                    },
                    {
                        "@pid": "178/9755",
                        "text": "Guohao Lan"
                    },
                    {
                        "@pid": "58/6299-8",
                        "text": "Jia Wang 0008"
                    },
                    {
                        "@pid": "156/1033",
                        "text": "Qingchuan Zhao"
                    },
                    {
                        "@pid": "98/7731",
                        "text": "Weitao Xu"
                    }
                ]
            },
            "title": "Eavesdropping Mobile App Activity via Radio-Frequency Energy Harvesting.",
            "venue": "USENIX Security Symposium",
            "pages": "3511-3528",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/NiL0ZX23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/ni",
            "url": "https://dblp.org/rec/conf/uss/NiL0ZX23",
            "abstract": "Radio-frequency (RF) energy harvesting is a promising technology for Internet-of-Things (IoT) devices to power sensors and prolong battery life. In this paper, we present a novel side-channel attack that leverages RF energy harvesting signals to eavesdrop mobile app activities. To demonstrate this novel attack, we propose AppListener , an automated attack framework that recognizes \ufb01ne-grained mobile app activities from harvested RF energy. The RF energy is harvested from a custom-built RF energy harvester which generates voltage signals from ambient Wi-Fi transmissions, and app activities are recognized from a three-tier classi\ufb01cation algorithm. We evaluate AppListener with four mobile devices running 40 common mobile apps (e.g., YouTube, Facebook, and What-sApp) belonging to \ufb01ve categories (i.e., video, music, social media, communication, and game); each category contains \ufb01ve application-speci\ufb01c activities. Experiment results show that AppListener achieves over 99% accuracy in differentiating four different mobile devices, over 98% accuracy in classifying 40 different apps, and 86 . 7% accuracy in recognizing \ufb01ve sets of application-speci\ufb01c activities. Moreover, a comprehensive study is conducted to show AppListener is robust to a number of impact factors, such as distance, environment, and non-target connected devices. Practices of integrating Ap-pListener into commercial IoT devices also demonstrate that it is easy to deploy. Finally, countermeasures are presented as the \ufb01rst step to defend against this novel attack.",
            "keywords": [
                "RF Energy Harvesting",
                "Mobile App Eavesdropping",
                "Side-Channel Attack",
                "App Activity Recognition",
                "IoT Device Security"
            ]
        },
        "url": "URL#915398",
        "sema_paperId": "775b4bb10a3e0854a06c0685ea3ad64348d2f94d"
    },
    {
        "@score": "1",
        "@id": "915399",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "326/5249",
                        "text": "Alexandra Nisenoff"
                    },
                    {
                        "@pid": "280/6860",
                        "text": "Arthur Borem"
                    },
                    {
                        "@pid": "353/7516",
                        "text": "Madison Pickering"
                    },
                    {
                        "@pid": "353/7540",
                        "text": "Grant Nakanishi"
                    },
                    {
                        "@pid": "353/7648",
                        "text": "Maya Thumpasery"
                    },
                    {
                        "@pid": "66/9786",
                        "text": "Blase Ur"
                    }
                ]
            },
            "title": "Defining &quot;Broken&quot;: User Experiences and Remediation Tactics When Ad-Blocking or Tracking-Protection Tools Break a Website&apos;s User Experience.",
            "venue": "USENIX Security Symposium",
            "pages": "3619-3636",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/NisenoffBPNTU23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/nisenoff-broken",
            "url": "https://dblp.org/rec/conf/uss/NisenoffBPNTU23",
            "abstract": "To counteract the ads and third-party tracking ubiquitous on the web, users turn to blocking tools\u2014ad-blocking and tracking-protection browser extensions and built-in features. Unfortunately, blocking tools can cause non-ad, non-tracking elements of a website to degrade or fail, a phenomenon termed breakage . Examples include missing images, non-functional buttons, and pages failing to load. While the literature frequently discusses breakage, prior work has not systematically mapped and disambiguated the spectrum of user experiences subsumed under \u201cbreakage,\u201d nor sought to understand how users experience, prioritize, and attempt to \ufb01x breakage. We \ufb01ll these gaps. First, through qualitative analysis of 18,932 extension-store reviews and GitHub issue reports for ten popular blocking tools, we developed novel taxonomies of 38 speci\ufb01c types of breakage and 15 associated mitigation strategies. To understand subjective experiences of breakage, we then conducted a 95-participant survey. Nearly all participants had experienced various types of breakage, and they employed an array of strategies of variable effectiveness in response to speci\ufb01c types of breakage in speci\ufb01c contexts. Unfortunately, participants rarely noti\ufb01ed anyone who could \ufb01x the root causes. We discuss how our taxonomies and re-sults can improve the comprehensiveness and prioritization of ongoing attempts to automatically detect and \ufb01x breakage.",
            "keywords": [
                "Ad-Blocking Tools",
                "User Experience",
                "Website Breakage",
                "Tracking Protection",
                "Mitigation Strategies"
            ]
        },
        "url": "URL#915399",
        "sema_paperId": "b8b217a0b8eb42738b4a360be2d6ca1444f36de3"
    },
    {
        "@score": "1",
        "@id": "915400",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "326/5249",
                        "text": "Alexandra Nisenoff"
                    },
                    {
                        "@pid": "177/0313",
                        "text": "Maximilian Golla"
                    },
                    {
                        "@pid": "217/4562",
                        "text": "Miranda Wei"
                    },
                    {
                        "@pid": "227/9054",
                        "text": "Juliette Hainline"
                    },
                    {
                        "@pid": "353/7689",
                        "text": "Hayley Szymanek"
                    },
                    {
                        "@pid": "353/7623",
                        "text": "Annika Braun"
                    },
                    {
                        "@pid": "301/5825",
                        "text": "Annika Hildebrandt"
                    },
                    {
                        "@pid": "353/7559",
                        "text": "Blair Christensen"
                    },
                    {
                        "@pid": "51/5857",
                        "text": "David Langenberg"
                    },
                    {
                        "@pid": "66/9786",
                        "text": "Blase Ur"
                    }
                ]
            },
            "title": "A Two-Decade Retrospective Analysis of a University&apos;s Vulnerability to Attacks Exploiting Reused Passwords.",
            "venue": "USENIX Security Symposium",
            "pages": "5127-5144",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/NisenoffGWHSBHC23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/nisenoff-retrospective",
            "url": "https://dblp.org/rec/conf/uss/NisenoffGWHSBHC23",
            "abstract": "Credential-guessing attacks often exploit passwords that were reused across a user\u2019s online accounts. To learn how organizations can better protect users, we retrospectively analyzed our university\u2019s vulnerability to credential-guessing attacks across twenty years. Given a list of university usernames, we searched for matches in both data breaches from hundreds of websites and a dozen large compilations of breaches. After cracking hashed passwords and tweaking guesses, we successfully guessed passwords for 32.0% of accounts matched to a university email address in a data breach, as well as 6.5% of accounts where the username (but not necessarily the domain) matched. Many of these accounts remained vulnerable for years after the breached data was leaked, and passwords found verbatim in breaches were nearly four times as likely to have been exploited (i.e., suspicious account activity was observed) than tweaked guesses. Over 70 different data breaches and various username-matching strategies bootstrapped correct guesses. In surveys of 40 users whose passwords we guessed, many users were unaware of the risks to their university account or that their credentials had been breached. This analysis of password reuse at our university provides pragmatic advice for organizations to protect accounts.",
            "keywords": [
                "Credential-Guessing Attacks",
                "Password Reuse",
                "Data Breaches",
                "Account Vulnerability",
                "User Awareness"
            ]
        },
        "url": "URL#915400",
        "sema_paperId": "ed4ddd65b95873c96b06d7aee978f8e9c885b227"
    },
    {
        "@score": "1",
        "@id": "915401",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "326/5249",
                        "text": "Alexandra Nisenoff"
                    },
                    {
                        "@pid": "326/5257",
                        "text": "Ranya Sharma"
                    },
                    {
                        "@pid": "87/840",
                        "text": "Nick Feamster"
                    }
                ]
            },
            "title": "User Awareness and Behaviors Concerning Encrypted DNS Settings in Web Browsers.",
            "venue": "USENIX Security Symposium",
            "pages": "3117-3133",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/NisenoffSF23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/nisenoff-awareness",
            "url": "https://dblp.org/rec/conf/uss/NisenoffSF23",
            "abstract": "Recent developments to encrypt the Domain Name System (DNS) have resulted in major browser and operating system vendors deploying encrypted DNS functionality, often enabling various configurations and settings by default. In many cases, default encrypted DNS settings have implications for performance and privacy; for example, Firefox's default DNS setting sends all of a user's DNS queries to Cloudflare, potentially introducing new privacy vulnerabilities. In this paper, we confirm that most users are unaware of these developments -- with respect to the rollout of these new technologies, the changes in default settings, and the ability to customize encrypted DNS configuration to balance user preferences between privacy and performance. Our findings suggest several important implications for the designers of interfaces for encrypted DNS functionality in both browsers and operating systems, to help improve user awareness concerning these settings, and to ensure that users retain the ability to make choices that allow them to balance tradeoffs concerning DNS privacy and performance.",
            "keywords": [
                "Encrypted DNS",
                "User Awareness",
                "Privacy Settings",
                "Browser Configuration",
                "Performance Trade-offs"
            ]
        },
        "url": "URL#915401",
        "sema_paperId": "dd2b8fe13c2a6482a003f67f6f421b90fda6eb3f"
    },
    {
        "@score": "1",
        "@id": "915402",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "78/8091",
                        "text": "Liang Niu"
                    },
                    {
                        "@pid": "216/4136",
                        "text": "Muhammad Shujaat Mirza"
                    },
                    {
                        "@pid": "353/7669",
                        "text": "Zayd Maradni"
                    },
                    {
                        "@pid": "11/3019",
                        "text": "Christina P\u00f6pper"
                    }
                ]
            },
            "title": "CodexLeaks: Privacy Leaks from Code Generation Language Models in GitHub Copilot.",
            "venue": "USENIX Security Symposium",
            "pages": "2133-2150",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/NiuMMP23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/niu",
            "url": "https://dblp.org/rec/conf/uss/NiuMMP23",
            "abstract": "Code generation language models are trained on billions of lines of source code to provide code generation and auto-completion features, like those offered by code assistant GitHub Copilot with more than a million users. These datasets may contain sensitive personal information\u2014personally identifiable, private, or secret\u2014that these models may regurgitate. This paper introduces and evaluates a semi-automated pipeline for extracting sensitive personal information from the Codex model used in GitHub Copilot. We employ carefully-designed templates to construct prompts that are more likely to result in privacy leaks. To overcome the non-public training data, we propose a semi-automated filtering method using a blind membership inference attack. We validate the effectiveness of our membership inference approach on different code generation models. We utilize hit rate through the GitHub Search API as a distinguishing heuristic followed by human-in-the-loop evaluation, uncovering that approximately 8% (43) of the prompts yield privacy leaks. Notably, we observe that the model tends to produce indirect leaks, compromising privacy as contextual integrity by generating information from individuals closely related to the queried subject in the training corpus.",
            "keywords": [
                "Code Generation Models",
                "Privacy Leaks",
                "Sensitive Information Extraction",
                "Membership Inference Attack",
                "Contextual Integrity"
            ]
        },
        "url": "URL#915402",
        "sema_paperId": "0a5ca7649ab378cc8c734ddac5bf6c6c00f086c1"
    },
    {
        "@score": "1",
        "@id": "915403",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "285/5550",
                        "text": "Harun Oz"
                    },
                    {
                        "@pid": "69/10491",
                        "text": "Ahmet Aris"
                    },
                    {
                        "@pid": "195/5992",
                        "text": "Abbas Acar"
                    },
                    {
                        "@pid": "118/3426",
                        "text": "G\u00fcliz Seray Tuncay"
                    },
                    {
                        "@pid": "154/3548",
                        "text": "Leonardo Babun"
                    },
                    {
                        "@pid": "46/1500",
                        "text": "A. Selcuk Uluagac"
                    }
                ]
            },
            "title": "R\u00f8B: Ransomware over Modern Web Browsers.",
            "venue": "USENIX Security Symposium",
            "pages": "7073-7090",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/OzAATBU23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/oz",
            "url": "https://dblp.org/rec/conf/uss/OzAATBU23",
            "abstract": "File System Access (FSA) API enables web applications to interact with files on the users' local devices. Even though it can be used to develop rich web applications, it greatly extends the attack surface, which can be abused by adversaries to cause significant harm. In this paper, for the first time in the literature, we extensively study this new attack vector that can be used to develop a powerful new ransomware strain over a browser. Using the FSA API and WebAssembly technology, we demonstrate this novel browser-based ransomware called R\u00f8B as a malicious web application that encrypts the user's files from the browser. We use R\u00f8B to perform impact analysis with different OSs, local directories, and antivirus solutions as well as to develop mitigation techniques against it. Our evaluations show that R\u00f8B can encrypt the victim's local files including cloud-integrated directories, external storage devices, and network-shared folders regardless of the access limitations imposed by the API. Moreover, we evaluate and show how the existing defense solutions fall short against R\u00f8B in terms of their feasibility. We propose three potential defense solutions to mitigate this new attack vector. These solutions operate at different levels (i.e., browser-level, file-system-level, and user-level) and are orthogonal to each other. Our work strives to raise awareness of the dangers of R\u00f8B-like browser-based ransomware strains and shows that the emerging API documentation (i.e., the popular FSA) can be equivocal in terms of reflecting the extent of the threat.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-oz.pdf",
            "keywords": [
                "Browser-based Ransomware",
                "File System Access API",
                "WebAssembly",
                "Ransomware Attack Vector",
                "Mitigation Techniques"
            ]
        },
        "url": "URL#915403",
        "sema_paperId": "d72bcb24da9a18a790a6ecbde590154ea6b7ab91"
    },
    {
        "@score": "1",
        "@id": "915405",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "318/1220",
                        "text": "Minzhou Pan"
                    },
                    {
                        "@pid": "75/148-5",
                        "text": "Yi Zeng 0005"
                    },
                    {
                        "@pid": "178/9876",
                        "text": "Lingjuan Lyu"
                    },
                    {
                        "@pid": "94/7236",
                        "text": "Xue Lin"
                    },
                    {
                        "@pid": "147/5355-1",
                        "text": "Ruoxi Jia 0001"
                    }
                ]
            },
            "title": "ASSET: Robust Backdoor Data Detection Across a Multiplicity of Deep Learning Paradigms.",
            "venue": "USENIX Security Symposium",
            "pages": "2725-2742",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PanZLLJ23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/pan",
            "url": "https://dblp.org/rec/conf/uss/PanZLLJ23",
            "abstract": "Backdoor data detection is traditionally studied in an end-to-end supervised learning (SL) setting. However, recent years have seen the proliferating adoption of self-supervised learning (SSL) and transfer learning (TL), due to their lesser need for labeled data. Successful backdoor attacks have also been demonstrated in these new settings. However, we lack a thorough understanding of the applicability of existing detection methods across a variety of learning settings. By evaluating 56 attack settings, we show that the performance of most existing detection methods varies significantly across different attacks and poison ratios, and all fail on the state-of-the-art clean-label attack. In addition, they either become inapplicable or suffer large performance losses when applied to SSL and TL. We propose a new detection method called Active Separation via Offset (ASSET), which actively induces different model behaviors between the backdoor and clean samples to promote their separation. We also provide procedures to adaptively select the number of suspicious points to remove. In the end-to-end SL setting, ASSET is superior to existing methods in terms of consistency of defensive performance across different attacks and robustness to changes in poison ratios; in particular, it is the only method that can detect the state-of-the-art clean-label attack. Moreover, ASSET's average detection rates are higher than the best existing methods in SSL and TL, respectively, by 69.3% and 33.2%, thus providing the first practical backdoor defense for these new DL settings. We open-source the project to drive further development and encourage engagement: https://github.com/ruoxi-jia-group/ASSET.",
            "keywords": [
                "Backdoor Data Detection",
                "Self-Supervised Learning",
                "Transfer Learning",
                "Active Separation via Offset",
                "Clean-Label Attack"
            ]
        },
        "url": "URL#915405",
        "sema_paperId": "28d394d1707c21b039db75af9542f41a5782441f"
    },
    {
        "@score": "1",
        "@id": "915406",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "164/5196",
                        "text": "Sharbani Pandit"
                    },
                    {
                        "@pid": "164/5072",
                        "text": "Krishanu Sarker"
                    },
                    {
                        "@pid": "60/6768",
                        "text": "Roberto Perdisci"
                    },
                    {
                        "@pid": "73/3162",
                        "text": "Mustaque Ahamad"
                    },
                    {
                        "@pid": "70/11145",
                        "text": "Diyi Yang"
                    }
                ]
            },
            "title": "Combating Robocalls with Phone Virtual Assistant Mediated Interaction.",
            "venue": "USENIX Security Symposium",
            "pages": "463-479",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PanditSPAY23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/pandit",
            "url": "https://dblp.org/rec/conf/uss/PanditSPAY23",
            "abstract": "Mass robocalls affect millions of people on a daily basis. Unfortunately, most current defenses against robocalls rely on phone blocklists and are ineffective against caller ID spoo\ufb01ng. To enable detection and blocking of spoofed robocalls, we propose a NLP-based smartphone virtual assistant that automatically vets incoming calls. Similar to a human assistant, the virtual assistant picks up an incoming call and uses machine learning models to interact with the caller to determine if the call source is a human or a robocaller. It interrupts a user by ringing the phone only when the call is determined to be not from a robocaller. Security analysis performed by us shows that such a system can stop current and more sophisticated robocallers that might emerge in the future. We also conduct a user study that shows that the virtual assistant can preserve phone call user experience.",
            "keywords": [
                "Robocall Detection",
                "Virtual Assistant",
                "Caller Identification",
                "NLP Interaction",
                "Spoofed Calls"
            ]
        },
        "url": "URL#915406",
        "sema_paperId": "0275f92a81459bf84d7cba4700b4e8be1109b9f2"
    },
    {
        "@score": "1",
        "@id": "915407",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "04/773",
                        "text": "Sarvar Patel"
                    },
                    {
                        "@pid": "175/1759",
                        "text": "Joon Young Seo"
                    },
                    {
                        "@pid": "176/7649",
                        "text": "Kevin Yeo"
                    }
                ]
            },
            "title": "Don&apos;t be Dense: Efficient Keyword PIR for Sparse Databases.",
            "venue": "USENIX Security Symposium",
            "pages": "3853-3870",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PatelSY23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/patel",
            "url": "https://dblp.org/rec/conf/uss/PatelSY23",
            "abstract": "In this paper, we introduce SparsePIR, a single-server keyword private information retrieval (PIR) construction that enables querying over sparse databases. At its core, SparsePIR is based on a novel encoding algorithm that encodes sparse database entries as linear combinations while being compatible with important PIR optimizations including recursion. SparsePIR achieves response overhead that is half of state-of-the art keyword PIR schemes without requiring long-term client storage of linear-sized mappings. We also introduce two variants, SparsePIRg and SparsePIRc, that further reduces the size of the serving database at the cost of increased encoding time and small additional client storage, respectively. Our frameworks enable performing keyword PIR with, essentially, the same costs as standard PIR. Finally, we also show that SparsePIR may be used to build batch keyword PIR with halved response overhead without any client mappings.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-patel.pdf",
            "keywords": [
                "Keyword Private Information Retrieval",
                "Sparse Databases",
                "Encoding Algorithm",
                "Response Overhead",
                "Batch Keyword PIR"
            ]
        },
        "url": "URL#915407"
    },
    {
        "@score": "1",
        "@id": "915408",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "39/780",
                        "text": "Kenneth G. Paterson"
                    },
                    {
                        "@pid": "201/6435",
                        "text": "Matteo Scarlata"
                    },
                    {
                        "@pid": "389/5650",
                        "text": "Kien Tuong Truong"
                    }
                ]
            },
            "title": "Three Lessons From Threema: Analysis of a Secure Messenger.",
            "venue": "USENIX Security Symposium",
            "pages": "1289-1306",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PatersonST23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/paterson",
            "url": "https://dblp.org/rec/conf/uss/PatersonST23",
            "abstract": "We provide an extensive cryptographic analysis of Threema, a Swiss-based encrypted messaging application with more than 10 million users and 7000 corporate customers. We present seven different attacks against the protocol in three different threat models. We discuss impact and remediations for our attacks, which have all been responsibly disclosed to Threema and patched. Finally, we draw wider lessons for developers of secure protocols.",
            "keywords": [
                "Cryptographic Analysis",
                "Secure Messaging",
                "Threema",
                "Protocol Attacks",
                "Threat Models"
            ]
        },
        "url": "URL#915408",
        "sema_paperId": "8ef3e20f8218a7974a41e56f1cd61e72464d1ff2"
    },
    {
        "@score": "1",
        "@id": "915409",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "227/2618",
                        "text": "Eric Pauley"
                    },
                    {
                        "@pid": "b/PaulBarford",
                        "text": "Paul Barford"
                    },
                    {
                        "@pid": "m/PatrickDrewMcDaniel",
                        "text": "Patrick D. McDaniel"
                    }
                ]
            },
            "title": "DScope: A Cloud-Native Internet Telescope.",
            "venue": "USENIX Security Symposium",
            "pages": "5989-6006",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PauleyBM23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/pauley",
            "url": "https://dblp.org/rec/conf/uss/PauleyBM23",
            "abstract": "Data from Internet telescopes that monitor routed but unused IP address space has been the basis for myriad insights on malicious, unwanted, and unexpected behavior. However, service migration to cloud infrastructure and the increasing scarcity of IPv4 address space present serious challenges to traditional Internet telescopes. This paper describes DS COPE , a cloud-based Internet telescope designed to be scalable and interactive. We describe the design and implementation of DS COPE , which includes two major components. Collectors are deployed on cloud VMs, interact with incoming connection requests, and capture pcap traces. The data processing pipeline organizes, transforms, and archives the pcap s from deployed collectors for post-facto analysis. In comparing a sampling of DS COPE \u2019s collected traffic with that of a traditional telescope, we see a striking difference in both the quantity and phenomena of behavior targeting cloud systems, with up to 450 \u00d7 as much cloud-targeting as expected under random scanning. We also show that DS COPE \u2019s adaptive approach achieves impressive price performance: optimal yield of scanners on a given IP address is achieved in under 8 minutes of observation. Our results demonstrate that cloud-based telescopes achieve a significantly broader and more comprehensive perspective than traditional techniques.",
            "keywords": [
                "Cloud-Native Internet Telescope",
                "IPv4 Address Space",
                "Data Collection",
                "Traffic Analysis",
                "Cloud Targeting Behavior"
            ]
        },
        "url": "URL#915409",
        "sema_paperId": "718f4eada39ee24e90c974628012add5d8e0df3f"
    },
    {
        "@score": "1",
        "@id": "915410",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "79/433",
                        "text": "Hui Peng"
                    },
                    {
                        "@pid": "154/8284-1",
                        "text": "Zhihao Yao 0001"
                    },
                    {
                        "@pid": "20/8069",
                        "text": "Ardalan Amiri Sani"
                    },
                    {
                        "@pid": "159/0537",
                        "text": "Dave Tian"
                    },
                    {
                        "@pid": "31/1273",
                        "text": "Mathias Payer"
                    }
                ]
            },
            "title": "GLeeFuzz: Fuzzing WebGL Through Error Message Guided Mutation.",
            "venue": "USENIX Security Symposium",
            "pages": "1883-1899",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PengYSTP23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/peng",
            "url": "https://dblp.org/rec/conf/uss/PengYSTP23",
            "abstract": "WebGL is a set of standardized JavaScript APIs for GPU accelerated graphics. Security of the WebGL interface is paramount because it exposes remote and unsandboxed access to the underlying graphics stack (including the native GL libraries and GPU drivers) in the host OS. Unfortunately, applying state-of-the-art fuzzing techniques to the WebGL interface for vulnerability discovery is challenging because of (1) its huge input state space, and (2) the infeasibility of collecting code coverage across concurrent processes, closed-source libraries, and device drivers in the kernel. Our fuzzing technique, GLeeFuzz, guides input mutation by error messages instead of code coverage. Our key observation is that browsers emit meaningful error messages to aid developers in debugging their WebGL programs. Error messages indicate which part of the input fails (e.g., incomplete arguments, invalid arguments, or unsatis\ufb01ed dependencies be-tween API calls). Leveraging error messages as feedback, the fuzzer effectively expands coverage by focusing mutation on erroneous parts of the input . We analyze Chrome\u2019s WebGL implementation to identify the dependencies between error-emitting statements and rejected parts of the input, and use this information to guide input mutation. We evaluate our GLeeFuzz prototype on Chrome, Firefox, and Safari on diverse desktop and mobile OSes. We discovered 7 vulnerabilities, 4 in Chrome, 2 in Safari, and 1 in Firefox. The Chrome vulnerabilities allow a remote attacker to freeze the GPU and possibly execute remote code at the browser privilege.",
            "keywords": [
                "WebGL Security",
                "Fuzzing Techniques",
                "Error Message Analysis",
                "Input Mutation",
                "Vulnerability Discovery"
            ]
        },
        "url": "URL#915410",
        "sema_paperId": "729fa869f8898ea8571eac45afdd97c25d4351b0"
    },
    {
        "@score": "1",
        "@id": "915411",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "237/0174",
                        "text": "Julien Piet"
                    },
                    {
                        "@pid": "70/5324",
                        "text": "Aashish Sharma"
                    },
                    {
                        "@pid": "p/VernPaxson",
                        "text": "Vern Paxson"
                    },
                    {
                        "@pid": "42/5626",
                        "text": "David A. Wagner 0001"
                    }
                ]
            },
            "title": "Network Detection of Interactive SSH Impostors Using Deep Learning.",
            "venue": "USENIX Security Symposium",
            "pages": "4283-4300",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PietSP023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/piet",
            "url": "https://dblp.org/rec/conf/uss/PietSP023",
            "abstract": "Impostors who have stolen a user\u2019s SSH login credentials can inflict significant harm to the systems to which the user has remote access. We consider the problem of identifying such imposters when they conduct interactive SSH logins by detecting discrepancies in the timing and sizes of the client-side data packets, which generally reflect the typing dynamics of the person sending keystrokes over the connection. The problem of keystroke authentication using unknown freeform text has received limited-scale study to date. We develop a supervised approach based on using a transformer (a sequence model from the ML deep learning literature) and a custom \u201cpartition layer\u201d that, once trained, takes as input the sequence of client packet timings and lengths, plus a purported user label, and outputs a decision regarding whether the sequence indeed corresponds to that user. We evaluate the model on 5 years of labeled SSH PCAPs (spanning 3,900 users) from a large research institute. While the performance specifics vary with training levels, we find that in all cases the model can catch over 95% of (injected) imposters within the first minutes of a connection, while incurring a manageable level of false positives per day.",
            "keywords": [
                "SSH Authentication",
                "Keystroke Dynamics",
                "Impostor Detection",
                "Packet Timing Analysis",
                "Transformer Model"
            ]
        },
        "url": "URL#915411",
        "sema_paperId": "7d1c33406f231c15acdd3859b362109627f7f765"
    },
    {
        "@score": "1",
        "@id": "915413",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "40/11429",
                        "text": "Antigoni Polychroniadou"
                    },
                    {
                        "@pid": "25/7423",
                        "text": "Gilad Asharov"
                    },
                    {
                        "@pid": "261/5164",
                        "text": "Benjamin E. Diamond"
                    },
                    {
                        "@pid": "b/TuckerRBalch",
                        "text": "Tucker Balch"
                    },
                    {
                        "@pid": "78/468",
                        "text": "Hans Buehler"
                    },
                    {
                        "@pid": "192/6105",
                        "text": "Richard Hua"
                    },
                    {
                        "@pid": "208/0664",
                        "text": "Suwen Gu"
                    },
                    {
                        "@pid": "343/6238",
                        "text": "Greg Gimler"
                    },
                    {
                        "@pid": "v/ManuelaMVeloso",
                        "text": "Manuela Veloso"
                    }
                ]
            },
            "title": "Prime Match: A Privacy-Preserving Inventory Matching System.",
            "venue": "USENIX Security Symposium",
            "pages": "6417-6434",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PolychroniadouA23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/polychroniadou",
            "url": "https://dblp.org/rec/conf/uss/PolychroniadouA23",
            "abstract": "Inventory matching is a standard mechanism for trading financial stocks by which buyers and sellers can be paired. In the financial world, banks often undertake the task of finding such matches between their clients. The related stocks can be traded without adversely impacting the market price for either client. If matches between clients are found, the bank can offer the trade at advantageous rates. If no match is found, the parties have to buy or sell the stock in the public market, which introduces additional costs. \nA problem with the process as it is presently conducted is that the involved parties must share their order to buy or sell a particular stock, along with the intended quantity (number of shares), to the bank.  Clients worry that if this information were to \u201cleak\u201d somehow, then other market participants would become aware of their intentions and thus cause the price to move adversely against them before their transaction finalizes.\nWe provide a solution that enables clients to match their orders efficiently with reduced market impact while maintaining privacy. In the case where there are no matches, no information is revealed. Our main cryptographic innovation is a two-round secure linear comparison protocol for computing the minimum between two quantities without preprocessing and with malicious security, which can be of independent interest. We report benchmarks of our Prime Match system, which runs in production and is adopted by a large bank in the US - J.P. Morgan. Prime Match is the first secure multiparty computation solution running live in the financial world.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-polychroniadou.pdf",
            "keywords": [
                "Privacy-Preserving Computation",
                "Inventory Matching",
                "Financial Trading",
                "Secure Multiparty Computation",
                "Market Impact Reduction"
            ]
        },
        "url": "URL#915413"
    },
    {
        "@score": "1",
        "@id": "915414",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "252/6374",
                        "text": "Sathvik Prasad"
                    },
                    {
                        "@pid": "322/0152",
                        "text": "Trevor Dunlap"
                    },
                    {
                        "@pid": "352/8221",
                        "text": "Alexander J. Ross"
                    },
                    {
                        "@pid": "117/3983",
                        "text": "Bradley Reaves"
                    }
                ]
            },
            "title": "Diving into Robocall Content with SnorCall.",
            "venue": "USENIX Security Symposium",
            "pages": "427-444",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PrasadDRR23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/prasad",
            "url": "https://dblp.org/rec/conf/uss/PrasadDRR23",
            "abstract": "Unsolicited bulk telephone calls \u2014 termed \"robocalls\" \u2014 nearly outnumber legitimate calls, overwhelming telephone users. While the vast majority of these calls are illegal, they are also ephemeral. Although telephone service providers, regulators, and researchers have ready access to call metadata, they do not have tools to investigate call content at the vast scale required. This paper presents SnorCall, a framework that scalably and efficiently extracts content from robocalls. SnorCall leverages the Snorkel framework that allows a domain expert to write simple labeling functions to classify text with high accuracy. We apply SnorCall to a corpus of transcripts covering 232,723 robocalls collected over a 23-month period. Among many other findings, SnorCall enables us to obtain first estimates on how prevalent different scam and legitimate robocall topics are, determine which organizations are referenced in these calls, estimate the average amounts solicited in scam calls, identify shared infrastructure between campaigns, and monitor the rise and fall of election-related political calls. As a result, we demonstrate how regulators, carriers, anti-robocall product vendors, and researchers can use SnorCall to obtain powerful and accurate analyses of robocall content and trends that can lead to better defenses.",
            "keywords": [
                "Robocalls",
                "Call Content Analysis",
                "Scam Detection",
                "Telecommunications Regulation",
                "SnorCall Framework"
            ]
        },
        "url": "URL#915414",
        "sema_paperId": "962abd852cbe3f78094c9064b5ac0b7755cfe451"
    },
    {
        "@score": "1",
        "@id": "915415",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "280/8483",
                        "text": "Soumyakant Priyadarshan"
                    },
                    {
                        "@pid": "280/8077",
                        "text": "Huan Nguyen 0004"
                    },
                    {
                        "@pid": "353/7597",
                        "text": "Rohit Chouhan"
                    },
                    {
                        "@pid": "90/1136-1",
                        "text": "R. Sekar 0001"
                    }
                ]
            },
            "title": "SAFER: Efficient and Error-Tolerant Binary Instrumentation.",
            "venue": "USENIX Security Symposium",
            "pages": "1451-1468",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Priyadarshan0C023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/priyadarshan",
            "url": "https://dblp.org/rec/conf/uss/Priyadarshan0C023",
            "abstract": "Recent advances in binary instrumentation have been focused on performance. By statically transforming the code to avoid additional runtime operations, systems such as Egalito and RetroWrite achieve near zero overheads. The safety of these static transformations relies on several assumptions: (a) error-free and complete disassembly, (b) exclusive use of position-independentcode,and(c)codepointeridentification thatisfree of both false positives and false negatives. Violations of these assumptions can cause an instrumented program to crash, or worse, experience delayed failures that corrupt data or compromise security. Many earlier binary instrumentation techniques (e.g., DynamoRio, Pin, and BinCFI) minimized such assumptions, but the price to be paid is a much higher overhead, especially for indirect-call-intensive (e.g., C++) applications. Thus, an open research question is whether the safety benefits of the earlier works can be combined with the performance benefits of recent works. We answer this question in the affirmative by presenting a new instrumentation technique that (a) tolerates the use of position-dependent code and common disassembly and static analysis errors, and (b) detects assumption violations at runtime before they can lead to undefined behavior. Our approach provides a fail-crash primitive for graceful shutdown or recovery. We achieve safe instrumentation without sacrificing performance, introducing a low overhead of about \u223c 2%.",
            "keywords": [
                "Binary Instrumentation",
                "Performance Optimization",
                "Error Tolerance",
                "Static Analysis",
                "Runtime Safety"
            ]
        },
        "url": "URL#915415",
        "sema_paperId": "662703e85470951dd46f142fc0bf362ae0de526d"
    },
    {
        "@score": "1",
        "@id": "915416",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "308/5541",
                        "text": "Jonathan Prokos"
                    },
                    {
                        "@pid": "210/0840",
                        "text": "Neil Fendley"
                    },
                    {
                        "@pid": "74/4531-1",
                        "text": "Matthew Green 0001"
                    },
                    {
                        "@pid": "180/8190",
                        "text": "Roei Schuster"
                    },
                    {
                        "@pid": "t/EranTromer",
                        "text": "Eran Tromer"
                    },
                    {
                        "@pid": "285/5429",
                        "text": "Tushar M. Jois"
                    },
                    {
                        "@pid": "28/8733",
                        "text": "Yinzhi Cao"
                    }
                ]
            },
            "title": "Squint Hard Enough: Attacking Perceptual Hashing with Adversarial Machine Learning.",
            "venue": "USENIX Security Symposium",
            "pages": "211-228",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ProkosF0STJC23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/prokos",
            "url": "https://dblp.org/rec/conf/uss/ProkosF0STJC23",
            "abstract": "Many online communications systems use perceptual hash matching systems to detect illicit \ufb01les in user content. These systems employ specialized perceptual hash functions such as Microsoft\u2019s PhotoDNA or Facebook\u2019s PDQ to produce a compact digest of an image \ufb01le that can be approximately compared to a database of known illicit-content digests. Recently, several proposals have suggested that hash-based matching systems be incorporated into client-side and end-to-end encrypted (E2EE) systems: in these designs, \ufb01les that register as illicit content will be reported to the provider, while the remaining content will be sent con\ufb01dentially. By using perceptual hashing to determine con\ufb01dentiality guarantees, this new setting signi\ufb01cantly changes the function of existing perceptual hashing \u2013 thus motivating the need to evaluate these functions from an adversarial perspective, using their perceptual capabilities against them. For example, an attacker may attempt to trigger a match on innocuous, but politically-charged, content in an attempt to sti\ufb02e speech. In this work we develop threat models for perceptual hashing algorithms in an adversarial setting, and present attacks against the two most widely deployed algorithms: PhotoDNA and PDQ. Our results show that it is possible to ef\ufb01ciently generate targeted second-preimage attacks in which an attacker creates a variant of some source image that matches some target digest. As a complement to this main result, we also further investigate",
            "keywords": [
                "Perceptual Hashing",
                "Adversarial Attacks",
                "PhotoDNA",
                "PDQ",
                "Content Moderation"
            ]
        },
        "url": "URL#915416",
        "sema_paperId": "43b6843ee300583bda9f0a7acbcb9e440e24b684"
    },
    {
        "@score": "1",
        "@id": "915417",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "274/2321",
                        "text": "Xiangyu Qi"
                    },
                    {
                        "@pid": "307/5298",
                        "text": "Tinghao Xie"
                    },
                    {
                        "@pid": "329/4974",
                        "text": "Jiachen T. Wang"
                    },
                    {
                        "@pid": "75/5056",
                        "text": "Tong Wu"
                    },
                    {
                        "@pid": "208/0825",
                        "text": "Saeed Mahloujifar"
                    },
                    {
                        "@pid": "39/6266",
                        "text": "Prateek Mittal"
                    }
                ]
            },
            "title": "Towards A Proactive ML Approach for Detecting Backdoor Poison Samples.",
            "venue": "USENIX Security Symposium",
            "pages": "1685-1702",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/QiXWWMM23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/qi",
            "url": "https://dblp.org/rec/conf/uss/QiXWWMM23",
            "abstract": "Adversaries can embed backdoors in deep learning models by introducing backdoor poison samples into training datasets. In this work, we investigate how to detect such poison samples to mitigate the threat of backdoor attacks. First, we uncover a post-hoc workflow underlying most prior work, where defenders passively allow the attack to proceed and then leverage the characteristics of the post-attacked model to uncover poison samples. We reveal that this workflow does not fully exploit defenders' capabilities, and defense pipelines built on it are prone to failure or performance degradation in many scenarios. Second, we suggest a paradigm shift by promoting a proactive mindset in which defenders engage proactively with the entire model training and poison detection pipeline, directly enforcing and magnifying distinctive characteristics of the post-attacked model to facilitate poison detection. Based on this, we formulate a unified framework and provide practical insights on designing detection pipelines that are more robust and generalizable. Third, we introduce the technique of Confusion Training (CT) as a concrete instantiation of our framework. CT applies an additional poisoning attack to the already poisoned dataset, actively decoupling benign correlation while exposing backdoor patterns to detection. Empirical evaluations on 4 datasets and 14 types of attacks validate the superiority of CT over 14 baseline defenses.",
            "keywords": [
                "Backdoor Detection",
                "Poison Samples",
                "Proactive Defense",
                "Confusion Training",
                "Adversarial Attacks"
            ]
        },
        "url": "URL#915417",
        "sema_paperId": "941bcb4a8fecc14b57e91e6d1167d10b36397ea6"
    },
    {
        "@score": "1",
        "@id": "915418",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "246/5857",
                        "text": "Kaihua Qin"
                    },
                    {
                        "@pid": "248/8003",
                        "text": "Stefanos Chaliasos"
                    },
                    {
                        "@pid": "246/6069",
                        "text": "Liyi Zhou"
                    },
                    {
                        "@pid": "46/2924",
                        "text": "Benjamin Livshits"
                    },
                    {
                        "@pid": "s/DXSong",
                        "text": "Dawn Song"
                    },
                    {
                        "@pid": "138/9020",
                        "text": "Arthur Gervais"
                    }
                ]
            },
            "title": "The Blockchain Imitation Game.",
            "venue": "USENIX Security Symposium",
            "pages": "3961-3978",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/QinCZLSG23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/qin",
            "url": "https://dblp.org/rec/conf/uss/QinCZLSG23",
            "abstract": "The use of blockchains for automated and adversarial trading has become commonplace. However, due to the transparent nature of blockchains, an adversary is able to observe any pending, not-yet-mined transactions, along with their execution logic. This transparency further enables a new type of adversary, which copies and front-runs profitable pending transactions in real-time, yielding significant financial gains.\nShedding light on such ''copy-paste'' malpractice, this paper introduces the Blockchain Imitation Game and proposes a generalized imitation attack methodology called Ape. Leveraging dynamic program analysis techniques, Ape supports the automatic synthesis of adversarial smart contracts. Over a timeframe of one year (1st of August, 2021 to 31st of July, 2022), Ape could have yielded 148.96M USD in profit on Ethereum, and 42.70M USD on BNB Smart Chain (BSC).\nNot only as a malicious attack, we further show the potential of transaction and contract imitation as a defensive strategy. Within one year, we find that Ape could have successfully imitated 13 and 22 known DeFi attacks on Ethereum and BSC, respectively. Our findings suggest that blockchain validators can imitate attacks in real-time to prevent intrusions in DeFi.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-qin.pdf",
            "keywords": [
                "Blockchain Trading",
                "Imitation Attack",
                "Dynamic Program Analysis",
                "DeFi Security",
                "Front-Running"
            ]
        },
        "url": "URL#915418"
    },
    {
        "@score": "1",
        "@id": "915419",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "150/8244",
                        "text": "Wenjun Qiu"
                    },
                    {
                        "@pid": "l/DavidLie",
                        "text": "David Lie"
                    },
                    {
                        "@pid": "169/3376",
                        "text": "Lisa M. Austin"
                    }
                ]
            },
            "title": "Calpric: Inclusive and Fine-grain Labeling of Privacy Policies with Crowdsourcing and Active Learning.",
            "venue": "USENIX Security Symposium",
            "pages": "1055-1072",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/QiuLA23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/qiu",
            "url": "https://dblp.org/rec/conf/uss/QiuLA23",
            "abstract": "A significant challenge to training accurate deep learning models on privacy policies is the cost and difficulty of obtaining a large and comprehensive set of training data. To address these challenges, we present Calpric , which combines automatic text selection and segmentation, active learning and the use of crowdsourced annotators to generate a large, balanced training set for privacy policies at low cost. Automated text selection and segmentation simplifies the labeling task, enabling untrained annotators from crowdsourcing platforms, like Amazon's Mechanical Turk, to be competitive with trained annotators, such as law students, and also reduces inter-annotator agreement, which decreases labeling cost. Having reliable labels for training enables the use of active learning, which uses fewer training samples to efficiently cover the input space, further reducing cost and improving class and data category balance in the data set.\nThe combination of these techniques allows Calpric to produce models that are accurate over a wider range of data categories, and provide more detailed, fine-grain labels than previous work. Our crowdsourcing process enables Calpric to attain reliable labeled data at a cost of roughly $0.92-$1.71 per labeled text segment. Calpric 's training process also generates a labeled data set of 16K privacy policy text segments across 9 Data categories with balanced positive and negative samples.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-qiu.pdf",
            "keywords": [
                "Privacy Policy Labeling",
                "Crowdsourcing",
                "Active Learning",
                "Data Annotation",
                "Training Data Generation"
            ]
        },
        "url": "URL#915419"
    },
    {
        "@score": "1",
        "@id": "915420",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "67/10326",
                        "text": "Jian Qu"
                    },
                    {
                        "@pid": "18/10062",
                        "text": "Xiaobo Ma"
                    },
                    {
                        "@pid": "10/3844-6",
                        "text": "Jianfeng Li 0006"
                    },
                    {
                        "@pid": "53/1565",
                        "text": "Xiapu Luo"
                    },
                    {
                        "@pid": "68/2052-1",
                        "text": "Lei Xue 0001"
                    },
                    {
                        "@pid": "99/6243-4",
                        "text": "Junjie Zhang 0004"
                    },
                    {
                        "@pid": "61/1951-1",
                        "text": "Zhenhua Li 0001"
                    },
                    {
                        "@pid": "39/456",
                        "text": "Li Feng"
                    },
                    {
                        "@pid": "45/503",
                        "text": "Xiaohong Guan"
                    }
                ]
            },
            "title": "An Input-Agnostic Hierarchical Deep Learning Framework for Traffic Fingerprinting.",
            "venue": "USENIX Security Symposium",
            "pages": "589-606",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/QuMLL000FG23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/qu",
            "url": "https://dblp.org/rec/conf/uss/QuMLL000FG23",
            "abstract": "Deep learning has proven to be promising for traffic finger-printing that explores features of packet timing and sizes. Although well-known for automatic feature extraction, it is faced with a gap between the heterogeneousness of the traffic (i.e., raw packet timing and sizes) and the homogeneousness of the required input (i.e., input-specific ). To address this gap, we design an input-agnostic hierarchical deep learning framework for traffic fingerprinting that can hierarchically abstract comprehensive heterogeneous traffic features into homogeneous vectors seamlessly digestible by existing neural networks for further classification. The extensive evaluation demonstrates that our framework, with just one paradigm, not only supports heterogeneous traffic input but also achieves better or comparable performance compared to state-of-the-art methods across a wide range of traffic fingerprinting tasks.",
            "keywords": [
                "Traffic Fingerprinting",
                "Hierarchical Deep Learning",
                "Heterogeneous Traffic Features",
                "Input-Agnostic Framework",
                "Traffic Classification"
            ]
        },
        "url": "URL#915420",
        "sema_paperId": "2a04d83650779decba21a5ffd24a928b2fd1bb35"
    },
    {
        "@score": "1",
        "@id": "915421",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "244/5063",
                        "text": "Prashant Hari Narayan Rajput"
                    },
                    {
                        "@pid": "314/5471",
                        "text": "Constantine Doumanidis"
                    },
                    {
                        "@pid": "56/1494",
                        "text": "Michail Maniatakos"
                    }
                ]
            },
            "title": "ICSPatch: Automated Vulnerability Localization and Non-Intrusive Hotpatching in Industrial Control Systems using Data Dependence Graphs.",
            "venue": "USENIX Security Symposium",
            "pages": "6861-6876",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RajputDM23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/rajput",
            "url": "https://dblp.org/rec/conf/uss/RajputDM23",
            "abstract": "The paradigm shift of enabling extensive intercommunication between the Operational Technology (OT) and Information Technology (IT) devices allows vulnerabilities typical to the IT world to propagate to the OT side. Therefore, the security layer offered in the past by air gapping is removed, making security patching for OT devices a hard requirement. Conventional patching involves a device reboot to load the patched code in the main memory, which does not apply to OT devices controlling critical processes due to downtime, necessitating in-memory vulnerability patching. Furthermore, these control binaries are often compiled by in-house proprietary compilers, further hindering the patching process and placing reliance on OT vendors for rapid vulnerability discovery and patch development. The current state-of-the-art hotpatching approaches only focus on firmware and/or RTOS. Therefore, in this work, we develop ICSPatch, a framework to automate control logic vulnerability localization using Data Dependence Graphs (DDGs). With the help of DDGs, ICSPatch pinpoints the vulnerability in the control application. As an independent second step, ICSPatch can non-intrusively hotpatch vulnerabilities in the control application directly in the main memory of Programmable Logic Controllers while maintaining reliable continuous operation. To evaluate our framework, we test ICSPatch on a synthetic dataset of 24 vulnerable control application binaries from diverse critical infrastructure sectors. Results show that ICSPatch could successfully localize all vulnerabilities and generate patches accordingly. Furthermore, the patch added negligible latency increase in the execution cycle while maintaining correctness and protection against the vulnerability.",
            "keywords": [
                "Industrial Control Systems",
                "Vulnerability Localization",
                "Hotpatching",
                "Data Dependence Graphs",
                "In-Memory Patching"
            ]
        },
        "url": "URL#915421",
        "sema_paperId": "7b47cf831845bfd2a266f6c48b99cccec1e8ac75"
    },
    {
        "@score": "1",
        "@id": "915422",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "270/2465",
                        "text": "Reethika Ramesh"
                    },
                    {
                        "@pid": "270/2488",
                        "text": "Ram Sundara Raman"
                    },
                    {
                        "@pid": "331/2188",
                        "text": "Apurva Virkud"
                    },
                    {
                        "@pid": "297/8337",
                        "text": "Alexandra Dirksen"
                    },
                    {
                        "@pid": "353/7619",
                        "text": "Armin Huremagic"
                    },
                    {
                        "@pid": "116/4822",
                        "text": "David Fifield"
                    },
                    {
                        "@pid": "20/1540",
                        "text": "Dirk Rodenburg"
                    },
                    {
                        "@pid": "169/8860",
                        "text": "Rod Hynes"
                    },
                    {
                        "@pid": "16/10681",
                        "text": "Douglas Madory"
                    },
                    {
                        "@pid": "24/973",
                        "text": "Roya Ensafi"
                    }
                ]
            },
            "title": "Network Responses to Russia&apos;s Invasion of Ukraine in 2022: A Cautionary Tale for Internet Freedom.",
            "venue": "USENIX Security Symposium",
            "pages": "2581-2598",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RameshRVDHFRHME23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/ramesh-network-responses",
            "url": "https://dblp.org/rec/conf/uss/RameshRVDHFRHME23",
            "abstract": "Russia\u2019s invasion of Ukraine in February 2022 was followed by sanctions and restrictions: by Russia against its citizens, by Russia against the world, and by foreign actors against Russia. Reports suggested a torrent of increased censorship, geoblocking, and network events affecting Internet freedom. This paper is an investigation into the network changes that occurred in the weeks following this escalation of hostili-ties. It is the result of a rapid mobilization of researchers and activists, examining the problem from multiple perspectives. We develop GeoInspector, and conduct measurements to identify different types of geoblocking, and synthesize data from nine independent data sources to understand and describe various network changes. Immediately after the invasion, more than 45% of Russian government domains tested blocked access from countries other than Russia and Kazakhstan; conversely, 444 foreign websites, including news and educational domains, geoblocked Russian users. We find significant increases in Russian censorship, especially of news and social media. We find evidence of the use of BGP withdrawals to implement restrictions, and we quantify the use of a new domestic certificate authority. Finally, we analyze data from circumvention tools, and investigate their usage and blocking. We hope that our findings showing the rapidly shifting landscape of Internet splintering serves as a cautionary tale, and encourages research and efforts to protect Internet freedom.",
            "keywords": [
                "Internet Freedom",
                "Geoblocking",
                "Censorship",
                "Network Changes",
                "BGP Withdrawals"
            ]
        },
        "url": "URL#915422",
        "sema_paperId": "7be7676ae682b0cee00dcfa4a86adb59bac9748d"
    },
    {
        "@score": "1",
        "@id": "915423",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "270/2465",
                        "text": "Reethika Ramesh"
                    },
                    {
                        "@pid": "304/6401",
                        "text": "Anjali Vyas"
                    },
                    {
                        "@pid": "24/973",
                        "text": "Roya Ensafi"
                    }
                ]
            },
            "title": "&quot;All of them claim to be the best&quot;: Multi-perspective study of VPN users and VPN providers.",
            "venue": "USENIX Security Symposium",
            "pages": "5773-5789",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RameshVE23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/ramesh-vpn",
            "url": "https://dblp.org/rec/conf/uss/RameshVE23",
            "abstract": "As more users adopt VPNs for a variety of reasons, it is important to develop empirical knowledge of their needs and mental models of what a VPN offers. Moreover, studying VPN users alone is not enough because, by using a VPN, a user essentially transfers trust, say from their network provider, onto the VPN provider. To that end, we are the first to study the VPN ecosystem from both the users' and the providers' perspectives. In this paper, we conduct a quantitative survey of 1,252 VPN users in the U.S. and qualitative interviews of nine providers to answer several research questions regarding the motivations, needs, threat model, and mental model of users, and the key challenges and insights from VPN providers. We create novel insights by augmenting our multi-perspective results, and highlight cases where the user and provider perspectives are misaligned. Alarmingly, we find that users rely on and trust VPN review sites, but VPN providers shed light on how these sites are mostly motivated by money. Worryingly, we find that users have flawed mental models about the protection VPNs provide, and about data collected by VPNs. We present actionable recommendations for technologists and security and privacy advocates by identifying potential areas on which to focus efforts and improve the VPN ecosystem.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-ramesh-vpn.pdf",
            "keywords": [
                "VPN Ecosystem",
                "User Trust",
                "VPN Providers",
                "User Mental Models",
                "VPN Review Sites"
            ]
        },
        "url": "URL#915423"
    },
    {
        "@score": "1",
        "@id": "915424",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "223/6113",
                        "text": "Deevashwer Rathee"
                    },
                    {
                        "@pid": "279/3993",
                        "text": "Anwesh Bhattacharya"
                    },
                    {
                        "@pid": "66/11477-1",
                        "text": "Divya Gupta 0001"
                    },
                    {
                        "@pid": "22/846-1",
                        "text": "Rahul Sharma 0001"
                    },
                    {
                        "@pid": "s/DXSong",
                        "text": "Dawn Song"
                    }
                ]
            },
            "title": "Secure Floating-Point Training.",
            "venue": "USENIX Security Symposium",
            "pages": "6329-6346",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RatheeB00S23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/rathee",
            "url": "https://dblp.org/rec/conf/uss/RatheeB00S23",
            "abstract": "Secure 2-party computation (2PC) of floating-point arithmetic is improving in performance and recent work runs deep learning algorithms with it, while being as numerically precise as commonly used machine learning (ML) frameworks like PyTorch. We find that the existing 2PC libraries for floating-point support generic computations and lack specialized support for ML training. Hence, their latency and communication costs for compound operations (e.g., dot products) are high. We provide novel specialized 2PC protocols for compound operations and prove their precision using numerical analysis. Our implementation BEACON outperforms state-of-the-art libraries for 2PC of floating-point by over $6\\times$.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-rathee.pdf",
            "keywords": [
                "Secure 2-party computation",
                "Floating-point arithmetic",
                "Machine Learning training",
                "Compound operations",
                "Numerical precision"
            ]
        },
        "url": "URL#915424"
    },
    {
        "@score": "1",
        "@id": "915425",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "198/1034",
                        "text": "Ruben Recabarren"
                    },
                    {
                        "@pid": "20/4777",
                        "text": "Bogdan Carbunar"
                    },
                    {
                        "@pid": "98/6487",
                        "text": "Nestor Hernandez"
                    },
                    {
                        "@pid": "331/5645",
                        "text": "Ashfaq Ali Shafin"
                    }
                ]
            },
            "title": "Strategies and Vulnerabilities of Participants in Venezuelan Influence Operations.",
            "venue": "USENIX Security Symposium",
            "pages": "6683-6700",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RecabarrenCHS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/recabarren",
            "url": "https://dblp.org/rec/conf/uss/RecabarrenCHS23",
            "abstract": "Studies of online influence operations, coordinated efforts to disseminate and amplify disinformation, focus on forensic analysis of social networks or of publicly available datasets of trolls and bot accounts. However, little is known about the experiences and challenges of human participants in influence operations. We conducted semi-structured interviews with 19 influence operations participants that contribute to the online image of Venezuela, to understand their incentives, capabilities, and strategies to promote content while evading detection. To validate a subset of their answers, we performed a quantitative investigation using data collected over almost four months, from Twitter accounts they control.\nWe found diverse participants that include pro-government and opposition supporters, operatives and grassroots campaigners, and sockpuppet account owners and real users. While pro-government and opposition participants have similar goals and promotion strategies, they differ in their motivation, organization, adversaries and detection avoidance strategies. We report the Patria framework, a government platform for operatives to log activities and receive benefits. We systematize participant strategies to promote political content, and to evade and recover from Twitter penalties. We identify vulnerability points associated with these strategies, and suggest more nuanced defenses against influence operations.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-recabarren.pdf",
            "keywords": [
                "Influence Operations",
                "Disinformation Campaigns",
                "Social Media Manipulation",
                "Participant Strategies",
                "Vulnerabilities in Influence Operations"
            ]
        },
        "url": "URL#915425"
    },
    {
        "@score": "1",
        "@id": "915426",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "35/8864",
                        "text": "Dani\u00ebl Reijsbergen"
                    },
                    {
                        "@pid": "252/0040",
                        "text": "Aung Maw"
                    },
                    {
                        "@pid": "59/5806-1",
                        "text": "Zheng Yang 0001"
                    },
                    {
                        "@pid": "24/1541",
                        "text": "Tien Tuan Anh Dinh"
                    },
                    {
                        "@pid": "z/JianyingZhou",
                        "text": "Jianying Zhou 0001"
                    }
                ]
            },
            "title": "TAP: Transparent and Privacy-Preserving Data Services.",
            "venue": "USENIX Security Symposium",
            "pages": "6489-6506",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ReijsbergenM0D023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/reijsbergen",
            "url": "https://dblp.org/rec/conf/uss/ReijsbergenM0D023",
            "abstract": "Users today expect more security from services that handle their data. In addition to traditional data privacy and integrity requirements, they expect transparency, i.e., that the service's processing of the data is verifiable by users and trusted auditors. Our goal is to build a multi-user system that provides data privacy, integrity, and transparency for a large number of operations, while achieving practical performance. To this end, we first identify the limitations of existing approaches that use authenticated data structures. We find that they fall into two categories: 1) those that hide each user's data from other users, but have a limited range of verifiable operations (e.g., CONIKS, Merkle2, and Proofs of Liabilities), and 2) those that support a wide range of verifiable operations, but make all data publicly visible (e.g., IntegriDB and FalconDB). We then present TAP to address the above limitations. The key component of TAP is a novel tree data structure that supports efficient result verification, and relies on independent audits that use zero-knowledge range proofs to show that the tree is constructed correctly without revealing user data. TAP supports a broad range of verifiable operations, including quantiles and sample standard deviations. We conduct a comprehensive evaluation of TAP, and compare it against two state-of-the-art baselines, namely IntegriDB and Merkle2, showing that the system is practical at scale.",
            "keywords": [
                "Data Privacy",
                "Data Integrity",
                "Transparent Data Services",
                "Zero-Knowledge Proofs",
                "Verifiable Operations"
            ]
        },
        "url": "URL#915426",
        "sema_paperId": "43ec5edb1c3a4b7ef902b6fd36f0f75b624e68fe"
    },
    {
        "@score": "1",
        "@id": "915427",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "28/9860",
                        "text": "Yili Ren"
                    },
                    {
                        "@pid": "79/10448",
                        "text": "Yichao Wang"
                    },
                    {
                        "@pid": "167/8033",
                        "text": "Sheng Tan"
                    },
                    {
                        "@pid": "18/2343-1",
                        "text": "Yingying Chen 0001"
                    },
                    {
                        "@pid": "12/1198-3",
                        "text": "Jie Yang 0003"
                    }
                ]
            },
            "title": "Person Re-identification in 3D Space: A WiFi Vision-based Approach.",
            "venue": "USENIX Security Symposium",
            "pages": "5217-5234",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RenWT0023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/ren",
            "url": "https://dblp.org/rec/conf/uss/RenWT0023",
            "abstract": "Person re-identification (Re-ID) has become increasingly important as it supports a wide range of security applications. Traditional person Re-ID mainly relies on optical camera-based systems, which incur several limitations due to the changes in the appearance of people, occlusions, and human poses. In this work, we propose a WiFi vision-based system, 3D-ID, for person Re-ID in 3D space. Our system leverages the advances of WiFi and deep learning to help WiFi devices \u201csee\u201d, identify, and recognize people. In particular, we leverage multiple antennas on next-generation WiFi devices and 2D AoA estimation of the signal reflections to enable WiFi to visualize a person in the physical environment. We then leverage deep learning to digitize the visualization of the person into 3D body representation and extract both the static body shape and dynamic walking patterns for person Re-ID. Our evaluation results under various indoor environments show that the 3D-ID system achieves an overall rank-1 accuracy of 85 . 3%. Results also show that our system is resistant to various attacks. The proposed 3D-ID is thus very promising as it could augment or complement camera-based systems.",
            "keywords": [
                "Person Re-identification",
                "WiFi Vision",
                "3D Body Representation",
                "Signal Reflections",
                "Dynamic Walking Patterns"
            ]
        },
        "url": "URL#915427",
        "sema_paperId": "34f9c63a6910150d9314232942a2f8e24441ed51"
    },
    {
        "@score": "1",
        "@id": "915428",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "283/4641",
                        "text": "Phillip Rieger"
                    },
                    {
                        "@pid": "338/0192",
                        "text": "Marco Chilese"
                    },
                    {
                        "@pid": "158/9223-2",
                        "text": "Reham Mohamed 0002"
                    },
                    {
                        "@pid": "05/617",
                        "text": "Markus Miettinen"
                    },
                    {
                        "@pid": "151/8708",
                        "text": "Hossein Fereidooni"
                    },
                    {
                        "@pid": "s/AhmadRezaSadeghi",
                        "text": "Ahmad-Reza Sadeghi"
                    }
                ]
            },
            "title": "ARGUS: Context-Based Detection of Stealthy IoT Infiltration Attacks.",
            "venue": "USENIX Security Symposium",
            "pages": "4301-4318",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RiegerC0MFS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/rieger",
            "url": "https://dblp.org/rec/conf/uss/RiegerC0MFS23",
            "abstract": "IoT application domains, device diversity and connectivity are rapidly growing. IoT devices control various functions in smart homes and buildings, smart cities, and smart factories, making these devices an attractive target for attackers.  On the other hand, the large variability of different application scenarios and inherent heterogeneity of devices make it very challenging to reliably detect abnormal IoT device behaviors and distinguish these from benign behaviors. Existing approaches for detecting attacks are mostly limited to attacks directly compromising individual IoT devices, or, require predefined detection policies. They cannot detect attacks that utilize the control plane of the IoT system to trigger actions in an unintended/malicious context, e.g., opening a smart lock while the smart home residents are absent.\nIn this paper, we tackle this problem and propose ARGUS, the first self-learning intrusion detection system for detecting contextual attacks on IoT environments, in which the attacker maliciously invokes IoT device actions to reach its goals. ARGUS monitors the contextual setting based on the state and actions of IoT devices in the environment. An unsupervised Deep Neural Network (DNN) is used for modeling the typical contextual device behavior and detecting actions taking place in abnormal contextual settings. This unsupervised approach ensures that ARGUS is not restricted to detecting previously known attacks but is also able to detect new attacks. We evaluated ARGUS on heterogeneous real-world smart-home settings and achieve at least an F1-Score of 99.64% for each setup, with a false positive rate (FPR) of at most 0.03%.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-rieger.pdf",
            "keywords": [
                "IoT Security",
                "Intrusion Detection",
                "Contextual Attacks",
                "Self-Learning Systems",
                "Anomaly Detection"
            ]
        },
        "url": "URL#915428"
    },
    {
        "@score": "1",
        "@id": "915429",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "301/5899",
                        "text": "Elsa Turcios Rodriguez"
                    },
                    {
                        "@pid": "353/7567",
                        "text": "Radu Anghel"
                    },
                    {
                        "@pid": "84/3561",
                        "text": "Simon Parkin"
                    },
                    {
                        "@pid": "17/7444",
                        "text": "Michel van Eeten"
                    },
                    {
                        "@pid": "22/7256",
                        "text": "Carlos Ga\u00f1\u00e1n"
                    }
                ]
            },
            "title": "Two Sides of the Shield: Understanding Protective DNS adoption factors.",
            "venue": "USENIX Security Symposium",
            "pages": "3135-3152",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RodriguezAPEG23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/rodriguez",
            "url": "https://dblp.org/rec/conf/uss/RodriguezAPEG23",
            "abstract": "Protective DNS (PDNS) filters out DNS requests leading to harmful resources. PDNS is currently being promoted by various governments and industry players \u2013 some global public DNS providers offer it, as do some government-sponsored DNS resolvers. Yet, are end users even interested in adopting it? The extent of current PDNS usage, as well as the factors that encourage or discourage end-users' adoption, have not been studied. We found that overall PDNS adoption is minimal, though in some countries over 20% of the DNS queries are being answered by these types of resolvers. Four human subjects studies were undertaken to understand end-user adoption factors: a survey with 295 consumers; 24 interviews with ISP customers offered a free PDNS after a malware infection; 12 interviews with public and private enterprise professionals, and 9 interviews with DNS technology specialists. We found that users are more likely to use PDNS if operated by their own ISP rather than the government. For enterprises, we uncovered that access to global threat intelligence, a layered security strategy, and compliance with regulations were the main factors for PDNS adoption. The DNS technical specialists highlighted broader challenges of PDNS adoption such as transparency and centralization.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-rodriguez.pdf",
            "keywords": [
                "Protective DNS",
                "DNS Adoption",
                "User Behavior",
                "Enterprise Security",
                "Threat Intelligence"
            ]
        },
        "url": "URL#915429"
    },
    {
        "@score": "1",
        "@id": "915430",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "295/1057",
                        "text": "Simon Rohlmann"
                    },
                    {
                        "@pid": "138/0964",
                        "text": "Vladislav Mladenov"
                    },
                    {
                        "@pid": "57/11338",
                        "text": "Christian Mainka"
                    },
                    {
                        "@pid": "353/7573",
                        "text": "Daniel Hirschberger"
                    },
                    {
                        "@pid": "58/5730",
                        "text": "J\u00f6rg Schwenk"
                    }
                ]
            },
            "title": "Every Signature is Broken: On the Insecurity of Microsoft Office&apos;s OOXML Signatures.",
            "venue": "USENIX Security Symposium",
            "pages": "7411-7428",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RohlmannMMHS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/rohlmann",
            "url": "https://dblp.org/rec/conf/uss/RohlmannMMHS23",
            "abstract": "Microsoft Office is one of the most widely used applications for office documents. For documents of prime importance, such as contracts and invoices, the content can be signed to guarantee authenticity and integrity. Since 2019, security researchers have uncovered attacks against the integrity protection in other office standards like PDF and ODF. Since Microsoft Office documents rely on different specifications and processing rules, the existing attacks are not applicable. We are the first to provide an in-depth analysis of Office Open XML (OOXML) Signatures, the Ecma/ISO standard that all Microsoft Office applications use. Our analysis reveals major discrepancies between the structure of office documents and the way digital signatures are verified. These discrepancies lead to serious security flaws in the specification and in the implementation. As a result, we discovered five new attack classes. Each attack allows attackers to modify the content in signed documents, while the signatures are still displayed as valid. We tested the attacks against different Microsoft Office versions on Windows and macOS, as well as against OnlyOffice Desktop on Windows, macOS and Linux. All tested Office versions are vulnerable. On macOS, we could reveal a surprising result: although Microsoft Office indicates that the document is protected by a signature, the signature is not validated. The attacks\u2019 impact is alarming: attackers can arbitrarily manipulate the displayed content of a signed document, and victims are unable to detect the tampering. Even worse, we present a universal signature forgery attack that allows the attacker to create an arbitrary document and apply a signature extracted from a different source, such as an ODF document or a SAML token. For the victim, the document is displayed as validly signed by a trusted entity. We propose countermeasures to prevent such issues in the future. During a coordinated disclosure, Microsoft acknowledged and awarded our research with a bug bounty.",
            "keywords": [
                "Office Open XML (OOXML)",
                "Digital Signatures",
                "Document Integrity",
                "Security Flaws",
                "Signature Forgery"
            ]
        },
        "url": "URL#915430",
        "sema_paperId": "a80b41d5128392ebed26472d5edae744a058b41f"
    },
    {
        "@score": "1",
        "@id": "915431",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "230/3942",
                        "text": "Harrison Rosenberg"
                    },
                    {
                        "@pid": "74/4900",
                        "text": "Brian Tang"
                    },
                    {
                        "@pid": "97/535",
                        "text": "Kassem Fawaz"
                    },
                    {
                        "@pid": "j/SomeshJha",
                        "text": "Somesh Jha"
                    }
                ]
            },
            "title": "Fairness Properties of Face Recognition and Obfuscation Systems.",
            "venue": "USENIX Security Symposium",
            "pages": "7231-7248",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RosenbergTFJ23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/rosenberg",
            "url": "https://dblp.org/rec/conf/uss/RosenbergTFJ23",
            "abstract": "The proliferation of automated face recognition in the commercial and government sectors has caused significant privacy concerns for individuals. One approach to address these privacy concerns is to employ evasion attacks against the metric embedding networks powering face recognition systems: Face obfuscation systems generate imperceptibly perturbed images that cause face recognition systems to misidentify the user. Perturbed faces are generated on metric embedding networks, which are known to be unfair in the context of face recognition. A question of demographic fairness naturally follows: are there demographic disparities in face obfuscation system performance? We answer this question with an analytical and empirical exploration of recent face obfuscation systems. Metric embedding networks are found to be demographically aware: face embeddings are clustered by demographic. We show how this clustering behavior leads to reduced face obfuscation utility for faces in minority groups. An intuitive analytical model yields insight into these phenomena.",
            "keywords": [
                "Face Recognition",
                "Face Obfuscation",
                "Demographic Fairness",
                "Evasion Attacks",
                "Metric Embedding Networks"
            ]
        },
        "url": "URL#915431",
        "sema_paperId": "1e556f0d7ca319e3106383a8aca04a6ca33da46b"
    },
    {
        "@score": "1",
        "@id": "915433",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "183/6253",
                        "text": "Sina Sajadmanesh"
                    },
                    {
                        "@pid": "198/1244",
                        "text": "Ali Shahin Shamsabadi"
                    },
                    {
                        "@pid": "61/8017",
                        "text": "Aur\u00e9lien Bellet"
                    },
                    {
                        "@pid": "55/1328",
                        "text": "Daniel Gatica-Perez"
                    }
                ]
            },
            "title": "GAP: Differentially Private Graph Neural Networks with Aggregation Perturbation.",
            "venue": "USENIX Security Symposium",
            "pages": "3223-3240",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SajadmaneshSBG23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/sajadmanesh",
            "url": "https://dblp.org/rec/conf/uss/SajadmaneshSBG23",
            "abstract": "In this paper, we study the problem of learning Graph Neural Networks (GNNs) with Differential Privacy (DP). We propose a novel differentially private GNN based on Aggregation Perturbation (GAP), which adds stochastic noise to the GNN's aggregation function to statistically obfuscate the presence of a single edge (edge-level privacy) or a single node and all its adjacent edges (node-level privacy). Tailored to the specifics of private learning, GAP's new architecture is composed of three separate modules: (i) the encoder module, where we learn private node embeddings without relying on the edge information; (ii) the aggregation module, where we compute noisy aggregated node embeddings based on the graph structure; and (iii) the classification module, where we train a neural network on the private aggregations for node classification without further querying the graph edges. GAP's major advantage over previous approaches is that it can benefit from multi-hop neighborhood aggregations, and guarantees both edge-level and node-level DP not only for training, but also at inference with no additional costs beyond the training's privacy budget. We analyze GAP's formal privacy guarantees using R\u00e9nyi DP and conduct empirical experiments over three real-world graph datasets. We demonstrate that GAP offers significantly better accuracy-privacy trade-offs than state-of-the-art DP-GNN approaches and naive MLP-based baselines. Our code is publicly available at https://github.com/sisaman/GAP.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-sajadmanesh.pdf",
            "keywords": [
                "Graph Neural Networks",
                "Differential Privacy",
                "Aggregation Perturbation",
                "Edge-Level Privacy",
                "Node-Level Privacy"
            ]
        },
        "url": "URL#915433"
    },
    {
        "@score": "1",
        "@id": "915434",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "319/3406",
                        "text": "Patrawat Samermit"
                    },
                    {
                        "@pid": "179/4718",
                        "text": "Anna Turner"
                    },
                    {
                        "@pid": "15/3631",
                        "text": "Patrick Gage Kelley"
                    },
                    {
                        "@pid": "57/1705",
                        "text": "Tara Matthews"
                    },
                    {
                        "@pid": "353/7522",
                        "text": "Vanessia Wu"
                    },
                    {
                        "@pid": "61/1413",
                        "text": "Sunny Consolvo"
                    },
                    {
                        "@pid": "68/8283",
                        "text": "Kurt Thomas"
                    }
                ]
            },
            "title": "&quot;Millions of people are watching you&quot;: Understanding the Digital-Safety Needs and Practices of Creators.",
            "venue": "USENIX Security Symposium",
            "pages": "5629-5645",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SamermitTKMWCT23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/samermit",
            "url": "https://dblp.org/rec/conf/uss/SamermitTKMWCT23",
            "abstract": "Online content creators\u2014who create and share theircontent on platforms such as Instagram, TikTok, Twitch, and YouTube\u2014 are uniquely at-risk of increased digital-safety threats due to their public prominence, the diverse social norms of wide-ranging audiences, and their access to audience members as a valuable resource. We interviewed 23 creators to understand their digital-safety experiences. This includes the security, privacy, and abuse threats they have experienced across multiple platforms and how the threats have changed over time. We also examined the protective practices they have employed to stay safer, including tensions in how they adopt the practices. We found that creators have diverse threat models that take into consideration their emotional, physical, relational, and \ufb01nan-cial safety. Most adopted protections\u2014including distancing from technology, moderating their communities, and seeking external or social support\u2014only after experiencing a serious safety incident. Lessons from their experiences help us better prepare and protect creators and ensure a diversity of voices are present online.",
            "keywords": [
                "Digital Safety",
                "Content Creators",
                "Online Threats",
                "Protective Practices",
                "Community Moderation"
            ]
        },
        "url": "URL#915434",
        "sema_paperId": "51cbb3780244251b7276794c5d3ebf13425c74a7"
    },
    {
        "@score": "1",
        "@id": "915435",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "165/2039",
                        "text": "Iskander S\u00e1nchez-Rola"
                    },
                    {
                        "@pid": "15/6037",
                        "text": "Leyla Bilge"
                    },
                    {
                        "@pid": "56/490",
                        "text": "Davide Balzarotti"
                    },
                    {
                        "@pid": "06/10929",
                        "text": "Armin Buescher"
                    },
                    {
                        "@pid": "91/5849",
                        "text": "Petros Efstathopoulos"
                    }
                ]
            },
            "title": "Rods with Laser Beams: Understanding Browser Fingerprinting on Phishing Pages.",
            "venue": "USENIX Security Symposium",
            "pages": "4157-4173",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Sanchez-RolaBBB23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/sanchez-rola",
            "url": "https://dblp.org/rec/conf/uss/Sanchez-RolaBBB23",
            "abstract": "Phishing is one of the most common forms of social engineering attacks and is regularly used by criminals to compromise millions of accounts every year. Numerous solutions have been proposed to detect or prevent identity thefts, but phishers have responded by improving their methods and adopting more sophisticated techniques. One of the most recent advancements is the use of browser \ufb01ngerprinting. In particular, \ufb01ngerprinting techniques can be used as an additional piece of information that complements the stolen credentials This is con\ufb01rmed by the fact that credentials with \ufb01ngerprint data are sold for higher prices in underground markets. To understand the real extent of this phenomenon, we conducted the largest study of the phishing ecosystem in the topic by analyzing more than 1.7M recent phishing pages that emerged over the course of 21 months. In our systematic study, we performed detailed measurements to estimate the prevalence of \ufb01ngerprinting techniques in phishing pages. We found that more than one in four phishing pages adopt some form of \ufb01ngerprinting. This seems an ever growing trend as the percentage of pages using these techniques steadily increased during the analysis period (last month doubling what detected in the \ufb01rst month).",
            "keywords": [
                "Phishing Detection",
                "Browser Fingerprinting",
                "Social Engineering Attacks",
                "Identity Theft",
                "Phishing Ecosystem"
            ]
        },
        "url": "URL#915435",
        "sema_paperId": "eabd7b7f478145f67e37d064a3d98cd6910caf40"
    },
    {
        "@score": "1",
        "@id": "915436",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "327/3113",
                        "text": "Gustavo Sandoval"
                    },
                    {
                        "@pid": "183/4902",
                        "text": "Hammond Pearce"
                    },
                    {
                        "@pid": "327/3187",
                        "text": "Teo Nys"
                    },
                    {
                        "@pid": "26/1589",
                        "text": "Ramesh Karri"
                    },
                    {
                        "@pid": "94/3807",
                        "text": "Siddharth Garg"
                    },
                    {
                        "@pid": "94/7563",
                        "text": "Brendan Dolan-Gavitt"
                    }
                ]
            },
            "title": "Lost at C: A User Study on the Security Implications of Large Language Model Code Assistants.",
            "venue": "USENIX Security Symposium",
            "pages": "2205-2222",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SandovalPNKGD23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/sandoval",
            "url": "https://dblp.org/rec/conf/uss/SandovalPNKGD23",
            "abstract": "Large Language Models (LLMs) such as OpenAI Codex are increasingly being used as AI-based coding assistants. Understanding the impact of these tools on developers' code is paramount, especially as recent work showed that LLMs may suggest cybersecurity vulnerabilities. We conduct a security-driven user study (N=58) to assess code written by student programmers when assisted by LLMs. Given the potential severity of low-level bugs as well as their relative frequency in real-world projects, we tasked participants with implementing a singly-linked 'shopping list' structure in C. Our results indicate that the security impact in this setting (low-level C with pointer and array manipulations) is small: AI-assisted users produce critical security bugs at a rate no greater than 10% more than the control, indicating the use of LLMs does not introduce new security risks.",
            "keywords": [
                "Large Language Models",
                "Code Assistants",
                "Security Bugs",
                "C Programming",
                "User Study"
            ]
        },
        "url": "URL#915436",
        "sema_paperId": "a889a606734cd47f802765866487c677497a70d6"
    },
    {
        "@score": "1",
        "@id": "915437",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "340/4038",
                        "text": "Xhani Marvin Sa\u00df"
                    },
                    {
                        "@pid": "244/4957",
                        "text": "Richard Mitev"
                    },
                    {
                        "@pid": "s/AhmadRezaSadeghi",
                        "text": "Ahmad-Reza Sadeghi"
                    }
                ]
            },
            "title": "Oops..! I Glitched It Again! How to Multi-Glitch the Glitching-Protections on ARM TrustZone-M.",
            "venue": "USENIX Security Symposium",
            "pages": "6239-6256",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SassMS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/sass",
            "url": "https://dblp.org/rec/conf/uss/SassMS23",
            "abstract": "Voltage Fault Injection (VFI), also known as power glitching, has proven to be a severe threat to real-world systems. In VFI attacks, the adversary disturbs the power-supply of the target-device forcing the device to illegitimate behavior. Various countermeasures have been proposed to address different types of fault injection attacks at different abstraction layers, either requiring to modify the underlying hardware or software/firmware at the machine instruction level. Moreover, only recently, individual chip manufacturers have started to respond to this threat by integrating countermeasures in their products. Generally, these countermeasures aim at protecting against single fault injection (SFI) attacks, since Multiple Fault Injection (MFI) is believed to be challenging and sometimes even impractical.\nIn this paper, we present \u03bc-Glitch, the first Voltage Fault Injection (VFI) platform which is capable of injecting multiple, coordinated voltage faults into a target device, requiring only a single trigger signal. We provide a novel flow for Multiple Voltage Fault Injection (MVFI) attacks to significantly reduce the search complexity for fault parameters, as the search space increases exponentially with each additional fault injection. We evaluate and showcase the effectiveness and practicality of our attack platform on four real-world chips, featuring TrustZone-M: \nThe first two have interdependent backchecking mechanisms, while the second two have additionally integrated countermeasures against fault injection. Our evaluation revealed that \u03bc-Glitch can successfully inject four consecutive faults within an average time of one day. Finally, we discuss potential countermeasures to mitigate VFI attacks and additionally propose two novel attack scenarios for MVFI.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-sass.pdf",
            "keywords": [
                "Voltage Fault Injection",
                "ARM TrustZone-M",
                "Multiple Fault Injection",
                "Countermeasures",
                "Power Glitching"
            ]
        },
        "url": "URL#915437"
    },
    {
        "@score": "1",
        "@id": "915439",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "306/8308",
                        "text": "Giulia Scaffino"
                    },
                    {
                        "@pid": "265/9073",
                        "text": "Lukas Aumayr"
                    },
                    {
                        "@pid": "183/6375",
                        "text": "Zeta Avarikioti"
                    },
                    {
                        "@pid": "25/3571",
                        "text": "Matteo Maffei"
                    }
                ]
            },
            "title": "Glimpse: On-Demand PoW Light Client with Constant-Size Storage for DeFi.",
            "venue": "USENIX Security Symposium",
            "pages": "733-750",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ScaffinoAAM23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/scaffino",
            "url": "https://dblp.org/rec/conf/uss/ScaffinoAAM23",
            "abstract": "Cross-chain communication is instrumental in unleashing the full potential of blockchain technologies, as it allows users and developers to exploit the unique design features and the profit opportunities of different existing blockchains. The majority of interoperability solutions are provided by centralized exchanges and bridge protocols based on a trusted majority, both introducing undesirable trust assumptions compared to native blockchain assets. Hence, increasing attention has been given to decentralized solutions: Light and super-light clients paved the way for chain relays, which allow verifying on a blockchain the state of another blockchain by respectively verifying and storing a linear and logarithmic amount of data. Unfortunately, relays turn out to be inefficient in terms of computational costs, storage, or compatibility. We introduce Glimpse , an on-demand bridge that leverages a novel on-demand light client construction with only constant on-chain storage, cost, and computational overhead. Glimpse is expressive , enabling a plethora of DeFi and off-chain applications such as lending, pegs, proofs of oracle at-testations, and betting hubs. Glimpse also remains compatible with blockchains featuring a limited scripting language such as the Liquid Network (a pegged sidechain of Bitcoin), for which we present a concrete instantiation. We prove Glimpse security in the Universal Composability (UC) framework and further conduct an economic analysis. We evaluate the cost of Glimpse for Bitcoin-like chains: verifying a simple transaction has at most 700 bytes of on-chain overhead, resulting in a one-time fee of $3, only twice as much as a standard Bitcoin transaction.",
            "keywords": [
                "Cross-Chain Communication",
                "Decentralized Solutions",
                "Light Clients",
                "On-Demand Bridge",
                "Constant-Size Storage"
            ]
        },
        "url": "URL#915439",
        "sema_paperId": "ad5605c004e041c3aff0b172a8b4d844ae31997b"
    },
    {
        "@score": "1",
        "@id": "915440",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "272/7190",
                        "text": "Tobias Scharnowski"
                    },
                    {
                        "@pid": "248/1623",
                        "text": "Simon W\u00f6rner"
                    },
                    {
                        "@pid": "353/7581",
                        "text": "Felix Buchmann"
                    },
                    {
                        "@pid": "331/2788",
                        "text": "Nils Bars"
                    },
                    {
                        "@pid": "207/4015",
                        "text": "Moritz Schloegel"
                    },
                    {
                        "@pid": "h/ThorstenHolz",
                        "text": "Thorsten Holz"
                    }
                ]
            },
            "title": "Hoedur: Embedded Firmware Fuzzing using Multi-Stream Inputs.",
            "venue": "USENIX Security Symposium",
            "pages": "2885-2902",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ScharnowskiWBBS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/scharnowski",
            "url": "https://dblp.org/rec/conf/uss/ScharnowskiWBBS23",
            "abstract": "Hoedur is a rehosting-based firmware fuzzer that introduces a multi-stream input format that extends the concepts contained in previous rehosting-based fuzzing works such as P2IM, uEmu, and Fuzzware. This format helps the fuzzer to mutate its input effectively. We provide GitHub repositories containing data and scripts to install our prototype, to automatically reproduce our new firmware targets/configurations, and to auto-generate configurations to rerun our experiments based on the available computation resources. Our experiments run in Docker containers. These can be rebuilt via the provided scripts, or prebuilt Docker containers can be used to rerun our experiments. To facilitate the reproduction, we provide an alternative experiment profile that reduces the CPU requirements while still, in our view, supporting our major claims. In our experiments, we compare our fuzzer against itself in different configurations (with and without multi-stream inputs) and against the related work Fuzzware given that this tool outperformed P2IM and uEmu in an evaluation. We test Hoedur\u2019s speed and reliability in finding known bugs, producing code coverage, and finding previously unknown vulnerabilities.",
            "keywords": [
                "Firmware Fuzzing",
                "Rehosting",
                "Multi-Stream Inputs",
                "Vulnerability Discovery",
                "Code Coverage"
            ]
        },
        "url": "URL#915440",
        "sema_paperId": "10634592710bae16beb30ba057a8497a179cd708"
    },
    {
        "@score": "1",
        "@id": "915441",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "198/6828",
                        "text": "Domien Schepers"
                    },
                    {
                        "@pid": "23/11190",
                        "text": "Aanjhan Ranganathan"
                    },
                    {
                        "@pid": "130/3608",
                        "text": "Mathy Vanhoef"
                    }
                ]
            },
            "title": "Framing Frames: Bypassing Wi-Fi Encryption by Manipulating Transmit Queues.",
            "venue": "USENIX Security Symposium",
            "pages": "53-68",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SchepersRV23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/schepers",
            "url": "https://dblp.org/rec/conf/uss/SchepersRV23",
            "abstract": "Wi-Fi devices routinely queue frames at various layers of the network stack before transmitting, for instance, when the receiver is in sleep mode. In this work, we investigate how Wi-Fi access points manage the security context of queued frames. By exploiting power-save features, we show how to trick access points into leaking frames in plaintext, or encrypted using the group or an all-zero key. We demonstrate resulting attacks against several open-source network stacks. We attribute our findings to the lack of explicit guidance in managing security contexts of buffered frames in the 802.11 standards. The unprotected nature of the power-save bit in a frame\u2019s header, which our work reveals to be a fundamental design flaw, also allows an adversary to force queue frames intended for a specific client resulting in its disconnection and trivially executing a denial-of-service attack. Furthermore, we demonstrate how an attacker can override and control the security context of frames that are yet to be queued. This exploits a design flaw in hotspot-like networks and allows the attacker to force an access points to encrypt yet to be queued frames using an adversary-chosen key, thereby bypassing Wi-Fi encryption entirely. Our attacks have a widespread impact as they affect various devices and operating systems (Linux, FreeBSD, iOS, and Android) and because they can be used to hijack TCP connections or intercept client and web traffic. Overall, we highlight the need for transparency in handling security context across the network stack layers and the challenges in doing so.",
            "keywords": [
                "Wi-Fi Security",
                "Frame Management",
                "Power-Save Features",
                "Encryption Bypass",
                "Denial-of-Service Attack"
            ]
        },
        "url": "URL#915441",
        "sema_paperId": "cda4a7687abc7e3b64cab3aac1dbe1c384243521"
    },
    {
        "@score": "1",
        "@id": "915442",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "353/0762",
                        "text": "Andrew Searles"
                    },
                    {
                        "@pid": "205/8037",
                        "text": "Yoshimichi Nakatsuka"
                    },
                    {
                        "@pid": "205/2579",
                        "text": "Ercan Ozturk"
                    },
                    {
                        "@pid": "30/9784",
                        "text": "Andrew Paverd"
                    },
                    {
                        "@pid": "08/1183",
                        "text": "Gene Tsudik"
                    },
                    {
                        "@pid": "239/2658",
                        "text": "Ai Enkoji"
                    }
                ]
            },
            "title": "An Empirical Study &amp; Evaluation of Modern CAPTCHAs.",
            "venue": "USENIX Security Symposium",
            "pages": "3081-3097",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SearlesNOPTE23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/searles",
            "url": "https://dblp.org/rec/conf/uss/SearlesNOPTE23",
            "abstract": "For nearly two decades, CAPTCHAS have been widely used as a means of protection against bots. Throughout the years, as their use grew, techniques to defeat or bypass CAPTCHAS have continued to improve. Meanwhile, CAPTCHAS have also evolved in terms of sophistication and diversity, becoming increasingly difficult to solve for both bots (machines) and humans. Given this long-standing and still-ongoing arms race, it is critical to investigate how long it takes legitimate users to solve modern CAPTCHAS, and how they are perceived by those users. In this work, we explore CAPTCHAS in the wild by evaluating users' solving performance and perceptions of unmodified currently-deployed CAPTCHAS. We obtain this data through manual inspection of popular websites and user studies in which 1,400 participants collectively solved 14,000 CAPTCHAS. Results show significant differences between the most popular types of CAPTCHAS: surprisingly, solving time and user perception are not always correlated. We performed a comparative study to investigate the effect of experimental context \u2013 specifically the difference between solving CAPTCHAS directly versus solving them as part of a more natural task, such as account creation. Whilst there were several potential confounding factors, our results show that experimental context could have an impact on this task, and must be taken into account in future CAPTCHA studies. Finally, we investigate CAPTCHA-induced user task abandonment by analyzing participants who start and do not complete the task.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-searles.pdf",
            "keywords": [
                "CAPTCHA Evaluation",
                "User Experience",
                "Solving Performance",
                "Task Abandonment",
                "Experimental Context"
            ]
        },
        "url": "URL#915442"
    },
    {
        "@score": "1",
        "@id": "915443",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "265/6251",
                        "text": "Lukas Seidel"
                    },
                    {
                        "@pid": "161/0742",
                        "text": "Dominik Christian Maier"
                    },
                    {
                        "@pid": "185/2352",
                        "text": "Marius Muench"
                    }
                ]
            },
            "title": "Forming Faster Firmware Fuzzers.",
            "venue": "USENIX Security Symposium",
            "pages": "2903-2920",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SeidelMM23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/seidel",
            "url": "https://dblp.org/rec/conf/uss/SeidelMM23",
            "abstract": "A recent trend for assessing the security of an embedded system\u2019s firmware is rehosting , the art of running the firmware in a virtualized environment, rather than on the original hardware platform. One significant use case for firmware rehosting is fuzzing to dynamically uncover security vulnerabilities. However, state-of-the-art implementations suffer from high emulator-induced overhead, leading to less-than-optimal execution speeds. Instead of emulation, we propose near-native rehosting: running embedded firmware as a Linux userspace process on a high-performance system that shares the instruction set family with the targeted device. We implement this approach with S AFIRE F UZZ , a throughput-optimized rehost-ing and fuzzing framework for ARM Cortex-M firmware. S AFIRE F UZZ takes monolithic binary-only firmware images and uses high-level emulation (HLE) and dynamic binary rewriting to run them on far more powerful hardware with low overhead. By replicating experiments of HALucinator, the state-of-the-art HLE-based rehosting system for binary firmware, we show that S AFIRE F UZZ can provide a 690x throughput increase on average during 24-hour fuzzing cam-paigns while covering up to 30% more basic blocks.",
            "keywords": [
                "Firmware Rehosting",
                "Fuzzing Framework",
                "Embedded Systems",
                "High-Level Emulation",
                "Dynamic Binary Rewriting"
            ]
        },
        "url": "URL#915443",
        "sema_paperId": "0c1a5c6515f294465d6d5d932cfbc92c4e86ad9c"
    },
    {
        "@score": "1",
        "@id": "915444",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "343/5480",
                        "text": "HyungBin Seo"
                    },
                    {
                        "@pid": "36/6231-1",
                        "text": "MyungKeun Yoon 0001"
                    }
                ]
            },
            "title": "Generative Intrusion Detection and Prevention on Data Stream.",
            "venue": "USENIX Security Symposium",
            "pages": "4319-4335",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SeoY23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/seo",
            "url": "https://dblp.org/rec/conf/uss/SeoY23",
            "abstract": "Data arrive in a stream, for example, network packets, emails, or malicious \ufb01les, and ideally they should be investigated for cybersecurity. The current best practice would be to check if each data includes any suspicious signatures, or simply strings, which were obtained a priori by elaborate manual analysis in previous cyberattack cases. Unfortunately, unknown attacks, called zero-day attacks, cannot be timely detected in this way because no signature is available yet. To tackle this problem, recent studies have presented high-speed methods that can extract frequent substrings from the data stream and use them as attack signatures because the frequently-occurred signatures are often related with attacks; unfortunately, more benign signatures are extracted than malicious ones, especially when there is no attack in most of the time. This causes both a tremendous number of false-positives and extra human interventions to remove benign signatures. In this paper, we design a new streaming algorithm that can \ufb01rst identify a frequent group of signatures appearing together at the same time from data streams. Using this frequent signature-group instead of frequently-occurred individual signatures, the new scheme achieves a high detection accuracy by mitigating the false-positive problem with only a small \ufb01xed amount of memory and a constant number of hash operations, which has not been achieved by any previous work. This improvement comes from a new method for summarizing similar data with a \ufb01xed amount of memory, called a minHashed virtual vector , which allows us to automatically identify a frequent group of signatures with each data read only once. We perform exhaustive experiments on different private and open datasets, to verify both the practical effectiveness and the experimental reproducibility of the new scheme.",
            "keywords": [
                "Generative Intrusion Detection",
                "Data Stream Analysis",
                "Signature Grouping",
                "Zero-Day Attacks",
                "False Positive Mitigation"
            ]
        },
        "url": "URL#915444",
        "sema_paperId": "54106bbe29f48cf0cdc1d1ae0b17a4da9fde03d0"
    },
    {
        "@score": "1",
        "@id": "915445",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "295/0479",
                        "text": "Khaled Serag"
                    },
                    {
                        "@pid": "43/1791",
                        "text": "Rohit Bhatia"
                    },
                    {
                        "@pid": "353/7593",
                        "text": "Akram Faqih"
                    },
                    {
                        "@pid": "202/6743",
                        "text": "Muslum Ozgur Ozmen"
                    },
                    {
                        "@pid": "41/9886",
                        "text": "Vireshwar Kumar"
                    },
                    {
                        "@pid": "143/2298",
                        "text": "Z. Berkay Celik"
                    },
                    {
                        "@pid": "59/5539",
                        "text": "Dongyan Xu"
                    }
                ]
            },
            "title": "ZBCAN: A Zero-Byte CAN Defense System.",
            "venue": "USENIX Security Symposium",
            "pages": "6893-6910",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SeragBFOKCX23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/serag",
            "url": "https://dblp.org/rec/conf/uss/SeragBFOKCX23",
            "abstract": "Controller Area Network (CAN) is a widely used network protocol. In addition to being the main communication medium for vehicles, it is also used in factories, medical equipment, elevators, and avionics. Unfortunately, CAN was designed without any security features. Consequently, it has come under scrutiny by the research community, showing its security weakness. Recent works have shown that a single compromised ECU on a CAN bus can launch a multitude of attacks ranging from message injection, to bus \ufb02ooding, to attacks exploiting CAN\u2019s error handling mechanism. Although several works have attempted to secure CAN, we argue that none of their approaches could be widely adopted for reasons inherent in their design. In this work, we introduce Z B CAN, a defense system that uses zero bytes of the CAN frame to secure against the most common CAN attacks, including message injection, impersonation, \ufb02ooding, and error handling, without using encryption or MACs, while taking into consideration performance metrics such as delay, busload, and data-rate.",
            "keywords": [
                "Controller Area Network (CAN)",
                "Automotive Security",
                "Message Injection",
                "Impersonation Attacks",
                "Error Handling Mechanism"
            ]
        },
        "url": "URL#915445",
        "sema_paperId": "ceaa8360c51dd0421c94a67e850f38e0a48a053c"
    },
    {
        "@score": "1",
        "@id": "915446",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "217/9308",
                        "text": "Shawn Shan"
                    },
                    {
                        "@pid": "205/3170",
                        "text": "Jenna Cryan"
                    },
                    {
                        "@pid": "259/1518",
                        "text": "Emily Wenger"
                    },
                    {
                        "@pid": "43/4261",
                        "text": "Haitao Zheng 0001"
                    },
                    {
                        "@pid": "167/2260",
                        "text": "Rana Hanocka"
                    },
                    {
                        "@pid": "z/BenYZhao",
                        "text": "Ben Y. Zhao"
                    }
                ]
            },
            "title": "Glaze: Protecting Artists from Style Mimicry by Text-to-Image Models.",
            "venue": "USENIX Security Symposium",
            "pages": "2187-2204",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ShanCW0HZ23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/shan",
            "url": "https://dblp.org/rec/conf/uss/ShanCW0HZ23",
            "abstract": "Recent text-to-image diffusion models such as MidJourney and Stable Diffusion threaten to displace many in the professional artist community. In particular, models can learn to mimic the artistic style of specific artists after\"fine-tuning\"on samples of their art. In this paper, we describe the design, implementation and evaluation of Glaze, a tool that enables artists to apply\"style cloaks\"to their art before sharing online. These cloaks apply barely perceptible perturbations to images, and when used as training data, mislead generative models that try to mimic a specific artist. In coordination with the professional artist community, we deploy user studies to more than 1000 artists, assessing their views of AI art, as well as the efficacy of our tool, its usability and tolerability of perturbations, and robustness across different scenarios and against adaptive countermeasures. Both surveyed artists and empirical CLIP-based scores show that even at low perturbation levels (p=0.05), Glaze is highly successful at disrupting mimicry under normal conditions (>92%) and against adaptive countermeasures (>85%).",
            "keywords": [
                "Text-to-Image Models",
                "Artistic Style Protection",
                "Style Mimicry",
                "Generative Art",
                "Style Cloaks"
            ]
        },
        "url": "URL#915446",
        "sema_paperId": "897c0aedead3105b7b6cd1afbb6aeb4f62a06e11"
    },
    {
        "@score": "1",
        "@id": "915448",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "221/3567",
                        "text": "Tanusree Sharma"
                    },
                    {
                        "@pid": "357/1506",
                        "text": "Kyrie Zhixuan Zhou"
                    },
                    {
                        "@pid": "39/1855-1",
                        "text": "Andrew Miller 0001"
                    },
                    {
                        "@pid": "w/YangWang5",
                        "text": "Yang Wang 0005"
                    }
                ]
            },
            "title": "A Mixed-Methods Study of Security Practices of Smart Contract Developers.",
            "venue": "USENIX Security Symposium",
            "pages": "2545-2562",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SharmaZ0023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/sharma",
            "url": "https://dblp.org/rec/conf/uss/SharmaZ0023",
            "abstract": "Smart contracts are self-executing programs that run on blockchains (e.g., Ethereum). While security is a key concern for smart contracts, it is unclear how smart contract developers approach security. To help \ufb01ll this research gap, we conducted a mixed-methods study of smart contract developers including interviews and a code review task with 29 developers and an online survey with 171 valid respondents. Our \ufb01ndings show various smart contract security perceptions and practices, including the usage of different tools and resources. Overall, the majority of our participants did not consider security as a priority in their smart contract development. In addition, the security vulnerability identi\ufb01cation rates in our code review tasks were alarmingly low (often lower than 50%) across different vulnerabilities and regardless of our participants\u2019 years of experience in smart contract development. We discuss how future education and tools could better support developers in ensuring smart contract security.",
            "keywords": [
                "Smart Contract Development",
                "Blockchain Security",
                "Security Practices",
                "Vulnerability Identification",
                "Developer Education"
            ]
        },
        "url": "URL#915448",
        "sema_paperId": "4102ddcb076074ed92711f16ff62802a77717838"
    },
    {
        "@score": "1",
        "@id": "915449",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "292/4657",
                        "text": "Mikhail Shcherbakov"
                    },
                    {
                        "@pid": "25/7796",
                        "text": "Musard Balliu"
                    },
                    {
                        "@pid": "179/8624",
                        "text": "Cristian-Alexandru Staicu"
                    }
                ]
            },
            "title": "Silent Spring: Prototype Pollution Leads to Remote Code Execution in Node.js.",
            "venue": "USENIX Security Symposium",
            "pages": "5521-5538",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ShcherbakovBS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/shcherbakov",
            "url": "https://dblp.org/rec/conf/uss/ShcherbakovBS23",
            "abstract": "Prototype pollution is a dangerous vulnerability affecting prototype-based languages like JavaScript and the Node.js platform. It refers to the ability of an attacker to inject properties into an object's root prototype at runtime and subsequently trigger the execution of legitimate code gadgets that access these properties on the object's prototype, leading to attacks such as Denial of Service (DoS), privilege escalation, and Remote Code Execution (RCE). While there is anecdotal evidence that prototype pollution leads to RCE, current research does not tackle the challenge of gadget detection, thus only showing feasibility of DoS attacks, mainly against Node.js libraries. In this paper, we set out to study the problem in a holistic way, from the detection of prototype pollution to detection of gadgets, with the ambitious goal of finding end-to-end exploits beyond DoS, in full-fledged Node.js applications. We build the first multi-staged framework that uses multi-label static taint analysis to identify prototype pollution in Node.js libraries and applications, as well as a hybrid approach to detect universal gadgets, notably, by analyzing the Node.js source code. We implement our framework on top of GitHub's static analysis framework CodeQL to find 11 universal gadgets in core Node.js APIs, leading to code execution. Furthermore, we use our methodology in a study of 15 popular Node.js applications to identify prototype pollutions and gadgets. We manually exploit eight RCE vulnerabilities in three high-profile applications such as NPM CLI, Parse Server, and Rocket.Chat. Our results provide alarming evidence that prototype pollution in combination with powerful universal gadgets lead to RCE in Node.js.",
            "keywords": [
                "Prototype Pollution",
                "Remote Code Execution",
                "Node.js Vulnerabilities",
                "Gadget Detection",
                "Static Taint Analysis"
            ]
        },
        "url": "URL#915449",
        "sema_paperId": "5e16b3067ce3237f7efd2ba81710d405aebdbf57"
    },
    {
        "@score": "1",
        "@id": "915450",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "195/5821",
                        "text": "Ryan Sheatsley"
                    },
                    {
                        "@pid": "293/7182",
                        "text": "Blaine Hoak"
                    },
                    {
                        "@pid": "227/2618",
                        "text": "Eric Pauley"
                    },
                    {
                        "@pid": "m/PatrickDrewMcDaniel",
                        "text": "Patrick D. McDaniel"
                    }
                ]
            },
            "title": "The Space of Adversarial Strategies.",
            "venue": "USENIX Security Symposium",
            "pages": "3745-3761",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SheatsleyHPM23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/sheatsley",
            "url": "https://dblp.org/rec/conf/uss/SheatsleyHPM23",
            "abstract": "Adversarial examples, inputs designed to induce worst-case behavior in machine learning models, have been extensively studied over the past decade. Yet, our understanding of this phenomenon stems from a rather fragmented pool of knowledge; at present, there are a handful of attacks, each with disparate assumptions in threat models and incomparable definitions of optimality. In this paper, we propose a systematic approach to characterize worst-case (i.e., optimal) adversaries. We first introduce an extensible decomposition of attacks in adversarial machine learning by atomizing attack components into surfaces and travelers. With our decomposition, we enumerate over components to create 576 attacks (568 of which were previously unexplored). Next, we propose the Pareto Ensemble Attack (PEA): a theoretical attack that upper-bounds attack performance. With our new attacks, we measure performance relative to the PEA on: both robust and non-robust models, seven datasets, and three extended \u2113p-based threat models incorporating compute costs, formalizing the Space of Adversarial Strategies. From our evaluation we find that attack performance to be highly contextual: the domain, model robustness, and threat model can have a profound influence on attack efficacy. Our investigation suggests that future studies measuring the security of machine learning should: (1) be contextualized to the domain & threat models, and (2) go beyond the handful of known attacks used today.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-sheatsley.pdf",
            "keywords": [
                "Adversarial Machine Learning",
                "Adversarial Examples",
                "Attack Strategies",
                "Pareto Ensemble Attack",
                "Threat Models"
            ]
        },
        "url": "URL#915450"
    },
    {
        "@score": "1",
        "@id": "915451",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "282/6569",
                        "text": "Ilia Shevrin"
                    },
                    {
                        "@pid": "12/5365",
                        "text": "Oded Margalit"
                    }
                ]
            },
            "title": "Detecting Multi-Step IAM Attacks in AWS Environments via Model Checking.",
            "venue": "USENIX Security Symposium",
            "pages": "6025-6042",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ShevrinM23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/shevrin",
            "url": "https://dblp.org/rec/conf/uss/ShevrinM23",
            "abstract": "Cloud services enjoy a surging popularity among IT professionals, owing to their rapid provision of virtual infrastructure on demand. Hand-in-hand with the growing usage, there is also a growing concern about potential security vulnerabilities arising from miscon\ufb01gurations, exposing resources or allowing malicious actors to escalate privileges. Model checking is a known method for verifying that a \ufb01nite-state Boolean model of a system satis\ufb01es certain properties, where the model and the properties are described in formal logic. In case it doesn\u2019t, a \ufb01nite trace leading to a violating state can be generated. In this paper, we present an approach to construct a \ufb01nite-state Boolean model from the Identity and Access Management (IAM) component of Amazon Web Services (AWS), and a property from an attack target, e.g., read a classi\ufb01ed S3 bucket object. We run a model checker that detects whether some initial setup allows an attacker to escalate privileges and reach the target in one or more steps by applying IAM manipulating actions. We show that our approach can discover existing miscon\ufb01gurations in real AWS environments, and that it can detect multi-step attacks in setups containing tens of AWS accounts with hundreds of resources in under a minute.",
            "keywords": [
                "Cloud Security",
                "IAM Attacks",
                "Model Checking",
                "Privilege Escalation",
                "AWS Misconfigurations"
            ]
        },
        "url": "URL#915451",
        "sema_paperId": "7f56888e7f5667e6c0a0c47c034931da2f362935"
    },
    {
        "@score": "1",
        "@id": "915452",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "03/1086",
                        "text": "Min Shi"
                    },
                    {
                        "@pid": "27/4364-3",
                        "text": "Jing Chen 0003"
                    },
                    {
                        "@pid": "59/1028-8",
                        "text": "Kun He 0008"
                    },
                    {
                        "@pid": "141/4084",
                        "text": "Haoran Zhao"
                    },
                    {
                        "@pid": "48/7487",
                        "text": "Meng Jia"
                    },
                    {
                        "@pid": "37/7220",
                        "text": "Ruiying Du"
                    }
                ]
            },
            "title": "Formal Analysis and Patching of BLE-SC Pairing.",
            "venue": "USENIX Security Symposium",
            "pages": "37-52",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Shi00ZJD23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/shi-min",
            "url": "https://dblp.org/rec/conf/uss/Shi00ZJD23",
            "abstract": "Bluetooth Low Energy (BLE) is the mainstream Bluetooth standard and BLE Secure Connections (BLC-SC) pairing is a protocol that authenticates two Bluetooth devices and derives a shared secret key between them. Although BLE-SC pairing employs well-studied cryptographic primitives to guarantee its security, a recent study revealed a logic \ufb02aw in the protocol. In this paper, we develop the \ufb01rst comprehensive formal model of the BLE-SC pairing protocol. Our model is compliant with the latest Bluetooth speci\ufb01cation version 5.3 and covers all association models in the speci\ufb01cation to discover attacks caused by the interplay between different association models. We also partly loosen the perfect cryptography assumption in traditional symbolic analysis approaches by designing a low-entropy key oracle to detect attacks caused by the poorly derived keys. Our analysis con\ufb01rms two existing attacks and discloses a new attack. We propose a countermeasure to \ufb01x the \ufb02aws found in the BLE-SC pairing protocol and discuss the backward compatibility. Moreover, we extend our model to verify the countermeasure, and the results demonstrate its effectiveness in our extended model.",
            "keywords": [
                "Bluetooth Low Energy",
                "Secure Connections",
                "Formal Analysis",
                "Key Derivation Attacks",
                "Countermeasure Development"
            ]
        },
        "url": "URL#915452",
        "sema_paperId": "58a5ebd3983a9883d01528970d0d564b028a528a"
    },
    {
        "@score": "1",
        "@id": "915453",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "203/6784",
                        "text": "Ji Shi"
                    },
                    {
                        "@pid": "119/3119",
                        "text": "Zhun Wang"
                    },
                    {
                        "@pid": "305/3607",
                        "text": "Zhiyao Feng"
                    },
                    {
                        "@pid": "08/1085",
                        "text": "Yang Lan"
                    },
                    {
                        "@pid": "297/2374",
                        "text": "Shisong Qin"
                    },
                    {
                        "@pid": "87/6465",
                        "text": "Wei You"
                    },
                    {
                        "@pid": "10/328",
                        "text": "Wei Zou"
                    },
                    {
                        "@pid": "31/1273",
                        "text": "Mathias Payer"
                    },
                    {
                        "@pid": "94/3019-8",
                        "text": "Chao Zhang 0008"
                    }
                ]
            },
            "title": "AIFORE: Smart Fuzzing Based on Automatic Input Format Reverse Engineering.",
            "venue": "USENIX Security Symposium",
            "pages": "4967-4984",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ShiWFLQYZP023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/shi-ji",
            "url": "https://dblp.org/rec/conf/uss/ShiWFLQYZP023",
            "abstract": "Knowledge of a program\u2019s input format is essential for effective input generation in fuzzing. Automated input format reverse engineering represents an attractive but challenging approach to learning the format. In this paper, we address several challenges of automated input format reverse engineering, and present a smart fuzzing solution AIFORE which makes full use of the reversed format and benefits from it. The structures and semantics of input fields are determined by the basic blocks (BBs) that process them rather than the input specification. Therefore, we first utilize byte-level taint analysis to recognize the input bytes processed by each BB, then identify indivisible input fields that are always processed together with a minimum cluster algorithm, and learn their types with a neural network model that characterizes the behavior of BBs. Lastly, we design a new power scheduling algorithm based on the inferred format knowledge to guide smart fuzzing. We implement a prototype of AIFORE and evaluate both the accuracy of format inference and the performance of fuzzing against state-of-the-art (SOTA) format reversing solutions and fuzzers. AIFORE significantly outperforms SOTA baselines on the accuracy of field boundary and type recognition. With AIFORE, we uncovered 20 bugs in 15 programs that were missed by other fuzzers.",
            "keywords": [
                "Input Format Reverse Engineering",
                "Smart Fuzzing",
                "Taint Analysis",
                "Field Boundary Recognition",
                "Bug Discovery"
            ]
        },
        "url": "URL#915453",
        "sema_paperId": "afa3ed39824b55dcdb1e181f43e83a3d33280ac2"
    },
    {
        "@score": "1",
        "@id": "915454",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "145/3943",
                        "text": "Qingkai Shi"
                    },
                    {
                        "@pid": "276/3462",
                        "text": "Xiangzhe Xu"
                    },
                    {
                        "@pid": "95/3760-1",
                        "text": "Xiangyu Zhang 0001"
                    }
                ]
            },
            "title": "Extracting Protocol Format as State Machine via Controlled Static Loop Analysis.",
            "venue": "USENIX Security Symposium",
            "pages": "7019-7036",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ShiX023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/shi-qingkai",
            "url": "https://dblp.org/rec/conf/uss/ShiX023",
            "abstract": "Reverse engineering of protocol message formats is critical for many security applications. Mainstream techniques use dynamic analysis and inherit its low-coverage problem -- the inferred message formats only reflect the features of their inputs. To achieve high coverage, we choose to use static analysis to infer message formats from the implementation of protocol parsers. In this work, we focus on a class of extremely challenging protocols whose formats are described via constraint-enhanced regular expressions and parsed using finite-state machines. Such state machines are often implemented as complicated parsing loops, which are inherently difficult to analyze via conventional static analysis. Our new technique extracts a state machine by regarding each loop iteration as a state and the dependency between loop iterations as state transitions. To achieve high, i.e., path-sensitive, precision but avoid path explosion, the analysis is controlled to merge as many paths as possible based on carefully-designed rules. The evaluation results show that we can infer a state machine and, thus, the message formats, in five minutes with over 90% precision and recall, far better than state of the art. We also applied the state machines to enhance protocol fuzzers, which are improved by 20% to 230% in terms of coverage and detect ten more zero-days compared to baselines.",
            "keywords": [
                "Protocol Reverse Engineering",
                "Static Analysis",
                "Finite-State Machines",
                "Message Format Inference",
                "Controlled Static Loop Analysis"
            ]
        },
        "url": "URL#915454",
        "sema_paperId": "0aa60dcc3fa33253d5087bc3e52704c74041a748"
    },
    {
        "@score": "1",
        "@id": "915455",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "346/7905",
                        "text": "Jiwoo Shin"
                    },
                    {
                        "@pid": "315/7789",
                        "text": "Hyunghoon Kim"
                    },
                    {
                        "@pid": "118/2458-3",
                        "text": "Seyoung Lee 0003"
                    },
                    {
                        "@pid": "09/6032",
                        "text": "Wonsuk Choi"
                    },
                    {
                        "@pid": "l/DongHoonLee",
                        "text": "Dong Hoon Lee 0001"
                    },
                    {
                        "@pid": "147/6656",
                        "text": "Hyo Jin Jo"
                    }
                ]
            },
            "title": "RIDAS: Real-time identification of attack sources on controller area networks.",
            "venue": "USENIX Security Symposium",
            "pages": "6911-6928",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ShinK0C0J23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/shin",
            "url": "https://dblp.org/rec/conf/uss/ShinK0C0J23",
            "abstract": "Researchers have responded to various cyber attacks on controller area network (CAN) by studying technologies for identifying the source of an attack. However, existing attack source identification technologies have shown significantly lower accuracy depending on changes in the vehicle environment (temperature, humidity, battery level, etc.), or have proven to be circumvented by identification-aware attackers, or do not provide real-time identification. A real-time attack node identification technology that cannot be bypassed by an attacker while not being affected by changes in the vehicle environment is essential for cyber attack response technologies such as node isolation, security patch, digital forensics, etc. To meet this need, we propose a novel real-time attack node identification method, called RIDAS, which can identify the attack source by using the error handling rule of CAN. RIDAS injects bit errors into the abnormal messages that have been detected by an existing intrusion detection system (IDS). The source that sent the abnormal message become the error passive state defined in CAN in which it cannot send consecutive messages. RIDAS then sequentially inspects all electronic control units (ECU) and identifies the node in the error passive state by checking the priority reduction phenomenon that occurs in that state. Moreover, RIDAS address two challenging issues, identification robustness and identification errors . Our experimental results, conducted on both a CAN bus prototype and one real vehicle, have demonstrated that RIDAS can accurately identify an attack source while remaining unaffected by changes in the vehicle\u2019s environment. Additionally, RIDAS is able to deal with RIDAS-aware attackers.",
            "keywords": [
                "Controller Area Network",
                "Real-time Identification",
                "Cyber Attack Source",
                "Error Handling",
                "Intrusion Detection"
            ]
        },
        "url": "URL#915455",
        "sema_paperId": "c446d1e57b7390ace7d307f30e75a9e81c884791"
    },
    {
        "@score": "1",
        "@id": "915456",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "294/0110",
                        "text": "Wai Man Si"
                    },
                    {
                        "@pid": "b/MichaelBackes1",
                        "text": "Michael Backes 0001"
                    },
                    {
                        "@pid": "06/6785-16",
                        "text": "Yang Zhang 0016"
                    },
                    {
                        "@pid": "41/506-1",
                        "text": "Ahmed Salem 0001"
                    }
                ]
            },
            "title": "Two-in-One: A Model Hijacking Attack Against Text Generation Models.",
            "venue": "USENIX Security Symposium",
            "pages": "2223-2240",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Si00023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/si",
            "url": "https://dblp.org/rec/conf/uss/Si00023",
            "abstract": "Machine learning has progressed significantly in various applications ranging from face recognition to text generation. However, its success has been accompanied by different attacks. Recently a new attack has been proposed which raises both accountability and parasitic computing risks, namely the model hijacking attack. Nevertheless, this attack has only focused on image classification tasks. In this work, we broaden the scope of this attack to include text generation and classification models, hence showing its broader applicability. More concretely, we propose a new model hijacking attack, Ditto, that can hijack different text classification tasks into multiple generation ones, e.g., language translation, text summarization, and language modeling. We use a range of text benchmark datasets such as SST-2, TweetEval, AGnews, QNLI, and IMDB to evaluate the performance of our attacks. Our results show that by using Ditto, an adversary can successfully hijack text generation models without jeopardizing their utility.",
            "keywords": [
                "Model Hijacking Attack",
                "Text Generation",
                "Text Classification",
                "Adversarial Attacks",
                "Ditto"
            ]
        },
        "url": "URL#915456",
        "sema_paperId": "5f63af3491caa8687ffaf5d3b11a078125be703b"
    },
    {
        "@score": "1",
        "@id": "915457",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "252/4834",
                        "text": "Carter Slocum"
                    },
                    {
                        "@pid": "186/7504",
                        "text": "Yicheng Zhang"
                    },
                    {
                        "@pid": "86/2654",
                        "text": "Nael B. Abu-Ghazaleh"
                    },
                    {
                        "@pid": "35/9005",
                        "text": "Jiasi Chen"
                    }
                ]
            },
            "title": "Going through the motions: AR/VR keylogging from user head motions.",
            "venue": "USENIX Security Symposium",
            "pages": "159-174",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SlocumZAC23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/slocum",
            "url": "https://dblp.org/rec/conf/uss/SlocumZAC23",
            "abstract": "Augmented Reality/Virtual Reality (AR/VR) are the next step in the evolution of ubiquitous computing after personal computers to mobile devices. Applications of AR/VR continue to grow, including education and virtual workspaces, increasing opportunities for users to enter private text, such as passwords or sensitive corporate information. In this work, we show that there is a serious security risk of typed text in the foreground being inferred by a background application, without requiring any special permissions. The key insight is that a user\u2019s head moves in subtle ways as she types on a virtual keyboard, and these motion signals are sufficient for inferring the text that a user types. We develop a system, TyPose , that extracts these signals and automatically infers words or characters that a victim is typing. Once the sensor signals are collected, TyPose uses machine learning to segment the motion signals in time to determine word/character boundaries, and also perform inference on the words/characters themselves. Our experimental evaluation on commercial AR/VR headsets demonstrate the feasibility of this attack, both in situations where multiple users\u2019 data is used for training (82% top-5 word classification accuracy) or when the attack is personalized to a particular victim (92% top-5 word classification accuracy). We also show that first-line defenses of reducing the sampling rate or precision of head tracking data are ineffective, suggesting that more sophisticated mitigations are needed.",
            "keywords": [
                "Augmented Reality",
                "Virtual Reality",
                "Keylogging",
                "User Head Motions",
                "TyPose"
            ]
        },
        "url": "URL#915457",
        "sema_paperId": "69e636bf58a6fa108b9aeaaf9eb9271d30b620bd"
    },
    {
        "@score": "1",
        "@id": "915458",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "44/2147",
                        "text": "Garrett Smith"
                    },
                    {
                        "@pid": "225/4590",
                        "text": "Tarun Kumar Yadav"
                    },
                    {
                        "@pid": "248/1615",
                        "text": "Jonathan Dutson"
                    },
                    {
                        "@pid": "124/2527",
                        "text": "Scott Ruoti"
                    },
                    {
                        "@pid": "s/KentESeamons",
                        "text": "Kent E. Seamons"
                    }
                ]
            },
            "title": "&quot;If I could do this, I feel anyone could: &quot; The Design and Evaluation of a Secondary Authentication Factor Manager.",
            "venue": "USENIX Security Symposium",
            "pages": "499-515",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SmithYDRS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/smith",
            "url": "https://dblp.org/rec/conf/uss/SmithYDRS23",
            "abstract": "Two-factor authentication (2FA) defends against account compromise by protecting an account with both a password\u2014the primary authentication factor\u2014and a device or resource that is hard to steal\u2014the secondary authentication factor (SAF). However, prior research shows that users need help registering their SAFs with websites and successfully enabling 2FA. To address these issues, we propose the concept of a SAF manager that helps users manage SAFs through their entire life cycle: setup, authentication, removal, replacement, and auditing. We design and implement two proof-of-concept prototypes. In a between-subjects user study (N=60), we demonstrate that our design improves users\u2019 ability to correctly and quickly setup and remove a SAF on their accounts. Qualitative results show that users responded very positively to the SAF manager and were enthusiastic about its ability to help them rapidly replace a SAF. Furthermore, our SAF manager prevented fatal errors that users experienced when not using the manager.",
            "keywords": [
                "Two-Factor Authentication",
                "Secondary Authentication Factor",
                "User Experience",
                "Authentication Management",
                "SAF Manager"
            ]
        },
        "url": "URL#915458",
        "sema_paperId": "f6fb24123e5fa7a41e0d383d09618eb58e3d561d"
    },
    {
        "@score": "1",
        "@id": "915459",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "139/5540",
                        "text": "Peter Snyder"
                    },
                    {
                        "@pid": "270/2346",
                        "text": "Soroush Karami"
                    },
                    {
                        "@pid": "297/9352",
                        "text": "Arthur Edelstein"
                    },
                    {
                        "@pid": "46/2924",
                        "text": "Benjamin Livshits"
                    },
                    {
                        "@pid": "33/5454",
                        "text": "Hamed Haddadi"
                    }
                ]
            },
            "title": "Pool-Party: Exploiting Browser Resource Pools for Web Tracking.",
            "venue": "USENIX Security Symposium",
            "pages": "7091-7105",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SnyderKELH23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/snyder",
            "url": "https://dblp.org/rec/conf/uss/SnyderKELH23",
            "abstract": "We identify class of covert channels in browsers that are not mitigated by current defenses, which we call\"pool-party\"attacks. Pool-party attacks allow sites to create covert channels by manipulating limited-but-unpartitioned resource pools. These class of attacks have been known, but in this work we show that they are both more prevalent, more practical for exploitation, and allow exploitation in more ways, than previously identified. These covert channels have sufficient bandwidth to pass cookies and identifiers across site boundaries under practical and real-world conditions. We identify pool-party attacks in all popular browsers, and show they are practical cross-site tracking techniques (i.e., attacks take 0.6s in Chrome and Edge, and 7s in Firefox and Tor Browser). In this paper we make the following contributions: first, we describe pool-party covert channel attacks that exploit limits in application-layer resource pools in browsers. Second, we demonstrate that pool-party attacks are practical, and can be used to track users in all popular browsers; we also share open source implementations of the attack and evaluate them through a representative web crawl. Third, we show that in Gecko based-browsers (including the Tor Browser) pool-party attacks can also be used for cross-profile tracking (e.g., linking user behavior across normal and private browsing sessions). Finally, we discuss possible mitigation strategies and defenses",
            "keywords": [
                "Web Tracking",
                "Covert Channels",
                "Pool-Party Attacks",
                "Cross-Site Tracking",
                "Resource Pool Exploitation"
            ]
        },
        "url": "URL#915459",
        "sema_paperId": "d9fd1b1a3220f15784d09d30066f5d62f7219421"
    },
    {
        "@score": "1",
        "@id": "915460",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "229/2470",
                        "text": "Nissy Sombatruang"
                    },
                    {
                        "@pid": "146/6116",
                        "text": "Tristan Caulfield"
                    },
                    {
                        "@pid": "183/8093",
                        "text": "Ingolf Becker"
                    },
                    {
                        "@pid": "97/3642",
                        "text": "Akira Fujita"
                    },
                    {
                        "@pid": "119/1132",
                        "text": "Takahiro Kasama"
                    },
                    {
                        "@pid": "97/3551",
                        "text": "Koji Nakao"
                    },
                    {
                        "@pid": "62/5563",
                        "text": "Daisuke Inoue"
                    }
                ]
            },
            "title": "Internet Service Providers&apos; and Individuals&apos; Attitudes, Barriers, and Incentives to Secure IoT.",
            "venue": "USENIX Security Symposium",
            "pages": "1541-1558",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SombatruangCBFK23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/sombatruang",
            "url": "https://dblp.org/rec/conf/uss/SombatruangCBFK23",
            "abstract": "Internet Service Providers (ISPs) and individual users of Internet of Things (IoT) play a vital role in securing IoT. However, encouraging them to do so is hard. Our study investigates ISPs' and individuals' attitudes towards the security of IoT, the obstacles they face, and their incentives to keep IoT secure, drawing evidence from Japan.\nDue to the complex interactions of the stakeholders, we follow an iterative methodology where we present issues and potential solutions to our stakeholders in turn.  For ISPs, we survey 27 ISPs in Japan, followed by a workshop with representatives from government and 5 ISPs. Based on the findings from this, we conduct semi-structured interviews with 20 participants followed by a more quantitative survey with 328 participants. We review these results in a second workshop with representatives from government and 7 ISPs. The appreciation of challenges by each party has lead to findings that are supported by all stakeholders. Securing IoT devices is neither users' nor ISPs' priority. Individuals are keen on more interventions both from the government as part of regulation and from ISPs in terms of filtering malicious traffic. Participants are willing to pay for enhanced monitoring and filtering. While ISPs do want to help users, there appears to be a lack of effective technology to aid them. ISPs would like to see more public recognition for their efforts, but internally they struggle with executive buy-in and effective means to communicate with their customers. The majority of barriers and incentives are external to ISPs and individuals, demonstrating the complexity of keeping IoT secure and emphasizing the need for relevant stakeholders in the IoT ecosystem to work in tandem.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-sombatruang.pdf",
            "keywords": [
                "Internet of Things (IoT)",
                "Internet Service Providers (ISPs)",
                "User Attitudes",
                "Security Barriers",
                "Incentives for IoT Security"
            ]
        },
        "url": "URL#915460"
    },
    {
        "@score": "1",
        "@id": "915461",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "329/6551",
                        "text": "Ruoyu Song"
                    },
                    {
                        "@pid": "202/6743",
                        "text": "Muslum Ozgur Ozmen"
                    },
                    {
                        "@pid": "155/0040",
                        "text": "Hyungsub Kim"
                    },
                    {
                        "@pid": "332/2911",
                        "text": "Raymond Muller"
                    },
                    {
                        "@pid": "143/2298",
                        "text": "Z. Berkay Celik"
                    },
                    {
                        "@pid": "99/3883",
                        "text": "Antonio Bianchi"
                    }
                ]
            },
            "title": "Discovering Adversarial Driving Maneuvers against Autonomous Vehicles.",
            "venue": "USENIX Security Symposium",
            "pages": "2957-2974",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SongOKMCB23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/song",
            "url": "https://dblp.org/rec/conf/uss/SongOKMCB23",
            "abstract": "Over 33% of vehicles sold in 2021 had integrated autonomous driving (AD) systems. While many adversarial machine learning attacks have been studied against these systems, they all require an adversary to perform specific (and often unrealistic) actions, such as carefully modifying traffic signs or projecting malicious images, which may arouse suspicion if discovered. In this paper, we present Acero, a robustness-guided framework to discover adversarial maneuver attacks against autonomous vehicles (AVs). These maneuvers look innocent to the outside observer but force the victim vehicle to violate safety rules for AVs, causing physical consequences, e.g., crashing with pedestrians and other vehicles. To optimally find adversarial driving maneuvers, we formalize seven safety requirements for AD systems and use this formalization to guide our search. We also formalize seven physical constraints that ensure the adversary does not place themselves in danger or violate traffic laws while conducting the attack. Acero then leverages trajectory-similarity metrics to cluster successful attacks into unique groups, enabling AD developers to analyze the root cause of attacks and mitigate them. We evaluated Acero on two open-source AD software, openpilot and Autoware, running on the CARLA simulator. Acero discovered 219 attacks against openpilot and 122 attacks against Autoware. 73.3% of these attacks cause the victim to collide with a third-party vehicle, pedestrian, or static object.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-song.pdf",
            "keywords": [
                "Adversarial Driving Maneuvers",
                "Autonomous Vehicles",
                "Safety Violations",
                "Robustness-guided Framework",
                "Traffic Law Compliance"
            ]
        },
        "url": "URL#915461",
        "sema_paperId": "1815e954e9e11ebd08669b10a7154f07e8e21706"
    },
    {
        "@score": "1",
        "@id": "915462",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "117/7980",
                        "text": "Marco Squarcina"
                    },
                    {
                        "@pid": "69/3516",
                        "text": "Pedro Ad\u00e3o"
                    },
                    {
                        "@pid": "213/8814",
                        "text": "Lorenzo Veronese"
                    },
                    {
                        "@pid": "25/3571",
                        "text": "Matteo Maffei"
                    }
                ]
            },
            "title": "Cookie Crumbles: Breaking and Fixing Web Session Integrity.",
            "venue": "USENIX Security Symposium",
            "pages": "5539-5556",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SquarcinaAVM23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/squarcina",
            "url": "https://dblp.org/rec/conf/uss/SquarcinaAVM23",
            "abstract": "This artifact is provided to support the evaluation of all the re-sults presented in the paper. In particular, (i) the cross-browser testing suite used to validate the results presented in Table 2, (ii) the toolchain developed to automatically test server-side cookie parsers (Section 4.2.2), (iii) the dataset and processing code of our cookie measurement study (Section 4.4), (iv) re-producible proof-of-concept attacks against vulnerable Web frameworks (Section 6), as well as (v) the ProVerif models and scripts (Section 7).",
            "keywords": [
                "Web Session Integrity",
                "Cookie Security",
                "Cross-Browser Testing",
                "Vulnerable Web Frameworks",
                "Proof-of-Concept Attacks"
            ]
        },
        "url": "URL#915462",
        "sema_paperId": "b388cbb43e513844636b8b102248511387b724a8"
    },
    {
        "@score": "1",
        "@id": "915463",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "179/8624",
                        "text": "Cristian-Alexandru Staicu"
                    },
                    {
                        "@pid": "208/7323",
                        "text": "Sazzadur Rahaman"
                    },
                    {
                        "@pid": "150/0067",
                        "text": "\u00c1gnes Kiss"
                    },
                    {
                        "@pid": "b/MichaelBackes1",
                        "text": "Michael Backes 0001"
                    }
                ]
            },
            "title": "Bilingual Problems: Studying the Security Risks Incurred by Native Extensions in Scripting Languages.",
            "venue": "USENIX Security Symposium",
            "pages": "6133-6150",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/StaicuRK023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/staicu",
            "url": "https://dblp.org/rec/conf/uss/StaicuRK023",
            "abstract": "Scripting languages are continuously gaining popularity due to their ease of use and the flourishing software ecosystems that surround them. These languages offer crash and memory safety by design, thus, developers do not need to understand and prevent low-level security issues like the ones plaguing the C code. However, scripting languages often allow native extensions, which are a way for custom C/C++ code to be invoked directly from the high-level language. While this feature promises several benefits such as increased performance or the reuse of legacy code, it can also break the language's guarantees, e.g., crash-safety. In this work, we first provide a comparative analysis of the security risks of native extension APIs in three popular scripting languages. Additionally, we discuss a novel methodology for studying the misuse of the native extension API. We then perform an in-depth study of npm, an ecosystem which is most exposed to threats introduced by native extensions. We show that vulnerabilities in extensions can be exploited in their embedding library by producing reads of uninitialized memory, hard crashes or memory leaks in 33 npm packages, simply by invoking their API with well-crafted inputs. Moreover, we identify six open-source web applications in which such exploits can be deployed remotely by a weak adversary. Finally, we were assigned seven security advisories for the work presented in this paper, most labeled as high severity.",
            "keywords": [
                "Scripting Languages",
                "Native Extensions",
                "Security Risks",
                "Memory Safety",
                "npm Vulnerabilities"
            ]
        },
        "url": "URL#915463",
        "sema_paperId": "681c9dac27366e20aa84fdb4992177dcf2aba9a2"
    },
    {
        "@score": "1",
        "@id": "915464",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "273/4247",
                        "text": "Jonah Stegman"
                    },
                    {
                        "@pid": "330/1956",
                        "text": "Patrick J. Trottier"
                    },
                    {
                        "@pid": "319/2979",
                        "text": "Caroline Hillier"
                    },
                    {
                        "@pid": "83/7562",
                        "text": "Hassan Khan"
                    },
                    {
                        "@pid": "m/MohammadMannan",
                        "text": "Mohammad Mannan"
                    }
                ]
            },
            "title": "&quot;My Privacy for their Security&quot;: Employees&apos; Privacy Perspectives and Expectations when using Enterprise Security Software.",
            "venue": "USENIX Security Symposium",
            "pages": "3583-3600",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/StegmanTHKM23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/stegman",
            "url": "https://dblp.org/rec/conf/uss/StegmanTHKM23",
            "abstract": "Employees are often required to use Enterprise Security Software (\"ESS\") on corporate and personal devices. ESS products collect users' activity data including users' location, applications used, and websites visited - operating from employees' device to the cloud. To the best of our knowledge, the privacy implications of this data collection have yet to be explored. We conduct an online survey (n=258) and a semi-structured interview (n=22) with ESS users to understand their privacy perceptions, the challenges they face when using ESS, and the ways they try to overcome those challenges. We found that while many participants reported receiving no information about what data their ESS collected, those who received some information often underestimated what was collected. Employees reported lack of communication about various data collection aspects including: the entities with access to the data and the scope of the data collected. We use the interviews to uncover several sources of misconceptions among the participants. Our findings show that while employees understand the need for data collection for security, the lack of communication and ambiguous data collection practices result in the erosion of employees' trust on the ESS and employers. We obtain suggestions from participants on how to mitigate these misconceptions and collect feedback on our design mockups of a privacy notice and privacy indicators for ESS. Our work will benefit researchers, employers, and ESS developers to protect users' privacy in the growing ESS market.",
            "keywords": [
                "Enterprise Security Software",
                "Employee Privacy",
                "Data Collection Practices",
                "Trust Erosion",
                "Privacy Communication"
            ]
        },
        "url": "URL#915464",
        "sema_paperId": "0c611a2b618cd8cab0a2e4d03e42d60031a08cbc"
    },
    {
        "@score": "1",
        "@id": "915465",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "325/3688",
                        "text": "Sophie Stephenson"
                    },
                    {
                        "@pid": "272/3319",
                        "text": "Majed Almansoori"
                    },
                    {
                        "@pid": "199/3074",
                        "text": "Pardis Emami Naeini"
                    },
                    {
                        "@pid": "03/9962",
                        "text": "Rahul Chatterjee 0001"
                    }
                ]
            },
            "title": "&quot;It&apos;s the Equivalent of Feeling Like You&apos;re in Jail&quot;: Lessons from Firsthand and Secondhand Accounts of IoT-Enabled Intimate Partner Abuse.",
            "venue": "USENIX Security Symposium",
            "pages": "105-122",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/StephensonAN023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/stephenson-lessons",
            "url": "https://dblp.org/rec/conf/uss/StephensonAN023",
            "abstract": "Victim-survivors of intimate partner violence (IPV) are facing a new technological threat: Abusers are leveraging IoT devices such as smart thermostats, hidden cameras, and GPS trackers to spy on and harass victim-survivors. Though prior work provides a foundation of what IoT devices can be involved in intimate partner violence, we lack a detailed understanding of the factors which contribute to this IoT abuse , the strategies victim-survivors use to mitigate IoT abuse, and the barriers they face along the way. Without this information, it is challenging to design effective solutions to stop IoT abuse. To fill this gap, we interviewed 20 participants with first-hand or secondhand experience with IoT abuse. Our inter-views captured 39 varied instances of IoT abuse, from surveillance with hidden GPS trackers to harassment with smart thermostats and light bulbs. They also surfaced 21 key barriers victim-survivors face while coping with IoT abuse. For instance, victim-survivors struggle to find proof of the IoT abuse they experience, which makes mitigations challenging. Even with proof, victim-survivors face barriers mitigating the abuse; for example, mitigation is all but impossible for victim-survivors living with an abusive partner. Our findings pinpoint several solutions to combat IoT abuse, including increased transparency of IoT devices, updated IoT access control protocols, and raising awareness of IoT abuse.",
            "keywords": [
                "IoT Abuse",
                "Intimate Partner Violence",
                "Surveillance Technology",
                "Victim-Survivor Challenges",
                "Mitigation Strategies"
            ]
        },
        "url": "URL#915465",
        "sema_paperId": "1de77c1b70aa55a8b3e8f040000b8c4f0e30f193"
    },
    {
        "@score": "1",
        "@id": "915466",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "325/3688",
                        "text": "Sophie Stephenson"
                    },
                    {
                        "@pid": "272/3319",
                        "text": "Majed Almansoori"
                    },
                    {
                        "@pid": "199/3074",
                        "text": "Pardis Emami Naeini"
                    },
                    {
                        "@pid": "77/8851",
                        "text": "Danny Yuxing Huang"
                    },
                    {
                        "@pid": "03/9962",
                        "text": "Rahul Chatterjee 0001"
                    }
                ]
            },
            "title": "Abuse Vectors: A Framework for Conceptualizing IoT-Enabled Interpersonal Abuse.",
            "venue": "USENIX Security Symposium",
            "pages": "69-86",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/StephensonANH023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/stephenson-vectors",
            "url": "https://dblp.org/rec/conf/uss/StephensonANH023",
            "abstract": "Tech-enabled interpersonal abuse (IPA) is a pervasive problem. Abusers, often intimate partners, use tools such as spyware to surveil and harass victim-survivors. Unfortunately, anecdotal evidence suggests that smart, Internet-connected devices such as home thermostats, cameras, and Bluetooth item \ufb01nders may similarly be used against victim-survivors of IPA. To tackle abuse involving smart devices, it is vital that we understand the ecosystem of smart devices that enable IPA. Thus, in this work, we conduct a large-scale qualitative analysis of the smart devices used in IPA. We systematically crawl Google Search results to uncover web pages discussing how abusers use smart devices to enact IPA. By analyzing these web pages, we identify 32 devices used for IPA and detail the varied strategies abusers use for spying and harassment via these devices. Then, we design a framework\u2014 abuse vectors \u2014 which conceptualizes IoT-enabled IPA as four overarching patterns: Covert Spying , Unauthorized Access , Repurposing , and Intended Use . Using this lens, we pinpoint the necessary solutions required to address each vector of IoT abuse and encourage the security community to take action.",
            "keywords": [
                "IoT-Enabled Abuse",
                "Interpersonal Abuse",
                "Smart Device Surveillance",
                "Abuse Vectors",
                "Victim-Survivor Harassment"
            ]
        },
        "url": "URL#915466",
        "sema_paperId": "6f30d131e2e226f1085a62b157053800d5817b98"
    },
    {
        "@score": "1",
        "@id": "915467",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "353/7646",
                        "text": "Leo Stone"
                    },
                    {
                        "@pid": "75/508",
                        "text": "Rishi Ranjan"
                    },
                    {
                        "@pid": "168/9038",
                        "text": "Stefan Nagy"
                    },
                    {
                        "@pid": "09/2334",
                        "text": "Matthew Hicks"
                    }
                ]
            },
            "title": "No Linux, No Problem: Fast and Correct Windows Binary Fuzzing via Target-embedded Snapshotting.",
            "venue": "USENIX Security Symposium",
            "pages": "4913-4929",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/StoneRNH23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/stone",
            "url": "https://dblp.org/rec/conf/uss/StoneRNH23",
            "abstract": "\u2014Coverage-guided fuzzing remains today\u2019s most successful approach for exposing software security vulnerabilities. Speed is paramount in fuzzing, as maintaining a high test case throughput enables more expeditious exploration of programs\u2014leading to faster vulnerability discovery. High-performance fuzzers exploit the Linux kernel\u2019s customizability to implement process snapshotting : fuzzing-oriented execution primitives that dramatically increase fuzzing throughput. Unfortunately, such speeds remain elusive on Windows. The closed-source nature of its kernel prevents current kernel-based snapshotting techniques from being ported\u2014severely limiting fuzzing\u2019s effectiveness on Windows programs. Thus, accelerating vetting of the Windows software ecosystem demands a fast , correct , and kernel-agnostic fuzzing execution mechanism. We propose making state snapshotting an application-level concern as opposed to a kernel-level concern via target-embedded snapshotting . Target-embedded-snapshotting combines binary-and library-level hooking to allow applications to snapshot themselves\u2014while leaving both their source code and the Windows kernel untouched. Our evaluation on 10 real-world Windows binaries shows that target-embedded snap-shotting overcomes the speed, correctness, and compatibility challenges of previous Windows fuzzing execution mechanisms (i.e., process creation, forkserver-based cloning, and persistent mode). The result is 7\u2013182x increased performance.",
            "keywords": [
                "Fuzzing",
                "Windows Binaries",
                "Target-embedded Snapshotting",
                "Performance Optimization",
                "Vulnerability Discovery"
            ]
        },
        "url": "URL#915467",
        "sema_paperId": "7f0dc07a7a4c85bdff9e3bc2c3e3aef332cc84e0"
    },
    {
        "@score": "1",
        "@id": "915468",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "158/7630",
                        "text": "Zhiyuan Sun"
                    },
                    {
                        "@pid": "53/1565",
                        "text": "Xiapu Luo"
                    },
                    {
                        "@pid": "77/3503",
                        "text": "Yinqian Zhang"
                    }
                ]
            },
            "title": "Panda: Security Analysis of Algorand Smart Contracts.",
            "venue": "USENIX Security Symposium",
            "pages": "1811-1828",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SunLZ23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/sun",
            "url": "https://dblp.org/rec/conf/uss/SunLZ23",
            "abstract": "Algorand has recently grown rapidly as a representative of the new generation of pure-proof-of-stake (PPoS) blockchains. At the same time, Algorand has also attracted more and more users to use it as a trading platform for non-fungible tokens. However, similar to traditional programs, the incorrect way of programming will lead to critical security vulnerabilities in Algorand smart contracts. In this paper, we \ufb01rst analyze the semantics of Algorand smart contracts and \ufb01nd 9 types of generic vulnerabilities. Next, we propose Panda , the \ufb01rst extensible static analysis framework that can automatically detect such vulnerabilities in Algorand smart contracts, and formally de\ufb01ne the vulnerability detection rules. We also construct the \ufb01rst benchmark dataset to evaluate Panda . Finally, we used Panda to conduct a vulnerability assessment on all smart contracts on the Algorand blockchain and found 80,515 (10.38%) vulnerable smart signatures and 150,676 (27.73%) vulnerable applications. Of the vulnerable applications, 4,008 (4.04%) are still on the blockchain and have not been deleted.",
            "keywords": [
                "Algorand",
                "Smart Contracts",
                "Static Analysis",
                "Vulnerability Detection",
                "Panda Framework"
            ]
        },
        "url": "URL#915468",
        "sema_paperId": "eec99883bdc0ebe0f28c40bf4b0dc7bda8341d95"
    },
    {
        "@score": "1",
        "@id": "915469",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "348/0504",
                        "text": "Hritvik Taneja"
                    },
                    {
                        "@pid": "325/3299",
                        "text": "Jason Kim 0007"
                    },
                    {
                        "@pid": "347/9973",
                        "text": "Jie Jeff Xu"
                    },
                    {
                        "@pid": "200/3206",
                        "text": "Stephan van Schaik"
                    },
                    {
                        "@pid": "98/8283",
                        "text": "Daniel Genkin"
                    },
                    {
                        "@pid": "90/10901",
                        "text": "Yuval Yarom"
                    }
                ]
            },
            "title": "Hot Pixels: Frequency, Power, and Temperature Attacks on GPUs and Arm SoCs.",
            "venue": "USENIX Security Symposium",
            "pages": "6275-6292",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Taneja0XSGY23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/taneja",
            "url": "https://dblp.org/rec/conf/uss/Taneja0XSGY23",
            "abstract": "The drive to create thinner, lighter, and more energy efficient devices has resulted in modern SoCs being forced to balance a delicate tradeoff between power consumption, heat dissipation, and execution speed (i.e., frequency). While beneficial, these DVFS mechanisms have also resulted in software-visible hybrid side-channels, which use software to probe analog properties of computing devices. Such hybrid attacks are an emerging threat that can bypass countermeasures for traditional microarchitectural side-channel attacks. Given the rise in popularity of both Arm SoCs and GPUs, in this paper we investigate the susceptibility of these devices to information leakage via power, temperature and frequency, as measured via internal sensors. We demonstrate that the sensor data observed correlates with both instructions executed and data processed, allowing us to mount software-visible hybrid side-channel attacks on these devices. To demonstrate the real-world impact of this issue, we present JavaScript-based pixel stealing and history sniffing attacks on Chrome and Safari, with all side channel countermeasures enabled. Finally, we also show website fingerprinting attacks, without any elevated privileges.",
            "keywords": [
                "Hybrid Side-Channel Attacks",
                "Arm SoCs",
                "GPU Security",
                "Information Leakage",
                "DVFS Mechanisms"
            ]
        },
        "url": "URL#915469",
        "sema_paperId": "8fd743533ecd52295b041fed538662c87bbea694"
    },
    {
        "@score": "1",
        "@id": "915470",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "74/4900",
                        "text": "Brian Tang"
                    },
                    {
                        "@pid": "s/KangGShin",
                        "text": "Kang G. Shin"
                    }
                ]
            },
            "title": "Eye-Shield: Real-Time Protection of Mobile Device Screen Information from Shoulder Surfing.",
            "venue": "USENIX Security Symposium",
            "pages": "5449-5466",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/TangS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/tang",
            "url": "https://dblp.org/rec/conf/uss/TangS23",
            "abstract": "People use mobile devices ubiquitously for computing, communication, storage, web browsing, and more. As a result, the information accessed and stored within mobile devices, such as financial and health information, text messages, and emails, can often be sensitive. Despite this, people frequently use their mobile devices in public areas, becoming susceptible to a simple yet effective attack \u2014 shoulder surfing. Shoulder surfing occurs when a person near a mobile user peeks at the user's mobile device, potentially acquiring passcodes, PINs, browsing behavior, or other personal information. We propose, Eye-Shield, a solution to prevent shoulder surfers from accessing/stealing sensitive on-screen information. Eye-Shield is designed to protect all types of on-screen information in real time, without any serious impediment to users' interactions with their mobile devices. Eye-Shield generates images that appear readable at close distances, but appear blurry or pixelated at farther distances and wider angles. It is capable of protecting on-screen information from shoulder surfers, operating in real time, and being minimally intrusive to the intended users. Eye-Shield protects images and text from shoulder surfers by reducing recognition rates to 24.24% and 15.91%. Our implementations of Eye-Shield achieved high frame rates for 1440 \u00d7 3088 screen resolutions (24 FPS for Android and 43 FPS for iOS). Eye-Shield also incurs acceptable memory usage, CPU utilization, and energy overhead. Finally, our MTurk and in-person user studies indicate that Eye-Shield protects on-screen information without a large usability cost for privacy-conscious users.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-tang_1.pdf",
            "keywords": [
                "Mobile Device Privacy",
                "Shoulder Surfing",
                "Real-Time Protection",
                "User Interaction",
                "Information Security"
            ]
        },
        "url": "URL#915470"
    },
    {
        "@score": "1",
        "@id": "915471",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "330/5252",
                        "text": "Hammas Bin Tanveer"
                    },
                    {
                        "@pid": "180/5453",
                        "text": "Rachee Singh"
                    },
                    {
                        "@pid": "61/1749",
                        "text": "Paul Pearce"
                    },
                    {
                        "@pid": "35/8412",
                        "text": "Rishab Nithyanand"
                    }
                ]
            },
            "title": "Glowing in the Dark: Uncovering IPv6 Address Discovery and Scanning Strategies in the Wild.",
            "venue": "USENIX Security Symposium",
            "pages": "6221-6237",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/TanveerSPN23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/bin-tanveer",
            "url": "https://dblp.org/rec/conf/uss/TanveerSPN23",
            "abstract": "In this work we identify scanning strategies of IPv6 scanners on the Internet. We offer a unique perspective on the behavior of IPv6 scanners by conducting controlled experiments leveraging a large and unused /56 IPv6 subnet. We selectively make parts of the subnet visible to scanners by hosting applications that make direct or indirect contact with IPv6-capable servers on the Internet. By careful experiment design, we mitigate the effects of hidden variables on scans sent to our /56 subnet and establish causal relationships between IPv6 host activity types and the scanner attention they evoke. We show that IPv6 host activities e.g., Web browsing, membership in the NTP pool and Tor network, cause scanners to send a magnitude higher number of unsolicited IP scans and reverse DNS queries to our subnet than before. DNS scanners focus their scans in narrow regions of the address space where our applications are hosted whereas IP scanners broadly scan the entire subnet. Even after the host activity from our subnet subsides, we observe persistent residual scanning to portions of the address space that previously hosted applications.",
            "keywords": [
                "IPv6 Scanning",
                "Network Discovery",
                "Address Space Scanning",
                "Host Activity Impact",
                "Residual Scanning Behavior"
            ]
        },
        "url": "URL#915471",
        "sema_paperId": "f60ffa5991753c5f13e2d1fd8d0da444cbbe42df"
    },
    {
        "@score": "1",
        "@id": "915472",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "88/10370-1",
                        "text": "Guanhong Tao 0001"
                    },
                    {
                        "@pid": "168/9413",
                        "text": "Shengwei An"
                    },
                    {
                        "@pid": "263/7049",
                        "text": "Siyuan Cheng 0005"
                    },
                    {
                        "@pid": "216/6403",
                        "text": "Guangyu Shen"
                    },
                    {
                        "@pid": "95/3760-1",
                        "text": "Xiangyu Zhang 0001"
                    }
                ]
            },
            "title": "Hard-label Black-box Universal Adversarial Patch Attack.",
            "venue": "USENIX Security Symposium",
            "pages": "697-714",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/TaoA0S023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/tao",
            "url": "https://dblp.org/rec/conf/uss/TaoA0S023",
            "abstract": "Deep learning models are widely used in many applications. Despite their impressive performance, the security aspect of these models has raised serious concerns. Universal adversarial patch attack is one of the security problems in deep learning, where an attacker can generate a patch trigger on pre-trained models using gradient information. Whenever the trigger is pasted on an input, the model will misclassify it to a target label. Existing attacks are realized with access to the model's gradient or its output confidence. In this paper, we propose a novel attack method HardBeat that generates universal adversarial patches with access only to the predicted label. It utilizes historical data points during the search for an optimal patch trigger and performs focused/directed search through a novel importance-aware gradient approximation to explore the neighborhood of the current trigger. The evaluation is conducted on four popular image datasets with eight models and two online commercial services. The experimental results show HardBeat is significantly more effective than eight baseline attacks, having more than twice high-ASR (attack success rate) patch triggers (>90%) on local models and 17.5% higher ASR on online services. Three existing advanced defense techniques fail to defend against HardBeat.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-tao.pdf",
            "keywords": [
                "Adversarial Patch Attack",
                "Universal Adversarial Attack",
                "HardBeat",
                "Attack Success Rate (ASR)",
                "Gradient-Free Attack"
            ]
        },
        "url": "URL#915472",
        "sema_paperId": "6f6f9f1632907ca5e8e8cb644fb5929ccf7debd6"
    },
    {
        "@score": "1",
        "@id": "915473",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "353/7591",
                        "text": "Massimiliano Taverna"
                    },
                    {
                        "@pid": "39/780",
                        "text": "Kenneth G. Paterson"
                    }
                ]
            },
            "title": "Snapping Snap Sync: Practical Attacks on Go Ethereum Synchronising Nodes.",
            "venue": "USENIX Security Symposium",
            "pages": "3331-3348",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/TavernaP23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/taverna",
            "url": "https://dblp.org/rec/conf/uss/TavernaP23",
            "abstract": "Go Ethereum is by far the most used Ethereum client. It originally implemented the Ethereum proof-of-work consensus mechanism, before the switch to proof-of-stake in 2022. We analyse the Go Ethereum implementation of chain synchronisation \u2013 the process through which a node first joining the network obtains the blockchain from its peers \u2013 in proof-of-work. We present three novel attacks that allow an adversary controlling a small fraction of the network mining power to induce synchronising nodes to deviate from consensus and eventually operate on an adversary-controlled version of the blockchain. We successfully implemented the attacks in a test network. We describe how the attacks can be leveraged to realise financial profits, through off-chain trading and via arbitrary code execution. Notably, the cheapest of our attacks can be mounted using a fraction of one GPU against both Ethereum Classic and EthereumPoW, two Ethereum forks still relying on the proof-of-work consensus mechanism and whose combined market capitalisation is around 3 billion USD. Our attacks would have also applied to the pre-Merge Ethereum mainnet during the period 2017\u20132022.",
            "keywords": [
                "Blockchain Security",
                "Ethereum Client",
                "Chain Synchronisation",
                "Consensus Deviation",
                "Adversarial Attacks"
            ]
        },
        "url": "URL#915473",
        "sema_paperId": "32d838d8fc13e8cea087e973c3b8c3b5349c91f2"
    },
    {
        "@score": "1",
        "@id": "915474",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "175/6612",
                        "text": "Hui Jun Tay"
                    },
                    {
                        "@pid": "270/2413",
                        "text": "Kyle Zeng"
                    },
                    {
                        "@pid": "224/1548",
                        "text": "Jayakrishna Menon Vadayath"
                    },
                    {
                        "@pid": "185/3910",
                        "text": "Arvind S. Raj"
                    },
                    {
                        "@pid": "353/7612",
                        "text": "Audrey Dutcher"
                    },
                    {
                        "@pid": "353/7665",
                        "text": "Tejesh Reddy"
                    },
                    {
                        "@pid": "353/7674",
                        "text": "Wil Gibbs"
                    },
                    {
                        "@pid": "332/3154",
                        "text": "Zion Leonahenahe Basque"
                    },
                    {
                        "@pid": "296/5462",
                        "text": "Fangzhou Dong"
                    },
                    {
                        "@pid": "353/7671",
                        "text": "Zack Smith"
                    },
                    {
                        "@pid": "28/8280",
                        "text": "Adam Doup\u00e9"
                    },
                    {
                        "@pid": "150/5198",
                        "text": "Tiffany Bao"
                    },
                    {
                        "@pid": "119/7712",
                        "text": "Yan Shoshitaishvili"
                    },
                    {
                        "@pid": "127/9829",
                        "text": "Ruoyu Wang 0001"
                    }
                ]
            },
            "title": "Greenhouse: Single-Service Rehosting of Linux-Based Firmware Binaries in User-Space Emulation.",
            "venue": "USENIX Security Symposium",
            "pages": "5791-5808",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/TayZVRDRGBDSDBS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/tay",
            "url": "https://dblp.org/rec/conf/uss/TayZVRDRGBDSDBS23",
            "abstract": "As IoT devices grow more widespread, scaling current analysis techniques to match becomes an increasingly critical task. Part of this challenge involves not only rehosting the \ufb01rmware of these embedded devices in an emulated environment, but to do so and discover real vulnerabilities. Current state-of-the-art approaches for rehosting must account for the discrepancies between emulated and physical devices, and thus generally focus on improving the emulation \ufb01delity . However, this pursuit of \ufb01delity ignores other potential solutions. In this paper, we propose a novel rehosting technique, user-space single-service rehosting , which emulates a single \ufb01rmware service in user space. We study the rehosting process involved in hundreds of \ufb01rmware samples to generalize a set of roadblocks that prevent emulation and create interventions to resolve them. Our prototype Greenhouse automatically rehosts 2,841 (39.7%) of our collected 7,140 \ufb01rmware images from nine different vendors. Our approach sidesteps many of the challenges encountered by previous rehosting techniques and enables us to apply common vulnerability discovery techniques to our rehosted images such as user-space coverage-guided fuzzing. Using these techniques, we \ufb01nd 717 N-day vulnerabilities and 26 zero-day vulnerabilities on a subset of our rehosted \ufb01rmware services.",
            "keywords": [
                "IoT Device Firmware",
                "User-Space Emulation",
                "Rehosting Techniques",
                "Vulnerability Discovery",
                "Coverage-Guided Fuzzing"
            ]
        },
        "url": "URL#915474",
        "sema_paperId": "0f74450aec343f64ca29a6c5816e9172774a40ec"
    },
    {
        "@score": "1",
        "@id": "915475",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "271/4264",
                        "text": "Jan Philipp Thoma"
                    },
                    {
                        "@pid": "290/8354",
                        "text": "Christian Niesler"
                    },
                    {
                        "@pid": "194/7254",
                        "text": "Dominic A. Funke"
                    },
                    {
                        "@pid": "90/4585",
                        "text": "Gregor Leander"
                    },
                    {
                        "@pid": "122/2519",
                        "text": "Pierre Mayr"
                    },
                    {
                        "@pid": "118/7424",
                        "text": "Nils Pohl"
                    },
                    {
                        "@pid": "73/7564",
                        "text": "Lucas Davi"
                    },
                    {
                        "@pid": "50/6307",
                        "text": "Tim G\u00fcneysu"
                    }
                ]
            },
            "title": "ClepsydraCache - Preventing Cache Attacks with Time-Based Evictions.",
            "venue": "USENIX Security Symposium",
            "pages": "1991-2008",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ThomaNFLMPDG23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/thoma",
            "url": "https://dblp.org/rec/conf/uss/ThomaNFLMPDG23",
            "abstract": "In the recent past, we have witnessed the shift towards attacks on the microarchitectural CPU level. In particular, cache side-channels play a predominant role as they allow an attacker to exfiltrate secret information by exploiting the CPU microarchitecture. These subtle attacks exploit the architectural visibility of conflicting cache addresses. In this paper, we present ClepsydraCache, which mitigates state-of-the-art cache attacks using a novel combination of cache decay and index randomization. Each cache entry is linked with a Time-To-Live (TTL) value. We propose a new dynamic scheduling mechanism of the TTL which plays a fundamental role in preventing those attacks while maintaining performance. ClepsydraCache efficiently protects against the latest cache attacks such as Prime+(Prune+)Probe. We present a full prototype in gem5 and lay out a proof-of-concept hardware design of the TTL mechanism, which demonstrates the feasibility of deploying ClepsydraCache in real-world systems.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-thoma.pdf",
            "keywords": [
                "Cache Side-Channel Attacks",
                "Microarchitectural Security",
                "ClepsydraCache",
                "Time-To-Live (TTL) Mechanism",
                "Cache Decay and Index Randomization"
            ]
        },
        "url": "URL#915475",
        "sema_paperId": "b61437fca82553118dfa60e6aecbd5c00bbfa18a"
    },
    {
        "@score": "1",
        "@id": "915476",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "209/1549",
                        "text": "Jianwen Tian"
                    },
                    {
                        "@pid": "254/7430",
                        "text": "Kefan Qiu"
                    },
                    {
                        "@pid": "60/206",
                        "text": "Debin Gao"
                    },
                    {
                        "@pid": "95/6543-14",
                        "text": "Zhi Wang 0014"
                    },
                    {
                        "@pid": "18/1267",
                        "text": "Xiaohui Kuang"
                    },
                    {
                        "@pid": "73/860",
                        "text": "Gang Zhao"
                    }
                ]
            },
            "title": "Sparsity Brings Vulnerabilities: Exploring New Metrics in Backdoor Attacks.",
            "venue": "USENIX Security Symposium",
            "pages": "2689-2706",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/TianQG0KZ23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/tian",
            "url": "https://dblp.org/rec/conf/uss/TianQG0KZ23",
            "abstract": "Nowadays, using AI-based detectors to keep pace with the fast iterating of malware has attracted a great attention. However, most AI-based malware detectors use features with vast sparse subspaces to characterize applications, which brings significant vulnerabilities to the model. To exploit this sparsity-related vulnerability, we propose a clean-label backdoor attack consisting of a dissimilarity metric-based candidate selection and a variation ratio-based trigger construction. The proposed backdoor is veri\ufb01ed on different datasets, including a Windows PE dataset, an Android dataset with numerical and boolean feature values, and a PDF dataset. The experimental results show that the attack can slash the accuracy on watermarked malware to nearly 0% even with the least number (0.01% of the class set) of watermarked goodwares compared to previous attacks. Problem space constraints are also considered with experiments in data-agnostic scenario and data-and-model-agnostic scenario , proving transferability between different datasets as well as deep neural networks and traditional classi\ufb01ers. The attack is veri\ufb01ed consistently powerful under the above scenarios. Moreover, eight existing defenses were tested with their effect left much to be desired. We demonstrated the reason and proposed a subspace compression strategy to boost models\u2019 robustness, which also makes part of the previously failed defenses effective.",
            "keywords": [
                "Backdoor Attacks",
                "Clean-label Attacks",
                "Sparsity Vulnerabilities",
                "Malware Detection",
                "Subspace Compression"
            ]
        },
        "url": "URL#915476",
        "sema_paperId": "a98290763b276e78241f623b5959841be89b03df"
    },
    {
        "@score": "1",
        "@id": "915477",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "329/5254",
                        "text": "Afonso Tinoco"
                    },
                    {
                        "@pid": "329/5629",
                        "text": "Sixiang Gao"
                    },
                    {
                        "@pid": "80/4580",
                        "text": "Elaine Shi"
                    }
                ]
            },
            "title": "EnigMap: External-Memory Oblivious Map for Secure Enclaves.",
            "venue": "USENIX Security Symposium",
            "pages": "4033-4050",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/TinocoGS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/tinoco",
            "url": "https://dblp.org/rec/conf/uss/TinocoGS23",
            "abstract": "Imagine that a privacy-conscious client would like to query a key-value store residing on an untrusted server equipped with a secure processor. To protect the privacy of the client\u2019s queries as well as the database, one approach is to implement an oblivious map inside a secure enclave. Indeed, earlier works demonstrated numerous applications of an enclaved-based oblivious map, including private contact discovery, key transparency, and secure outsourced databases. Our work is motivated by the observation that the previous enclave implementations of oblivious algorithms are sub-optimal both asymptotically and concretely. We make the key observation that for enclave applications, the number of page swaps should be a primary performance metric. We therefore adopt techniques from the external-memory algorithms literature, and we are the \ufb01rst to implement such algorithms inside hardware enclaves. We also devise asymptotically better algorithms for ensuring a strong notion of obliviousness that resists cache-timing attacks. We complement our algorithmic improvements with various concrete optimizations that save constant factors in practice. The resulting system, called E NIG M AP , achieves 15 \u00d7 speedup over Signal\u2019s linear scan implementation, and 53 \u00d7 speedup over the prior best oblivious algorithm implementation, at a realistic database size of 256 million and a batch size of 1000. The speedup is asymptotical in nature and will be even greater as Signal\u2019s user base grows.",
            "keywords": [
                "Secure Enclaves",
                "Oblivious Map",
                "External-Memory Algorithms",
                "Cache-Timing Attacks",
                "Performance Optimization"
            ]
        },
        "url": "URL#915477",
        "sema_paperId": "8fa7e16aed11925e33d5ace72ec80ca4b4621f96"
    },
    {
        "@score": "1",
        "@id": "915478",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "169/2279",
                        "text": "Christof Ferreira Torres"
                    },
                    {
                        "@pid": "349/4893",
                        "text": "Fiona Willi"
                    },
                    {
                        "@pid": "136/8404",
                        "text": "Shweta Shinde"
                    }
                ]
            },
            "title": "Is Your Wallet Snitching On You? An Analysis on the Privacy Implications of Web3.",
            "venue": "USENIX Security Symposium",
            "pages": "769-786",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/TorresWS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/torres",
            "url": "https://dblp.org/rec/conf/uss/TorresWS23",
            "abstract": "With the recent hype around the Metaverse and NFTs, Web3 is getting more and more popular. The goal of Web3 is to decentralize the web via decentralized applications. Wallets play a crucial role as they act as an interface between these applications and the user. Wallets such as MetaMask are being used by millions of users nowadays. Unfortunately, Web3 is often advertised as more secure and private. However, decentralized applications as well as wallets are based on traditional technologies, which are not designed with privacy of users in mind. In this paper, we analyze the privacy implications that Web3 technologies such as decentralized applications and wallets have on users. To this end, we build a framework that measures exposure of wallet information. First, we study whether information about installed wallets is being used to track users online. We analyze the top 100K websites and find evidence of 1,325 websites running scripts that probe whether users have wallets installed in their browser. Second, we measure whether decentralized applications and wallets leak the user's unique wallet address to third-parties. We intercept the traffic of 616 decentralized applications and 100 wallets and find over 2000 leaks across 211 applications and more than 300 leaks across 13 wallets. Our study shows that Web3 poses a threat to users' privacy and requires new designs towards more privacy-aware wallet architectures.",
            "keywords": [
                "Web3 Privacy",
                "Decentralized Applications",
                "Wallet Security",
                "User Tracking",
                "Data Leaks"
            ]
        },
        "url": "URL#915478",
        "sema_paperId": "c2f5c4c7538c1265b118d6053223849f26890b84"
    },
    {
        "@score": "1",
        "@id": "915479",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "331/2106",
                        "text": "Dani\u00ebl Trujillo"
                    },
                    {
                        "@pid": "331/2554",
                        "text": "Johannes Wikner"
                    },
                    {
                        "@pid": "121/2685",
                        "text": "Kaveh Razavi"
                    }
                ]
            },
            "title": "Inception: Exposing New Attack Surfaces with Training in Transient Execution.",
            "venue": "USENIX Security Symposium",
            "pages": "7303-7320",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/TrujilloWR23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/trujillo",
            "url": "https://dblp.org/rec/conf/uss/TrujilloWR23",
            "abstract": "To protect against transient control-\ufb02ow hijacks, software relies on a secure state of microarchitectural buffers that are involved in branching decisions. To achieve this secure state, hardware and software mitigations restrict or sanitize these microarchitectural buffers when switching the security context, e.g., when a user process enters the kernel. Unfortunately, we show that these mitigations do not prevent an attacker from manipulating the state of these microarchitectural buffers in many cases of interest. In particular, we present T raining in T ransient E xecution (TTE), a new class of transient execution attacks that enables an attacker to train a target microarchitectural buffer after switching to the victim context. To show the impact of TTE, we build an end-to-end exploit called I NCEPTION that creates an in\ufb01nite transient loop in hardware to train the return stack buffer with an attacker-controlled target in all existing AMD Zen microarchitectures. I NCEP - TION leaks arbitrary kernel memory at a rate of 39 bytes/s on AMD Zen 4 despite all mitigations against transient control-\ufb02ow hijacks, including the recent Automatic IBRS.",
            "keywords": [
                "Transient Execution Attacks",
                "Microarchitectural Buffers",
                "Control-Flow Hijacks",
                "Kernel Memory Leakage",
                "Return Stack Buffer"
            ]
        },
        "url": "URL#915479",
        "sema_paperId": "6d7b1eb62eb9b2b7d233e500f4dabeaf5a8e9dea"
    },
    {
        "@score": "1",
        "@id": "915480",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "222/2846",
                        "text": "Yazhou Tu"
                    },
                    {
                        "@pid": "276/6779",
                        "text": "Liqun Shan"
                    },
                    {
                        "@pid": "283/5666",
                        "text": "Md. Imran Hossen"
                    },
                    {
                        "@pid": "135/7828",
                        "text": "Sara Rampazzi"
                    },
                    {
                        "@pid": "82/1935",
                        "text": "Kevin R. B. Butler"
                    },
                    {
                        "@pid": "07/8968",
                        "text": "Xiali Hei 0001"
                    }
                ]
            },
            "title": "Auditory Eyesight: Demystifying \u03bcs-Precision Keystroke Tracking Attacks on Unconstrained Keyboard Inputs.",
            "venue": "USENIX Security Symposium",
            "pages": "175-192",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/TuSHRB023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/tu",
            "url": "https://dblp.org/rec/conf/uss/TuSHRB023",
            "abstract": "In various scenarios from system login to writing emails, documents, and forms, keyboard inputs carry alluring data such as usernames, passwords, addresses, and IDs. Due to commonly existing non-alphabetic inputs, punctuation, and typos, users\u2019 natural inputs rarely contain only constrained, purely alphabetic keys/words. This work studies how to reveal unconstrained keyboard inputs using auditory interfaces. Audio interfaces are not intended to have the capability of light sensors such as cameras to identify compactly located keys. Our analysis shows that effectively distinguishing the keys can require a fine localization precision level of keystroke sounds close to the range of microseconds. This work (1) explores the limits of audio interfaces to distinguish keystrokes, (2) proposes a \u00b5 s-level customized signal processing and analysis-based keystroke tracking approach that takes into account the mechanical physics and imperfect measuring of keystroke sounds, (3) develops the first acoustic side-channel attack study on unconstrained keyboard inputs that are not purely alphabetic keys/words and do not necessarily follow known sequences in a given dictionary or training dataset, and (4) reveals the threats of non-line-of-sight keystroke sound tracking. Our results indicate that, without relying on vision sensors, attacks using limited-resolution audio interfaces can reveal unconstrained inputs from the keyboard with a fairly sharp and bendable \u201cauditory eyesight.\u201d",
            "keywords": [
                "Auditory Interfaces",
                "Keystroke Tracking",
                "Acoustic Side-Channel Attacks",
                "Unconstrained Keyboard Inputs",
                "Microsecond Precision"
            ]
        },
        "url": "URL#915480",
        "sema_paperId": "c50bbf995312c3367a24f6802fbd06799f553309"
    },
    {
        "@score": "1",
        "@id": "915481",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "207/8076",
                        "text": "Adithya Vadapalli"
                    },
                    {
                        "@pid": "86/8283",
                        "text": "Ryan Henry"
                    },
                    {
                        "@pid": "04/6434",
                        "text": "Ian Goldberg"
                    }
                ]
            },
            "title": "Duoram: A Bandwidth-Efficient Distributed ORAM for 2- and 3-Party Computation.",
            "venue": "USENIX Security Symposium",
            "pages": "3907-3924",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/VadapalliHG23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/vadapalli",
            "url": "https://dblp.org/rec/conf/uss/VadapalliHG23",
            "abstract": "We design, analyze, and implement Duoram, a fast and bandwidth-efficient distributed ORAM protocol suitable for secure 2- and 3-party computation settings. Following Doerner and shelat's Floram construction (CCS 2017), Duoram leverages (2,2)-distributed point functions (DPFs) to represent PIR and PIR-writing queries compactly\u2014but with a host of innovations that yield massive asymptotic reductions in communication cost and notable speedups in practice, even for modestly sized instances.  Specifically, Duoram introduces a novel method for evaluating dot products of certain secret-shared vectors using communication that is only logarithmic in the vector length. As a result, for memories with n addressable locations, Duoram can perform a sequence of m arbitrarily interleaved reads and writes using just O(mlgn) words of communication, compared with Floram's O(m\u221an) words. Moreover, most of this work can occur during a data-independent preprocessing phase, leaving just O(m) words of online communication cost for the sequence\u2014i.e., a constant online communication cost per memory access.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-vadapalli.pdf",
            "keywords": [
                "Distributed ORAM",
                "Secure Computation",
                "Bandwidth Efficiency",
                "Point Functions",
                "Communication Cost"
            ]
        },
        "url": "URL#915481"
    },
    {
        "@score": "1",
        "@id": "915482",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "205/8958",
                        "text": "Piet De Vaere"
                    },
                    {
                        "@pid": "16/6873",
                        "text": "Adrian Perrig"
                    }
                ]
            },
            "title": "Hey Kimya, Is My Smart Speaker Spying on Me? Taking Control of Sensor Privacy Through Isolation and Amnesia.",
            "venue": "USENIX Security Symposium",
            "pages": "2401-2418",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/VaereP23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/de-vaere",
            "url": "https://dblp.org/rec/conf/uss/VaereP23",
            "abstract": "Although smart speakers and other voice assistants are becoming increasingly ubiquitous, their always-standby nature continues to prompt significant privacy concerns. To address these, we propose K IMYA , a hardening framework that allows device vendors to provide strong data-privacy guarantees. Concretely, K IMYA guarantees that microphone data can only be used for local processing, and is immediately discarded unless a user-auditable notification is generated. K IMYA thus makes devices accountable for their data-retention behavior. Moreover, K IMYA is not limited to voice assistants, but is applicable to all devices with always-standby, event-triggered sensors. We implement K IMYA for ARM Cortex-M, and apply it to a wake-word detection engine. Our evaluation shows that K IMYA introduces low overhead, can be used in constrained environments, and does not require hardware modifications.",
            "keywords": [
                "Smart Speaker Privacy",
                "Data Retention",
                "Sensor Isolation",
                "User Auditable Notification",
                "Wake-Word Detection"
            ]
        },
        "url": "URL#915482",
        "sema_paperId": "607bcdffe64f11359734379ddf5be0d580676697"
    },
    {
        "@score": "1",
        "@id": "915483",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "332/0891",
                        "text": "Viktor Valadi"
                    },
                    {
                        "@pid": "265/6559",
                        "text": "Xinchi Qiu"
                    },
                    {
                        "@pid": "88/10808",
                        "text": "Pedro Porto Buarque de Gusm\u00e3o"
                    },
                    {
                        "@pid": "03/2663",
                        "text": "Nicholas D. Lane"
                    },
                    {
                        "@pid": "128/2967",
                        "text": "Mina Alibeigi"
                    }
                ]
            },
            "title": "FedVal: Different good or different bad in federated learning.",
            "venue": "USENIX Security Symposium",
            "pages": "6365-6380",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ValadiQGLA23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/valadi",
            "url": "https://dblp.org/rec/conf/uss/ValadiQGLA23",
            "abstract": "Federated learning (FL) systems are susceptible to attacks from malicious actors who might attempt to corrupt the training model through various poisoning attacks. FL also poses new challenges in addressing group bias, such as ensuring fair performance for different demographic groups. Traditional methods used to address such biases require centralized access to the data, which FL systems do not have. In this paper, we present a novel approach FedVal for both robustness and fairness that does not require any additional information from clients that could raise privacy concerns and consequently compromise the integrity of the FL system. To this end, we propose an innovative score function based on a server-side validation method that assesses client updates and determines the optimal aggregation balance between locally-trained models. Our research shows that this approach not only provides solid protection against poisoning attacks but can also be used to reduce group bias and subsequently promote fairness while maintaining the system's capability for differential privacy. Extensive experiments on the CIFAR-10, FEMNIST, and PUMS ACSIncome datasets in different configurations demonstrate the effectiveness of our method, resulting in state-of-the-art performances. We have proven robustness in situations where 80% of participating clients are malicious. Additionally, we have shown a significant increase in accuracy for underrepresented labels from 32% to 53%, and increase in recall rate for underrepresented features from 19% to 50%.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-valadi.pdf",
            "keywords": [
                "Federated Learning",
                "Robustness",
                "Fairness",
                "Poisoning Attacks",
                "Group Bias"
            ]
        },
        "url": "URL#915483"
    },
    {
        "@score": "1",
        "@id": "915484",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "353/7635",
                        "text": "Willy R. Vasquez"
                    },
                    {
                        "@pid": "14/8302",
                        "text": "Stephen Checkoway"
                    },
                    {
                        "@pid": "35/1061",
                        "text": "Hovav Shacham"
                    }
                ]
            },
            "title": "The Most Dangerous Codec in the World: Finding and Exploiting Vulnerabilities in H.264 Decoders.",
            "venue": "USENIX Security Symposium",
            "pages": "6647-6664",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/VasquezCS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/vasquez",
            "url": "https://dblp.org/rec/conf/uss/VasquezCS23",
            "abstract": "Modern video encoding standards such as H.264 are a marvel of hidden complexity. But with hidden complexity comes hidden security risk. Decoding video in practice means interacting with dedicated hardware accelerators and the pro-prietary, privileged software components used to drive them. The video decoder ecosystem is obscure, opaque, diverse, highly privileged, largely untested, and highly exposed\u2014a dangerous combination. We introduce and evaluate H26F ORGE , domain-speci\ufb01c infrastructure for analyzing, generating, and manipulating syntactically correct but semantically spec-non-compliant video \ufb01les. Using H26F ORGE , we uncover insecurity in depth across the video decoder ecosystem, including kernel memory corruption bugs in iOS, memory corruption bugs in Firefox and VLC for Windows, and video accelerator and application processor kernel memory bugs in multiple Android devices.",
            "keywords": [
                "Video Codec Security",
                "H.264 Decoders",
                "Memory Corruption",
                "Vulnerability Analysis",
                "H26F ORGE"
            ]
        },
        "url": "URL#915484",
        "sema_paperId": "9199b18b092f9591d518006ec0fa20e814bb53d7"
    },
    {
        "@score": "1",
        "@id": "915485",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "353/7673",
                        "text": "Swaathi Vetrivel"
                    },
                    {
                        "@pid": "353/7552",
                        "text": "Veerle van Harten"
                    },
                    {
                        "@pid": "22/7256",
                        "text": "Carlos Hernandez Ga\u00f1\u00e1n"
                    },
                    {
                        "@pid": "17/7444",
                        "text": "Michel van Eeten"
                    },
                    {
                        "@pid": "84/3561",
                        "text": "Simon Parkin"
                    }
                ]
            },
            "title": "Examining Consumer Reviews to Understand Security and Privacy Issues in the Market of Smart Home Devices.",
            "venue": "USENIX Security Symposium",
            "pages": "1523-1540",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/VetrivelHGEP23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/vetrivel",
            "url": "https://dblp.org/rec/conf/uss/VetrivelHGEP23",
            "abstract": "Despite growing evidence that consumers care about secure Internet-of-Things (IoT) devices, relevant security and privacy-related information is unavailable at the point of purchase. While initiatives such as security labels create new avenues to signal a device\u2019s security and privacy posture, we analyse an existing avenue for such market signals - customer reviews. We investigate whether and to what extent customer reviews of IoT devices with well-known security and privacy issues reflect these concerns. We examine 83,686 reviews of four IoT device types commonly infected with Mirai across all Amazon websites in English. We perform topic modelling to group the reviews and conduct manual coding to understand (i) the prevalence of security and privacy issues and (ii) the themes that these issues articulate. Overall, around one in ten reviews (9.8%) mentions security and privacy issues; the geographical distribution varies across the six countries. We distil references to security and privacy into seven themes and identify two orthogonal themes: reviews written in technical language and those that mention friction with security steps. Our results thus highlight the value of the already existing avenue of customer reviews. We draw on these results to make recommendations and identify future research directions.",
            "keywords": [
                "Smart Home Devices",
                "Consumer Reviews",
                "Security and Privacy Issues",
                "Internet-of-Things (IoT)",
                "Market Signals"
            ]
        },
        "url": "URL#915485",
        "sema_paperId": "b8dcd44e3b803e5bc2a9248e766a3e6ce3d78be5"
    },
    {
        "@score": "1",
        "@id": "915486",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "231/9670",
                        "text": "Alexander Viand"
                    },
                    {
                        "@pid": "283/5559",
                        "text": "Patrick Jattke"
                    },
                    {
                        "@pid": "266/1494",
                        "text": "Miro Haller"
                    },
                    {
                        "@pid": "122/5664",
                        "text": "Anwar Hithnawi"
                    }
                ]
            },
            "title": "HECO: Fully Homomorphic Encryption Compiler.",
            "venue": "USENIX Security Symposium",
            "pages": "4715-4732",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ViandJHH23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/viand",
            "url": "https://dblp.org/rec/conf/uss/ViandJHH23",
            "abstract": "In recent years, Fully Homomorphic Encryption (FHE) has undergone several breakthroughs and advancements, leading to a leap in performance. Today, performance is no longer a major barrier to adoption. Instead, it is the complexity of developing an efficient FHE application that currently limits deploying FHE in practice and at scale. Several FHE compilers have emerged recently to ease FHE development. However, none of these answer how to automatically transform imperative programs to secure and efficient FHE implementations. This is a fundamental issue that needs to be addressed before we can realistically expect broader use of FHE. Automating these transformations is challenging because the restrictive set of operations in FHE and their non-intuitive performance characteristics require programs to be drastically transformed to achieve efficiency. Moreover, existing tools are monolithic and focus on individual optimizations. Therefore, they fail to fully address the needs of end-to-end FHE development. In this paper, we present HECO, a new end-to-end design for FHE compilers that takes high-level imperative programs and emits efficient and secure FHE implementations. In our design, we take a broader view of FHE development, extending the scope of optimizations beyond the cryptographic challenges existing tools focus on.",
            "keywords": [
                "Fully Homomorphic Encryption",
                "FHE Compiler",
                "Imperative Programs",
                "End-to-End Development",
                "Program Transformation"
            ]
        },
        "url": "URL#915486",
        "sema_paperId": "79aaa6f4f43a900ac8def62a4d3dd284d101bc54"
    },
    {
        "@score": "1",
        "@id": "915487",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "226/0913",
                        "text": "Parjanya Vyas"
                    },
                    {
                        "@pid": "287/4144",
                        "text": "Asim Waheed"
                    },
                    {
                        "@pid": "138/6356",
                        "text": "Yousra Aafer"
                    },
                    {
                        "@pid": "39/2508",
                        "text": "N. Asokan"
                    }
                ]
            },
            "title": "Auditing Framework APIs via Inferred App-side Security Specifications.",
            "venue": "USENIX Security Symposium",
            "pages": "6061-6077",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/VyasWAA23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/vyas",
            "url": "https://dblp.org/rec/conf/uss/VyasWAA23",
            "abstract": "In this work, we explore auditing access control implementations of Android private framework APIs by leveraging app-side security specifications. The seemingly straightforward auditing task faces significant challenges. It requires extracting unconventional security indicators and understanding their relevance to private framework APIs. More importantly, addressing these challenges requires relying on uncertain hints. We hence, introduce Bluebird , a security auditing platform for Android APIs, that mimics a human expert. Bluebird seamlessly fuses human-like understanding of app-side logic with statically-derived program semantics using probabilistic inference to detect access control gaps in private APIs.",
            "keywords": [
                "Android Security",
                "Access Control Auditing",
                "Private Framework APIs",
                "Security Specifications",
                "Access Control Gaps"
            ]
        },
        "url": "URL#915487",
        "sema_paperId": "f7239c8e0cc2c28f4e951807ba3315c37a780539"
    },
    {
        "@score": "1",
        "@id": "915488",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "353/7622",
                        "text": "Salim Al Wahaibi"
                    },
                    {
                        "@pid": "320/8506",
                        "text": "Myles Foley"
                    },
                    {
                        "@pid": "m/SergioMaffeis",
                        "text": "Sergio Maffeis"
                    }
                ]
            },
            "title": "SQIRL: Grey-Box Detection of SQL Injection Vulnerabilities Using Reinforcement Learning.",
            "venue": "USENIX Security Symposium",
            "pages": "6097-6114",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WahaibiFM23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/al-wahaibi",
            "url": "https://dblp.org/rec/conf/uss/WahaibiFM23",
            "abstract": "Web security scanners are used to discover SQL injection vulnerabilities in deployed web applications. Scanners tend to use static rules to cover the most common injection cases, missing diversity in their payloads, leading to a high volume of requests and false negatives. Moreover, scanners often rely on the presence of error messages or other significant feedback on the target web pages, as a result of additional insecure programming practices by web developers. In this paper we develop S QIRL , a novel approach to detecting SQL injection vulnerabilities based on deep reinforcement learning, using multiple worker agents and grey-box feedback. Each worker intelligently fuzzes the input fields discovered by an automated crawling component. This approach generates a more varied set of payloads than existing scanners, leading to the discovery of more vulnerabilities. Moreover, S QIRL attempts fewer payloads, because they are generated in a targeted fashion. S QIRL finds all vulnerabilities in our microbenchmark for SQL injection, with substantially fewer requests than most of the state-of-the-art scanners compared with. It also significantly outperforms other scanners on a set of 14 production grade web applications, discovering 33 vulnerabilities, with zero false positives. We have responsibly disclosed 22 novel vulnerabilities found by S QIRL , grouped in 6 CVEs.",
            "keywords": [
                "SQL Injection Detection",
                "Web Application Vulnerabilities",
                "Reinforcement Learning",
                "Fuzzing Techniques",
                "Grey-Box Testing"
            ]
        },
        "url": "URL#915488",
        "sema_paperId": "efe5f6490180fd71480af0ba5728584812b04414"
    },
    {
        "@score": "1",
        "@id": "915489",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "336/5873",
                        "text": "Th\u00e9ophile Wallez"
                    },
                    {
                        "@pid": "132/3972",
                        "text": "Jonathan Protzenko"
                    },
                    {
                        "@pid": "165/5515",
                        "text": "Benjamin Beurdouche"
                    },
                    {
                        "@pid": "80/3503",
                        "text": "Karthikeyan Bhargavan"
                    }
                ]
            },
            "title": "TreeSync: Authenticated Group Management for Messaging Layer Security.",
            "venue": "USENIX Security Symposium",
            "pages": "1217-1233",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WallezPBB23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/wallez",
            "url": "https://dblp.org/rec/conf/uss/WallezPBB23",
            "abstract": "Messaging Layer Security (MLS), currently undergoing standardization at the IETF, is an asynchronous group messaging protocol that aims to be efficient for large dynamic groups, while providing strong guarantees like forward secrecy (FS) and post-compromise security (PCS). While prior work on MLS has extensively studied its group key establishment component (called TreeKEM), many flaws in early designs of MLS have stemmed from its group integrity and authentication mechanisms that are not as well-understood.  In this work, we identify and formalize TreeSync: a sub-protocol of MLS that specifies the shared group state, defines group management operations, and ensures consistency, integrity, and authentication for the group state across all members.\nWe present a precise, executable, machine-checked formal specification of TreeSync, and show how it can be composed with other components to implement the full MLS protocol. Our specification is written in F* and serves as a reference implementation of MLS; it passes the RFC test vectors and is interoperable with other MLS implementations. Using the DY* symbolic protocol analysis framework, we formalize and prove the integrity and authentication guarantees of TreeSync, under minimal security assumptions on the rest of MLS. Our analysis identifies a new attack and we propose several changes that have been incorporated in the latest MLS draft. Ours is the first testable, machine-checked, formal specification for MLS, and should be of interest to both developers and researchers interested in this upcoming standard.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-wallez.pdf",
            "keywords": [
                "Messaging Layer Security",
                "Group Management",
                "TreeSync",
                "Integrity and Authentication",
                "Forward Secrecy"
            ]
        },
        "url": "URL#915489"
    },
    {
        "@score": "1",
        "@id": "915490",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "97/604",
                        "text": "Haiming Wang"
                    },
                    {
                        "@pid": "90/545-1",
                        "text": "Zhikun Zhang 0001"
                    },
                    {
                        "@pid": "145/3288-1",
                        "text": "Tianhao Wang 0001"
                    },
                    {
                        "@pid": "07/7178",
                        "text": "Shibo He"
                    },
                    {
                        "@pid": "b/MichaelBackes1",
                        "text": "Michael Backes 0001"
                    },
                    {
                        "@pid": "55/2484-1",
                        "text": "Jiming Chen 0001"
                    },
                    {
                        "@pid": "06/6785-16",
                        "text": "Yang Zhang 0016"
                    }
                ]
            },
            "title": "PrivTrace: Differentially Private Trajectory Synthesis by Adaptive Markov Models.",
            "venue": "USENIX Security Symposium",
            "pages": "1649-1666",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Wang00H00023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/wang-haiming",
            "url": "https://dblp.org/rec/conf/uss/Wang00H00023",
            "abstract": "Publishing trajectory data (individual's movement information) is very useful, but it also raises privacy concerns. To handle the privacy concern, in this paper, we apply differential privacy, the standard technique for data privacy, together with Markov chain model, to generate synthetic trajectories. We notice that existing studies all use Markov chain model and thus propose a framework to analyze the usage of the Markov chain model in this problem. Based on the analysis, we come up with an effective algorithm PrivTrace that uses the first-order and second-order Markov model adaptively. We evaluate PrivTrace and existing methods on synthetic and real-world datasets to demonstrate the superiority of our method.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-wang-haiming.pdf",
            "keywords": [
                "Differential Privacy",
                "Trajectory Synthesis",
                "Markov Chain Model",
                "Synthetic Trajectories",
                "Privacy Preservation"
            ]
        },
        "url": "URL#915490"
    },
    {
        "@score": "1",
        "@id": "915491",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "60/8494",
                        "text": "Xueqiang Wang"
                    },
                    {
                        "@pid": "57/4707-10",
                        "text": "Yifan Zhang 0010"
                    },
                    {
                        "@pid": "06/6268",
                        "text": "XiaoFeng Wang 0001"
                    },
                    {
                        "@pid": "230/3262",
                        "text": "Yan Jia"
                    },
                    {
                        "@pid": "34/8412",
                        "text": "Luyi Xing"
                    }
                ]
            },
            "title": "Union under Duress: Understanding Hazards of Duplicate Resource Mismediation in Android Software Supply Chain.",
            "venue": "USENIX Security Symposium",
            "pages": "3403-3420",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Wang00JX23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/wang-xueqiang-duress",
            "url": "https://dblp.org/rec/conf/uss/Wang00JX23",
            "abstract": "Malicious third-party libraries have become a major source of security risks to the Android software supply chain. A recent study shows that a malicious library could harvest data from other libraries hosted in the same app via unauthorized API accesses. However, it is unclear whether third-party libraries could still pose a threat to other libraries after their code and APIs are thoroughly vetted for security. A third-party Android library often contains diverse resources to support its operations. These resources, along with resources from other libraries, are managed by the Android resource compiler ( ARC ) during the app build process. ARC needs to mediate the resources in case multiple libraries have duplicate resources . In this paper, we report a new attack surface on the Android app supply chain: duplicate resource mismediation ( Duress ). This attack surface provides an opportunity for attackers to contaminate security-and privacy-sensitive resources of a victim library by exploiting ARC , using duplicate resources in malicious libraries. Our attack cases demonstrate that with several effective attack strategies, an attacker can stealthily mislead the victim library and its users to expose sensitive data, and lower down the security protections, etc. Further, we conduct the first systematic study to understand the impacts of Duress risks. Our study has brought to light the pervasiveness of the Duress risks in third-party libraries: an analysis of over 23K libraries and 150K apps discovered that 18.4% libraries have sensitive resources that are exposed to Duress risks, 25.7% libraries have duplicate sensitive resources with other libraries, i.e., integration risks, and over 400 apps in the wild are affected by potential occurrences of Duress , etc. To mitigate the risks, we discuss a lightweight and compile-time resource isolation method to prevent malicious libraries from contaminating the sensitive resources of other libraries.",
            "keywords": [
                "Android Software Supply Chain",
                "Third-Party Libraries",
                "Duplicate Resource Mismediation",
                "Security Risks",
                "Resource Contamination"
            ]
        },
        "url": "URL#915491",
        "sema_paperId": "41f8bee27c69b75164759a9b5e161c60dabee66e"
    },
    {
        "@score": "1",
        "@id": "915492",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "24/10098",
                        "text": "Zicheng Wang"
                    },
                    {
                        "@pid": "16/6884-1",
                        "text": "Yueqi Chen 0001"
                    },
                    {
                        "@pid": "66/3005-2",
                        "text": "Qingkai Zeng 0002"
                    }
                ]
            },
            "title": "PET: Prevent Discovered Errors from Being Triggered in the Linux Kernel.",
            "venue": "USENIX Security Symposium",
            "pages": "4193-4210",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WangC023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/wang-zicheng",
            "url": "https://dblp.org/rec/conf/uss/WangC023",
            "abstract": "The Linux kernel is the backbone of modern society. When a kernel error is discovered, a quick remediation is needed. Whereas sanitizers greatly facilitate root cause diagnosis, \ufb01x-ing errors takes a long time, resulting in errors discovered but still exploited. In this work, we propose PET , a temporary so-lution to prevent discovered errors from being triggered and exploited before patches are available. Technically, PET takes a sanitizer report as the input, constructing the triggering condition that can be evaluated at run-time. If the condition is met, PET takes a series of actions to prevent error triggering. PET is designed to be extensible to various error types. In our experiment, we demonstrated its effectiveness against the \ufb01ve most common errors that state-of-the-art sanitizers can report. PET is lightweight with performance overhead less than 3%. Further, PET is scalable in the presence of multiple errors with acceptable memory assumption. The kernel has run stably for more than 3 months under intensive use after errors are prevented.",
            "keywords": [
                "Linux Kernel",
                "Error Prevention",
                "Sanitizers",
                "Error Exploitation",
                "Runtime Error Handling"
            ]
        },
        "url": "URL#915492",
        "sema_paperId": "7651c5f332e5e0935d044140b64c92ffdb834e9e"
    },
    {
        "@score": "1",
        "@id": "915493",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "41/8349",
                        "text": "Ruipeng Wang"
                    },
                    {
                        "@pid": "227/9058",
                        "text": "Kaixiang Chen"
                    },
                    {
                        "@pid": "94/3019-8",
                        "text": "Chao Zhang 0008"
                    },
                    {
                        "@pid": "270/5744",
                        "text": "Zulie Pan"
                    },
                    {
                        "@pid": "214/5962",
                        "text": "Qianyu Li"
                    },
                    {
                        "@pid": "353/7570",
                        "text": "Siliang Qin"
                    },
                    {
                        "@pid": "64/10449",
                        "text": "Shenglin Xu"
                    },
                    {
                        "@pid": "83/5342",
                        "text": "Min Zhang"
                    },
                    {
                        "@pid": "37/4190",
                        "text": "Yang Li"
                    }
                ]
            },
            "title": "AlphaEXP: An Expert System for Identifying Security-Sensitive Kernel Objects.",
            "venue": "USENIX Security Symposium",
            "pages": "4229-4246",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WangC0PLQXZL23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/wang-ruipeng",
            "url": "https://dblp.org/rec/conf/uss/WangC0PLQXZL23",
            "abstract": "Memory corruption vulnerabilities are often exploited to corrupt sensitive objects and launch attacks. An efficient way to mitigate such threats is identifying and protecting such sensitive objects against corruption. However, it is still an open question that what objects are security sensitive and how sensitive they are. In this paper, we present the first expert system based solution AlphaEXP to identify security sensitive objects, in a specific and important target\u2014the Linux kernel. It works by simulating an adversary to assess whether an object could be abused to get unintended capabilities and contribute to exploitation, and marks it as sensitive if so. Specifically, AlphaEXP first constructs a knowledge graph to represent the facts of the kernel, including objects, functions, and their relationships etc. Then, it explores the knowledge graph to infer potential attack paths for given vulnerabilities, and marks objects used in the attack paths as sensitive. Lastly, it evaluates the feasibility of the attack paths in a customized emulating system, and classifies the sensitivity of objects accordingly. We have built a prototype of AlphaEXP and evaluated it on 84 synthesized representative vulnerabilities and 19 real world vulnerabilities to identify sensitive kernel objects. AlphaEXP successfully generates attack paths for most of these vulnerabilities, and finds 50 objects that could be abused to get writing capability, 81 objects with reading capability, and 112 objects with execution capability. AlphaEXP classifies them into 12 levels of sensitivity.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-wang-ruipeng.pdf",
            "keywords": [
                "Kernel Security",
                "Memory Corruption",
                "Sensitive Objects Identification",
                "Attack Path Analysis",
                "Expert System"
            ]
        },
        "url": "URL#915493",
        "sema_paperId": "0f038e60dc0f72af7aa1c38eef589558b6bf324d"
    },
    {
        "@score": "1",
        "@id": "915494",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "94/9817",
                        "text": "Cheng-Long Wang"
                    },
                    {
                        "@pid": "150/8482",
                        "text": "Mengdi Huai"
                    },
                    {
                        "@pid": "18/5410-15",
                        "text": "Di Wang 0015"
                    }
                ]
            },
            "title": "Inductive Graph Unlearning.",
            "venue": "USENIX Security Symposium",
            "pages": "3205-3222",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WangH023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/wang-cheng-long",
            "url": "https://dblp.org/rec/conf/uss/WangH023",
            "abstract": "As a way to implement the\"right to be forgotten\"in machine learning, \\textit{machine unlearning} aims to completely remove the contributions and information of the samples to be deleted from a trained model without affecting the contributions of other samples. Recently, many frameworks for machine unlearning have been proposed, and most of them focus on image and text data. To extend machine unlearning to graph data, \\textit{GraphEraser} has been proposed. However, a critical issue is that \\textit{GraphEraser} is specifically designed for the transductive graph setting, where the graph is static and attributes and edges of test nodes are visible during training. It is unsuitable for the inductive setting, where the graph could be dynamic and the test graph information is invisible in advance. Such inductive capability is essential for production machine learning systems with evolving graphs like social media and transaction networks. To fill this gap, we propose the \\underline{{\\bf G}}\\underline{{\\bf U}}ided \\underline{{\\bf I}}n\\underline{{\\bf D}}uctiv\\underline{{\\bf E}} Graph Unlearning framework (GUIDE). GUIDE consists of three components: guided graph partitioning with fairness and balance, efficient subgraph repair, and similarity-based aggregation. Empirically, we evaluate our method on several inductive benchmarks and evolving transaction graphs. Generally speaking, GUIDE can be efficiently implemented on the inductive graph learning tasks for its low graph partition cost, no matter on computation or structure information. The code will be available here: https://github.com/Happy2Git/GUIDE.",
            "keywords": [
                "Graph Unlearning",
                "Inductive Learning",
                "Dynamic Graphs",
                "Fairness in Graph Partitioning",
                "Subgraph Repair"
            ]
        },
        "url": "URL#915494",
        "sema_paperId": "00630c05a4b2f17fb03120b0af09368291ba44e9"
    },
    {
        "@score": "1",
        "@id": "915495",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "00/6350",
                        "text": "Wansen Wang"
                    },
                    {
                        "@pid": "47/7564",
                        "text": "Wenchao Huang"
                    },
                    {
                        "@pid": "186/2989",
                        "text": "Zhaoyi Meng"
                    },
                    {
                        "@pid": "70/880",
                        "text": "Yan Xiong"
                    },
                    {
                        "@pid": "76/2786",
                        "text": "Fuyou Miao"
                    },
                    {
                        "@pid": "49/8453",
                        "text": "Xianjin Fang"
                    },
                    {
                        "@pid": "327/9154",
                        "text": "Caichang Tu"
                    },
                    {
                        "@pid": "120/5277",
                        "text": "Renjie Ji"
                    }
                ]
            },
            "title": "Automated Inference on Financial Security of Ethereum Smart Contracts.",
            "venue": "USENIX Security Symposium",
            "pages": "3367-3383",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WangHMXMFTJ23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/wang-wansen",
            "url": "https://dblp.org/rec/conf/uss/WangHMXMFTJ23",
            "abstract": "Nowadays millions of Ethereum smart contracts are created per year and become attractive targets for financially motivated attackers. However, existing analyzers are not sufficient to analyze the financial security of a large number of contracts precisely. In this paper, we propose and implement FASVERIF, an automated inference system for fine-grained analysis of smart contracts. FASVERIF automatically generates models to be verified against security properties of smart contracts. Besides, different from existing approaches of formal verifications, our inference system also automatically generates the security properties. Specifically, we propose two types of security properties, invariant properties and equivalence properties, which can be used to detect various types of finance-related vulnerabilities and can be automatically generated based on our statistical analysis. As a result, FASVERIF can automatically process source code of smart contracts, and uses formal methods whenever possible to simultaneously maximize its accuracy. We also prove the soundness of verifying our properties using our translated model based on a custom semantics of Solidity.We evaluate FASVERIF on a vulnerabilities dataset of 549 contracts by comparing it with other automatic tools. Our evaluation shows that FASVERIF greatly outperforms the representative tools using different technologies, with respect to accuracy and coverage of types of vulnerabilities. We also evaluate FASVERIF on a real-world dataset of 1700 contracts, and find 13 contracts with bugs that can still be leveraged by adversaries online.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-wang-wansen.pdf",
            "keywords": [
                "Ethereum Smart Contracts",
                "Financial Security",
                "Automated Inference",
                "Vulnerability Detection",
                "Formal Verification"
            ]
        },
        "url": "URL#915495",
        "sema_paperId": "fec12cb0f37dc8834246c41967cd4e20484a227e"
    },
    {
        "@score": "1",
        "@id": "915496",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "129/1981",
                        "text": "Zixin Wang"
                    },
                    {
                        "@pid": "77/8851",
                        "text": "Danny Yuxing Huang"
                    },
                    {
                        "@pid": "142/7931",
                        "text": "Yaxing Yao"
                    }
                ]
            },
            "title": "Exploring Tenants&apos; Preferences of Privacy Negotiation in Airbnb.",
            "venue": "USENIX Security Symposium",
            "pages": "535-551",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WangHY23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/wang-zixin",
            "url": "https://dblp.org/rec/conf/uss/WangHY23",
            "abstract": "Literature suggests the unmatched or conflicting privacy needs between users and bystanders in smart homes due to their different privacy concerns and priorities. A promising approach to mitigate such conflicts is through negotiation. Yet, it is not clear whether bystanders have privacy negotiation needs and if so, what factors may influence their negotiation intention and how to better support the negotiation to achieve their privacy goals. To answer these questions, we conducted a vignette study that varied across three categorical factors, including device types, device location, and duration of stay with 867 participants in the context of Airbnb. We further examined our participants' preferences regarding with whom, when, how, and why they would like to negotiate their privacy. Our findings showed that device type remained the only factor that significantly influenced our participants' negotiation intention. Additionally, we found our participants' other preferences, such as they preferred to contact Airbnb hosts first to convey their privacy needs through asynchronous channels (e.g., messages and emails). We summarized design implications to fulfill tenants' privacy negotiation needs.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-wang-zixin.pdf",
            "keywords": [
                "Airbnb",
                "Privacy Negotiation",
                "Smart Homes",
                "Tenant Preferences",
                "Device Influence"
            ]
        },
        "url": "URL#915496",
        "sema_paperId": "6f285e2d05badc9b3b82f9e9bfbd6f93a6712c3e"
    },
    {
        "@score": "1",
        "@id": "915497",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "39/2537-21",
                        "text": "Dawei Wang 0021"
                    },
                    {
                        "@pid": "22/1805",
                        "text": "Ying Li"
                    },
                    {
                        "@pid": "45/6271",
                        "text": "Zhiyu Zhang"
                    },
                    {
                        "@pid": "c/KaiChen12",
                        "text": "Kai Chen 0012"
                    }
                ]
            },
            "title": "CarpetFuzz: Automatic Program Option Constraint Extraction from Documentation for Fuzzing.",
            "venue": "USENIX Security Symposium",
            "pages": "1919-1936",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WangLZ023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/wang-dawei",
            "url": "https://dblp.org/rec/conf/uss/WangLZ023",
            "abstract": "The large-scale code in software supports the rich and diverse functionalities, and at the same time contains potential vulnerabilities. Fuzzing, as one of the most popular vulnerability detection methods, continues evolving in both industry and academy, aiming to find more vulnerabilities by covering more code. However, we find that even with the state-of-the-art fuzzers, there is still some unexplored code that can only be triggered using a specific combination of program options. Simply mutating the options may generate many invalid combinations due to the lack of consideration of constraints (or called relationships ) among options. In this paper, we leverage natural language processing (NLP) to automatically extract option descriptions from program documents and analyze the relationship (e.g., conflicts, dependencies) among the options before filtering out invalid combinations and only leaving the valid ones for fuzzing. We implemented a tool called CarpetFuzz and evaluated its performance. The results show that CarpetFuzz accurately extracts the relationships from documents with 96.10% precision and 88.85% recall. Based on these relationships, CarpetFuzz reduced the 67.91% option combinations to be tested. It helps AFL find 45.97% more paths that other fuzzers cannot discover. After analyzing 20 popular open-source programs, CarpetFuzz discovered 57 vulnerabilities, including 43 undisclosed ones. We also successfully obtained CVE IDs for 30 vulnerabilities.",
            "keywords": [
                "Fuzzing",
                "Vulnerability Detection",
                "Option Constraints",
                "Natural Language Processing",
                "Program Options Relationships"
            ]
        },
        "url": "URL#915497",
        "sema_paperId": "4f606d07a01ea23f27a7de73bd672072520450ed"
    },
    {
        "@score": "1",
        "@id": "915498",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "76/2435",
                        "text": "Chenghong Wang"
                    },
                    {
                        "@pid": "241/9560",
                        "text": "David Pujol"
                    },
                    {
                        "@pid": "143/4459",
                        "text": "Kartik Nayak"
                    },
                    {
                        "@pid": "m/AMachanavajjhala",
                        "text": "Ashwin Machanavajjhala"
                    }
                ]
            },
            "title": "Private Proof-of-Stake Blockchains using Differentially-Private Stake Distortion.",
            "venue": "USENIX Security Symposium",
            "pages": "1577-1594",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WangPNM23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/wang-chenghong",
            "url": "https://dblp.org/rec/conf/uss/WangPNM23",
            "abstract": "Safety, liveness, and privacy are three critical properties for any private proof-of-stake (PoS) blockchain. However, prior work (SP'21) has shown that to obtain safety and liveness, a PoS blockchain must in theory forgo privacy. In particular, to obtain safety and liveness, PoS blockchains elect parties proportional to their stake, which, in turn, can potentially reveal the stake of a party even if the transaction processing mechanism is private.\nIn this work, we make two key contributions. First, we present the first stake inference attack that can be actually run in practice. Specifically, our attack applies to both deterministic and randomized PoS protocols and has exponentially lesser running time in comparison with the SOTA approach. Second, we use differentially private stake distortion to achieve privacy in PoS blockchains. We formulate certain privacy requirements to achieve transaction and stake privacy, and design two stake distortion mechanisms that any PoS protocol can use. Moreover, we analyze our proposed mechanisms with Ethereum 2.0, a well-known PoS blockchain that is already operating in practice. The results indicate that our mechanisms mitigate stake inference risks and, at the same time, provide reasonable privacy while preserving required safety and liveness properties.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-wang-chenghong.pdf",
            "keywords": [
                "Private Proof-of-Stake",
                "Differential Privacy",
                "Stake Inference Attack",
                "Stake Distortion Mechanisms",
                "Ethereum 2.0"
            ]
        },
        "url": "URL#915498"
    },
    {
        "@score": "1",
        "@id": "915499",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "60/8494",
                        "text": "Xueqiang Wang"
                    },
                    {
                        "@pid": "139/7955",
                        "text": "Yuqiong Sun"
                    },
                    {
                        "@pid": "07/1026",
                        "text": "Susanta Nanda"
                    },
                    {
                        "@pid": "06/6268",
                        "text": "XiaoFeng Wang 0001"
                    }
                ]
            },
            "title": "Credit Karma: Understanding Security Implications of Exposed Cloud Services through Automated Capability Inference.",
            "venue": "USENIX Security Symposium",
            "pages": "6007-6024",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WangSN023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/wang-xueqiang-karma",
            "url": "https://dblp.org/rec/conf/uss/WangSN023",
            "abstract": "The increasing popularity of mobile applications (apps) has led to a rapid increase in demand for backend services, such as notifications, data storage, authentication, etc., hosted in cloud platforms. This has induced the attackers to consistently target such cloud services,resulting in a rise in data security incidents. In this paper, we focus on one of the main reasons why cloud services become increasingly vulnerable: (over-)privileges in cloud credentials. We propose a systematic approach to recover cloud credentials from apps, infer their capabilities in cloud, and verify if the capabilities exceed the legitimate needs of the apps. We further look into the security implications of the leaked capabilities, demonstrating how seemingly benev-olent, unprivileged capabilities, when combined, can lead to unexpected, severe security problems. A large-scale study of \u223c 1.3 million apps overtwo types ofcloudservices,notification and storage, on three popular cloud platforms, AWS, Azure, and Alibaba Cloud, shows that \u223c 27.3% of apps that use cloud services expose over-privileged cloud credentials. Moreover, a majority of over-privileged cloud credentials ( \u223c 64.8%) potentially lead to data attacks. During the study, we also uncover new types of attacks enabled by regular cloud credentials, such as spear-phishing through push notification and targeted user data pollution. We have made responsible disclosures to both app vendors and cloud providers and start seeing the impact\u2014over 300 app vendors already fixed the problems.",
            "keywords": [
                "Cloud Security",
                "Mobile Applications",
                "Over-privileged Credentials",
                "Data Security Incidents",
                "Automated Capability Inference"
            ]
        },
        "url": "URL#915499",
        "sema_paperId": "be0a20f3ea58a47500918d3c0c36790b57fe2238"
    },
    {
        "@score": "1",
        "@id": "915500",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "233/4780",
                        "text": "Junzhe Wang"
                    },
                    {
                        "@pid": "50/7822",
                        "text": "Matthew Sharp"
                    },
                    {
                        "@pid": "322/6647",
                        "text": "Chuxiong Wu"
                    },
                    {
                        "@pid": "81/583-1",
                        "text": "Qiang Zeng 0001"
                    },
                    {
                        "@pid": "153/5297",
                        "text": "Lannan Luo"
                    }
                ]
            },
            "title": "Can a Deep Learning Model for One Architecture Be Used for Others? Retargeted-Architecture Binary Code Analysis.",
            "venue": "USENIX Security Symposium",
            "pages": "7339-7356",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WangSW0L23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/wang-junzhe",
            "url": "https://dblp.org/rec/conf/uss/WangSW0L23",
            "abstract": "NLP-inspired deep learning for binary code analysis demonstrates notable performance. Considering the diverse Instruction Set Architectures (ISAs) on the market, it is important to be able to analyze code of various ISAs. However, training a deep learning model usually requires a large amount of data, which poses a challenge for certain ISAs such as PowerPC that suffer from the \u201c data scarcity \u201d issue. For instance, acquiring a large dataset of PowerPC malware proves to be challenging. Moreover, given a binary analysis task and multiple ISAs, it takes much time and effort (e.g., for data collection, labeling and cleaning, and parameter tuning) to train one model per ISA. We propose a new direction, retargeted-architecture binary code analysis , to handle the data scarcity issue and alleviate the per-ISA effort. Our idea is to transfer knowledge from one ISA to others \u2014that is, a model, trained with rich data and much time and effort for one ISA, can perform prediction for others without any modi-\ufb01cation . We showcase the idea through two important tasks: malware detection and function similarity detection. An extensive evaluation involving four ISAs (x86, ARM, MIPS, and PowerPC) demonstrates the effectiveness of the approach and the high performance is interpreted.",
            "keywords": [
                "Binary Code Analysis",
                "Instruction Set Architectures",
                "Data Scarcity",
                "Malware Detection",
                "Function Similarity Detection"
            ]
        },
        "url": "URL#915500",
        "sema_paperId": "a92149d57ba21e8181a3f2d97d15342823daea4b"
    },
    {
        "@score": "1",
        "@id": "915501",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "05/10698",
                        "text": "Zixuan Wang"
                    },
                    {
                        "@pid": "174/8281",
                        "text": "Mohammadkazem Taram"
                    },
                    {
                        "@pid": "241/6242",
                        "text": "Daniel Moghimi"
                    },
                    {
                        "@pid": "97/3886",
                        "text": "Steven Swanson"
                    },
                    {
                        "@pid": "t/DeanMTullsen",
                        "text": "Dean M. Tullsen"
                    },
                    {
                        "@pid": "66/8314",
                        "text": "Jishen Zhao"
                    }
                ]
            },
            "title": "NVLeak: Off-Chip Side-Channel Attacks via Non-Volatile Memory Systems.",
            "venue": "USENIX Security Symposium",
            "pages": "6771-6788",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WangTMSTZ23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/wang-zixuan",
            "url": "https://dblp.org/rec/conf/uss/WangTMSTZ23",
            "abstract": "We study microarchitectural side-channel attacks and defenses on non-volatile RAM (NVRAM) DIMMs. In this study, we \ufb01rst perform reverse-engineering of NVRAMs as implemented by the Intel Optane DIMM and reveal several of its previously undocumented microarchitectural details: on-DIMM cache structures (NVCache) and wear-leveling policies. Based on these \ufb01ndings, we \ufb01rst develop cross-core and cross-VM covert channels to establish the channel capacity of these shared hardware resources. Then, we devise NVCache-based side channels under the umbrella of NVLeak. We apply NVLeak to a series of attack case studies, including compromising the privacy of databases and key-value storage backed by NVRAM and spying on the execution path of code pages when NVRAM is used as a volatile runtime memory. Our results show that side-channel attacks exploiting NVRAM are practical and defeat previously-proposed defense that only focuses on on-chip hardware resources. To \ufb01ll this gap in defense, we develop system-level mitigations based on cache partitioning to prevent side-channel leakage from NVCache.",
            "keywords": [
                "Non-Volatile Memory",
                "Side-Channel Attacks",
                "Microarchitectural Vulnerabilities",
                "Cache Partitioning",
                "NVLeak"
            ]
        },
        "url": "URL#915501",
        "sema_paperId": "17c840424e27ab47311c373d6d63ca7d1502ba68"
    },
    {
        "@score": "1",
        "@id": "915502",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "18/689",
                        "text": "Weijie Wang"
                    },
                    {
                        "@pid": "329/4574",
                        "text": "Annie Ulichney"
                    },
                    {
                        "@pid": "p/CharalamposPapamanthou",
                        "text": "Charalampos Papamanthou"
                    }
                ]
            },
            "title": "BalanceProofs: Maintainable Vector Commitments with Fast Aggregation.",
            "venue": "USENIX Security Symposium",
            "pages": "4409-4426",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WangUP23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/wang-weijie",
            "url": "https://dblp.org/rec/conf/uss/WangUP23",
            "abstract": "We present BalanceProofs, the first vector commitment that is maintainable (i.e., supporting sublinear updates) while also enjoying fast proof aggregation and verification. The basic version of BalanceProofs has O(\u221anlogn) update time and O(\u221an) query time and its constant-size aggregated proofs can be produced and verified in milliseconds. In particular, BalanceProofs improves the aggregation time and aggregation verification time of the only known maintainable and aggregatable vector commitment scheme, Hyperproofs (USENIX SECURITY 2022), by up to 1000\u00d7 and up to 100\u00d7 respectively. Fast verification of aggregated proofs is particularly useful for applications such as stateless cryptocurrencies (and was a major bottleneck for Hyperproofs), where an aggregated proof of balances is produced once but must be verified multiple times and by a large number of nodes. As a limitation, the updating time in BalanceProofs compared to Hyperproofs is roughly 6\u00d7 slower, but always stays in the range from 10 to 18 milliseconds. We finally study useful tradeoffs in BalanceProofs between (aggregate) proof size, update time and (aggregate) proof computation and verification, by introducing a bucketing technique, and present an extensive evaluation as well as a comparison to Hyperproofs.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-wang-weijie.pdf",
            "keywords": [
                "Vector Commitment",
                "Maintainable Data Structures",
                "Proof Aggregation",
                "Cryptocurrency Verification",
                "Update Efficiency"
            ]
        },
        "url": "URL#915502"
    },
    {
        "@score": "1",
        "@id": "915503",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "03/2885",
                        "text": "Jinwen Wang"
                    },
                    {
                        "@pid": "00/8454",
                        "text": "Yujie Wang"
                    },
                    {
                        "@pid": "54/2788-6",
                        "text": "Ao Li 0006"
                    },
                    {
                        "@pid": "181/1848-10",
                        "text": "Yang Xiao 0010"
                    },
                    {
                        "@pid": "183/6821",
                        "text": "Ruide Zhang"
                    },
                    {
                        "@pid": "73/3673",
                        "text": "Wenjing Lou"
                    },
                    {
                        "@pid": "h/YTHou",
                        "text": "Y. Thomas Hou 0001"
                    },
                    {
                        "@pid": "181/2597-17",
                        "text": "Ning Zhang 0017"
                    }
                ]
            },
            "title": "ARI: Attestation of Real-time Mission Execution Integrity.",
            "venue": "USENIX Security Symposium",
            "pages": "2761-2778",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WangW00ZL0023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/wang-jinwen",
            "url": "https://dblp.org/rec/conf/uss/WangW00ZL0023",
            "abstract": "With the proliferation of autonomous safety-critical cyber-physical systems (CPS) in our daily life, their security is becoming ever more important. Remote attestation is a powerful mechanism to enable remote veri\ufb01cation of system integrity. While recent developments have made it possible to ef\ufb01ciently attest IoT operations, autonomous systems that are built on top of real-time cyber-physical control loops and execute missions independently present new unique challenges. In this paper, we formulate a new security property, Real-time Mission Execution Integrity (RMEI) to provide proof of correct and timely execution of the missions. While it is an attractive property, measuring it can incur prohibitive overhead for the real-time autonomous system. To tackle this challenge, we propose policy-based attestation of compartments to enable a trade-off between the level of details in measurement and runtime overhead. To further minimize the impact on real-time responsiveness, multiple techniques were developed to improve the performance, including customized software instrumentation and timing recovery through re-execution. We implemented a prototype of ARI and evaluated its performance on \ufb01ve CPS platforms. A user study involving 21 developers with different skill sets was conducted to understand the usability of our solution.",
            "keywords": [
                "Cyber-Physical Systems",
                "Remote Attestation",
                "Real-time Mission Execution Integrity",
                "Policy-based Attestation",
                "Runtime Overhead"
            ]
        },
        "url": "URL#915503",
        "sema_paperId": "466064ca3f979c988f22a0e06da1e85b7c5bfe92"
    },
    {
        "@score": "1",
        "@id": "915504",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "188/7759",
                        "text": "Chao Wang"
                    },
                    {
                        "@pid": "47/722-25",
                        "text": "Yue Zhang 0025"
                    },
                    {
                        "@pid": "49/4102-1",
                        "text": "Zhiqiang Lin 0001"
                    }
                ]
            },
            "title": "One Size Does Not Fit All: Uncovering and Exploiting Cross Platform Discrepant APIs in WeChat.",
            "venue": "USENIX Security Symposium",
            "pages": "6629-6646",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WangZL23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/wang-chao",
            "url": "https://dblp.org/rec/conf/uss/WangZL23",
            "abstract": "The past few years have witnessed a boom of mobile super apps, which are the apps offering multiple services such as e-commerce, e-learning, and e-government via miniapps executed inside. While originally designed for mobile platforms, super apps such as WeChat have also been made available on desktop platforms such as Windows. However, when running on desktop platforms, WeChat experiences differences in some behaviors, which presents opportunities for attacks (e.g., platform fingerprinting attacks). This paper thus aims to systematically identify the potential discrepancies in the APIs of WeChat across platforms and demonstrate how these differences can be exploited by remote attackers or local malicious miniapps. To this end, we present APIDIFF, an automatic tool that generates test cases for each API and identifies execution discrepancies. With APIDIFF, we have identified three sets of discrepant APIs that exhibit existence (109), permission (17), and output (22) discrepancies across platforms and devices, and provided concrete examples of their exploitation. We have responsibly disclosed these vulnerabilities to Tencent and received bug bounties for our findings. These vulnerabilities were ranked as high-severity and some have already been patched.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-wang-chao.pdf",
            "keywords": [
                "Mobile Super Apps",
                "Cross-Platform APIs",
                "WeChat Discrepancies",
                "API Exploitation",
                "Platform Fingerprinting Attacks"
            ]
        },
        "url": "URL#915504"
    },
    {
        "@score": "1",
        "@id": "915505",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "223/6095",
                        "text": "Jialai Wang"
                    },
                    {
                        "@pid": "131/3921",
                        "text": "Ziyuan Zhang"
                    },
                    {
                        "@pid": "225/1521",
                        "text": "Meiqi Wang"
                    },
                    {
                        "@pid": "15/4507-1",
                        "text": "Han Qiu 0001"
                    },
                    {
                        "@pid": "77/7902-4",
                        "text": "Tianwei Zhang 0004"
                    },
                    {
                        "@pid": "181/2688-2",
                        "text": "Qi Li 0002"
                    },
                    {
                        "@pid": "24/1320",
                        "text": "Zongpeng Li"
                    },
                    {
                        "@pid": "64/5099",
                        "text": "Tao Wei"
                    },
                    {
                        "@pid": "94/3019-8",
                        "text": "Chao Zhang 0008"
                    }
                ]
            },
            "title": "Aegis: Mitigating Targeted Bit-flip Attacks against Deep Neural Networks.",
            "venue": "USENIX Security Symposium",
            "pages": "2329-2346",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WangZW000LW023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/wang-jialai",
            "url": "https://dblp.org/rec/conf/uss/WangZW000LW023",
            "abstract": "Bit-flip attacks (BFAs) have attracted substantial attention recently, in which an adversary could tamper with a small number of model parameter bits to break the integrity of DNNs. To mitigate such threats, a batch of defense methods are proposed, focusing on the untargeted scenarios. Unfortunately, they either require extra trustworthy applications or make models more vulnerable to targeted BFAs. Countermeasures against targeted BFAs, stealthier and more purposeful by nature, are far from well established. In this work, we propose Aegis, a novel defense method to mitigate targeted BFAs. The core observation is that existing targeted attacks focus on flipping critical bits in certain important layers. Thus, we design a dynamic-exit mechanism to attach extra internal classifiers (ICs) to hidden layers. This mechanism enables input samples to early-exit from different layers, which effectively upsets the adversary's attack plans. Moreover, the dynamic-exit mechanism randomly selects ICs for predictions during each inference to significantly increase the attack cost for the adaptive attacks where all defense mechanisms are transparent to the adversary. We further propose a robustness training strategy to adapt ICs to the attack scenarios by simulating BFAs during the IC training phase, to increase model robustness. Extensive evaluations over four well-known datasets and two popular DNN structures reveal that Aegis could effectively mitigate different state-of-the-art targeted attacks, reducing attack success rate by 5-10$\\times$, significantly outperforming existing defense methods.",
            "keywords": [
                "Bit-flip Attacks",
                "Dynamic-exit Mechanism",
                "Internal Classifiers",
                "Targeted Attacks",
                "Model Robustness"
            ]
        },
        "url": "URL#915505",
        "sema_paperId": "e2040cda6b1a2f4d136d5d7e0e89b71c9b4b48b9"
    },
    {
        "@score": "1",
        "@id": "915506",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "60/6198",
                        "text": "Feng Wei"
                    },
                    {
                        "@pid": "49/6722-2",
                        "text": "Hongda Li 0002"
                    },
                    {
                        "@pid": "11/7704-1",
                        "text": "Ziming Zhao 0001"
                    },
                    {
                        "@pid": "02/2870",
                        "text": "Hongxin Hu"
                    }
                ]
            },
            "title": "xNIDS: Explaining Deep Learning-based Network Intrusion Detection Systems for Active Intrusion Responses.",
            "venue": "USENIX Security Symposium",
            "pages": "4337-4354",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Wei00H23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/wei-feng",
            "url": "https://dblp.org/rec/conf/uss/Wei00H23",
            "abstract": "While Deep Learning-based Network Intrusion Detection Systems (DL-NIDS) have recently been significantly explored and shown superior performance, they are insufficient to actively respond to the detected intrusions due to the semantic gap between their detection results and actionable interpretations. Furthermore, their high error costs make network operators unwilling to respond solely based on their detection results. The root cause of these drawbacks can be traced to the lack of explainability of DL-NIDS. Although some methods have been developed to explain deep learning-based systems, they are incapable of handling the history inputs and complex feature dependencies of structured data and do not perform well in explaining DL-NIDS. In this paper, we present X NIDS, a novel framework that facilitates active intrusion responses by explaining DL-NIDS. Our explanation method is highlighted by: (1) approximating and sampling around history inputs; and (2) capturing feature dependencies of structured data to achieve a high-fidelity explanation. Based on the explanation results, X NIDS can further generate actionable defense rules. We evaluate X NIDS with four state-of-the-art DL-NIDS. Our evaluation results show that X NIDS outperforms previous explanation methods in terms of fidelity, sparsity, completeness, and stability, all of which are important to active intrusion responses. Moreover, we demonstrate that X NIDS can efficiently generate practical defense rules, help understand DL-NIDS behaviors, and troubleshoot detection errors.",
            "keywords": [
                "Network Intrusion Detection",
                "Active Intrusion Response",
                "Explainability",
                "Deep Learning Interpretability",
                "Defense Rule Generation"
            ]
        },
        "url": "URL#915506",
        "sema_paperId": "75f06aa49259162df5e839c703b8d8039eab05e7"
    },
    {
        "@score": "1",
        "@id": "915507",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "353/7546",
                        "text": "Cheng&apos;an Wei"
                    },
                    {
                        "@pid": "153/5787",
                        "text": "Yeonjoon Lee"
                    },
                    {
                        "@pid": "c/KaiChen12",
                        "text": "Kai Chen 0012"
                    },
                    {
                        "@pid": "134/8681",
                        "text": "Guozhu Meng"
                    },
                    {
                        "@pid": "289/1355",
                        "text": "Peizhuo Lv"
                    }
                ]
            },
            "title": "Aliasing Backdoor Attacks on Pre-trained Models.",
            "venue": "USENIX Security Symposium",
            "pages": "2707-2724",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WeiL0ML23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/wei-chengan",
            "url": "https://dblp.org/rec/conf/uss/WeiL0ML23",
            "abstract": "Pre-trained deep learning models are widely used to train accurate models with limited data in a short time. To reduce computational costs, pre-trained neural networks often employ subsampling operations. However, recent studies have shown that these subsampling operations can cause aliasing issues, resulting in problems with generalization. Despite this knowledge, there is still a lack of research on the relationship between the aliasing of neural networks and security threats, such as adversarial attacks and backdoor attacks, which manipulate model predictions without the awareness of victims. In this paper, we propose the aliasing backdoor, a low-cost and data-free attack that threatens mainstream pre-trained models and transfers to all student models fine-tuned from them. The key idea is to create an aliasing error in the strided layers of the network and manipulate a benign input to a targeted intermediate representation. To evaluate the attack, we conduct experiments on image classification, face recognition, and speech recognition tasks. The results show that our approach can effectively attack mainstream models with a success rate of over 95%. Our research, based on the aliasing error caused by subsampling, reveals a fundamental security weakness of strided layers, which are widely used in modern neural network architectures. To the best of our knowledge, this is the first work to exploit the strided layers to launch backdoor attacks.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-wei-chengan.pdf",
            "keywords": [
                "Aliasing Backdoor Attacks",
                "Pre-trained Models",
                "Strided Layers",
                "Adversarial Manipulation",
                "Generalization Issues"
            ]
        },
        "url": "URL#915507",
        "sema_paperId": "9cd28509ee6ce50743642dca74a8595a68e6b24b"
    },
    {
        "@score": "1",
        "@id": "915508",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "215/0123",
                        "text": "Haohuang Wen"
                    },
                    {
                        "@pid": "49/4102-1",
                        "text": "Zhiqiang Lin 0001"
                    }
                ]
            },
            "title": "Egg Hunt in Tesla Infotainment: A First Look at Reverse Engineering of Qt Binaries.",
            "venue": "USENIX Security Symposium",
            "pages": "3997-4014",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WenL23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/wen",
            "url": "https://dblp.org/rec/conf/uss/WenL23",
            "abstract": "As one of the most popular C++ extensions for developing graphical user interface (GUI) based applications, Qt has been widely used in desktops, mobiles, IoTs, automobiles, etc . Although existing binary analysis platforms ( e.g. , angr and Ghidra ) could help reverse engineer Qt binaries, they still need to address many fundamental challenges such as the recovery of control flow graphs and symbols. In this paper, we take a first look at understanding the unique challenges and opportunities in Qt binary analysis, developing enabling techniques, and demonstrating novel applications. In particular, although callbacks make control flow recovery challenging, we notice that Qt\u2019s signal and slot mechanism can be used to recover function callbacks. More interestingly, Qt\u2019s unique dynamic introspection can also be repurposed to recover semantic symbols. Based on these insights, we develop Q T RE for function callback and semantic symbol recovery for Qt binaries. We have tested Q T RE with two suites of Qt binaries: Linux KDE and the Tesla Model S firmware, where Q T RE additionally recovered 10 , 867 callback instances and 24 , 973 semantic symbols from 123 binaries, which cannot be identified by existing tools. We demonstrate a novel application of using Q T RE to extract hidden commands from a Tesla Model S firmware. Q T RE discovered 12 hidden commands including five unknown to the public, which can potentially be exploited to manipulate vehicle settings.",
            "keywords": [
                "Qt Binary Analysis",
                "Reverse Engineering",
                "Control Flow Recovery",
                "Function Callbacks",
                "Tesla Infotainment"
            ]
        },
        "url": "URL#915508",
        "sema_paperId": "5448dad6a61b04f37dbfbd7f5522b4b192d79a86"
    },
    {
        "@score": "1",
        "@id": "915509",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "225/5356",
                        "text": "Jan Wichelmann"
                    },
                    {
                        "@pid": "327/9148",
                        "text": "Anna P\u00e4tschke"
                    },
                    {
                        "@pid": "263/7337",
                        "text": "Luca Wilke"
                    },
                    {
                        "@pid": "72/817",
                        "text": "Thomas Eisenbarth 0001"
                    }
                ]
            },
            "title": "Cipherfix: Mitigating Ciphertext Side-Channel Attacks in Software.",
            "venue": "USENIX Security Symposium",
            "pages": "6789-6806",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WichelmannPW023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/wichelmann",
            "url": "https://dblp.org/rec/conf/uss/WichelmannPW023",
            "abstract": "Trusted execution environments (TEEs) provide an environment for running workloads in the cloud without having to trust cloud service providers, by offering additional hardware-assisted security guarantees. However, main memory encryption as a key mechanism to protect against system-level attackers trying to read the TEE's content and physical, off-chip attackers, is insufficient. The recent Cipherleaks attacks infer secret data from TEE-protected implementations by analyzing ciphertext patterns exhibited due to deterministic memory encryption. The underlying vulnerability, dubbed the ciphertext side-channel, is neither protected by state-of-the-art countermeasures like constant-time code nor by hardware fixes. Thus, in this paper, we present a software-based, drop-in solution that can harden existing binaries such that they can be safely executed under TEEs vulnerable to ciphertext side-channels, without requiring recompilation. We combine taint tracking with both static and dynamic binary instrumentation to find sensitive memory locations, and mitigate the leakage by masking secret data before it gets written to memory. This way, although the memory encryption remains deterministic, we destroy any secret-dependent patterns in encrypted memory. We show that our proof-of-concept implementation protects various constant-time implementations against ciphertext side-channels with reasonable overhead.",
            "keywords": [
                "Trusted Execution Environments",
                "Ciphertext Side-Channel",
                "Memory Encryption",
                "Data Leakage Mitigation",
                "Taint Tracking"
            ]
        },
        "url": "URL#915509",
        "sema_paperId": "65f58616ad6391920b061f285c8dc41c13273801"
    },
    {
        "@score": "1",
        "@id": "915510",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "201/9210",
                        "text": "Seunghoon Woo"
                    },
                    {
                        "@pid": "196/5004",
                        "text": "Eunjin Choi"
                    },
                    {
                        "@pid": "75/4485",
                        "text": "Heejo Lee"
                    },
                    {
                        "@pid": "13/7537",
                        "text": "Hakjoo Oh"
                    }
                ]
            },
            "title": "V1SCAN: Discovering 1-day Vulnerabilities in Reused C/C++ Open-source Software Components Using Code Classification Techniques.",
            "venue": "USENIX Security Symposium",
            "pages": "6541-6556",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WooCLO23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/woo",
            "url": "https://dblp.org/rec/conf/uss/WooCLO23",
            "abstract": "We present V1 SCAN , an effective approach for discovering 1-day vulnerabilities in reused C/C++ open-source software (OSS) components. Reusing third-party OSS has many benefits, but can put the entire software at risk owing to the vulnerabilities they propagate. In mitigation, several techniques for detecting propagated vulnerabilities, which can be classified into version-and code-based approaches, have been proposed. However, state-of-the-art techniques unfortunately produce many false positives or negatives when OSS projects are reused with code modifications. In this paper, we show that these limitations can be addressed by improving version-and code-based approaches and synergistically combining them. By classifying reused code from OSS components, V1 SCAN only considers vulnerabilities contained in the target program and filters out unused vulnerable code, thereby reducing false alarms produced by version-based approaches. V1 SCAN improves the coverage of code-based approaches by classifying vulnerable code and then detecting vulnerabilities propagated with code changes in various code locations. Evaluation on GitHub popular C/C++ software showed that V1 SCAN outperformed state-of-the-art vulnerability detection approaches by discovering 50% more vulnerabilities than they detected. In addition, V1 SCAN reduced the false positive rate of the simple integration of existing version-and code-based approaches from 71% to 4% and the false negative rate from 33% to 7%. With V1 SCAN , developers can detect propagated vulnerabilities with high accuracy, maintaining a secure software supply chain.",
            "keywords": [
                "Open-source Software Security",
                "Vulnerability Detection",
                "C/C++ Code Analysis",
                "False Positives Reduction",
                "1-day Vulnerabilities"
            ]
        },
        "url": "URL#915510",
        "sema_paperId": "096d76afc25f32f4dd94faa7a276d645de7d2c64"
    },
    {
        "@score": "1",
        "@id": "915511",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "228/4088",
                        "text": "Daniel W. Woods"
                    },
                    {
                        "@pid": "52/6295",
                        "text": "Rainer B\u00f6hme"
                    },
                    {
                        "@pid": "37/9875",
                        "text": "Josephine Wolff"
                    },
                    {
                        "@pid": "353/7684",
                        "text": "Daniel Schwarcz"
                    }
                ]
            },
            "title": "Lessons Lost: Incident Response in the Age of Cyber Insurance and Breach Attorneys.",
            "venue": "USENIX Security Symposium",
            "pages": "2259-2273",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WoodsBWS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/woods",
            "url": "https://dblp.org/rec/conf/uss/WoodsBWS23",
            "abstract": "Incident Response (IR) allows victim \ufb01rms to detect, contain, and recover from security incidents. It should also help the wider community avoid similar attacks in the future. In pursuit of these goals, technical practitioners are increasingly in\ufb02uenced by stakeholders like cyber insurers and lawyers. This paper explores these impacts via a multi-stage, mixed methods research design that involved 69 expert interviews, data on commercial relationships, and an online validation workshop. The \ufb01rst stage of our study established 11 stylized facts that describe how cyber insurance sends work to a small numbers of IR \ufb01rms, drives down the fee paid, and appoints lawyers to direct technical investigators. The second stage showed that lawyers when directing incident response often: introduce legalistic contractual and communication steps that slow-down incident response; advise IR practitioners not to write down remediation steps or to produce formal reports; and restrict access to any documents produced.",
            "keywords": [
                "Incident Response",
                "Cyber Insurance",
                "Legal Influence",
                "Breach Attorneys",
                "Incident Management Challenges"
            ]
        },
        "url": "URL#915511",
        "sema_paperId": "2c93540b5080cfbac6bc8231281b7f56f9b2d283"
    },
    {
        "@score": "1",
        "@id": "915512",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "141/2030",
                        "text": "Yafei Wu"
                    },
                    {
                        "@pid": "45/5103-1",
                        "text": "Cong Sun 0001"
                    },
                    {
                        "@pid": "216/4152",
                        "text": "Dongrui Zeng"
                    },
                    {
                        "@pid": "91/6206",
                        "text": "Gang Tan"
                    },
                    {
                        "@pid": "130/5642",
                        "text": "Siqi Ma"
                    },
                    {
                        "@pid": "147/7771",
                        "text": "Peicheng Wang"
                    }
                ]
            },
            "title": "LibScan: Towards More Precise Third-Party Library Identification for Android Applications.",
            "venue": "USENIX Security Symposium",
            "pages": "3385-3402",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Wu0ZTMW23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/wu-yafei",
            "url": "https://dblp.org/rec/conf/uss/Wu0ZTMW23",
            "abstract": "Android apps pervasively use third-party libraries (TPL) to reuse functionalities and improve development efficiency. The insufficient knowledge of the TPL internal exposes the developers and users to severe threats of security vulnerabilities. To mitigate such threats, people have proposed diversified approaches to identifying vulnerable or even malicious TPLs. However, the rich features of different modern obfuscators, including advanced repackaging, dead code removal, and control-flow randomization, have significantly impeded the precise detection of the TPLs. In this work, we propose a general-purpose TPL detection approach, LibScan. We first fingerprint code features to build the potential class correspondence relations between the app and TPL classes. Then, we use the method-opcode similarity and call-chain-opcode similarity to improve the accuracy of detected class correspondences. Moreover, we design early-stop criteria and reuse intermediate results to improve the efficiency of LibScan. In experiments, the evaluation with ground truths demonstrated the effectiveness of LibScan and its detection steps. We also applied LibScan to detect vulnerable TPLs in the top Google Play apps and large-scale wild apps, which shows the efficiency and scalability of our approach, as well as the potential of our approach as an auxiliary tool that helps malware detection.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-wu-yafei.pdf",
            "keywords": [
                "Third-Party Library Identification",
                "Android Applications",
                "Vulnerable Libraries",
                "Obfuscation Techniques",
                "Malware Detection"
            ]
        },
        "url": "URL#915512",
        "sema_paperId": "ca168c779cac3019fedf9766ab325331ea4ef8d3"
    },
    {
        "@score": "1",
        "@id": "915513",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "350/4832",
                        "text": "Ka Lok Wu"
                    },
                    {
                        "@pid": "306/0915",
                        "text": "Man Hong Hue"
                    },
                    {
                        "@pid": "353/7627",
                        "text": "Ngai Man Poon"
                    },
                    {
                        "@pid": "306/0778",
                        "text": "Kin Man Leung"
                    },
                    {
                        "@pid": "353/7651",
                        "text": "Wai Yin Po"
                    },
                    {
                        "@pid": "353/7551",
                        "text": "Kin Ting Wong"
                    },
                    {
                        "@pid": "353/7539",
                        "text": "Sze Ho Hui"
                    },
                    {
                        "@pid": "201/9242",
                        "text": "Sze Yiu Chau"
                    }
                ]
            },
            "title": "Back to School: On the (In)Security of Academic VPNs.",
            "venue": "USENIX Security Symposium",
            "pages": "5737-5754",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WuHPLPWHC23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/wu-ka-lok",
            "url": "https://dblp.org/rec/conf/uss/WuHPLPWHC23",
            "abstract": "In this paper, we investigate the security of academic VPNs around the globe, covering various protocols that are used to realize VPN services. Our study considers 3 aspects that can go wrong in a VPN setup, which include (i) the design and implementation of VPN front-ends, (ii) the client-side configurations, and (iii) the back-end configurations. For (i), we tested more than 140 front-ends, and discovered numerous design and implementation issues that enable stealthy but severe attacks, including credential theft and remote code execution. For (ii), we collected and evaluated 2097 VPN setup guides from universities, and discovered many instances of secret key leakage and lack of consideration to potential attacks, leaving many client-side setups vulnerable. Finally, for (iii), we probed more than 2000 VPN back-ends to evaluate their overall health, and uncovered some concerning configuration and maintenance issues on many of them. Our findings suggest that severe cracks exist in the VPN setups of many organizations, making them profitable targets for criminals.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-wu-ka-lok.pdf",
            "keywords": [
                "VPN Security",
                "Academic Networks",
                "Configuration Vulnerabilities",
                "Credential Theft",
                "Remote Code Execution"
            ]
        },
        "url": "URL#915513",
        "sema_paperId": "6bbc3b9bd49ae1bb2f30bad36260a652551b290e"
    },
    {
        "@score": "1",
        "@id": "915514",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "41/7732-3",
                        "text": "Yuhang Wu 0003"
                    },
                    {
                        "@pid": "277/7909",
                        "text": "Zhenpeng Lin"
                    },
                    {
                        "@pid": "16/6884-1",
                        "text": "Yueqi Chen 0001"
                    },
                    {
                        "@pid": "353/7560",
                        "text": "Dang K. Le"
                    },
                    {
                        "@pid": "187/8991",
                        "text": "Dongliang Mu"
                    },
                    {
                        "@pid": "40/6431",
                        "text": "Xinyu Xing"
                    }
                ]
            },
            "title": "Mitigating Security Risks in Linux with KLAUS: A Method for Evaluating Patch Correctness.",
            "venue": "USENIX Security Symposium",
            "pages": "4247-4264",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WuLCLMX23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/wu-yuhang",
            "url": "https://dblp.org/rec/conf/uss/WuLCLMX23",
            "abstract": "This artifact is applying for an Artifacts Available badge, an Artifacts Functional badge, and an Results Reproduced badge. The artifact primarily consists of two parts: the source code of KLAUS, and the Docker runtime environment for KLAUS. These components encompass the specific implementation of the designs in our paper, and also offer a very user-friendly and convenient mode of operation. KLAUS is a framework for verifying the correctness of Linux kernel patches, mainly composed of a static analysis part (identifying AWRPs as proposed in our paper) and a dynamic fuzz testing part (Fuzzing). Firstly, our open-source source code includes the source code for static analysis, the source code for automatic instrumentation, and the source code for the fuzzer. These source codes have good extensibility and will be beneficial for other researchers to conduct more in-depth research improvements or extensions. Subsequently, we encapsulate the entire KLAUS framework in a Docker image, for the convenience of all researchers and users. In this Appendix, we will provide the necessary explanations and some screenshots to facilitate the evaluation of our academic achievements.",
            "keywords": [
                "Linux Kernel Security",
                "Patch Verification",
                "Static Analysis",
                "Dynamic Fuzz Testing",
                "Automated Instrumentation"
            ]
        },
        "url": "URL#915514",
        "sema_paperId": "3411778b805f7a9fb19fce5644950d65a96a6f0d"
    },
    {
        "@score": "1",
        "@id": "915515",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "277/1836",
                        "text": "Xinghui Wu"
                    },
                    {
                        "@pid": "172/8745",
                        "text": "Shiqing Ma"
                    },
                    {
                        "@pid": "48/4825-1",
                        "text": "Chao Shen 0001"
                    },
                    {
                        "@pid": "198/9470",
                        "text": "Chenhao Lin"
                    },
                    {
                        "@pid": "75/5723-2",
                        "text": "Qian Wang 0002"
                    },
                    {
                        "@pid": "181/2688-2",
                        "text": "Qi Li 0002"
                    },
                    {
                        "@pid": "73/4103",
                        "text": "Yuan Rao"
                    }
                ]
            },
            "title": "KENKU: Towards Efficient and Stealthy Black-box Adversarial Attacks against ASR Systems.",
            "venue": "USENIX Security Symposium",
            "pages": "247-264",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WuM0L00R23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/wu-xinghui",
            "url": "https://dblp.org/rec/conf/uss/WuM0L00R23",
            "abstract": "Prior researchers show that existing automatic speech recognition (ASR) systems are vulnerable to adversarial examples. Most existing adversarial attacks against ASR systems are either white-or gray-box, limiting their practical usage in the real world. Some black-box attacks also assume the knowledge of output probability vectors to infer output distribution. Other black-box attacks leverage inefficient heavyweight processes, i.e., training auxiliary models or estimating gradients. Moreover, they require input-specific and manual hyperpa-rameter tuning to improve the attack success rate against a specific ASR system. Despite such a heavyweight tuning process, nearly or even more than half of the generated adversarial examples are perceptible to humans. This paper designs K ENKU , an efficient and stealthy black-box adversarial attack framework against ASRs, supporting hidden voice command and integrated command attacks. It optimizes the novel acoustic feature loss and perturbation loss, based on Mel-frequency Cepstral Coefficients (MFCC). Both loss values can be calculated locally, avoiding training auxiliary models or estimating gradients, making the attack efficient. Furthermore, we introduce a hyperparameter in optimization that balances the attack effectiveness and imperceptibility automatically. K ENKU uses the binary search algorithm to find its optimal value. We evaluated our prototype on eight real-world systems (including five digital and three physical attacks) and compared K ENKU with five state-of-the-art works. Results show that K ENKU can outperform existing works in the attack performance.",
            "keywords": [
                "Adversarial Attacks",
                "Automatic Speech Recognition",
                "Black-box Attacks",
                "Acoustic Feature Loss",
                "Stealthy Attacks"
            ]
        },
        "url": "URL#915515",
        "sema_paperId": "a7aa21ec5ecf3a953054215a18f82dab5d69a36d"
    },
    {
        "@score": "1",
        "@id": "915516",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "353/7580",
                        "text": "Mingshi Wu"
                    },
                    {
                        "@pid": "327/9719",
                        "text": "Jackson Sippe"
                    },
                    {
                        "@pid": "353/7534",
                        "text": "Danesh Sivakumar"
                    },
                    {
                        "@pid": "353/7549",
                        "text": "Jack Burg"
                    },
                    {
                        "@pid": "88/3792",
                        "text": "Peter Anderson"
                    },
                    {
                        "@pid": "58/8838",
                        "text": "Xiaokang Wang"
                    },
                    {
                        "@pid": "186/5066",
                        "text": "Kevin Bock 0001"
                    },
                    {
                        "@pid": "22/1797",
                        "text": "Amir Houmansadr"
                    },
                    {
                        "@pid": "03/6428",
                        "text": "Dave Levin"
                    },
                    {
                        "@pid": "60/8733",
                        "text": "Eric Wustrow"
                    }
                ]
            },
            "title": "How the Great Firewall of China Detects and Blocks Fully Encrypted Traffic.",
            "venue": "USENIX Security Symposium",
            "pages": "2653-2670",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WuSSBAW0HLW23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/wu-mingshi",
            "url": "https://dblp.org/rec/conf/uss/WuSSBAW0HLW23",
            "abstract": "One of the cornerstones in censorship circumvention is fully encrypted protocols, which encrypt every byte of the payload in an attempt to \u201clook like nothing\u201d. In early November 2021, the Great Firewall of China (GFW) deployed a new censorship technique that passively detects\u2014and subsequently blocks\u2014 fully encrypted traf\ufb01c in real time. The GFW\u2019s new censorship capability affects a large set of popular censorship circum-vention protocols, including but not limited to Shadowsocks, VMess, and Obfs4. Although China had long actively probed such protocols, this was the \ufb01rst report of purely passive detection, leading the anti-censorship community to ask how detection was possible. In this paper, we measure and characterize the GFW\u2019s new system for censoring fully encrypted traf\ufb01c. We \ufb01nd that, instead of directly de\ufb01ning what fully encrypted traf\ufb01c is, the censor applies crude but ef\ufb01cient heuristics to exempt traf\ufb01c that is unlikely to be fully encrypted traf\ufb01c; it then blocks the remaining non-exempted traf\ufb01c. These heuristics are based on the \ufb01ngerprints of common protocols, the fraction of set bits, and the number, fraction, and position of printable ASCII characters. Our Internet scans reveal what traf\ufb01c and which IP addresses the GFW inspects. We simulate the inferred GFW\u2019s detection algorithm on live traf\ufb01c at a university network tap to evaluate its comprehensiveness and false positives. We show evidence that the rules we inferred have good coverage",
            "keywords": [
                "Great Firewall of China",
                "Censorship Circumvention",
                "Encrypted Traffic Detection",
                "Traffic Blocking Heuristics",
                "Protocol Fingerprinting"
            ]
        },
        "url": "URL#915516",
        "sema_paperId": "239f3c1b6297c035f096b1d59fb5951c5a2f74c9"
    },
    {
        "@score": "1",
        "@id": "915517",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "22/1911",
                        "text": "Mingli Wu"
                    },
                    {
                        "@pid": "10/6625",
                        "text": "Tsz Hon Yuen"
                    }
                ]
            },
            "title": "Efficient Unbalanced Private Set Intersection Cardinality and User-friendly Privacy-preserving Contact Tracing.",
            "venue": "USENIX Security Symposium",
            "pages": "283-300",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WuY23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/wu-mingli",
            "url": "https://dblp.org/rec/conf/uss/WuY23",
            "abstract": "An unbalanced private set intersection cardinality (PSI-CA) protocol is a protocol to securely get the intersection cardinality of two sets X and Y without disclosing anything else, in which |Y| < |X|. In this paper, we propose efficient unbalanced PSI-CA protocols based on fully homomorphic encryption (FHE). To handle the long item issue in PSI-CA protocols, we invent two techniques: virtual Bloom filter and polynomial links. The former can encode a long item into several independent shorter ones. The latter fragments each long item into shorter slices and builds links between them.\nOur FHE-based unbalanced PSI-CA protocols have the lowest communication complexity O(|Y|log(|X|), which is much cheaper than the existing balanced PSI-CA protocols with O(|Y|+|X|). When |X|=228 and |Y|=2048, our protocols are 172\u00d7 \u223c 412\u00d7 cheaper than the best balanced PSI-CA protocol. Our protocols can be easily modified into unbalanced PSI protocols. Compared with Cong et al. (CCS'21), one of our unbalanced PSI protocols can save 42.04% \u223c 58.85% communication costs and accelerate the receiver querying time.\nWe apply our lightweight unbalanced PSI-CA protocols to design a privacy-preserving contact tracing system. We demonstrate that our system outperforms existing schemes in terms of security and performance.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-wu-mingli.pdf",
            "keywords": [
                "Private Set Intersection",
                "Fully Homomorphic Encryption",
                "Unbalanced PSI-CA Protocols",
                "Contact Tracing",
                "Communication Complexity"
            ]
        },
        "url": "URL#915517",
        "sema_paperId": "7d5ee3e5ad55629ccbf16aa6824038e14043dd8b"
    },
    {
        "@score": "1",
        "@id": "915518",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "224/9296",
                        "text": "Zhaohan Xi"
                    },
                    {
                        "@pid": "128/2982",
                        "text": "Tianyu Du"
                    },
                    {
                        "@pid": "216/3218",
                        "text": "Changjiang Li"
                    },
                    {
                        "@pid": "252/5223",
                        "text": "Ren Pang"
                    },
                    {
                        "@pid": "07/8388",
                        "text": "Shouling Ji"
                    },
                    {
                        "@pid": "53/1565",
                        "text": "Xiapu Luo"
                    },
                    {
                        "@pid": "13/9656",
                        "text": "Xusheng Xiao"
                    },
                    {
                        "@pid": "85/10856",
                        "text": "Fenglong Ma"
                    },
                    {
                        "@pid": "12/2633-6",
                        "text": "Ting Wang 0006"
                    }
                ]
            },
            "title": "On the Security Risks of Knowledge Graph Reasoning.",
            "venue": "USENIX Security Symposium",
            "pages": "3259-3276",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/XiDLPJLXM023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/xi",
            "url": "https://dblp.org/rec/conf/uss/XiDLPJLXM023",
            "abstract": "Knowledge graph reasoning (KGR) \u2013 answering complex logical queries over large knowledge graphs \u2013 represents an important artificial intelligence task, entailing a range of applications (e.g., cyber threat hunting). However, despite its surging popularity, the potential security risks of KGR are largely unexplored, which is concerning, given the increasing use of such capability in security-critical domains.This work represents a solid initial step towards bridging the striking gap. We systematize the security threats to KGR according to the adversary's objectives, knowledge, and attack vectors. Further, we present ROAR, a new class of attacks that instantiate a variety of such threats. Through empirical evaluation in representative use cases (e.g., medical decision support, cyber threat hunting, and commonsense reasoning), we demonstrate that ROAR is highly effective to mislead KGR to suggest pre-defined answers for target queries, yet with negligible impact on non-target ones. Finally, we explore potential countermeasures against ROAR, including filtering of potentially poisoning knowledge and training with adversarially augmented queries, which leads to several promising research directions.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-xi.pdf",
            "keywords": [
                "Knowledge Graph Reasoning",
                "Security Risks",
                "Adversarial Attacks",
                "ROAR",
                "Countermeasures"
            ]
        },
        "url": "URL#915518"
    },
    {
        "@score": "1",
        "@id": "915519",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "88/5697",
                        "text": "Qi Xia"
                    },
                    {
                        "@pid": "11/1394",
                        "text": "Qian Chen"
                    },
                    {
                        "@pid": "78/2715",
                        "text": "Shouhuai Xu"
                    }
                ]
            },
            "title": "Near-Ultrasound Inaudible Trojan (Nuit): Exploiting Your Speaker to Attack Your Microphone.",
            "venue": "USENIX Security Symposium",
            "pages": "4589-4606",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/XiaCX23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/xia",
            "url": "https://dblp.org/rec/conf/uss/XiaCX23",
            "abstract": "Voice Control Systems (VCSs) offer a convenient interface for issuing voice commands to smart devices. However, VCS security has yet to be adequately understood and addressed as evidenced by the presence of two classes of attacks: (i) inaudi-ble attacks, which can be waged when the attacker and the victim are in proximity to each other; and (ii) audible attacks, which can be waged remotely by embedding attack signals into audios. In this paper, we introduce a new class of attacks, dubbed near-ultrasound inaudible trojan ( NUIT ). NUIT attacks achieve the best of the two classes of attacks mentioned above: they are inaudible and can be waged remotely . Moreover, NUIT attacks can achieve end-to-end unnoticeabil-ity , which is important but has not been paid due attention in the literature. Another feature of NUIT attacks is that they exploit victim speakers to attack victim microphones and their associated VCSs, meaning the attacker does not need to use any special speaker. We demonstrate the feasibility of NUIT attacks and propose an effective defense against them.",
            "keywords": [
                "Voice Control Systems",
                "Inaudible Attacks",
                "Near-Ultrasound Inaudible Trojan",
                "Remote Exploitation",
                "End-to-End Unnoticeability"
            ]
        },
        "url": "URL#915519",
        "sema_paperId": "cb3341b3e9dce40ede4084830ea59c05f70fda99"
    },
    {
        "@score": "1",
        "@id": "915520",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "80/6791-7",
                        "text": "Yue Xiao 0007"
                    },
                    {
                        "@pid": "85/9245",
                        "text": "Zhengyi Li"
                    },
                    {
                        "@pid": "142/1169",
                        "text": "Yue Qin"
                    },
                    {
                        "@pid": "20/10240",
                        "text": "Xiaolong Bai"
                    },
                    {
                        "@pid": "322/4156",
                        "text": "Jiale Guan"
                    },
                    {
                        "@pid": "129/1113",
                        "text": "Xiaojing Liao"
                    },
                    {
                        "@pid": "34/8412",
                        "text": "Luyi Xing"
                    }
                ]
            },
            "title": "Lalaine: Measuring and Characterizing Non-Compliance of Apple Privacy Labels.",
            "venue": "USENIX Security Symposium",
            "pages": "1091-1108",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/XiaoLQBGLX23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/xiao-yue",
            "url": "https://dblp.org/rec/conf/uss/XiaoLQBGLX23",
            "abstract": "As a key supplement to privacy policies that are known to be lengthy and difficult to read, Apple has launched app privacy labels, which purportedly help users more easily understand an app's privacy practices. However, false and misleading privacy labels can dupe privacy-conscious consumers into downloading data-intensive apps, ultimately eroding the credibility and integrity of the labels.  Although Apple releases requirements and guidelines for app developers to create privacy labels, little is known about whether and to what extent the privacy labels in the wild are correct and compliant, reflecting the actual data practices of iOS apps. \nThis paper presents the first systematic study, based on our new methodology named Lalaine, to evaluate data-flow to privacy-label flow-to-label consistency. Lalaine fully analyzed the privacy labels and binaries of 5,102 iOS apps, shedding lights on the prevalence and seriousness of privacy-label non-compliance. We provide detailed case studies and analyze root causes for privacy label non-compliance that complements prior understandings. This has led to new insights for improving privacy-label design and compliance requirements, so app developers, platform stakeholders, and policy-makers can better achieve their privacy and accountability goals. Lalaine is thoroughly evaluated for its high effectiveness and efficiency. We are responsibly reporting the results to stakeholders.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-xiao-yue.pdf",
            "keywords": [
                "App Privacy Labels",
                "Data Practices",
                "Privacy Compliance",
                "Non-Compliance Analysis",
                "Lalaine Methodology"
            ]
        },
        "url": "URL#915520"
    },
    {
        "@score": "1",
        "@id": "915521",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "272/7143",
                        "text": "Qifan Xiao"
                    },
                    {
                        "@pid": "71/7816",
                        "text": "Xudong Pan"
                    },
                    {
                        "@pid": "38/712",
                        "text": "Yifan Lu"
                    },
                    {
                        "@pid": "84/2519-1",
                        "text": "Mi Zhang 0001"
                    },
                    {
                        "@pid": "217/3746",
                        "text": "Jiarun Dai"
                    },
                    {
                        "@pid": "02/1640-2",
                        "text": "Min Yang 0002"
                    }
                ]
            },
            "title": "Exorcising &quot;Wraith&quot;: Protecting LiDAR-based Object Detector in Automated Driving System from Appearing Attacks.",
            "venue": "USENIX Security Symposium",
            "pages": "2939-2956",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/XiaoPL0D023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/xiao-qifan",
            "url": "https://dblp.org/rec/conf/uss/XiaoPL0D023",
            "abstract": "Automated driving systems rely on 3D object detectors to recognize possible obstacles from LiDAR point clouds. However, recent works show the adversary can forge non-existent cars in the prediction results with a few fake points (i.e., appearing attack). By removing statistical outliers, existing defenses are however designed for specific attacks or biased by predefined heuristic rules. Towards more comprehensive mitigation, we first systematically inspect the mechanism of previous appearing attacks: Their common weaknesses are observed in crafting fake obstacles which (i) have obvious differences in the local parts compared with real obstacles and (ii) violate the physical relation between depth and point density. \nIn this paper, we propose a novel plug-and-play defensive module which works by side of a trained LiDAR-based object detector to eliminate forged obstacles where a major proportion of local parts have low objectness, i.e., to what degree it belongs to a real object. At the core of our module is a local objectness predictor, which explicitly incorporates the depth information to model the relation between depth and point density, and predicts each local part of an obstacle with an objectness score. Extensive experiments show, our proposed defense eliminates at least 70% cars forged by three known appearing attacks in most cases, while, for the best previous defense, less than 30% forged cars are eliminated. Meanwhile, under the same circumstance, our defense incurs less overhead for AP/precision on cars compared with existing defenses. Furthermore, We validate the effectiveness of our proposed defense on simulation-based closed-loop control driving tests in the open-source system of Baidu's Apollo.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-xiao-qifan.pdf",
            "keywords": [
                "Automated Driving Systems",
                "LiDAR Object Detection",
                "Adversarial Attacks",
                "Appearing Attacks",
                "Local Objectness Prediction"
            ]
        },
        "url": "URL#915521"
    },
    {
        "@score": "1",
        "@id": "915522",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "345/9258",
                        "text": "Madelyne Xiao"
                    },
                    {
                        "@pid": "319/9769",
                        "text": "Mona Wang"
                    },
                    {
                        "@pid": "02/11141",
                        "text": "Anunay Kulshrestha"
                    },
                    {
                        "@pid": "116/8542",
                        "text": "Jonathan R. Mayer"
                    }
                ]
            },
            "title": "Account Verification on Social Media: User Perceptions and Paid Enrollment.",
            "venue": "USENIX Security Symposium",
            "pages": "3099-3116",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/XiaoWKM23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/xiao-madelyne",
            "url": "https://dblp.org/rec/conf/uss/XiaoWKM23",
            "abstract": "We investigate how users perceive social media account verification, how those perceptions compare to platform practices, and what happens when a gap emerges. We use recent changes in Twitter's verification process as a natural experiment, where the meaning and types of verification indicators rapidly and significantly shift. The project consists of two components: a user survey and a measurement of verified Twitter accounts. In the survey study, we ask a demographically representative sample of U.S. respondents (n = 299) about social media account verification requirements both in general and for particular platforms. We also ask about experiences with online information sources and digital literacy. More than half of respondents misunderstand Twitter's criteria for blue check account verification, and over 80% of respondents misunderstand Twitter's new gold and gray check verification indicators. Our analysis of survey responses suggests that people who are older or have lower digital literacy may be modestly more likely to misunderstand Twitter verification. In the measurement study, we randomly sample 15 million English language tweets from October 2022. We obtain account verification status for the associated accounts in November 2022, just before Twitter's verification changes, and we collect verification status again in January 2022. The resulting longitudinal dataset of 2.85 million accounts enables us to characterize the accounts that gained and lost verification following Twitter's changes. We find that accounts posting conservative political content, exhibiting positive views about Elon Musk, and promoting cryptocurrencies disproportionately obtain blue check verification after Twitter's changes. We close by offering recommendations for improving account verification indicators and processes.",
            "keywords": [
                "Social Media Verification",
                "User Perceptions",
                "Account Verification Practices",
                "Digital Literacy",
                "Twitter Verification Changes"
            ]
        },
        "url": "URL#915522",
        "sema_paperId": "345bfbb4a861922550c740c781b5d2e77948e18a"
    },
    {
        "@score": "1",
        "@id": "915523",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "306/1083",
                        "text": "Jietao Xiao"
                    },
                    {
                        "@pid": "306/1261",
                        "text": "Nanzi Yang"
                    },
                    {
                        "@pid": "18/5040",
                        "text": "Wenbo Shen"
                    },
                    {
                        "@pid": "06/8291",
                        "text": "Jinku Li"
                    },
                    {
                        "@pid": "17/1430",
                        "text": "Xin Guo"
                    },
                    {
                        "@pid": "296/2889",
                        "text": "Zhiqiang Dong"
                    },
                    {
                        "@pid": "51/1316",
                        "text": "Fei Xie"
                    },
                    {
                        "@pid": "12/6604-1",
                        "text": "Jianfeng Ma 0001"
                    }
                ]
            },
            "title": "Attacks are Forwarded: Breaking the Isolation of MicroVM-based Containers Through Operation Forwarding.",
            "venue": "USENIX Security Symposium",
            "pages": "7517-7534",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/XiaoYSLGDX023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/xiao-jietao",
            "url": "https://dblp.org/rec/conf/uss/XiaoYSLGDX023",
            "abstract": "People proposed to use virtualization techniques to reinforce the isolation between containers. In the design, each container runs inside a lightweight virtual machine (called microVM). MicroVM-based containers benefit from both the security of microVM and the high efficiency of the container, and thus are widely used on the public cloud. However, in this paper, we demonstrate a new attack surface that can be exploited to break the isolation of the microVM-based container, called operation forwarding attacks . Our key observation is that certain operations of the microVM-based container are forwarded to host system calls and host kernel functions. The attacker can leverage the operation forwarding to exploit the host kernel\u2019s vulnerabilities and exhaust host resources. To fully understand the security risk of operation forwarding attacks, we divide the components of the microVM-based container into three layers according to their functionalities and present corresponding attacking strategies to exploit the operation forwarding of each layer. Moreover, we design eight attacks against Kata Containers and Firecracker-based containers and conduct experiments on the local environment, AWS, and Alibaba Cloud. Our results show that the attacker can trigger potential privilege escalation, downgrade 93.4% IO performance and 75.0% CPU performance of the victim container, and even crash the host. We further give security suggestions for mitigating these attacks.",
            "keywords": [
                "MicroVM-based Containers",
                "Operation Forwarding Attacks",
                "Isolation Break",
                "Kata Containers",
                "Firecracker"
            ]
        },
        "url": "URL#915523",
        "sema_paperId": "eec54882557ec9cfcfd964a3f6512a4c03534044"
    },
    {
        "@score": "1",
        "@id": "915524",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "191/1022",
                        "text": "Renjie Xie"
                    },
                    {
                        "@pid": "218/8811",
                        "text": "Jiahao Cao"
                    },
                    {
                        "@pid": "139/2623",
                        "text": "Enhuan Dong"
                    },
                    {
                        "@pid": "18/6055",
                        "text": "Mingwei Xu"
                    },
                    {
                        "@pid": "30/3530-1",
                        "text": "Kun Sun 0001"
                    },
                    {
                        "@pid": "181/2688-2",
                        "text": "Qi Li 0002"
                    },
                    {
                        "@pid": "249/8349",
                        "text": "Licheng Shen"
                    },
                    {
                        "@pid": "188/5710-1",
                        "text": "Menghao Zhang 0001"
                    }
                ]
            },
            "title": "Rosetta: Enabling Robust TLS Encrypted Traffic Classification in Diverse Network Environments with TCP-Aware Traffic Augmentation.",
            "venue": "USENIX Security Symposium",
            "pages": "625-642",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/XieCDX00SZ23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/xie",
            "url": "https://dblp.org/rec/conf/uss/XieCDX00SZ23",
            "abstract": "As the majority of Internet traffic is encrypted by the Transport Layer Security (TLS) protocol, recent advances leverage Deep Learning (DL) models to conduct encrypted traffic classification by automatically extracting complicated and informative features from the packet length sequences of TLS flows. Though existing DL models have reported to achieve excellent classification results on encrypted traffic, we conduct a comprehensive study to show that they all have significant performance degradation in real diverse network environments. After systematically studying the reasons, we discover the packet length sequences of flows may change dramatically due to various TCP mechanisms for reliable transmission in varying network environments. Thereafter, we propose Rosetta to enable robust TLS encrypted traffic classification for existing DL models. It leverages TCP-aware traffic augmentation mechanisms and self-supervised learning to understand implict TCP semantics, and hence extracts robust features of TLS flows. Extensive experiments show that Rosetta can significantly improve the classification performance of existing DL models on TLS traffic in diverse network environments.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-xie.pdf",
            "keywords": [
                "Encrypted Traffic Classification",
                "Transport Layer Security (TLS)",
                "TCP Mechanisms",
                "Traffic Augmentation",
                "Self-Supervised Learning"
            ]
        },
        "url": "URL#915524"
    },
    {
        "@score": "1",
        "@id": "915525",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "329/5827",
                        "text": "Alex Luoyuan Xiong"
                    },
                    {
                        "@pid": "133/2004",
                        "text": "Binyi Chen"
                    },
                    {
                        "@pid": "55/7298",
                        "text": "Zhenfei Zhang"
                    },
                    {
                        "@pid": "161/0070",
                        "text": "Benedikt B\u00fcnz"
                    },
                    {
                        "@pid": "148/2252",
                        "text": "Ben Fisch"
                    },
                    {
                        "@pid": "119/7736",
                        "text": "Fernando Krell"
                    },
                    {
                        "@pid": "13/1643",
                        "text": "Philippe Camacho"
                    }
                ]
            },
            "title": "VeriZexe: Decentralized Private Computation with Universal Setup.",
            "venue": "USENIX Security Symposium",
            "pages": "4445-4462",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/XiongCZBFKC23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/xiong",
            "url": "https://dblp.org/rec/conf/uss/XiongCZBFKC23",
            "abstract": "Traditional blockchain systems execute program state transitions on-chain, requiring each network node participating in state-machine replication to re-compute every step of the program when validating transactions. This limits both scalability and privacy. Recently, Bowe et al. introduced a primitive called decentralized private computation (DPC) and provided an instantiation called Zexe, which allows users to execute arbitrary computations off-chain without revealing the program logic to the network. Moreover, transaction validation takes only constant time, independent of the off-chain computation. However, Zexe required a separate trusted setup for each application, which is highly impractical. Prior attempts to remove this per-application setup incurred significant performance loss.\nWe propose a new DPC instantiation VeriZexe that is highly efficient and requires only a single universal setup to support an arbitrary number of applications. Our benchmark improves the state-of-the-art by 9x in transaction generation time and by 3.4x in memory usage. Along the way, we also design efficient gadgets for variable-base multi-scalar multiplication and modular arithmetic within the Plonk constraint system, leading to a Plonk verifier gadget using only \u223c 21k Plonk constraints.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-xiong.pdf",
            "keywords": [
                "Decentralized Private Computation",
                "Blockchain Scalability",
                "Universal Setup",
                "Off-chain Computation",
                "Transaction Validation Efficiency"
            ]
        },
        "url": "URL#915525"
    },
    {
        "@score": "1",
        "@id": "915526",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "47/8617",
                        "text": "Xiaojun Xu"
                    },
                    {
                        "@pid": "254/0865",
                        "text": "Qingying Hao"
                    },
                    {
                        "@pid": "152/4206",
                        "text": "Zhuolin Yang"
                    },
                    {
                        "@pid": "50/3402-26",
                        "text": "Bo Li 0026"
                    },
                    {
                        "@pid": "31/10314",
                        "text": "David M. Liebovitz"
                    },
                    {
                        "@pid": "71/4292-11",
                        "text": "Gang Wang 0011"
                    },
                    {
                        "@pid": "g/CarlAGunter",
                        "text": "Carl A. Gunter"
                    }
                ]
            },
            "title": "How to Cover up Anomalous Accesses to Electronic Health Records.",
            "venue": "USENIX Security Symposium",
            "pages": "229-246",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/XuHY0L0G23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/xu-xiaojun",
            "url": "https://dblp.org/rec/conf/uss/XuHY0L0G23",
            "abstract": "Illegitimate access detection systems in hospital logs perform post hoc detection instead of runtime access restriction to allow widespread access in emergencies. We study the effectiveness of adversarial machine learning strategies against such detection systems on a large-scale dataset consisting of a year of access logs at a major hospital. We study a range of graph-based anomaly detection systems, including heuristic-based and Graph Neural Network (GNN)-based models. We find that evasion attacks , in which covering accesses (that is, accesses made to disguise a target access ) are injected during evaluation period of the target access, can successfully fool the detection system. We also show that such evasion attacks can transfer among different detection algorithms. On the other hand, we find that poisoning attacks , in which adversaries inject covering accesses during the training phase of the model, do not effectively mislead the trained detection system unless the attacker is given unrealistic capabilities such as injecting over 10,000 accesses or imposing a high weight on the covering accesses in the training algorithm. To examine the generalizability of the results, we also apply our attack against a state-of-the-art detection model on the LANL network lateral movement dataset, and observe similar conclusions.",
            "keywords": [
                "Electronic Health Records",
                "Anomalous Access Detection",
                "Adversarial Machine Learning",
                "Evasion Attacks",
                "Graph Neural Networks"
            ]
        },
        "url": "URL#915526",
        "sema_paperId": "eae2c1044679e6c01490ddc9b5b6760934e5f568"
    },
    {
        "@score": "1",
        "@id": "915527",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "302/1583",
                        "text": "Jianhao Xu"
                    },
                    {
                        "@pid": "67/10639",
                        "text": "Kangjie Lu"
                    },
                    {
                        "@pid": "322/7798",
                        "text": "Zhengjie Du"
                    },
                    {
                        "@pid": "83/5619",
                        "text": "Zhu Ding"
                    },
                    {
                        "@pid": "212/6748",
                        "text": "Linke Li"
                    },
                    {
                        "@pid": "248/1662",
                        "text": "Qiushi Wu"
                    },
                    {
                        "@pid": "31/1273",
                        "text": "Mathias Payer"
                    },
                    {
                        "@pid": "98/5039-1",
                        "text": "Bing Mao 0001"
                    }
                ]
            },
            "title": "Silent Bugs Matter: A Study of Compiler-Introduced Security Bugs.",
            "venue": "USENIX Security Symposium",
            "pages": "3655-3672",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/XuLDDLWPM23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/xu-jianhao",
            "url": "https://dblp.org/rec/conf/uss/XuLDDLWPM23",
            "abstract": "Compilers assure that any produced optimized code is semantically equivalent to the original code. However, even \u201ccorrect\u201d compilers may introduce security bugs as security properties go beyond translation correctness. Security bugs introduced by such correct compiler behaviors can be dis-putable; compiler developers expect users to strictly follow language specifications and understand all assumptions, while compiler users may incorrectly assume that their code is secure. Such bugs are hard to find and prevent, especially when it is unclear whether they should be fixed on the compiler or user side. Nevertheless, these bugs are real and can be severe, thus should be studied carefully. We perform a comprehensive study on compiler-introduced security bugs (CISB) and their root causes. We collect a large set of CISB in the wild by manually analyzing 4,827 potential bug reports of the most popular compilers (GCC and Clang), distilling them into a taxonomy of CISB. We further conduct a user study to understand how compiler users view compiler behaviors. Our study shows that compiler-introduced security bugs are common and may have serious security impacts. It is unrealistic to expect compiler users to understand and comply with compiler assumptions. For example, the \u201cno-undefined-behavior\u201d assumption has become a nightmare for users and a major cause of CISB.",
            "keywords": [
                "Compiler Security",
                "Compiler-Introduced Bugs",
                "Undefined Behavior",
                "Security Properties",
                "User Assumptions"
            ]
        },
        "url": "URL#915527",
        "sema_paperId": "3d7652db8f29c8921921849eeb9c9508b6f0421c"
    },
    {
        "@score": "1",
        "@id": "915528",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "189/3091",
                        "text": "Jinyan Xu"
                    },
                    {
                        "@pid": "278/1917",
                        "text": "Yiyuan Liu"
                    },
                    {
                        "@pid": "321/8333",
                        "text": "Sirui He"
                    },
                    {
                        "@pid": "325/1474",
                        "text": "Haoran Lin"
                    },
                    {
                        "@pid": "15/7381",
                        "text": "Yajin Zhou"
                    },
                    {
                        "@pid": "18/2771-1",
                        "text": "Cong Wang 0001"
                    }
                ]
            },
            "title": "MorFuzz: Fuzzing Processor via Runtime Instruction Morphing enhanced Synchronizable Co-simulation.",
            "venue": "USENIX Security Symposium",
            "pages": "1307-1324",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/XuLHLZ023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/xu-jinyan",
            "url": "https://dblp.org/rec/conf/uss/XuLHLZ023",
            "abstract": "Modern processors are too complex to be bug free. Recently, a few hardware fuzzing techniques have shown promising results in verifying processor designs. However, due to the complexity of processors, they suffer from complex input grammar, deceptive mutation guidance, and model implementation differences. Therefore, how to effectively and efficiently verify processors is still an open problem. This paper proposes MorFuzz, a novel processor fuzzer that can efficiently discover software triggerable hardware bugs. The core idea behind MorFuzz is to use runtime information to generate instruction streams with valid formats and meaningful semantics. MorFuzz designs a new input structure to provide multi-level runtime mutation primitives and proposes the instruction morphing technique to mutate instruction dynamically. Besides, we also extend the co-simulation framework to various microarchitectures and develop the state synchronization technique to eliminate implementation differences. We evaluate MorFuzz on three popular open-source RISC-V processors: CVA6, Rocket, BOOM, and discover 17 new bugs (with 13 CVEs assigned). Our evaluation shows MorFuzz achieves 4.4 \u00d7 and 1.6 \u00d7 more state coverage than the state-of-the-art fuzzer, DifuzzRTL, and the famous constrained instruction generator, riscv-dv.",
            "keywords": [
                "Processor Fuzzing",
                "Instruction Morphing",
                "Hardware Bugs",
                "Co-simulation Framework",
                "RISC-V Processors"
            ]
        },
        "url": "URL#915528",
        "sema_paperId": "fbc2eea9ea1a103902477456a16566252835d29b"
    },
    {
        "@score": "1",
        "@id": "915529",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "194/2272",
                        "text": "Nian Xue"
                    },
                    {
                        "@pid": "353/7565",
                        "text": "Yashaswi Malla"
                    },
                    {
                        "@pid": "353/7531",
                        "text": "Zihang Xia"
                    },
                    {
                        "@pid": "11/3019",
                        "text": "Christina P\u00f6pper"
                    },
                    {
                        "@pid": "130/3608",
                        "text": "Mathy Vanhoef"
                    }
                ]
            },
            "title": "Bypassing Tunnels: Leaking VPN Client Traffic by Abusing Routing Tables.",
            "venue": "USENIX Security Symposium",
            "pages": "5719-5736",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/XueMXPV23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/xue",
            "url": "https://dblp.org/rec/conf/uss/XueMXPV23",
            "abstract": "Virtual Private Networks (VPNs) authenticate and encrypt network traffic to protect users\u2019 security and privacy, and are used in professional and personal settings to defend against malicious actors, circumvent censorship, remotely work from home, etc. It is therefore essential that VPNs are secure. In this paper, we present two novel attacks that cause VPN clients to leak traffic outside the protected VPN tunnel. The root cause of both attacks is a widespread design flaw in how clients configure the Operating System (OS) to route all traffic through the VPN tunnel. This is typically done by updating the system\u2019s IP routing tables such that all traffic will first pass through the VPN client. However, some routing exceptions are added to ensure the system keeps functioning properly, namely that traffic to the local network, and to the VPN server itself, is sent outside the VPN tunnel. We show that by setting up a Wi-Fi access point or by spoofing DNS responses, an adversary can manipulate these exceptions to make the victim send arbitrary traffic in plaintext outside the VPN tunnel. We confirm our findings in practice by conducting 248 experiments against 67 of the most representative VPN providers on Windows, macOS, iOS, Linux, and Android. Our experimental results reveal that a significant number (126 and 39) and proportion (64.6% and 73.6%) of free, paid, open-source, corporate, and built-in VPN clients are vulnerable to (variants of) our two attacks respectively, suffering from leaky traffic. We discuss countermeasures to mitigate the vulnerabilities and confirm the effectiveness of selected defenses in practice.",
            "keywords": [
                "VPN Security",
                "Traffic Leakage",
                "Routing Table Vulnerabilities",
                "Network Traffic Manipulation",
                "VPN Client Attacks"
            ]
        },
        "url": "URL#915529",
        "sema_paperId": "1465cb2748d808aba6d2ce7c355f1fb21fb4ac3c"
    },
    {
        "@score": "1",
        "@id": "915530",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "225/4590",
                        "text": "Tarun Kumar Yadav"
                    },
                    {
                        "@pid": "207/8090",
                        "text": "Devashish Gosain"
                    },
                    {
                        "@pid": "s/KentESeamons",
                        "text": "Kent E. Seamons"
                    }
                ]
            },
            "title": "Cryptographic Deniability: A Multi-perspective Study of User Perceptions and Expectations.",
            "venue": "USENIX Security Symposium",
            "pages": "3637-3654",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YadavGS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/yadav",
            "url": "https://dblp.org/rec/conf/uss/YadavGS23",
            "abstract": "Cryptographic deniability allows a sender to deny authoring a message. However, it requires social and legal acceptance to be effective. Although popular secure messaging apps support deniability, security experts are divided on whether it should be the default property for these applications. This paper presents a multi-perspective, multi-methods study of user perceptions and expectations of deniability. The methodology includes (1) qualitative analysis of expert opinions obtained from a public forum on deniability, (2) qualitative analysis of semi-structured interviews of US participants, (3) quantitative analysis of a survey ( n=664 ) of US participants, and (4) qualitative and quantitative analysis of US court cases with help from a legal expert to understand the legal standpoint of deniability. The results show that deniability is not socially accepted, and most users prefer non-repudiation. We found no US court cases involving WhatApp that consider denia-bility. Significant human-centered research is needed before deniability can adequately protect vulnerable users.",
            "keywords": [
                "Cryptographic Deniability",
                "User Perceptions",
                "Secure Messaging",
                "Non-repudiation",
                "Legal Acceptance"
            ]
        },
        "url": "URL#915530",
        "sema_paperId": "408483b0deae7acbaec830fa02ca0f17205a6128"
    },
    {
        "@score": "1",
        "@id": "915531",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "185/6250",
                        "text": "Carter Yagemann"
                    },
                    {
                        "@pid": "38/860",
                        "text": "Simon P. Chung"
                    },
                    {
                        "@pid": "150/5240",
                        "text": "Brendan Saltaformaggio"
                    },
                    {
                        "@pid": "29/5976",
                        "text": "Wenke Lee"
                    }
                ]
            },
            "title": "PUMM: Preventing Use-After-Free Using Execution Unit Partitioning.",
            "venue": "USENIX Security Symposium",
            "pages": "823-840",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YagemannCSL23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/yagemann",
            "url": "https://dblp.org/rec/conf/uss/YagemannCSL23",
            "abstract": "Critical software is written in memory unsafe languages that are vulnerable to use-after-free and double free bugs. This has led to proposals to secure memory allocators by strategically deferring memory reallocations long enough to make such bugs unexploitable. Unfortunately, existing solutions suffer from high runtime and memory overheads. Seeking a better solution, we propose to pro\ufb01le programs to identify units of code that correspond to the handling of individual tasks. With the intuition that little to no data should \ufb02ow between separate tasks at runtime, reallocation of memory freed by the currently executing unit is deferred until after its completion; just long enough to prevent use-after-free exploitation. To demonstrate the ef\ufb01cacy of our design, we implement a prototype for Linux, PUMM, which consists of an of\ufb02ine pro\ufb01ler and an online enforcer that transparently wraps standard libraries to protect C/C++ binaries. In our evaluation of 40 real-world and 3,000 synthetic vulnerabilities across 26 programs, including complex multi-threaded cases like the Chakra JavaScript engine, PUMM successfully thwarts all real-world exploits, and only allows 4 synthetic exploits, while reducing memory overhead by 52.0% over prior work and incurring an average runtime overhead of 2.04%.",
            "keywords": [
                "Memory Safety",
                "Use-After-Free",
                "Memory Reallocation",
                "Execution Unit Partitioning",
                "Runtime Overhead"
            ]
        },
        "url": "URL#915531",
        "sema_paperId": "f9fdcaf171203e51e810f48e97e1316810d56893"
    },
    {
        "@score": "1",
        "@id": "915532",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "209/7183",
                        "text": "Yifan Yan"
                    },
                    {
                        "@pid": "71/7816",
                        "text": "Xudong Pan"
                    },
                    {
                        "@pid": "84/2519-1",
                        "text": "Mi Zhang 0001"
                    },
                    {
                        "@pid": "02/1640-2",
                        "text": "Min Yang 0002"
                    }
                ]
            },
            "title": "Rethinking White-Box Watermarks on Deep Learning Models under Neural Structural Obfuscation.",
            "venue": "USENIX Security Symposium",
            "pages": "2347-2364",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YanP0023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/yan",
            "url": "https://dblp.org/rec/conf/uss/YanP0023",
            "abstract": "Copyright protection for deep neural networks (DNNs) is an urgent need for AI corporations. To trace illegally distributed model copies, DNN watermarking is an emerging technique for embedding and verifying secret identity messages in the prediction behaviors or the model internals. Sacrificing less functionality and involving more knowledge about the target DNN, the latter branch called \\textit{white-box DNN watermarking} is believed to be accurate, credible and secure against most known watermark removal attacks, with emerging research efforts in both the academy and the industry. In this paper, we present the first systematic study on how the mainstream white-box DNN watermarks are commonly vulnerable to neural structural obfuscation with \\textit{dummy neurons}, a group of neurons which can be added to a target model but leave the model behavior invariant. Devising a comprehensive framework to automatically generate and inject dummy neurons with high stealthiness, our novel attack intensively modifies the architecture of the target model to inhibit the success of watermark verification. With extensive evaluation, our work for the first time shows that nine published watermarking schemes require amendments to their verification procedures.",
            "keywords": [
                "White-Box Watermarking",
                "Neural Structural Obfuscation",
                "Dummy Neurons",
                "Watermark Verification",
                "Model Architecture Modification"
            ]
        },
        "url": "URL#915532",
        "sema_paperId": "5be46f86c857d560bc50563d1e6a171a9fc78cda"
    },
    {
        "@score": "1",
        "@id": "915533",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "152/4206",
                        "text": "Zhuolin Yang"
                    },
                    {
                        "@pid": "11/5123-1",
                        "text": "Yuxin Chen 0001"
                    },
                    {
                        "@pid": "331/5331",
                        "text": "Zain Sarwar"
                    },
                    {
                        "@pid": "353/7523",
                        "text": "Hadleigh Schwartz"
                    },
                    {
                        "@pid": "z/BenYZhao",
                        "text": "Ben Y. Zhao"
                    },
                    {
                        "@pid": "43/4261",
                        "text": "Haitao Zheng 0001"
                    }
                ]
            },
            "title": "Towards a General Video-based Keystroke Inference Attack.",
            "venue": "USENIX Security Symposium",
            "pages": "141-158",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Yang0SSZ023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/yang-zhuolin",
            "url": "https://dblp.org/rec/conf/uss/Yang0SSZ023",
            "abstract": "A large collection of research literature has identified the privacy risks of keystroke inference attacks that use statistical models to extract content typed onto a keyboard. Yet existing attacks cannot operate in realistic settings, and rely on strong assumptions of labeled training data, knowledge of keyboard layout, carefully placed sensors or data from other side-channels. This paper describes experiences developing and evaluating a general, video-based keystroke inference attack that operates in common public settings using a single commodity camera phone, with no pretraining, no keyboard knowledge, no local sensors, and no side-channels. We show that using a self-supervised approach, noisy finger tracking data from a video can be processed, labeled and filtered to train DNN keystroke inference models that operate accurately on the same video. Using IRB approved user studies, we validate attack efficacy across a variety of environments, keyboards, and content, and users with different typing behaviors and abilities. Our project website is located at: https://sandlab.cs.uchicago.edu/keystroke/ .",
            "keywords": [
                "Keystroke Inference Attack",
                "Video-based Attack",
                "Self-supervised Learning",
                "User Study Validation",
                "Noisy Finger Tracking"
            ]
        },
        "url": "URL#915533",
        "sema_paperId": "8d666f200b1c59121aef0c9552037fc5486ec929"
    },
    {
        "@score": "1",
        "@id": "915534",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "59/5806",
                        "text": "Zheng Yang"
                    },
                    {
                        "@pid": "224/9407",
                        "text": "Joey Allen"
                    },
                    {
                        "@pid": "231/1936",
                        "text": "Matthew Landen"
                    },
                    {
                        "@pid": "60/6768",
                        "text": "Roberto Perdisci"
                    },
                    {
                        "@pid": "29/5976",
                        "text": "Wenke Lee"
                    }
                ]
            },
            "title": "TRIDENT: Towards Detecting and Mitigating Web-based Social Engineering Attacks.",
            "venue": "USENIX Security Symposium",
            "pages": "6701-6718",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YangALPL23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/yang-zheng",
            "url": "https://dblp.org/rec/conf/uss/YangALPL23",
            "abstract": "As the weakest link in cybersecurity, humans have become the main target of attackers who take advantage of sophisticated web-based social engineering techniques. These attackers leverage low-tier ad networks to inject social engineering components onto web pages to lure users into websites that the attackers control for further exploitation. Most of these exploitations are Web-based Social Engineering Attacks (WSEAs), such as reward and lottery scams. Although researchers have proposed systems and tools to detect some WSEAs, these approaches are very tailored to specific scam techniques (i.e., tech support scams, survey scams) only. They were not designed to be effective against a broad set of attack techniques. With the ever-increasing diversity and sophistication of WSEAs that any user can encounter, there is an urgent need for new and more effective in-browser systems that can accurately detect generic WSEAs. To address this need, we propose T RIDENT , a novel defense system that aims to detect and block generic WSEAs in real-time. T RIDENT stops WSEAs by detecting Social Engineering Ads (SE-ads), the entry point of general web social engineering attacks distributed by low-tier ad networks at scale. Our extensive evaluation shows that T RIDENT can detect SE-ads with an accuracy of 92.63% and a false positive rate of 2.57% and is robust against evasion attempts. We also evaluated T RIDENT against the state-of-the-art ad-blocking tools. The results show that T RIDENT outperforms these tools with a 10% increase in accuracy. Additionally, T RIDENT only incurs 2.13% runtime overhead as a median rate, which is small enough to deploy in production.",
            "keywords": [
                "Web-based Social Engineering",
                "Social Engineering Ads",
                "Attack Detection",
                "Ad Network Exploitation",
                "Real-time Mitigation"
            ]
        },
        "url": "URL#915534",
        "sema_paperId": "eccb03bc3bebb271016a7ad24eb7be6cbff47f68"
    },
    {
        "@score": "1",
        "@id": "915535",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "235/0627",
                        "text": "Lanqing Yang"
                    },
                    {
                        "@pid": "318/1946",
                        "text": "Xinqi Chen"
                    },
                    {
                        "@pid": "353/7571",
                        "text": "Xiangyong Jian"
                    },
                    {
                        "@pid": "285/5848",
                        "text": "Leping Yang"
                    },
                    {
                        "@pid": "54/8054",
                        "text": "Yijie Li"
                    },
                    {
                        "@pid": "353/7544",
                        "text": "Qianfei Ren"
                    },
                    {
                        "@pid": "91/699-1",
                        "text": "Yi-Chao Chen 0001"
                    },
                    {
                        "@pid": "79/1810",
                        "text": "Guangtao Xue"
                    },
                    {
                        "@pid": "39/1697-1",
                        "text": "Xiaoyu Ji 0001"
                    }
                ]
            },
            "title": "Remote Attacks on Speech Recognition Systems Using Sound from Power Supply.",
            "venue": "USENIX Security Symposium",
            "pages": "4571-4588",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YangCJYLR0X023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/yang-lanqing",
            "url": "https://dblp.org/rec/conf/uss/YangCJYLR0X023",
            "abstract": "Speech recognition (SR) systems are used on smartphones and speakers to make inquiries, compose emails, and initiate phone calls. However, they also impose a severe security risk. Researchers have demonstrated that the introduction of certain sounds can threaten the security of SR systems. Nonetheless, most of those methods require that the attacker approach within a short distance of the victim, thereby limiting the applicability of such schemes. Other researchers have attacked SR systems remotely using peripheral devices (e.g., lasers); however, those methods require line-of-sight access and an always-on speaker in the vicinity of the victim. To the best of our knowledge, this paper presents the \ufb01rst-ever scheme, named S ING A TTACK , in which SR systems are manipulated by human-like sounds generated in the switching mode power supply of the victim\u2019s device. The fact that attack signals are transmitted via the power grid enables long-range attacks on existing SR systems. In experiments on ten SR systems, S ING A TTACK achieved Mel-Cepstral Distortion of 7 . 8 from an attack initiated at a distance of 23m.",
            "keywords": [
                "Speech Recognition Systems",
                "Remote Attacks",
                "Power Supply Manipulation",
                "Acoustic Signals",
                "SING ATTACK"
            ]
        },
        "url": "URL#915535",
        "sema_paperId": "2689b0cc023863650425a33eabb172807bb74e94"
    },
    {
        "@score": "1",
        "@id": "915536",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "06/7124-1",
                        "text": "Yuchen Yang 0001"
                    },
                    {
                        "@pid": "260/4200-2",
                        "text": "Bo Hui 0002"
                    },
                    {
                        "@pid": "238/9094",
                        "text": "Haolin Yuan"
                    },
                    {
                        "@pid": "03/9437",
                        "text": "Neil Zhenqiang Gong"
                    },
                    {
                        "@pid": "28/8733",
                        "text": "Yinzhi Cao"
                    }
                ]
            },
            "title": "PrivateFL: Accurate, Differentially Private Federated Learning via Personalized Data Transformation.",
            "venue": "USENIX Security Symposium",
            "pages": "1595-1612",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YangHYGC23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/yang-yuchen",
            "url": "https://dblp.org/rec/conf/uss/YangHYGC23",
            "abstract": "Federated learning (FL) enables multiple clients to collaboratively train a model with the coordination of a central server. Although FL improves data privacy via keeping each client\u2019s training data locally, an attacker\u2014e.g., an untrusted server\u2014 can still compromise the privacy of clients\u2019 local training data via various inference attacks. A de facto approach to preserving FL privacy is Differential Privacy (DP), which adds random noise during training. However, when applied to FL, DP suffers from a key limitation: it sacrifices the model accuracy substantially\u2014which is even more severely than being applied to traditional centralized learning\u2014to achieve a meaningful level of privacy. In this paper, we study the accuracy degradation cause of FL+DP and then design an approach to improve the accuracy. First, we propose that such accuracy degradation is partially because DP introduces additional heterogeneity among FL clients when adding different random noise with clipping bias during local training. To the best of our knowledge, we are the first to associate DP in FL with client heterogeneity. Second, we design P RIVATE FL to learn accurate, differentially private models in FL with reduced heterogeneity. The key idea is to jointly learn a differentially private, personalized data transformation for each client during local training. The personalized data transformation shifts client\u2019s local data distribution to compensate the heterogeneity introduced by DP, thus improving FL model\u2019s accuracy. In the evaluation, we combine and compare P RIVATE FL with eight state-of-the-art differentially private FL methods on seven benchmark datasets, including six image and one non-image datasets. Our results show that P RIVATE FL learns accurate FL models with a small \u03b5 , e.g., 93.3% on CIFAR-10 with 100 clients under ( \u03b5 = 2, \u03b4 = 1 e \u2212 3)-DP. Moreover, P RIVATE FL can be combined with prior works to reduce DP-induced heterogeneity",
            "keywords": [
                "Federated Learning",
                "Differential Privacy",
                "Client Heterogeneity",
                "Personalized Data Transformation",
                "Model Accuracy"
            ]
        },
        "url": "URL#915536",
        "sema_paperId": "e2bb53bf77797ce75ac5959c0245bf4f4c2b87fd"
    },
    {
        "@score": "1",
        "@id": "915537",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "29/3081",
                        "text": "Fan Yang"
                    },
                    {
                        "@pid": "224/4836",
                        "text": "Jiacen Xu"
                    },
                    {
                        "@pid": "86/5273",
                        "text": "Chunlin Xiong"
                    },
                    {
                        "@pid": "62/4119-1",
                        "text": "Zhou Li 0001"
                    },
                    {
                        "@pid": "66/6560",
                        "text": "Kehuan Zhang"
                    }
                ]
            },
            "title": "PROGRAPHER: An Anomaly Detection System based on Provenance Graph Embedding.",
            "venue": "USENIX Security Symposium",
            "pages": "4355-4372",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YangXXLZ23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/yang-fan",
            "url": "https://dblp.org/rec/conf/uss/YangXXLZ23",
            "abstract": "In recent years, the Advanced Persistent Threat (APT), which involves complex and malicious actions over a long period, has become one of the biggest threats against the security of the modern computing environment. As a countermeasure, data provenance is leveraged to capture the complex relations between entities in a computing system/network, and uses such information to detect sophisticated APT attacks. Though showing promise in countering APT attacks, the existing systems still cannot achieve a good balance between efficiency, accuracy, and granularity. In this work, we design a new anomaly detection system on provenance graphs, termed P RO G RAPHER . To address the problem of \u201cdependency explosion\u201d of provenance graphs and achieve high efficiency, P RO G RAPHER extracts temporal-ordered snapshots from the ingested logs and performs detection on the snapshots. To capture the rich structural properties of a graph, whole graph embedding and sequence-based learning are applied. Finally, key indicators are extracted from the abnormal snapshots and reported to the analysts, so their workload will be greatly reduced. We evaluate P RO G RAPHER on five real-world datasets. The results show that P RO G RAPHER can detect standard attacks and APT attacks with high accuracy and outperform the state-of-the-art detection systems.",
            "keywords": [
                "Anomaly Detection",
                "Provenance Graphs",
                "Advanced Persistent Threats (APT)",
                "Dependency Explosion",
                "Graph Embedding"
            ]
        },
        "url": "URL#915537",
        "sema_paperId": "b0b9f026a209de75d39024b620790858fc46fc4a"
    },
    {
        "@score": "1",
        "@id": "915538",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "210/4952",
                        "text": "Mingxuan Yao"
                    },
                    {
                        "@pid": "151/1951",
                        "text": "Jonathan Fuller"
                    },
                    {
                        "@pid": "248/1646",
                        "text": "Ranjita Pai Kasturi"
                    },
                    {
                        "@pid": "251/2448",
                        "text": "Saumya Agarwal"
                    },
                    {
                        "@pid": "202/9503",
                        "text": "Amit Kumar Sikder"
                    },
                    {
                        "@pid": "150/5240",
                        "text": "Brendan Saltaformaggio"
                    }
                ]
            },
            "title": "Hiding in Plain Sight: An Empirical Study of Web Application Abuse in Malware.",
            "venue": "USENIX Security Symposium",
            "pages": "6115-6132",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YaoFKASS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/yao-mingxuan",
            "url": "https://dblp.org/rec/conf/uss/YaoFKASS23",
            "abstract": "Web applications provide a wide array of utilities that are abused by malware as a replacement for traditional attacker-controlled servers. Thwarting these Web App-Engaged (WAE) malware requires rapid collaboration between incident responders and web app providers. Unfortunately, our research found that delays in this collaboration allow WAE malware to thrive. We developed Marsea, an automated malware analysis pipeline that studies WAE malware and enables rapid remediation. Given 10K malware samples, Marsea revealed 893 WAE malware in 97 families abusing 29 web apps. Our research uncovered a 226% increase in the number of WAE malware since 2020 and that malware authors are beginning to reduce their reliance on attacker-controlled servers.  In fact, we found a 13.7% decrease in WAE malware relying on attacker-controlled  servers. To date, we have used Marsea to collaborate with the web app providers to take down 50% of the malicious web app content.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-yao-mingxuan.pdf",
            "keywords": [
                "Web Application Abuse",
                "Malware Analysis",
                "WAE Malware",
                "Automated Remediation",
                "Malicious Web Content"
            ]
        },
        "url": "URL#915538"
    },
    {
        "@score": "1",
        "@id": "915539",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "290/9011",
                        "text": "Hengkai Ye"
                    },
                    {
                        "@pid": "80/1141",
                        "text": "Song Liu"
                    },
                    {
                        "@pid": "334/9029",
                        "text": "Zhechang Zhang"
                    },
                    {
                        "@pid": "70/2543-4",
                        "text": "Hong Hu 0004"
                    }
                ]
            },
            "title": "VIPER: Spotting Syscall-Guard Variables for Data-Only Attacks.",
            "venue": "USENIX Security Symposium",
            "pages": "1397-1414",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YeLZ023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/ye",
            "url": "https://dblp.org/rec/conf/uss/YeLZ023",
            "abstract": "As control-flow protection techniques are widely deployed, it is difficult for attackers to modify control data, like function pointers, to hijack program control flow. Instead, data-only attacks corrupt security-critical non-control data (critical data), and can bypass all control-flow protections to revive severe attacks. Previous works have explored various methods to help construct or prevent data-only attacks. However, no solution can automatically detect program-specific critical data. In this paper, we identify an important category of critical data, syscall-guard variables , and propose a set of solutions to automatically detect such variables in a scalable manner. Syscall-guard variables determine to invoke security-related system calls (syscalls), and altering them will allow attackers to request extra privileges from the operating system. We propose branch force , which intentionally flips every conditional branch during the execution and checks whether new security-related syscalls are invoked. If so, we conduct data-flow analysis to estimate the feasibility to flip such branches through common memory errors. We build a tool, V IPER , to implement our ideas. V IPER successfully detects 34 previously unknown syscall-guard variables from 13 programs. We build four new data-only attacks on sqlite and v8, which execute arbitrary command or delete arbitrary file. V IPER completes its analysis within five minutes for most programs, showing its practicality for spotting syscall-guard variables.",
            "keywords": [
                "Data-Only Attacks",
                "Syscall-Guard Variables",
                "Control-Flow Protection",
                "Security-Critical Data",
                "Branch Force"
            ]
        },
        "url": "URL#915539",
        "sema_paperId": "31127b10874d1d124350b66cdaaf777cb1c2df76"
    },
    {
        "@score": "1",
        "@id": "915540",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "243/2692",
                        "text": "Wei-Zhu Yeoh"
                    },
                    {
                        "@pid": "320/7875",
                        "text": "Michal Kepkowski"
                    },
                    {
                        "@pid": "332/3161",
                        "text": "Gunnar Heide"
                    },
                    {
                        "@pid": "71/5612",
                        "text": "Dali Kaafar"
                    },
                    {
                        "@pid": "119/3581",
                        "text": "Lucjan Hanzlik"
                    }
                ]
            },
            "title": "Fast IDentity Online with Anonymous Credentials (FIDO-AC).",
            "venue": "USENIX Security Symposium",
            "pages": "3029-3046",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YeohKHKH23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/yeoh",
            "url": "https://dblp.org/rec/conf/uss/YeohKHKH23",
            "abstract": "Web authentication is a critical component of today's Internet and the digital world we interact with. The FIDO2 protocol enables users to leverage common devices to easily authenticate to online services in both mobile and desktop environments following the passwordless authentication approach based on cryptography and biometric verification. However, there is little to no connection between the authentication process and users' attributes. More specifically, the FIDO protocol does not specify methods that could be used to combine trusted attributes with the FIDO authentication process generically and allows users to disclose them to the relying party arbitrarily. In essence, applications requiring attributes verification (e.g. age or expiry date of a driver's license, etc.) still rely on ad-hoc approaches, not satisfying the data minimization principle and not allowing the user to vet the disclosed data. A primary recent example is the data breach on Singtel Optus, one of the major telecommunications providers in Australia, where very personal and sensitive data (e.g. passport numbers) were leaked. This paper introduces FIDO-AC, a novel framework that combines the FIDO2 authentication process with the user's digital and non-shareable identity. We show how to instantiate this framework using off-the-shelf FIDO tokens and any electronic identity document, e.g., the ICAO biometric passport (ePassport). We demonstrate the practicality of our approach by evaluating a prototype implementation of the FIDO-AC system.",
            "keywords": [
                "FIDO2 Protocol",
                "Passwordless Authentication",
                "User Attributes Verification",
                "Data Minimization Principle",
                "Anonymous Credentials"
            ]
        },
        "url": "URL#915540",
        "sema_paperId": "a2d0939870ae8e613e579682b5d4bc6486c4e1ba"
    },
    {
        "@score": "1",
        "@id": "915541",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "40/4177",
                        "text": "Tingting Yin"
                    },
                    {
                        "@pid": "263/9668",
                        "text": "Zicong Gao"
                    },
                    {
                        "@pid": "351/5605",
                        "text": "Zhenghang Xiao"
                    },
                    {
                        "@pid": "249/4978",
                        "text": "Zheyu Ma"
                    },
                    {
                        "@pid": "23/328",
                        "text": "Min Zheng"
                    },
                    {
                        "@pid": "94/3019-8",
                        "text": "Chao Zhang 0008"
                    }
                ]
            },
            "title": "KextFuzz: Fuzzing macOS Kernel EXTensions on Apple Silicon via Exploiting Mitigations.",
            "venue": "USENIX Security Symposium",
            "pages": "5039-5054",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YinGXMZ023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/yin",
            "url": "https://dblp.org/rec/conf/uss/YinGXMZ023",
            "abstract": "macOS drivers, i.e., Kernel EXTensions (kext), are attractive attack targets for adversaries. However, automatically discovering vulnerabilities in kexts is extremely challenging because kexts are mostly closed-source, and the latest macOS running on customized Apple Silicon has limited tool-chain support. Most existing static analysis and dynamic testing solutions cannot be applied to the latest macOS. In this paper, we present the first smart fuzzing solution KextFuzz to detect bugs in the latest macOS kexts running on Apple Silicon. Unlike existing driver fuzzing solutions, KextFuzz does not require source code, execution traces, hypervisors, or hardware features (e.g., coverage tracing) and thus is universal and practical. We note that macOS has deployed many mitigations, including pointer authentication, code signature, and userspace kernel layer wrappers, to thwart potential attacks. These mitigations can provide extra knowledge and resources for us to enable kernel fuzzing. KextFuzz exploits these mitigation schemes to instrument the binary for coverage tracking, test privileged kext code that is guarded and infrequently accessed, and infer the type and semantic information of the kext interfaces. KextFuzz has found 48 unique kernel bugs in the macOS kexts. Some of them could cause severe consequences like non-recoverable denial-of-service or damages.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-yin.pdf",
            "keywords": [
                "Kernel Extensions",
                "Fuzzing",
                "macOS",
                "Apple Silicon",
                "Kernel Vulnerabilities"
            ]
        },
        "url": "URL#915541",
        "sema_paperId": "fe40746e7e1c0811607d4e61246f288a53ae758d"
    },
    {
        "@score": "1",
        "@id": "915542",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "238/6241-1",
                        "text": "Jiahao Yu 0001"
                    },
                    {
                        "@pid": "144/1238-2",
                        "text": "Wenbo Guo 0002"
                    },
                    {
                        "@pid": "143/4836",
                        "text": "Qi Qin"
                    },
                    {
                        "@pid": "71/4292-11",
                        "text": "Gang Wang 0011"
                    },
                    {
                        "@pid": "12/2633-6",
                        "text": "Ting Wang 0006"
                    },
                    {
                        "@pid": "40/6431",
                        "text": "Xinyu Xing"
                    }
                ]
            },
            "title": "AIRS: Explanation for Deep Reinforcement Learning based Security Applications.",
            "venue": "USENIX Security Symposium",
            "pages": "7375-7392",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Yu0Q00X23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/yu-jiahao",
            "url": "https://dblp.org/rec/conf/uss/Yu0Q00X23",
            "abstract": "Recently, we have witnessed the success of deep reinforcement learning (DRL) in many security applications, ranging from malware mutation to selfish blockchain mining. Like all other machine learning methods, the lack of explainability has been limiting its broad adoption as users have difficulty establishing trust in DRL models\u2019 decisions. Over the past years, different methods have been proposed to explain DRL models but unfortunately, they are often not suitable for security applications, in which explanation fidelity, efficiency, and the capability of model debugging are largely lacking. In this work, we propose AIRS , a general framework to explain deep reinforcement learning-based security applications. Unlike previous works that pinpoint important features to the agent\u2019s current action, our explanation is at the step level. It models the relationship between the final reward and the key steps that a DRL agent takes, and thus outputs the steps that are most critical towards the final reward the agent has gathered. Using four representative security-critical applications, we evaluate AIRS from the perspectives of ex-plainability, fidelity, stability, and efficiency. We show that AIRS could outperform alternative explainable DRL methods. We also showcase AIRS \u2019s utility, demonstrating that our explanation could facilitate the DRL model\u2019s failure offset, help users establish trust in a model decision, and even assist the identification of inappropriate reward designs.",
            "keywords": [
                "Deep Reinforcement Learning",
                "Security Applications",
                "Explainability",
                "Reward Design",
                "Model Debugging"
            ]
        },
        "url": "URL#915542",
        "sema_paperId": "8ba2051ec12ccf07f06148f77ef5705b48fa7f97"
    },
    {
        "@score": "1",
        "@id": "915543",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "172/4550-1",
                        "text": "Zhiyuan Yu 0001"
                    },
                    {
                        "@pid": "332/3084",
                        "text": "Yuanhaur Chang"
                    },
                    {
                        "@pid": "181/2597-17",
                        "text": "Ning Zhang 0017"
                    },
                    {
                        "@pid": "150/3317",
                        "text": "Chaowei Xiao"
                    }
                ]
            },
            "title": "SMACK: Semantically Meaningful Adversarial Audio Attack.",
            "venue": "USENIX Security Symposium",
            "pages": "3799-3816",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YuC0X23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/yu-zhiyuan-smack",
            "url": "https://dblp.org/rec/conf/uss/YuC0X23",
            "abstract": "Voice controllable systems rely on speech recognition and speaker identification as the key enabling technologies. While they bring revolutionary changes to our daily lives, their security has become a growing concern. Existing work has demonstrated the feasibility of using maliciously crafted perturbations to manipulate speech or speaker recognition. Although these attacks vary in targets and techniques, they all require the addition of noise perturbations. While these perturbations are generally restricted to L p -bounded neighborhood, the added noises inevitably leave unnatural traces recognizable by humans, and can be used for defense. To address this limitation, we introduce a new class of adversarial audio attack, named S emantically M eaningful Adversarial A udio Atta CK (SMACK), where the inherent speech attributes (such as prosody) are modified such that they still semantically represent the same speech and preserves the speech quality. The efficacy of SMACK was evaluated against five transcription systems and two speaker recognition systems in a black-box manner. By manipulating semantic attributes, our adversarial audio examples are capable of evading the state-of-the-art defenses, with better speech naturalness compared to traditional L p -bounded attacks in the human perceptual study.",
            "keywords": [
                "Adversarial Audio Attack",
                "Speech Recognition",
                "Speaker Identification",
                "Semantic Manipulation",
                "Naturalness Preservation"
            ]
        },
        "url": "URL#915543",
        "sema_paperId": "6829464aef98372915cedb96d50a033224cbf572"
    },
    {
        "@score": "1",
        "@id": "915544",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "172/4550-1",
                        "text": "Zhiyuan Yu 0001"
                    },
                    {
                        "@pid": "332/3084",
                        "text": "Yuanhaur Chang"
                    },
                    {
                        "@pid": "336/4249",
                        "text": "Shixuan Zhai"
                    },
                    {
                        "@pid": "353/7663",
                        "text": "Nicholas Deily"
                    },
                    {
                        "@pid": "16/2529",
                        "text": "Tao Ju"
                    },
                    {
                        "@pid": "06/6268",
                        "text": "XiaoFeng Wang 0001"
                    },
                    {
                        "@pid": "353/7518",
                        "text": "Uday Jammalamadaka"
                    },
                    {
                        "@pid": "181/2597-17",
                        "text": "Ning Zhang 0017"
                    }
                ]
            },
            "title": "XCheck: Verifying Integrity of 3D Printed Patient-Specific Devices via Computing Tomography.",
            "venue": "USENIX Security Symposium",
            "pages": "2815-2832",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YuCZDJ0J023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/yu-zhiyuan-xcheck",
            "url": "https://dblp.org/rec/conf/uss/YuCZDJ0J023",
            "abstract": "3D printing is bringing revolutionary changes to the field of medicine, with applications ranging from hearing aids to regrowing organs. As our society increasingly relies on this technology to save lives, the security of these systems is a growing concern. However, existing defense approaches that leverage side channels may require domain knowledge from computer security to fully understand the impact of the attack.\nTo bridge the gap, we propose XCheck, which leverages medical imaging to verify the integrity of the printed patient-specific device (PSD). XCheck follows a defense-in-depth approach and directly compares the computed tomography (CT) scan of the printed device to its original design. XCheck utilizes a voxel-based approach to build multiple layers of defense involving both 3D geometric verification and multivariate material analysis. To further enhance usability, XCheck also provides an adjustable visualization scheme that allows practitioners' inspection of the printed object with varying tolerance thresholds to meet the needs of different applications. We evaluated the system with 47 PSDs representing different medical applications to validate the efficacy.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-yu-zhiyuan-xcheck.pdf",
            "keywords": [
                "3D Printing",
                "Medical Imaging",
                "Patient-Specific Devices",
                "Integrity Verification",
                "Computed Tomography (CT)"
            ]
        },
        "url": "URL#915544"
    },
    {
        "@score": "1",
        "@id": "915545",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "218/6153",
                        "text": "Jiyong Yu"
                    },
                    {
                        "@pid": "353/7654",
                        "text": "Aishani Dutta"
                    },
                    {
                        "@pid": "45/576",
                        "text": "Trent Jaeger"
                    },
                    {
                        "@pid": "131/5093",
                        "text": "David Kohlbrenner"
                    },
                    {
                        "@pid": "25/8166",
                        "text": "Christopher W. Fletcher"
                    }
                ]
            },
            "title": "Synchronization Storage Channels (S2C): Timer-less Cache Side-Channel Attacks on the Apple M1 via Hardware Synchronization Instructions.",
            "venue": "USENIX Security Symposium",
            "pages": "1973-1990",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YuDJKF23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/yu-jiyong",
            "url": "https://dblp.org/rec/conf/uss/YuDJKF23",
            "abstract": "Shared caches have been a prime target for mounting cross-process/core side-channel attacks. Fundamentally, these attacks require a mechanism to accurately observe changes in cache state. Most cache attacks rely on timing measurements to indirectly infer cache state changes, and attack success hinges on the reliability/availability of accurate timing sources. Far fewer techniques have been proposed to directly observe cache state changes without reliance on timers. Further, none of said \u2018timer-less\u2019 techniques are accessible to userspace attackers targeting modern CPUs. This paper proposes a novel technique for mounting timer-less cache attacks targeting Apple M1 CPUs named Synchronization Storage Channels (S 2 C). The key observation is that the implementation of synchronization instructions, specifically Load-Linked/Store-Conditional (LL/SC), makes architectural state changes when L1 cache evictions occur. This by itself is a useful starting point for attacks, however faces multiple technical challenges when being used to perpetrate cross-core cache attacks. Specifically, LL/SC only observes L1 evictions (not shared L2 cache evictions). Further, each attacker thread can only simultaneously monitor one address at a time through LL/SC (as opposed to many). We propose a suite of techniques and reverse engineering to overcome these limitations, and demonstrate how a single-threaded userspace attacker can use LL/SC to simultaneously monitor multiple (up to 11) victim L2 sets and succeed at standard cache-attack applications, such as breaking cryptographic implementations and constructing covert channels.",
            "keywords": [
                "Cache Side-Channel Attacks",
                "Apple M1",
                "Synchronization Instructions",
                "Timer-less Techniques",
                "Load-Linked/Store-Conditional (LL/SC)"
            ]
        },
        "url": "URL#915545",
        "sema_paperId": "54d59d89046cc4597726f374ecb239957ac82a66"
    },
    {
        "@score": "1",
        "@id": "915546",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "276/6842",
                        "text": "Jason Zhijingcheng Yu"
                    },
                    {
                        "@pid": "165/2801",
                        "text": "Conrad Watt"
                    },
                    {
                        "@pid": "341/1481",
                        "text": "Aditya Badole"
                    },
                    {
                        "@pid": "37/10441",
                        "text": "Trevor E. Carlson"
                    },
                    {
                        "@pid": "90/105",
                        "text": "Prateek Saxena"
                    }
                ]
            },
            "title": "Capstone: A Capability-based Foundation for Trustless Secure Memory Access.",
            "venue": "USENIX Security Symposium",
            "pages": "787-804",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YuWBCS23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/yu-jason",
            "url": "https://dblp.org/rec/conf/uss/YuWBCS23",
            "abstract": "Capability-based memory isolation is a promising new architectural primitive. Software can access low-level memory only via capability handles rather than raw pointers, which provides a natural interface to enforce security restrictions. Existing architectural capability designs such as CHERI provide spatial safety, but fail to extend to other memory models that security-sensitive software designs may desire. In this paper, we propose Capstone, a more expressive architectural capability design that supports multiple existing memory isolation models in a trustless setup, i.e., without relying on trusted software components. We show how Capstone is well-suited for environments where privilege boundaries are fluid (dynamically extensible), memory sharing/delegation are desired both temporally and spatially, and where such needs are to be balanced with availability concerns. Capstone can also be implemented efficiently. We present an implementation sketch and through evaluation show that its overhead is below 50% in common use cases. We also prototype a functional emulator for Capstone and use it to demonstrate the runnable implementations of six real-world memory models without trusted software components: three types of enclave-based TEEs, a thread scheduler, a memory allocator, and Rust-style memory safety -- all within the interface of Capstone.",
            "keywords": [
                "Capability-based Memory Isolation",
                "Trustless Secure Memory Access",
                "Memory Models",
                "Dynamic Privilege Boundaries",
                "Enclave-based TEEs"
            ]
        },
        "url": "URL#915546",
        "sema_paperId": "cfcfebcc497cc7c95db5d4707e81dd56969c3404"
    },
    {
        "@score": "1",
        "@id": "915547",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "295/5277",
                        "text": "Yuanyuan Yuan"
                    },
                    {
                        "@pid": "42/1503-11",
                        "text": "Shuai Wang 0011"
                    },
                    {
                        "@pid": "s/ZhendongSu",
                        "text": "Zhendong Su 0001"
                    }
                ]
            },
            "title": "Precise and Generalized Robustness Certification for Neural Networks.",
            "venue": "USENIX Security Symposium",
            "pages": "4769-4786",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Yuan0023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/yuan-yuanyuan-certification",
            "url": "https://dblp.org/rec/conf/uss/Yuan0023",
            "abstract": "The objective of neural network (NN) robustness certification is to determine if a NN changes its predictions when mutations are made to its inputs. While most certification research studies pixel-level or a few geometrical-level and blurring operations over images, this paper proposes a novel framework, GCERT, which certifies NN robustness under a precise and unified form of diverse semantic-level image mutations. We formulate a comprehensive set of semantic-level image mutations uniformly as certain directions in the latent space of generative models. We identify two key properties, independence and continuity, that convert the latent space into a precise and analysis-friendly input space representation for certification. GCERT can be smoothly integrated with de facto complete, incomplete, or quantitative certification frameworks. With its precise input space representation, GCERT enables for the first time complete NN robustness certification with moderate cost under diverse semantic-level input mutations, such as weather-filter, style transfer, and perceptual changes (e.g., opening/closing eyes). We show that GCERT enables certifying NN robustness under various common and security-sensitive scenarios like autonomous driving.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-yuan-yuanyuan-certification.pdf",
            "keywords": [
                "Neural Network Robustness",
                "Semantic-Level Mutations",
                "Latent Space Representation",
                "Robustness Certification",
                "GCERT Framework"
            ]
        },
        "url": "URL#915547"
    },
    {
        "@score": "1",
        "@id": "915548",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "29/5782",
                        "text": "Quan Yuan"
                    },
                    {
                        "@pid": "90/545-1",
                        "text": "Zhikun Zhang 0001"
                    },
                    {
                        "@pid": "246/4947",
                        "text": "Linkang Du"
                    },
                    {
                        "@pid": "50/6996-32",
                        "text": "Min Chen 0032"
                    },
                    {
                        "@pid": "76/185-1",
                        "text": "Peng Cheng 0001"
                    },
                    {
                        "@pid": "143/6589",
                        "text": "Mingyang Sun"
                    }
                ]
            },
            "title": "PrivGraph: Differentially Private Graph Data Publication by Exploiting Community Information.",
            "venue": "USENIX Security Symposium",
            "pages": "3241-3258",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Yuan0DC0S23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/yuan-quan",
            "url": "https://dblp.org/rec/conf/uss/Yuan0DC0S23",
            "abstract": "Graph data is used in a wide range of applications, while analyzing graph data without protection is prone to privacy breach risks. To mitigate the privacy risks, we resort to the standard technique of differential privacy to publish a synthetic graph. However, existing differentially private graph synthesis approaches either introduce excessive noise by directly perturbing the adjacency matrix, or suffer significant information loss during the graph encoding process. In this paper, we propose an effective graph synthesis algorithm PrivGraph by exploiting the community information. Concretely, PrivGraph differentially privately partitions the private graph into communities, extracts intra-community and inter-community information, and reconstructs the graph from the extracted graph information. We validate the effectiveness of PrivGraph on six real-world graph datasets and seven commonly used graph metrics.",
            "keywords": [
                "Differential Privacy",
                "Graph Synthesis",
                "Community Detection",
                "Privacy Preservation",
                "Graph Data Publication"
            ]
        },
        "url": "URL#915548",
        "sema_paperId": "16714b969a8062b80e6ebc7798192b12336ff0e7"
    },
    {
        "@score": "1",
        "@id": "915549",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "295/5277",
                        "text": "Yuanyuan Yuan"
                    },
                    {
                        "@pid": "193/9286",
                        "text": "Zhibo Liu"
                    },
                    {
                        "@pid": "42/1503-11",
                        "text": "Shuai Wang 0011"
                    }
                ]
            },
            "title": "CacheQL: Quantifying and Localizing Cache Side-Channel Vulnerabilities in Production Software.",
            "venue": "USENIX Security Symposium",
            "pages": "2009-2026",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YuanL023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/yuan-yuanyuan-cacheql",
            "url": "https://dblp.org/rec/conf/uss/YuanL023",
            "abstract": "Cache side-channel attacks extract secrets by examining how victim software accesses cache. To date, practical attacks on cryptosystems and media libraries are demonstrated under different scenarios, inferring secret keys and reconstructing private media data such as images. This work first presents eight criteria for designing a full-fledged detector for cache side-channel vulnerabilities. Then, we propose CacheQL, a novel detector that meets all of these criteria. CacheQL precisely quantifies information leaks of binary code, by characterizing the distinguishability of logged side channel traces. Moreover, CacheQL models leakage as a cooperative game, allowing information leakage to be precisely distributed to program points vulnerable to cache side channels. CacheQL is meticulously optimized to analyze whole side channel traces logged from production software (where each trace can have millions of records), and it alleviates randomness introduced by cryptographic blinding, ORAM, or real-world noises. Our evaluation quantifies side-channel leaks of production cryptographic and media software. We further localize vulnerabilities reported by previous detectors and also identify a few hundred new leakage sites in recent OpenSSL (ver. 3.0.0), MbedTLS (ver. 3.0.0), Libgcrypt (ver. 1.9.4). Many of our localized program points are within the pre-processing modules of cryptosystems, which are not analyzed by existing works due to scalability. We also localize vulnerabilities in Libjpeg (ver. 2.1.2) that leak privacy about input images.",
            "keywords": [
                "Cache Side-Channel Attacks",
                "Information Leakage",
                "Vulnerability Detection",
                "Cryptographic Software",
                "Localizing Vulnerabilities"
            ]
        },
        "url": "URL#915549",
        "sema_paperId": "a52f864a708ca24aebec191284d6148c86839d1b"
    },
    {
        "@score": "1",
        "@id": "915550",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "37/449-3",
                        "text": "Ming Yuan 0003"
                    },
                    {
                        "@pid": "237/1416",
                        "text": "Bodong Zhao"
                    },
                    {
                        "@pid": "81/8013-1",
                        "text": "Penghui Li 0001"
                    },
                    {
                        "@pid": "277/8159",
                        "text": "Jiashuo Liang"
                    },
                    {
                        "@pid": "38/2577",
                        "text": "Xinhui Han"
                    },
                    {
                        "@pid": "53/1565",
                        "text": "Xiapu Luo"
                    },
                    {
                        "@pid": "94/3019-8",
                        "text": "Chao Zhang 0008"
                    }
                ]
            },
            "title": "DDRace: Finding Concurrency UAF Vulnerabilities in Linux Drivers with Directed Fuzzing.",
            "venue": "USENIX Security Symposium",
            "pages": "2849-2866",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YuanZLLHL023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/yuan-ming",
            "url": "https://dblp.org/rec/conf/uss/YuanZLLHL023",
            "abstract": "Concurrency use-after-free (UAF) vulnerabilities account for a large portion of UAF vulnerabilities in Linux drivers. Many solutions have been proposed to find either concurrency bugs or UAF vulnerabilities, but few of them can be directly applied to efficiently find concurrency UAF vulnerabilities. In this paper, we propose the first concurrency directed greybox fuzzing solution DDRace to discover concurrency UAF vulnerabilities efficiently in Linux drivers. First, we identify candidate use-after-free locations as target sites and extract the relevant concurrency elements to reduce the exploration space of directed fuzzing. Second, we design a novel vulnerability-related distance metric and an interleaving priority scheme to guide the fuzzer to better explore UAF vulnerabilities and thread interleavings. Lastly, to make test cases reproducible, we design an adaptive kernel state migration scheme to assist continuous fuzzing. We have implemented a prototype of DDRace, and evaluated it on upstream Linux drivers. Results show that DDRace is effective at discovering concurrency use-after-free vulnerabilities. It finds 4 unknown vulnerabilities and 8 known ones, which is more effective than other state-of-the-art solutions.",
            "keywords": [
                "Concurrency Vulnerabilities",
                "Use-After-Free",
                "Linux Drivers",
                "Directed Fuzzing",
                "Kernel State Migration"
            ]
        },
        "url": "URL#915550",
        "sema_paperId": "ff2fb804ff811306f20163d3c53228349f75f383"
    },
    {
        "@score": "1",
        "@id": "915551",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "41/10614",
                        "text": "Kai Yue"
                    },
                    {
                        "@pid": "194/6950",
                        "text": "Richeng Jin"
                    },
                    {
                        "@pid": "24/10474",
                        "text": "Chau-Wai Wong"
                    },
                    {
                        "@pid": "57/1162",
                        "text": "Dror Baron"
                    },
                    {
                        "@pid": "09/5360",
                        "text": "Huaiyu Dai"
                    }
                ]
            },
            "title": "Gradient Obfuscation Gives a False Sense of Security in Federated Learning.",
            "venue": "USENIX Security Symposium",
            "pages": "6381-6398",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YueJWBD23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/yue",
            "url": "https://dblp.org/rec/conf/uss/YueJWBD23",
            "abstract": "Federated learning has been proposed as a privacy-preserving machine learning framework that enables multiple clients to collaborate without sharing raw data. However, client privacy protection is not guaranteed by design in this framework. Prior work has shown that the gradient sharing strategies in federated learning can be vulnerable to data reconstruction attacks. In practice, though, clients may not transmit raw gradients considering the high communication cost or due to privacy enhancement requirements. Empirical studies have demonstrated that gradient obfuscation, including intentional obfuscation via gradient noise injection and unintentional obfuscation via gradient compression, can provide more privacy protection against reconstruction attacks. In this work, we present a new reconstruction attack framework targeting the image classification task in federated learning. We show how commonly adopted gradient postprocessing procedures, such as gradient quantization, gradient sparsification, and gradient perturbation may give a false sense of security in federated learning. Contrary to prior studies, we argue that privacy enhancement should not be treated as a byproduct of gradient compression. Additionally, we design a new method under the proposed framework to reconstruct images at the semantic level. We quantify the semantic privacy leakage and compare it with conventional image similarity scores. Our comparisons challenge the image data leakage evaluation schemes in the literature. The results emphasize the importance of revisiting and redesigning the privacy protection mechanisms for client data in existing federated learning algorithms.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-yue.pdf",
            "keywords": [
                "Federated Learning",
                "Gradient Obfuscation",
                "Data Reconstruction Attacks",
                "Privacy Protection Mechanisms",
                "Semantic Privacy Leakage"
            ]
        },
        "url": "URL#915551"
    },
    {
        "@score": "1",
        "@id": "915552",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "216/8530",
                        "text": "Thomas Yurek"
                    },
                    {
                        "@pid": "175/1673",
                        "text": "Zhuolun Xiang"
                    },
                    {
                        "@pid": "28/4326-5",
                        "text": "Yu Xia 0005"
                    },
                    {
                        "@pid": "39/1855-1",
                        "text": "Andrew Miller 0001"
                    }
                ]
            },
            "title": "Long Live The Honey Badger: Robust Asynchronous DPSS and its Applications.",
            "venue": "USENIX Security Symposium",
            "pages": "5413-5430",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YurekX0023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/yurek",
            "url": "https://dblp.org/rec/conf/uss/YurekX0023",
            "abstract": "Secret sharing is an essential tool for many distributed applications, including distributed key generation and multiparty computation. For many practical applications, we would like to tolerate network churn, meaning participants can dynamically enter and leave the pool of protocol participants as they please. Such protocols, called Dynamic-committee Proactive Secret Sharing (DPSS) have recently been studied; however, existing DPSS protocols do not gracefully handle faults: the presence of even one unexpectedly slow node can often slow down the whole protocol by a factor of O(n).\nIn this work, we explore optimally fault-tolerant asynchronous DPSS that is not slowed down by crash faults and even handles byzantine faults while maintaining the same performance. We first introduce the first high-threshold DPSS, which offers favorable characteristics relative to prior non-synchronous works in the presence of faults while simultaneously supporting higher privacy thresholds. We then batch-amortize this scheme along with a parallel non-high-threshold scheme which achieves optimal bandwidth characteristics. We implement our schemes and demonstrate that they can compete with prior work in best-case performance while outperforming it in non-optimal settings.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-yurek.pdf",
            "keywords": [
                "Dynamic-committee Proactive Secret Sharing",
                "Asynchronous Protocols",
                "Fault Tolerance",
                "Byzantine Faults",
                "Network Churn"
            ]
        },
        "url": "URL#915552"
    },
    {
        "@score": "1",
        "@id": "915553",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "75/148-5",
                        "text": "Yi Zeng 0005"
                    },
                    {
                        "@pid": "318/1220",
                        "text": "Minzhou Pan"
                    },
                    {
                        "@pid": "331/2669",
                        "text": "Himanshu Jahagirdar"
                    },
                    {
                        "@pid": "34/3870-2",
                        "text": "Ming Jin 0002"
                    },
                    {
                        "@pid": "178/9876",
                        "text": "Lingjuan Lyu"
                    },
                    {
                        "@pid": "147/5355-1",
                        "text": "Ruoxi Jia 0001"
                    }
                ]
            },
            "title": "Meta-Sift: How to Sift Out a Clean Subset in the Presence of Data Poisoning?",
            "venue": "USENIX Security Symposium",
            "pages": "1667-1684",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZengPJ0LJ23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/zeng",
            "url": "https://dblp.org/rec/conf/uss/ZengPJ0LJ23",
            "abstract": "External data sources are increasingly being used to train machine learning (ML) models as the data demand increases. However, the integration of external data into training poses data poisoning risks, where malicious providers manipulate their data to compromise the utility or integrity of the model. Most data poisoning defenses assume access to a set of clean data (referred to as the base set), which could be obtained through trusted sources. But it also becomes common that entire data sources for an ML task are untrusted (e.g., Internet data). In this case, one needs to identify a subset within a contaminated dataset as the base set to support these defenses.\nThis paper starts by examining the performance of defenses when poisoned samples are mistakenly mixed into the base set. We analyze five representative defenses that use base sets and find that their performance deteriorates dramatically with less than 1% poisoned points in the base set. These findings suggest that sifting out a base set with \\emph{high precision} is key to these defenses' performance.\nMotivated by these observations, we study how precise existing automated tools and human inspection are at identifying clean data in the presence of data poisoning. Unfortunately, neither effort achieves the precision needed that enables effective defenses. Worse yet, many of the outcomes of these methods are worse than random selection.\nIn addition to uncovering the challenge, we take a step further and propose a practical countermeasure, Meta-Sift. Our method is based on the insight that existing poisoning attacks shift data distributions, resulting in high prediction loss when training on the clean portion of a poisoned dataset and testing on the corrupted portion. Leveraging the insight, we formulate a bilevel optimization to identify clean data and further introduce a suite of techniques to improve the efficiency and precision of the identification. Our evaluation shows that Meta-Sift can sift a clean base set with 100\\% precision under a wide range of poisoning threats. The selected base set is large enough to give rise to successful defense when plugged into the existing defense techniques.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-zeng.pdf",
            "keywords": [
                "Data Poisoning",
                "Clean Data Identification",
                "Base Set Selection",
                "Meta-Sift",
                "Bilevel Optimization"
            ]
        },
        "url": "URL#915553"
    },
    {
        "@score": "1",
        "@id": "915554",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "29/9985",
                        "text": "Xianglong Zhang"
                    },
                    {
                        "@pid": "35/7092-88",
                        "text": "Wei Wang 0088"
                    },
                    {
                        "@pid": "84/586-3",
                        "text": "Peng Xu 0003"
                    },
                    {
                        "@pid": "y/LaurenceTianruoYang",
                        "text": "Laurence T. Yang"
                    },
                    {
                        "@pid": "126/6037",
                        "text": "Kaitai Liang"
                    }
                ]
            },
            "title": "High Recovery with Fewer Injections: Practical Binary Volumetric Injection Attacks against Dynamic Searchable Encryption.",
            "venue": "USENIX Security Symposium",
            "pages": "5953-5970",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Zhang00YL23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/zhang-xianglong",
            "url": "https://dblp.org/rec/conf/uss/Zhang00YL23",
            "abstract": "Searchable symmetric encryption enables private queries over an encrypted database, but it can also result in information leakages. Adversaries can exploit these leakages to launch injection attacks (Zhang et al., USENIX Security'16) to recover the underlying keywords from queries. The performance of the existing injection attacks is strongly dependent on the amount of leaked information or injection. In this work, we propose two new injection attacks, namely  BVA and BVMA, by leveraging a binary volumetric approach. We enable adversaries to inject fewer files than the existing volumetric attacks by using the known keywords and reveal the queries by observing the volume of the query results. Our attacks can thwart well-studied defenses (e.g., threshold countermeasure, padding) without exploiting the distribution of target queries and client databases. We evaluate the proposed attacks empirically in real-world datasets with practical queries. The results show that our attacks can obtain a high recovery rate (> 80%) in the best-case scenario and a roughly 60% recovery even under a large-scale dataset with a small number of injections (< 20 files).",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-zhang-xianglong.pdf",
            "keywords": [
                "Dynamic Searchable Encryption",
                "Injection Attacks",
                "Information Leakage",
                "Binary Volumetric Approach",
                "Keyword Recovery"
            ]
        },
        "url": "URL#915554"
    },
    {
        "@score": "1",
        "@id": "915555",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "18/2908",
                        "text": "Cong Zhang"
                    },
                    {
                        "@pid": "87/1254-3",
                        "text": "Yu Chen 0003"
                    },
                    {
                        "@pid": "71/10355",
                        "text": "Weiran Liu"
                    },
                    {
                        "@pid": "83/5342",
                        "text": "Min Zhang"
                    },
                    {
                        "@pid": "44/6488",
                        "text": "Dongdai Lin"
                    }
                ]
            },
            "title": "Linear Private Set Union from Multi-Query Reverse Private Membership Test.",
            "venue": "USENIX Security Symposium",
            "pages": "337-354",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Zhang0LZL23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/zhang-cong",
            "url": "https://dblp.org/rec/conf/uss/Zhang0LZL23",
            "abstract": "Private set union (PSU) protocol enables two parties, each holding a set, to compute the union of their sets without revealing anything else to either party. So far, there are two known approaches for constructing PSU protocols. The first mainly depends on additively homomorphic encryption (AHE), which is generally inefficient since it needs to perform a non-constant number of homomorphic computations on each item. The second is mainly based on oblivious transfer and symmetric-key operations, which is recently proposed by Kolesnikov et al. (ASIACRYPT 2019). It features good practical performance, which is several orders of magnitude faster than the first one. However, neither of these two approaches is optimal in the sense that their computation and communication complexity are not both O ( n ) , where n is the size of the set. Therefore, the problem of constructing the optimal PSU protocol remains open. In this work, we resolve this open problem by proposing a generic framework of PSU from oblivious transfer and a newly introduced protocol called multi-query reverse private membership test (mq-RPMT). We present two generic constructions of mq-RPMT. The first is based on symmetric-key encryption and general 2PC techniques. The second is based on re-randomizable public-key encryption. Both constructions lead to PSU with linear computation and communication complexity. We",
            "keywords": [
                "Private Set Union",
                "Oblivious Transfer",
                "Multi-Query Reverse Private Membership Test",
                "Linear Complexity",
                "Secure Computation"
            ]
        },
        "url": "URL#915555",
        "sema_paperId": "f077708611258b2019b54f95bace59f6c725b69c"
    },
    {
        "@score": "1",
        "@id": "915556",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "72/1760-5",
                        "text": "Zhiyuan Zhang 0005"
                    },
                    {
                        "@pid": "b/GBarthe",
                        "text": "Gilles Barthe"
                    },
                    {
                        "@pid": "124/1916",
                        "text": "Chitchanok Chuengsatiansup"
                    },
                    {
                        "@pid": "30/1431",
                        "text": "Peter Schwabe"
                    },
                    {
                        "@pid": "90/10901",
                        "text": "Yuval Yarom"
                    }
                ]
            },
            "title": "Ultimate SLH: Taking Speculative Load Hardening to the Next Level.",
            "venue": "USENIX Security Symposium",
            "pages": "7125-7142",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhangBCSY23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/zhang-zhiyuan-slh",
            "url": "https://dblp.org/rec/conf/uss/ZhangBCSY23",
            "abstract": "In this paper we revisit the Spectre v1 vulnerability and software-only countermeasures. Specifically, we systematically investigate the performance penalty and security properties of multiple variants of speculative load hardening (SLH). As part of this investigation we implement the \u201cstrong SLH\u201d variant by Patrignani and Guarnieri (CCS 2021) as a compiler extension to LLVM. We show that none of the existing variants, including strong SLH, is able to protect against all Spectre v1 attacks in practice. We do this by demonstrating, for the first time, that variable-time arithmetic instructions leak secret information even if they are executed only speculatively. We extend strong SLH to include protections also against this kind of leakage, implement the resulting full protection in LLVM, and use the SPEC2017 benchmarks to compare its performance to the existing variants of SLH and to code that uses fencing instructions to completely prevent speculative execution. We show that our proposed counter-measure offers full protection against Spectre v1 attacks at much better performance than code using fences. In fact, for several benchmarks our approach is more than twice as fast.",
            "keywords": [
                "Speculative Load Hardening",
                "Spectre v1 Vulnerability",
                "Compiler Extension",
                "Performance Evaluation",
                "Security Countermeasures"
            ]
        },
        "url": "URL#915556",
        "sema_paperId": "7050b98176255b686289c8427b901d378a09f3ef"
    },
    {
        "@score": "1",
        "@id": "915557",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "13/5236",
                        "text": "Bin Zhang"
                    },
                    {
                        "@pid": "224/2480",
                        "text": "Jiongyi Chen"
                    },
                    {
                        "@pid": "242/7076",
                        "text": "Runhao Li"
                    },
                    {
                        "@pid": "97/164",
                        "text": "Chao Feng"
                    },
                    {
                        "@pid": "24/7930",
                        "text": "Ruilin Li"
                    },
                    {
                        "@pid": "57/1674",
                        "text": "Chaojing Tang"
                    }
                ]
            },
            "title": "Automated Exploitable Heap Layout Generation for Heap Overflows Through Manipulation Distance-Guided Fuzzing.",
            "venue": "USENIX Security Symposium",
            "pages": "4499-4515",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhangCLFLT23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/zhang-bin",
            "url": "https://dblp.org/rec/conf/uss/ZhangCLFLT23",
            "abstract": "Generating exploitable heap layouts is a fundamental step to produce working exploits for heap overflows. For this purpose, the heap primitives identified from the target program, serving as functional units to manipulate the heap layout, are strategically leveraged to construct exploitable states. To flexibly use primitives, prior efforts only focus on particular program types or programs with dispatcher-loop structures. Beyond that, automatically generating exploitable heap lay-outs is hard for general-purpose programs due to the difficulties in explicitly and flexibly using primitives. This paper presents S CATTER , enabling the generation of exploitable heap layouts for heap overflows in general-purpose programs in a primitive-free manner. At the center of S CATTER is a fuzzer that is guided by a new manipulation distance which measures the distance to the corruption of a victim object in the heap layout space. To make the fuzzing-based approach practical, S CATTER leverages a set of techniques to improve the efficiency and handle the side effects introduced by the heap manager\u2019s sophisticated behaviors in the real-world environment. Our evaluation demonstrates that S CATTER can successfully generate a total of 126 ex-ploitable heap layouts for 18 out of 27 heap overflows in 10 general-purpose programs.",
            "keywords": [
                "Heap Overflow",
                "Exploitable Heap Layouts",
                "Fuzzing",
                "Manipulation Distance",
                "Heap Manager"
            ]
        },
        "url": "URL#915557",
        "sema_paperId": "7a38d41d7e24cc6160e1298dd6d5ef74e0a06e47"
    },
    {
        "@score": "1",
        "@id": "915558",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "35/1541",
                        "text": "Shibo Zhang"
                    },
                    {
                        "@pid": "63/4074",
                        "text": "Yushi Cheng"
                    },
                    {
                        "@pid": "83/4183",
                        "text": "Wenjun Zhu"
                    },
                    {
                        "@pid": "39/1697-1",
                        "text": "Xiaoyu Ji 0001"
                    },
                    {
                        "@pid": "10/3878-1",
                        "text": "Wenyuan Xu 0001"
                    }
                ]
            },
            "title": "CAPatch: Physical Adversarial Patch against Image Captioning Systems.",
            "venue": "USENIX Security Symposium",
            "pages": "679-696",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhangCZ0023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/zhang-shibo",
            "url": "https://dblp.org/rec/conf/uss/ZhangCZ0023",
            "abstract": "The fast-growing surveillance systems will make image captioning, i.e., automatically generating text descriptions of images, an essential technique to process the huge volumes of videos efficiently, and correct captioning is essential to ensure the text authenticity. While prior work has demonstrated the feasibility of fooling computer vision models with adversarial patches, it is unclear whether the vulnerability can lead to incorrect captioning, which involves natural language processing after image feature extraction. In this paper, we design CAPatch, a physical adversarial patch that can result in mistakes in the final captions, i.e., either create a completely different sentence or a sentence with keywords missing, against multi-modal image captioning systems. To make CAPatch effective and practical in the physical world, we propose a detection assurance and attention enhancement method to increase the impact of CAPatch and a robustness improvement method to address the patch distortions caused by image printing and capturing. Evaluations on three commonly-used image captioning systems (Show-and-Tell, Self-critical Sequence Training: Att2in, and Bottom-up Top-down) demonstrate the effectiveness of CAPatch in both the digital and physical worlds, whereby volunteers wear printed patches in various scenarios, clothes, lighting conditions. With a size of 5% of the image, physically-printed CAPatch can achieve continuous attacks with an attack success rate higher than 73.1% over a video recorder.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-zhang-shibo.pdf",
            "keywords": [
                "Image Captioning",
                "Adversarial Attacks",
                "Physical Adversarial Patch",
                "Multi-modal Systems",
                "Captioning Vulnerability"
            ]
        },
        "url": "URL#915558"
    },
    {
        "@score": "1",
        "@id": "915559",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "10/239",
                        "text": "Jiawei Zhang"
                    },
                    {
                        "@pid": "297/5403",
                        "text": "Zhongzhu Chen"
                    },
                    {
                        "@pid": "23/1797-1",
                        "text": "Huan Zhang 0001"
                    },
                    {
                        "@pid": "150/3317",
                        "text": "Chaowei Xiao"
                    },
                    {
                        "@pid": "50/3402-26",
                        "text": "Bo Li 0026"
                    }
                ]
            },
            "title": "DiffSmooth: Certifiably Robust Learning via Diffusion Models and Local Smoothing.",
            "venue": "USENIX Security Symposium",
            "pages": "4787-4804",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhangCZX023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/zhang-jiawei",
            "url": "https://dblp.org/rec/conf/uss/ZhangCZX023",
            "abstract": "Diffusion models have been leveraged to perform adversarial purification and thus provide both empirical and certified robustness for a standard  model. On the other hand, different robustly trained smoothed  models have been studied to improve the certified robustness. Thus, it raises a natural question: Can diffusion model be used to achieve improved certified robustness on those robustly trained smoothed models?  In this work, we first theoretically show that recovered instances by diffusion models are in the bounded neighborhood of the original instance with high probability; and the \"one-shot\" denoising diffusion probabilistic models (DDPM) can approximate the mean of the generated distribution of a continuous-time diffusion model, which approximates the original instance under mild conditions. Inspired by our analysis, we propose a certifiably robust pipeline DiffSmooth, which first performs adversarial purification via diffusion models and then maps the purified instances to a common region via a simple yet effective local smoothing  strategy. We conduct extensive experiments on different datasets and show that DiffSmooth achieves SOTA-certified robustness compared with eight baselines. For instance, DiffSmooth improves the SOTA-certified accuracy from 36.0% to 53.0% under \u21132 radius 1.5 on ImageNet.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-zhang-jiawei.pdf",
            "keywords": [
                "Diffusion Models",
                "Certified Robustness",
                "Adversarial Purification",
                "Local Smoothing",
                "SOTA-Certified Accuracy"
            ]
        },
        "url": "URL#915559"
    },
    {
        "@score": "1",
        "@id": "915560",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "22/1887",
                        "text": "Haibin Zhang"
                    },
                    {
                        "@pid": "146/0078",
                        "text": "Sisi Duan"
                    },
                    {
                        "@pid": "153/7633",
                        "text": "Boxin Zhao"
                    },
                    {
                        "@pid": "26/2546",
                        "text": "Liehuang Zhu"
                    }
                ]
            },
            "title": "WaterBear: Practical Asynchronous BFT Matching Security Guarantees of Partially Synchronous BFT.",
            "venue": "USENIX Security Symposium",
            "pages": "5341-5357",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhangDZZ23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/zhang-haibin",
            "url": "https://dblp.org/rec/conf/uss/ZhangDZZ23",
            "abstract": "Asynchronous Byzantine fault-tolerant (BFT) protocols assuming no timing assumptions are inherently more robust than their partially synchronous counterparts, but typically have much weaker security guarantees. We design and implement WaterBear, a family of new and efficient asynchronous BFT protocols matching all security guarantees of partially synchronous protocols. To achieve the goal, we have developed the local coin (flipping a coin locally and independently at each replica) based BFT approach\u2014one long deemed as being inefficient\u2014and designed more efficient asynchronous binary agreement (ABA) protocols and their reproposable ABA (RABA) versions from local coins. Our techniques on ABA and RABA are of independent interests and also allow us to build more efficient ABA protocols from common coins (distributively generating the same random coins for all replicas), helping improve various other protocols such as distributed key generation and BFT assuming trusted setup. We implemented in total five BFT protocols in a new golang library, including four WaterBear protocols and BEAT. Via extensive evaluation, we show that our protocols are efficient under both failure-free and failure scenarios, achieving at least comparable or superior performance to BEAT with much weaker security guarantees. Specifically, the most efficient WaterBear protocol consistently outperforms BEAT in terms of all metrics. For instance, when the number of replicas is 16, the latency of our protocol is about 1/8 of that of BEAT and the throughput of our protocol is 1.23x that of BEAT. Our work",
            "keywords": [
                "Asynchronous Byzantine Fault Tolerance",
                "Partially Synchronous Protocols",
                "Local Coin",
                "Asynchronous Binary Agreement",
                "Performance Evaluation"
            ]
        },
        "url": "URL#915560",
        "sema_paperId": "8076dcd68fad9e4a9e0166137bf2f3082c30137c"
    },
    {
        "@score": "1",
        "@id": "915561",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "76/5416",
                        "text": "Yiming Zhang"
                    },
                    {
                        "@pid": "153/1929",
                        "text": "Yuxin Hu"
                    },
                    {
                        "@pid": "47/8535",
                        "text": "Zhenyu Ning"
                    },
                    {
                        "@pid": "20/11242",
                        "text": "Fengwei Zhang"
                    },
                    {
                        "@pid": "53/1565",
                        "text": "Xiapu Luo"
                    },
                    {
                        "@pid": "248/7736",
                        "text": "Haoyang Huang"
                    },
                    {
                        "@pid": "08/6611",
                        "text": "Shoumeng Yan"
                    },
                    {
                        "@pid": "79/7449",
                        "text": "Zhengyu He"
                    }
                ]
            },
            "title": "SHELTER: Extending Arm CCA with Isolation in User Space.",
            "venue": "USENIX Security Symposium",
            "pages": "6257-6274",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhangHNZLHYH23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/zhang-yiming",
            "url": "https://dblp.org/rec/conf/uss/ZhangHNZLHYH23",
            "abstract": "The increasing adoption of confidential computing is providing individual users with a more seamless interaction with numerous mobile and server devices. TrustZone is a promis-ing security technology for the use of partitioning sensitive private data into a trusted execution environment (TEE). Un-fortunately, third-party developers have limited accessibility to TrustZone. This is because TEE vendors need to validate such security applications to preserve their security rigorously. Moreover, TrustZone-based systems suffer from vulnerabilities affecting Trusted App and trusted OS, possibly causing the entire system to be compromised.",
            "keywords": [
                "Confidential Computing",
                "Trusted Execution Environment",
                "TrustZone",
                "Security Vulnerabilities",
                "Trusted App Isolation"
            ]
        },
        "url": "URL#915561",
        "sema_paperId": "70f3c6a0d41069c6f369377bf2e2c250422e8bdc"
    },
    {
        "@score": "1",
        "@id": "915562",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "34/10139",
                        "text": "Boyang Zhang"
                    },
                    {
                        "@pid": "227/7262-1",
                        "text": "Xinlei He 0001"
                    },
                    {
                        "@pid": "14/4412",
                        "text": "Yun Shen"
                    },
                    {
                        "@pid": "145/3288-1",
                        "text": "Tianhao Wang 0001"
                    },
                    {
                        "@pid": "06/6785-16",
                        "text": "Yang Zhang 0016"
                    }
                ]
            },
            "title": "A Plot is Worth a Thousand Words: Model Information Stealing Attacks via Scientific Plots.",
            "venue": "USENIX Security Symposium",
            "pages": "5289-5306",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhangHS0023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/zhang-boyang",
            "url": "https://dblp.org/rec/conf/uss/ZhangHS0023",
            "abstract": "Building advanced machine learning (ML) models requires expert knowledge and many trials to discover the best architecture and hyperparameter settings. Previous work demonstrates that model information can be leveraged to assist other attacks, such as membership inference, generating adversarial examples. Therefore, such information, e.g., hyperparameters, should be kept confidential. It is well known that an adversary can leverage a target ML model's output to steal the model's information. In this paper, we discover a new side channel for model information stealing attacks, i.e., models' scientific plots which are extensively used to demonstrate model performance and are easily accessible. Our attack is simple and straightforward. We leverage the shadow model training techniques to generate training data for the attack model which is essentially an image classifier. Extensive evaluation on three benchmark datasets shows that our proposed attack can effectively infer the architecture/hyperparameters of image classifiers based on convolutional neural network (CNN) given the scientific plot generated from it. We also reveal that the attack's success is mainly caused by the shape of the scientific plots, and further demonstrate that the attacks are robust in various scenarios. Given the simplicity and effectiveness of the attack method, our study indicates scientific plots indeed constitute a valid side channel for model information stealing attacks. To mitigate the attacks, we propose several defense mechanisms that can reduce the original attacks' accuracy while maintaining the plot utility. However, such defenses can still be bypassed by adaptive attacks.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-zhang-boyang.pdf",
            "keywords": [
                "Model Information Theft",
                "Scientific Plots",
                "Hyperparameter Inference",
                "Convolutional Neural Networks",
                "Attack Defense Mechanisms"
            ]
        },
        "url": "URL#915562"
    },
    {
        "@score": "1",
        "@id": "915563",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "08/7975",
                        "text": "Ruiyi Zhang"
                    },
                    {
                        "@pid": "86/2584",
                        "text": "Taehyun Kim"
                    },
                    {
                        "@pid": "04/5465-7",
                        "text": "Daniel Weber 0007"
                    },
                    {
                        "@pid": "08/1117-1",
                        "text": "Michael Schwarz 0001"
                    }
                ]
            },
            "title": "(M)WAIT for It: Bridging the Gap between Microarchitectural and Architectural Side Channels.",
            "venue": "USENIX Security Symposium",
            "pages": "7267-7284",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhangK0023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/zhang-ruiyi",
            "url": "https://dblp.org/rec/conf/uss/ZhangK0023",
            "abstract": "In the last years, there has been a rapid increase in microarchitectural attacks, exploiting side effects of various parts of the CPU. Most of them have in common that they rely on timing differences, requiring an architectural high-resolution timer to make microarchitectural states visible to an attacker. In this paper, we present a new primitive that converts microarchitectural states into architectural states without relying on time measurements. We exploit the unprivileged idle-loop optimization instructions umonitor and umwait introduced with the new Intel microarchitectures (Tremont and Alder Lake). Although not documented, these instructions provide architectural feedback about the transient usage of a speci\ufb01ed memory region. In three case studies, we show the versatility of our primitive. First, with Spectral, we present a way of enabling transient-execution attacks to leak bits architecturally with up to 200 kbit / s without requiring any architectural timer. Second, we show traditional side-channel attacks without relying on an architectural timer. Finally, we demonstrate that when augmented with a coarse-grained timer, we can also mount interrupt-timing attacks, allowing us to, e.g., detect which website a user opens. Our case studies highlight that the boundary between architecture and microarchitecture becomes more and more blurry, leading to new attack variants and complicating effective countermeasures.",
            "keywords": [
                "Microarchitectural Attacks",
                "Side Channels",
                "Architectural States",
                "Transient Execution",
                "Idle-loop Optimization"
            ]
        },
        "url": "URL#915563",
        "sema_paperId": "67c0d43990829687fa71459511fede93563bf2e7"
    },
    {
        "@score": "1",
        "@id": "915564",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "200/7275",
                        "text": "Cen Zhang"
                    },
                    {
                        "@pid": "204/3729",
                        "text": "Yuekang Li"
                    },
                    {
                        "@pid": "63/778-9",
                        "text": "Hao Zhou 0009"
                    },
                    {
                        "@pid": "96/6053",
                        "text": "Xiaohan Zhang"
                    },
                    {
                        "@pid": "190/2868",
                        "text": "Yaowen Zheng"
                    },
                    {
                        "@pid": "154/0904",
                        "text": "Xian Zhan"
                    },
                    {
                        "@pid": "127/0713",
                        "text": "Xiaofei Xie"
                    },
                    {
                        "@pid": "53/1565",
                        "text": "Xiapu Luo"
                    },
                    {
                        "@pid": "72/3476-1",
                        "text": "Xinghua Li 0001"
                    },
                    {
                        "@pid": "51/3710-3",
                        "text": "Yang Liu 0003"
                    },
                    {
                        "@pid": "18/8079",
                        "text": "Sheikh Mahbub Habib"
                    }
                ]
            },
            "title": "Automata-Guided Control-Flow-Sensitive Fuzz Driver Generation.",
            "venue": "USENIX Security Symposium",
            "pages": "2867-2884",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhangLZZZZXLL0H23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/zhang-cen",
            "url": "https://dblp.org/rec/conf/uss/ZhangLZZZZXLL0H23",
            "abstract": "Fuzz drivers are essential for fuzzing library APIs. However, manually composing fuzz drivers is difficult and time-consuming. Therefore, several works have been proposed to generate fuzz drivers automatically. Although these works can learn correct API usage from the consumer programs of the target library, three challenges still hinder the quality of the generated fuzz drivers: 1) How to learn and utilize the control dependencies in API usage; 2) How to handle the noises of the learned API usage, especially for complex real-world consumer programs; 3) How to organize independent sets of API usage inside the fuzz driver to better coordinate with fuzzers.\nTo solve these challenges, we propose RUBICK, an automata-guided control-flow-sensitive fuzz driver generation technique. RUBICK has three key features: 1) it models the API usage (including API data and control dependencies) as a deterministic finite automaton; 2) it leverages active automata learning algorithm to distill the learned API usage; 3) it synthesizes a single automata-guided fuzz driver, which provides scheduling interface for the fuzzer to test independent sets of API usage during fuzzing. During the experiments, the fuzz drivers generated by RUBICK showed a significant performance advantage over the baselines by covering an average of 50.42% more edges than fuzz drivers generated by FUZZGEN and 44.58% more edges than manually written fuzz drivers from OSS-Fuzz or human experts. By learning from large-scale open source projects, RUBICK has generated fuzz drivers for 11 popular Java projects and two of them have been merged into OSS-Fuzz. So far, 199 bugs, including four CVEs, are found using these fuzz drivers, which can affect popular PC and Android software with dozens of millions of downloads.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-zhang-cen.pdf",
            "keywords": [
                "Fuzz Driver Generation",
                "Automata Learning",
                "Control Flow Sensitivity",
                "API Usage Modeling",
                "Fuzzing Techniques"
            ]
        },
        "url": "URL#915564",
        "sema_paperId": "419f776c2edb013cdc8c1035e29ad561922701f5"
    },
    {
        "@score": "1",
        "@id": "915565",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "186/7504",
                        "text": "Yicheng Zhang"
                    },
                    {
                        "@pid": "252/4834",
                        "text": "Carter Slocum"
                    },
                    {
                        "@pid": "35/9005",
                        "text": "Jiasi Chen"
                    },
                    {
                        "@pid": "86/2654",
                        "text": "Nael B. Abu-Ghazaleh"
                    }
                ]
            },
            "title": "It&apos;s all in your head(set): Side-channel attacks on AR/VR systems.",
            "venue": "USENIX Security Symposium",
            "pages": "3979-3996",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhangSCA23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/zhang-yicheng",
            "url": "https://dblp.org/rec/conf/uss/ZhangSCA23",
            "abstract": "With the increasing adoption of Augmented Reality/Virtual Reality (AR/VR) systems, security and privacy concerns attract attention from both academia and industry. This paper demonstrates that AR/VR systems are vulnerable to side-channel attacks launched from software; a malicious application without any special permissions can infer private information about user interactions, other concurrent applications, or even the surrounding world. We develop a number of side-channel attacks targeting different types of private information. Specifically, we demonstrate three attacks on the victim\u2019s interactions, successfully recovering hand gestures, voice commands made by victims, and keystrokes on a virtual keyboard, with accuracy exceeding 90%. We also demonstrate an application fingerprinting attack where the spy is able to identify an application being launched by the victim. The final attack demonstrates that the adversary can perceive a bystander in the real-world environment and estimate the bystander\u2019s distance with Mean Absolute Error (MAE) of 10.3 cm. We believe the threats presented by our attacks are pressing; they expand our understanding of the threat model faced by these emerging systems and inform the development of new AR/VR systems that are resistant to these threats.",
            "keywords": [
                "Augmented Reality",
                "Virtual Reality",
                "Side-Channel Attacks",
                "User Interaction Privacy",
                "Application Fingerprinting"
            ]
        },
        "url": "URL#915565",
        "sema_paperId": "2ba76bb929a1533951a09b349ea1c7f248e06c17"
    },
    {
        "@score": "1",
        "@id": "915566",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "72/1760-5",
                        "text": "Zhiyuan Zhang 0005"
                    },
                    {
                        "@pid": "353/7670",
                        "text": "Mingtian Tao"
                    },
                    {
                        "@pid": "207/7931",
                        "text": "Sioli O&apos;Connell"
                    },
                    {
                        "@pid": "124/1916",
                        "text": "Chitchanok Chuengsatiansup"
                    },
                    {
                        "@pid": "98/8283",
                        "text": "Daniel Genkin"
                    },
                    {
                        "@pid": "90/10901",
                        "text": "Yuval Yarom"
                    }
                ]
            },
            "title": "BunnyHop: Exploiting the Instruction Prefetcher.",
            "venue": "USENIX Security Symposium",
            "pages": "7321-7337",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhangTOCGY23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/zhang-zhiyuan-bunnyhop",
            "url": "https://dblp.org/rec/conf/uss/ZhangTOCGY23",
            "abstract": "The instruction prefetcher is a microarchitectural component whose task is to bring program code into the instruction cache. To predict which code is likely to be executed, the instruction prefetcher relies on the branch predictor.\nIn this paper we investigate the instruction prefetcher in modern Intel processors. We first propose BunnyHop, a technique that uses the instruction prefetcher to encode branch prediction information as a cache state. We show how to use BunnyHop to perform low-noise attacks on the branch predictor. Specifically, we show how to implement attacks similar to Flush+Reload and Prime+Probe on the branch predictor instead of on the data caches. We then show that BunnyHop allows using the instruction prefetcher as a confused deputy to force cache eviction within a victim. We use this to demonstrate an attack on an implementation of AES protected with both cache coloring and data prefetch.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-zhang-zhiyuan-bunnyhop.pdf",
            "keywords": [
                "Instruction Prefetcher",
                "Branch Prediction",
                "Cache Eviction",
                "Microarchitectural Attacks",
                "AES Implementation Attack"
            ]
        },
        "url": "URL#915566"
    },
    {
        "@score": "1",
        "@id": "915567",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "24/10828",
                        "text": "Yuxing Zhang"
                    },
                    {
                        "@pid": "171/2501",
                        "text": "Xiaogang Zhu 0001"
                    },
                    {
                        "@pid": "60/7270",
                        "text": "Daojing He"
                    },
                    {
                        "@pid": "166/1912",
                        "text": "Minhui Xue 0001"
                    },
                    {
                        "@pid": "07/8388",
                        "text": "Shouling Ji"
                    },
                    {
                        "@pid": "02/4828",
                        "text": "Mohammad Sayad Haghighi"
                    },
                    {
                        "@pid": "41/3095",
                        "text": "Sheng Wen"
                    },
                    {
                        "@pid": "140/5462",
                        "text": "Zhiniang Peng"
                    }
                ]
            },
            "title": "Detecting Union Type Confusion in Component Object Model.",
            "venue": "USENIX Security Symposium",
            "pages": "4265-4281",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhangZHXJHWP23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/zhang-yuxing",
            "url": "https://dblp.org/rec/conf/uss/ZhangZHXJHWP23",
            "abstract": "Component Object Model (COM) is a binary-interface standard for software components introduced by Microsoft in 1993. Thirty years after its first release, COM is still the basis to support many other core technologies of Microsoft. COM developers used many unions rather than structs in the coding to conserve memory in legacy computers. However, the excessive use of union architecture will most likely introduce type confusion vulnerabilities that can be taken advantage of by 100%-reliable exploits. According to our studies, the problem of union type confusion has long been overlooked and no solutions have been developed for off-the-shelf systems that employ COM. In this paper, we propose COMFUSION, the first tool that detects union type confusion in COM. The crux is to infer union variables and their discriminants in COM binaries. This is challenging since existing type recovery techniques do not support union type in binaries. To resolve this problem, COMFUSION identifies union variables through taint propagation with the help of Microsoft Interface Definition Language (MIDL) files and then searches for union type confusion via symbolic execution. We evaluate COMFUSION on three popular releases of Windows operating system, including Windows 10 1809, Windows 10 21H2, and Windows 11 21H2. COMFUSION successfully found 36 union type confusions. Out of these, 19 type confusions have been confirmed to be capable of corrupting memory, exposing 4 confirmed CVEs.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-zhang-yuxing.pdf",
            "keywords": [
                "Component Object Model",
                "Union Type Confusion",
                "Type Confusion Vulnerabilities",
                "Memory Corruption",
                "COMFUSION Tool"
            ]
        },
        "url": "URL#915567",
        "sema_paperId": "a31d5944927b32478788208db0cd79418e9d35ec"
    },
    {
        "@score": "1",
        "@id": "915568",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "44/2817",
                        "text": "Yudi Zhao"
                    },
                    {
                        "@pid": "48/2168-9",
                        "text": "Yuan Zhang 0009"
                    },
                    {
                        "@pid": "02/1640-2",
                        "text": "Min Yang 0002"
                    }
                ]
            },
            "title": "Remote Code Execution from SSTI in the Sandbox: Automatically Detecting and Exploiting Template Escape Bugs.",
            "venue": "USENIX Security Symposium",
            "pages": "3691-3708",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Zhao0023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/zhao-yudi",
            "url": "https://dblp.org/rec/conf/uss/Zhao0023",
            "abstract": "Template engines are widely used in web applications to ease the development of user interfaces. The powerful capabilities provided by the template engines can be abused by attackers through server-side template injection (SSTI), enabling severe attacks on the server side, including remote code execution (RCE). Hence, modern template engines have provided a sandbox mode to prevent SSTI attacks from RCE. In this paper, we study an overlooked sandbox bypass vulnerability in template engines, called template escape, that could elevate SSTI attacks to RCE. By escaping the template rendering process, template escape bugs can be used to inject executable code on the server side. Template escape bugs are subtle to detect and exploit, due to their dependencies on the template syntax and the template rendering logic. Consequently, little knowledge is known about their prevalence and severity in the real world. To this end, we conduct the first in-depth study on template escape bugs and present TEF UZZ , an automatic tool to detect and exploit such bugs. By incorporating several new techniques, TEF UZZ does not need to learn the template syntax and can generate PoCs and exploits for the discovered bugs. We apply TEF UZZ to seven popular PHP template engines. In all, TEF UZZ discovers 135 new template escape bugs and synthesizes RCE exploits for 55 bugs. Our study shows that template escape bugs are prevalent and pose severe threats.",
            "keywords": [
                "Server-Side Template Injection",
                "Template Escape",
                "Remote Code Execution",
                "Vulnerability Detection",
                "Exploitation Techniques"
            ]
        },
        "url": "URL#915568",
        "sema_paperId": "9210d71913ec9de42812d900c017bbbc1c997f91"
    },
    {
        "@score": "1",
        "@id": "915569",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "79/7820",
                        "text": "Binbin Zhao"
                    },
                    {
                        "@pid": "07/8388",
                        "text": "Shouling Ji"
                    },
                    {
                        "@pid": "139/6932-2",
                        "text": "Xuhong Zhang 0002"
                    },
                    {
                        "@pid": "39/5423-1",
                        "text": "Yuan Tian 0001"
                    },
                    {
                        "@pid": "156/1247",
                        "text": "Qinying Wang"
                    },
                    {
                        "@pid": "220/9652",
                        "text": "Yuwen Pu"
                    },
                    {
                        "@pid": "248/1663",
                        "text": "Chenyang Lyu"
                    },
                    {
                        "@pid": "12/6354",
                        "text": "Raheem Beyah"
                    }
                ]
            },
            "title": "UVSCAN: Detecting Third-Party Component Usage Violations in IoT Firmware.",
            "venue": "USENIX Security Symposium",
            "pages": "3421-3438",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhaoJ00WPLB23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/zhao-binbin",
            "url": "https://dblp.org/rec/conf/uss/ZhaoJ00WPLB23",
            "abstract": "Nowadays, IoT devices integrate a wealth of third-party components (TPCs) in firmware to shorten the development cycle. TPCs usually have strict usage specifications, e.g., checking the return value of the function. Violating the usage specifications of TPCs can cause serious consequences, e.g., NULL pointer dereference. Therefore, this massive amount of TPC integrations, if not properly implemented, will lead to pervasive vulnerabilities in IoT devices. Detecting vulnerabilities automatically in TPC integration is challenging from several perspectives: (1) There is a gap between the high-level specifications from TPC documents, and the low-level implementations in the IoT firmware. (2) IoT firmware is mostly the closed-source binary, which loses a lot of information when compiling from the source code and has diverse architectures.To address these challenges, we design and implement UVScan, an automated and scalable system to detect TPC usage violations in IoT firmware. In UVScan, we first propose a novel natural language processing (NLP)-based rule extraction framework, which extracts API specifications from inconsistently formatted TPC documents. We then design a rule-driven NLP-guided binary analysis engine, which maps the logical information from the high-level TPC document to the low-level binary, and detects TPC usage violations in IoT firmware across different architectures. We evaluate UVScan from four perspectives on four popular TPCs and six ground-truth datasets. The results show that UVScan achieves more than 70% precision and recall, and has a significant performance improvement compared with even the source-level API misuse detectors. To provide an in-depth status quo understanding of the TPC usage violation problem in IoT firmware, we conduct a large-scale analysis on 4,545 firmware images and detect 27,621 usage violations. Our further case studies, the Denial-of-Service attack and the Man-In-The-Middle attack on several firmware images, demonstrate the serious risks of TPC usage violations. Currently, 206 usage violations have been confirmed by vendors as vulnerabilities, and seven of them have been assigned CVE IDs with high severity.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-zhao-binbin.pdf",
            "keywords": [
                "IoT Firmware Security",
                "Third-Party Components",
                "Usage Violations",
                "Vulnerability Detection",
                "Automated Analysis"
            ]
        },
        "url": "URL#915569"
    },
    {
        "@score": "1",
        "@id": "915570",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "75/1424",
                        "text": "Han Zheng"
                    },
                    {
                        "@pid": "24/7579",
                        "text": "Jiayuan Zhang"
                    },
                    {
                        "@pid": "211/9469",
                        "text": "Yuhang Huang"
                    },
                    {
                        "@pid": "325/5000",
                        "text": "Zezhong Ren"
                    },
                    {
                        "@pid": "01/6368-14",
                        "text": "He Wang 0014"
                    },
                    {
                        "@pid": "05/9205",
                        "text": "Chunjie Cao"
                    },
                    {
                        "@pid": "83/6530-1",
                        "text": "Yuqing Zhang 0001"
                    },
                    {
                        "@pid": "88/9958",
                        "text": "Flavio Toffalini"
                    },
                    {
                        "@pid": "31/1273",
                        "text": "Mathias Payer"
                    }
                ]
            },
            "title": "FISHFUZZ: Catch Deeper Bugs by Throwing Larger Nets.",
            "venue": "USENIX Security Symposium",
            "pages": "1343-1360",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhengZHRWC0TP23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/zheng",
            "url": "https://dblp.org/rec/conf/uss/ZhengZHRWC0TP23",
            "abstract": "Fuzzers effectively explore programs to discover bugs. Greybox fuzzers mutate seed inputs and observe their execution. Whenever a seed reaches new behavior ( e.g., new code or higher execution frequency), it is stored for further mutation. Greybox fuzzers directly measure exploration and, by repeating execution of the same targets with large amounts of mutated seeds, passively exploit any lingering bugs. Directed greybox fuzzers (DGFs) narrow the search to a few code locations but so far generalize distance to all targets into a single score and do not prioritize targets dynamically. F ISH F UZZ introduces an input prioritization strategy that builds on three concepts: (i) a novel multi-distance metric whose precision is independent of the number of targets, (ii) a dynamic target ranking to automatically discard exhausted targets, and (iii) a smart queue culling algorithm, based on hyperparameters, that alternates between exploration and exploitation . F ISH F UZZ enables fuzzers to seamlessly scale among thousands of targets and prioritize seeds toward interesting locations, thus achieving more comprehensive program testing. To demonstrate generality, we implement F ISH F UZZ over two well-established greybox fuzzers (AFL and AFL++). We evaluate F ISH F UZZ by leveraging all sanitizer labels as targets. In comparison to modern DGFs and state-of-the-art coverage guided fuzzers, F ISH F UZZ reaches higher coverage compared to the direct competitors, \ufb01nds up",
            "keywords": [
                "Fuzz Testing",
                "Greybox Fuzzers",
                "Input Prioritization",
                "Dynamic Target Ranking",
                "Multi-Distance Metric"
            ]
        },
        "url": "URL#915570",
        "sema_paperId": "8c8e0ad93c14ff4a51beb8a06fff070f63b06ea4"
    },
    {
        "@score": "1",
        "@id": "915571",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "319/0899",
                        "text": "Victoria Zhong"
                    },
                    {
                        "@pid": "130/0483",
                        "text": "Susan E. McGregor"
                    },
                    {
                        "@pid": "93/655",
                        "text": "Rachel Greenstadt"
                    }
                ]
            },
            "title": "&quot;I&apos;m going to trust this until it burns me&quot; Parents&apos; Privacy Concerns and Delegation of Trust in K-8 Educational Technology.",
            "venue": "USENIX Security Symposium",
            "pages": "5073-5090",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhongMG23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/zhong",
            "url": "https://dblp.org/rec/conf/uss/ZhongMG23",
            "abstract": "After COVID-19 restrictions forced an almost overnight transition to distance learning for students of all ages, education software became a target for data breaches, with incidents like the Illuminate data breach affecting millions of students nationwide and over 820,000 current and former students in New York City (NYC) alone. Despite a general return to in-person schooling, some schools continue to rely on remote-learning technologies, with NYC even using remote learning during weather-related closures or \u201csnow days.\u201d Given the ongoing use of these classroom technologies, we sought to understand parents\u2019 awareness of their security and privacy risks. We also wanted to know what concerns parents had around their childrens\u2019 use of these tools, and what informed these concerns. To answer these questions, we interviewed 18 NYC parents with children in grades K-8. We found that though the COVID-19 pandemic was the first exposure to remote learning technologies for many children and some parents, there was insufficient guidance and training around them provided for children, parents, and educators. We also found that participating parents implicitly trusted schools and the Department of Education (DOE) to keep their children - and their children\u2019s data - safe, and therefore rarely reported privacy and security concerns about classroom technologies. At the same time, however, they described many situations that indicated privacy and security risks with respect to classroom technologies.",
            "keywords": [
                "Educational Technology",
                "Data Privacy",
                "Parental Trust",
                "K-8 Education",
                "Remote Learning Risks"
            ]
        },
        "url": "URL#915571",
        "sema_paperId": "2a9e13188bba0d7a8e5b114fbe3d95f00e09f7b0"
    },
    {
        "@score": "1",
        "@id": "915572",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "295/9534",
                        "text": "Guangmeng Zhou"
                    },
                    {
                        "@pid": "69/11514",
                        "text": "Zhuotao Liu"
                    },
                    {
                        "@pid": "274/0756",
                        "text": "Chuanpu Fu"
                    },
                    {
                        "@pid": "181/2688-2",
                        "text": "Qi Li 0002"
                    },
                    {
                        "@pid": "181/2626-2",
                        "text": "Ke Xu 0002"
                    }
                ]
            },
            "title": "An Efficient Design of Intelligent Network Data Plane.",
            "venue": "USENIX Security Symposium",
            "pages": "6203-6220",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhouLF0023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/zhou-guangmeng",
            "url": "https://dblp.org/rec/conf/uss/ZhouLF0023",
            "abstract": "Deploying machine learning models directly on the network data plane enables intelligent traffic analysis at line-speed using data-driven models rather than predefined protocols. Such a capability, referred to as Intelligent Data Plane ( IDP ) , may potentially transform a wide range of networking designs. The emerging programmable switches provide crucial hardware support to realize IDP . Prior art in this regard is divided into two major categories: (i) focusing on extracting useful flow information from the data plane, while placing the learning-based traffic analysis on the control plane; and (ii) taking a step further to embed learning models into the data plane, while failing to use flow-level features that are critical to achieve high learning accuracies. In this paper, we propose NetBeacon to advance the state-of-the-art in both model accuracy and model deployment efficiency. In particular, NetBeacon proposes a multi-phase sequential model architecture to perform dynamic packet analysis at different phases of a flow as it proceeds, by incorporating flow-level features that are computable at line-speed to boost learning accuracies. Further, NetBeacon designs efficient model representation mechanisms to address the table entry explosion problem when deploying tree-based models on the network data plane. Finally, NetBeacon hardens its scalability for handling concurrent flows via multiple tightly-coupled designs for managing stateful storage used to store per-flow state. We implement a prototype of NetBeacon and extensively evaluate its performance over multiple traffic analysis tasks.",
            "keywords": [
                "Intelligent Data Plane",
                "Programmable Switches",
                "Traffic Analysis",
                "Flow-Level Features",
                "Model Deployment Efficiency"
            ]
        },
        "url": "URL#915572",
        "sema_paperId": "a3c847991f0a022b9c7c4df27be7981a35c30b1c"
    },
    {
        "@score": "1",
        "@id": "915573",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "56/6786",
                        "text": "Lu Zhou"
                    },
                    {
                        "@pid": "353/7579",
                        "text": "Chengyongxiao Wei"
                    },
                    {
                        "@pid": "36/1469",
                        "text": "Tong Zhu"
                    },
                    {
                        "@pid": "05/1884",
                        "text": "Guoxing Chen"
                    },
                    {
                        "@pid": "158/4724",
                        "text": "Xiaokuan Zhang"
                    },
                    {
                        "@pid": "82/10060",
                        "text": "Suguo Du"
                    },
                    {
                        "@pid": "15/2905",
                        "text": "Hui Cao"
                    },
                    {
                        "@pid": "22/5702",
                        "text": "Haojin Zhu"
                    }
                ]
            },
            "title": "POLICYCOMP: Counterpart Comparison of Privacy Policies Uncovers Overbroad Personal Data Collection Practices.",
            "venue": "USENIX Security Symposium",
            "pages": "1073-1090",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhouWZCZDCZ23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/zhou-lu",
            "url": "https://dblp.org/rec/conf/uss/ZhouWZCZDCZ23",
            "abstract": "Since mobile apps\u2019 privacy policies are usually complex, various tools have been developed to examine whether privacy policies have contradictions and verify whether privacy policies are consistent with the apps\u2019 behaviors. However, to the best of our knowledge, no prior work answers whether the personal data collection practices (PDCPs) in an app\u2019s privacy policy are necessary for given purposes ( i.e. , whether to comply with the principle of data minimization ). Though de\ufb01ned by most existing privacy regulations/laws such as GDPR, the principle of data minimization has been translated into different privacy practices depending on the different contexts ( e.g. , various developers and targeted users). In the end, the developers can collect personal data claimed in the privacy policies as long as they receive authorizations from the users. Currently, it mainly relies on legal experts to manually audit the necessity of personal data collection according to the spe-ci\ufb01c contexts, which is not very scalable for millions of apps. In this study, we aim to take the \ufb01rst step to automatically investigate whether PDCPs in an app\u2019s privacy policy are over-broad from the perspective of counterpart comparison . Our basic insight is that, if an app claims to collect much more personal data in its privacy policy than most of its counterparts, it is more likely to be conducting overbroad collection. To achieve this, P OLICY C OMP , an automatic framework for detecting overbroad PDCPs is proposed. We use P OLICY C OMP to perform a large-scale analysis",
            "keywords": [
                "Privacy Policies",
                "Data Minimization",
                "Personal Data Collection",
                "Overbroad Practices",
                "Counterpart Comparison"
            ]
        },
        "url": "URL#915573",
        "sema_paperId": "3003959ade164779194169f8eaecc8f718777190"
    },
    {
        "@score": "1",
        "@id": "915574",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "83/4183",
                        "text": "Wenjun Zhu"
                    },
                    {
                        "@pid": "39/1697-1",
                        "text": "Xiaoyu Ji 0001"
                    },
                    {
                        "@pid": "63/4074",
                        "text": "Yushi Cheng"
                    },
                    {
                        "@pid": "35/1541",
                        "text": "Shibo Zhang"
                    },
                    {
                        "@pid": "10/3878-1",
                        "text": "Wenyuan Xu 0001"
                    }
                ]
            },
            "title": "TPatch: A Triggered Physical Adversarial Patch.",
            "venue": "USENIX Security Symposium",
            "pages": "661-678",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Zhu0CZ023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/zhu",
            "url": "https://dblp.org/rec/conf/uss/Zhu0CZ023",
            "abstract": "Autonomous vehicles increasingly utilize the vision-based perception module to acquire information about driving environments and detect obstacles. Correct detection and classification are important to ensure safe driving decisions. Existing works have demonstrated the feasibility of fooling the perception models such as object detectors and image classifiers with printed adversarial patches. However, most of them are indiscriminately offensive to every passing autonomous vehicle. In this paper, we propose TPatch, a physical adversarial patch triggered by acoustic signals. Unlike other adversarial patches, TPatch remains benign under normal circumstances but can be triggered to launch a hiding, creating or altering attack by a designed distortion introduced by signal injection attacks towards cameras. To avoid the suspicion of human drivers and make the attack practical and robust in the real world, we propose a content-based camouflage method and an attack robustness enhancement method to strengthen it. Evaluations with three object detectors, YOLO V3/V5 and Faster R-CNN, and eight image classifiers demonstrate the effectiveness of TPatch in both the simulation and the real world. We also discuss possible defenses at the sensor, algorithm, and system levels.",
            "keywords": [
                "Autonomous Vehicles",
                "Adversarial Attacks",
                "Physical Adversarial Patch",
                "Triggered Attacks",
                "Object Detection"
            ]
        },
        "url": "URL#915574",
        "sema_paperId": "0ba18c68371252a028c80d8abb7d85f15af43a24"
    },
    {
        "@score": "1",
        "@id": "915575",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "236/5576",
                        "text": "Maximilian Zinkus"
                    },
                    {
                        "@pid": "28/8733",
                        "text": "Yinzhi Cao"
                    },
                    {
                        "@pid": "74/4531-1",
                        "text": "Matthew D. Green"
                    }
                ]
            },
            "title": "McFIL: Model Counting Functionality-Inherent Leakage.",
            "venue": "USENIX Security Symposium",
            "pages": "7001-7018",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZinkusCG23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/zinkus",
            "url": "https://dblp.org/rec/conf/uss/ZinkusCG23",
            "abstract": "Protecting the confidentiality of private data and using it for useful collaboration have long been at odds. Modern cryptography is bridging this gap through rapid growth in secure protocols such as multi-party computation, fully-homomorphic encryption, and zero-knowledge proofs. However, even with provable indistinguishability or zero-knowledgeness, confidentiality loss from leakage inherent to the functionality may partially or even completely compromise secret values without ever falsifying proofs of security.\nIn this work, we describe McFIL, an algorithmic approach and accompanying software implementation which automatically quantifies intrinsic leakage for a given functionality. Extending and generalizing the Chosen-Ciphertext attack framework of Beck et al. with a practical heuristic, our approach not only quantifies but maximizes functionality-inherent leakage using Maximum Model Counting within a SAT solver. As a result, McFIL automatically derives approximately-optimal adversary inputs that, when used in secure protocols, maximize information leakage of private values.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity23-zinkus.pdf",
            "keywords": [
                "Functionality-Inherent Leakage",
                "Model Counting",
                "Secure Protocols",
                "Information Leakage",
                "Adversary Inputs"
            ]
        },
        "url": "URL#915575"
    },
    {
        "@score": "1",
        "@id": "915576",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "319/7554",
                        "text": "No\u00e9 Zufferey"
                    },
                    {
                        "@pid": "83/8816",
                        "text": "Mathias Humbert"
                    },
                    {
                        "@pid": "11/1066",
                        "text": "Romain Tavenard"
                    },
                    {
                        "@pid": "10/3024",
                        "text": "K\u00e9vin Huguenin"
                    }
                ]
            },
            "title": "Watch your Watch: Inferring Personality Traits from Wearable Activity Trackers.",
            "venue": "USENIX Security Symposium",
            "pages": "193-210",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZuffereyHTH23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/zufferey",
            "url": "https://dblp.org/rec/conf/uss/ZuffereyHTH23",
            "abstract": "Wearable devices, such as wearable activity trackers (WATs), are increasing in popularity. Although they can help to improve one\u2019s quality of life, they also raise serious privacy issues. One particularly sensitive type of information has recently attracted substantial attention, namely personality, as it provides a means to influence individuals (e.g., voters in the Cambridge Analytica scandal). This paper presents the first empirical study to show a significant correlation between WAT data and personality traits (Big Five). We conduct an experiment with 200+ participants. The ground truth was established by using the NEO-PI-3 questionnaire. The participants\u2019 step count, heart rate, battery level, activities, sleep time, etc . were collected for four months. By following a principled machine-learning approach, the participants\u2019 personality privacy was quantified. Our results demonstrate that WATs data brings valuable information to infer the openness, extraversion, and neuroticism personality traits. We further study the importance of the different features (i.e., data types) and found that step counts play a key role in the inference of extraversion and neuroticism, while openness is more related to heart rate.",
            "keywords": [
                "Wearable Activity Trackers",
                "Personality Traits",
                "Big Five Personality",
                "Privacy Concerns",
                "Data Inference"
            ]
        },
        "url": "URL#915576",
        "sema_paperId": "5c761821926ecc19247910d80e5f4b71975c31e2"
    },
    {
        "@score": "1",
        "@id": "915577",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "149/8302",
                        "text": "Chaoshun Zuo"
                    },
                    {
                        "@pid": "188/7759",
                        "text": "Chao Wang"
                    },
                    {
                        "@pid": "49/4102-1",
                        "text": "Zhiqiang Lin 0001"
                    }
                ]
            },
            "title": "A Peek into the Metaverse: Detecting 3D Model Clones in Mobile Games.",
            "venue": "USENIX Security Symposium",
            "pages": "3925-3942",
            "year": "2023",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZuoWL23",
            "ee": "https://www.usenix.org/conference/usenixsecurity23/presentation/zuo",
            "url": "https://dblp.org/rec/conf/uss/ZuoWL23",
            "abstract": "3D models are indispensable assets in metaverse in general and mobile games in particular. Yet, these 3D models can be readily extracted, duplicated, or cloned, a reality that poses a considerable threat. Although instances of games duplicating 3D models from other games have been documented, the pervasiveness of this issue remains unexplored. In this paper, we undertake the \ufb01rst systematic investigation of 3D model cloning within mobile games. However, multiple challenges have to be addressed for clone detection, including scalability, precision, and robustness. Our solution is 3DS CAN , an open source 3D Scanning tool for Clone Assessment and Noti\ufb01cation. We have evaluated 3DS CAN with about 12.2 million static 3D models and 2.5 million animated 3D models extracted from 176K mobile games. With these 3D models, 3DS CAN determined that 63.03% of the static models are likely cloned ones (derived from 1,046,632 distinct models), and 37.07% animated 3D models are likely cloned ones (derived from 180,174 distinctive models). With a heuristic-based clone detection algorithm, 3DS CAN \ufb01nally detected 5,238 mobile games likely containing unauthorized 3D model clones.",
            "keywords": [
                "Metaverse",
                "3D Model Cloning",
                "Mobile Games",
                "Clone Detection",
                "3DS CAN"
            ]
        },
        "url": "URL#915577",
        "sema_paperId": "be6625db00cef0b04aa2b1ab8ae6f37cb375c171"
    },
    {
        "@score": "1",
        "@id": "928614",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "04/6443",
                        "text": "Joseph A. Calandrino"
                    },
                    {
                        "@pid": "01/4825",
                        "text": "Carmela Troncoso"
                    }
                ]
            },
            "title": "32nd USENIX Security Symposium, USENIX Security 2023, Anaheim, CA, USA, August 9-11, 2023",
            "venue": "USENIX Security Symposium",
            "publisher": "USENIX Association",
            "year": "2023",
            "type": "Editorship",
            "access": "open",
            "key": "conf/uss/2023",
            "ee": "https://www.usenix.org/conference/usenixsecurity23",
            "url": "https://dblp.org/rec/conf/uss/2023",
            "abstract": null
        },
        "url": "URL#928614",
        "sema_paperId": "aaf5da4ed2f24913bf7176620f5eb60e549544fe"
    }
]