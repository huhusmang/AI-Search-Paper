[
    {
        "@score": "1",
        "@id": "2332580",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "41/506-1",
                        "text": "Ahmed Salem 0001"
                    },
                    {
                        "@pid": "180/5968",
                        "text": "Apratim Bhattacharya"
                    },
                    {
                        "@pid": "b/MichaelBackes1",
                        "text": "Michael Backes 0001"
                    },
                    {
                        "@pid": "07/5701",
                        "text": "Mario Fritz"
                    },
                    {
                        "@pid": "06/6785-16",
                        "text": "Yang Zhang 0016"
                    }
                ]
            },
            "title": "Updates-Leak: Data Set Inference and Reconstruction Attacks in Online Learning.",
            "venue": "USENIX Security Symposium",
            "pages": "1291-1308",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0001B0F020",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/salem",
            "url": "https://dblp.org/rec/conf/uss/0001B0F020",
            "abstract": "Machine learning (ML) has progressed rapidly during the past decade and the major factor that drives such development is the unprecedented large-scale data. As data generation is a continuous process, this leads to ML model owners updating their models frequently with newly-collected data in an online learning scenario. In consequence, if an ML model is queried with the same set of data samples at two different points in time, it will provide different results.In this paper, we investigate whether the change in the output of a black-box ML model before and after being updated can leak information of the dataset used to perform the update, namely the updating set. This constitutes a new attack surface against black-box ML models and such information leakage may compromise the intellectual property and data privacy of the ML model owner. We propose four attacks following an encoder-decoder formulation, which allows inferring diverse information of the updating set. Our new attacks are facilitated by state-of-the-art deep learning techniques. In particular, we propose a hybrid generative model (CBM-GAN) that is based on generative adversarial networks (GANs) but includes a reconstructive loss that allows reconstructing accurate samples. Our experiments show that the proposed attacks achieve strong performance.",
            "pdf_url": "",
            "keywords": [
                "Online Learning",
                "Information Leakage",
                "Data Set Inference",
                "Reconstruction Attacks",
                "Black-Box Model Updates"
            ]
        },
        "url": "URL#2332580"
    },
    {
        "@score": "1",
        "@id": "2332582",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "191/4716-1",
                        "text": "Junjie Shen 0001"
                    },
                    {
                        "@pid": "176/4056",
                        "text": "Jun Yeon Won"
                    },
                    {
                        "@pid": "191/1578",
                        "text": "Zeyuan Chen"
                    },
                    {
                        "@pid": "150/3272",
                        "text": "Qi Alfred Chen"
                    }
                ]
            },
            "title": "Drift with Devil: Security of Multi-Sensor Fusion based Localization in High-Level Autonomous Driving under GPS Spoofing.",
            "venue": "USENIX Security Symposium",
            "pages": "931-948",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0001WCC20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/shen",
            "url": "https://dblp.org/rec/conf/uss/0001WCC20",
            "abstract": "For high-level Autonomous Vehicles (AV), localization is highly security and safety critical. One direct threat to it is GPS spoofing, but fortunately, AV systems today predominantly use Multi-Sensor Fusion (MSF) algorithms that are generally believed to have the potential to practically defeat GPS spoofing. However, no prior work has studied whether today's MSF algorithms are indeed sufficiently secure under GPS spoofing, especially in AV settings. In this work, we perform the first study to fill this critical gap. As the first study, we focus on a production-grade MSF with both design and implementation level representativeness, and identify two AV-specific attack goals, off-road and wrong-way attacks. \nTo systematically understand the security property, we first analyze the upper-bound attack effectiveness, and discover a take-over effect that can fundamentally defeat the MSF design principle. We perform a cause analysis and find that such vulnerability only appears dynamically and non-deterministically. Leveraging this insight, we design FusionRipper, a novel and general attack that opportunistically captures and exploits take-over vulnerabilities. We evaluate it on 6 real-world sensor traces, and find that FusionRipper can achieve at least 97% and 91.3% success rates in all traces for off-road and wrong-way attacks respectively. We also find that it is highly robust to practical factors such as spoofing inaccuracies. To improve the practicality, we further design an offline method that can effectively identify attack parameters with over 80% average success rates for both attack goals, with the cost of at most half a day. We also discuss promising defense directions.",
            "keywords": [
                "Autonomous Vehicles",
                "Multi-Sensor Fusion",
                "GPS Spoofing",
                "Attack Vulnerabilities",
                "FusionRipper"
            ]
        },
        "url": "URL#2332582",
        "sema_paperId": "0efc99bc2d4a1694d3a3c55a733563b5e0d18b6e"
    },
    {
        "@score": "1",
        "@id": "2332583",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "22/1822-2",
                        "text": "Daniel Lehmann 0002"
                    },
                    {
                        "@pid": "74/3780",
                        "text": "Johannes Kinder"
                    },
                    {
                        "@pid": "25/2188",
                        "text": "Michael Pradel"
                    }
                ]
            },
            "title": "Everything Old is New Again: Binary Security of WebAssembly.",
            "venue": "USENIX Security Symposium",
            "pages": "217-234",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0002KP20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/lehmann",
            "url": "https://dblp.org/rec/conf/uss/0002KP20",
            "abstract": "WebAssembly is an increasingly popular compilation target designed to run code in browsers and on other platforms safely and securely, by strictly separating code and data, enforcing types, and limiting indirect control \ufb02ow. Still, vulnerabilities in memory-unsafe source languages can translate to vulnerabilities in WebAssembly binaries. In this paper, we analyze to what extent vulnerabilities are exploitable in WebAssembly binaries, and how this compares to native code. We \ufb01nd that many classic vulnerabilities which, due to common mitiga-tions, are no longer exploitable in native binaries, are completely exposed in WebAssembly. Moreover, WebAssembly enables unique attacks, such as overwriting supposedly constant data or manipulating the heap using a stack over\ufb02ow. We present a set of attack primitives that enable an attacker (i) to write arbitrary memory, (ii) to overwrite sensitive data, and (iii) to trigger unexpected behavior by diverting control \ufb02ow or manipulating the host environment. We provide a set of vulnerable proof-of-concept applications along with complete end-to-end exploits, which cover three WebAssembly platforms. An empirical risk assessment on real-world binaries and SPEC CPU programs compiled to WebAssembly shows that our attack primitives are likely to be feasible in practice. Overall, our \ufb01ndings show a perhaps surprising lack of binary security in WebAssembly. We discuss potential protection mechanisms to mitigate the resulting risks.",
            "keywords": [
                "WebAssembly Security",
                "Binary Exploitation",
                "Memory Safety",
                "Control Flow Manipulation",
                "Heap Manipulation"
            ]
        },
        "url": "URL#2332583",
        "sema_paperId": "f035359e26cad960b5c6363fbe6d5c031bc2805e"
    },
    {
        "@score": "1",
        "@id": "2332584",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "59/2151-6",
                        "text": "Hailong Zhang 0006"
                    },
                    {
                        "@pid": "230/7569",
                        "text": "Sufian Latif"
                    },
                    {
                        "@pid": "88/8656",
                        "text": "Raef Bassily"
                    },
                    {
                        "@pid": "83/1412",
                        "text": "Atanas Rountev"
                    }
                ]
            },
            "title": "Differentially-Private Control-Flow Node Coverage for Software Usage Analysis.",
            "venue": "USENIX Security Symposium",
            "pages": "1021-1038",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0006LBR20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/zhang-hailong",
            "url": "https://dblp.org/rec/conf/uss/0006LBR20",
            "abstract": ",",
            "keywords": [
                "Differential Privacy",
                "Control-Flow Analysis",
                "Software Usage Analysis",
                "Node Coverage",
                "Privacy Preservation"
            ]
        },
        "url": "URL#2332584",
        "sema_paperId": "371263559bb84eaf2eb301eea89247355b033070"
    },
    {
        "@score": "1",
        "@id": "2332585",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "47/722-25",
                        "text": "Yue Zhang 0025"
                    },
                    {
                        "@pid": "81/1232-1",
                        "text": "Jian Weng 0001"
                    },
                    {
                        "@pid": "245/3217",
                        "text": "Rajib Dey"
                    },
                    {
                        "@pid": "34/756",
                        "text": "Yier Jin"
                    },
                    {
                        "@pid": "49/4102-1",
                        "text": "Zhiqiang Lin 0001"
                    },
                    {
                        "@pid": "49/2189",
                        "text": "Xinwen Fu"
                    }
                ]
            },
            "title": "Breaking Secure Pairing of Bluetooth Low Energy Using Downgrade Attacks.",
            "venue": "USENIX Security Symposium",
            "pages": "37-54",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/00250DJLF20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/zhang-yue",
            "url": "https://dblp.org/rec/conf/uss/00250DJLF20",
            "abstract": "To defeat security threats such as man-in-the-middle (MITM) attacks, Bluetooth Low Energy (BLE) 4.2 and 5.x introduced a Secure Connections Only (SCO) mode, under which a BLE device can only accept secure pairing such as Passkey Entry and Numeric Comparison from an initiator, e.g., an Android mobile. However, the BLE specification does not require the SCO mode for the initiator, and does not specify how the BLE programming framework should implement this mode. In this paper we show that the BLE programming framework of the initiator must properly handle SCO initiation, status management, error handling, and bond management; otherwise severe flaws can be exploited to perform downgrade attacks, forcing the BLE pairing protocols to run in an insecure mode without user's awareness. To validate our findings, we have tested 18 popular BLE commercial products with 5 Android phones. Our experimental results proved that MITM attacks (caused by downgrading) are possible to all these products. More importantly, due to such system flaws from the BLE programming framework, all BLE apps in Android are subject to our downgrade attacks. To defend against our attacks, we have built a prototype for the SCO mode on Android 8 atop Android Open Source Project (AOSP). Finally, in addition to Android, we also find all major OSes including iOS, macOS, Windows, and Linux do not support the SCO mode properly. We have reported the identified BLE pairing vulnerabilities to Bluetooth Special Interest Group, Google, Apple, Texas Instruments, and Microsoft.",
            "pdf_url": "",
            "keywords": [
                "Bluetooth Low Energy",
                "Secure Connections Only",
                "Downgrade Attacks",
                "Man-in-the-Middle Attacks",
                "BLE Pairing Vulnerabilities"
            ]
        },
        "url": "URL#2332585"
    },
    {
        "@score": "1",
        "@id": "2332586",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "175/3324-30",
                        "text": "Hao Chen 0030"
                    },
                    {
                        "@pid": "175/5881",
                        "text": "Ilaria Chillotti"
                    },
                    {
                        "@pid": "223/1274",
                        "text": "Yihe Dong"
                    },
                    {
                        "@pid": "153/9899",
                        "text": "Oxana Poburinnaya"
                    },
                    {
                        "@pid": "10/7611",
                        "text": "Ilya P. Razenshteyn"
                    },
                    {
                        "@pid": "181/9181",
                        "text": "M. Sadegh Riazi"
                    }
                ]
            },
            "title": "SANNS: Scaling Up Secure Approximate k-Nearest Neighbors Search.",
            "venue": "USENIX Security Symposium",
            "pages": "2111-2128",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0030CDPRR20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/chen-hao",
            "url": "https://dblp.org/rec/conf/uss/0030CDPRR20",
            "abstract": "The k-Nearest Neighbor Search (k-NNS) is the backbone of several cloud-based services such as recommender systems, face recognition, and database search on text and images. In these services, the client sends the query to the cloud server and receives the response in which case the query and response are revealed to the service provider. Such data disclosures are unacceptable in several scenarios due to the sensitivity of data and/or privacy laws.\nIn this paper, we introduce SANNS, a system for secure k-NNS that keeps client's query and the search result confidential. SANNS comprises two protocols: an optimized linear scan and a protocol based on a novel sublinear time clustering-based algorithm. We prove the security of both protocols in the standard semi-honest model. The protocols are built upon several state-of-the-art cryptographic primitives such as lattice-based additively homomorphic encryption, distributed oblivious RAM, and garbled circuits. We provide several contributions to each of these primitives which are applicable to other secure computing tasks. Both of our protocols rely on a new circuit for the approximate top-k selection from n numbers that is built from O(n + k2) comparators.\nWe have implemented our proposed system and performed extensive experimental results on four datasets in two different computation environments, demonstrating more than 18 \u2014 31 \u00d7 faster response time compared to optimally implemented protocols from the prior work. Moreover, SANNS is the first work that scales to the database of 10 million entries, pushing the limit by more than two orders of magnitude.",
            "pdf_url": "",
            "keywords": [
                "Secure k-NN Search",
                "Privacy-preserving Protocols",
                "Approximate Nearest Neighbors",
                "Cryptographic Primitives",
                "Scalability in Search Systems"
            ]
        },
        "url": "URL#2332586"
    },
    {
        "@score": "1",
        "@id": "2332588",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "a/YAfek",
                        "text": "Yehuda Afek"
                    },
                    {
                        "@pid": "b/ABremlerBarr",
                        "text": "Anat Bremler-Barr"
                    },
                    {
                        "@pid": "206/9042",
                        "text": "Lior Shafir"
                    }
                ]
            },
            "title": "NXNSAttack: Recursive DNS Inefficiencies and Vulnerabilities.",
            "venue": "USENIX Security Symposium",
            "pages": "631-648",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AfekBS20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/afek",
            "url": "https://dblp.org/rec/conf/uss/AfekBS20",
            "abstract": "This paper exposes a new vulnerability and introduces a corresponding attack, the NoneXistent Name Server Attack (NXNSAttack), that disrupts and may paralyze the DNS system, making it difficult or impossible for Internet users to access websites, web e-mail, online video chats, or any other online resource. The NXNSAttack generates a storm of packets between DNS resolvers and DNS authoritative name servers. The storm is produced by the response of resolvers to unrestricted referral response messages of authoritative name servers. The attack is significantly more destructive than NXDomain attacks (e.g., the Mirai attack): i) It reaches an amplification factor of more than 1620x on the number of packets exchanged by the recursive resolver. ii) In addition to the negative cache, the attack also saturates the 'NS' section of the resolver caches. To mitigate the attack impact, we propose an enhancement to the recursive resolver algorithm, MaxFetch(k), that prevents unnecessary proactive fetches. We implemented the MaxFetch(1) mitigation enhancement on a BIND resolver and tested it on real-world DNS query datasets. Our results show that MaxFetch(1) degrades neither the recursive resolver throughput nor its latency. Following the discovery of the attack, a responsible disclosure procedure was carried out, and several DNS vendors and public providers have issued a CVE and patched their systems.",
            "pdf_url": "",
            "keywords": [
                "DNS Security",
                "NXNSAttack",
                "Recursive DNS",
                "Amplification Attack",
                "Mitigation Techniques"
            ]
        },
        "url": "URL#2332588"
    },
    {
        "@score": "1",
        "@id": "2332589",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "207/6255",
                        "text": "Shimaa Ahmed"
                    },
                    {
                        "@pid": "147/6281",
                        "text": "Amrita Roy Chowdhury 0001"
                    },
                    {
                        "@pid": "97/535",
                        "text": "Kassem Fawaz"
                    },
                    {
                        "@pid": "r/PRamanathan",
                        "text": "Parmesh Ramanathan"
                    }
                ]
            },
            "title": "Preech: A System for Privacy-Preserving Speech Transcription.",
            "venue": "USENIX Security Symposium",
            "pages": "2703-2720",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Ahmed0FR20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/ahmed-shimaa",
            "url": "https://dblp.org/rec/conf/uss/Ahmed0FR20",
            "abstract": "New advances in machine learning have made Automated Speech Recognition (ASR) systems practical and more scalable. These systems, however, pose serious privacy threats as speech is a rich source of sensitive acoustic and textual information. Although offline and open-source ASR eliminates the privacy risks, its transcription performance is inferior to that of cloud-based ASR systems, especially for real-world use cases. In this paper, we propose Pr\u03b5\u03b5ch, an end-to-end speech transcription system which lies at an intermediate point in the privacy-utility spectrum. It protects the acoustic features of the speakers\u2019 voices and protects the privacy of the textual content at an improved performance relative to offline ASR. Additionally, Pr\u03b5\u03b5ch provides several control knobs to allow customizable utility-usability-privacy trade-off. It relies on cloud-based services to transcribe a speech file after applying a series of privacy-preserving operations on the user\u2019s side. We perform a comprehensive evaluation of Pr\u03b5\u03b5ch, using diverse real-world datasets, that demonstrates its effectiveness. Pr\u03b5\u03b5ch provides transcription at a 2% to 32.25% (mean 17.34%) relative improvement in word error rate over Deep Speech, while fully obfuscating the speakers' voice biometrics and allowing only a differentially private view of the textual content.",
            "pdf_url": "",
            "keywords": [
                "Privacy-Preserving ASR",
                "Speech Transcription",
                "Voice Biometrics Protection",
                "Differential Privacy",
                "Utility-Usability-Privacy Trade-off"
            ]
        },
        "url": "URL#2332589"
    },
    {
        "@score": "1",
        "@id": "2332590",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "87/9285",
                        "text": "Muhammad Ejaz Ahmed"
                    },
                    {
                        "@pid": "178/7756",
                        "text": "Il-Youp Kwak"
                    },
                    {
                        "@pid": "58/3207",
                        "text": "Jun Ho Huh"
                    },
                    {
                        "@pid": "162/9339",
                        "text": "Iljoo Kim"
                    },
                    {
                        "@pid": "220/2452",
                        "text": "Taekkyung Oh"
                    },
                    {
                        "@pid": "64/5383",
                        "text": "Hyoungshick Kim"
                    }
                ]
            },
            "title": "Void: A fast and light voice liveness detection system.",
            "venue": "USENIX Security Symposium",
            "pages": "2685-2702",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AhmedKHKOK20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/ahmed-muhammad",
            "url": "https://dblp.org/rec/conf/uss/AhmedKHKOK20",
            "abstract": "Due to the open nature of voice assistants\u2019 input channels, adversaries could easily record people\u2019s use of voice commands, and replay them to spoof voice assistants. To mitigate such spoofing attacks, we present a highly efficient voice liveness detection solution called \u201cVoid.\u201d Void detects voice spoofing attacks using the differences in spectral power between live-human voices and voices replayed through speakers. In contrast to existing approaches that use multiple deep learning models, and thousands of features, Void uses a single classification model with just 97 features. We used two datasets to evaluate its performance: (1) 255,173 voice samples generated with 120 participants, 15 playback devices and 12 recording devices, and (2) 18,030 publicly available voice samples generated with 42 participants, 26 playback devices and 25 recording devices. Void achieves equal error rate of 0.3% and 11.6% in detecting voice replay attacks for each dataset, respectively. Compared to a state of the art, deep learning-based solution that achieves 7.4% error rate in that public dataset, Void uses 153 times less memory and is about 8 times faster in detection. When combined with a Gaussian Mixture Model that uses Melfrequency cepstral coefficients (MFCC) as classification features \u2013 MFCC is already being extracted and used as the main feature in speech recognition services \u2013 Void achieves 8.7% error rate on the public dataset. Moreover, Void is resilient against hidden voice command, inaudible voice command, voice synthesis, equalization manipulation attacks, and combining replay attacks with live-human voices achieving about 99.7%, 100%, 90.2%, 86.3%, and 98.2% detection rates for those attacks, respectively.",
            "keywords": [
                "Voice Liveness Detection",
                "Spoofing Attacks",
                "Voice Assistants",
                "Replay Attacks",
                "Spectral Power Analysis"
            ]
        },
        "url": "URL#2332590",
        "sema_paperId": "bde997305a544f472516bc36ec213fdc48dce8db"
    },
    {
        "@score": "1",
        "@id": "2332591",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "131/3440",
                        "text": "Taslima Akter"
                    },
                    {
                        "@pid": "145/7551",
                        "text": "Bryan Dosono"
                    },
                    {
                        "@pid": "161/3346",
                        "text": "Tousif Ahmed"
                    },
                    {
                        "@pid": "50/6916",
                        "text": "Apu Kapadia"
                    },
                    {
                        "@pid": "17/3107",
                        "text": "Bryan C. Semaan"
                    }
                ]
            },
            "title": "&quot;I am uncomfortable sharing what I can&apos;t see&quot;: Privacy Concerns of the Visually Impaired with Camera Based Assistive Applications.",
            "venue": "USENIX Security Symposium",
            "pages": "1929-1948",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AkterDAKS20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/akter",
            "url": "https://dblp.org/rec/conf/uss/AkterDAKS20",
            "abstract": "The emergence of camera-based assistive technologies has empowered people with visual impairments (VIP) to obtain independence in their daily lives. Popular services feature volunteers who answer questions about photos or videos (e.g., to identify a medical prescription). However, people with VIPs can (inadvertently) reveal sensitive information to these volunteers. To better understand the privacy concerns regarding the disclosure of background objects to different types of human assistants (friends, family, and others), we conducted an online survey with 155 visually impaired participants. In general, our participants had varying concerns depending on the type of assistants and the kind of information. We found that our participants were more concerned about the privacy of bystanders than their own when capturing people in images. We also found that participants were concerned about self-presentation and were more comfortable sharing embar-rassing information with family than with their friends. Our \ufb01ndings suggest directions for future work in the development of human-assisted question-answering systems. Speci\ufb01cally, we discuss how humanizing these systems can give people a greater sense of personal security.",
            "keywords": [
                "Camera-based Assistive Technologies",
                "Visual Impairments",
                "Privacy Concerns",
                "Human-assisted Systems",
                "Sensitive Information Disclosure"
            ]
        },
        "url": "URL#2332591",
        "sema_paperId": "0eb4ecdbbf691e9827d5452ae1cd524ba1d017dd"
    },
    {
        "@score": "1",
        "@id": "2332593",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "167/0165",
                        "text": "Benjamin Andow"
                    },
                    {
                        "@pid": "248/1724",
                        "text": "Samin Yaseer Mahmud"
                    },
                    {
                        "@pid": "248/1643",
                        "text": "Justin Whitaker"
                    },
                    {
                        "@pid": "22/4463",
                        "text": "William Enck"
                    },
                    {
                        "@pid": "117/3983",
                        "text": "Bradley Reaves"
                    },
                    {
                        "@pid": "87/6804",
                        "text": "Kapil Singh"
                    },
                    {
                        "@pid": "07/1108",
                        "text": "Serge Egelman"
                    }
                ]
            },
            "title": "Actions Speak Louder than Words: Entity-Sensitive Privacy Policy and Data Flow Analysis with PoliCheck.",
            "venue": "USENIX Security Symposium",
            "pages": "985-1002",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AndowMWERSE20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/andow",
            "url": "https://dblp.org/rec/conf/uss/AndowMWERSE20",
            "abstract": "Identifying privacy-sensitive data leaks by mobile applications has been a topic of great research interest for the past decade. Technically, such data \ufb02ows are not \u201cleaks\u201d if they are disclosed in a privacy policy. To address this limitation in automated analysis, recent work has combined program analysis of applications with analysis of privacy policies to determine the \ufb02ow-to-policy consistency, and hence violations thereof. However, this prior work has a fundamental weakness: it does not differentiate the entity (e.g., \ufb01rst-party vs. third-party) receiving the privacy-sensitive data. In this paper, we propose P OLI C HECK , which formalizes and implements an entity-sensitive \ufb02ow-to-policy consistency model. We use P OLI C HECK to study 13,796 applications and their privacy policies and \ufb01nd that up to 42.4% of applications either incorrectly disclose or omit disclosing their privacy-sensitive data \ufb02ows. Our results also demonstrate the signi\ufb01cance of considering entities: without considering entity, prior approaches would falsely classify up to 38.4% of applications as having privacy-sensitive data \ufb02ows consistent with their privacy policies. These false classi\ufb01cations include data \ufb02ows to third-parties that are omitted (e.g., the policy states only the \ufb01rst-party collects the data type), incorrect (e.g., the policy states the third-party does not collect the data type), and ambiguous (e.g., the policy has con\ufb02icting statements about the data type collection). By de\ufb01ning a novel automated, entity-sensitive \ufb02ow-to-policy consistency analysis, P OLI C HECK provides the highest-precision method to",
            "keywords": [
                "Mobile Application Privacy",
                "Data Flow Analysis",
                "Privacy Policy Compliance",
                "Entity-Sensitive Analysis",
                "Data Leak Identification"
            ]
        },
        "url": "URL#2332593",
        "sema_paperId": "28b8d6394ab3b32b78d2f7a91d65dda98ab1c8f2"
    },
    {
        "@score": "1",
        "@id": "2332594",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "164/7430",
                        "text": "Mozhgan Azimpourkivi"
                    },
                    {
                        "@pid": "t/UmutTopkara",
                        "text": "Umut Topkara"
                    },
                    {
                        "@pid": "20/4777",
                        "text": "Bogdan Carbunar"
                    }
                ]
            },
            "title": "Human Distinguishable Visual Key Fingerprints.",
            "venue": "USENIX Security Symposium",
            "pages": "2237-2254",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AzimpourkiviTC20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/azimpourkivi",
            "url": "https://dblp.org/rec/conf/uss/AzimpourkiviTC20",
            "abstract": "Visual fingerprints are used in human verification of identities to improve security against impersonation attacks. The verification requires the user to confirm that the visual fingerprint image derived from the trusted source is the same as the one derived from the unknown source. We introduce CEAL, a novel mechanism to build generators for visual fingerprint representations of arbitrary public strings. CEAL stands out from existing approaches in three significant aspects: (1) eliminates the need for hand curated image generation rules by learning a generator model that imitates the style and domain of fingerprint images from a large collection of sample images, hence enabling easy customizability, (2) operates within limits of the visual discriminative ability of human perception, such that the learned fingerprint image generator avoids mapping distinct keys to images which are not distinguishable by humans, and (3) the resulting model deterministically generates realistic fingerprint images from an input vector, where the vector components are designated to control visual properties which are either readily perceptible to a human eye, or imperceptible, yet necessary for accurately modeling the target image domain. Unlike existing visual fingerprint generators, CEAL factors in the limits of human perception, and pushes the key payload capacity of the images toward the limits of its generative model: We have built a generative network for nature landscape images which can reliably encode 123 bits of entropy in the fingerprint. We label 3,996 image pairs by 931 participants. In experiments with 402 million attack image pairs, we found that pre-image attacks performed by adversaries equipped with the human perception discriminators that we build, achieve a success rate against CEAL that is at most 2 \u00d710\u22124%. The CEAL generator model is small (67MB) and efficient (2.3s to generate an image fingerprint on a laptop).",
            "keywords": [
                "Visual Fingerprints",
                "Human Verification",
                "Image Generation",
                "Perceptual Distinction",
                "Entropy Encoding"
            ]
        },
        "url": "URL#2332594",
        "sema_paperId": "5c87ac7b20be65811052c2f42f543cd125fd458c"
    },
    {
        "@score": "1",
        "@id": "2332595",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "265/9612",
                        "text": "Anomadarshi Barua"
                    },
                    {
                        "@pid": "06/1521",
                        "text": "Mohammad Abdullah Al Faruque"
                    }
                ]
            },
            "title": "Hall Spoofing: A Non-Invasive DoS Attack on Grid-Tied Solar Inverter.",
            "venue": "USENIX Security Symposium",
            "pages": "1273-1290",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BaruaF20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/barua",
            "url": "https://dblp.org/rec/conf/uss/BaruaF20",
            "abstract": "Grid-tied solar inverters continue to proliferate rapidly to tackle the growing environmental challenges. Nowadays, different smart sensors and transducers are tightly integrated with the grid-tied inverter. This integration opens the \"Pandora\u2019s Box\" of unknown threats that could come from very unconventional ways. This paper demonstrates a noninvasive attack that could come by spoofing the Hall sensor of an inverter in a stealthy way by using an external magnetic field. We demonstrate how an attacker can camouflage his/her attack tool and place it near a target inverter. In doing so, he/she can intentionally perturb grid voltage and frequency and can inject false real and reactive power to the grid. We also show the consequences of the attack on a scaled-down testbed of a power grid with a commercial 140 W grid-tied inverter from Texas Instruments. We are able to achieve a 31.52% change in output voltage, 3.16x (-6dB to -11dB) increase in lowfrequency harmonics power, and 3.44x increase in real power. Moreover, we introduce a duty-cycle variation approach for a noninvasive adversarial control that can change the inverter voltage up to 34% and real power up to 38%. We discuss the feasibility of using a 100 kW inverter through discussion. This provides insights behind the generalization of the attack model. In addition, the commercial power system simulation tool Etap 19.0.1 is used to simulate the impact of the attack on a 2.3 MW power grid. To the best of our knowledge, this is the first methodology that highlights the possibility of such an attack that might lead to grid blackout in a weak grid.",
            "keywords": [
                "Grid-Tied Solar Inverters",
                "DoS Attack",
                "Hall Sensor Spoofing",
                "Power Grid Stability",
                "Non-Invasive Attack"
            ]
        },
        "url": "URL#2332595",
        "sema_paperId": "a0e95184871055ef057dbbc6d76b2c740d9a8de4"
    },
    {
        "@score": "1",
        "@id": "2332596",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "224/2397",
                        "text": "Gabrielle Beck"
                    },
                    {
                        "@pid": "236/5576",
                        "text": "Maximilian Zinkus"
                    },
                    {
                        "@pid": "74/4531-1",
                        "text": "Matthew Green 0001"
                    }
                ]
            },
            "title": "Automating the Development of Chosen Ciphertext Attacks.",
            "venue": "USENIX Security Symposium",
            "pages": "1821-1837",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BeckZ020",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/beck",
            "url": "https://dblp.org/rec/conf/uss/BeckZ020",
            "abstract": "In this work we investigate the problem of automating the development of adaptive chosen ciphertext attacks on systems that contain vulnerable format oracles . Unlike previous attempts, which simply automate the execution of known attacks, we consider a more challenging problem: to programmatically derive a novel attack strategy, given only a machine-readable description of the plaintext veri\ufb01cation function and the malleability characteristics of the encryption scheme. We present a new set of algorithms that use SAT and SMT solvers to reason deeply over the design of the system, producing an automated attack strategy that can entirely decrypt protected messages. Developing our algorithms required us to adapt techniques from a diverse range of research \ufb01elds, as well as to explore and develop new ones. We implement our algorithms using existing theory solvers. The result is a practical tool called Delphinium that succeeds against real-world and contrived format oracles. To our knowledge, this is the \ufb01rst work to automatically derive such complex chosen ciphertext attacks.",
            "keywords": [
                "Chosen Ciphertext Attacks",
                "Format Oracles",
                "Adaptive Attacks",
                "SAT Solvers",
                "Automated Attack Strategy"
            ]
        },
        "url": "URL#2332596",
        "sema_paperId": "ad7bc505416758b366fe232fafd33fa80845d383"
    },
    {
        "@score": "1",
        "@id": "2332599",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "b/DanielJBernstein",
                        "text": "Daniel J. Bernstein"
                    },
                    {
                        "@pid": "56/2224",
                        "text": "Tanja Lange 0001"
                    }
                ]
            },
            "title": "McTiny: Fast High-Confidence Post-Quantum Key Erasure for Tiny Network Servers.",
            "venue": "USENIX Security Symposium",
            "pages": "1731-1748",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Bernstein020",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/bernstein",
            "url": "https://dblp.org/rec/conf/uss/Bernstein020",
            "abstract": "Recent results have shown that some post-quantum cryptographic systems have encryption and decryption performance comparable to fast elliptic-curve cryptography (ECC) or even better. However, this performance metric is considering only CPU time and ignoring bandwidth and storage. High-confidence post-quantum encryption systems have much larger keys than ECC. For example, the code-based cryptosystem recommended by the PQCRYPTO project uses public keys of 1MB.\nFast key erasure (to provide \"forward secrecy\") requires new public keys to be constantly transmitted. Either the server needs to constantly generate, store, and transmit large keys, or it needs to receive, store, and use large keys from the clients. This is not necessarily a problem for overall bandwidth, but it is a problem for storage and computation time on tiny network servers. All straightforward approaches allow easy denial-of-service attacks.\nThis paper describes a protocol, suitable for today's networks and tiny servers, in which clients transmit their code-based one-time public keys to servers. Servers never store full client public keys but work on parts provided by the clients, without having to maintain any per-client state. Intermediate results are stored on the client side in the form of encrypted cookies and are eventually combined by the server to obtain the ciphertext. Requirements on the server side are very small: storage of one long-term private key, which is much smaller than a public key, and a few small symmetric cookie keys, which are updated regularly and erased after use. The protocol is highly parallel, requiring only a few round trips, and involves total bandwidth not much larger than a single public key. The total number of packets sent by each side is 971, each fitting into one IPv6 packet of less than 1280 bytes.\nThe protocol makes use of the structure of encryption in code-based cryptography and benefits from small ciphertexts in code-based cryptography.",
            "pdf_url": "",
            "keywords": [
                "Post-Quantum Cryptography",
                "Key Erasure",
                "Tiny Network Servers",
                "Forward Secrecy",
                "Code-Based Cryptography"
            ]
        },
        "url": "URL#2332599"
    },
    {
        "@score": "1",
        "@id": "2332601",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "205/2079",
                        "text": "Tim Blazytko"
                    },
                    {
                        "@pid": "207/4015",
                        "text": "Moritz Schl\u00f6gel"
                    },
                    {
                        "@pid": "160/7844",
                        "text": "Cornelius Aschermann"
                    },
                    {
                        "@pid": "73/2297-2",
                        "text": "Ali Abbasi 0002"
                    },
                    {
                        "@pid": "64/5428",
                        "text": "Joel Frank"
                    },
                    {
                        "@pid": "248/1623",
                        "text": "Simon W\u00f6rner"
                    },
                    {
                        "@pid": "h/ThorstenHolz",
                        "text": "Thorsten Holz"
                    }
                ]
            },
            "title": "AURORA: Statistical Crash Analysis for Automated Root Cause Explanation.",
            "venue": "USENIX Security Symposium",
            "pages": "235-252",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BlazytkoSAAFWH20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/blazytko",
            "url": "https://dblp.org/rec/conf/uss/BlazytkoSAAFWH20",
            "abstract": "Given the huge success of automated software testing techniques, a large amount of crashes is found in practice. Identifying the root cause of a crash is a time-intensive endeavor, causing a disproportion between \ufb01nding a crash and \ufb01xing the underlying software fault. To address this problem, various approaches have been proposed that rely on techniques such as reverse execution and backward taint analysis. Still, these techniques are either limited to certain fault types or provide an analyst with assembly instructions, but no context information or explanation of the underlying fault. In this paper, we propose an automated analysis approach that does not only identify the root cause of a given crashing input for a binary executable, but also provides the analyst with context information on the erroneous behavior that characterizes crashing inputs. Starting with a single crashing input, we generate a diverse set of similar inputs that either also crash the program or induce benign behavior. We then trace the program\u2019s states while executing each found input and generate predicates, i. e., simple Boolean expressions that capture behavioral differences between crashing and non-crashing inputs. A statistical analysis of all predicates allows us to identify the predicate pinpointing the root cause, thereby not only revealing the location of the root cause, but also providing an analyst with an explanation of the misbehavior a crash exhibits at this location. We implement our approach in a tool called A URORA and evaluate it on 25 diverse software faults. Our evaluation shows that A URORA is able to uncover root causes even for complex bugs. For example, it succeeded in cases where many millions of instructions were executed between developer \ufb01x and crashing location. In contrast to existing approaches, A URORA is also able to handle bugs with no data dependency between root cause and crash, such as type confusion bugs.",
            "keywords": [
                "Automated Crash Analysis",
                "Root Cause Identification",
                "Behavioral Differences",
                "Statistical Analysis",
                "Type Confusion Bugs"
            ]
        },
        "url": "URL#2332601",
        "sema_paperId": "ef4a1d2dc007eb96fac5cf0b76428e6107746899"
    },
    {
        "@score": "1",
        "@id": "2332603",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "202/6734",
                        "text": "Jonas B\u00f6hler"
                    },
                    {
                        "@pid": "26/5304",
                        "text": "Florian Kerschbaum"
                    }
                ]
            },
            "title": "Secure Multi-party Computation of Differentially Private Median.",
            "venue": "USENIX Security Symposium",
            "pages": "2147-2164",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BohlerK20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/boehler",
            "url": "https://dblp.org/rec/conf/uss/BohlerK20",
            "abstract": "In this work, we consider distributed private learning. For this purpose, companies collect statistics about telemetry, usage and frequent settings from their users without disclosing individual values. We focus on rank-based statistics, speci\ufb01cally, the median which is more robust to outliers than the mean. Local differential privacy, where each user shares locally perturbed data with an untrusted server, is often used in private learning but does not provide the same accuracy as the central model, where noise is applied only once by a trusted server. Existing solutions to compute the differentially private median provide good accuracy only for large amounts of users (local model), by using a trusted third party (central model), or for a very small data universe (secure multi-party computation). We present a multi-party computation to ef\ufb01ciently compute the exponential mechanism for the median, which also supports, e.g., general rank-based statistics (e.g., p th - percentile, interquartile range) and convex optimizations for machine learning. Our approach is ef\ufb01cient (practical running time), scaleable (sublinear in the data universe size) and accurate, i.e., the absolute error is smaller than comparable methods and is independent of the number of users, hence, our protocols can be used even for a small number of users. In our experiments we were able to compute the differentially private median for 1 million users in 3 minutes using 3 semi-honest computation parties distributed over the Internet.",
            "keywords": [
                "Secure Multi-party Computation",
                "Differential Privacy",
                "Private Learning",
                "Median Computation",
                "Exponential Mechanism"
            ]
        },
        "url": "URL#2332603",
        "sema_paperId": "55bceed9c600545e0c2d0fc0d4318644997220ac"
    },
    {
        "@score": "1",
        "@id": "2332604",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "272/7083",
                        "text": "Xander Bouwman"
                    },
                    {
                        "@pid": "245/4471",
                        "text": "Harm Griffioen"
                    },
                    {
                        "@pid": "272/7144",
                        "text": "Jelle Egbers"
                    },
                    {
                        "@pid": "d/ChristianDoerr",
                        "text": "Christian Doerr"
                    },
                    {
                        "@pid": "29/5649",
                        "text": "Bram Klievink"
                    },
                    {
                        "@pid": "17/7444",
                        "text": "Michel van Eeten"
                    }
                ]
            },
            "title": "A different cup of TI? The added value of commercial threat intelligence.",
            "venue": "USENIX Security Symposium",
            "pages": "433-450",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BouwmanGEDKE20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/bouwman",
            "url": "https://dblp.org/rec/conf/uss/BouwmanGEDKE20",
            "abstract": "Commercial threat intelligence is thought to provide unmatched coverage on attacker behavior, but it is out of reach for many organizations due to its hefty price tag. This paper presents the first empirical assessment of the services of commercial threat intelligence providers. For two leading vendors, we describe what these services consist of and compare their indicators with each other. There is almost no overlap between them, nor with four large open threat intelligence feeds. Even for 22 specific threat actors \u2013 which both vendors claim to track \u2013 we find an average overlap of only 2.5% to 4.0% between the indicator feeds. The small number of overlapping indicators show up in the feed of the other vendor with a delay of, on average, a month. These findings raise questions on the coverage and timeliness of paid threat intelligence. We also conducted 14 interviews with security professionals that use paid threat intelligence. We find that value in this market is understood differently than prior work on quality metrics has assumed. Poor coverage and small volume appear less of a problem to customers. They seem to be optimizing for the workflow of their scarce resource \u2013 analyst time \u2013 rather than for the detection of threats. Respondents evaluate TI mostly through informal processes and heuristics, rather than the quantitative metrics that research has proposed.",
            "keywords": [
                "Commercial Threat Intelligence",
                "Threat Actor Tracking",
                "Indicator Overlap",
                "Threat Intelligence Coverage",
                "Analyst Workflow Optimization"
            ]
        },
        "url": "URL#2332604",
        "sema_paperId": "df15e00957bc1a6aa66a53286ace5946fa6a4b45"
    },
    {
        "@score": "1",
        "@id": "2332605",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "189/1192",
                        "text": "Samira Briongos"
                    },
                    {
                        "@pid": "83/6233",
                        "text": "Pedro Malag\u00f3n"
                    },
                    {
                        "@pid": "09/5886",
                        "text": "Jos\u00e9 Manuel Moya"
                    },
                    {
                        "@pid": "72/817",
                        "text": "Thomas Eisenbarth 0001"
                    }
                ]
            },
            "title": "RELOAD+REFRESH: Abusing Cache Replacement Policies to Perform Stealthy Cache Attacks.",
            "venue": "USENIX Security Symposium",
            "pages": "1967-1984",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BriongosMM020",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/briongos",
            "url": "https://dblp.org/rec/conf/uss/BriongosMM020",
            "abstract": "Caches have become the prime method for unintended information extraction across logical isolation boundaries. They are widely available on all major CPU platforms and, as a side channel, caches provide great resolution, making them the most convenient channel for Spectre and Meltdown. As a consequence, several methods to stop cache attacks by detecting them have been proposed.  Detection is strongly aided by the fact that observing cache activity of co-resident processes is not possible without altering the cache state and thereby forcing evictions on the observed processes. In this work we show that this widely held assumption is incorrect. Through clever usage of the cache replacement policy, it is possible to track cache accesses of a victim's process without forcing evictions on the victim's data. Hence, online detection mechanisms that rely on these evictions can be circumvented as they would not detect the introduced RELOAD+REFRESH attack. The attack requires a profound understanding of the cache replacement policy. We present a methodology to recover the replacement policy and apply it to the last five generations of Intel processors. We further show empirically that the performance of RELOAD+REFRESH on cryptographic implementations is comparable to that of other widely used cache attacks, while detection methods that rely on L3 cache events are successfully thwarted.",
            "pdf_url": "",
            "keywords": [
                "Cache Attacks",
                "Cache Replacement Policy",
                "Information Leakage",
                "Co-resident Processes",
                "RELOAD+REFRESH Attack"
            ]
        },
        "url": "URL#2332605"
    },
    {
        "@score": "1",
        "@id": "2332606",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "177/8590",
                        "text": "Fraser Brown"
                    },
                    {
                        "@pid": "91/6118",
                        "text": "Deian Stefan"
                    },
                    {
                        "@pid": "e/DREngler",
                        "text": "Dawson R. Engler"
                    }
                ]
            },
            "title": "Sys: A Static/Symbolic Tool for Finding Good Bugs in Good (Browser) Code.",
            "venue": "USENIX Security Symposium",
            "pages": "199-216",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BrownSE20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/brown",
            "url": "https://dblp.org/rec/conf/uss/BrownSE20",
            "abstract": "We describe and evaluate an extensible bug-\ufb01nding tool, Sys, designed to automatically \ufb01nd security bugs in huge code-bases, even when easy-to-\ufb01nd bugs have been already picked clean by years of aggressive automatic checking. Sys uses a two-step approach to \ufb01nd such tricky errors. First, it breaks down large\u2014tens of millions of lines\u2014systems into small pieces using user-extensible static checkers to quickly \ufb01nd and mark potential errorsites. Second, it uses user-extensible symbolic execution to deeply examine these potential errorsites for actual bugs. Both the checkers and the system itself are small (6KLOC total). Sys is \ufb02exible, because users must be able to exploit domain-or system-speci\ufb01c knowledge in order to detect errors and suppress false positives in real codebases. Sys \ufb01nds many security bugs (51 bugs, 43 con\ufb01rmed) in well-checked code\u2014the Chrome and Firefox web browsers\u2014and code that some symbolic tools struggle with\u2014the FreeBSD operating system. Sys\u2019s most interesting results include: an exploitable, cash bountied CVE in Chrome that was \ufb01xed in seven hours (and whose patch was backported in two days); a trio of bountied bugs with a CVE in Firefox; and a bountied bug in Chrome\u2019s audio support.",
            "keywords": [
                "Static Analysis",
                "Symbolic Execution",
                "Bug Finding",
                "Security Vulnerabilities",
                "Browser Code"
            ]
        },
        "url": "URL#2332606",
        "sema_paperId": "4184df60baf929477d4af76b10c171f4c4a86b86"
    },
    {
        "@score": "1",
        "@id": "2332608",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "89/9526",
                        "text": "Stefano Calzavara"
                    },
                    {
                        "@pid": "244/5274",
                        "text": "Sebastian Roth"
                    },
                    {
                        "@pid": "159/0703",
                        "text": "Alvise Rabitti"
                    },
                    {
                        "@pid": "b/MichaelBackes1",
                        "text": "Michael Backes 0001"
                    },
                    {
                        "@pid": "136/8343",
                        "text": "Ben Stock"
                    }
                ]
            },
            "title": "A Tale of Two Headers: A Formal Analysis of Inconsistent Click-Jacking Protection on the Web.",
            "venue": "USENIX Security Symposium",
            "pages": "683-697",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CalzavaraRR0S20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/calzavara",
            "url": "https://dblp.org/rec/conf/uss/CalzavaraRR0S20",
            "abstract": "Click-jacking protection on the modern Web is commonly enforced via client-side security mechanisms for framing control, like the X-Frame-Options header (XFO) and Content Security Policy (CSP). Though these client-side security mechanisms are certainly useful and successful, delegating protection to web browsers opens room for inconsistencies in the security guarantees offered to users of different browsers. In particular, inconsistencies might arise due to the lack of support for CSP and the different implementations of the underspecified XFO header. In this paper, we formally study the problem of inconsistencies in framing control policies across different browsers and we implement an automated policy analyzer based on our theory, which we use to assess the state of click-jacking protection on the Web. Our analysis shows that 10% of the (distinct) framing control policies in the wild are inconsistent and most often do not provide any level of protection to at least one browser. We thus propose recommendations for web developers and browser vendors to mitigate this issue. Finally, we design and implement a server-side proxy to retrofit security in web applications.",
            "keywords": [
                "Click-Jacking Protection",
                "Framing Control",
                "X-Frame-Options",
                "Content Security Policy",
                "Browser Inconsistencies"
            ]
        },
        "url": "URL#2332608",
        "sema_paperId": "51e4f4b60b9b93da942700fd8009412960ae69c3"
    },
    {
        "@score": "1",
        "@id": "2332609",
        "info": {
            "authors": {
                "author": {
                    "@pid": "51/1639",
                    "text": "Srdjan Capkun"
                }
            },
            "title": "Digital Contact Tracing.",
            "venue": "USENIX Security Symposium",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Capkun20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/panel-contact-tracing",
            "url": "https://dblp.org/rec/conf/uss/Capkun20",
            "abstract": "COVID-19 pandemic, caused by the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) resulted in many deaths and halted large parts of the world economy. Since this virus spreads between people during close contact, one of the main tools in the fight against COVID-19 outbreak has been contact tracing, whose purpose is to trace and quarantine contacts of virus-positive persons. To facilitate this process, digital contact tracing solutions were recently proposed and deployed in a number of countries. Google and Apple further implemented support for contact tracing within Android and iOS. The deployment of such large scale tracing infrastructure raises a number of security, privacy, ethical and legal issues. The panelists will address these issues and describe their experiences in building and analyzing digital contact tracing systems.",
            "pdf_url": "",
            "keywords": [
                "Digital Contact Tracing",
                "COVID-19",
                "Privacy Issues",
                "Security Concerns",
                "Ethical and Legal Challenges"
            ]
        },
        "url": "URL#2332609",
        "sema_paperId": "16e097990515ae5ee67aeba07aca59c5661870c0"
    },
    {
        "@score": "1",
        "@id": "2332610",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "179/2245",
                        "text": "Varun Chandrasekaran"
                    },
                    {
                        "@pid": "56/6435",
                        "text": "Kamalika Chaudhuri"
                    },
                    {
                        "@pid": "136/5992",
                        "text": "Irene Giacomelli"
                    },
                    {
                        "@pid": "j/SomeshJha",
                        "text": "Somesh Jha"
                    },
                    {
                        "@pid": "146/8180",
                        "text": "Songbai Yan"
                    }
                ]
            },
            "title": "Exploring Connections Between Active Learning and Model Extraction.",
            "venue": "USENIX Security Symposium",
            "pages": "1309-1326",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChandrasekaranC20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/chandrasekaran",
            "url": "https://dblp.org/rec/conf/uss/ChandrasekaranC20",
            "abstract": "Machine learning is being increasingly used by individuals, research institutions, and corporations. This has resulted in the surge of Machine Learning-as-a-Service (MLaaS) - cloud services that provide (a) tools and resources to learn the model, and (b) a user-friendly query interface to access the model. However, such MLaaS systems raise privacy concerns such as model extraction. In model extraction attacks, adversaries maliciously exploit the query interface to steal the model. More precisely, in a model extraction attack, a good approximation of a sensitive or proprietary model held by the server is extracted (i.e. learned) by a dishonest user who interacts with the server only via the query interface. This attack was introduced by Tramer et al. at the 2016 USENIX Security Symposium, where practical attacks for various models were shown. We believe that better understanding the efficacy of model extraction attacks is paramount to designing secure MLaaS systems. To that end, we take the first step by (a) formalizing model extraction and discussing possible defense strategies, and (b) drawing parallels between model extraction and established area of active learning. In particular, we show that recent advancements in the active learning domain can be used to implement powerful model extraction attacks, and investigate possible defense strategies.",
            "keywords": [
                "Model Extraction",
                "Active Learning",
                "MLaaS",
                "Privacy Concerns",
                "Defense Strategies"
            ]
        },
        "url": "URL#2332610",
        "sema_paperId": "35c863e151e47b6dbf6356e9a1abaa2a0eeab3fc"
    },
    {
        "@score": "1",
        "@id": "2332611",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "09/7487-1",
                        "text": "Yizheng Chen 0001"
                    },
                    {
                        "@pid": "58/9145-2",
                        "text": "Shiqi Wang 0002"
                    },
                    {
                        "@pid": "168/9537",
                        "text": "Dongdong She"
                    },
                    {
                        "@pid": "74/28",
                        "text": "Suman Jana"
                    }
                ]
            },
            "title": "On Training Robust PDF Malware Classifiers.",
            "venue": "USENIX Security Symposium",
            "pages": "2343-2360",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Chen0SJ20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/chen-yizheng",
            "url": "https://dblp.org/rec/conf/uss/Chen0SJ20",
            "abstract": "Although state-of-the-art PDF malware classifiers can be trained with almost perfect test accuracy (99%) and extremely low false positive rate (under 0.1%), it has been shown that even a simple adversary can evade them. A practically useful malware classifier must be robust against evasion attacks. However, achieving such robustness is an extremely challenging task.\nIn this paper, we take the first steps towards training robust PDF malware classifiers with verifiable robustness properties. For instance, a robustness property can enforce that no matter how many pages from benign documents are inserted into a PDF malware, the classifier must still classify it as malicious. We demonstrate how the worst-case behavior of a malware classifier with respect to specific robustness properties can be formally verified. Furthermore, we find that training classifiers that satisfy formally verified robustness properties can increase the evasion cost of unbounded (i.e., not bounded by the robustness properties) attackers by eliminating simple evasion attacks.\nSpecifically, we propose a new distance metric that operates on the PDF tree structure and specify two classes of robustness properties including subtree insertions and deletions. We utilize state-of-the-art verifiably robust training method to build robust PDF malware classifiers. Our results show that, we can achieve 92.27% average verified robust accuracy over three properties, while maintaining 99.74% accuracy and 0.56% false positive rate. With simple robustness properties, our robust model maintains 7% higher robust accuracy than all the baseline models against unrestricted whitebox attacks. Moreover, the state-of-the-art and new adaptive evolutionary attackers need up to 10 times larger $L_0$ feature distance and 21 times more PDF basic mutations (e.g., inserting and deleting objects) to evade our robust model than the baselines.",
            "pdf_url": "",
            "keywords": [
                "PDF Malware Classification",
                "Robustness Properties",
                "Evasion Attacks",
                "Verifiable Robustness",
                "PDF Tree Structure"
            ]
        },
        "url": "URL#2332611"
    },
    {
        "@score": "1",
        "@id": "2332612",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "147/5824-1",
                        "text": "Hongxu Chen 0001"
                    },
                    {
                        "@pid": "162/3606",
                        "text": "Shengjian Guo"
                    },
                    {
                        "@pid": "73/7055",
                        "text": "Yinxing Xue"
                    },
                    {
                        "@pid": "58/10567",
                        "text": "Yulei Sui"
                    },
                    {
                        "@pid": "200/7275",
                        "text": "Cen Zhang"
                    },
                    {
                        "@pid": "204/3729",
                        "text": "Yuekang Li"
                    },
                    {
                        "@pid": "46/1165",
                        "text": "Haijun Wang"
                    },
                    {
                        "@pid": "51/3710-3",
                        "text": "Yang Liu 0003"
                    }
                ]
            },
            "title": "MUZZ: Thread-aware Grey-box Fuzzing for Effective Bug Hunting in Multithreaded Programs.",
            "venue": "USENIX Security Symposium",
            "pages": "2325-2342",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChenGXSZLWL20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/chen-hongxu",
            "url": "https://dblp.org/rec/conf/uss/ChenGXSZLWL20",
            "abstract": "Grey-box fuzz testing has revealed thousands of vulnerabilities in real-world software owing to its lightweight instrumentation, fast coverage feedback, and dynamic adjusting strategies. However, directly applying grey-box fuzzing to input-dependent multithreaded programs can be extremely inefficient. In practice, multithreading-relevant bugs are usually buried in sophisticated program flows. Meanwhile, the existing grey-box fuzzing techniques do not stress thread-interleavings which affect execution states in multithreaded programs. Therefore, mainstream grey-box fuzzers cannot effectively test problematic segments in multithreaded programs despite they might obtain high code coverage statistics. \nTo this end, we propose MUZZ, a new grey-box fuzzing technique that hunts for bugs in multithreaded programs. MUZZ owns three novel thread-aware instrumentations, namely coverage-oriented instrumentation, thread-context instrumentation, and schedule-intervention instrumentation. During fuzzing, these instrumentations engender runtime feedback to stress execution states caused by thread interleavings. By leveraging the feedback in the dynamic seed selection and execution strategies, MUZZ preserves more valuable seeds that expose bugs in a multithreading context. \nWe evaluate MUZZ on 12 real-world software programs. Experiments show that MUZZ outperforms AFL in both multithreading-relevant seed generation and concurrency-vulnerability detection. Further, by replaying the target programs against the generated seeds, MUZZ also reveals more concurrency-bugs (e.g., data-races, thread-leaks) than AFL. In total, MUZZ detected 8 new concurrency-vulnerabilities and 19 new concurrency-bugs. At the time of writing, 4 CVE IDs have been assigned to the reported issues.",
            "keywords": [
                "Grey-box Fuzzing",
                "Multithreaded Programs",
                "Concurrency Bugs",
                "Thread Interleavings",
                "Vulnerability Detection"
            ]
        },
        "url": "URL#2332612",
        "sema_paperId": "35cc8e42362f4067c31d189578051a46a479bd26"
    },
    {
        "@score": "1",
        "@id": "2332613",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "42/1159",
                        "text": "Jiayi Chen"
                    },
                    {
                        "@pid": "04/6136",
                        "text": "Urs Hengartner"
                    },
                    {
                        "@pid": "83/7562",
                        "text": "Hassan Khan"
                    },
                    {
                        "@pid": "m/MohammadMannan",
                        "text": "Mohammad Mannan"
                    }
                ]
            },
            "title": "Chaperone: Real-time Locking and Loss Prevention for Smartphones.",
            "venue": "USENIX Security Symposium",
            "pages": "325-342",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChenHKM20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/chen-jiayi",
            "url": "https://dblp.org/rec/conf/uss/ChenHKM20",
            "abstract": "Smartphone loss affects millions of users each year and causes significant monetary and data losses. Device tracking services (e.g., Google\u2019s \u201cFind My Device\u201d) enable the device owner to secure or recover a lost device, but they can be easily circumvented with physical access (e.g., turn on airplane mode). An effective loss prevention solution should immediately lock the phone and alert the owner before they leave without the phone. We present such an opensource, real-time system called Chaperone that does not require additional hardware. Chaperone adopts active acoustic sensing to detect a phone\u2019s unattended status by tracking the owner\u2019s departure via the built-in speaker and microphone. It is designed to robustly operate in real-world scenarios characterized by bursting highfrequency noise, bustling crowds, and diverse environmental layouts. We evaluate Chaperone by conducting over 1,300 experiments at a variety of locations including coffee shops, restaurants, transit stations, and cars, under different testing conditions. Chaperone provides an overall precision rate of 93% and an overall recall rate of 96% for smartphone loss events. Chaperone detects these events in under 0.5 seconds for 95% of the successful detection cases. We conduct a user study (n = 17) to investigate participants\u2019 smartphone loss experiences, collect feedback on using Chaperone, and study different alert methods. Most participants were satisfied with Chaperone\u2019s performance for its detection ability, detection accuracy, and power consumption. Finally, we provide an implementation of Chaperone as a standalone Android app.",
            "keywords": [
                "Smartphone Loss Prevention",
                "Real-time Detection",
                "Active Acoustic Sensing",
                "Device Locking",
                "User Alert System"
            ]
        },
        "url": "URL#2332613",
        "sema_paperId": "5a757459901955712b89a43b2fa2258ecfb0f411"
    },
    {
        "@score": "1",
        "@id": "2332614",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "20/1036-5",
                        "text": "Jianjun Chen 0005"
                    },
                    {
                        "@pid": "p/VernPaxson",
                        "text": "Vern Paxson"
                    },
                    {
                        "@pid": "00/2797-2",
                        "text": "Jian Jiang 0002"
                    }
                ]
            },
            "title": "Composition Kills: A Case Study of Email Sender Authentication.",
            "venue": "USENIX Security Symposium",
            "pages": "2183-2199",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChenPJ20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/chen-jianjun",
            "url": "https://dblp.org/rec/conf/uss/ChenPJ20",
            "abstract": "Component-based software design has been widely adopted as a way to manage complexity and improve reusability. The approach divides complex systems into smaller modules that can be independently created and reused in different systems. One then combines these components together to achieve desired functionality. Modern software systems are commonly built using components made by different developers who work independently.",
            "keywords": [
                "Component-based Software Design",
                "Email Sender Authentication",
                "Software Composition",
                "Authentication Vulnerabilities",
                "Complex System Management"
            ]
        },
        "url": "URL#2332614",
        "sema_paperId": "b7a9b8710d59138406131f9a7372bef4472e053e"
    },
    {
        "@score": "1",
        "@id": "2332615",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "145/7790",
                        "text": "Yuxuan Chen"
                    },
                    {
                        "@pid": "213/8010",
                        "text": "Xuejing Yuan"
                    },
                    {
                        "@pid": "93/10773",
                        "text": "Jiangshan Zhang"
                    },
                    {
                        "@pid": "48/76-18",
                        "text": "Yue Zhao 0018"
                    },
                    {
                        "@pid": "65/3618",
                        "text": "Shengzhi Zhang"
                    },
                    {
                        "@pid": "c/KaiChen12",
                        "text": "Kai Chen 0012"
                    },
                    {
                        "@pid": "06/6268",
                        "text": "XiaoFeng Wang 0001"
                    }
                ]
            },
            "title": "Devil&apos;s Whisper: A General Approach for Physical Adversarial Attacks against Commercial Black-box Speech Recognition Devices.",
            "venue": "USENIX Security Symposium",
            "pages": "2667-2684",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChenYZ0Z0020",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/chen-yuxuan",
            "url": "https://dblp.org/rec/conf/uss/ChenYZ0Z0020",
            "abstract": "Recently studies show that adversarial examples (AEs) can pose a serious threat to a \u201cwhite-box\u201d automatic speech recognition (ASR) system, when its machine-learning model is exposed to the adversary. Less clear is how realistic such a threat would be towards commercial devices, such as Google Home, Cortana, Echo, etc., whose models are not publicly available. Exploiting the learning model behind ASR system in black-box is challenging, due to the presence of complicated preprocessing and feature extraction even before the AEs could reach the model. Our research, however, shows that such a black-box attack is realistic. In the paper, we present Devil\u2019s Whisper, a general adversarial attack on commercial ASR systems. Our idea is to enhance a simple local model roughly approximating the target black-box platform with a white-box model that is more advanced yet unrelated to the target. We find that these two models can effectively complement each other in predicting the target\u2019s behavior, which enables highly transferable and generic attacks on the target. Using a novel optimization technique, we show that a local model built upon just over 1500 queries can be elevated by the open-source Kaldi Aspire Chain Model to effectively exploit commercial devices (Google Assistant, Google Home, Amazon Echo and Microsoft Cortana). For 98% of the target commands of these devices, our approach can generate at least one AE for attacking the target devices.",
            "pdf_url": "",
            "keywords": [
                "Adversarial Attacks",
                "Automatic Speech Recognition",
                "Black-box Systems",
                "Commercial Devices",
                "Transferable Adversarial Examples"
            ]
        },
        "url": "URL#2332615"
    },
    {
        "@score": "1",
        "@id": "2332616",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "224/9379",
                        "text": "Weiteng Chen"
                    },
                    {
                        "@pid": "210/0533",
                        "text": "Xiaochen Zou"
                    },
                    {
                        "@pid": "272/7041",
                        "text": "Guoren Li"
                    },
                    {
                        "@pid": "31/8302",
                        "text": "Zhiyun Qian"
                    }
                ]
            },
            "title": "KOOBE: Towards Facilitating Exploit Generation of Kernel Out-Of-Bounds Write Vulnerabilities.",
            "venue": "USENIX Security Symposium",
            "pages": "1093-1110",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChenZLQ20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/chen-weiteng",
            "url": "https://dblp.org/rec/conf/uss/ChenZLQ20",
            "abstract": "The monolithic nature of modern OS kernels leads to a constant stream of bugs being discovered. It is often unclear which of these bugs are worth \ufb01xing, as only a subset of them may be serious enough to lead to security takeovers ( i.e., privilege escalations). Therefore, researchers have recently started to develop automated exploit generation techniques (for UAF bugs) to assist the bug triage process. In this paper, we investigate another top memory vulnerability in Linux kernel \u2014 out-of-bounds (OOB) memory write from heap. We design KOOBE to assist the analysis of such vulnerabilities based on two observations: (1) Surprisingly often, different OOB vulnerability instances exhibit a wide range of capabilities. (2) Kernel exploits are multi-interaction in nature ( i.e., multiple syscalls are involved in an exploit) which allows the exploit crafting process to be modular. Speci\ufb01cally, we focus on the extraction of capabilities of an OOB vulnerability which will feed the subsequent exploitability evaluation process. Our system builds on several building blocks, including a novel capability-guided fuzzing solution to uncover hidden capabilities, and a way to compose capabilities together to further enhance the likelihood of successful exploitations. In our evaluation, we demonstrate the applicability of KOOBE by exhaustively analyzing 17 most recent Linux kernel OOB vulnerabilities (where only 5 of them have publicly available exploits), for which KOOBE successfully generated candidate exploit strategies for 11 of them (including 5 that do not even have any CVEs assigned). Subsequently from these strategies, we are able to construct fully working exploits for all of them.",
            "keywords": [
                "Kernel Vulnerabilities",
                "Out-Of-Bounds Write",
                "Exploit Generation",
                "Capability Extraction",
                "Linux Kernel Security"
            ]
        },
        "url": "URL#2332616",
        "sema_paperId": "74aa2ceeb0e0772ee6c1ea736944eb5bb89d2a91"
    },
    {
        "@score": "1",
        "@id": "2332618",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "126/1782",
                        "text": "Jake Christensen"
                    },
                    {
                        "@pid": "272/7097",
                        "text": "Ionut Mugurel Anghel"
                    },
                    {
                        "@pid": "272/7132",
                        "text": "Rob Taglang"
                    },
                    {
                        "@pid": "187/8996",
                        "text": "Mihai Chiroiu"
                    },
                    {
                        "@pid": "s/RaduSion",
                        "text": "Radu Sion"
                    }
                ]
            },
            "title": "DECAF: Automatic, Adaptive De-bloating and Hardening of COTS Firmware.",
            "venue": "USENIX Security Symposium",
            "pages": "1713-1730",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChristensenATCS20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/christensen",
            "url": "https://dblp.org/rec/conf/uss/ChristensenATCS20",
            "abstract": "Once compromised, server \ufb01rmware can surreptitiously and permanently take over a machine and any stack running thereon, with no hope for recovery, short of hardware-level intervention. To make things worse, modern \ufb01rmware contains millions of lines of unnecessary code and hundreds of unnecessary modules as a result of a long \ufb01rmware supply chain designed to optimize time-to-market and cost, but not security. As a result, off-the-shelf motherboards contain large, unnecessarily complex, closed-source vulnerability surfaces that can completely and irreversibly compromise systems. In this work, we address this problem by dramatically and automatically reducing the vulnerability surface. DECAF is an extensible platform for automatically pruning a wide class of commercial UEFI \ufb01rmware. DECAF intelligently runs dynamic iterative surgery on UEFI \ufb01rmware to remove a maximal amount of code with no regressive effects on the functionality and performance of higher layers in the stack (OS, applications). DECAF has successfully pruned over 70% of unnecessary, redundant, reachable \ufb01rmware in leading server-grade moth-erboards with no effect on the upper layers, and increased resulting system performance and boot times.",
            "keywords": [
                "Firmware Security",
                "UEFI Firmware",
                "Vulnerability Surface Reduction",
                "Dynamic Code Pruning",
                "COTS Firmware Hardening"
            ]
        },
        "url": "URL#2332618",
        "sema_paperId": "f456980df02291cd5e1e188a14c5aef9b7a874f9"
    },
    {
        "@score": "1",
        "@id": "2332619",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "187/9046",
                        "text": "Abraham A. Clements"
                    },
                    {
                        "@pid": "121/1138",
                        "text": "Eric Gustafson"
                    },
                    {
                        "@pid": "272/7190",
                        "text": "Tobias Scharnowski"
                    },
                    {
                        "@pid": "212/6813",
                        "text": "Paul Grosen"
                    },
                    {
                        "@pid": "153/2079",
                        "text": "David Fritz"
                    },
                    {
                        "@pid": "k/ChristopherKruegel",
                        "text": "Christopher Kruegel"
                    },
                    {
                        "@pid": "v/GiovanniVigna",
                        "text": "Giovanni Vigna"
                    },
                    {
                        "@pid": "57/95",
                        "text": "Saurabh Bagchi"
                    },
                    {
                        "@pid": "31/1273",
                        "text": "Mathias Payer"
                    }
                ]
            },
            "title": "HALucinator: Firmware Re-hosting Through Abstraction Layer Emulation.",
            "venue": "USENIX Security Symposium",
            "pages": "1201-1218",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ClementsGSGFKVB20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/clements",
            "url": "https://dblp.org/rec/conf/uss/ClementsGSGFKVB20",
            "abstract": "Given the increasing ubiquity of online embedded devices, analyzing their \ufb01rmware is important to security, privacy, and safety. The tight coupling between hardware and \ufb01rmware and the diversity found in embedded systems makes it hard to perform dynamic analysis on \ufb01rmware. However, \ufb01rmware developers regularly develop code using abstractions, such as Hardware Abstraction Layers (HALs), to simplify their job. We leverage such abstractions as the basis for the re-hosting and analysis of \ufb01rmware. By providing high-level replacements for HAL functions (a process termed High-Level Emulation \u2013 HLE ), we decouple the hardware from the \ufb01rmware. This approach works by \ufb01rst locating the library functions in a \ufb01rmware sample, through binary analysis, and then providing generic implementations of these functions in a full-system emulator. Wepresent these ideas in a prototype system, HALucinator, able to re-host \ufb01rmware, and allow the virtual device to be used normally. First, we introduce extensions to existing library matching techniques that are needed to identify library functions in binary \ufb01rmware, to reduce collisions, and for inferring additional function names. Next, we demonstrate the re-hosting process, through the use of simpli\ufb01ed handlers and peripheral models , which make the process fast, \ufb02exible, and portable between \ufb01rmware samples",
            "keywords": [
                "Embedded Systems",
                "Firmware Analysis",
                "Hardware Abstraction Layers",
                "Dynamic Analysis",
                "High-Level Emulation (HLE)"
            ]
        },
        "url": "URL#2332619",
        "sema_paperId": "c8bbda223845d8253d307675474cc1c2b70d07c4"
    },
    {
        "@score": "1",
        "@id": "2332620",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "270/1642",
                        "text": "Tobias Cloosters"
                    },
                    {
                        "@pid": "132/9407",
                        "text": "Michael Rodler"
                    },
                    {
                        "@pid": "73/7564",
                        "text": "Lucas Davi"
                    }
                ]
            },
            "title": "TeeRex: Discovery and Exploitation of Memory Corruption Vulnerabilities in SGX Enclaves.",
            "venue": "USENIX Security Symposium",
            "pages": "841-858",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CloostersRD20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/cloosters",
            "url": "https://dblp.org/rec/conf/uss/CloostersRD20",
            "abstract": "Intel's Software Guard Extensions (SGX) introduced new instructions to switch\nthe processor to enclave mode which protects it from introspection. While\nthe enclave mode strongly protects the memory and the state of the processor,\nit cannot withstand memory corruption errors inside the enclave code. In this\npaper, we show that the attack surface of SGX enclaves provides new challenges\nfor enclave developers as exploitable memory corruption vulnerabilities are\neasily introduced into enclave code. We develop TeeRex to automatically analyze\nenclave binary code for vulnerabilities introduced at the host-to-enclave\nboundary by means of symbolic execution. Our evaluation on public enclave\nbinaries reveal that many of them suffer from memory corruption errors allowing\nan attacker to corrupt function pointers or perform arbitrary memory writes. As\nwe will show, TeeRex features a specifically tailored framework for SGX\nenclaves that allows simple proof-of-concept exploit construction to assess the\ndiscovered vulnerabilities. Our findings reveal vulnerabilities in multiple\nenclaves, including enclaves developed by Intel, Baidu, and WolfSSL, as well as\nbiometric fingerprint software deployed on popular laptop brands.",
            "pdf_url": "",
            "keywords": [
                "SGX Enclaves",
                "Memory Corruption",
                "Vulnerability Analysis",
                "Symbolic Execution",
                "Host-to-Enclave Boundary"
            ]
        },
        "url": "URL#2332620"
    },
    {
        "@score": "1",
        "@id": "2332621",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "177/2254",
                        "text": "Katriel Cohn-Gordon"
                    },
                    {
                        "@pid": "200/2459",
                        "text": "Georgios Damaskinos"
                    },
                    {
                        "@pid": "272/7050",
                        "text": "Divino Neto"
                    },
                    {
                        "@pid": "272/7076",
                        "text": "Joshi Cordova"
                    },
                    {
                        "@pid": "272/7233",
                        "text": "Beno\u00eet Reitz"
                    },
                    {
                        "@pid": "39/8142",
                        "text": "Benjamin Strahs"
                    },
                    {
                        "@pid": "133/3718",
                        "text": "Daniel Obenshain"
                    },
                    {
                        "@pid": "61/1749",
                        "text": "Paul Pearce"
                    },
                    {
                        "@pid": "45/4905",
                        "text": "Ioannis Papagiannis"
                    },
                    {
                        "@pid": "272/7073",
                        "text": "Available Media"
                    }
                ]
            },
            "title": "DELF: Safeguarding deletion correctness in Online Social Networks.",
            "venue": "USENIX Security Symposium",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Cohn-GordonDNCR20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/cohn-gordon",
            "url": "https://dblp.org/rec/conf/uss/Cohn-GordonDNCR20",
            "abstract": "Deletion is a core facet of Online Social Networks (OSNs). For users, deletion is a tool to remove what they have shared and control their data. For OSNs, robust deletion is both an obligation to their users and a risk when developer mistakes inevitably occur. While developers are effective at identifying high-level deletion requirements in products (e.g., users should be able to delete posted photos), they are less effective at mapping high-level requirements into concrete operations (e.g., deleting all relevant items in data stores). Without framework support, developer mistakes lead to violations of users\u2019 privacy, such as retaining data that should be deleted, deleting the wrong data, and exploitable vulnerabilities. We propose DELF, a deletion framework for modern OSNs. In DELF, developers specify deletion annotations on data type definitions, which the framework maps into asynchronous, reliable and temporarily reversible operations on backing data stores. DELF validates annotations both statically and dynamically, proactively flagging errors and suggesting fixes. We deployed DELF in three distinct OSNs, showing the feasibility of our approach. DELF detected, surfaced, and helped developers correct thousands of omissions and dozens of mistakes, while also enabling timely recovery in tens of incidents where user data was inadvertently deleted.",
            "keywords": [
                "Online Social Networks",
                "Data Deletion",
                "Privacy Protection",
                "Deletion Framework",
                "Developer Errors"
            ]
        },
        "url": "URL#2332621",
        "sema_paperId": "65dc5e38f83e7f59e221246ca8fd7a090aa0185c"
    },
    {
        "@score": "1",
        "@id": "2332622",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "184/4259",
                        "text": "R. Joseph Connor"
                    },
                    {
                        "@pid": "185/1211",
                        "text": "Tyler McDaniel"
                    },
                    {
                        "@pid": "180/3218",
                        "text": "Jared M. Smith"
                    },
                    {
                        "@pid": "54/8732",
                        "text": "Max Schuchard"
                    }
                ]
            },
            "title": "PKU Pitfalls: Attacks on PKU-based Memory Isolation Systems.",
            "venue": "USENIX Security Symposium",
            "pages": "1409-1426",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ConnorMSS20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/connor",
            "url": "https://dblp.org/rec/conf/uss/ConnorMSS20",
            "abstract": "Intra-process memory isolation can improve security by enforcing least-privilege at a \ufb01ner granularity than traditional operating system controls without the context-switch overhead associated with inter -process communication. A single process can be divided into separate components such that memory belonging to one component can only be accessed by the code of that component. Because the process has traditionally been a fundamental security boundary, assigning different levels of trust to components within a process is a fundamental change in secure systems design. However, so far there has been little research on the challenges of securely implementing intra-process isolation on top of existing operating system abstractions. We identify that despite providing strong intra-process memory isolation, existing, general purpose approaches neglect the ways in which the OS makes memory and other intra-process resources accessible through system objects. Using two recently-proposed memory isolation systems, we show that such designs are vulnerable to generic attacks that bypass memory isolation These attacks use the kernel as a confused deputy, taking advantage of existing intended kernel functionality that is agnostic of intra-process isolation. We argue that the root cause stems from a fundamentally different security model between kernel abstractions and user-level, intra-process memory isolation. Finally, we discuss potential mitigations and show that the performance cost of extending a ptrace -based sandbox to prevent the new attacks is high, highlighting the need for more ef\ufb01cient system call interception",
            "keywords": [
                "Intra-process Memory Isolation",
                "Kernel Abstractions",
                "Security Model",
                "Memory Isolation Attacks",
                "System Call Interception"
            ]
        },
        "url": "URL#2332622",
        "sema_paperId": "0343e348da0626f9bfae9e0e72a0d4ef02491493"
    },
    {
        "@score": "1",
        "@id": "2332623",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "17/2282",
                        "text": "Cas Cremers"
                    },
                    {
                        "@pid": "167/5022",
                        "text": "Benjamin Kiesl"
                    },
                    {
                        "@pid": "272/7168",
                        "text": "Niklas Medinger"
                    }
                ]
            },
            "title": "A Formal Analysis of IEEE 802.11&apos;s WPA2: Countering the Kracks Caused by Cracking the Counters.",
            "venue": "USENIX Security Symposium",
            "pages": "1-17",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CremersKM20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/cremers",
            "url": "https://dblp.org/rec/conf/uss/CremersKM20",
            "abstract": "The IEEE 802.11 WPA2 protocol is widely used across the globe to protect network connections. The protocol, which is specified on more than three-thousand pages and has received various patches over the years, is extremely complex and therefore hard to analyze. In particular, it involves various mechanisms that interact with each other in subtle ways, which offers little hope for modular reasoning. Perhaps because of this, there exists no formal or cryptographic argument that shows that the patches to the core protocol indeed prevent the corresponding attacks, such as, e.g., the notorious KRACK attacks from 2017. In this work, we address this situation and present an extensive formal analysis of the WPA2 protocol design. Our model is the first that is detailed enough to detect the KRACK attacks; it includes mechanisms such as the four-way handshake, the group-key handshake, WNM sleep mode, the dataconfidentiality protocol, and their complex interactions. Our analysis provides the first security argument, in any formalism, that the patched WPA2 protocol meets its claimed security guarantees in the face of complex modern attacks.",
            "keywords": [
                "WPA2 Protocol",
                "Formal Analysis",
                "KRACK Attacks",
                "Security Guarantees",
                "Complex Interactions"
            ]
        },
        "url": "URL#2332623",
        "sema_paperId": "608199c62713d4233bb2f8dbea9040fe9072ce53"
    },
    {
        "@score": "1",
        "@id": "2332624",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "217/3746",
                        "text": "Jiarun Dai"
                    },
                    {
                        "@pid": "48/2168-9",
                        "text": "Yuan Zhang 0009"
                    },
                    {
                        "@pid": "272/7066",
                        "text": "Zheyue Jiang"
                    },
                    {
                        "@pid": "272/7229",
                        "text": "Yingtian Zhou"
                    },
                    {
                        "@pid": "16/9279",
                        "text": "Junyan Chen"
                    },
                    {
                        "@pid": "40/6431",
                        "text": "Xinyu Xing"
                    },
                    {
                        "@pid": "96/6053-1",
                        "text": "Xiaohan Zhang 0001"
                    },
                    {
                        "@pid": "89/6413",
                        "text": "Xin Tan"
                    },
                    {
                        "@pid": "02/1640-2",
                        "text": "Min Yang 0002"
                    },
                    {
                        "@pid": "55/11040",
                        "text": "Zhemin Yang"
                    }
                ]
            },
            "title": "BScout: Direct Whole Patch Presence Test for Java Executables.",
            "venue": "USENIX Security Symposium",
            "pages": "1147-1164",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Dai0JZCXZT0Y20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/dai",
            "url": "https://dblp.org/rec/conf/uss/Dai0JZCXZT0Y20",
            "abstract": "To protect end-users and software from known vulnerabilities, it is crucial to apply security patches to affected executables timely. To this end, patch presence tests are proposed with the capability of independently investigating patch application status on a target without source code. Existing work on patch presence testing adopts a signature-based approach. To make a trade-off between the uniqueness and the stability of the signature, existing work is limited to use a small and localized patch snippet (instead of the whole patch) for signature generation, so they are inherently unreliable. In light of this, we present BSCOUT, which directly checks the presence of a whole patch in Java executables without generating signatures. BSCOUT features several new techniques to bridge the semantic gap between source code and bytecode instructions during the testing, and accurately checks the fine-grained patch semantics in the whole target executable. We evaluate BScout with 194 CVEs from the Android framework and third-party libraries. The results show that it achieves remarkable accuracy with and without line number information (i.e., debug information) presented in a target executable. We further apply BSCOUT to perform a large-scale patch application practice study with 2,506 Android system images from 7 vendors. Our study reveals many findings that have not yet been reported.",
            "keywords": [
                "Patch Presence Testing",
                "Java Executables",
                "Vulnerability Mitigation",
                "Semantic Analysis",
                "BScout"
            ]
        },
        "url": "URL#2332624",
        "sema_paperId": "b42e072da9825db1d16da3b420cf868868436ba5"
    },
    {
        "@score": "1",
        "@id": "2332625",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "171/6802",
                        "text": "Leila Delshadtehrani"
                    },
                    {
                        "@pid": "216/7277",
                        "text": "Sadullah Canakci"
                    },
                    {
                        "@pid": "163/3695",
                        "text": "Boyou Zhou"
                    },
                    {
                        "@pid": "145/7549",
                        "text": "Schuyler Eldridge"
                    },
                    {
                        "@pid": "23/3290",
                        "text": "Ajay Joshi"
                    },
                    {
                        "@pid": "27/3108",
                        "text": "Manuel Egele"
                    }
                ]
            },
            "title": "PHMon: A Programmable Hardware Monitor and Its Security Use Cases.",
            "venue": "USENIX Security Symposium",
            "pages": "807-824",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DelshadtehraniC20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/delshadtehrani",
            "url": "https://dblp.org/rec/conf/uss/DelshadtehraniC20",
            "abstract": "There has been a resurgent trend in the industry to enforce a variety of security policies in hardware. The current trend for developing dedicated hardware security extensions is an imperfect, lengthy, and costly process. In contrast to this trend, a \ufb02exible hardware monitor can ef\ufb01ciently enforce and enhance a variety of security policies as security threats evolve. Existing hardware monitors typically suffer from one (or more) of the following drawbacks: a restricted set of monitoring actions, considerable performance and power overheads, or an invasive design. In this paper, we propose a minimally-invasive and ef\ufb01cient implementation of a Programmable Hardware Monitor (PHMon) with expressive monitoring rules and \ufb02exible \ufb01ne-grained actions. PHMon can enforce a variety of security policies and can also assist with detecting software bugs and security vulnerabilities. Our prototype of PHMon on an FPGA includes the hardware monitor and its interface with a RISC-V Rocket processor as well as a complete Linux software stack. We demonstrate the versatility of PHMon and its ease of adoption through four different use cases: a shadow stack, a hardware-accelerated fuzzing engine, an information leak prevention mechanism, and a hardware-accelerated debugger. Our prototype implementation of PHMon incurs 0.9% performance overhead on average, while the hardware-accelerated fuzzing engine improves fuzzing performance on average by 16 \u00d7 over the state-of-the art software-based implementation. Our ASIC implementation of PHMon only incurs a 5% power overhead and a 13.5% area overhead.",
            "keywords": [
                "Programmable Hardware Monitor",
                "Hardware Security",
                "Security Policies",
                "FPGA Implementation",
                "Performance Overhead"
            ]
        },
        "url": "URL#2332625",
        "sema_paperId": "4cfb5e0054bea94964f51b6147b475a94a538ccc"
    },
    {
        "@score": "1",
        "@id": "2332626",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "181/5758",
                        "text": "Ioannis Demertzis"
                    },
                    {
                        "@pid": "18/9002",
                        "text": "Dimitrios Papadopoulos 0001"
                    },
                    {
                        "@pid": "p/CharalamposPapamanthou",
                        "text": "Charalampos Papamanthou"
                    },
                    {
                        "@pid": "129/0982",
                        "text": "Saurabh Shintre"
                    }
                ]
            },
            "title": "SEAL: Attack Mitigation for Encrypted Databases via Adjustable Leakage.",
            "venue": "USENIX Security Symposium",
            "pages": "2433-2450",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DemertzisPPS20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/demertzis",
            "url": "https://dblp.org/rec/conf/uss/DemertzisPPS20",
            "abstract": "Building expressive encrypted databases that can scale to large volumes of data while enjoying formal security guarantees has been one of the holy grails of security and cryptography research. Searchable Encryption (SE) is considered to be an attractive implementation choice for this goal: It naturally supports basic database queries such as point, join, group-by and range, and is very practical at the expense of well-defined leakage such as search and access pattern. Nevertheless, recent attacks have exploited these leakages to recover the plaintext database or the posed queries, casting doubt to the usefulness of SE in encrypted systems. Defenses against such leakage-abuse attacks typically require the use of Oblivious RAM or worst-case padding---such countermeasures are however quite impractical. In order to efficiently defend against leakage-abuse attacks on SE-based systems, we propose SEAL, a family of new SE schemes with adjustable leakage. In SEAL, the amount of privacy loss is expressed in leaked bits of search or access pattern and can be defined at setup. As our experiments  show, when protecting only a few bits of leakage (e.g., three to four bits of access pattern), enough for existing and even new more aggressive attacks to fail, SEAL's query execution time is within the realm of practical for real-world applications (a little over one order of magnitude slowdown compared to traditional SE-based encrypted databases). Thus, SEAL could comprise a promising approach to build efficient and robust encrypted databases.",
            "pdf_url": "",
            "keywords": [
                "Searchable Encryption",
                "Encrypted Databases",
                "Leakage Mitigation",
                "Privacy Loss",
                "SEAL"
            ]
        },
        "url": "URL#2332626"
    },
    {
        "@score": "1",
        "@id": "2332627",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "153/0574",
                        "text": "Ghada Dessouky"
                    },
                    {
                        "@pid": "189/1758",
                        "text": "Tommaso Frassetto"
                    },
                    {
                        "@pid": "s/AhmadRezaSadeghi",
                        "text": "Ahmad-Reza Sadeghi"
                    }
                ]
            },
            "title": "HybCache: Hybrid Side-Channel-Resilient Caches for Trusted Execution Environments.",
            "venue": "USENIX Security Symposium",
            "pages": "451-468",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DessoukyFS20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/dessouky",
            "url": "https://dblp.org/rec/conf/uss/DessoukyFS20",
            "abstract": "Modern multi-core processors share cache resources for maximum cache utilization and performance gains. However, this leaves the cache vulnerable to side-channel attacks, where inherent timing differences in shared cache behavior are exploited to infer information on the victim\u2019s execution patterns, ultimately leaking private information such as a secret key. The root cause for these attacks is mutually distrusting processes sharing the cache entries and accessing them in a deterministic and consistent manner. Various defenses against cache side-channel attacks have been proposed. However, they suffer from serious shortcomings: they either degrade performance significantly, impose impractical restrictions, or can only defeat certain classes of these attacks. More importantly, they assume that side-channel-resilient caches are required for the entire execution workload and do not allow the possibility to selectively enable the mitigation only for the security-critical portion of the workload.We present a generic mechanism for a flexible and soft partitioning of set-associative caches and propose a hybrid cache architecture, called HybCache. HybCache can be configured to selectively apply side-channel-resilient cache behavior only for isolated execution domains, while providing the non-isolated execution with conventional cache behavior, capacity and performance. An isolation domain can include one or more processes, specific portions of code, or a Trusted Execution Environment (e.g., SGX or TrustZone). We show that, with minimal hardware modifications and kernel support, HybCache can provide side-channel-resilient cache only for isolated execution with a performance overhead of 3.5\u20135%, while incurring no performance overhead for the remaining execution workload. We provide a simulator-based and hardware implementation of HybCache to evaluate the performance and area overheads, and show how HybCache mitigates typical access-based and contention-based cache attacks",
            "pdf_url": "",
            "keywords": [
                "Cache Architecture",
                "Side-Channel Attacks",
                "Trusted Execution Environments",
                "HybCache",
                "Performance Overhead"
            ]
        },
        "url": "URL#2332627"
    },
    {
        "@score": "1",
        "@id": "2332628",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "141/0599",
                        "text": "Siva Nishok Dhanuskodi"
                    },
                    {
                        "@pid": "40/1491",
                        "text": "Xiang Li"
                    },
                    {
                        "@pid": "67/7583",
                        "text": "Daniel E. Holcomb"
                    }
                ]
            },
            "title": "COUNTERFOIL: Verifying Provenance of Integrated Circuits using Intrinsic Package Fingerprints and Inexpensive Cameras.",
            "venue": "USENIX Security Symposium",
            "pages": "1255-1272",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DhanuskodiLH20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/dhanuskodi",
            "url": "https://dblp.org/rec/conf/uss/DhanuskodiLH20",
            "abstract": "Counterfeit integrated circuits are responsible for billions of dollars in losses to the semiconductor industry each year, and jeopardize the reliability of critical systems that unwittingly rely on them. Counterfeit parts, which are primarily recycled, test rejects, or legitimate but regraded, have to date been found in a number of systems, including critical defense systems. In this work, we present COUNTERFOIL \u2013 an anti-counterfeiting system based on enrolling and authenticating intrinsic features of the molded packages that enclose a majority of semiconductor chips sold on the market. Our system relies on computer-readable labels, inexpensive cameras, imaging processing using OpenCV, and digital signatures, to enroll and verify chip packages. We demonstrate our approach on a dataset from over 100 chips. Our method is able to authenticate chips within 150ms, which makes it suitable for real-time use in pick-and-place machines. We show that our technique is effective and reliable for verifying provenance under a variety of settings, and evaluate the robustness of the package features by using different imaging platforms, and by wearing the chips with silicon carbide polishing grit in a rock tumbler. We show that, even if an adversary steals the exact mold used to produce an enrolled chip package, he will have limited success in being able to counterfeit the chip.",
            "keywords": [
                "Integrated Circuits",
                "Counterfeit Detection",
                "Provenance Verification",
                "Intrinsic Package Fingerprints",
                "Imaging Authentication"
            ]
        },
        "url": "URL#2332628",
        "sema_paperId": "32720feb9537fcd9943118ced3a87693533835a4"
    },
    {
        "@score": "1",
        "@id": "2332629",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "241/6211",
                        "text": "Zain ul Abi Din"
                    },
                    {
                        "@pid": "257/7230",
                        "text": "Hari Venugopalan"
                    },
                    {
                        "@pid": "272/7067",
                        "text": "Jaime Park"
                    },
                    {
                        "@pid": "132/1119",
                        "text": "Andy Li"
                    },
                    {
                        "@pid": "272/7047",
                        "text": "Weisu Yin"
                    },
                    {
                        "@pid": "24/129",
                        "text": "Haohui Mai"
                    },
                    {
                        "@pid": "15/5471",
                        "text": "Yong Jae Lee"
                    },
                    {
                        "@pid": "74/5947",
                        "text": "Steven Liu"
                    },
                    {
                        "@pid": "54/5833",
                        "text": "Samuel T. King"
                    }
                ]
            },
            "title": "Boxer: Preventing fraud by scanning credit cards.",
            "venue": "USENIX Security Symposium",
            "pages": "1571-1588",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DinVPLYMLLK20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/din",
            "url": "https://dblp.org/rec/conf/uss/DinVPLYMLLK20",
            "abstract": "Card-not-present credit card fraud costs businesses billions of dollars a year. In this paper, we present Boxer, a mobile SDK and server that enables apps to combat card-not-present fraud by scanning cards and verifying that they are genuine. Boxer analyzes the images from these scans, looking for telltale signs of attacks, and introduces a novel abstraction on top of modern security hardware for complementary protection. Currently, 323 apps have integrated Boxer, and tens of them have deployed it to production, including some large, popular, and international apps, resulting in Boxer scanning over 10 million real cards already. Our evaluation of Boxer from one of these deployments shows ten cases of real attacks that our novel hardware-based abstraction detects. Additionally, from the same deployment, without letting in any fraud, Boxer\u2019s card scanning recovers 89% of the good users whom the app would have blocked. In another evaluation of Boxer, we run our image analysis models against images from real users and show an accuracy of 96% and 100% on the two models that we use.",
            "keywords": [
                "Card-Not-Present Fraud",
                "Mobile SDK",
                "Credit Card Scanning",
                "Fraud Detection",
                "Image Analysis"
            ]
        },
        "url": "URL#2332629",
        "sema_paperId": "9b291e45d52c46037d6215ede1f44fafcdde6b5d"
    },
    {
        "@score": "1",
        "@id": "2332630",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "129/9841",
                        "text": "Manu Drijvers"
                    },
                    {
                        "@pid": "117/3299-1",
                        "text": "Sergey Gorbunov 0001"
                    },
                    {
                        "@pid": "30/3210",
                        "text": "Gregory Neven"
                    },
                    {
                        "@pid": "81/5927",
                        "text": "Hoeteck Wee"
                    }
                ]
            },
            "title": "Pixel: Multi-signatures for Consensus.",
            "venue": "USENIX Security Symposium",
            "pages": "2093-2110",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Drijvers0NW20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/drijvers",
            "url": "https://dblp.org/rec/conf/uss/Drijvers0NW20",
            "abstract": "In Proof-of-Stake (PoS) and permissioned blockchains, a committee of verifiers agrees and sign every new block of transactions. These blocks are validated, propagated, and stored by all users in the network. However, posterior corruptions pose a common threat to these designs, because the adversary can corrupt committee verifiers after they certified a block and use their signing keys to certify a different block. Designing efficient and secure digital signatures for use in PoS blockchains can substantially reduce bandwidth, storage and computing requirements from nodes, thereby enabling more efficient applications.We present Pixel, a pairing-based forward-secure multi-signature scheme optimized for use in blockchains, that achieves substantial savings in bandwidth, storage requirements, and verification effort. Pixel signatures consist of two group elements, regardless of the number of signers, can be verified using three pairings and one exponentiation, and support non-interactive aggregation of individual signatures into a multi-signature. Pixel signatures are also forward-secure and let signers evolve their keys over time, such that new keys cannot be used to sign on old blocks, protecting against posterior corruptions attacks on blockchains. We show how to integrate Pixel into any PoS blockchain. Next, we evaluate Pixel in a real-world PoS blockchain implementation, showing that it yields notable savings in storage, bandwidth, and block verification time. In particular, Pixel signatures reduce the size of blocks with 1500 transactions by 35% and reduce block verification time by 38%.",
            "pdf_url": "",
            "keywords": [
                "Blockchain Technology",
                "Proof-of-Stake",
                "Multi-signature Scheme",
                "Posterior Corruptions",
                "Forward-Secure Signatures"
            ]
        },
        "url": "URL#2332630"
    },
    {
        "@score": "1",
        "@id": "2332631",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "220/2826",
                        "text": "Kasra Edalatnejad"
                    },
                    {
                        "@pid": "35/9846",
                        "text": "Wouter Lueks"
                    },
                    {
                        "@pid": "266/3201",
                        "text": "Julien Pierre Martin"
                    },
                    {
                        "@pid": "266/3062",
                        "text": "Soline Led\u00e9sert"
                    },
                    {
                        "@pid": "222/8881",
                        "text": "Anne L&apos;H\u00f4te"
                    },
                    {
                        "@pid": "59/2842",
                        "text": "Bruno Thomas"
                    },
                    {
                        "@pid": "266/3242",
                        "text": "Laurent Girod"
                    },
                    {
                        "@pid": "01/4825",
                        "text": "Carmela Troncoso"
                    }
                ]
            },
            "title": "DatashareNetwork: A Decentralized Privacy-Preserving Search Engine for Investigative Journalists.",
            "venue": "USENIX Security Symposium",
            "pages": "1911-1927",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/EdalatnejadLMLL20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/edalatnejad",
            "url": "https://dblp.org/rec/conf/uss/EdalatnejadLMLL20",
            "abstract": "Investigative journalists collect large numbers of digital documents during their investigations. These documents can greatly benefit other journalists' work. However, many of these documents contain sensitive information. Hence, possessing such documents can endanger reporters, their stories, and their sources. Consequently, many documents are used only for single, local, investigations. \nWe present DatashareNetwork, a decentralized and privacy-preserving search system that enables journalists worldwide to find documents via a dedicated network of peers. DatashareNetwork combines well-known anonymous authentication mechanisms and anonymous communication primitives, a novel asynchronous messaging system, and a novel multi-set private set intersection protocol (MS-PSI) into a *decentralized peer-to-peer private document search engine*. We prove that DatashareNetwork is secure; and show using a prototype implementation that it scales to thousands of users and millions of documents.",
            "keywords": [
                "Decentralized Search Engine",
                "Privacy-Preserving",
                "Investigative Journalism",
                "Document Sharing",
                "Anonymous Communication"
            ]
        },
        "url": "URL#2332631",
        "sema_paperId": "2350c17517e15a9beecd5ba5bdb9120c3d11b776"
    },
    {
        "@score": "1",
        "@id": "2332632",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "45/7864",
                        "text": "Mohamed Elsabagh"
                    },
                    {
                        "@pid": "98/3414-2",
                        "text": "Ryan Johnson 0002"
                    },
                    {
                        "@pid": "14/5349",
                        "text": "Angelos Stavrou"
                    },
                    {
                        "@pid": "149/8302",
                        "text": "Chaoshun Zuo"
                    },
                    {
                        "@pid": "156/1033",
                        "text": "Qingchuan Zhao"
                    },
                    {
                        "@pid": "49/4102-1",
                        "text": "Zhiqiang Lin 0001"
                    }
                ]
            },
            "title": "FIRMSCOPE: Automatic Uncovering of Privilege-Escalation Vulnerabilities in Pre-Installed Apps in Android Firmware.",
            "venue": "USENIX Security Symposium",
            "pages": "2379-2396",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Elsabagh0SZZL20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/elsabagh",
            "url": "https://dblp.org/rec/conf/uss/Elsabagh0SZZL20",
            "abstract": "Android devices ship with pre-installed privileged apps in their \ufb01rmware \u2014 some of which are essential system components, others deliver a unique user experience \u2014 that users cannot disable. These pre-installed apps are assumed to be secure as they are handpicked or developed by the device vendors themselves rather than third parties. Unfortunately, we have identi\ufb01ed an alarming number of Android \ufb01rmware that contain privilege-escalation vulnerabilities in pre-installed apps, allowing attackers to perform unauthorized actions such as executing arbitrary commands, recording the device audio and screen, and accessing personal data to name a few. To uncover these vulnerabilities, we built F IRM S COPE , a novel static analysis system that analyzes Android \ufb01rmware to expose unwanted functionality in pre-installed apps using an ef\ufb01cient and practical context-sensitive, \ufb02ow-sensitive, \ufb01eld-sensitive, and partially object-sensitive taint analysis. Our experimental results demonstrate that F IRM S COPE signi\ufb01-cantly outperforms the state-of-the-art Android taint analysis solutions both in terms of detection power and runtime performance. We used F IRM S COPE to scan 331 , 342 pre-installed apps in 2 , 017 Android \ufb01rmware images from v4.0 to v9.0 from more than 100 Android vendors. Among them, F IRM - S COPE uncovered 850 unique privilege-escalation vulnerabilities, many of which",
            "keywords": [
                "Android Firmware Security",
                "Privilege Escalation Vulnerabilities",
                "Static Analysis",
                "Pre-installed Apps",
                "Taint Analysis"
            ]
        },
        "url": "URL#2332632",
        "sema_paperId": "d7b07f6f72995eb327b131a91173f66431eed081"
    },
    {
        "@score": "1",
        "@id": "2332633",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "159/2518",
                        "text": "Maik Ender"
                    },
                    {
                        "@pid": "38/3348",
                        "text": "Amir Moradi 0001"
                    },
                    {
                        "@pid": "p/ChristofPaar",
                        "text": "Christof Paar"
                    }
                ]
            },
            "title": "The Unpatchable Silicon: A Full Break of the Bitstream Encryption of Xilinx 7-Series FPGAs.",
            "venue": "USENIX Security Symposium",
            "pages": "1803-1819",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Ender0P20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/ender",
            "url": "https://dblp.org/rec/conf/uss/Ender0P20",
            "abstract": "The security of FPGAs is a crucial topic, as any vulnerability within the hardware can have severe consequences, if they are used in a secure design. Since FPGA designs are encoded in a bitstream, securing the bitstream is of the utmost importance. Adversaries have many motivations to recover and manipulate the bitstream, including design cloning, IP theft, manipulation of the design, or design subversions e.g., through hardware Trojans. Given that FPGAs are often part of cyber-physical systems e.g., in aviation, medical, or industrial devices, this can even lead to physical harm. Consequently, vendors have introduced bitstream encryption, offering authenticity and confidentiality. Even though attacks against bitstream encryption have been proposed in the past, e.g., side-channel analysis and probing, these attacks require sophisticated equipment and considerable technical expertise.In this paper, we introduce novel low-cost attacks against the Xilinx 7-Series (and Virtex-6) bitstream encryption, resulting in the total loss of authenticity and confidentiality. We exploit a design flaw which piecewise leaks the decrypted bitstream. In the attack, the FPGA is used as a decryption oracle, while only access to a configuration interface is needed. The attack does not require any sophisticated tools and, depending on the target system, can potentially be launched remotely. In addition to the attacks, we discuss several countermeasures.",
            "pdf_url": "",
            "keywords": [
                "FPGA Security",
                "Bitstream Encryption",
                "Xilinx 7-Series",
                "Decryption Attacks",
                "Design Flaw Exploitation"
            ]
        },
        "url": "URL#2332633"
    },
    {
        "@score": "1",
        "@id": "2332634",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "157/0863",
                        "text": "Minghong Fang"
                    },
                    {
                        "@pid": "146/9100",
                        "text": "Xiaoyu Cao"
                    },
                    {
                        "@pid": "24/5124-1",
                        "text": "Jinyuan Jia 0001"
                    },
                    {
                        "@pid": "03/9437",
                        "text": "Neil Zhenqiang Gong"
                    }
                ]
            },
            "title": "Local Model Poisoning Attacks to Byzantine-Robust Federated Learning.",
            "venue": "USENIX Security Symposium",
            "pages": "1605-1622",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/FangCJG20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/fang",
            "url": "https://dblp.org/rec/conf/uss/FangCJG20",
            "abstract": "In federated learning, multiple client devices jointly learn a machine learning model: each client device maintains a local model for its local training dataset, while a master device maintains a global model via aggregating the local models from the client devices. The machine learning community recently proposed several federated learning methods that were claimed to be robust against Byzantine failures (e.g., system failures, adversarial manipulations) of certain client devices. In this work, we perform the first systematic study on local model poisoning attacks to federated learning. We assume an attacker has compromised some client devices, and the attacker manipulates the local model parameters on the compromised client devices during the learning process such that the global model has a large testing error rate. We formulate our attacks as optimization problems and apply our attacks to four recent Byzantine-robust federated learning methods. Our empirical results on four real-world datasets show that our attacks can substantially increase the error rates of the models learnt by the federated learning methods that were claimed to be robust against Byzantine failures of some client devices. We generalize two defenses for data poisoning attacks to defend against our local model poisoning attacks. Our evaluation results show that one defense can effectively defend against our attacks in some cases, but the defenses are not effective enough in other cases, highlighting the need for new defenses against our local model poisoning attacks to federated learning.",
            "keywords": [
                "Federated Learning",
                "Byzantine Robustness",
                "Local Model Poisoning",
                "Adversarial Attacks",
                "Model Error Rate"
            ]
        },
        "url": "URL#2332634",
        "sema_paperId": "0a1574ce29eec463bd3e0b50b82157f3e5a1f81d"
    },
    {
        "@score": "1",
        "@id": "2332635",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "25/13-2",
                        "text": "Bo Feng 0002"
                    },
                    {
                        "@pid": "249/2297",
                        "text": "Alejandro Mera"
                    },
                    {
                        "@pid": "81/7428",
                        "text": "Long Lu"
                    }
                ]
            },
            "title": "P2IM: Scalable and Hardware-independent Firmware Testing via Automatic Peripheral Interface Modeling.",
            "venue": "USENIX Security Symposium",
            "pages": "1237-1254",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/FengML20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/feng",
            "url": "https://dblp.org/rec/conf/uss/FengML20",
            "abstract": "Dynamic testing or fuzzing of embedded firmware is severely limited by hardware-dependence and poor scalability, partly contributing to the widespread vulnerable IoT devices. We propose a software framework that continuously executes a given firmware binary while channeling inputs from an off-the-shelf fuzzer, enabling hardware-independent and scalable firmware testing. Our framework, using a novel technique called P$^2$IM, abstracts diverse peripherals and handles firmware I/O on the fly based on automatically generated models. P$^2$IM is oblivious to peripheral designs and generic to firmware implementations, and therefore, applicable to a wide range of embedded devices. We evaluated our framework using 70 sample firmware and 10 firmware from real devices, including a drone, a robot, and a PLC. It successfully executed 79% of the sample firmware without any manual assistance. We also performed a limited fuzzing test on the real firmware, which unveiled 7 unique unknown bugs.",
            "keywords": [
                "Firmware Testing",
                "Embedded Systems",
                "Fuzzing",
                "Peripheral Interface Modeling",
                "IoT Vulnerabilities"
            ]
        },
        "url": "URL#2332635",
        "sema_paperId": "9991f3531a8cd444d5c09a74bf6d49ccfb5f25bc"
    },
    {
        "@score": "1",
        "@id": "2332637",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "150/7924",
                        "text": "Paul Fiterau-Brostean"
                    },
                    {
                        "@pid": "j/BengtJonsson",
                        "text": "Bengt Jonsson 0001"
                    },
                    {
                        "@pid": "248/1716",
                        "text": "Robert Merget"
                    },
                    {
                        "@pid": "24/10823",
                        "text": "Joeri de Ruiter"
                    },
                    {
                        "@pid": "s/KonstantinosFSagonas",
                        "text": "Konstantinos Sagonas"
                    },
                    {
                        "@pid": "27/8331",
                        "text": "Juraj Somorovsky"
                    }
                ]
            },
            "title": "Analysis of DTLS Implementations Using Protocol State Fuzzing.",
            "venue": "USENIX Security Symposium",
            "pages": "2523-2540",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Fiterau-Brostean20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/fiterau-brostean",
            "url": "https://dblp.org/rec/conf/uss/Fiterau-Brostean20",
            "abstract": "Recent years have witnessed an increasing number of protocols relying on UDP. Compared to TCP, UDP offers performance advantages such as simplicity and lower latency. This has motivated its adoption in Voice over IP, tunneling technologies, IoT, and novel Web protocols. To protect sensitive data exchange in these scenarios, the DTLS protocol has been developed as a cryptographic variation of TLS. DTLS\u2019s main challenge is to support the stateless and unreliable transport of UDP. This has forced protocol designers to make choices that affect the complexity of DTLS, and to incorporate features that need not be addressed in the numerous TLS analyses. We present the first comprehensive analysis of DTLS implementations using protocol state fuzzing. To that end, we extend TLS-Attacker, an open source framework for analyzing TLS implementations, with support for DTLS tailored to the stateless and unreliable nature of the underlying UDP layer. We build a framework for applying protocol state fuzzing on DTLS servers, and use it to learn state machine models for thirteen DTLS implementations. Analysis of the learned state models reveals four serious security vulnerabilities, including a full client authentication bypass in the latest JSSE version, as well as several functional bugs and non-conformance issues. It also uncovers considerable differences between the models, confirming the complexity of DTLS state machines.",
            "keywords": [
                "DTLS Protocol",
                "Protocol State Fuzzing",
                "UDP Transport",
                "Security Vulnerabilities",
                "State Machine Models"
            ]
        },
        "url": "URL#2332637",
        "sema_paperId": "58d0badbbad789dd097177c7af23ae0174a530d3"
    },
    {
        "@score": "1",
        "@id": "2332638",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "40/10517",
                        "text": "Antonio Flores-Montoya"
                    },
                    {
                        "@pid": "32/8523",
                        "text": "Eric M. Schulte"
                    }
                ]
            },
            "title": "Datalog Disassembly.",
            "venue": "USENIX Security Symposium",
            "pages": "1075-1092",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Flores-MontoyaS20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/flores-montoya",
            "url": "https://dblp.org/rec/conf/uss/Flores-MontoyaS20",
            "abstract": "Disassembly is fundamental to binary analysis and rewriting. We present a novel disassembly technique that takes a stripped binary and produces reassembleable assembly code. The resulting assembly code has accurate symbolic information, providing cross-references for analysis and to enable adjustment of code and data pointers to accommodate rewriting. Our technique features multiple static analyses and heuristics in a combined Datalog implementation. We argue that Datalog's inference process is particularly well suited for disassembly and the required analyses. Our implementation and experiments support this claim. We have implemented our approach into an open-source tool called Ddisasm. In extensive experiments in which we rewrite thousands of x64 binaries we find Ddisasm is both faster and more accurate than the current state-of-the-art binary reassembling tool, Ramblr.",
            "keywords": [
                "Binary Analysis",
                "Disassembly",
                "Reassembleable Assembly Code",
                "Static Analysis",
                "Datalog Implementation"
            ]
        },
        "url": "URL#2332638",
        "sema_paperId": "4245bf41e3b9296f8b441a6e76e3f0d5d3567056"
    },
    {
        "@score": "1",
        "@id": "2332639",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "64/5428",
                        "text": "Joel Frank"
                    },
                    {
                        "@pid": "160/7844",
                        "text": "Cornelius Aschermann"
                    },
                    {
                        "@pid": "h/ThorstenHolz",
                        "text": "Thorsten Holz"
                    }
                ]
            },
            "title": "ETHBMC: A Bounded Model Checker for Smart Contracts.",
            "venue": "USENIX Security Symposium",
            "pages": "2757-2774",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/FrankAH20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/frank",
            "url": "https://dblp.org/rec/conf/uss/FrankAH20",
            "abstract": "The introduction of smart contracts has significantly advanced the state-of-the-art in cryptocurrencies. Smart contracts are programs who live on the blockchain, governing the flow of money. However, the promise of monetary gain has attracted miscreants, resulting in spectacular hacks which resulted in the loss of millions worth of currency. In response, several powerful static analysis tools were developed to address these problems. We surveyed eight recently proposed static analyzers for Ethereum smart contracts and found that none of them captures all relevant features of the Ethereum ecosystem. For example, we discovered that a precise memory model is missing and inter-contract analysis is only partially supported. Based on these insights, we present the design and implementation of ETHBMC, a bounded model checker based on symbolic execution which provides a precise model of the Ethereum network. We demonstrate its capabilities in a series of experiments. First, we compare against the eight aforementioned tools, showing that even relatively simple toy examples can obstruct other analyzers. Further proving that precise modeling is indispensable, we leverage ETHBMC capabilities for automatic vulnerability scanning.We perform a large-scale analysis of roughly 2.2 million accounts currently active on the blockchain and automatically generate 5,905 valid inputs which trigger a vulnerability. From these, 1,989 can destroy a contract at will (so called suicidal contracts) and the rest can be used by an adversary to arbitrarily extract money. Finally, we compare our large-scale analysis against two previous analysis runs, finding significantly more inputs (22.8%) than previous approaches.",
            "keywords": [
                "Smart Contracts",
                "Ethereum",
                "Bounded Model Checking",
                "Vulnerability Analysis",
                "Symbolic Execution"
            ]
        },
        "url": "URL#2332639",
        "sema_paperId": "d91c85d7278e48371ab70258c9dbedb81f57d5e2"
    },
    {
        "@score": "1",
        "@id": "2332640",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "239/8147",
                        "text": "Alisa Frik"
                    },
                    {
                        "@pid": "272/7118",
                        "text": "Amelia Haviland"
                    },
                    {
                        "@pid": "49/3744",
                        "text": "Alessandro Acquisti"
                    }
                ]
            },
            "title": "The Impact of Ad-Blockers on Product Search and Purchase Behavior: A Lab Experiment.",
            "venue": "USENIX Security Symposium",
            "pages": "163-179",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/FrikHA20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/frik",
            "url": "https://dblp.org/rec/conf/uss/FrikHA20",
            "abstract": ". Ad-blocking applications have become increasingly popular among Internet users. Ad-blockers offer various privacy- and security-enhancing features: they can reduce personal data collection and exposure to malicious advertising, help safeguard users' decision-making autonomy, reduce users' costs (by increasing the speed of page loading), and improve the browsing experience (by reducing visual clutter). On the other hand, the online advertising industry has claimed that ads increase consumers' economic welfare by helping them find better, cheaper deals faster. If so, using ad-blockers would deprive consumers of these benefits. However, little is known about the actual economic impact of ad-blockers. We designed a lab experiment (N=212) with real economic incentives to understand the impact of ad-blockers on consumers' product searching and purchasing behavior, and the resulting consumer outcomes. We focus on the effects of blocking contextual ads (ads targeted to individual, potentially sensitive, contexts, such as search queries in a search engine or the content of web pages) on how participants searched for and purchased various products online, and the resulting consumer welfare. We find that blocking contextual ads did not have a statistically significant effect on the prices of products participants chose to purchase, the time they spent searching for them, or how satisfied they were with the chosen products, prices, and perceived quality. Hence we do not reject the null hypothesis that consumer behavior and outcomes stay constant when such ads are blocked or shown. We conclude that the use of ad-blockers does not seem to compromise consumer economic welfare (along the metrics captured in the experiment) in exchange for privacy and security benefits. We discuss the implications of this work in terms of end-users' privacy, the study's limitations, and future work to extend these results.Presented at the 29th USENIX Security Symposium, August 12-14, 2020",
            "keywords": [
                "Ad-Blockers",
                "Consumer Behavior",
                "Product Search",
                "Purchase Behavior",
                "Consumer Welfare"
            ]
        },
        "url": "URL#2332640",
        "sema_paperId": "130bd04f35901bc091b29f0cd084f657a9a201cb"
    },
    {
        "@score": "1",
        "@id": "2332642",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "153/0205",
                        "text": "Shuitao Gan"
                    },
                    {
                        "@pid": "94/3019-8",
                        "text": "Chao Zhang 0008"
                    },
                    {
                        "@pid": "27/7017-34",
                        "text": "Peng Chen 0034"
                    },
                    {
                        "@pid": "237/1416",
                        "text": "Bodong Zhao"
                    },
                    {
                        "@pid": "153/0254",
                        "text": "Xiaojun Qin"
                    },
                    {
                        "@pid": "48/1853",
                        "text": "Dong Wu"
                    },
                    {
                        "@pid": "17/9580",
                        "text": "Zuoning Chen"
                    }
                ]
            },
            "title": "GREYONE: Data Flow Sensitive Fuzzing.",
            "venue": "USENIX Security Symposium",
            "pages": "2577-2594",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Gan0CZQWC20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/gan",
            "url": "https://dblp.org/rec/conf/uss/Gan0CZQWC20",
            "abstract": "Data flow analysis (e.g., dynamic taint analysis) has proven to be useful for guiding fuzzers to explore hard-to-reach code and find vulnerabilities. However, traditional taint analysis is labor-intensive, inaccurate and slow, affecting the fuzzing efficiency. Apart from taint, few data flow features are utilized. In this paper, we proposed a data flow sensitive fuzzing solution GREYONE. We first utilize the classic feature taint to guide fuzzing. A lightweight and sound fuzzing-driven taint inference (FTI) is adopted to infer taint of variables, by monitoring their value changes while mutating input bytes during fuzzing. With the taint, we propose a novel input prioritization model to determine which branch to explore, which bytes to mutate and how to mutate. Further, we use another data flow feature constraint conformance, i.e., distance of tainted variables to values expected in untouched branches, to tune the evolution direction of fuzzing. We implemented a prototype of GREYONE and evaluated it on the LAVA data set and 19 real world programs. The results showed that it outperforms various state-of-the-art fuzzers in terms of both code coverage and vulnerability discovery. In the LAVA data set, GREYONE found all listed bugs and 336 more unlisted. In real world programs, GREYONE on average found 2.12X unique program paths and 3.09X unique bugs than state-of-the-art evolutionary fuzzers, including AFL, VUzzer, CollAFL, Angora and Honggfuzz, Moreover, GREYONE on average found 1.2X unique program paths and 1.52X unique bugs than a state-of-the-art symbolic exeuction assisted fuzzer QSYM. In total, it found 105 new security bugs, of which 41 are confirmed by CVE.",
            "keywords": [
                "Fuzzing",
                "Data Flow Analysis",
                "Taint Analysis",
                "Vulnerability Discovery",
                "Input Prioritization"
            ]
        },
        "url": "URL#2332642",
        "sema_paperId": "a00e6441b65462fe8def9298f0d1c4c8ddfae59e"
    },
    {
        "@score": "1",
        "@id": "2332643",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "181/1564",
                        "text": "Cesar Pereida Garc\u00eda"
                    },
                    {
                        "@pid": "223/9675",
                        "text": "Sohaib ul Hassan"
                    },
                    {
                        "@pid": "54/10083",
                        "text": "Nicola Tuveri"
                    },
                    {
                        "@pid": "238/9967",
                        "text": "Iaroslav Gridin"
                    },
                    {
                        "@pid": "180/3056",
                        "text": "Alejandro Cabrera Aldaya"
                    },
                    {
                        "@pid": "25/1876",
                        "text": "Billy Bob Brumley"
                    }
                ]
            },
            "title": "Certified Side Channels.",
            "venue": "USENIX Security Symposium",
            "pages": "2021-2038",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GarciaHTGAB20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/garcia",
            "url": "https://dblp.org/rec/conf/uss/GarciaHTGAB20",
            "abstract": "We demonstrate that the format in which private keys are persisted impacts Side Channel Analysis (SCA) security. Surveying several widely deployed software libraries, we investigate the formats they support, how they parse these keys, and what runtime decisions they make. We uncover a combination of weaknesses and vulnerabilities, in extreme cases inducing completely disjoint multi-precision arithmetic stacks deep within the cryptosystem level for keys that otherwise seem logically equivalent. Exploiting these vulnerabilities, we design and implement key recovery attacks utilizing signals ranging from electromagnetic (EM) emanations, to granular microarchitecture cache timings, to coarse traditional wall clock timings.",
            "pdf_url": "",
            "keywords": [
                "Side Channel Analysis",
                "Cryptographic Key Management",
                "Key Recovery Attacks",
                "Multi-Precision Arithmetic",
                "Vulnerabilities in Software Libraries"
            ]
        },
        "url": "URL#2332643"
    },
    {
        "@score": "1",
        "@id": "2332644",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "238/1681",
                        "text": "Seyedhamed Ghavamnia"
                    },
                    {
                        "@pid": "159/0008",
                        "text": "Tapti Palit"
                    },
                    {
                        "@pid": "231/1924",
                        "text": "Shachee Mishra"
                    },
                    {
                        "@pid": "09/1231",
                        "text": "Michalis Polychronakis"
                    }
                ]
            },
            "title": "Temporal System Call Specialization for Attack Surface Reduction.",
            "venue": "USENIX Security Symposium",
            "pages": "1749-1766",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GhavamniaPMP20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/ghavamnia",
            "url": "https://dblp.org/rec/conf/uss/GhavamniaPMP20",
            "abstract": "Attack surface reduction through the removal of unnecessary application features and code is a promising technique for improving security without incurring any additional overhead. Recent software debloating techniques consider an application\u2019s entire lifetime when extracting its code requirements, and reduce the attack surface accordingly. In this paper, we present temporal specialization , a novel approach for limiting the set of system calls available to a process depending on its phase of execution. Our approach is tailored to server applications, which exhibit distinct initialization and serving phases with different system call requirements. We present novel static analysis techniques for improving the precision of extracting the application\u2019s call graph for each execution phase, which is then used to pinpoint the system calls used in each phase. We show that requirements change throughout the lifetime of servers, and many dangerous system calls (such as execve ) can be disabled after the completion of the initialization phase. We have implemented a prototype of temporal specialization on top of the LLVM compiler, and evaluated its effectiveness with six popular server applications. Our results show that it disables 51% more security-critical system calls compared to existing library specialization approaches, while offering the additional bene\ufb01t of neutralizing 13 more Linux kernel vulnerabilities that could lead to privilege escalation.",
            "keywords": [
                "Temporal Specialization",
                "System Call Limitation",
                "Attack Surface Reduction",
                "Server Application Security",
                "Static Analysis Techniques"
            ]
        },
        "url": "URL#2332644",
        "sema_paperId": "4673a22c86782950a0dc2ab8629cce000f4dc947"
    },
    {
        "@score": "1",
        "@id": "2332645",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "272/7154",
                        "text": "Guillaume Girol"
                    },
                    {
                        "@pid": "140/7281",
                        "text": "Lucca Hirschi"
                    },
                    {
                        "@pid": "35/4406",
                        "text": "Ralf Sasse"
                    },
                    {
                        "@pid": "242/3244",
                        "text": "Dennis Jackson"
                    },
                    {
                        "@pid": "17/2282",
                        "text": "Cas Cremers"
                    },
                    {
                        "@pid": "b/DavidABasin",
                        "text": "David A. Basin"
                    }
                ]
            },
            "title": "A Spectral Analysis of Noise: A Comprehensive, Automated, Formal Analysis of Diffie-Hellman Protocols.",
            "venue": "USENIX Security Symposium",
            "pages": "1857-1874",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GirolHSJCB20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/girol",
            "url": "https://dblp.org/rec/conf/uss/GirolHSJCB20",
            "abstract": "The Noise specification describes how to systematically construct a large family of Diffie-Hellman based key exchange protocols, including the secure transports used by WhatsApp, Lightning, and WireGuard. As the specification only makes informal security claims, earlier work has explored which formal security properties may be enjoyed by protocols in the Noise framework, yet many important questions remain open.In this work we provide the most comprehensive, systematic analysis of the Noise framework to date. We start from first principles and, using an automated analysis tool, compute the strongest threat model under which a protocol is secure, thus enabling formal comparison between protocols. Our results allow us to objectively and automatically associate each informal security level presented in the Noise specification with a formal security claim.We also provide a fine-grained separation of Noise protocols that were previously described as offering similar security properties, revealing a subclass for which alternative Noise protocols exist that offer strictly better security guarantees. Our analysis also uncovers missing assumptions in the Noise specification and some surprising consequences, e.g., in some situations higher security levels yield strictly worse security.",
            "pdf_url": "",
            "keywords": [
                "Diffie-Hellman Protocols",
                "Noise Framework",
                "Formal Security Analysis",
                "Threat Model",
                "Security Guarantees"
            ]
        },
        "url": "URL#2332645"
    },
    {
        "@score": "1",
        "@id": "2332646",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "147/2244",
                        "text": "Tom van Goethem"
                    },
                    {
                        "@pid": "11/3019",
                        "text": "Christina P\u00f6pper"
                    },
                    {
                        "@pid": "13/86",
                        "text": "Wouter Joosen"
                    },
                    {
                        "@pid": "130/3608",
                        "text": "Mathy Vanhoef"
                    }
                ]
            },
            "title": "Timeless Timing Attacks: Exploiting Concurrency to Leak Secrets over Remote Connections.",
            "venue": "USENIX Security Symposium",
            "pages": "1985-2002",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GoethemPJV20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/van-goethem",
            "url": "https://dblp.org/rec/conf/uss/GoethemPJV20",
            "abstract": "To perform successful remote timing attacks, an adversary typically collects a series of network timing measurements and subsequently performs statistical analysis to reveal a difference in execution time. The number of measurements that must be obtained largely depends on the amount of jitter that the requests and responses are subjected to. In remote timing attacks, a signi\ufb01cant source of jitter is the network path between the adversary and the targeted server, making it practically infeasible to successfully exploit timing side-channels that exhibit only a small difference in execution time. In this paper, we introduce a conceptually novel type of timing attack that leverages the coalescing of packets by network protocols and concurrent handling of requests by applications. These concurrency-based timing attacks infer a relative timing difference by analyzing the order in which responses are returned, and thus do not rely on any absolute timing information. We show how these attacks result in a 100-fold improvement over typical timing attacks performed over the Internet, and can accurately detect timing differences as small as 100ns, similar to attacks launched on a local system. We describe how these timing attacks can be successfully deployed against HTTP/2 webservers, Tor onion services, and EAP-pwd, a popular Wi-Fi authentication method.",
            "keywords": [
                "Timing Attacks",
                "Concurrency Exploitation",
                "Network Protocols",
                "Remote Connections",
                "Execution Time Leakage"
            ]
        },
        "url": "URL#2332646",
        "sema_paperId": "eccd12a666280541269bab18b004350606d0a710"
    },
    {
        "@score": "1",
        "@id": "2332647",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "272/7227",
                        "text": "Jiajun Gong"
                    },
                    {
                        "@pid": "12/5838-12",
                        "text": "Tao Wang 0012"
                    }
                ]
            },
            "title": "Zero-delay Lightweight Defenses against Website Fingerprinting.",
            "venue": "USENIX Security Symposium",
            "pages": "717-734",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GongW20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/gong",
            "url": "https://dblp.org/rec/conf/uss/GongW20",
            "abstract": "Website Fingerprinting (WF) attacks threaten user privacy on anonymity networks because they can be used by network surveillants to identify the webpage being visited by extracting features from network traf\ufb01c. A number of defenses have been put forward to mitigate the threat of WF, but they are \ufb02awed: some have been defeated by stronger WF attacks, some are too expensive in overhead, while others are impractical to deploy. In this work, we propose two novel zero-delay lightweight defenses, FRONT and GLUE. We \ufb01nd that WF attacks rely on the feature-rich trace front, so FRONT focuses on obfus-cating the trace front with dummy packets. It also random-izes the number and distribution of dummy packets for trace-to-trace randomness to impede the attacker\u2019s learning process. GLUE adds dummy packets between separate traces so that they appear to the attacker as a long consecutive trace, rendering the attacker unable to \ufb01nd their start or end points, let alone classify them. Our experiments show that with 33% data overhead, FRONT outperforms the best known lightweight defense, WTF-PAD, which has a similar data overhead. With around 22%\u201344% data overhead, GLUE can lower the accuracy and precision of the best WF attacks to a degree comparable with the best heavyweight defenses. Both defenses have no latency overhead.",
            "keywords": [
                "Website Fingerprinting",
                "Anonymity Networks",
                "Privacy Protection",
                "Traffic Obfuscation",
                "Dummy Packet Insertion"
            ]
        },
        "url": "URL#2332647",
        "sema_paperId": "c200ce9ea6c38d36c53cb08452e279fdc5289336"
    },
    {
        "@score": "1",
        "@id": "2332649",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "139/2372",
                        "text": "Paul Grubbs"
                    },
                    {
                        "@pid": "162/1936",
                        "text": "Anurag Khandelwal"
                    },
                    {
                        "@pid": "172/4062",
                        "text": "Marie-Sarah Lacharit\u00e9"
                    },
                    {
                        "@pid": "272/7111",
                        "text": "Lloyd Brown"
                    },
                    {
                        "@pid": "174/9518",
                        "text": "Lucy Li"
                    },
                    {
                        "@pid": "41/5447-1",
                        "text": "Rachit Agarwal 0001"
                    },
                    {
                        "@pid": "26/3399",
                        "text": "Thomas Ristenpart"
                    }
                ]
            },
            "title": "Pancake: Frequency Smoothing for Encrypted Data Stores.",
            "venue": "USENIX Security Symposium",
            "pages": "2451-2468",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GrubbsKLBL0R20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/grubbs",
            "url": "https://dblp.org/rec/conf/uss/GrubbsKLBL0R20",
            "abstract": "We present PANCAKE, the first system to protect key-value stores from access pattern leakage attacks with small constant factor bandwidth overhead. PANCAKE uses a new approach, that we call frequency smoothing, to transform plaintext accesses into uniformly distributed encrypted accesses to an encrypted data store. We show that frequency smoothing prevents access pattern leakage attacks by passive persistent adversaries in a new formal security model. We integrate PANCAKE into three key-value stores used in production clusters, and demonstrate its practicality: on standard benchmarks, PANCAKE achieves 229\u00d7 better throughput than non-recursive Path ORAM \u2014 within 3\u20136\u00d7 of insecure baselines for these key-value stores.",
            "pdf_url": "",
            "keywords": [
                "Encrypted Data Stores",
                "Access Pattern Leakage",
                "Frequency Smoothing",
                "Key-Value Stores",
                "Bandwidth Overhead"
            ]
        },
        "url": "URL#2332649"
    },
    {
        "@score": "1",
        "@id": "2332650",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "195/4752",
                        "text": "Xiaolan Gu"
                    },
                    {
                        "@pid": "l/MingLi3",
                        "text": "Ming Li 0003"
                    },
                    {
                        "@pid": "15/8296",
                        "text": "Yueqiang Cheng"
                    },
                    {
                        "@pid": "39/3530-1",
                        "text": "Li Xiong 0001"
                    },
                    {
                        "@pid": "25/7045-11",
                        "text": "Yang Cao 0011"
                    }
                ]
            },
            "title": "PCKV: Locally Differentially Private Correlated Key-Value Data Collection with Optimized Utility.",
            "venue": "USENIX Security Symposium",
            "pages": "967-984",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Gu0C0020",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/gu",
            "url": "https://dblp.org/rec/conf/uss/Gu0C0020",
            "abstract": "Data collection under local differential privacy (LDP) has been mostly studied for homogeneous data. Real-world applications often involve a mixture of different data types such as key-value pairs, where the frequency of keys and mean of values under each key must be estimated simultaneously. For key-value data collection with LDP, it is challenging to achieve a good utility-privacy tradeoff since the data contains two dimensions and a user may possess multiple key-value pairs. There is also an inherent correlation between key and values which if not harnessed, will lead to poor utility. In this paper, we propose a locally differentially private key-value data collection framework that utilizes correlated perturbations to enhance utility. We instantiate our framework by two protocols PCKV-UE (based on Unary Encoding) and PCKV-GRR (based on Generalized Randomized Response), where we design an advanced Padding-and-Sampling mechanism and an improved mean estimator which is non-interactive. Due to our correlated key and value perturbation mechanisms, the composed privacy budget is shown to be less than that of independent perturbation of key and value, which enables us to further optimize the perturbation parameters via budget allocation. Experimental results on both synthetic and real-world datasets show that our proposed protocols achieve better utility for both frequency and mean estimations under the same LDP guarantees than state-of-the-art mechanisms.",
            "keywords": [
                "Local Differential Privacy",
                "Key-Value Data Collection",
                "Utility-Privacy Tradeoff",
                "Correlated Perturbations",
                "Frequency and Mean Estimation"
            ]
        },
        "url": "URL#2332650",
        "sema_paperId": "53463b9db8b6821c0139624c8d07ffdab7b51aa5"
    },
    {
        "@score": "1",
        "@id": "2332651",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "201/5394",
                        "text": "Zhixiu Guo"
                    },
                    {
                        "@pid": "272/7059",
                        "text": "Zijin Lin"
                    },
                    {
                        "@pid": "72/2643",
                        "text": "Pan Li"
                    },
                    {
                        "@pid": "c/KaiChen12",
                        "text": "Kai Chen 0012"
                    }
                ]
            },
            "title": "SkillExplorer: Understanding the Behavior of Skills in Large Scale.",
            "venue": "USENIX Security Symposium",
            "pages": "2649-2666",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GuoLL020",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/guo",
            "url": "https://dblp.org/rec/conf/uss/GuoLL020",
            "abstract": "Smart speakers have been popularly used around the world recently, mainly due to the convenience brought from the virtual personal assistant (VPA) which offers interactive actions through the convenient voice commands from users. Besides the built-in capabilities, VPA services can be further extended by third-party developers through skills. Similar to smartphone applications on Android and iOS markets, skills are also available on markets (e.g., Amazon, Google), attracting users together with malicious developers. Recent researches discover that malicious developers are able to route users\u2019 requests to malicious skills without users\u2019 consent by creating skills with similar names of legitimate ones. However, to the best of our knowledge, there is no prior research that systematically explores the interaction behaviors of skills, mainly due to the challenges in handling skills\u2019 inputs/outputs which are in the form of natural languages. In this paper, we propose the first systematic study on behaviors of skills, which is achieved by a suite of new grammar-based techniques including utterance extraction, question understanding, and answer generation specifically designed for skills. We build an interactive system called SkillExplorer and analyze 28,904 skills from the Amazon market and 1,897 actions from the Google market. Among these skills, we find that 1,141 skills request users\u2019 private information without following developer specifications, which are actually demanded by markets. 68 skills continue to eavesdrop users\u2019 private conversations, even after users have sent the command to stop them.",
            "keywords": [
                "Voice-Activated Assistants",
                "Skill Interaction Behavior",
                "Natural Language Processing",
                "User Privacy Concerns",
                "Malicious Skill Development"
            ]
        },
        "url": "URL#2332651",
        "sema_paperId": "be6d3b3b6c6858c50110cccc83f1e92fc8b77611"
    },
    {
        "@score": "1",
        "@id": "2332652",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "224/9328",
                        "text": "Lee Harrison"
                    },
                    {
                        "@pid": "24/687",
                        "text": "Hayawardh Vijayakumar"
                    },
                    {
                        "@pid": "129/1434",
                        "text": "Rohan Padhye"
                    },
                    {
                        "@pid": "04/418",
                        "text": "Koushik Sen"
                    },
                    {
                        "@pid": "168/9541",
                        "text": "Michael Grace"
                    }
                ]
            },
            "title": "PARTEMU: Enabling Dynamic Analysis of Real-World TrustZone Software Using Emulation.",
            "venue": "USENIX Security Symposium",
            "pages": "789-806",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HarrisonVPSG20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/harrison",
            "url": "https://dblp.org/rec/conf/uss/HarrisonVPSG20",
            "abstract": "ARM\u2019s TrustZone technology is the basis for security of billions of devices worldwide, including Android smartphones and IoT devices. Because TrustZone has access to sensitive information such as cryptographic keys, access to TrustZone has been locked down on real-world devices: only code that is authenticated by a trusted party can run in TrustZone. A side-effect is that TrustZone software cannot be instrumented or monitored. Thus, recent advances in dynamic analysis techniques such as feedback-driven fuzz testing have not been applied to TrustZone software. To address the above problem, this work builds an emulator that runs four widely-used, real-world TrustZone operating systems (TZOSes) - Qualcomm\u2019s QSEE, Trustonic\u2019s Kinibi, Samsung\u2019s TEEGRIS, and Linaro\u2019s OP-TEE - and the trusted applications (TAs) that run on them. The traditional challenge for this approach is that the emulation effort required is often impractical. However, we \ufb01nd that TZOSes depend only on a limited subset of hardware and software components. By carefully choosing a subset of components to emulate, we \ufb01nd we are able to make the effort practical. We implement our emulation on P ART E MU , a modular framework we develop on QEMU and PANDA. We show the utility of P ART E MU by integrating feedback-driven fuzz-testing us-ing AFL and use it to perform a large-scale study of 194 unique TAs from 12 different Android smartphone vendors and a leading IoT vendor, \ufb01nding previously unknown vulnerabilities in 48 TAs, several of which are exploitable. We identify patterns of developer mistakes unique to TrustZone development that cause some of these vulnerabilities, high-lighting the need for TrustZone-speci\ufb01c developer education. We also demonstrate using P ART E MU to test the QSEE TZOS itself, \ufb01nding crashes in code paths that would not normally be exercised on a real device. Our work shows that dynamic analysis of real-world TrustZone software through emulation is both feasible and bene\ufb01cial.",
            "keywords": [
                "TrustZone Emulation",
                "Dynamic Analysis",
                "Trusted Applications",
                "Fuzz Testing",
                "Vulnerability Discovery"
            ]
        },
        "url": "URL#2332652",
        "sema_paperId": "3c61b2073fceb87d0055d99808ebc95c3843c672"
    },
    {
        "@score": "1",
        "@id": "2332653",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "96/29",
                        "text": "Md. Mehedi Hasan"
                    },
                    {
                        "@pid": "14/6192",
                        "text": "Biswajit Ray"
                    }
                ]
            },
            "title": "Data Recovery from &quot;Scrubbed&quot; NAND Flash Storage: Need for Analog Sanitization.",
            "venue": "USENIX Security Symposium",
            "pages": "1399-1408",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HasanR20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/hasan",
            "url": "https://dblp.org/rec/conf/uss/HasanR20",
            "abstract": "Digital sanitization of flash based non-volatile memory system is a well-researched topic. Since flash memory cell holds information in the analog threshold voltage, flash cell may hold the imprints of previously written data even after digital sanitization. In this paper, we show that data is partially or completely recoverable from the flash media sanitized with \u201cscrubbing\u201d based technique, which is a popular technique for page deletion in NAND flash. We find that adversary may utilize the data retention property of the memory cells for recovering the deleted data using standard digital interfaces with the memory. We demonstrate data recovery from commercial flash memory chip, sanitized with scrubbing, by using partial erase operation on the chip. Our results show that analog scrubbing is needed to securely delete information in flash system. We propose and implement analog scrubbing using partial program operation based on the file creation time information.",
            "keywords": [
                "NAND Flash Storage",
                "Data Recovery",
                "Digital Sanitization",
                "Analog Scrubbing",
                "Memory Cell Imprints"
            ]
        },
        "url": "URL#2332653",
        "sema_paperId": "6775726b62667343621d7286d3332c5644213240"
    },
    {
        "@score": "1",
        "@id": "2332654",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "190/9888",
                        "text": "Grant Hernandez"
                    },
                    {
                        "@pid": "159/0537",
                        "text": "Dave (Jing) Tian"
                    },
                    {
                        "@pid": "250/9151",
                        "text": "Anurag Swarnim Yadav"
                    },
                    {
                        "@pid": "67/181",
                        "text": "Byron J. Williams"
                    },
                    {
                        "@pid": "82/1935",
                        "text": "Kevin R. B. Butler"
                    }
                ]
            },
            "title": "BigMAC: Fine-Grained Policy Analysis of Android Firmware.",
            "venue": "USENIX Security Symposium",
            "pages": "271-287",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HernandezTYWB20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/hernandez",
            "url": "https://dblp.org/rec/conf/uss/HernandezTYWB20",
            "abstract": "The Android operating system is the world's dominant mobile computing platform. To defend against malicious applications and external attack, Android relies upon a complex combination of discretionary and mandatory access control mechanisms, including Linux capabilities, to maintain least privilege. To understand the impact and interaction between these layers, we created a framework called BigMAC that combines and instantiates all layers of the policy together in a fine grained graph supporting millions of edges. Our model filters out paths and types not in use on actual systems that policy analysis alone would consider. Unlike previous work which requires a rooted device, using only static firmware and Android domain knowledge, we are able to extract and recreate the security state of a running system, achieving a process credential recovery at best 74.7% and a filesystem DAC and MAC accuracy of over 98%. Using BigMAC, we develop attack queries to discover sets of objects that can be influenced by untrusted applications and external peripherals. Our evaluation against Samsung S8+ and LG G7 firmwares reveals multiple policy concerns, including untrusted apps on LG being able to communicate with a kernel monitoring service, Samsung S8+ allowing IPC from untrusted apps to some root processes, at least 24 processes with the CAP_SYS_ADMIN capability, and system_server with the capability to load kernel modules. We have reported our findings to the corresponding vendors and release BigMAC for the community.",
            "pdf_url": "",
            "keywords": [
                "Android Security",
                "Access Control Mechanisms",
                "Policy Analysis",
                "Firmware Analysis",
                "Malicious Application Defense"
            ]
        },
        "url": "URL#2332654"
    },
    {
        "@score": "1",
        "@id": "2332655",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "205/2182",
                        "text": "Stephen Herwig"
                    },
                    {
                        "@pid": "129/9491",
                        "text": "Christina Garman"
                    },
                    {
                        "@pid": "03/6428",
                        "text": "Dave Levin"
                    }
                ]
            },
            "title": "Achieving Keyless CDNs with Conclaves.",
            "venue": "USENIX Security Symposium",
            "pages": "735-751",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HerwigGL20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/herwig",
            "url": "https://dblp.org/rec/conf/uss/HerwigGL20",
            "abstract": "Content Delivery Networks (CDNs) serve a large and increasing portion of today\u2019s web content. Beyond caching, CDNs provide their customers with a variety of services, including protection against DDoS and targeted attacks. As the web shifts from HTTP to HTTPS, CDNs continue to provide such services by also assuming control of their customers\u2019 private keys, thereby breaking a fundamental security principle: private keys must only be known by their owner. We present the design and implementation of Phoenix, the first truly \u201ckeyless CDN\u201d. Phoenix uses secure enclaves (in particular Intel SGX) to host web content, store sensitive key material, apply web application firewalls, and more on otherwise untrusted machines. To support scalability and multitenancy, Phoenix is built around a new architectural primitive which we call conclaves: containers of enclaves. Conclaves make it straightforward to deploy multi-process, scalable, legacy applications. We also develop a filesystem to extend the enclave\u2019s security guarantees to untrusted storage. In its strongest configuration, Phoenix reduces the knowledge of the edge server to that of a traditional on-path HTTPS adversary. We evaluate the performance of Phoenix with a series of microand macro-benchmarks.",
            "keywords": [
                "Content Delivery Networks",
                "Keyless Architecture",
                "Secure Enclaves",
                "Multi-tenancy",
                "Conclaves"
            ]
        },
        "url": "URL#2332655",
        "sema_paperId": "e911b5f6817bdbcf3b1de71e87793fbfc2e2aefd"
    },
    {
        "@score": "1",
        "@id": "2332660",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "185/1655",
                        "text": "Kyriakos K. Ispoglou"
                    },
                    {
                        "@pid": "97/5374",
                        "text": "Daniel Austin"
                    },
                    {
                        "@pid": "86/7620",
                        "text": "Vishwath Mohan"
                    },
                    {
                        "@pid": "31/1273",
                        "text": "Mathias Payer"
                    }
                ]
            },
            "title": "FuzzGen: Automatic Fuzzer Generation.",
            "venue": "USENIX Security Symposium",
            "pages": "2271-2287",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/IspoglouAMP20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/ispoglou",
            "url": "https://dblp.org/rec/conf/uss/IspoglouAMP20",
            "abstract": "Fuzzing is a testing technique to discover unknown vulnerabilities in software. When applying fuzzing to libraries, the core idea of supplying random input remains unchanged, yet it is non-trivial to achieve good code coverage. Libraries cannot run as standalone programs, but instead are invoked through another application. Triggering code deep in a library remains challenging as specific sequences of API calls are required to build up the necessary state. Libraries are diverse and have unique interfaces that require unique fuzzers, so far written by a human analyst. To address this issue, we present FuzzGen, a tool for automatically synthesizing fuzzers for complex libraries in a given environment. FuzzGen leverages a whole system analysis to infer the library\u2019s interface and synthesizes fuzzers specifically for that library. FuzzGen requires no human interaction and can be applied to a wide range of libraries. Furthermore, the generated fuzzers leverage LibFuzzer to achieve better code coverage and expose bugs that reside deep in the library. FuzzGen was evaluated on Debian and the Android Open Source Project (AOSP) selecting 7 libraries to generate fuzzers. So far, we have found 17 previously unpatched vulnerabilities with 6 assigned CVEs. The generated fuzzers achieve an average of 54.94% code coverage; an improvement of 6.94% when compared to manually written fuzzers, demonstrating the effectiveness and generality of FuzzGen.",
            "keywords": [
                "Fuzzing",
                "Library Testing",
                "Automated Fuzzer Generation",
                "Code Coverage",
                "Vulnerability Discovery"
            ]
        },
        "url": "URL#2332660",
        "sema_paperId": "ebbc7b3a179ff697d5d0d76252a61bcf70e25bfc"
    },
    {
        "@score": "1",
        "@id": "2332661",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "218/5156",
                        "text": "Matthew Jagielski"
                    },
                    {
                        "@pid": "145/1806",
                        "text": "Nicholas Carlini"
                    },
                    {
                        "@pid": "96/6489",
                        "text": "David Berthelot"
                    },
                    {
                        "@pid": "56/9834",
                        "text": "Alex Kurakin"
                    },
                    {
                        "@pid": "162/1405",
                        "text": "Nicolas Papernot"
                    }
                ]
            },
            "title": "High Accuracy and High Fidelity Extraction of Neural Networks.",
            "venue": "USENIX Security Symposium",
            "pages": "1345-1362",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/JagielskiCBKP20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/jagielski",
            "url": "https://dblp.org/rec/conf/uss/JagielskiCBKP20",
            "abstract": "In a model extraction attack, an adversary steals a copy of a remotely deployed machine learning model, given oracle prediction access. We taxonomize model extraction attacks around two objectives: *accuracy*, i.e., performing well on the underlying learning task, and *fidelity*, i.e., matching the predictions of the remote victim classifier on any input. \nTo extract a high-accuracy model, we develop a learning-based attack exploiting the victim to supervise the training of an extracted model. Through analytical and empirical arguments, we then explain the inherent limitations that prevent any learning-based strategy from extracting a truly high-fidelity model---i.e., extracting a functionally-equivalent model whose predictions are identical to those of the victim model on all possible inputs. Addressing these limitations, we expand on prior work to develop the first practical functionally-equivalent extraction attack for direct extraction (i.e., without training) of a model's weights. \nWe perform experiments both on academic datasets and a state-of-the-art image classifier trained with 1 billion proprietary images. In addition to broadening the scope of model extraction research, our work demonstrates the practicality of model extraction attacks against production-grade systems.",
            "keywords": [
                "Model Extraction Attacks",
                "Oracle Prediction Access",
                "High-Fidelity Extraction",
                "Functionally-Equivalent Model",
                "Learning-Based Attack"
            ]
        },
        "url": "URL#2332661",
        "sema_paperId": "52a222d38a8640499010d470d5589a81882bc425"
    },
    {
        "@score": "1",
        "@id": "2332662",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "64/1812",
                        "text": "Bin Yuan"
                    },
                    {
                        "@pid": "230/3262",
                        "text": "Yan Jia"
                    },
                    {
                        "@pid": "34/8412",
                        "text": "Luyi Xing"
                    },
                    {
                        "@pid": "272/7105",
                        "text": "Dongfang Zhao 0010"
                    },
                    {
                        "@pid": "06/6268",
                        "text": "XiaoFeng Wang 0001"
                    },
                    {
                        "@pid": "z/DeqingZou",
                        "text": "Deqing Zou"
                    },
                    {
                        "@pid": "98/4156",
                        "text": "Hai Jin 0001"
                    },
                    {
                        "@pid": "83/6530-1",
                        "text": "Yuqing Zhang 0001"
                    }
                ]
            },
            "title": "Shattered Chain of Trust: Understanding Security Risks in Cross-Cloud IoT Access Delegation.",
            "venue": "USENIX Security Symposium",
            "pages": "1183-1200",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/JiaXZ0Z20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/yuan",
            "url": "https://dblp.org/rec/conf/uss/JiaXZ0Z20",
            "abstract": "IoT clouds facilitate the communication between IoT devices and users, and authorize users\u2019 access to their devices. In this paradigm, an IoT device is usually managed under a particular IoT cloud designated by the device vendor, e.g., Philips bulbs are managed under Philips Hue cloud. Today\u2019s mainstream IoT clouds also support device access delegation across different vendors (e.g., Philips Hue, LIFX, etc.) and cloud providers (e.g., Google, IFTTT, etc.): for example, Philips Hue and SmartThings clouds support to delegate device access to another cloud such as Google Home, so a user can manage multiple devices from different vendors all through Google Home. Serving this purpose are the IoT delegation mechanisms developed and utilized by IoT clouds, which we found are heterogeneous and ad-hoc in the wild, in the absence of a standardized delegation protocol suited for IoT environments. In this paper, we report the first systematic study on real-world IoT access delegation, based upon a semi-automatic verification tool we developed. Our study brought to light the pervasiveness of security risks in these delegation mechanisms, allowing the adversary (e.g., Airbnb tenants, former employees) to gain unauthorized access to the victim\u2019s devices (e.g., smart locks) or impersonate the devices to trigger other devices. We confirmed the presence of critical security flaws in these mechanisms through end-to-end exploits on them, and further conducted a measurement study. Our research demonstrates the serious consequences of these exploits and the security implications of the practice today for building these mechanisms. We reported our findings to related parties, which acknowledged the problems. We further propose principles for developing more secure cross-cloud IoT delegation services, before a standardized solution can be widely deployed.",
            "keywords": [
                "IoT Access Delegation",
                "Cross-Cloud Security",
                "Delegation Mechanisms",
                "Unauthorized Access",
                "Security Flaws in IoT"
            ]
        },
        "url": "URL#2332662",
        "sema_paperId": "929764020669df7c6d9cc02fa33ac0df8d3325d5"
    },
    {
        "@score": "1",
        "@id": "2332663",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "237/8586",
                        "text": "Zu-Ming Jiang"
                    },
                    {
                        "@pid": "161/7805",
                        "text": "Jia-Ju Bai"
                    },
                    {
                        "@pid": "67/10639",
                        "text": "Kangjie Lu"
                    },
                    {
                        "@pid": "h/ShiMinHu",
                        "text": "Shi-Min Hu 0001"
                    }
                ]
            },
            "title": "Fuzzing Error Handling Code using Context-Sensitive Software Fault Injection.",
            "venue": "USENIX Security Symposium",
            "pages": "2595-2612",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/JiangBL020",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/jiang",
            "url": "https://dblp.org/rec/conf/uss/JiangBL020",
            "abstract": "Error handling code is often critical but difficult to test in reality. As a result, many hard-to-find bugs exist in error handling code and may cause serious security problems once triggered. Fuzzing has become a widely used technique for finding software bugs nowadays. Fuzzing approaches mutate and/or generate various inputs to cover infrequently-executed code. However, existing fuzzing approaches are very limited in testing error handling code, because some of this code can be only triggered by occasional errors (such as insufficient memory and network-connection failures), but not specific inputs. Therefore, existing fuzzing approaches in general cannot effectively test such error handling code. In this paper, we propose a new fuzzing framework named FIFUZZ, to effectively test error handling code and detect bugs. The core of FIFUZZ is a context-sensitive software fault injection (SFI) approach, which can effectively cover error handling code in different calling contexts to find deep bugs hidden in error handling code with complicated contexts. We have implemented FIFUZZ and evaluated it on 9 widelyused C programs. It reports 317 alerts which are caused by 50 unique bugs in terms of the root causes. 32 of these bugs have been confirmed by related developers. We also compare FIFUZZ to existing fuzzing tools (including AFL, AFLFast, AFLSmart and FairFuzz), and find that FIFUZZ finds many bugs missed by these tools. We believe that FIFUZZ can effectively augment existing fuzzing approaches to find many real bugs that have been otherwise missed.",
            "keywords": [
                "Fuzzing",
                "Error Handling Code",
                "Software Fault Injection",
                "Bug Detection",
                "Context-Sensitive Testing"
            ]
        },
        "url": "URL#2332663",
        "sema_paperId": "4ec033ec6ac03374bbf7492e1d472ed6d0283b92"
    },
    {
        "@score": "1",
        "@id": "2332664",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "146/7849",
                        "text": "Harry A. Kalodner"
                    },
                    {
                        "@pid": "152/1158",
                        "text": "Malte M\u00f6ser"
                    },
                    {
                        "@pid": "44/765",
                        "text": "Kevin Lee"
                    },
                    {
                        "@pid": "151/5205",
                        "text": "Steven Goldfeder"
                    },
                    {
                        "@pid": "272/7159",
                        "text": "Martin Plattner"
                    },
                    {
                        "@pid": "206/7162",
                        "text": "Alishah Chator"
                    },
                    {
                        "@pid": "08/3080",
                        "text": "Arvind Narayanan"
                    }
                ]
            },
            "title": "BlockSci: Design and applications of a blockchain analysis platform.",
            "venue": "USENIX Security Symposium",
            "pages": "2721-2738",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KalodnerMLGPCN20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/kalodner",
            "url": "https://dblp.org/rec/conf/uss/KalodnerMLGPCN20",
            "abstract": "Analysis of blockchain data is useful for both scientific research and commercial applications. We present BlockSci, an open-source software platform for blockchain analysis. BlockSci is versatile in its support for different blockchains and analysis tasks. It incorporates an in-memory, analytical (rather than transactional) database, making it orders of magnitudes faster than using general-purpose graph databases. We describe BlockSci's design and present four analyses that illustrate its capabilities, shedding light on the security, privacy, and economics of cryptocurrencies.",
            "pdf_url": "",
            "keywords": [
                "Blockchain Analysis",
                "Open-source Software",
                "Cryptocurrency Economics",
                "Data Privacy",
                "In-memory Database"
            ]
        },
        "url": "URL#2332664"
    },
    {
        "@score": "1",
        "@id": "2332665",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "188/2454",
                        "text": "Qiao Kang"
                    },
                    {
                        "@pid": "68/2052-1",
                        "text": "Lei Xue 0001"
                    },
                    {
                        "@pid": "223/0769",
                        "text": "Adam Morrison 0003"
                    },
                    {
                        "@pid": "86/2476",
                        "text": "Yuxin Tang"
                    },
                    {
                        "@pid": "59/146-1",
                        "text": "Ang Chen 0001"
                    },
                    {
                        "@pid": "53/1565",
                        "text": "Xiapu Luo"
                    }
                ]
            },
            "title": "Programmable In-Network Security for Context-aware BYOD Policies.",
            "venue": "USENIX Security Symposium",
            "pages": "595-612",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Kang00TCL20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/kang",
            "url": "https://dblp.org/rec/conf/uss/Kang00TCL20",
            "abstract": "Bring Your Own Device (BYOD) has become the new norm for enterprise networks, but BYOD security remains a top concern. Context-aware security, which enforces access control based on dynamic runtime context, is a promising approach. Recent work has developed SDN solutions to collect device contexts and enforce access control at a central controller. However, the central controller could become a bottleneck and attack target. Processing context signals at the remote controller is also too slow for real-time decision change.We present a new paradigm, programmable in-network security (Poise), which is enabled by the emergence of programmable switches. At the heart of Poise is a novel security primitive, which can be programmed to support a wide range of context-aware policies in hardware. Users of Poise specify concise policies, and Poise compiles them into different configurations of the primitive in P4. Compared with traditional SDN defenses, Poise is resilient to control plane saturation attacks, and it dramatically increases defense agility.",
            "pdf_url": "",
            "keywords": [
                "Programmable In-Network Security",
                "Context-aware BYOD Policies",
                "Access Control",
                "Central Controller Bottleneck",
                "Real-time Decision Making"
            ]
        },
        "url": "URL#2332665"
    },
    {
        "@score": "1",
        "@id": "2332666",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "255/4780",
                        "text": "Zijo Kenjar"
                    },
                    {
                        "@pid": "189/1758",
                        "text": "Tommaso Frassetto"
                    },
                    {
                        "@pid": "164/2771",
                        "text": "David Gens"
                    },
                    {
                        "@pid": "f/MichaelFranz",
                        "text": "Michael Franz"
                    },
                    {
                        "@pid": "s/AhmadRezaSadeghi",
                        "text": "Ahmad-Reza Sadeghi"
                    }
                ]
            },
            "title": "V0LTpwn: Attacking x86 Processor Integrity from Software.",
            "venue": "USENIX Security Symposium",
            "pages": "1445-1461",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KenjarFGFS20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/kenjar",
            "url": "https://dblp.org/rec/conf/uss/KenjarFGFS20",
            "abstract": "Fault-injection attacks have been proven in the past to be a reliable way of bypassing hardware-based security measures, such as cryptographic hashes, privilege and access permission enforcement, and trusted execution environments. However, traditional fault-injection attacks require physical presence, and hence, were often considered out of scope in many real-world adversary settings. \nIn this paper we show this assumption may no longer be justified. We present V0LTpwn, a novel hardware-oriented but software-controlled attack that affects the integrity of computation in virtually any execution mode on modern x86 processors. To the best of our knowledge, this represents the first attack on x86 integrity from software. The key idea behind our attack is to undervolt a physical core to force non-recoverable hardware faults. Under a V0LTpwn attack, CPU instructions will continue to execute with erroneous results and without crashes, allowing for exploitation. In contrast to recently presented side-channel attacks that leverage vulnerable speculative execution, V0LTpwn is not limited to information disclosure, but allows adversaries to affect execution, and hence, effectively breaks the integrity goals of modern x86 platforms. In our detailed evaluation we successfully launch software-based attacks against Intel SGX enclaves from a privileged process to demonstrate that a V0LTpwn attack can successfully change the results of computations within enclave execution across multiple CPU revisions.",
            "keywords": [
                "Fault Injection Attacks",
                "x86 Processor Integrity",
                "Undervolting",
                "Software-Controlled Attacks",
                "Intel SGX Enclaves"
            ]
        },
        "url": "URL#2332666",
        "sema_paperId": "766adfdf75243bcb2b13692ba7306ab5b5f2d561"
    },
    {
        "@score": "1",
        "@id": "2332667",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "157/5259",
                        "text": "Taegyu Kim"
                    },
                    {
                        "@pid": "122/2010",
                        "text": "Chung Hwan Kim"
                    },
                    {
                        "@pid": "199/2183",
                        "text": "Altay Ozen"
                    },
                    {
                        "@pid": "61/7710-2",
                        "text": "Fan Fei 0002"
                    },
                    {
                        "@pid": "203/5343",
                        "text": "Zhan Tu"
                    },
                    {
                        "@pid": "95/3760-1",
                        "text": "Xiangyu Zhang 0001"
                    },
                    {
                        "@pid": "33/2032",
                        "text": "Xinyan Deng"
                    },
                    {
                        "@pid": "159/0537",
                        "text": "Dave (Jing) Tian"
                    },
                    {
                        "@pid": "59/5539",
                        "text": "Dongyan Xu"
                    }
                ]
            },
            "title": "From Control Model to Program: Investigating Robotic Aerial Vehicle Accidents with MAYDAY.",
            "venue": "USENIX Security Symposium",
            "pages": "913-930",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KimKOFT0DTX20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/kim",
            "url": "https://dblp.org/rec/conf/uss/KimKOFT0DTX20",
            "abstract": "With wide adoption of robotic aerial vehicles (RAVs), their accidents increasingly occur, calling for in-depth investigation of such accidents. Unfortunately, an inquiry to \u201cwhy did my drone crash\u201d often ends up with nowhere, if the root cause lies in the RAV\u2019s control program, due to the key challenges in evidence and methodology: (1) Current RAVs\u2019 flight log only records high-level vehicle control states and events, without recording control program execution; (2) The capability of \u201cconnecting the dots\u201d \u2013 from controller anomaly to program variable corruption to program bug location \u2013 is lacking. To address these challenges, we develop MAYDAY, a crossdomain post-accident investigation framework by mapping control model to control program, enabling (1) in-flight logging of control program execution, and (2) traceback to the control-semantic bug that led to an accident, based on controland program-level logs. We have applied MAYDAY to ArduPilot, a popular open-source RAV control program that runs on a wide range of commodity RAVs. Our investigation of 10 RAV accidents caused by real ArduPilot bugs demonstrates that MAYDAY is able to pinpoint the root causes of these accidents within the program with high accuracy and minimum runtime and storage overhead. We also found 4 recently patched bugs still vulnerable and alerted the ArduPilot team.",
            "keywords": [
                "Robotic Aerial Vehicles",
                "Accident Investigation",
                "Control Program",
                "Bug Localization",
                "Flight Log Analysis"
            ]
        },
        "url": "URL#2332667",
        "sema_paperId": "e8740922c1953b0c08efb3b27e9b0842e798c327"
    },
    {
        "@score": "1",
        "@id": "2332668",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "270/7339",
                        "text": "Chelsea Komlo"
                    },
                    {
                        "@pid": "21/993",
                        "text": "Nick Mathewson"
                    },
                    {
                        "@pid": "04/6434",
                        "text": "Ian Goldberg"
                    }
                ]
            },
            "title": "Walking Onions: Scaling Anonymity Networks while Protecting Users.",
            "venue": "USENIX Security Symposium",
            "pages": "1003-1020",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KomloMG20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/komlo",
            "url": "https://dblp.org/rec/conf/uss/KomloMG20",
            "abstract": "Scaling anonymity networks offers unique security challenges, as attackers can exploit differing views of the network\u2019s topology to perform epistemic and route capture attacks. Anonymity networks in practice, such as Tor, have opted for security over scalability by requiring participants to share a globally consistent view of all relays to prevent these kinds of attacks. Such an approach requires each user to maintain up-to-date information about every relay, causing the total amount of data each user must download every epoch to scale linearly with the number of relays. As the number of clients increases, more relays must be added to provide bandwidth, further exacerbating the total load on the network. In this work, we present Walking Onions , a set of protocols improving scalability for anonymity networks. Walking Onions enables constant-size scaling of the information each user must download in every epoch, even as the number of relays in the network grows. Furthermore, we show how relaxing the clients\u2019 bandwidth growth from constant to logarithmic can enable an outsized improvement to relays\u2019 bandwidth costs. Notably, Walking Onions offers the same security properties as current designs that require a globally consistent network view. We present two protocol variants. The \ufb01rst requires minimal changes from current onion-routing systems. The second presents a more signi\ufb01cant design change, thereby reducing the latency required to establish a path through the network while providing better forward secrecy than previous such constructions. We implement and evaluate Walking Onions in a simulated onion-routing anonymity network modelled after Tor, and validate that Walking Onions indeed offers signi\ufb01cant scalability improvements for networks at or above the size of the current Tor network.",
            "keywords": [
                "Anonymity Networks",
                "Scalability",
                "Epistemic Attacks",
                "Route Capture Attacks",
                "Walking Onions"
            ]
        },
        "url": "URL#2332668",
        "sema_paperId": "1df0dabddb42a865faf6727dd9de94a024049010"
    },
    {
        "@score": "1",
        "@id": "2332669",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "89/7860",
                        "text": "Ahmed E. Kosba"
                    },
                    {
                        "@pid": "18/9002",
                        "text": "Dimitrios Papadopoulos 0001"
                    },
                    {
                        "@pid": "p/CharalamposPapamanthou",
                        "text": "Charalampos Papamanthou"
                    },
                    {
                        "@pid": "s/DXSong",
                        "text": "Dawn Song"
                    }
                ]
            },
            "title": "MIRAGE: Succinct Arguments for Randomized Algorithms with Applications to Universal zk-SNARKs.",
            "venue": "USENIX Security Symposium",
            "pages": "2129-2146",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KosbaPPS20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/kosba",
            "url": "https://dblp.org/rec/conf/uss/KosbaPPS20",
            "abstract": "The last few years have witnessed increasing interest in the deployment of zero-knowledge proof systems, in particular ones with succinct proofs and efficient verification (zk-SNARKs). One of the main challenges facing the wide deployment of zk-SNARKs  is the requirement of a trusted key generation phase per different computation to achieve practical proving performance. Existing zero-knowledge proof systems that do not require trusted setup or have a single trusted preprocessing phase suffer from increased proof size and/or additional verification overhead. On the other other hand, although universal circuit generators for zk-SNARKs (that can eliminate the need for per-computation preprocessing) have been introduced in the literature, the performance of the prover remains far from practical for real-world applications.In this paper, we first present a new zk-SNARK system that is well-suited for randomized algorithms\u2014in particular it does not encode randomness generation within the arithmetic circuit allowing for more practical prover times. Then, we design a universal circuit that takes as input any arithmetic circuit of a bounded number of operations as well as a possible value assignment, and performs  randomized checks to verify consistency. Our universal circuit is linear in the number of operations instead of quasi-linear like other universal circuits. By applying our new zk-SNARK system to our universal circuit, we build MIRAGE, a universal zk-SNARK with very succinct proofs\u2014the proof contains just one additional element compared to the per-circuit preprocessing state-of-the-art zk-SNARK by Groth (Eurocrypt 2016). Finally, we implement MIRAGE and experimentally evaluate its performance for different circuits and in the context of privacy-preserving smart contracts.",
            "pdf_url": "",
            "keywords": [
                "Zero-Knowledge Proofs",
                "zk-SNARKs",
                "Randomized Algorithms",
                "Universal Circuit",
                "Succinct Proofs"
            ]
        },
        "url": "URL#2332669"
    },
    {
        "@score": "1",
        "@id": "2332670",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "227/2162",
                        "text": "Renuka Kumar"
                    },
                    {
                        "@pid": "231/4169",
                        "text": "Sreesh Kishore"
                    },
                    {
                        "@pid": "72/5422",
                        "text": "Hao Lu"
                    },
                    {
                        "@pid": "p/AtulPrakash",
                        "text": "Atul Prakash 0001"
                    }
                ]
            },
            "title": "Security Analysis of Unified Payments Interface and Payment Apps in India.",
            "venue": "USENIX Security Symposium",
            "pages": "1499-1516",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KumarKLP20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/kumar",
            "url": "https://dblp.org/rec/conf/uss/KumarKLP20",
            "abstract": "Since 2016, with a strong push from the Government of India, smartphone-based payment apps have become mainstream, with over $50 billion transacted through these apps in 2018. Many of these apps use a common infrastructure introduced by the Indian government, called the Uni\ufb01ed Payments Interface (UPI), but there has been no security analysis of this critical piece of infrastructure that supports money transfers. This paper uses a principled methodology to do a detailed security analysis of the UPI protocol by reverse-engineering the design of this protocol through seven popular UPI apps. We discover previously-unreported multi-factor authentication design-level \ufb02aws in the UPI 1.0 speci\ufb01cation that can lead to signi\ufb01cant attacks when combined with an installed attacker-controlled application. In an extreme version of the attack, the \ufb02aws could allow a victim\u2019s bank account to be linked and emptied, even if a victim had never used a UPI app. The potential attacks were scalable and could be done remotely. We discuss our methodology and detail how we overcame challenges in reverse-engineering this unpublished application layer protocol, including that all UPI apps undergo a rigorous security review in India and are designed to resist analysis. The work resulted in several CVEs, and a key attack vector that we reported was later addressed in UPI 2.0.",
            "keywords": [
                "Unified Payments Interface",
                "Payment Apps",
                "Security Analysis",
                "Multi-Factor Authentication Flaws",
                "Bank Account Vulnerabilities"
            ]
        },
        "url": "URL#2332670",
        "sema_paperId": "b1eed4353ca9c76d45dfc6b399bce330d0dc773f"
    },
    {
        "@score": "1",
        "@id": "2332671",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "267/1560",
                        "text": "Hyeonmin Lee"
                    },
                    {
                        "@pid": "272/7202",
                        "text": "Aniketh Gireesh"
                    },
                    {
                        "@pid": "155/5773",
                        "text": "Roland van Rijswijk-Deij"
                    },
                    {
                        "@pid": "14/2293-1",
                        "text": "Taekyoung Kwon 0001"
                    },
                    {
                        "@pid": "90/8396",
                        "text": "Taejoong Chung"
                    }
                ]
            },
            "title": "A Longitudinal and Comprehensive Study of the DANE Ecosystem in Email.",
            "venue": "USENIX Security Symposium",
            "pages": "613-630",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LeeGR0C20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/lee-hyeonmin",
            "url": "https://dblp.org/rec/conf/uss/LeeGR0C20",
            "abstract": "The DNS-based Authentication of Named Entities (DANE) standard allows clients and servers to establish a TLS connection without relying on trusted third parties like CAs by publishing TLSA records. DANE uses the Domain Name System Security Extensions (DNSSEC) PKI to achieve integrity and authenticity. However, DANE can only work correctly if each principal in its PKI properly performs its duty: through their DNSSEC-aware DNS servers, DANE servers (e.g., SMTP servers) must publish their TLSA records, which are consistent with their certi\ufb01cates. Similarly, DANE clients (e.g., SMTP clients) must verify the DANE servers\u2019 TLSA records, which are also used to validate the fetched certi\ufb01cates. DANE is rapidly gaining popularity in the email ecosystem, to help improve transport security between mail servers. Yet its security bene\ufb01ts hinge on deploying DANE correctly. In this paper we perform a large-scale, longitudinal, and comprehensive measurement study on how well the DANE standard and its relevant protocols are deployed and managed. We collect data for all second-level domains under the .com , .net , .org , .nl , and .se TLDs over a period of 24 months to analyze server-side deployment and management. To analyse the client-side deployment and management, we investigate 29 popular email service providers, and four popular MTA and eleven DNS software programs. Our study reveals pervasive mismanagement in the DANE ecosystem. For instance, we found that 35% of TLSA records cannot be validated due to missing or incorrect DNSSEC records, and 3.68% of them are inconsistent with their certi\ufb01cates. We also found that only four email service providers support DANE for both outgoing and",
            "keywords": [
                "DANE Ecosystem",
                "Email Security",
                "TLSA Records",
                "DNSSEC",
                "Deployment Mismanagement"
            ]
        },
        "url": "URL#2332671",
        "sema_paperId": "6fcc091291209d10f64f66a133d4194a73c0c877"
    },
    {
        "@score": "1",
        "@id": "2332672",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "256/5167",
                        "text": "Suyoung Lee"
                    },
                    {
                        "@pid": "207/6588",
                        "text": "HyungSeok Han"
                    },
                    {
                        "@pid": "49/8463",
                        "text": "Sang Kil Cha"
                    },
                    {
                        "@pid": "09/3668",
                        "text": "Sooel Son"
                    }
                ]
            },
            "title": "Montage: A Neural Network Language Model-Guided JavaScript Engine Fuzzer.",
            "venue": "USENIX Security Symposium",
            "pages": "2613-2630",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LeeHCS20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/lee-suyoung",
            "url": "https://dblp.org/rec/conf/uss/LeeHCS20",
            "abstract": "JavaScript (JS) engine vulnerabilities pose significant security threats affecting billions of web browsers. While fuzzing is a prevalent technique for finding such vulnerabilities, there have been few studies that leverage the recent advances in neural network language models (NNLMs). In this paper, we present Montage, the first NNLM-guided fuzzer for finding JS engine vulnerabilities. The key aspect of our technique is to transform a JS abstract syntax tree (AST) into a sequence of AST subtrees that can directly train prevailing NNLMs. We demonstrate that Montage is capable of generating valid JS tests, and show that it outperforms previous studies in terms of finding vulnerabilities. Montage found 37 real-world bugs, including three CVEs, in the latest JS engines, demonstrating its efficacy in finding JS engine bugs.",
            "keywords": [
                "JavaScript Engine Fuzzing",
                "Neural Network Language Models",
                "Vulnerability Detection",
                "Abstract Syntax Tree",
                "Real-World Bugs"
            ]
        },
        "url": "URL#2332672",
        "sema_paperId": "f976a25fbbb86fc7c10008b1276940885cee41d0"
    },
    {
        "@score": "1",
        "@id": "2332673",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "223/7759",
                        "text": "Dayeol Lee"
                    },
                    {
                        "@pid": "38/1591",
                        "text": "Dongha Jung"
                    },
                    {
                        "@pid": "255/4803",
                        "text": "Ian T. Fang"
                    },
                    {
                        "@pid": "277/2163",
                        "text": "Chia-Che Tsai"
                    },
                    {
                        "@pid": "91/275",
                        "text": "Raluca Ada Popa"
                    }
                ]
            },
            "title": "An Off-Chip Attack on Hardware Enclaves via the Memory Bus.",
            "venue": "USENIX Security Symposium",
            "pages": "487-504",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LeeJFTP20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/lee-dayeol",
            "url": "https://dblp.org/rec/conf/uss/LeeJFTP20",
            "abstract": "This paper shows how an attacker can break the confidentiality of a hardware enclave with Membuster, an off-chip attack based on snooping the memory bus. An attacker with physical access can observe an unencrypted address bus and extract fine-grained memory access patterns of the victim. Membuster is qualitatively different from prior on-chip attacks to enclaves and is more difficult to thwart. \nWe highlight several challenges for Membuster. First, DRAM requests are only visible on the memory bus at last-level cache misses. Second, the attack needs to incur minimal interference or overhead to the victim to prevent the detection of the attack. Lastly, the attacker needs to reverse-engineer the translation between virtual, physical, and DRAM addresses to perform a robust attack. We introduce three techniques, critical page whitelisting, cache squeezing, and oracle-based fuzzy matching algorithm to increase cache misses for memory accesses that are useful for the attack, with no detectable interference to the victim, and to convert memory accesses to sensitive data. We demonstrate Membuster on an Intel SGX CPU to leak confidential data from two applications: Hunspell and Memcached. We show that a single uninterrupted run of the victim can leak most of the sensitive data with high accuracy.",
            "pdf_url": "",
            "keywords": [
                "Hardware Enclaves",
                "Memory Bus Attacks",
                "Confidentiality Breach",
                "Off-Chip Attacks",
                "Intel SGX"
            ]
        },
        "url": "URL#2332673"
    },
    {
        "@score": "1",
        "@id": "2332674",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "262/5593",
                        "text": "Markus Legner"
                    },
                    {
                        "@pid": "182/9170",
                        "text": "Tobias Klenze"
                    },
                    {
                        "@pid": "227/7984",
                        "text": "Marc Wyss"
                    },
                    {
                        "@pid": "s/ChristophSprenger",
                        "text": "Christoph Sprenger 0001"
                    },
                    {
                        "@pid": "16/6873",
                        "text": "Adrian Perrig"
                    }
                ]
            },
            "title": "EPIC: Every Packet Is Checked in the Data Plane of a Path-Aware Internet.",
            "venue": "USENIX Security Symposium",
            "pages": "541-558",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LegnerKW0P20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/legner",
            "url": "https://dblp.org/rec/conf/uss/LegnerKW0P20",
            "abstract": "An exciting insight of recent networking research has been that path-aware networking architectures are able to fundamentally solve many of the security issues of today\u2019s Internet, while increasing overall efficiency and giving control over path selection to end hosts. In this paper, we consider three important issues related to this new networking paradigm: First, network operators still need to be able to impose their own policies to rule out uneconomical paths and to enforce these decisions on the data plane. Second, end hosts should be able to verify that their forwarding decisions are actually followed by the network. Finally, both intermediate routers and recipients should be able to authenticate the source of packets. These properties have been considered by previous work, but there is no existing system that achieves both strong security guarantees and high efficiency. We propose EPIC, a family of data-plane protocols that provide increasingly strong security properties, addressing all three described requirements. The EPIC protocols have significantly lower communication overhead than comparable systems: for realistic path lengths, the overhead is 3\u20135 times smaller compared to the state-of-the-art systems OPT and ICING. Our prototype implementation is able to saturate a 40 Gbps link even on commodity hardware due to the use of only few highly efficient symmetric cryptographic operations in the forwarding process. Thus, by ensuring that every packet is checked at every hop, we make an important step towards an efficient and secure future Internet.",
            "keywords": [
                "Path-Aware Networking",
                "Data Plane Protocols",
                "Packet Authentication",
                "Forwarding Verification",
                "Security and Efficiency"
            ]
        },
        "url": "URL#2332674",
        "sema_paperId": "220c327b85ebf750708c173d294fba0268f0a2b9"
    },
    {
        "@score": "1",
        "@id": "2332675",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "215/3626",
                        "text": "Klas Leino"
                    },
                    {
                        "@pid": "38/2612",
                        "text": "Matt Fredrikson"
                    }
                ]
            },
            "title": "Stolen Memories: Leveraging Model Memorization for Calibrated White-Box Membership Inference.",
            "venue": "USENIX Security Symposium",
            "pages": "1605-1622",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LeinoF20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/leino",
            "url": "https://dblp.org/rec/conf/uss/LeinoF20",
            "abstract": "Membership inference (MI) attacks exploit the fact that machine learning algorithms sometimes leak information about their training data through the learned model. In this work, we study membership inference in the white-box setting in order to exploit the internals of a model, which have not been effectively utilized by previous work. Leveraging new insights about how overfitting occurs in deep neural networks, we show how a model's idiosyncratic use of features can provide evidence for membership to white-box attackers---even when the model's black-box behavior appears to generalize well---and demonstrate that this attack outperforms prior black-box methods. Taking the position that an effective attack should have the ability to provide confident positive inferences, we find that previous attacks do not often provide a meaningful basis for confidently inferring membership, whereas our attack can be effectively calibrated for high precision. Finally, we examine popular defenses against MI attacks, finding that (1) smaller generalization error is not sufficient to prevent attacks on real models, and (2) while small-\u03f5-differential privacy reduces the attack's effectiveness, this often comes at a significant cost to the model's accuracy; and for larger \u03f5 that are sometimes used in practice (e.g., \u03f5=16), the attack can achieve nearly the same accuracy as on the unprotected model.",
            "pdf_url": "",
            "keywords": [
                "Membership Inference",
                "White-Box Attacks",
                "Model Overfitting",
                "Calibrated Inference",
                "Differential Privacy"
            ]
        },
        "url": "URL#2332675"
    },
    {
        "@score": "1",
        "@id": "2332676",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "30/1133",
                        "text": "Ga\u00ebtan Leurent"
                    },
                    {
                        "@pid": "p/ThomasPeyrin",
                        "text": "Thomas Peyrin"
                    }
                ]
            },
            "title": "SHA-1 is a Shambles: First Chosen-Prefix Collision on SHA-1 and Application to the PGP Web of Trust.",
            "venue": "USENIX Security Symposium",
            "pages": "1839-1856",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LeurentP20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/leurent",
            "url": "https://dblp.org/rec/conf/uss/LeurentP20",
            "abstract": "The SHA-1 hash function was designed in 1995 and has been widely used during two decades. A theoretical collision attack was first proposed in 2004 [29], but due to its high complexity it was only implemented in practice in 2017, using a large GPU cluster [23]. More recently, an almost practical chosen-prefix collision attack against SHA-1 has been proposed [12]. This more powerful attack allows to build colliding messages with two arbitrary prefixes, which is much more threatening for real protocols. In this paper, we report the first practical implementation of this attack, and its impact on real-world security with a PGP/GnuPG impersonation attack. We managed to significantly reduce the complexity of collision attacks against SHA-1: on an Nvidia GTX 970, identical-prefix collisions can now be computed with a complexity (expressed in terms of SHA-1 equivalents on this GPU) of 261.2 rather than 264.7, and chosen-prefix collisions with a complexity of 263.4 rather than 267.1. When renting cheap GPUs, this translates to a cost of US$ 11k for a collision, and US$ 45k for a chosen-prefix collision, within the means of academic researchers. Our actual attack required two months of computations using 900 Nvidia GTX 1060 GPUs. Therefore, the same attacks that have been practical on MD5 since 2009 are now practical on SHA-1. In particular, chosen-prefix collisions can break signature schemes and handshake security in secure channel protocols (TLS, SSH), if generated extremely quickly. We strongly advise to remove SHA-1 from those type of applications as soon as possible. We exemplify our cryptanalysis by creating a pair of PGP/GnuPG keys with different identities, but colliding SHA-1 certificates. A SHA-1 certification of the first key can therefore be transferred to the second key, leading to an impersonation attack. This proves that SHA-1 signatures now offer virtually no security in practice. \u2217https://sha-mbles.github.io/ The legacy branch of GnuPG still uses SHA-1 by default for identity certifications, but after notifying the authors, the modern branch now rejects SHA-1 signatures (the issue is tracked as CVE-2019-14855).",
            "keywords": [
                "SHA-1 Cryptography",
                "Chosen-Prefix Collision",
                "PGP/GnuPG Impersonation",
                "Collision Attack Complexity",
                "Hash Function Vulnerability"
            ]
        },
        "url": "URL#2332676",
        "sema_paperId": "b3acfb1793ba495b165053e90c60030aac75e22d"
    },
    {
        "@score": "1",
        "@id": "2332677",
        "info": {
            "authors": {
                "author": {
                    "@pid": "53/10825",
                    "text": "Frank Li 0001"
                }
            },
            "title": "Shim Shimmeny: Evaluating the Security and Privacy Contributions of Link Shimming in the Modern Web.",
            "venue": "USENIX Security Symposium",
            "pages": "649-664",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Li20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/li-frank",
            "url": "https://dblp.org/rec/conf/uss/Li20",
            "abstract": "Link shimming (also known as URL wrapping) is a technique widely used by websites, where URLs on a site are rewritten to direct link navigations to an intermediary end-point before redirecting to the original destination. This \u201cshim-ming\u201d of URL clicks can serve navigation security, privacy, and analytics purposes, and has been deployed by prominent websites (e.g., Facebook, Twitter, Microsoft, Google) for over a decade. Yet, we lack a deep understanding of its purported security and privacy contributions, particularly in today\u2019s web ecosystem, where modern browsers provide potential alternative mechanisms for protecting link navigations without link shimming\u2019s costs. In this paper, we provide a large-scale empirical evaluation of link shimming\u2019s security and privacy contributions, using Facebook\u2019s real-world deployment as a case study. Our results indicate that even in the modern web, link shimming can provide meaningful security and privacy bene\ufb01ts to users broadly. These bene\ufb01ts are most notable for the sizable populations that we observed with a high prevalence of legacy browser clients, such as in mobile-centric developing countries. We discuss the tradeoff of these gains against potential costs. Beyond link shimming, our \ufb01ndings also provide insights for advancing user online protection, such as on the web ecosystem\u2019s distribution of responsibility, legacy software scenarios, and user responses to website security warnings.",
            "keywords": [
                "Link Shimming",
                "Web Security",
                "Privacy Protection",
                "URL Rewriting",
                "Browser Compatibility"
            ]
        },
        "url": "URL#2332677",
        "sema_paperId": "91e3c1dfefe1d1a4627aef60dc6a82b9cd0e2aa8"
    },
    {
        "@score": "1",
        "@id": "2332678",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "76/7842",
                        "text": "Jinfeng Li"
                    },
                    {
                        "@pid": "128/2982",
                        "text": "Tianyu Du"
                    },
                    {
                        "@pid": "07/8388",
                        "text": "Shouling Ji"
                    },
                    {
                        "@pid": "13/5366-6",
                        "text": "Rong Zhang 0006"
                    },
                    {
                        "@pid": "73/5241",
                        "text": "Quan Lu"
                    },
                    {
                        "@pid": "02/1640-2",
                        "text": "Min Yang 0002"
                    },
                    {
                        "@pid": "12/2633-6",
                        "text": "Ting Wang 0006"
                    }
                ]
            },
            "title": "TextShield: Robust Text Classification Based on Multimodal Embedding and Neural Machine Translation.",
            "venue": "USENIX Security Symposium",
            "pages": "1381-1398",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiDJZLY020",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/li-jinfeng",
            "url": "https://dblp.org/rec/conf/uss/LiDJZLY020",
            "abstract": "Text-based toxic content detection is an important tool for reducing harmful interactions in online social media environments. Yet, its underlying mechanism, deep learning-based text classi\ufb01cation (DLTC), is inherently vulnerable to maliciously crafted adversarial texts. To mitigate such vulnerabilities, intensive research has been conducted on strengthening English-based DLTC models. However, the existing defenses are not effective for Chinese-based DLTC models, due to the unique sparseness, diversity, and variation of the Chinese language. In this paper, we bridge this striking gap by presenting T EXT S HIELD , a new adversarial defense framework speci\ufb01cally designed for Chinese-based DLTC models. T EXT S HIELD differs from previous work in several key aspects: (i) generic \u2013 it applies to any Chinese-based DLTC models without requiring re-training; (ii) robust \u2013 it signi\ufb01-cantly reduces the attack success rate even under the setting of adaptive attacks; and (iii) accurate \u2013 it has little impact on the performance of DLTC models over legitimate inputs. Extensive evaluations show that it outperforms both existing methods and the industry-leading platforms. Future work will explore its applicability in broader practical tasks.",
            "keywords": [
                "Text Classification",
                "Adversarial Defense",
                "Toxic Content Detection",
                "Chinese Language Processing",
                "Attack Resilience"
            ]
        },
        "url": "URL#2332678",
        "sema_paperId": "93ad61c5700b3aabbc9192f742fea1a734bcb45b"
    },
    {
        "@score": "1",
        "@id": "2332679",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "272/7161",
                        "text": "Baozheng Liu"
                    },
                    {
                        "@pid": "94/3019-8",
                        "text": "Chao Zhang 0008"
                    },
                    {
                        "@pid": "55/3195",
                        "text": "Guang Gong"
                    },
                    {
                        "@pid": "272/7212",
                        "text": "Yishun Zeng"
                    },
                    {
                        "@pid": "272/7206",
                        "text": "Haifeng Ruan"
                    },
                    {
                        "@pid": "15/3840",
                        "text": "Jianwei Zhuge"
                    }
                ]
            },
            "title": "FANS: Fuzzing Android Native System Services via Automated Interface Analysis.",
            "venue": "USENIX Security Symposium",
            "pages": "307-323",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiuZGZRZ20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/liu",
            "url": "https://dblp.org/rec/conf/uss/LiuZGZRZ20",
            "abstract": "Android native system services provide essential supports and fundamental functionalities for user apps. Finding vulnerabilities in them is crucial for Android security. Fuzzing is one of the most popular vulnerability discovery solutions, yet faces several challenges when applied to Android native system services. First, such services are invoked via a special inter-process communication (IPC) mechanism, namely binder , via service-speci\ufb01c interfaces. Thus, the fuzzer has to recognize all interfaces and generate interface-speci\ufb01c test cases automatically. Second, effective test cases should satisfy the interface model of each interface. Third, the test cases should also satisfy the semantic requirements, including variable dependencies and interface dependencies. In this paper, we propose an automated generation-based fuzzing solution FANS to \ufb01nd vulnerabilities in Android native system services. It \ufb01rst collects all interfaces in target services and uncovers deep nested multi-level interfaces to test. Then, it automatically extracts interface models, including feasible transaction code, variable names and types in the transaction data, from the abstract syntax tree (AST) of target interfaces. Further, it infers variable dependencies in transactions via the variable name and type knowledge, and infers interface dependencies via the generation and use relationship. Finally, it employs the interface models and dependency knowledge to generate sequences of transactions, which have valid formats and semantics, to test interfaces of target services. We implemented a prototype of FANS from scratch and evaluated it on six smartphones equipped with a recent version of Android, i.e., android-9.0.0_r46 , and found 30 unique vulnerabilities deduplicated from thousands of crashes, of which 20 have been con\ufb01rmed by Google. Surprisingly, we also discovered 138 unique Java exceptions during fuzzing.",
            "keywords": [
                "Android Native System Services",
                "Fuzzing",
                "Vulnerability Discovery",
                "Inter-Process Communication (IPC)",
                "Interface Model Generation"
            ]
        },
        "url": "URL#2332679",
        "sema_paperId": "bf82b7275d3b4327e3251089f43c4effbabadf3c"
    },
    {
        "@score": "1",
        "@id": "2332680",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "35/9846",
                        "text": "Wouter Lueks"
                    },
                    {
                        "@pid": "239/7253",
                        "text": "I\u00f1igo Querejeta-Azurmendi"
                    },
                    {
                        "@pid": "01/4825",
                        "text": "Carmela Troncoso"
                    }
                ]
            },
            "title": "VoteAgain: A scalable coercion-resistant voting system.",
            "venue": "USENIX Security Symposium",
            "pages": "1553-1570",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LueksQT20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/lueks",
            "url": "https://dblp.org/rec/conf/uss/LueksQT20",
            "abstract": "The strongest threat model for voting systems considers coercion resistance: protection against coercers that force voters to modify their votes, or to abstain. Existing remote voting systems either do not provide this property; require an expensive tallying phase; or burden users with the need to store cryptographic key material and with the responsibility to deceive their coercers. We propose VoteAgain, a scalable voting scheme that relies on the revoting paradigm to provide coercion resistance. VoteAgain uses a novel deterministic ballot padding mechanism to ensure that coercers cannot see whether a vote has been replaced. This mechanism ensures tallies take quasilinear time, making VoteAgain the first revoting scheme that can handle elections with millions of voters. We prove that VoteAgain provides ballot privacy, coercion resistance, and verifiability; and we demonstrate its scalability using a prototype implementation of all cryptographic primitives.",
            "keywords": [
                "Coercion-Resistant Voting",
                "Revoting Paradigm",
                "Ballot Privacy",
                "Voting System Scalability",
                "Deterministic Ballot Padding"
            ]
        },
        "url": "URL#2332680",
        "sema_paperId": "ff4177de2b9ed1e031c767892134a6cbd4cd750f"
    },
    {
        "@score": "1",
        "@id": "2332681",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "166/4034",
                        "text": "Mulong Luo"
                    },
                    {
                        "@pid": "m/AndrewCMyers",
                        "text": "Andrew C. Myers"
                    },
                    {
                        "@pid": "09/5657",
                        "text": "G. Edward Suh"
                    }
                ]
            },
            "title": "Stealthy Tracking of Autonomous Vehicles with Cache Side Channels.",
            "venue": "USENIX Security Symposium",
            "pages": "859-876",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LuoMS20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/luo",
            "url": "https://dblp.org/rec/conf/uss/LuoMS20",
            "abstract": "Autonomous vehicles are becoming increasingly popular, but their reliance on computer systems to sense and operate in the physical world introduces new security risks. In this paper, we show that the location privacy of an autonomous vehicle may be compromised by software side-channel attacks if localization software shares a hardware platform with an attack program. In particular, we demonstrate that a cache side-channel attack can be used to infer the route or the location of a vehicle that runs the adaptive Monte-Carlo localization (AMCL) algorithm. The main contributions of the paper are as follows. First, we show that adaptive behaviors of perception and control algorithms may introduce new sidechannel vulnerabilities that reveal the physical properties of a vehicle or its environment. Second, we introduce statistical learning models that infer the AMCL algorithm\u2019s state from cache access patterns and predict the route or the location of a vehicle from the trace of the AMCL state. Third, we implement and demonstrate the attack on a realistic software stack using real-world sensor data recorded on city roads. Our findings suggest that autonomous driving software needs strong timing-channel protection for location privacy.",
            "keywords": [
                "Autonomous Vehicles",
                "Cache Side-Channel Attacks",
                "Location Privacy",
                "Adaptive Monte-Carlo Localization",
                "Timing-Channel Protection"
            ]
        },
        "url": "URL#2332681",
        "sema_paperId": "e595257684bfdeeb30f37fa840abb031bd6379ff"
    },
    {
        "@score": "1",
        "@id": "2332682",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "248/1724",
                        "text": "Samin Yaseer Mahmud"
                    },
                    {
                        "@pid": "202/9038",
                        "text": "Akhil Acharya"
                    },
                    {
                        "@pid": "167/0165",
                        "text": "Benjamin Andow"
                    },
                    {
                        "@pid": "22/4463",
                        "text": "William Enck"
                    },
                    {
                        "@pid": "117/3983",
                        "text": "Bradley Reaves"
                    }
                ]
            },
            "title": "Cardpliance: PCI DSS Compliance of Android Applications.",
            "venue": "USENIX Security Symposium",
            "pages": "1517-1533",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MahmudAAER20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/mahmud",
            "url": "https://dblp.org/rec/conf/uss/MahmudAAER20",
            "abstract": "Smartphones and their applications have become a predominant way of computing, and it is only natural that they have become an important part of \ufb01nancial transaction technology. However, applications asking users to enter credit card numbers have been largely overlooked by prior studies, which frequently report pervasive security and privacy concerns in the general mobile application ecosystem. Such applications are particularly security-sensitive, and they are subject to the Payment Card Industry Data Security Standard (PCI DSS). In this paper, we design a tool called Cardpliance , which bridges the semantics of the graphical user interface with static program analysis to capture relevant requirements from PCI DSS. We use Cardpliance to study 358 popular applications from Google Play that ask the user to enter a credit card number. Overall, we found that 1.67 % of the 358 applications are not compliant with PCI DSS, with vulnerabilities including improperly storing credit card numbers and card veri\ufb01cation codes. These \ufb01ndings paint a largely positive picture of the state of PCI DSS compliance of popular Android applications.",
            "keywords": [
                "Android Application Security",
                "PCI DSS Compliance",
                "Credit Card Processing",
                "Vulnerabilities in Mobile Apps",
                "Cardpliance Tool"
            ]
        },
        "url": "URL#2332682",
        "sema_paperId": "bc44b4f4c75bcec792acae4743a2ad19b41e086e"
    },
    {
        "@score": "1",
        "@id": "2332684",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "128/2970",
                        "text": "Sahar Mazloom"
                    },
                    {
                        "@pid": "252/4143",
                        "text": "Phi Hung Le"
                    },
                    {
                        "@pid": "09/10308",
                        "text": "Samuel Ranellucci"
                    },
                    {
                        "@pid": "73/2739",
                        "text": "S. Dov Gordon"
                    }
                ]
            },
            "title": "Secure parallel computation on national scale volumes of data.",
            "venue": "USENIX Security Symposium",
            "pages": "2487-2504",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MazloomLRG20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/mazloom",
            "url": "https://dblp.org/rec/conf/uss/MazloomLRG20",
            "abstract": "We revisit the problem of performing secure computation of graph-parallel algorithms, focusing on the applications of securely outsourcing matrix factorization, and histograms. Leveraging recent results in low-communication secure multi-party computation, and a security relaxation that allows the computation servers to learn some differentially private leakage about user inputs, we construct a new protocol that reduces overall runtime by 320 X , reduces the number of AES calls by 750 X , and reduces the total communication by 200 X . Our system can securely compute histograms over 300 million items in about 4 minutes, and it can perform sparse matrix factorization, which is commonly used in recommendation systems, on 20 million records in about 6 minutes. 1 Furthermore, in contrast to prior work, our system is secure against a malicious adversary that corrupts one of the computing servers.",
            "keywords": [
                "Secure Multi-Party Computation",
                "Graph-Parallel Algorithms",
                "Matrix Factorization",
                "Differential Privacy",
                "Malicious Adversary"
            ]
        },
        "url": "URL#2332684",
        "sema_paperId": "e785a3a5e6d7cd1b6069aa40ae3f3106f35ec925"
    },
    {
        "@score": "1",
        "@id": "2332685",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "219/5889",
                        "text": "Zeyu Mi"
                    },
                    {
                        "@pid": "237/7672",
                        "text": "Dingji Li"
                    },
                    {
                        "@pid": "31/6601-1",
                        "text": "Haibo Chen 0001"
                    },
                    {
                        "@pid": "86/680",
                        "text": "Binyu Zang"
                    },
                    {
                        "@pid": "96/5680",
                        "text": "Haibing Guan"
                    }
                ]
            },
            "title": "(Mostly) Exitless VM Protection from Untrusted Hypervisor through Disaggregated Nested Virtualization.",
            "venue": "USENIX Security Symposium",
            "pages": "1695-1712",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MiLCZG20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/mi",
            "url": "https://dblp.org/rec/conf/uss/MiLCZG20",
            "abstract": "Today\u2019s cloud tenants are facing severe security threats such as compromised hypervisors, which forces a strong adversary model where the hypervisor should be excluded out of the TCB. Previous approaches to shielding guest VMs either suffer from insufficient protection or result in suboptimal performance due to frequent VM exits (especially for I/O operations). This paper presents CloudVisor-D, an efficient nested hypervisor design that embraces both strong protection and high performance. The core idea of CloudVisor-D is to disaggregate the nested hypervisor by separating major protection logics into a protected Guardian-VM alongside each guest VM. The Guardian-VM is securely isolated and protected by the nested hypervisor and provides secure services for most privileged operations like hypercalls, EPT violations and I/O operations from guest VMs. By leveraging recent hardware features, most privileged operations from a guest VM require no VM exits to the nested hypervisor, which are the major sources of performance slowdown in prior designs. We have implemented CloudVisor-D on a commercially available machine with these recent hardware features. Experimental evaluation shows that CloudVisor-D incurs negligible performance overhead even for I/O intensive benchmarks and in some cases outperforms a vanilla hypervisor due to the reduced number of VM exits.",
            "keywords": [
                "Nested Virtualization",
                "Cloud Security",
                "Hypervisor Isolation",
                "Guardian-VM",
                "Performance Optimization"
            ]
        },
        "url": "URL#2332685",
        "sema_paperId": "779bab2dedbc78b4232fd8388ebee30890164fb1"
    },
    {
        "@score": "1",
        "@id": "2332686",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "119/3501",
                        "text": "Seyed Ali Mirheidari"
                    },
                    {
                        "@pid": "93/7474",
                        "text": "Sajjad Arshad"
                    },
                    {
                        "@pid": "77/8031",
                        "text": "Kaan Onarlioglu"
                    },
                    {
                        "@pid": "c/BrunoCrispo",
                        "text": "Bruno Crispo"
                    },
                    {
                        "@pid": "k/EnginKirda",
                        "text": "Engin Kirda"
                    },
                    {
                        "@pid": "r/WilliamKRobertson",
                        "text": "William Robertson 0002"
                    }
                ]
            },
            "title": "Cached and Confused: Web Cache Deception in the Wild.",
            "venue": "USENIX Security Symposium",
            "pages": "665-682",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MirheidariAOCK020",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/mirheidari",
            "url": "https://dblp.org/rec/conf/uss/MirheidariAOCK020",
            "abstract": "Web cache deception (WCD) is an attack proposed in 2017, where an attacker tricks a caching proxy into erroneously storing private information transmitted over the Internet and subsequently gains unauthorized access to that cached data. Due to the widespread use of web caches and, in particular, the use of massive networks of caching proxies deployed by content distribution network (CDN) providers as a critical component of the Internet, WCD puts a substantial population of Internet users at risk. We present the first large-scale study that quantifies the prevalence of WCD in 340 high-profile sites among the Alexa Top 5K. Our analysis reveals WCD vulnerabilities that leak private user data as well as secret authentication and authorization tokens that can be leveraged by an attacker to mount damaging web application attacks. Furthermore, we explore WCD in a scientific framework as an instance of the path confusion class of attacks, and demonstrate that variations on the path confusion technique used make it possible to exploit sites that are otherwise not impacted by the original attack. Our findings show that many popular sites remain vulnerable two years after the public disclosure of WCD. Our empirical experiments with popular CDN providers underline the fact that web caches are not plug & play technologies. In order to mitigate WCD, site operators must adopt a holistic view of their web infrastructure and carefully configure cache settings appropriate for their applications.",
            "keywords": [
                "Web Cache Deception",
                "Caching Proxy Vulnerabilities",
                "Content Distribution Networks",
                "Path Confusion Attacks",
                "Private Data Leakage"
            ]
        },
        "url": "URL#2332686",
        "sema_paperId": "b935383163b683e754fcfb2df02dec088a259973"
    },
    {
        "@score": "1",
        "@id": "2332687",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "161/3103",
                        "text": "Pratyush Mishra"
                    },
                    {
                        "@pid": "256/9139",
                        "text": "Ryan Lehmkuhl"
                    },
                    {
                        "@pid": "153/9906",
                        "text": "Akshayaram Srinivasan"
                    },
                    {
                        "@pid": "94/4314",
                        "text": "Wenting Zheng"
                    },
                    {
                        "@pid": "91/275",
                        "text": "Raluca Ada Popa"
                    }
                ]
            },
            "title": "Delphi: A Cryptographic Inference Service for Neural Networks.",
            "venue": "USENIX Security Symposium",
            "pages": "2505-2522",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MishraLSZP20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/mishra",
            "url": "https://dblp.org/rec/conf/uss/MishraLSZP20",
            "abstract": "Many companies provide neural network prediction services to users for a wide range of applications. However, current prediction systems compromise  one party's privacy: either the user has to send sensitive inputs to the service provider for classification, or the service provider must store its proprietary neural networks on the user's device. The former harms the personal privacy of the user, while the latter reveals the service provider's proprietary model.We design, implement, and evaluate Delphi, a secure prediction system that allows two parties to run a neural network inference without revealing either party's data. Delphi approaches the problem by simultaneously co-designing cryptography and machine learning. We first design a hybrid cryptographic protocol that improves upon the communication and computation costs over prior work. Second, we develop a planner that automatically generates neural network architecture configurations that navigate the performance-accuracy trade-offs of our hybrid protocol. Together, these techniques allow us to achieve a 22x improvement in prediction latency compared to the state-of-the-art prior work.",
            "pdf_url": "",
            "keywords": [
                "Secure Prediction Systems",
                "Cryptographic Protocols",
                "Privacy Preservation",
                "Neural Network Inference",
                "Performance-Accuracy Trade-offs"
            ]
        },
        "url": "URL#2332687"
    },
    {
        "@score": "1",
        "@id": "2332688",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "241/6242",
                        "text": "Daniel Moghimi"
                    },
                    {
                        "@pid": "167/1573",
                        "text": "Jo Van Bulck"
                    },
                    {
                        "@pid": "12/3207",
                        "text": "Nadia Heninger"
                    },
                    {
                        "@pid": "85/6647",
                        "text": "Frank Piessens"
                    },
                    {
                        "@pid": "91/465",
                        "text": "Berk Sunar"
                    }
                ]
            },
            "title": "CopyCat: Controlled Instruction-Level Attacks on Enclaves.",
            "venue": "USENIX Security Symposium",
            "pages": "469-486",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MoghimiBHPS20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/moghimi-copycat",
            "url": "https://dblp.org/rec/conf/uss/MoghimiBHPS20",
            "abstract": "The adversarial model presented by trusted execution environments (TEEs) has prompted researchers to investigate unusual attack vectors. One particularly powerful class of controlled-channel attacks abuses page-table modifications to reliably track enclave memory accesses at a page-level granularity. In contrast to noisy microarchitectural timing leakage, this line of deterministic controlled-channel attacks abuses indispensable architectural interfaces and hence cannot be mitigated by tweaking microarchitectural resources. We propose an innovative controlled-channel attack, named CopyCat, that deterministically counts the number of instructions executed within a single enclave code page. We show that combining the instruction counts harvested by CopyCat with traditional, coarse-grained page-level leakage allows the accurate reconstruction of enclave control flow at a maximal instruction-level granularity. CopyCat can identify intra-page and intra-cache line branch decisions that ultimately may only differ in a single instruction, underscoring that even extremely subtle control flow deviations can be deterministically leaked from secure enclaves. We demonstrate the improved resolution and practicality of CopyCat on Intel SGX in an extensive study of single-trace and deterministic attacks against cryptographic implementations, and give novel algorithmic attacks to perform single-trace key extraction that exploit subtle vulnerabilities in the latest versions of widely-used cryptographic libraries. Our findings highlight the importance of stricter verification of cryptographic implementations, especially in the context of TEEs.",
            "pdf_url": "",
            "keywords": [
                "Trusted Execution Environments",
                "Controlled-Channel Attacks",
                "Intel SGX",
                "Enclave Memory Access",
                "Cryptographic Implementation Vulnerabilities"
            ]
        },
        "url": "URL#2332688"
    },
    {
        "@score": "1",
        "@id": "2332689",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "241/6242",
                        "text": "Daniel Moghimi"
                    },
                    {
                        "@pid": "172/1127",
                        "text": "Moritz Lipp"
                    },
                    {
                        "@pid": "91/465",
                        "text": "Berk Sunar"
                    },
                    {
                        "@pid": "08/1117-1",
                        "text": "Michael Schwarz 0001"
                    }
                ]
            },
            "title": "Medusa: Microarchitectural Data Leakage via Automated Attack Synthesis.",
            "venue": "USENIX Security Symposium",
            "pages": "1427-1444",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MoghimiLS020",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/moghimi-medusa",
            "url": "https://dblp.org/rec/conf/uss/MoghimiLS020",
            "abstract": "In May 2019, a new class of transient execution attack based on Meltdown called microarchitectural data sampling (MDS), was disclosed. MDS enables adversaries to leak secrets across security domains by collecting data from shared CPU resources such as data cache, \ufb01ll buffers, and store buffers. These resources may temporarily hold data that belongs to other processes and privileged contexts, which could falsely be forwarded to memory accesses of an adversary. We perform an in-depth analysis of these Meltdown-style attacks using our novel fuzzing-based approach. We introduce an analysis tool, named Transynther, which mutates the basic block of existing Meltdown variants to generate and evaluate new Meltdown subvariants. We apply Transynther to analyze modern CPUs and better understand the root cause of these attacks. As a result, we \ufb01nd new variants of MDS that only target speci\ufb01c memory operations, e.g., fast string copies. Based on our \ufb01ndings, we propose a new attack, named Medusa, which can leak data from implicit write-combining memory operations. Since Medusa only applies to speci\ufb01c operations, it can be used to pinpoint vulnerable targets. In a case study, we apply Medusa to recover the key during the RSA signing operation. We show that Medusa can leak various parts of an RSA key during the base64 decoding stage. Then we build leakage templates and recover full RSA keys by employing lattice-based cryptanalysis techniques.",
            "keywords": [
                "Microarchitectural Data Leakage",
                "Transient Execution Attacks",
                "Meltdown Variants",
                "Data Recovery",
                "RSA Key Leakage"
            ]
        },
        "url": "URL#2332689",
        "sema_paperId": "b91d3d2a187501a76143822d9ce1ed24b1360b36"
    },
    {
        "@score": "1",
        "@id": "2332690",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "241/6242",
                        "text": "Daniel Moghimi"
                    },
                    {
                        "@pid": "91/465",
                        "text": "Berk Sunar"
                    },
                    {
                        "@pid": "72/817",
                        "text": "Thomas Eisenbarth 0001"
                    },
                    {
                        "@pid": "12/3207",
                        "text": "Nadia Heninger"
                    }
                ]
            },
            "title": "TPM-FAIL: TPM meets Timing and Lattice Attacks.",
            "venue": "USENIX Security Symposium",
            "pages": "2057-2073",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MoghimiS0H20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/moghimi-tpm",
            "url": "https://dblp.org/rec/conf/uss/MoghimiS0H20",
            "abstract": "Trusted Platform Module (TPM) serves as a hardware-based root of trust that protects cryptographic keys from privileged system and physical adversaries. In this work, we perform a black-box timing analysis of TPM 2.0 devices deployed on commodity computers. Our analysis reveals that some of these devices feature secret-dependent execution times during signature generation based on elliptic curves. In particular, we discovered timing leakage on an Intel firmware-based TPM as well as a hardware TPM. We show how this information allows an attacker to apply lattice techniques to recover 256-bit private keys for ECDSA and ECSchnorr signatures. On Intel fTPM, our key recovery succeeds after about 1,300 observations and in less than two minutes. Similarly, we extract the private ECDSA key from a hardware TPM manufactured by STMicroelectronics, which is certified at Common Criteria (CC) EAL 4+, after fewer than 40,000 observations. We further highlight the impact of these vulnerabilities by demonstrating a remote attack against a StrongSwan IPsec VPN that uses a TPM to generate the digital signatures for authentication. In this attack, the remote client recovers the server\u2019s private authentication key by timing only 45,000 authentication handshakes via a network connection.\nThe vulnerabilities we have uncovered emphasize the difficulty of correctly implementing known constant-time techniques, and show the importance of evolutionary testing and transparent evaluation of cryptographic implementations. Even certified devices that claim resistance against attacks require additional scrutiny by the community and industry, as we learn more about these attacks.",
            "pdf_url": "",
            "keywords": [
                "Trusted Platform Module (TPM)",
                "Timing Attacks",
                "Lattice Attacks",
                "Key Recovery",
                "ECDSA Vulnerabilities"
            ]
        },
        "url": "URL#2332690"
    },
    {
        "@score": "1",
        "@id": "2332691",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "201/9230",
                        "text": "Shravan Narayan"
                    },
                    {
                        "@pid": "199/4885",
                        "text": "Craig Disselkoen"
                    },
                    {
                        "@pid": "55/1439",
                        "text": "Tal Garfinkel"
                    },
                    {
                        "@pid": "20/4414",
                        "text": "Nathan Froyd"
                    },
                    {
                        "@pid": "260/1056",
                        "text": "Eric Rahm"
                    },
                    {
                        "@pid": "11/3644",
                        "text": "Sorin Lerner"
                    },
                    {
                        "@pid": "35/1061",
                        "text": "Hovav Shacham"
                    },
                    {
                        "@pid": "91/6118",
                        "text": "Deian Stefan"
                    }
                ]
            },
            "title": "Retrofitting Fine Grain Isolation in the Firefox Renderer.",
            "venue": "USENIX Security Symposium",
            "pages": "699-716",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/NarayanDGFRLSS20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/narayan",
            "url": "https://dblp.org/rec/conf/uss/NarayanDGFRLSS20",
            "abstract": "Firefox and other major browsers rely on dozens of third-party libraries to render audio, video, images, and other content. These libraries are a frequent source of vulnerabilities. To mitigate this threat, we are migrating Firefox to an architecture that isolates these libraries in lightweight sandboxes, dramatically reducing the impact of a compromise.Retrofitting isolation can be labor-intensive, very prone to security bugs, and requires critical attention to performance. To help, we developed RLBox, a framework that minimizes the burden of converting Firefox to securely and efficiently use untrusted code. To enable this, RLBox employs static information flow enforcement, and lightweight dynamic checks, expressed directly in the C++ type system.RLBox supports efficient sandboxing through either software-based-fault isolation or multi-core process isolation. Performance overheads are modest and transient, and have only minor impact on page latency. We demonstrate this by sandboxing performance-sensitive image decoding libraries (libjpeg and libpng), video decoding libraries (libtheora and libvpx), the libvorbis audio decoding library, and the zlib decompression library.RLBox, using a WebAssembly sandbox, has been integrated into production Firefox to sandbox the libGraphite font shaping library.",
            "pdf_url": "",
            "keywords": [
                "Browser Security",
                "Sandboxing",
                "Isolation Framework",
                "Third-Party Library Vulnerabilities",
                "RLBox"
            ]
        },
        "url": "URL#2332691"
    },
    {
        "@score": "1",
        "@id": "2332692",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "192/7560",
                        "text": "Amirreza Niakanlahiji"
                    },
                    {
                        "@pid": "52/5640",
                        "text": "Jinpeng Wei"
                    },
                    {
                        "@pid": "272/3704",
                        "text": "Md Rabbi Alam"
                    },
                    {
                        "@pid": "75/1008-1",
                        "text": "Qingyang Wang 0001"
                    },
                    {
                        "@pid": "48/4335",
                        "text": "Bei-Tseng Chu"
                    }
                ]
            },
            "title": "ShadowMove: A Stealthy Lateral Movement Strategy.",
            "venue": "USENIX Security Symposium",
            "pages": "559-576",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/NiakanlahijiWAW20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/niakanlahiji",
            "url": "https://dblp.org/rec/conf/uss/NiakanlahijiWAW20",
            "abstract": "Advanced Persistence Threat (APT) attacks use various strategies and techniques to move laterally within an enterprise environment; however, the existing strategies and techniques have limitations such as requiring elevated permissions, creating new connections, performing new authentications, or requiring process injections. Based on these characteristics, many host and network-based solutions have been proposed to prevent or detect such lateral movement attempts. In this paper, we present a novel stealthy lateral movement strategy, ShadowMove, in which only established connections between systems in an enterprise network are misused for lateral movements. It has a set of unique features such as requiring no elevated privilege, no new connection, no extra authentication, and no process injection, which makes it stealthy against state-of-the-art detection mechanisms. ShadowMove is enabled by a novel socket duplication approach that allows a malicious process to silently abuse TCP connections established by benign processes. We design and implement ShadowMove for current Windows and Linux operating systems. To validate the feasibility of ShadowMove, we build several prototypes that successfully hijack three kinds of enterprise protocols, FTP, Microsoft SQL, and Window Remote Management, to perform lateral movement actions such as copying malware to the next target machine and launching malware on the target machine. We also confirm that our prototypes cannot be detected by existing host and network-based solutions, such as five top-notch anti-virus products (McAfee, Norton, Webroot, Bitdefender, and Windows Defender), four IDSes (Snort, OSSEC, Osquery, and Wazuh), and two Endpoint Detection and Response systems (CrowdStrike Falcon Prevent and Cisco AMP).",
            "pdf_url": "",
            "keywords": [
                "Lateral Movement",
                "Advanced Persistent Threats",
                "Stealth Techniques",
                "Socket Duplication",
                "Enterprise Protocol Hijacking"
            ]
        },
        "url": "URL#2332692"
    },
    {
        "@score": "1",
        "@id": "2332693",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "272/7242",
                        "text": "Timothy Nosco"
                    },
                    {
                        "@pid": "272/7255",
                        "text": "Jared Ziegler"
                    },
                    {
                        "@pid": "272/7030",
                        "text": "Zechariah Clark"
                    },
                    {
                        "@pid": "272/7192",
                        "text": "Davy Marrero"
                    },
                    {
                        "@pid": "272/7153",
                        "text": "Todd Finkler"
                    },
                    {
                        "@pid": "272/7149",
                        "text": "Andrew Barbarello"
                    },
                    {
                        "@pid": "130/9411",
                        "text": "W. Michael Petullo"
                    }
                ]
            },
            "title": "The Industrial Age of Hacking.",
            "venue": "USENIX Security Symposium",
            "pages": "1129-1146",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/NoscoZCMFBP20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/nosco",
            "url": "https://dblp.org/rec/conf/uss/NoscoZCMFBP20",
            "abstract": "There is a cognitive bias in the hacker community to select a piece of software and invest signi\ufb01cant human resources into \ufb01nding bugs in that software without any prior indication of success. We label this strategy depth-\ufb01rst search andproposeanalternative: breadth-\ufb01rstsearch. Inbreadth-\ufb01rst search, humans perform minimal work to enable automated analysis on a range of targets before committing additional time and effort to research any particular one. We present a repeatable human study that leverages teams of varying skill while using automation to the greatest extent possible. Our goal is a process that is effective at \ufb01nding bugs; has a clear plan for the growth, coaching, and ef\ufb01cient use of team members; and supports measurable, incremental progress. We derive an assembly-line process that improves on what was once intricate, manual work. Our work provides evidence that the breadth-\ufb01rst approach increases the effectiveness of teams.",
            "keywords": [
                "Hacking Strategies",
                "Software Vulnerability Discovery",
                "Depth-First Search",
                "Breadth-First Search",
                "Automated Analysis"
            ]
        },
        "url": "URL#2332693",
        "sema_paperId": "8b9eb636ef82edad03f2612f09c16c25aca8e042"
    },
    {
        "@score": "1",
        "@id": "2332694",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "173/5375",
                        "text": "Ivan De Oliveira Nunes"
                    },
                    {
                        "@pid": "01/4656",
                        "text": "Karim Eldefrawy"
                    },
                    {
                        "@pid": "198/1339",
                        "text": "Norrathep Rattanavipanon"
                    },
                    {
                        "@pid": "08/1183",
                        "text": "Gene Tsudik"
                    }
                ]
            },
            "title": "APEX: A Verified Architecture for Proofs of Execution on Remote Devices under Full Software Compromise.",
            "venue": "USENIX Security Symposium",
            "pages": "771-788",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/NunesERT20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/nunes",
            "url": "https://dblp.org/rec/conf/uss/NunesERT20",
            "abstract": "Modern society is increasingly surrounded by, and is growing accustomed to, a wide range of Cyber-Physical Systems (CPS), Internet-of-Things (IoT), and smart devices. They often perform safety-critical functions, e.g., personal medical devices, automotive CPS as well as industrial and residential automation, e.g., sensor-alarm combinations. On the lower end of the scale, these devices are small, cheap and specialized sensors and/or actuators. They tend to host small anemic CPUs, have small amounts of memory and run simple software. If such devices are left unprotected, consequences of forged sensor readings or ignored actuation commands can be catastrophic, particularly, in safety-critical settings. This prompts the following three questions: (1) How to trust data produced, or verify that commands were performed, by a simple remote embedded device?, (2) How to bind these actions/results to the execution of expected software? and, (3) Can (1) and (2) be attained even if all software on a device can be modified and/or compromised?In this paper we answer these questions by designing, demonstrating security of, and formally verifying, APEX: an Architecture for Provable Execution. To the best of our knowledge, this is the first of its kind result for low-end embedded systems. Our work has a range of applications, especially, authenticated sensing and trustworthy actuation, which are increasingly relevant in the context of safety-critical systems. APEX is publicly available and our evaluation shows that it incurs low overhead, affordable even for very low-end embedded devices, e.g., those based on TI MSP430 or AVR ATmega processors.",
            "pdf_url": "",
            "keywords": [
                "Cyber-Physical Systems",
                "Internet-of-Things",
                "Remote Device Trust",
                "Execution Verification",
                "Software Compromise"
            ]
        },
        "url": "URL#2332694"
    },
    {
        "@score": "1",
        "@id": "2332695",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "247/1242",
                        "text": "Sean Oesch"
                    },
                    {
                        "@pid": "124/2527",
                        "text": "Scott Ruoti"
                    }
                ]
            },
            "title": "That Was Then, This Is Now: A Security Evaluation of Password Generation, Storage, and Autofill in Browser-Based Password Managers.",
            "venue": "USENIX Security Symposium",
            "pages": "2165-2182",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/OeschR20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/oesch",
            "url": "https://dblp.org/rec/conf/uss/OeschR20",
            "abstract": "Password managers have the potential to help users more effectively manage their passwords and address many of the concerns surrounding password-based authentication, however prior research has identified significant vulnerabilities in existing password managers. Since that time, five years has passed, leaving it unclear whether password managers remain vulnerable or whether they are now ready for broad adoption. To answer this question, we evaluate thirteen popular password managers and consider all three stages of the password manager lifecycle--password generation, storage, and autofill. Our evaluation is the first analysis of password generation in password managers, finding several non-random character distributions and identifying instances where generated passwords were vulnerable to online and offline guessing attacks. For password storage and autofill, we replicate past evaluations, demonstrating that while password managers have improved in the half-decade since those prior evaluations, there are still significant issues, particularly with browser-based password managers; these problems include unencrypted metadata, unsafe defaults, and vulnerabilities to clickjacking attacks. Based on our results, we identify password managers to avoid, provide recommendations on how to improve existing password managers, and identify areas of future research.",
            "keywords": [
                "Password Managers",
                "Password Generation",
                "Password Storage",
                "Autofill Vulnerabilities",
                "Security Evaluation"
            ]
        },
        "url": "URL#2332695",
        "sema_paperId": "3c1f54eea4f1f6ab4962e77f5079cbe02639d581"
    },
    {
        "@score": "1",
        "@id": "2332696",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "72/10989",
                        "text": "Adam Oest"
                    },
                    {
                        "@pid": "183/8531",
                        "text": "Yeganeh Safaei"
                    },
                    {
                        "@pid": "143/1850",
                        "text": "Penghui Zhang"
                    },
                    {
                        "@pid": "91/8856",
                        "text": "Brad Wardman"
                    },
                    {
                        "@pid": "249/2935",
                        "text": "Kevin Tyers"
                    },
                    {
                        "@pid": "119/7712",
                        "text": "Yan Shoshitaishvili"
                    },
                    {
                        "@pid": "28/8280",
                        "text": "Adam Doup\u00e9"
                    }
                ]
            },
            "title": "PhishTime: Continuous Longitudinal Measurement of the Effectiveness of Anti-phishing Blacklists.",
            "venue": "USENIX Security Symposium",
            "pages": "379-396",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/OestSZWTSD20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/oest-phishtime",
            "url": "https://dblp.org/rec/conf/uss/OestSZWTSD20",
            "abstract": "Due to their ubiquity in modern web browsers, antiphishing blacklists are a key defense against large-scale phishing attacks. However, sophistication in phishing websites\u2014such as evasion techniques that seek to defeat these blacklists\u2014continues to grow. Yet, the e ectiveness of blacklists against evasive websites is di cult to measure, and there have been no methodical e orts to make and track such measurements, at the ecosystem level, over time. We propose a framework for continuously identifying unmitigated phishing websites in the wild, replicating key aspects of theircon guration in a controlledsetting,andgenerating longitudinal experiments to measure the ecosystem\u2019s protection. In six experiment deployments over nine months, we systematically launchandreport2,862 new (innocuous) phishing websites to evaluate the performance (speed and coverage) and consistency of blacklists, with the goal of improving them. We show that methodical long-term empirical measurements are an e ective strategy for proactively detecting weaknesses in the anti-phishing ecosystem. Through our experiments, we identify and disclose several such weaknesses, including a class of behavior-based JavaScript evasion that blacklists were unable to detect. We nd that enhanced protections on mobile devices and the expansion of evidence-based reporting protocols are critical ecosystem improvements that could better protect users against modern phishing attacks, which routinely seek to evade detection infrastructure.",
            "keywords": [
                "Anti-phishing Blacklists",
                "Phishing Detection",
                "Evasion Techniques",
                "Longitudinal Measurement",
                "JavaScript Evasion"
            ]
        },
        "url": "URL#2332696",
        "sema_paperId": "c10acb7113cc63373507cd9136880609c42dccae"
    },
    {
        "@score": "1",
        "@id": "2332697",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "72/10989",
                        "text": "Adam Oest"
                    },
                    {
                        "@pid": "143/1850",
                        "text": "Penghui Zhang"
                    },
                    {
                        "@pid": "91/8856",
                        "text": "Brad Wardman"
                    },
                    {
                        "@pid": "166/1207",
                        "text": "Eric Nunes"
                    },
                    {
                        "@pid": "272/7237",
                        "text": "Jakub Burgis"
                    },
                    {
                        "@pid": "49/10638",
                        "text": "Ali Zand"
                    },
                    {
                        "@pid": "68/8283",
                        "text": "Kurt Thomas"
                    },
                    {
                        "@pid": "28/8280",
                        "text": "Adam Doup\u00e9"
                    },
                    {
                        "@pid": "a/GailJoonAhn",
                        "text": "Gail-Joon Ahn"
                    }
                ]
            },
            "title": "Sunrise to Sunset: Analyzing the End-to-end Life Cycle and Effectiveness of Phishing Attacks at Scale.",
            "venue": "USENIX Security Symposium",
            "pages": "361-377",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/OestZWNBZTDA20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/oest-sunrise",
            "url": "https://dblp.org/rec/conf/uss/OestZWNBZTDA20",
            "abstract": "Despite an extensive anti-phishing ecosystem, phishing attacks continue to capitalize on gaps in detection to reach a significant volume of daily victims. In this paper, we isolate and identify these detection gaps by measuring the end-to-end life cycle of large-scale phishing attacks. We develop a unique framework\u2014 Golden Hour \u2014that allows us to passively measure victim traffic to phishing pages while proactively protectingtensofthousandsofaccountsintheprocess. Overa one yearperiod,ournetworkmonitorrecorded4.8 million victims who visitedphishing pages,excluding crawlertraffic. We use these events and related data sources to dissect phishing campaigns: from the time they first come online, to email distribution, to visitor traffic, to ecosystem detection, and finally to account compromise. We find the average campaign from startto the lastvictim takes just21 hours. Atleast7.42% ofvisi-tors supply their credentials and ultimately experience a compromise and subsequent fraudulent transaction. Furthermore, a smallcollection ofhighlysuccessfulcampaigns are responsible for 89.13% of victims. Based on our findings, we outline potential opportunities to respond to these sophisticated attacks.",
            "keywords": [
                "Phishing Attacks",
                "Detection Gaps",
                "Victim Traffic Analysis",
                "Campaign Effectiveness",
                "Account Compromise"
            ]
        },
        "url": "URL#2332697",
        "sema_paperId": "ad9cd1b746bfd1248720efd58442a3803e94d158"
    },
    {
        "@score": "1",
        "@id": "2332698",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "166/4142",
                        "text": "Oleksii Oleksenko"
                    },
                    {
                        "@pid": "189/0114",
                        "text": "Bohdan Trach"
                    },
                    {
                        "@pid": "94/2996",
                        "text": "Mark Silberstein"
                    },
                    {
                        "@pid": "f/ChristofFetzer",
                        "text": "Christof Fetzer"
                    }
                ]
            },
            "title": "SpecFuzz: Bringing Spectre-type vulnerabilities to the surface.",
            "venue": "USENIX Security Symposium",
            "pages": "1481-1498",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/OleksenkoTSF20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/oleksenko",
            "url": "https://dblp.org/rec/conf/uss/OleksenkoTSF20",
            "abstract": "SpecFuzz is the first tool that enables dynamic testing for speculative execution vulnerabilities (e.g., Spectre). The key is a novel concept of speculation exposure: The program is instrumented to simulate speculative execution in software by forcefully executing the code paths that could be triggered due to mispredictions, thereby making the speculative memory accesses visible to integrity checkers (e.g., AddressSanitizer). Combined with the conventional fuzzing techniques, speculation exposure enables more precise identification of potential vulnerabilities compared to state-of-the-art static analyzers.\nOur prototype for detecting Spectre V1 vulnerabilities successfully identifies all known variations of Spectre V1 and decreases the mitigation overheads across the evaluated applications, reducing the amount of instrumented branches by up to 77% given a sufficient test coverage.",
            "pdf_url": "",
            "keywords": [
                "Speculative Execution",
                "Spectre Vulnerabilities",
                "Dynamic Testing",
                "Speculation Exposure",
                "Fuzzing Techniques"
            ]
        },
        "url": "URL#2332698"
    },
    {
        "@score": "1",
        "@id": "2332699",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "238/5438",
                        "text": "Sebastian \u00d6sterlund"
                    },
                    {
                        "@pid": "121/2685",
                        "text": "Kaveh Razavi"
                    },
                    {
                        "@pid": "91/800",
                        "text": "Herbert Bos"
                    },
                    {
                        "@pid": "75/8194",
                        "text": "Cristiano Giuffrida"
                    }
                ]
            },
            "title": "ParmeSan: Sanitizer-guided Greybox Fuzzing.",
            "venue": "USENIX Security Symposium",
            "pages": "2289-2306",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/OsterlundRBG20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/osterlund",
            "url": "https://dblp.org/rec/conf/uss/OsterlundRBG20",
            "abstract": "One of the key questions when fuzzing is where to look for vulnerabilities. Coverage-guided fuzzers indiscriminately optimize for covering as much code as possible given that bug coverage often correlates with code coverage. Since code coverage overapproximates bug coverage, this approach is less than ideal and may lead to non-trivial time-to-exposure (TTE) of bugs. Directed fuzzers try to address this problem by directing the fuzzer to a basic block with a potential vulnerability. This approach can greatly reduce the TTE for a specific bug, but such special-purpose fuzzers can then greatly underapproximate overall bug coverage.\nIn this paper, we present sanitizer-guided fuzzing, a new design point in this space that specifically optimizes for bug coverage. For this purpose, we make the key observation that while the instrumentation performed by existing software sanitizers are regularly used for detecting fuzzer-induced error conditions, they can further serve as a generic and effective mechanism to identify interesting basic blocks for guiding fuzzers. We present the design and implementation of ParmeSan, a new sanitizer-guided fuzzer that builds on this observation. We show that ParmeSan greatly reduces the TTE of real-world bugs, and finds bugs 37% faster than existing state-of-the-art coverage-based fuzzers (Angora) and 288% faster than directed fuzzers (AFLGo), while still covering the same set of bugs.",
            "pdf_url": "",
            "keywords": [
                "Fuzzing",
                "Software Vulnerabilities",
                "Sanitizer-guided Fuzzing",
                "Time-to-Exposure (TTE)",
                "Bug Coverage"
            ]
        },
        "url": "URL#2332699"
    },
    {
        "@score": "1",
        "@id": "2332700",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "200/3122",
                        "text": "Alex Ozdemir"
                    },
                    {
                        "@pid": "150/9448",
                        "text": "Riad S. Wahby"
                    },
                    {
                        "@pid": "272/7096",
                        "text": "Barry Whitehat"
                    },
                    {
                        "@pid": "b/DanBoneh",
                        "text": "Dan Boneh"
                    }
                ]
            },
            "title": "Scaling Verifiable Computation Using Efficient Set Accumulators.",
            "venue": "USENIX Security Symposium",
            "pages": "2075-2092",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/OzdemirWWB20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/ozdemir",
            "url": "https://dblp.org/rec/conf/uss/OzdemirWWB20",
            "abstract": "Verifiable outsourcing systems offload a large computation to a remote server, but require that the remote server provide a succinct proof, called a SNARK, that proves that the server carried out the computation correctly. Real-world applications of this approach can be found in several blockchain systems that employ verifiable outsourcing to process a large number of transactions off-chain. This reduces the on-chain work to simply verifying a succinct proof that transaction processing was done correctly. In practice, verifiable outsourcing of state updates is done by updating the leaves of a Merkle tree, recomputing the resulting Merkle root, and proving using a SNARK that the state update was done correctly.In this work, we use a combination of existing and novel techniques to implement an RSA accumulator inside of a SNARK, and use it as a replacement for a Merkle tree. We specifically optimize the accumulator for compatibility with SNARKs. Our experiments show that the resulting system can dramatically reduce costs compared to existing approaches that use Merkle trees for committing to the current state. These results apply broadly to any system that needs to offload batches of state updates to a remote untrusted server.",
            "pdf_url": "",
            "keywords": [
                "Verifiable Computation",
                "SNARKs",
                "RSA Accumulator",
                "Merkle Trees",
                "State Updates"
            ]
        },
        "url": "URL#2332700"
    },
    {
        "@score": "1",
        "@id": "2332701",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "71/7816",
                        "text": "Xudong Pan"
                    },
                    {
                        "@pid": "84/2519-1",
                        "text": "Mi Zhang 0001"
                    },
                    {
                        "@pid": "217/4508",
                        "text": "Duocai Wu"
                    },
                    {
                        "@pid": "272/7143",
                        "text": "Qifan Xiao"
                    },
                    {
                        "@pid": "07/8388",
                        "text": "Shouling Ji"
                    },
                    {
                        "@pid": "02/1640-2",
                        "text": "Min Yang 0002"
                    }
                ]
            },
            "title": "Justinian&apos;s GAAvernor: Robust Distributed Learning with Gradient Aggregation Agent.",
            "venue": "USENIX Security Symposium",
            "pages": "1641-1658",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PanZWXJY20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/pan",
            "url": "https://dblp.org/rec/conf/uss/PanZWXJY20",
            "abstract": "The hidden vulnerability of distributed learning systems against Byzantine attacks has been investigated by recent researches and, fortunately, some known defenses showed the ability to mitigate Byzantine attacks when a minority of workers are under adversarial control. Yet, our community still has very little knowledge on how to handle the situations when the proportion of malicious workers is 50% or more. Based on our preliminary study of this open challenge, we \ufb01nd there is more that can be done to restore Byzantine robustness in these more threatening situations, if we better utilize the auxiliary information inside the learning process. In this paper, we propose Justinian\u2019s GAAvernor (GAA), a Gradient Aggregation Agent which learns to be robust against Byzantine attacks via reinforcement learning techniques. Ba-sically, GAA relies on utilizing the historical interactions with the workers as experience and a quasi-validation set , a small dataset that consists of less than 10 data samples from similar data domains, to generate reward signals for policy learning. As a complement to existing defenses, our proposed approach does not bound the expected number of malicious workers and is proved to be robust in more challenging scenarios. Through extensive evaluations on four benchmark systems and against various adversarial settings, our proposed defense shows desirable robustness as if the systems were under no attacks, even in some case when 90% Byzantine workers are controlled by the adversary. Meanwhile, our approach shows a similar level of time ef\ufb01ciency compared with the state-of-the-art defenses. Moreover, GAA provides highly interpretable traces of worker behavior as by-products for further mitigation usages like Byzantine worker detection and behavior pattern analysis.",
            "keywords": [
                "Distributed Learning",
                "Byzantine Attacks",
                "Gradient Aggregation",
                "Reinforcement Learning",
                "Robustness Against Malicious Workers"
            ]
        },
        "url": "URL#2332701",
        "sema_paperId": "403a5f7e0d63a9e4719023fc78fe00ccb580e7bb"
    },
    {
        "@score": "1",
        "@id": "2332703",
        "info": {
            "authors": {
                "author": {
                    "@pid": "134/7518",
                    "text": "Arnis Parsovs"
                }
            },
            "title": "Estonian Electronic Identity Card: Security Flaws in Key Management.",
            "venue": "USENIX Security Symposium",
            "pages": "1785-1802",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Parsovs20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/parsovs",
            "url": "https://dblp.org/rec/conf/uss/Parsovs20",
            "abstract": "The Estonian electronic identity card (ID card) is considered to be one of the most successful deployments of smart cardbased national ID card systems in the world. The publickey cryptography and private keys stored on the card enable Estonian ID card holders to access e-services, give legally binding digital signatures and even cast an i-vote in national elections. In this paper, we describe several security flaws found in the ID card manufacturing process. The flaws have been discovered by analyzing public-key certificates that have been collected from the public ID card certificate repository. In particular, we find that in some cases, contrary to the security requirements, the ID card manufacturer has generated private keys outside the chip. In several cases, copies of the same private key have been imported in the ID cards of different cardholders, allowing them to impersonate each other. In addition, as a result of a separate flaw in the manufacturing process, corrupted RSA public key moduli have been included in the certificates, which in one case led to the full recovery of the corresponding private key. This paper describes the discovery process of these findings and the incident response taken by the authorities.",
            "keywords": [
                "Electronic Identity Card",
                "Public-Key Cryptography",
                "Key Management Flaws",
                "RSA Public Key Corruption",
                "Impersonation Vulnerabilities"
            ]
        },
        "url": "URL#2332703",
        "sema_paperId": "cf4a24a6adae0c4c92260c1f1ffccbf590f5cb3e"
    },
    {
        "@score": "1",
        "@id": "2332704",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "79/433",
                        "text": "Hui Peng"
                    },
                    {
                        "@pid": "31/1273",
                        "text": "Mathias Payer"
                    }
                ]
            },
            "title": "USBFuzz: A Framework for Fuzzing USB Drivers by Device Emulation.",
            "venue": "USENIX Security Symposium",
            "pages": "2559-2575",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PengP20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/peng",
            "url": "https://dblp.org/rec/conf/uss/PengP20",
            "abstract": "The Universal Serial Bus (USB) connects external devices to a host. This interface exposes the OS kernels and device drivers to attacks by malicious devices. Unfortunately, kernels and drivers were developed under a security model that implicitly trusts connected devices. Drivers expect faulty hardware but not malicious attacks. Similarly, security testing drivers is challenging as input must cross the hardware/software barrier. Fuzzing, the most widely used bug finding technique, relies on providing random data to programs. However, fuzzing device drivers is challenging due to the difficulty in crossing the hardware/software barrier and providing random device data to the driver under test. We present USBFuzz, a portable, flexible, and modular framework for fuzz testing USB drivers. At its core, USBFuzz uses a software-emulated USB device to provide random device data to drivers (when they perform IO operations). As the emulated USB device works at the device level, porting it to other platforms is straight-forward. Using the USBFuzz framework, we apply (i) coverage-guided fuzzing to a broad range of USB drivers in the Linux kernel; (ii) dumb fuzzing in FreeBSD, MacOS, and Windows through cross-pollination seeded by the Linux inputs; and (iii) focused fuzzing of a USB webcam driver. USBFuzz discovered a total of 26 new bugs, including 16 memory bugs of high security impact in various Linux subsystems (USB core, USB sound, and network), one bug in FreeBSD, three in MacOS (two resulting in an unplanned reboot and one freezing the system), and four in Windows 8 and Windows 10 (resulting in Blue Screens of Death), and one bug in the Linux USB host controller driver and another one in a USB camera driver. From the Linux bugs, we have fixed and upstreamed 11 bugs and received 10 CVEs.",
            "keywords": [
                "USB Driver Fuzzing",
                "Device Emulation",
                "Security Testing",
                "Memory Bugs",
                "Cross-Platform Vulnerabilities"
            ]
        },
        "url": "URL#2332704",
        "sema_paperId": "60cd7e38d9a4cfdae9b7efce3308d90593a7f577"
    },
    {
        "@score": "1",
        "@id": "2332705",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "39/10311",
                        "text": "Rishabh Poddar"
                    },
                    {
                        "@pid": "08/5351",
                        "text": "Ganesh Ananthanarayanan"
                    },
                    {
                        "@pid": "68/8463",
                        "text": "Srinath T. V. Setty"
                    },
                    {
                        "@pid": "77/11029",
                        "text": "Stavros Volos"
                    },
                    {
                        "@pid": "91/275",
                        "text": "Raluca Ada Popa"
                    }
                ]
            },
            "title": "Visor: Privacy-Preserving Video Analytics as a Cloud Service.",
            "venue": "USENIX Security Symposium",
            "pages": "1039-1056",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PoddarASVP20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/poddar",
            "url": "https://dblp.org/rec/conf/uss/PoddarASVP20",
            "abstract": "Video-analytics-as-a-service is becoming an important offering for cloud providers. A key concern in such services is privacy of the videos being analyzed. While trusted execution environments (TEEs) are promising options for preventing the direct leakage of private video content, they remain vulnerable to side-channel attacks. \nWe present Visor, a system that provides confidentiality for the user's video stream as well as the ML models in the presence of a compromised cloud platform and untrusted co-tenants. Visor executes video pipelines in a hybrid TEE that spans both the CPU and GPU. It protects the pipeline against side-channel attacks induced by data-dependent access patterns of video modules, and also addresses leakage in the CPU-GPU communication channel. Visor is up to $1000\\times$ faster than naive oblivious solutions, and its overheads relative to a non-oblivious baseline are limited to $2\\times$--$6\\times$.",
            "keywords": [
                "Video Analytics",
                "Privacy Preservation",
                "Trusted Execution Environments",
                "Side-Channel Attacks",
                "Cloud Service Security"
            ]
        },
        "url": "URL#2332705",
        "sema_paperId": "8b7a41ddbf4da230af1517e1fa6bbb683221c68e"
    },
    {
        "@score": "1",
        "@id": "2332706",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "123/5395",
                        "text": "Sebastian Poeplau"
                    },
                    {
                        "@pid": "88/3343",
                        "text": "Aur\u00e9lien Francillon"
                    }
                ]
            },
            "title": "Symbolic execution with SymCC: Don&apos;t interpret, compile!",
            "venue": "USENIX Security Symposium",
            "pages": "181-198",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PoeplauF20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/poeplau",
            "url": "https://dblp.org/rec/conf/uss/PoeplauF20",
            "abstract": "A major impediment to practical symbolic execution is speed, especially when compared to near-native speed solutions like fuzz testing. We propose a compilation-based approach to symbolic execution that performs better than state-of-the-art implementations by orders of magnitude. We present S YM CC, an LLVM-based C and C++ compiler that builds concolic execution right into the binary. It can be used by software developers as a drop-in replacement for clang and clang++ , and we show how to add support for other languages with little effort. In comparison with KLEE, S YM CC is faster by up to three orders of magnitude and an average factor of 12. It also outperforms QSYM, a system that recently showed great performance improvements over other implementations, by up to two orders of magnitude and an average factor of 10. Using it on real-world software, we found that our approach consistently achieves higher coverage, and we discovered two vulnerabilities in the heavily tested OpenJPEG project, which have been con\ufb01rmed by the project maintainers and assigned CVE identi\ufb01ers.",
            "keywords": [
                "Symbolic Execution",
                "Concolic Execution",
                "LLVM Compiler",
                "Performance Improvement",
                "Vulnerability Discovery"
            ]
        },
        "url": "URL#2332706",
        "sema_paperId": "b21b444ec5daeebf5af16f9b88a812e98a9f1284"
    },
    {
        "@score": "1",
        "@id": "2332707",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "227/9091",
                        "text": "Andrea Possemato"
                    },
                    {
                        "@pid": "11/10929",
                        "text": "Yanick Fratantonio"
                    }
                ]
            },
            "title": "Towards HTTPS Everywhere on Android: We Are Not There Yet.",
            "venue": "USENIX Security Symposium",
            "pages": "343-360",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PossematoF20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/possemato",
            "url": "https://dblp.org/rec/conf/uss/PossematoF20",
            "abstract": "Nowadays, virtually all mobile apps rely on communicating with a network backend. Given the sensitive nature of the data exchanged between apps and their backends, securing these network communications is of growing importance. In recent years, Google has developed a number of security mechanisms for Android apps, ranging from multiple KeyStores to the recent introduction of the new Network Security Policy, an XML-based con\ufb01guration \ufb01le that allows apps to de\ufb01ne their network security posture. In this paper, we perform the \ufb01rst comprehensive study on these new network defense mechanisms. In particular, we presentthem in detail,we discuss the attacks they are defending from, and the relevant threat models. We then discuss the \ufb01rst large-scale analysis on this aspect. During June and July 2019, wecrawled125,419applicationsandwefoundhowonly16,332 appsadoptthisnewsecurityfeature.Wethenfocusonthese apps,andweuncoverhowdevelopersadoptweakandpotentially vulnerablenetworksecuritycon\ufb01gurations.Wenotethat,in November2019,Googlethenmadethedefaultpolicystricter, whichwouldhelptheadoption.Wethusoptedtore-crawl thesamedataset(fromApriltoJune2020)andwerepeated theexperiments:whilemoreappsdoadoptthisnewsecurity mechanism,asigni\ufb01cantportionofthemstilldonottakefully advantageofit(e.g.,byallowingusageofinsecureprotocols). We then set out to explore the root cause of these weaknesses (i.e., the why ). Our analysis showed that app developers often copy-paste vulnerable policies from popular developer websites (e.g., StackOver\ufb02ow). We also found that several popular ad libraries require apps to weaken their security policy, the key problem lying in the vast complexity of the ad ecosystem. As a last contribution, we propose a new extension of the Network Security Policy, so to allow app developers to embed problematic ad libraries without the need to weaken the security of their entire app.",
            "keywords": [
                "Android Network Security",
                "HTTPS Adoption",
                "Network Security Policy",
                "Vulnerable Configurations",
                "Ad Library Complexity"
            ]
        },
        "url": "URL#2332707",
        "sema_paperId": "71940433a07e78e4957aab480d68babd4561ee8a"
    },
    {
        "@score": "1",
        "@id": "2332708",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "252/6374",
                        "text": "Sathvik Prasad"
                    },
                    {
                        "@pid": "344/8676",
                        "text": "Elijah Robert Bouma-Sims"
                    },
                    {
                        "@pid": "272/7235",
                        "text": "Athishay Kiran Mylappan"
                    },
                    {
                        "@pid": "117/3983",
                        "text": "Bradley Reaves"
                    }
                ]
            },
            "title": "Who&apos;s Calling? Characterizing Robocalls through Audio and Metadata Analysis.",
            "venue": "USENIX Security Symposium",
            "pages": "397-414",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PrasadBMR20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/prasad",
            "url": "https://dblp.org/rec/conf/uss/PrasadBMR20",
            "abstract": "Unsolicited calls are one of the most prominent security issues facing individuals today. Despite wide-spread anec-dotal discussion of the problem, many important questions remain unanswered. In this paper, we present the \ufb01rst large-scale, longitudinal analysis of unsolicited calls to a honeypot of up to 66,606 lines over 11 months. From call metadata we characterize the long-term trends of unsolicited calls, develop the \ufb01rst techniques to measure voicemail spam, wangiri attacks, and identify unexplained high-volume call incidences. Additionally, we mechanically answer a subset of the call attempts we receive to cluster related calls into operational campaigns, allowing us to characterize how these campaigns use telephone numbers. Critically, we \ufb01nd no evidence that answering unsolicited calls increases the amount of unsolicited calls received, overturning popular wisdom. We also \ufb01nd that we can reliably isolate individual call campaigns, in the process revealing the extent of two distinct Social Security scams while empirically demonstrating the majority of campaigns rarely reuse phone numbers. These analyses comprise powerful new tools and perspectives for researchers, investigators, and a beleaguered public.",
            "keywords": [
                "Robocalls",
                "Unsolicited Calls",
                "Voicemail Spam",
                "Call Campaigns",
                "Social Security Scams"
            ]
        },
        "url": "URL#2332708",
        "sema_paperId": "df55d89860a2699d938db85ecb98f787d0a1d329"
    },
    {
        "@score": "1",
        "@id": "2332709",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "207/0871",
                        "text": "Raul Quinonez"
                    },
                    {
                        "@pid": "47/10540",
                        "text": "Jairo Giraldo"
                    },
                    {
                        "@pid": "252/6396",
                        "text": "Luis E. Salazar"
                    },
                    {
                        "@pid": "160/9772",
                        "text": "Erick Bauman"
                    },
                    {
                        "@pid": "48/6119",
                        "text": "Alvaro A. C\u00e1rdenas"
                    },
                    {
                        "@pid": "49/4102",
                        "text": "Zhiqiang Lin"
                    }
                ]
            },
            "title": "SAVIOR: Securing Autonomous Vehicles with Robust Physical Invariants.",
            "venue": "USENIX Security Symposium",
            "pages": "895-912",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/QuinonezGSBCL20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/quinonez",
            "url": "https://dblp.org/rec/conf/uss/QuinonezGSBCL20",
            "abstract": "Autonomous Vehicles (AVs), including aerial, sea, and ground vehicles, assess their environment with a variety of sensors and actuators that allow them to perform speci \ufb01 c tasks such as navigating a route, hovering, or avoiding collisions. So far, AVs tend to trust the information provided by their sensors to make navigation decisions without data validation or veri \ufb01 cation, and therefore, attackers can exploit these limitations by feeding erroneous sensor data with the intention of disrupting or taking control of the system. In this paper we introduce SAVIOR: an architecture for securing autonomous vehicles with robust physical invariants. We implement and validate our proposal on two popular open-source controllers for aerial and ground vehicles, and demonstrate its effectiveness.",
            "keywords": [
                "Autonomous Vehicles",
                "Sensor Data Validation",
                "Robust Physical Invariants",
                "Security Architecture",
                "Data Integrity"
            ]
        },
        "url": "URL#2332709",
        "sema_paperId": "b65254172f3b980a613a5b33704c0cba467faff6"
    },
    {
        "@score": "1",
        "@id": "2332710",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "149/3695",
                        "text": "Erwin Quiring"
                    },
                    {
                        "@pid": "78/854-1",
                        "text": "David Klein 0001"
                    },
                    {
                        "@pid": "119/8218",
                        "text": "Daniel Arp"
                    },
                    {
                        "@pid": "82/359",
                        "text": "Martin Johns"
                    },
                    {
                        "@pid": "64/4020",
                        "text": "Konrad Rieck"
                    }
                ]
            },
            "title": "Adversarial Preprocessing: Understanding and Preventing Image-Scaling Attacks in Machine Learning.",
            "venue": "USENIX Security Symposium",
            "pages": "1363-1380",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/QuiringKAJR20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/quiring",
            "url": "https://dblp.org/rec/conf/uss/QuiringKAJR20",
            "abstract": "Machine learning has made remarkable progress in the last years, yet its success has been overshadowed by different attacks that can thwart its correct operation. While a large body of research has studied attacks against learning algorithms, vulnerabilities in the preprocessing for machine learning have received little attention so far. An exception is the recent work of Xiao et al. that proposes attacks against image scaling. In contrast to prior work, these attacks are agnostic to the learning algorithm and thus impact the majority of learning-based approaches in computer vision. The mechanisms underlying the attacks, however, are not understood yet, and hence their root cause remains unknown. In this paper, we provide the first in-depth analysis of image-scaling attacks. We theoretically analyze the attacks from the perspective of signal processing and identify their root cause as the interplay of downsampling and convolution. Based on this finding, we investigate three popular imaging libraries for machine learning (OpenCV, TensorFlow, and Pillow) and confirm the presence of this interplay in different scaling algorithms. As a remedy, we develop a novel defense against image-scaling attacks that prevents all possible attack variants. We empirically demonstrate the efficacy of this defense against non-adaptive and adaptive adversaries.",
            "keywords": [
                "Image Scaling Attacks",
                "Adversarial Preprocessing",
                "Signal Processing Vulnerabilities",
                "Convolution Interplay",
                "Defense Mechanism"
            ]
        },
        "url": "URL#2332710",
        "sema_paperId": "2b9514be4679f68f97bbcf9671053ac2f03df2e4"
    },
    {
        "@score": "1",
        "@id": "2332711",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "141/9244",
                        "text": "Elissa M. Redmiles"
                    },
                    {
                        "@pid": "239/0184",
                        "text": "Noel Warford"
                    },
                    {
                        "@pid": "272/7072",
                        "text": "Amritha Jayanti"
                    },
                    {
                        "@pid": "272/7203",
                        "text": "Aravind Koneru"
                    },
                    {
                        "@pid": "159/0234",
                        "text": "Sean Kross"
                    },
                    {
                        "@pid": "186/4928",
                        "text": "Miraida Morales"
                    },
                    {
                        "@pid": "79/512",
                        "text": "Rock Stevens"
                    },
                    {
                        "@pid": "20/7983",
                        "text": "Michelle L. Mazurek"
                    }
                ]
            },
            "title": "A Comprehensive Quality Evaluation of Security and Privacy Advice on the Web.",
            "venue": "USENIX Security Symposium",
            "pages": "89-108",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RedmilesWJKKMSM20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/redmiles",
            "url": "https://dblp.org/rec/conf/uss/RedmilesWJKKMSM20",
            "abstract": "End users learn defensive security behaviors from a variety of channels, including a plethora of security advice given in on-line articles. A great deal of e \ufb00 ort is devoted to getting users to follow this advice. Surprisingly then, little is known about the quality of this advice: Is it comprehensible? Is it actionable? Is it e \ufb00 ective? To answer these questions, we \ufb01rst conduct a large-scale, user-driven measurement study to identify 374 unique recommended behaviors contained within 1,264 documents of online security and privacy advice. Second, we develop and validate measurement approaches for evaluating the quality \u2013 comprehensibility, perceived actionability, and perceived e \ufb03 cacy \u2013 of security advice. Third, we deploy these measurement approaches to evaluate the 374 unique pieces of security advice in a user-study with 1,586 users and 41 professional security experts. Our results suggest a crisis of advice prioritization. The majority of advice is perceived by the most users to be at least somewhat actionable, and somewhat comprehensible. Yet, both users and experts struggle to prioritize this advice. For example, experts perceive 89% of the hundreds of studied behaviors as being e \ufb00 ective, and identify 118 of them as being among the \u201ctop 5\u201d things users should do, leaving end-users on their own to prioritize and take action to protect themselves.",
            "keywords": [
                "Online Security Advice",
                "User Behavior",
                "Advice Quality Evaluation",
                "Comprehensibility and Actionability",
                "Security Awareness"
            ]
        },
        "url": "URL#2332711",
        "sema_paperId": "0a7f47a8937fdb0e18cb61887085d9021695c15d"
    },
    {
        "@score": "1",
        "@id": "2332712",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "272/7155",
                        "text": "Jake Reichel"
                    },
                    {
                        "@pid": "272/7130",
                        "text": "Fleming C. Peck"
                    },
                    {
                        "@pid": "272/7133",
                        "text": "Mikako Inaba"
                    },
                    {
                        "@pid": "272/7039",
                        "text": "Bisrat Moges"
                    },
                    {
                        "@pid": "272/7245",
                        "text": "Brahmnoor Singh Chawla"
                    },
                    {
                        "@pid": "c/MarshiniChetty",
                        "text": "Marshini Chetty"
                    }
                ]
            },
            "title": "&apos;I have too much respect for my elders&apos;: Understanding South African Mobile Users&apos; Perceptions of Privacy and Current Behaviors on Facebook and WhatsApp.",
            "venue": "USENIX Security Symposium",
            "pages": "1949-1966",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ReichelPIMCC20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/reichel",
            "url": "https://dblp.org/rec/conf/uss/ReichelPIMCC20",
            "abstract": "Facebook usage is growing in developing countries, but we know little about how to tailor social media privacy settings to users in less well-resourced settings. To that end, we present findings from interviews of 52 current mobile social media users in South Africa. We found users\u2019 primary privacyrelated concern was who else could see their posts and messages, not what data the platforms or advertisers collect about them. Second, users displayed general knowledge gaps on existing social media privacy settings and relied heavily on blocking and passwords for privacy and security protection. Third, users\u2019 privacy and security-related behaviors were heavily influenced by living in high-crime areas. Based on these findings, we suggest future work to better serve users\u2019 privacy and security needs in less well-resourced settings.",
            "keywords": [
                "Social Media Privacy",
                "Mobile Users",
                "User Perceptions",
                "Privacy Settings",
                "High-Crime Areas"
            ]
        },
        "url": "URL#2332712",
        "sema_paperId": "af308eec2f48b9d0ee358c1c9b27eba2a36bed91"
    },
    {
        "@score": "1",
        "@id": "2332713",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "12/4508",
                        "text": "Joshua Reynolds"
                    },
                    {
                        "@pid": "224/4443",
                        "text": "Nikita Samarin"
                    },
                    {
                        "@pid": "248/1589",
                        "text": "Joseph D. Barnes"
                    },
                    {
                        "@pid": "248/1720",
                        "text": "Taylor Judd"
                    },
                    {
                        "@pid": "34/3008",
                        "text": "Joshua Mason"
                    },
                    {
                        "@pid": "359/0958",
                        "text": "Michael D. Bailey"
                    },
                    {
                        "@pid": "07/1108",
                        "text": "Serge Egelman"
                    }
                ]
            },
            "title": "Empirical Measurement of Systemic 2FA Usability.",
            "venue": "USENIX Security Symposium",
            "pages": "127-143",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ReynoldsSBJMBE20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/reynolds",
            "url": "https://dblp.org/rec/conf/uss/ReynoldsSBJMBE20",
            "abstract": "Two-Factor Authentication (2FA) hardens an organization against user account compromise, but adds an extra step to organizations\u2019 mission-critical tasks. We investigate to what extent quantitative analysis of operational logs of 2FA systems both supports and challenges recent results from user studies and surveys identifying usability challenges in 2FA systems. Using tens of millions of logs and records kept at two public universities, we quantify the at-scale impact on organizations and their employees during a mandatory 2FA implementation. We show the multiplicative effects of device remembrance, fragmented login services, and authentication timeouts on user burden. We find that user burden does not deviate far from other compliance and risk management time requirements already common to large organizations. We investigate the cause of more than one in twenty 2FA ceremonies being aborted or failing, and the variance in user experience across users. We hope our analysis will empower more organizations to protect themselves with 2FA.",
            "keywords": [
                "Two-Factor Authentication",
                "Usability Challenges",
                "User Experience",
                "Operational Logs Analysis",
                "User Burden"
            ]
        },
        "url": "URL#2332713",
        "sema_paperId": "f754c86c7975fe891cc327fc758da1f4f239d690"
    },
    {
        "@score": "1",
        "@id": "2332714",
        "info": {
            "authors": {
                "author": {
                    "@pid": "233/0351",
                    "text": "Avi Rubin"
                }
            },
            "title": "The 2020 Election: Remote Voting, Disinformation, and Audit.",
            "venue": "USENIX Security Symposium",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Rubin20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/panel-voting",
            "url": "https://dblp.org/rec/conf/uss/Rubin20",
            "abstract": "By all accounts, the 2020 election will be historic. Perhaps the most emotionally charged election in the history of the United States is happening in the midst of a global pandemic. Never before has disinformation about the process of voting come directly out of the White House. The results of the election are likely to be challenged, and the legitimacy of the results brought into question. Never has there been more pressure to safeguard the public perception of fairness and integrity, while at the same time COVID19 will stretch the ability of election officials to run a smooth election. Vote by mail will be widely adopted, and there will be pressure to move to remote electronic voting. This panel will address the questions of how to protect the legitimacy of the process. The panelists will share their experiences working with election officials, and we will discuss technologies such as end-to-end voting and risk-limiting audits.",
            "pdf_url": "",
            "keywords": [
                "Remote Voting",
                "Disinformation",
                "Election Integrity",
                "Risk-Limiting Audits",
                "Vote by Mail"
            ]
        },
        "url": "URL#2332714",
        "sema_paperId": "900733a89808781952814e95ac4fc3603c5d8d40"
    },
    {
        "@score": "1",
        "@id": "2332715",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "267/9738",
                        "text": "Jan Ruge"
                    },
                    {
                        "@pid": "155/8567",
                        "text": "Jiska Classen"
                    },
                    {
                        "@pid": "59/4302",
                        "text": "Francesco Gringoli"
                    },
                    {
                        "@pid": "95/1816",
                        "text": "Matthias Hollick"
                    }
                ]
            },
            "title": "Frankenstein: Advanced Wireless Fuzzing to Exploit New Bluetooth Escalation Targets.",
            "venue": "USENIX Security Symposium",
            "pages": "19-36",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RugeCGH20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/ruge",
            "url": "https://dblp.org/rec/conf/uss/RugeCGH20",
            "abstract": "Wireless communication standards and implementations have a troubled history regarding security. Since most implementations and firmwares are closed-source, fuzzing remains one of the main methods to uncover Remote Code Execution (RCE) vulnerabilities in deployed systems. Generic over-the-air fuzzing suffers from several shortcomings, such as constrained speed, limited repeatability, and restricted ability to debug. In this paper, we present Frankenstein, a fuzzing framework based on advanced firmware emulation, which addresses these shortcomings. Frankenstein brings firmware dumps \"back to life\", and provides fuzzed input to the chip's virtual modem. The speed-up of our new fuzzing method is sufficient to maintain interoperability with the attached operating system, hence triggering realistic full-stack behavior. We demonstrate the potential of Frankenstein by finding three zero-click vulnerabilities in the Broadcom and Cypress Bluetooth stack, which is used in most Apple devices, many Samsung smartphones, the Raspberry Pis, and many others.\nGiven RCE on a Bluetooth chip, attackers may escalate their privileges beyond the chip's boundary. We uncover a Wi-Fi/Bluetooth coexistence issue that crashes multiple operating system kernels and a design flaw in the Bluetooth 5.2 specification that allows link key extraction from the host. Turning off Bluetooth will not fully disable the chip, making it hard to defend against RCE attacks. Moreover, when testing our chip-based vulnerabilities on those devices, we find BlueFrag, a chip-independent Android RCE.",
            "pdf_url": "",
            "keywords": [
                "Wireless Communication Security",
                "Bluetooth Vulnerabilities",
                "Firmware Emulation",
                "Remote Code Execution (RCE)",
                "Zero-Click Exploits"
            ]
        },
        "url": "URL#2332715"
    },
    {
        "@score": "1",
        "@id": "2332716",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "77/2192",
                        "text": "David Rupprecht"
                    },
                    {
                        "@pid": "155/5132",
                        "text": "Katharina Kohls"
                    },
                    {
                        "@pid": "h/ThorstenHolz",
                        "text": "Thorsten Holz"
                    },
                    {
                        "@pid": "11/3019",
                        "text": "Christina P\u00f6pper"
                    }
                ]
            },
            "title": "Call Me Maybe: Eavesdropping Encrypted LTE Calls With ReVoLTE.",
            "venue": "USENIX Security Symposium",
            "pages": "73-88",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RupprechtKHP20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/rupprecht",
            "url": "https://dblp.org/rec/conf/uss/RupprechtKHP20",
            "abstract": "Voice over LTE (VoLTE) is a packet-based telephony service seamlessly integrated into the Long Term Evolution (LTE) standard and deployed by most telecommunication providers in practice. Due to this widespread use, successful attacks against VoLTE can affect a large number of users worldwide. In this work, we introduce R E V O LTE, an attack that exploits an LTE implementation \ufb02aw to recover the contents of an encrypted VoLTE call, hence enabling an adversary to eaves-drop on phone calls. R E V O LTE makes use of a predictable keystream reuse on the radio layer that allows an adversary to decrypt a recorded call with minimal resources. Through a series of preliminary as well as real-world experiments, we successfully demonstrate the feasibility of R E V O LTE and analyze various factors that critically in\ufb02uence our attack in commercial networks. For mitigating the R E V O LTE attack, we propose and discuss short-and long-term countermeasures deployable by providers and equipment vendors.",
            "keywords": [
                "Voice over LTE (VoLTE)",
                "Eavesdropping",
                "LTE Implementation Flaw",
                "Encrypted Call Decryption",
                "ReVoLTE Attack"
            ]
        },
        "url": "URL#2332716",
        "sema_paperId": "021429b0d43ffc0f4f13eab0da6d10b5acc4508a"
    },
    {
        "@score": "1",
        "@id": "2332717",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "272/7215",
                        "text": "David Schrammel"
                    },
                    {
                        "@pid": "145/2706",
                        "text": "Samuel Weiser"
                    },
                    {
                        "@pid": "272/7222",
                        "text": "Stefan Steinegger"
                    },
                    {
                        "@pid": "223/9857",
                        "text": "Martin Schwarzl"
                    },
                    {
                        "@pid": "08/1117-1",
                        "text": "Michael Schwarz 0001"
                    },
                    {
                        "@pid": "91/4831",
                        "text": "Stefan Mangard"
                    },
                    {
                        "@pid": "166/1494",
                        "text": "Daniel Gruss"
                    }
                ]
            },
            "title": "Donky: Domain Keys - Efficient In-Process Isolation for RISC-V and x86.",
            "venue": "USENIX Security Symposium",
            "pages": "1677-1694",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SchrammelWSS0MG20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/schrammel",
            "url": "https://dblp.org/rec/conf/uss/SchrammelWSS0MG20",
            "abstract": "Ef\ufb01cient and secure in-process isolation is in great demand, as evidenced in the shift towards JavaScript and the recent re-vival of memory protection keys. Yet, state-of-the-art systems do not offer strong security or struggle with frequent domain crossings and oftentimes intrusive kernel modi\ufb01cations. We propose Donky, an ef\ufb01cient hardware-software co-design for strong in-process isolation based on dynamic memory protection domains. The two components of our design are a secure software framework and a non-intrusive hardware extension. We facilitate domain switches entirely in userspace, thus minimizing switching overhead as well as kernel complexity. We show the versatility of Donky in three realistic use cases, secure V8 sandboxing, software vaults, and untrusted third-party libraries. We provide an open-source implementation on a RISC-V Ariane CPU and an Intel-MPK-based emulation mode for x86. We evaluate the security and performance of our implementation for RISC-V synthesized on an FPGA. We also evaluate the performance on x86 and show why our new design is more secure than Intel MPK. Donky does not impede the runtime of in-domain computation. Cross-domain switches are 16\u2013116x faster than regular process context switches. Fully protecting the mbedTLS cryptographic operations has a 4 % overhead.",
            "keywords": [
                "In-Process Isolation",
                "Dynamic Memory Protection",
                "RISC-V",
                "x86",
                "Domain Switching"
            ]
        },
        "url": "URL#2332717",
        "sema_paperId": "7736448fb9e83719b87453ac0e1508b53425ca96"
    },
    {
        "@score": "1",
        "@id": "2332718",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "272/7031",
                        "text": "Fabian Schwarz"
                    },
                    {
                        "@pid": "08/6024",
                        "text": "Christian Rossow"
                    }
                ]
            },
            "title": "SENG, the SGX-Enforcing Network Gateway: Authorizing Communication from Shielded Clients.",
            "venue": "USENIX Security Symposium",
            "pages": "753-770",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SchwarzR20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/schwarz",
            "url": "https://dblp.org/rec/conf/uss/SchwarzR20",
            "abstract": "Network administrators face a security-critical dilemma. While they want to tightly contain their hosts, they usually have to relax firewall policies to support a large variety of applications. However, liberal policies like this enable data exfiltration by unknown (and untrusted) client applications. An inability to attribute communication accurately and reliably to applications is at the heart of this problem. Firewall policies are restricted to coarse-grained features that are easy to evade and mimic, such as protocols or port numbers. \n \nWe present SENG, a network gateway that enables firewalls to reliably attribute traffic to an application. SENG shields an application in an SGX-tailored LibOS and transparently establishes an attestation-based DTLS channel between the SGX enclave and the central network gateway. Consequently, administrators can perfectly attribute traffic to its originating application, and thereby enforce fine-grained per-application communication policies at a central firewall. Our prototype implementation demonstrates that SENG (i) allows administrators to readily use their favorite firewall to enforce network policies on a certified per-application basis and (ii) prevents local system-level attackers from interfering with the shielded application's communication.",
            "keywords": [
                "Network Security",
                "Application Shielding",
                "Firewall Policy Enforcement",
                "Traffic Attribution",
                "SGX Enclave Communication"
            ]
        },
        "url": "URL#2332718",
        "sema_paperId": "f4c06eb1092a416aa083a639112ad73e4623c4b6"
    },
    {
        "@score": "1",
        "@id": "2332719",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "128/4566",
                        "text": "Hossein Shafagh"
                    },
                    {
                        "@pid": "188/9265",
                        "text": "Lukas Burkhalter"
                    },
                    {
                        "@pid": "68/5579",
                        "text": "Sylvia Ratnasamy"
                    },
                    {
                        "@pid": "122/5664",
                        "text": "Anwar Hithnawi"
                    }
                ]
            },
            "title": "Droplet: Decentralized Authorization and Access Control for Encrypted Data Streams.",
            "venue": "USENIX Security Symposium",
            "pages": "2469-2486",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ShafaghBRH20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/shafagh",
            "url": "https://dblp.org/rec/conf/uss/ShafaghBRH20",
            "abstract": "This paper presents Droplet , a decentralized data access con-trol service. Droplet enables data owners to securely and selectively share their encrypted data while guaranteeing data con\ufb01dentiality in the presence of unauthorized parties and compromised data servers. Droplet\u2019s contribution lies in coupling two key ideas: (i) a cryptographically-enforced access control construction for encrypted data streams which enables users to de\ufb01ne \ufb01ne-grained stream-speci\ufb01c access policies, and (ii) a decentralized authorization service that serves user-de\ufb01ned access policies. In this paper, we present Droplet\u2019s design, the reference implementation of Droplet, and the experimental results of three case-study applications deployed with Droplet: Fitbit activity tracker, Ava health tracker, and ECOviz smart meter dashboard, demonstrating Droplet\u2019s applicability for secure sharing of IoT streams.",
            "keywords": [
                "Decentralized Access Control",
                "Encrypted Data Streams",
                "Data Confidentiality",
                "Authorization Service",
                "IoT Data Sharing"
            ]
        },
        "url": "URL#2332719",
        "sema_paperId": "0785fd5d4dfdc020997f23225d445bf67132be1a"
    },
    {
        "@score": "1",
        "@id": "2332720",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "217/9308",
                        "text": "Shawn Shan"
                    },
                    {
                        "@pid": "259/1518",
                        "text": "Emily Wenger"
                    },
                    {
                        "@pid": "189/5595",
                        "text": "Jiayun Zhang"
                    },
                    {
                        "@pid": "23/4315",
                        "text": "Huiying Li"
                    },
                    {
                        "@pid": "43/4261",
                        "text": "Haitao Zheng 0001"
                    },
                    {
                        "@pid": "z/BenYZhao",
                        "text": "Ben Y. Zhao"
                    }
                ]
            },
            "title": "Fawkes: Protecting Privacy against Unauthorized Deep Learning Models.",
            "venue": "USENIX Security Symposium",
            "pages": "1589-1604",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ShanWZLZZ20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/shan",
            "url": "https://dblp.org/rec/conf/uss/ShanWZLZZ20",
            "abstract": "Today's proliferation of powerful facial recognition systems poses a real threat to personal privacy. As this http URL demonstrated, anyone can canvas the Internet for data and train highly accurate facial recognition models of individuals without their knowledge. We need tools to protect ourselves from potential misuses of unauthorized facial recognition systems. Unfortunately, no practical or effective solutions exist. \nIn this paper, we propose Fawkes, a system that helps individuals inoculate their images against unauthorized facial recognition models. Fawkes achieves this by helping users add imperceptible pixel-level changes (we call them \"cloaks\") to their own photos before releasing them. When used to train facial recognition models, these \"cloaked\" images produce functional models that consistently cause normal images of the user to be misidentified. We experimentally demonstrate that Fawkes provides 95+% protection against user recognition regardless of how trackers train their models. Even when clean, uncloaked images are \"leaked\" to the tracker and used for training, Fawkes can still maintain an 80+% protection success rate. We achieve 100% success in experiments against today's state-of-the-art facial recognition services. Finally, we show that Fawkes is robust against a variety of countermeasures that try to detect or disrupt image cloaks.",
            "keywords": [
                "Facial Recognition Privacy",
                "Image Cloaking",
                "Unauthorized Model Training",
                "Personal Privacy Protection",
                "Cloaked Image Defense"
            ]
        },
        "url": "URL#2332720",
        "sema_paperId": "755a392fe813c9ba3282f60c0e1f1ec81e68f263"
    },
    {
        "@score": "1",
        "@id": "2332723",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "136/8404",
                        "text": "Shweta Shinde"
                    },
                    {
                        "@pid": "87/7450",
                        "text": "Shengyi Wang"
                    },
                    {
                        "@pid": "153/3110",
                        "text": "Pinghai Yuan"
                    },
                    {
                        "@pid": "26/3410",
                        "text": "Aquinas Hobor"
                    },
                    {
                        "@pid": "04/5884",
                        "text": "Abhik Roychoudhury"
                    },
                    {
                        "@pid": "90/105",
                        "text": "Prateek Saxena"
                    }
                ]
            },
            "title": "BesFS: A POSIX Filesystem for Enclaves with a Mechanized Safety Proof.",
            "venue": "USENIX Security Symposium",
            "pages": "523-540",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ShindeWYHRS20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/shinde",
            "url": "https://dblp.org/rec/conf/uss/ShindeWYHRS20",
            "abstract": "New trusted computing primitives such as Intel SGX have shown the feasibility of running user-level applications in enclaves on a commodity trusted processor without trusting a large OS. However, the OS can still compromise the integrity of an enclave by tampering with the system call return values. In fact, it has been shown that a subclass of these attacks, called Iago attacks, enables arbitrary logic execution in enclave programs. Existing enclave systems have very large TCB and they implement ad-hoc checks at the system call interface which are hard to verify for completeness. To this end, we present BesFS\u2014the first filesystem interface which provably protects the enclave integrity against a completely malicious OS. We prove 167 lemmas and 2 key theorems in 4625 lines of Coq proof scripts, which directly proves the safety properties of the BesFS specification. BesFS comprises of 15 APIs with compositional safety and is expressive enough to support 31 real applications we test. BesFS integrates into existing SGX-enabled applications with minimal impact to TCB. BesFS can serve as a reference implementation for hand-coded API checks.",
            "pdf_url": "",
            "keywords": [
                "Trusted Computing",
                "Enclave Integrity",
                "Filesystem Interface",
                "Iago Attacks",
                "Safety Proofs"
            ]
        },
        "url": "URL#2332723"
    },
    {
        "@score": "1",
        "@id": "2332724",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "210/0976",
                        "text": "Dokyung Song"
                    },
                    {
                        "@pid": "188/6046",
                        "text": "Felicitas Hetzelt"
                    },
                    {
                        "@pid": "57/10239",
                        "text": "Jonghwan Kim"
                    },
                    {
                        "@pid": "17/6702",
                        "text": "Brent ByungHoon Kang"
                    },
                    {
                        "@pid": "98/117",
                        "text": "Jean-Pierre Seifert"
                    },
                    {
                        "@pid": "f/MichaelFranz",
                        "text": "Michael Franz"
                    }
                ]
            },
            "title": "Agamotto: Accelerating Kernel Driver Fuzzing with Lightweight Virtual Machine Checkpoints.",
            "venue": "USENIX Security Symposium",
            "pages": "2541-2557",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SongHKKSF20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/song",
            "url": "https://dblp.org/rec/conf/uss/SongHKKSF20",
            "abstract": "Kernel-mode drivers are challenging to analyze for vulnerabilities, yet play a critical role in maintaining the security of OS kernels. Their wide attack surface, exposed via both the system call interface and the peripheral interface, is often found to be the most direct attack vector to compromise an OS kernel. Researchers therefore have proposed many fuzzing techniques to \ufb01nd vulnerabilities in kernel drivers. However, the performance of kernel fuzzers is still lacking, for reasons such as prolonged execution of kernel code, interference be-tween test inputs, and kernel crashes. This paper proposes lightweight virtual machine check-pointing as a new primitive that enables high-throughput kernel driver fuzzing. Our key insight is that kernel driver fuzzers frequently execute similar test cases in a row, and that their performance can be improved by dynamically creating multiple checkpoints while executing test cases and skipping parts of test cases using the created checkpoints. We built a system, dubbed Agamotto, around the virtual machine check-pointing primitive and evaluated it by fuzzing the peripheral attack surface of USB and PCI drivers in Linux. The results are convincing. Agamotto improved the performance of the state-of-the-art kernel fuzzer, Syzkaller, by 66.6% on average in fuzzing 8 USB drivers, and an AFL-based PCI fuzzer by 21.6% in fuzzing 4 PCI drivers, without modifying their underlying input generation algorithm.",
            "keywords": [
                "Kernel Driver Fuzzing",
                "Virtual Machine Checkpointing",
                "Vulnerability Analysis",
                "Performance Improvement",
                "USB and PCI Drivers"
            ]
        },
        "url": "URL#2332724",
        "sema_paperId": "e4140b80fabd7636ee275d2f5642307dc51abe1f"
    },
    {
        "@score": "1",
        "@id": "2332725",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "169/8186",
                        "text": "Michael A. Specter"
                    },
                    {
                        "@pid": "203/8089",
                        "text": "James Koppel"
                    },
                    {
                        "@pid": "w/DanielJWeitzner",
                        "text": "Daniel J. Weitzner"
                    }
                ]
            },
            "title": "The Ballot is Busted Before the Blockchain: A Security Analysis of Voatz, the First Internet Voting Application Used in U.S. Federal Elections.",
            "venue": "USENIX Security Symposium",
            "pages": "1535-1553",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SpecterKW20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/specter",
            "url": "https://dblp.org/rec/conf/uss/SpecterKW20",
            "abstract": "In the 2018 midterm elections, West Virginia became the \ufb01rst state in the U.S. to allow select voters to cast their ballot on a mobile phone via a proprietary app called \u201cVoatz.\u201d Although there is no public formal description of Voatz\u2019s security model, the company claims that election security and integrity are maintained through the use of a permissioned blockchain, biometrics, a mixnet, and hardware-backed key storage modules on the user\u2019s device. In this work, we present the \ufb01rst public security analysis of Voatz, based on a reverse engineering of their Android application and the minimal available documentation of the system. We performed a clean-room reimplementation of Voatz\u2019s server and present an analysis of the election process as visible from the app itself. We \ufb01nd that Voatz has vulnerabilities that allow different kinds of adversaries to alter, stop, or expose a user\u2019s vote, including a sidechannel attack in which a completely passive network adversary can potentially recover a user\u2019s secret ballot. We additionally \ufb01nd that Voatz has a number of privacy issues stemming from their use of third party services for crucial app functionality. Our \ufb01ndings serve as a concrete illustration of the common wisdom against Internet voting, and of the importance of transparency to the legitimacy of elections.",
            "keywords": [
                "Internet Voting",
                "Voatz",
                "Security Analysis",
                "Ballot Privacy",
                "Blockchain Vulnerabilities"
            ]
        },
        "url": "URL#2332725",
        "sema_paperId": "d6a5afd47a5bddc669399dc299c11ab8ac3368c2"
    },
    {
        "@score": "1",
        "@id": "2332726",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "163/2618",
                        "text": "Darius Suciu"
                    },
                    {
                        "@pid": "32/1703",
                        "text": "Stephen E. McLaughlin"
                    },
                    {
                        "@pid": "90/5314",
                        "text": "Laurent Simon"
                    },
                    {
                        "@pid": "s/RaduSion",
                        "text": "Radu Sion"
                    }
                ]
            },
            "title": "Horizontal Privilege Escalation in Trusted Applications.",
            "venue": "USENIX Security Symposium",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SuciuMSS20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/suciu",
            "url": "https://dblp.org/rec/conf/uss/SuciuMSS20",
            "abstract": "Trusted Execution Environments (TEEs) use hardware-basedisolation toguardsensitivedatafrom conventionalmono-lithic OSes. While such isolation strengthens security guarantees, it also introduces a semantic gap between the TEE on the one side and the conventional OS and applications on the other. In this work, we studied the impact of this semantic gap on the handling of sensitive data by Trusted Applications (TAs) running in popular TEEs. We found that the combination of two properties, ( i ) multi-tenancy and ( ii ) statefulness in TAs leads to vulnerabilities of Horizontal Privilege Escalation (HPE). These vulnerabilities leaked sensitive session data or provided cryptographic oracles without requiring code execution vulnerabilities in TEE logic. We identi\ufb01ed 19 HPE vulnerabilities present across 95 TAs running on three major ARM TrustZone-basedtrustedOSes. Ourresults showedthatHPE attacks can be used to decrypt DRM protected content, to forge attestations, andtoobtaincryptographickeysunderallthreeevaluatedOSes. Here, we present HOOPER an automatic symbolic execution based scanner for HPE vulnerabilities, in order to aid manual analysis and to dramatically reduce overall time. In particular, in the Teegris Trusted OS HOOPER is able to identify 19 out of 24 HPE-based attack \ufb02ows in 24-hours contrasted with our original manual analysis time of approximately four weeks.",
            "keywords": [
                "Trusted Execution Environments",
                "Horizontal Privilege Escalation",
                "Trusted Applications",
                "Multi-tenancy Vulnerabilities",
                "Cryptographic Oracles"
            ]
        },
        "url": "URL#2332726",
        "sema_paperId": "8bac5d02b49a01d943a4f44355aaeb593759e63c"
    },
    {
        "@score": "1",
        "@id": "2332727",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "68/2734",
                        "text": "Takeshi Sugawara 0001"
                    },
                    {
                        "@pid": "222/2727",
                        "text": "Benjamin Cyr"
                    },
                    {
                        "@pid": "135/7828",
                        "text": "Sara Rampazzi"
                    },
                    {
                        "@pid": "98/8283",
                        "text": "Daniel Genkin"
                    },
                    {
                        "@pid": "f/KevinFu",
                        "text": "Kevin Fu"
                    }
                ]
            },
            "title": "Light Commands: Laser-Based Audio Injection Attacks on Voice-Controllable Systems.",
            "venue": "USENIX Security Symposium",
            "pages": "2631-2648",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SugawaraCRGF20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/sugawara",
            "url": "https://dblp.org/rec/conf/uss/SugawaraCRGF20",
            "abstract": "We propose a new class of signal injection attacks on microphones by physically converting light to sound. We show how an attacker can inject arbitrary audio signals to a target microphone by aiming an amplitude-modulated light at the microphone's aperture. We then proceed to show how this effect leads to a remote voice-command injection attack on voice-controllable systems. Examining various products that use Amazon's Alexa, Apple's Siri, Facebook's Portal, and Google Assistant, we show how to use light to obtain control over these devices at distances up to 110 meters and from two separate buildings. Next, we show that user authentication on these devices is often lacking, allowing the attacker to use light-injected voice commands to unlock the target's smartlock-protected front doors, open garage doors, shop on e-commerce websites at the target's expense, or even unlock and start various vehicles connected to the target's Google account (e.g., Tesla and Ford). Finally, we conclude with possible software and hardware defenses against our attacks.",
            "pdf_url": "",
            "keywords": [
                "Laser-Based Attacks",
                "Audio Injection",
                "Voice-Controlled Systems",
                "Remote Command Injection",
                "Microphone Exploitation"
            ]
        },
        "url": "URL#2332727"
    },
    {
        "@score": "1",
        "@id": "2332728",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "174/9967",
                        "text": "Jiachen Sun"
                    },
                    {
                        "@pid": "207/6576",
                        "text": "Yulong Cao"
                    },
                    {
                        "@pid": "150/3272",
                        "text": "Qi Alfred Chen"
                    },
                    {
                        "@pid": "91/584",
                        "text": "Z. Morley Mao"
                    }
                ]
            },
            "title": "Towards Robust LiDAR-based Perception in Autonomous Driving: General Black-box Adversarial Sensor Attack and Countermeasures.",
            "venue": "USENIX Security Symposium",
            "pages": "877-894",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SunCCM20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/sun",
            "url": "https://dblp.org/rec/conf/uss/SunCCM20",
            "abstract": "Perception plays a pivotal role in autonomous driving systems, which utilizes onboard sensors like cameras and LiDARs (Light Detection and Ranging) to assess surroundings. Recent studies have demonstrated that LiDAR-based perception is vulnerable to spoofing attacks, in which adversaries spoof a fake vehicle in front of a victim self-driving car by strategically transmitting laser signals to the victim's LiDAR sensor. However, existing attacks suffer from effectiveness and generality limitations. In this work, we perform the first study to explore the general vulnerability of current LiDAR-based perception architectures and discover that the ignored occlusion patterns in LiDAR point clouds make self-driving cars vulnerable to spoofing attacks. We construct the first black-box spoofing attack based on our identified vulnerability, which universally achieves around 80% mean success rates on all target models. We perform the first defense study, proposing CARLO to mitigate LiDAR spoofing attacks. CARLO detects spoofed data by treating ignored occlusion patterns as invariant physical features, which reduces the mean attack success rate to 5.5%. Meanwhile, we take the first step towards exploring a general architecture for robust LiDAR-based perception, and propose SVF that embeds the neglected physical features into end-to-end learning. SVF further reduces the mean attack success rate to around 2.3%.",
            "pdf_url": "",
            "keywords": [
                "LiDAR Perception",
                "Autonomous Driving",
                "Spoofing Attacks",
                "Occlusion Patterns",
                "CARLO Defense"
            ]
        },
        "url": "URL#2332728"
    },
    {
        "@score": "1",
        "@id": "2332729",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "211/7696",
                        "text": "Fnu Suya"
                    },
                    {
                        "@pid": "231/6028",
                        "text": "Jianfeng Chi"
                    },
                    {
                        "@pid": "e/DavidEvans",
                        "text": "David Evans 0001"
                    },
                    {
                        "@pid": "39/5423-1",
                        "text": "Yuan Tian 0001"
                    }
                ]
            },
            "title": "Hybrid Batch Attacks: Finding Black-box Adversarial Examples with Limited Queries.",
            "venue": "USENIX Security Symposium",
            "pages": "1327-1344",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SuyaC0020",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/suya",
            "url": "https://dblp.org/rec/conf/uss/SuyaC0020",
            "abstract": "We study adversarial examples in a black-box setting where the adversary only has API access to the target model and each query is expensive. Prior work on black-box adversarial examples follows one of two main strategies: (1) transfer attacks use white-box attacks on local models to find candidate adversarial examples that transfer to the target model, and (2) optimization-based attacks use queries to the target model and apply optimization techniques to search for adversarial examples. We propose hybrid attacks that combine both strategies, using candidate adversarial examples from local models as starting points for optimization-based attacks and using labels learned in optimization-based attacks to tune local models for finding transfer candidates. We empirically demonstrate on the MNIST, CIFAR10, and ImageNet datasets that our hybrid attack strategy reduces cost and improves success rates. We also introduce a seed prioritization strategy which enables attackers to focus their resources on the most promising seeds. Combining hybrid attacks with our seed prioritization strategy enables batch attacks that can reliably find adversarial examples with only a handful of queries.",
            "pdf_url": "",
            "keywords": [
                "Adversarial Attacks",
                "Black-box Attacks",
                "Hybrid Attacks",
                "Transfer Learning",
                "Seed Prioritization"
            ]
        },
        "url": "URL#2332729"
    },
    {
        "@score": "1",
        "@id": "2332731",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "79/11224",
                        "text": "Zhushou Tang"
                    },
                    {
                        "@pid": "50/3146",
                        "text": "Ke Tang"
                    },
                    {
                        "@pid": "166/1912",
                        "text": "Minhui Xue 0001"
                    },
                    {
                        "@pid": "39/5423-1",
                        "text": "Yuan Tian 0001"
                    },
                    {
                        "@pid": "180/8218-1",
                        "text": "Sen Chen 0001"
                    },
                    {
                        "@pid": "72/7208-1",
                        "text": "Muhammad Ikram 0001"
                    },
                    {
                        "@pid": "08/7063",
                        "text": "Tielei Wang"
                    },
                    {
                        "@pid": "22/5702",
                        "text": "Haojin Zhu"
                    }
                ]
            },
            "title": "iOS, Your OS, Everybody&apos;s OS: Vetting and Analyzing Network Services of iOS Applications.",
            "venue": "USENIX Security Symposium",
            "pages": "2415-2432",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/TangTX0CIWZ20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/tang",
            "url": "https://dblp.org/rec/conf/uss/TangTX0CIWZ20",
            "abstract": ".",
            "keywords": [
                "iOS Applications",
                "Network Services",
                "Vulnerability Analysis",
                "Security Assessment",
                "Service Vetting"
            ]
        },
        "url": "URL#2332731",
        "sema_paperId": "e3a732d850dbbc5715773542a9230b30b0e0333a"
    },
    {
        "@score": "1",
        "@id": "2332732",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "158/7224",
                        "text": "Florian Tram\u00e8r"
                    },
                    {
                        "@pid": "b/DanBoneh",
                        "text": "Dan Boneh"
                    },
                    {
                        "@pid": "39/780",
                        "text": "Kenny Paterson"
                    }
                ]
            },
            "title": "Remote Side-Channel Attacks on Anonymous Transactions.",
            "venue": "USENIX Security Symposium",
            "pages": "2739-2756",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/TramerBP20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/tramer",
            "url": "https://dblp.org/rec/conf/uss/TramerBP20",
            "abstract": "Privacy-focused crypto-currencies, such as Zcash or Monero, aim to provide strong cryptographic guarantees for transaction confidentiality and unlinkability. In this paper, we describe side-channel attacks that let remote adversaries bypass these protections.We present a general class of timing side-channel and traffic-analysis attacks on receiver privacy. These attacks enable an active remote adversary to identify the (secret) payee of any transaction in Zcash or Monero. The attacks violate the privacy goals of these crypto-currencies by exploiting side-channel information leaked by the implementation of different system components. Specifically, we show that a remote party who measures the response time of a user's P2P node to certain requests can link all transactions that send funds to that user. The timing differences are large enough that the attacks can be mounted remotely over a WAN. We responsibly disclosed the issues to the affected projects, and they have patched the vulnerabilities. We further study the impact of timing side-channels on the zero-knowledge proof systems used in these crypto-currencies. We observe that in Zcash's implementation, the time to generate a zero-knowledge proof depends on secret transaction data, and in particular on the amount of transacted funds. Hence, an adversary capable of measuring proof generation time can break transaction confidentiality, despite the proof system's zero-knowledge property.Our attacks highlight the dangers of side-channel leakage in anonymous crypto-currencies, and the need to systematically protect them against such attacks.",
            "pdf_url": "",
            "keywords": [
                "Cryptocurrency Privacy",
                "Side-Channel Attacks",
                "Transaction Confidentiality",
                "Timing Attacks",
                "Zero-Knowledge Proofs"
            ]
        },
        "url": "URL#2332732"
    },
    {
        "@score": "1",
        "@id": "2332733",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "277/2163",
                        "text": "Chia-Che Tsai"
                    },
                    {
                        "@pid": "129/2856",
                        "text": "Jeongseok Son"
                    },
                    {
                        "@pid": "07/10441",
                        "text": "Bhushan Jain"
                    },
                    {
                        "@pid": "272/7037",
                        "text": "John McAvey"
                    },
                    {
                        "@pid": "91/275",
                        "text": "Raluca Ada Popa"
                    },
                    {
                        "@pid": "08/4732",
                        "text": "Donald E. Porter"
                    }
                ]
            },
            "title": "Civet: An Efficient Java Partitioning Framework for Hardware Enclaves.",
            "venue": "USENIX Security Symposium",
            "pages": "505-522",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/TsaiSJMPP20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/tsai",
            "url": "https://dblp.org/rec/conf/uss/TsaiSJMPP20",
            "abstract": "Hardware enclaves are designed to execute small pieces of sensitive code or to operate on sensitive data, in isolation from larger, less trusted systems. Partitioning a large, legacy application requires signi\ufb01cant effort. Partitioning an application written in a managed language, such as Java, is more challenging because of mutable language characteristics, extensive code reachability in class libraries, and the inevitability of using a heavyweight runtime. Civet is a framework for partitioning Java applications into enclaves. Civet reduces the number of lines of code in the enclave and uses language-level defenses, including deep type checks and dynamic taint-tracking, to harden the enclave interface. Civet also contributes a partitioned Java runtime de-sign, including a garbage collection design optimized for the peculiarities of enclaves. Civet is ef\ufb01cient for data-intensive workloads; partitioning a Hadoop mapper reduces the en-clave overhead from 10 \u00d7 to 16\u201322% without taint-tracking or 70\u201380% with taint-tracking.",
            "keywords": [
                "Hardware Enclaves",
                "Java Partitioning",
                "Enclave Interface Hardening",
                "Dynamic Taint-Tracking",
                "Garbage Collection Optimization"
            ]
        },
        "url": "URL#2332733",
        "sema_paperId": "2748160bb490aa681687676014fef089d8b28c14"
    },
    {
        "@score": "1",
        "@id": "2332734",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "245/6107",
                        "text": "Emily Tseng"
                    },
                    {
                        "@pid": "217/9409",
                        "text": "Rosanna Bellini"
                    },
                    {
                        "@pid": "128/9352",
                        "text": "Nora McDonald"
                    },
                    {
                        "@pid": "231/1859",
                        "text": "Matan Danos"
                    },
                    {
                        "@pid": "93/655",
                        "text": "Rachel Greenstadt"
                    },
                    {
                        "@pid": "58/4016",
                        "text": "Damon McCoy"
                    },
                    {
                        "@pid": "75/11301",
                        "text": "Nicola Dell"
                    },
                    {
                        "@pid": "26/3399",
                        "text": "Thomas Ristenpart"
                    }
                ]
            },
            "title": "The Tools and Tactics Used in Intimate Partner Surveillance: An Analysis of Online Infidelity Forums.",
            "venue": "USENIX Security Symposium",
            "pages": "1893-1909",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/TsengBMDGMDR20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/tseng",
            "url": "https://dblp.org/rec/conf/uss/TsengBMDGMDR20",
            "abstract": "Abusers increasingly use spyware apps, account compromise, and social engineering to surveil their intimate partners, causing substantial harms that can culminate in violence. This form of privacy violation, termed intimate partner surveillance (IPS), is a profoundly challenging problem to address due to the physical access and trust present in the relationship between the target and attacker. While previous research has examined IPS from the perspectives of survivors, we present the first measurement study of online forums in which (potential) attackers discuss IPS strategies and techniques. In domains such as cybercrime, child abuse, and human trafficking, studying the online behaviors of perpetrators has led to better threat intelligence and techniques to combat attacks. We aim to provide similar insights in the context of IPS. We identified five online forums containing discussion of monitoring cellphones and other means of surveilling an intimate partner, including three within the context of investigating relationship infidelity. We perform a mixed-methods analysis of these forums, surfacing the tools and tactics that attackers use to perform surveillance. Via qualitative analysis of forum content, we present a taxonomy of IPS strategies used and recommended by attackers, and synthesize lessons for technologists seeking to curb the spread of IPS.",
            "keywords": [
                "Intimate Partner Surveillance",
                "Online Infidelity Forums",
                "Surveillance Tactics",
                "Spyware Applications",
                "Privacy Violations"
            ]
        },
        "url": "URL#2332734",
        "sema_paperId": "0c22cdfa540102b58ae0ab1fed8d6df3f4ce5031"
    },
    {
        "@score": "1",
        "@id": "2332735",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "118/3426",
                        "text": "G\u00fcliz Seray Tuncay"
                    },
                    {
                        "@pid": "204/9434",
                        "text": "Jingyu Qian"
                    },
                    {
                        "@pid": "g/CarlAGunter",
                        "text": "Carl A. Gunter"
                    }
                ]
            },
            "title": "See No Evil: Phishing for Permissions with False Transparency.",
            "venue": "USENIX Security Symposium",
            "pages": "415-432",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/TuncayQG20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/tuncay",
            "url": "https://dblp.org/rec/conf/uss/TuncayQG20",
            "abstract": "Android introduced runtime permissions in order to provide users with more contextual information to make informed decisions as well as with finer granularity when dealing with permissions. In this work, we identified that the correct operation of the runtime permission model relies on certain implicit assumptions which can conveniently be broken by adversaries to illegitimately obtain permissions from the background while impersonating foreground apps. We call this detrimental scenario false transparency attacks. These attacks constitute a serious security threat to the Android platform as they invalidate the security guarantees of 1) runtime permissions by enabling background apps to spoof the context and identity of foreground apps when requesting permissions and of 2) Android permissions altogether by allowing adversaries to exploit users' trust in other apps to obtain permissions. We demonstrated via a user study we conducted on Amazon Mechanical Turk that mobile users' comprehension of runtime permissions renders them susceptible to this attack vector. We carefully designed our attacks to launch strategically in order to appear persuasive and verified the validity of our design strategies through our user study. To demonstrate the feasibility of our attacks, we conducted an in-lab user study in a realistic setting and showed that none of the subjects noticed our attacks. Finally, we discuss why the existing defenses against mobile phishing fail in the context of false transparency attacks. In particular, we disclose the security vulnerabilities we identified in a key security mechanism added in Android 10. We then propose a list of countermeasures to be implemented on the Android platform and on app stores to practically tackle false transparency attacks.",
            "pdf_url": "",
            "keywords": [
                "Android Security",
                "Runtime Permissions",
                "False Transparency Attacks",
                "User Trust Exploitation",
                "Mobile Phishing"
            ]
        },
        "url": "URL#2332735",
        "sema_paperId": "6fa2a5073ece01faa6a9d4e1bbd6acfb6c673205"
    },
    {
        "@score": "1",
        "@id": "2332736",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "61/11094",
                        "text": "Daniel Votipka"
                    },
                    {
                        "@pid": "244/2188",
                        "text": "Kelsey R. Fulton"
                    },
                    {
                        "@pid": "00/2904",
                        "text": "James Parker"
                    },
                    {
                        "@pid": "272/7152",
                        "text": "Matthew Hou"
                    },
                    {
                        "@pid": "20/7983",
                        "text": "Michelle L. Mazurek"
                    },
                    {
                        "@pid": "h/MichaelWHicks",
                        "text": "Michael Hicks 0001"
                    }
                ]
            },
            "title": "Understanding security mistakes developers make: Qualitative analysis from Build It, Break It, Fix It.",
            "venue": "USENIX Security Symposium",
            "pages": "109-126",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/VotipkaFPHM020",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/votipka-understanding",
            "url": "https://dblp.org/rec/conf/uss/VotipkaFPHM020",
            "abstract": "Secure software development is a challenging task requiring consideration of many possible threats and mitigations. This paper investigates how and why programmers, despite a baseline of security experience, make security-relevant errors. To do this, we conducted an in-depth analysis of 94 submissions to a secure-programming contest designed to mimic real-world constraints: correctness, performance, and security. In addition to writing secure code, participants were asked to search for vulnerabilities in other teams\u2019 programs; in total, teams submitted 866 exploits against the submissions we considered. Over an intensive six-month period, we used iterative open coding to manually, but systematically, characterize each submitted project and vulnerability (including vulnerabilities we identi\ufb01ed ourselves). We labeled vulnerabilities by type, attacker control allowed, and ease of exploitation, and projects according to security implementation strategy. Several patterns emerged. For example, simple mistakes were least common: only 21% of projects introduced such an error. Conversely, vulnerabilities arising from a misunderstanding of security concepts were signi\ufb01cantly more common, appearing in 78% of projects. Our results have implications for improving secure-programming APIs, API documentation, vulnerability-\ufb01nding tools, and security education.",
            "keywords": [
                "Secure Software Development",
                "Vulnerability Analysis",
                "Security Misunderstandings",
                "Programming Errors",
                "Secure Coding Practices"
            ]
        },
        "url": "URL#2332736",
        "sema_paperId": "fec0d8cb70fc8aa19f1167a28cfa23e7dd5956d4"
    },
    {
        "@score": "1",
        "@id": "2332737",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "61/11094",
                        "text": "Daniel Votipka"
                    },
                    {
                        "@pid": "224/9249",
                        "text": "Seth M. Rabin"
                    },
                    {
                        "@pid": "131/6731",
                        "text": "Kristopher K. Micinski"
                    },
                    {
                        "@pid": "18/2050",
                        "text": "Jeffrey S. Foster"
                    },
                    {
                        "@pid": "20/7983",
                        "text": "Michelle L. Mazurek"
                    }
                ]
            },
            "title": "An Observational Investigation of Reverse Engineers&apos; Processes.",
            "venue": "USENIX Security Symposium",
            "pages": "1875-1892",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/VotipkaRMFM20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/votipka-observational",
            "url": "https://dblp.org/rec/conf/uss/VotipkaRMFM20",
            "abstract": "Reverse engineering is a complex process essential to software-security tasks such as vulnerability discovery and malware analysis. Significant research and engineering effort has gone into developing tools to support reverse engineers. However, little work has been done to understand the way reverse engineers think when analyzing programs, leaving tool developers to make interface design decisions based only on intuition.This paper takes a first step toward a better understanding of reverse engineers\u2019 processes, with the goal of producing insights for improving interaction design for reverse engineering tools. We present the results of a semi-structured, observational interview study of reverse engineers (N=16). Each observation investigated the questions reverse engineers ask as they probe a program, how they answer these questions, and the decisions they make throughout the reverse engineering process. From the interview responses, we distill a model of the reverse engineering process, divided into three phases: overview, sub-component scanning, and focused experimentation. Each analysis phase\u2019s results feed the next as reverse engineers\u2019 mental representations become more concrete. We find that reverse engineers typically use static methods in the first two phases, but dynamic methods in the final phase, with experience playing large, but varying, roles in each phase. Based on these results, we provide five interaction design guidelines for reverse engineering tools.",
            "pdf_url": "",
            "keywords": [
                "Reverse Engineering",
                "Software Analysis",
                "Vulnerability Discovery",
                "Dynamic Analysis",
                "Interaction Design Guidelines"
            ]
        },
        "url": "URL#2332737"
    },
    {
        "@score": "1",
        "@id": "2332738",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "220/3081",
                        "text": "Ke Coby Wang"
                    },
                    {
                        "@pid": "r/MichaelKReiter",
                        "text": "Michael K. Reiter"
                    }
                ]
            },
            "title": "Detecting Stuffing of a User&apos;s Credentials at Her Own Accounts.",
            "venue": "USENIX Security Symposium",
            "pages": "2201-2218",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WangR20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/wang",
            "url": "https://dblp.org/rec/conf/uss/WangR20",
            "abstract": "We propose a framework by which websites can coordinate to detect credential stuffing on individual user accounts. Our detection algorithm teases apart normal login behavior (involving password reuse, entering correct passwords into the wrong sites, etc.) from credential stuffing, by leveraging modern anomaly detection and carefully tracking suspicious logins. Websites coordinate using a novel private membership-test protocol, thereby ensuring that information about passwords is not leaked; this protocol is highly scalable, partly due to its use of cuckoo filters, and is more secure than similarly scalable alternatives in an important measure that we define. We use probabilistic model checking to estimate our credential-stuffing detection accuracy across a range of operating points. These methods might be of independent interest for their novel application of formal methods to estimate the usability impacts of our design. We show that even a minimal-infrastructure deployment of our framework should already support the combined login load experienced by the airline, hotel, retail, and consumer banking industries in the U.S.",
            "keywords": [
                "Credential Stuffing",
                "Anomaly Detection",
                "User Account Security",
                "Private Membership-Test Protocol",
                "Scalable Detection Framework"
            ]
        },
        "url": "URL#2332738",
        "sema_paperId": "21d0e8c4769ef04de82a0eff78c18f0fdd45d633"
    },
    {
        "@score": "1",
        "@id": "2332739",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "217/4562",
                        "text": "Miranda Wei"
                    },
                    {
                        "@pid": "272/7201",
                        "text": "Madison Stamos"
                    },
                    {
                        "@pid": "264/7270",
                        "text": "Sophie Veys"
                    },
                    {
                        "@pid": "238/8867",
                        "text": "Nathan Reitinger"
                    },
                    {
                        "@pid": "232/2188",
                        "text": "Justin Goodman"
                    },
                    {
                        "@pid": "272/7236",
                        "text": "Margot Herman"
                    },
                    {
                        "@pid": "239/9280",
                        "text": "Dorota Filipczuk"
                    },
                    {
                        "@pid": "217/9566",
                        "text": "Ben Weinshel"
                    },
                    {
                        "@pid": "20/7983",
                        "text": "Michelle L. Mazurek"
                    },
                    {
                        "@pid": "66/9786",
                        "text": "Blase Ur"
                    }
                ]
            },
            "title": "What Twitter Knows: Characterizing Ad Targeting Practices, User Perceptions, and Ad Explanations Through Users&apos; Own Twitter Data.",
            "venue": "USENIX Security Symposium",
            "pages": "145-162",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WeiSVRGHFWMU20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/wei",
            "url": "https://dblp.org/rec/conf/uss/WeiSVRGHFWMU20",
            "abstract": "Although targeted advertising has drawn signifcant attention from privacy researchers, many critical empirical questions remain. In particular, only a few of the dozens of targeting mechanisms used by major advertising platforms are well understood, and studies examining users\u2019 perceptions of ad targeting often rely on hypothetical situations. Further, it is unclear how well existing transparency mechanisms, from data-access rights to ad explanations, actually serve the users they are intended for. To develop a deeper understanding of the current targeting advertising ecosystem, this paper engages 231 participants\u2019 own Twitter data, containing ads they were shown and the associated targeting criteria, for measurement and user study. We fnd many targeting mechanisms ignored by prior work \u2014 including advertiser-uploaded lists of specifc users, lookalike audiences, and retargeting cam-paigns \u2014 are widely used on Twitter. Crucially, participants found these understudied practices among the most privacy invasive. Participants also found ad explanations designed for this study more useful, more comprehensible, and overall more preferable than Twitter\u2019s current ad explanations. Our fndings underscore the benefts of data access, characterize unstudied facets of targeted advertising, and identify potential directions for improving transparency in targeted advertising.",
            "keywords": [
                "Targeted Advertising",
                "User Privacy",
                "Ad Transparency",
                "Twitter Data",
                "Ad Targeting Mechanisms"
            ]
        },
        "url": "URL#2332739",
        "sema_paperId": "60f5f171e46382d6d612c72c88b2cd3e794dea98"
    },
    {
        "@score": "1",
        "@id": "2332740",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "09/7865",
                        "text": "Charles Weir"
                    },
                    {
                        "@pid": "147/7971",
                        "text": "Ben Hermann"
                    },
                    {
                        "@pid": "38/9378",
                        "text": "Sascha Fahl"
                    }
                ]
            },
            "title": "From Needs to Actions to Secure Apps? The Effect of Requirements and Developer Practices on App Security.",
            "venue": "USENIX Security Symposium",
            "pages": "289-305",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WeirHF20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/weir",
            "url": "https://dblp.org/rec/conf/uss/WeirHF20",
            "abstract": "Increasingly mobile device users are being hurt by security or privacy issues with the apps they use. App developers can help prevent this; inexpensive security assurance techniques to do so are now well established, but do developers use them? And if they do so, is that reflected in more secure apps? From a survey of 335 successful app developers, we conclude that less than a quarter of such professionals have access to security experts; that less than a third use assurance techniques regularly; and that few have made more than cosmetic changes as a result of the European GDPR legislation. Reas-suringly, we found that app developers tend to use more assurance techniques and make more frequent security updates when (1) they see more need for security, and (2) there is security expert or champion involvement. In a second phase we downloaded the apps corresponding to each completed survey and analyzed them for SSL issues, cryptographic API misuse and privacy leaks, finding only one fifth defect-free as far as our tools could detect. We found that having security experts or champions involved led to more cryptographic API issues, probably because of greater cryptography usage; but that measured defect counts did not relate to the need for security, nor to the use of assurance techniques. This offers two major opportunities for research: to further improve the detection of security issues in app binaries; and to support increasing the use of assurance techniques in the app developer community.",
            "keywords": [
                "Mobile App Security",
                "Security Assurance Techniques",
                "Developer Practices",
                "Cryptographic API Misuse",
                "Privacy Leaks"
            ]
        },
        "url": "URL#2332740",
        "sema_paperId": "624844b6e606151c11d957e6e003027a352dda23"
    },
    {
        "@score": "1",
        "@id": "2332741",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "145/2706",
                        "text": "Samuel Weiser"
                    },
                    {
                        "@pid": "272/7215",
                        "text": "David Schrammel"
                    },
                    {
                        "@pid": "220/2558",
                        "text": "Lukas Bodner"
                    },
                    {
                        "@pid": "128/5169",
                        "text": "Raphael Spreitzer"
                    }
                ]
            },
            "title": "Big Numbers - Big Troubles: Systematically Analyzing Nonce Leakage in (EC)DSA Implementations.",
            "venue": "USENIX Security Symposium",
            "pages": "1767-1784",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WeiserSBS20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/weiser",
            "url": "https://dblp.org/rec/conf/uss/WeiserSBS20",
            "abstract": "Side-channel attacks exploiting (EC)DSA nonce leakage easily lead to full key recovery. Although (EC)DSA implementations have already been hardened against side-channel leakage using the constant-time paradigm, the long-standing cat-and-mouse-game of attacks and patches continues. In particular, current code review is prone to miss less obvious side channels hidden deeply in the call stack. To solve this problem, a systematic study of nonce leakage is necessary. We present a systematic analysis of nonce leakage in cryptographic implementations. In particular, we expand DATA, an open-source side-channel analysis framework, to detect nonce leakage. Our analysis identi\ufb01ed multiple unknown nonce leakage vulnerabilities across all essential computation steps involving nonces. Among others, we uncover inherent problems in Bignumber implementations that break claimed constant-time guarantees of (EC)DSA implementations if secrets are close to a word boundary. We found that lazy re-sizing of Bignumbers in OpenSSL and LibreSSL yields a highly accurate and easily exploitable side channel, which has been acknowledged with two CVEs. Surprisingly, we also found a tiny but expressive leakage in the constant-time scalar multiplication of OpenSSL and BoringSSL. Moreover, in the process of reporting and patching, we identi\ufb01ed newly introduced leakage with the support of our tool, thus preventing another attack-patch cycle. We open-source our tool, together with an intuitive graphical user interface we developed.",
            "keywords": [
                "Cryptographic Implementations",
                "Nonce Leakage",
                "Side-Channel Attacks",
                "Bignumber Vulnerabilities",
                "Constant-Time Guarantees"
            ]
        },
        "url": "URL#2332741",
        "sema_paperId": "f7f5f867fa72b680cfdf61ce3b8362a2d3fc2ed4"
    },
    {
        "@score": "1",
        "@id": "2332742",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "215/0123",
                        "text": "Haohuang Wen"
                    },
                    {
                        "@pid": "150/3272",
                        "text": "Qi Alfred Chen"
                    },
                    {
                        "@pid": "49/4102-1",
                        "text": "Zhiqiang Lin 0001"
                    }
                ]
            },
            "title": "Plug-N-Pwned: Comprehensive Vulnerability Analysis of OBD-II Dongles as A New Over-the-Air Attack Surface in Automotive IoT.",
            "venue": "USENIX Security Symposium",
            "pages": "949-965",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WenCL20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/wen",
            "url": "https://dblp.org/rec/conf/uss/WenCL20",
            "abstract": "With the growing trend of the Internet of Things, a large number of wireless OBD-II dongles are developed, which can be simply plugged into vehicles to enable remote functions such as sophisticated vehicle control and status monitoring. However, since these dongles are directly connected with in-vehicle networks, they may open a new over-the-air attack surface for vehicles. In this paper, we conduct the first comprehensive security analysis on all wireless OBD-II dongles available on Amazon in the US in February 2019, which were 77 in total. To systematically perform the analysis, we design and implement an automated tool DONGLESCOPE that dynamically tests these dongles from all possible attack stages on a real automobile. With DONGLESCOPE, we have identified 5 different types of vulnerabilities, with 4 being newly discovered. Our results reveal that each of the 77 dongles exposes at least two types of these vulnerabilities, which indicates a widespread vulnerability exposure among wireless OBD-II dongles on the market today. To demonstrate the severity, we further construct 4 classes of concrete attacks with a variety of practical implications such as privacy leakage, property theft, and even safety threat. We also discuss the root causes and feasible countermeasures, and have made corresponding responsible disclosure.",
            "keywords": [
                "Automotive IoT",
                "OBD-II Dongles",
                "Vulnerability Analysis",
                "Over-the-Air Attacks",
                "DONGLESCOPE"
            ]
        },
        "url": "URL#2332742",
        "sema_paperId": "f87fe733aba25a9e8582820d1a68d11aec7de131"
    },
    {
        "@score": "1",
        "@id": "2332743",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "30/10768-3",
                        "text": "Cong Wu 0003"
                    },
                    {
                        "@pid": "59/1028-8",
                        "text": "Kun He 0008"
                    },
                    {
                        "@pid": "27/4364-3",
                        "text": "Jing Chen 0003"
                    },
                    {
                        "@pid": "11/7704-1",
                        "text": "Ziming Zhao 0001"
                    },
                    {
                        "@pid": "37/7220",
                        "text": "Ruiying Du"
                    }
                ]
            },
            "title": "Liveness is Not Enough: Enhancing Fingerprint Authentication with Behavioral Biometrics to Defeat Puppet Attacks.",
            "venue": "USENIX Security Symposium",
            "pages": "2219-2236",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Wu000D20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/wu",
            "url": "https://dblp.org/rec/conf/uss/Wu000D20",
            "abstract": "Fingerprint authentication has gained increasing popularity on mobile devices in recent years. However, it is vulnerable to presentation attacks, which include that an attacker spoofs with an arti\ufb01cial replica. Many liveness detection solutions have been proposed to defeat such presentation attacks; however, they all fail to defend against a particular type of presentation attack, namely puppet attack , in which an attacker places an unwilling victim\u2019s \ufb01nger on the \ufb01ngerprint sensor. In this paper, we propose F IN A UTH , an effective and ef\ufb01cient software-only solution, to complement \ufb01ngerprint authentication by defeating both synthetic spoofs and puppet attacks using \ufb01ngertip-touch characteristics. F IN A UTH characterizes intrinsic \ufb01ngertip-touch behaviors including the acceleration and the rotation angle of mobile devices when a legitimate user authenticates. F IN A UTH only utilizes common sensors equipped on mobile devices and does not introduce extra usability burdens on users. To evaluate the effectiveness of F IN A UTH , we carried out experiments on datasets collected from 90 subjects after the IRB approval. The results show that F IN A UTH can achieve the average balanced accuracy of 96.04% with 5 training data points and 99.28% with 100 training data points. Security experiments also demonstrate that F IN A UTH is resilient against possible attacks. In addition, we report the usability analysis results of F IN A UTH , including user authentication delay and overhead.",
            "keywords": [
                "Fingerprint Authentication",
                "Behavioral Biometrics",
                "Puppet Attacks",
                "Liveness Detection",
                "FINGAUTH"
            ]
        },
        "url": "URL#2332743",
        "sema_paperId": "fc6ae6b382a218f774f3eb778d03b3b56a245630"
    },
    {
        "@score": "1",
        "@id": "2332744",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "181/1848-11",
                        "text": "Yang Xiao 0011"
                    },
                    {
                        "@pid": "61/9197",
                        "text": "Bihuan Chen 0001"
                    },
                    {
                        "@pid": "256/6148",
                        "text": "Chendong Yu"
                    },
                    {
                        "@pid": "183/0183",
                        "text": "Zhengzi Xu"
                    },
                    {
                        "@pid": "91/10236",
                        "text": "Zimu Yuan"
                    },
                    {
                        "@pid": "92/2954",
                        "text": "Feng Li"
                    },
                    {
                        "@pid": "237/8683",
                        "text": "Binghong Liu"
                    },
                    {
                        "@pid": "51/3710-3",
                        "text": "Yang Liu 0003"
                    },
                    {
                        "@pid": "24/679",
                        "text": "Wei Huo"
                    },
                    {
                        "@pid": "10/328",
                        "text": "Wei Zou"
                    },
                    {
                        "@pid": "74/2181",
                        "text": "Wenchang Shi"
                    }
                ]
            },
            "title": "MVP: Detecting Vulnerabilities using Patch-Enhanced Vulnerability Signatures.",
            "venue": "USENIX Security Symposium",
            "pages": "1165-1182",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Xiao0YXYLL0HZS20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/xiao",
            "url": "https://dblp.org/rec/conf/uss/Xiao0YXYLL0HZS20",
            "abstract": "Recurring vulnerabilities widely exist and remain undetected in real-world systems, which are often resulted from reused code base or shared code logic. However, the potentially small differences between vulnerable functions and their patched functions as well as the possibly large differences between vulnerable functions and target functions to be detected bring challenges to clone-based and function matching-based approaches to identify these recurring vulnerabilities, i.e., causing high false positives and false negatives. In this paper, we propose a novel approach to detect recurring vulnerabilities with low false positives and low false negatives. We first use our novel program slicing to extract vulnerability and patch signatures from vulnerable function and its patched function at syntactic and semantic levels. Then a target function is identified as potentially vulnerable if it matches the vulnerability signature but does not match the patch signature. We implement our approach in a tool named MVP. Our evaluation on ten open-source systems has shown that, i) MVP significantly outperformed state-of-the-art clone-based and function matching-based recurring vulnerability detection approaches; ii) MVP detected recurring vulnerabilities that cannot be detected by general-purpose vulnerability detection approaches, i.e., two learning-based approaches and two commercial tools; and iii) MVP has detected 97 new vulnerabilities with 23 CVE identifiers assigned.",
            "keywords": [
                "Vulnerability Detection",
                "Recurring Vulnerabilities",
                "Patch-Enhanced Signatures",
                "Program Slicing",
                "False Positives and Negatives"
            ]
        },
        "url": "URL#2332744",
        "sema_paperId": "680a98ab69abb8778ae66e017d0994d13f0fc138"
    },
    {
        "@score": "1",
        "@id": "2332745",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "217/0857",
                        "text": "Jiarong Xing"
                    },
                    {
                        "@pid": "188/2454",
                        "text": "Qiao Kang"
                    },
                    {
                        "@pid": "59/146-1",
                        "text": "Ang Chen 0001"
                    }
                ]
            },
            "title": "NetWarden: Mitigating Network Covert Channels while Preserving Performance.",
            "venue": "USENIX Security Symposium",
            "pages": "2039-2056",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/XingKC20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/xing",
            "url": "https://dblp.org/rec/conf/uss/XingKC20",
            "abstract": "Network covert channels are an advanced threat to the security of distributed systems. Existing defenses all come at the cost of performance, so they present signi\ufb01cant barriers to a practical deployment in high-speed networks. We propose NetWarden , a novel defense whose key design goal is to preserve TCP performance while mitigating covert channels. The use of programmable data planes makes it possible for Net-Warden to adapt defenses that were only demonstrated before as proof of concept, and apply them at linespeed. Moreover, NetWarden uses a set of performance boosting techniques to temporarily increase the performance of connections that have been affected by covert channel mitigation, with the ultimate goal of neutralizing the overall performance impact. NetWarden also uses a fastpath/slowpath architecture to combine the generality of software and the ef\ufb01ciency of hardware for effective defense. Our evaluation shows that NetWarden works smoothly with complex applications and workloads, and that it can mitigate covert timing and storage channels with little performance disturbance.",
            "keywords": [
                "Network Covert Channels",
                "TCP Performance",
                "Covert Channel Mitigation",
                "Programmable Data Planes",
                "Fastpath/Slowpath Architecture"
            ]
        },
        "url": "URL#2332745",
        "sema_paperId": "4038cfd1d848d6b9a96783333ac2cd116eb5cace"
    },
    {
        "@score": "1",
        "@id": "2332746",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "70/880",
                        "text": "Yan Xiong"
                    },
                    {
                        "@pid": "98/4430",
                        "text": "Cheng Su"
                    },
                    {
                        "@pid": "47/7564",
                        "text": "Wenchao Huang"
                    },
                    {
                        "@pid": "76/2786",
                        "text": "Fuyou Miao"
                    },
                    {
                        "@pid": "00/6350",
                        "text": "Wansen Wang"
                    },
                    {
                        "@pid": "272/7210",
                        "text": "Hengyi Ouyang"
                    }
                ]
            },
            "title": "SmartVerif: Push the Limit of Automation Capability of Verifying Security Protocols by Dynamic Strategies.",
            "venue": "USENIX Security Symposium",
            "pages": "253-270",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/XiongSHMWO20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/xiong",
            "url": "https://dblp.org/rec/conf/uss/XiongSHMWO20",
            "abstract": "Current formal approaches have been successfully used to find design flaws in many security protocols. However, it is still challenging to automatically analyze protocols due to their large or infinite state spaces. In this paper, we propose SmartVerif, a novel and general framework that pushes the limit of automation capability of state-of-the-art verification approaches. The primary technical contribution is the dynamic strategy inside SmartVerif, which can be used to smartly search proof paths. Different from the non-trivial and error-prone design of existing static strategies, the design of our dynamic strategy is simple and flexible: it can automatically optimize itself according to the security protocols without any human intervention. With the optimized strategy, SmartVerif can localize and prove supporting lemmata, which leads to higher probability of success in verification. The insight of designing the strategy is that the node representing a supporting lemma is on an incorrect proof path with lower probability, when a random strategy is given. Hence, we implement the strategy around the insight by introducing a reinforcement learning algorithm. We also propose several methods to deal with other technical problems in implementing SmartVerif. Experimental results show that SmartVerif can automatically verify all security protocols studied in this paper. The case studies also validate the efficiency of our dynamic strategy.",
            "keywords": [
                "Security Protocol Verification",
                "Dynamic Strategy",
                "Reinforcement Learning",
                "Proof Path Optimization",
                "Automated Verification"
            ]
        },
        "url": "URL#2332746",
        "sema_paperId": "23c9bbe7571406a82b88e0f9a56bdbcf394a90af"
    },
    {
        "@score": "1",
        "@id": "2332747",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "183/0183",
                        "text": "Zhengzi Xu"
                    },
                    {
                        "@pid": "32/9374",
                        "text": "Yulong Zhang"
                    },
                    {
                        "@pid": "272/7204",
                        "text": "Longri Zheng"
                    },
                    {
                        "@pid": "205/2057",
                        "text": "Liangzhao Xia"
                    },
                    {
                        "@pid": "205/2109",
                        "text": "Chenfu Bao"
                    },
                    {
                        "@pid": "95/6543-4",
                        "text": "Zhi Wang 0004"
                    },
                    {
                        "@pid": "51/3710-3",
                        "text": "Yang Liu 0003"
                    }
                ]
            },
            "title": "Automatic Hot Patch Generation for Android Kernels.",
            "venue": "USENIX Security Symposium",
            "pages": "2397-2414",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/XuZZXB0L20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/xu",
            "url": "https://dblp.org/rec/conf/uss/XuZZXB0L20",
            "abstract": "The rapid growth of the Android ecosystem has led to the fragmentation problem where a wide range of (customized) versions of Android OS exist in the market. This poses a severe security issue as it is very costly for Android vendors to \ufb01x vulnerabilities in their customized Android kernels in time. The recent development of the hot patching technique provides an ideal solution to solve this problem since it can be applied to a wide range of Android kernels without in-terrupting their normal functionalities. However, the current hot patches are written by human experts, which can be time-consuming and error-prone. To this end, we \ufb01rst study the feasibility of automatic patch generation from 373 Android kernel CVEs ranging from 2012 to 2016. Then, we develop an automatic hot patch generation tool, named V ulmet , which produces semantic preserving hot patches by learning from the o \ufb03 cial patches. The key idea of V ulmet is to use the weakest precondition reasoning to transform the changes made by the o \ufb03 cial patches into the hot patch constraints. The experiments have shown that V ulmet can generate correct hot patches for 55 real-world Android kernel CVEs. The hot patches do not a \ufb00 ect the robustness of the kernels and have low performance overhead.",
            "keywords": [
                "Android Kernel Security",
                "Hot Patching",
                "Automatic Patch Generation",
                "Vulnerability Mitigation",
                "Semantic Preservation"
            ]
        },
        "url": "URL#2332747",
        "sema_paperId": "e7cd329bbd69cfa932bd707498186ef48a8ea002"
    },
    {
        "@score": "1",
        "@id": "2332748",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "137/0590",
                        "text": "Mengjia Yan 0001"
                    },
                    {
                        "@pid": "25/8166",
                        "text": "Christopher W. Fletcher"
                    },
                    {
                        "@pid": "t/JosepTorrellas",
                        "text": "Josep Torrellas"
                    }
                ]
            },
            "title": "Cache Telepathy: Leveraging Shared Resource Attacks to Learn DNN Architectures.",
            "venue": "USENIX Security Symposium",
            "pages": "2003-2020",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YanFT20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/yan",
            "url": "https://dblp.org/rec/conf/uss/YanFT20",
            "abstract": "Deep Neural Networks (DNNs) are fast becoming ubiquitous for their ability to attain good accuracy in various machine learning tasks. A DNN\u2019s architecture (i.e., its hyperparameters) broadly determines the DNN\u2019s accuracy and performance, and is often confidential. Attacking a DNN in the cloud to obtain its architecture can potentially provide major commercial value. Further, attaining a DNN\u2019s architecture facilitates other existing DNN attacks.\nThis paper presents Cache Telepathy: an efficient mechanism to help obtain a DNN\u2019s architecture using the cache side channel. The attack is based on the insight that DNN inference relies heavily on tiled GEMM (Generalized Matrix Multiply), and that DNN architecture parameters determine the number of GEMM calls and the dimensions of the matrices used in the GEMM functions. Such information can be leaked through the cache side channel. \nThis paper uses Prime+Probe and Flush+Reload to attack the VGG and ResNet DNNs running OpenBLAS and Intel MKL libraries. Our attack is effective in helping obtain the DNN architectures by very substantially reducing the search space of target DNN architectures. For example, when attacking the OpenBLAS library, for the different layers in VGG-16, it reduces the search space from more than 5.4\u00d71012 architectures to just 16; for the different modules in ResNet-50, it reduces the search space from more than 6\u00d71046 architectures to only 512.",
            "pdf_url": "",
            "keywords": [
                "Cache Side Channel",
                "DNN Architecture Recovery",
                "Resource Attacks",
                "Prime+Probe",
                "Flush+Reload"
            ]
        },
        "url": "URL#2332748"
    },
    {
        "@score": "1",
        "@id": "2332749",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "139/7075",
                        "text": "Fan Yao"
                    },
                    {
                        "@pid": "215/3683",
                        "text": "Adnan Siraj Rakin"
                    },
                    {
                        "@pid": "129/1701",
                        "text": "Deliang Fan"
                    }
                ]
            },
            "title": "DeepHammer: Depleting the Intelligence of Deep Neural Networks through Targeted Chain of Bit Flips.",
            "venue": "USENIX Security Symposium",
            "pages": "1463-1480",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YaoRF20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/yao",
            "url": "https://dblp.org/rec/conf/uss/YaoRF20",
            "abstract": "Security of machine learning is increasingly becoming a major concern due to the ubiquitous deployment of deep learning in many security-sensitive domains. Many prior studies have shown external attacks such as adversarial examples that tamper with the integrity of DNNs using maliciously crafted inputs. However, the security implication of internal threats (i.e., hardware vulnerability) to DNN models has not yet been well understood. In this paper, we demonstrate the first hardware-based attack on quantized deep neural networks-DeepHammer-that deterministically induces bit flips in model weights to compromise DNN inference by exploiting the rowhammer vulnerability. DeepHammer performs aggressive bit search in the DNN model to identify the most vulnerable weight bits that are flippable under system constraints. To trigger deterministic bit flips across multiple pages within reasonable amount of time, we develop novel system-level techniques that enable fast deployment of victim pages, memory-efficient rowhammering and precise flipping of targeted bits. DeepHammer can deliberately degrade the inference accuracy of the victim DNN system to a level that is only as good as random guess, thus completely depleting the intelligence of targeted DNN systems. We systematically demonstrate our attacks on real systems against 12 DNN architectures with 4 different datasets and different application domains. Our evaluation shows that DeepHammer is able to successfully tamper DNN inference behavior at run-time within a few minutes. We further discuss several mitigation techniques from both algorithm and system levels to protect DNNs against such attacks. Our work highlights the need to incorporate security mechanisms in future deep learning system to enhance the robustness of DNN against hardware-based deterministic fault injections.",
            "keywords": [
                "Hardware Vulnerability",
                "Rowhammer Attack",
                "Bit Flips",
                "Quantized Deep Neural Networks",
                "Inference Accuracy Degradation"
            ]
        },
        "url": "URL#2332749",
        "sema_paperId": "73778d5f300958fc1b728905e3eb55c53ce590db"
    },
    {
        "@score": "1",
        "@id": "2332750",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "220/7449",
                        "text": "Lingjing Yu"
                    },
                    {
                        "@pid": "71/2890",
                        "text": "Bo Luo"
                    },
                    {
                        "@pid": "91/4845",
                        "text": "Jun Ma"
                    },
                    {
                        "@pid": "231/6078",
                        "text": "Zhaoyu Zhou"
                    },
                    {
                        "@pid": "47/9461",
                        "text": "Qingyun Liu"
                    }
                ]
            },
            "title": "You Are What You Broadcast: Identification of Mobile and IoT Devices from (Public) WiFi.",
            "venue": "USENIX Security Symposium",
            "pages": "55-72",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YuLMZL20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/yu",
            "url": "https://dblp.org/rec/conf/uss/YuLMZL20",
            "abstract": "With the rapid growth of mobile devices and WiFi hotspots, security risks arise. In practice, it is critical for administrators of corporate and public wireless networks to identify the type and/or model of devices connected to the network, in order to set access/firewall rules, to check for known vulnerabilities, or to configure IDS accordingly. Mobile devices are not obligated to report their detailed identities when they join a (public) wireless network, while adversaries could easily forge device attributes. In the literature, efforts have been made to utilize features from network traffic for device identification. In this paper, we present OWL, a novel device identification mechanism for both network administrators and normal users. We first extract network traffic features from passively received broadcast and multicast (BC/MC) packets. Embedding representations are learned to model features into six independent and complementary views. We then present a new multi-view wide and deep learning (MvWDL) framework that is optimized on both generalization performance and labelview interaction performance. Meanwhile, a malicious device detection mechanism is designed to assess the inconsistencies across views in the multi-view classifier to identify anomalies. Finally, we demonstrate OWL\u2019s performance through experiments, case studies, and qualitative analysis.",
            "keywords": [
                "Device Identification",
                "WiFi Security",
                "Network Traffic Analysis",
                "Malicious Device Detection",
                "Multi-View Learning"
            ]
        },
        "url": "URL#2332750",
        "sema_paperId": "06883ec4a92448a42b0bef5a51417fd3715ea273"
    },
    {
        "@score": "1",
        "@id": "2332751",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "248/3501",
                        "text": "Tai Yue"
                    },
                    {
                        "@pid": "90/4693-10",
                        "text": "Pengfei Wang 0010"
                    },
                    {
                        "@pid": "01/2880-5",
                        "text": "Yong Tang 0005"
                    },
                    {
                        "@pid": "70/8419",
                        "text": "Enze Wang"
                    },
                    {
                        "@pid": "75/2868-8",
                        "text": "Bo Yu 0008"
                    },
                    {
                        "@pid": "31/6932",
                        "text": "Kai Lu"
                    },
                    {
                        "@pid": "66/5686",
                        "text": "Xu Zhou"
                    }
                ]
            },
            "title": "EcoFuzz: Adaptive Energy-Saving Greybox Fuzzing as a Variant of the Adversarial Multi-Armed Bandit.",
            "venue": "USENIX Security Symposium",
            "pages": "2307-2324",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YueWTWYLZ20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/yue",
            "url": "https://dblp.org/rec/conf/uss/YueWTWYLZ20",
            "abstract": "Fuzzing is one of the most effective approaches for identifying security vulnerabilities. As a state-of-the-art coverage-based greybox fuzzer, AFL is a highly effective and widely used technique. However, AFL allocates excessive energy (i.e., the number of test cases generated by the seed) to seeds that exercise the high-frequency paths and can not adaptively adjust the energy allocation, thus wasting a signi\ufb01cant amount of energy. Moreover, the current Markov model for modeling coverage-based greybox fuzzing is not profound enough. This paper presents a variant of the Adversarial Multi-Armed Bandit model for modeling AFL\u2019s power schedule process. We \ufb01rst explain the challenges in AFL\u2019s scheduling algorithm by using the reward probability that generates a test case for discovering a new path. Moreover, we illustrated the three states of the seeds set and developed a unique adaptive scheduling algorithm as well as a probability-based search strategy. These approaches are implemented on top of AFL in an adaptive energy-saving greybox fuzzer called EcoFuzz. EcoFuzz is examined against other six AFL-type tools on 14 real-world subjects over 490 CPU days. According to the results, EcoFuzz could attain 214% of the path coverage of AFL with reducing 32% test cases generation of that of AFL. Besides, EcoFuzz identi\ufb01ed 12 vulnerabilities in GNU Binutils and other software. We also extended EcoFuzz to test some IoT devices and found a new vulnerability in the SNMP component.",
            "keywords": [
                "Greybox Fuzzing",
                "Energy Efficiency",
                "Adversarial Multi-Armed Bandit",
                "Path Coverage",
                "Vulnerability Discovery"
            ]
        },
        "url": "URL#2332751",
        "sema_paperId": "de4653ccb1712e9cb9d7471e71d33a09e7b8d8f4"
    },
    {
        "@score": "1",
        "@id": "2332752",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "119/7670",
                        "text": "Insu Yun"
                    },
                    {
                        "@pid": "237/9511",
                        "text": "Dhaval Kapil"
                    },
                    {
                        "@pid": "38/8882",
                        "text": "Taesoo Kim"
                    }
                ]
            },
            "title": "Automatic Techniques to Systematically Discover New Heap Exploitation Primitives.",
            "venue": "USENIX Security Symposium",
            "pages": "1111-1128",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YunKK20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/yun",
            "url": "https://dblp.org/rec/conf/uss/YunKK20",
            "abstract": "Heap exploitation techniques to abuse the metadata of allocators have been widely studied since they are application independent and can be used in restricted environments that corrupt only metadata. Although prior work has found several interesting exploitation techniques, they are ad-hoc and manual, which cannot effectively handle changes or a variety of allocators. \nIn this paper, we present a new naming scheme for heap exploitation techniques that systematically organizes them to discover the unexplored space in finding the techniques and ArcHeap, the tool that finds heap exploitation techniques automatically and systematically regardless of their underlying implementations. For that, ArcHeap generates a set of heap actions (e.g. allocation or deallocation) by leveraging fuzzing, which exploits common designs of modern heap allocators. Then, ArcHeap checks whether the actions result in impact of exploitations such as arbitrary write or overlapped chunks that efficiently determine if the actions can be converted into the exploitation technique. Finally, from these actions, ArcHeap generates Proof-of-Concept code automatically for an exploitation technique. \nWe evaluated ArcHeap with real-world allocators --- ptmalloc, jemalloc, and tcmalloc --- and custom allocators from the DARPA Cyber Grand Challenge. ArcHeap successfully found 14 out of 16 known exploitation techniques and found five new exploitation techniques in ptmalloc. Moreover, ArcHeap found several exploitation techniques for jemalloc, tcmalloc, and even for the custom allocators. Further, ArcHeap can automatically show changes in exploitation techniques along with version change in ptmalloc using differential testing.",
            "keywords": [
                "Heap Exploitation",
                "Memory Allocators",
                "Fuzzing",
                "Exploitation Techniques",
                "ArcHeap Tool"
            ]
        },
        "url": "URL#2332752",
        "sema_paperId": "89dbd5f282bae0317c0f85d64462b273dc27ebd7"
    },
    {
        "@score": "1",
        "@id": "2332753",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "29/2669-1",
                        "text": "Xinyang Zhang 0001"
                    },
                    {
                        "@pid": "232/2229",
                        "text": "Ningfei Wang"
                    },
                    {
                        "@pid": "09/3220",
                        "text": "Hua Shen"
                    },
                    {
                        "@pid": "07/8388",
                        "text": "Shouling Ji"
                    },
                    {
                        "@pid": "53/1565",
                        "text": "Xiapu Luo"
                    },
                    {
                        "@pid": "12/2633-6",
                        "text": "Ting Wang 0006"
                    }
                ]
            },
            "title": "Interpretable Deep Learning under Fire.",
            "venue": "USENIX Security Symposium",
            "pages": "1659-1676",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhangWSJL020",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/zhang-xinyang",
            "url": "https://dblp.org/rec/conf/uss/ZhangWSJL020",
            "abstract": "Providing explanations for deep neural network (DNN) models is crucial for their use in security-sensitive domains. A plethora of interpretation models have been proposed to help users understand the inner workings of DNNs: how does a DNN arrive at a specific decision for a given input? The improved interpretability is believed to offer a sense of security by involving human in the decision-making process. Yet, due to its data-driven nature, the interpretability itself is potentially susceptible to malicious manipulations, about which little is known thus far. \nHere we bridge this gap by conducting the first systematic study on the security of interpretable deep learning systems (IDLSes). We show that existing \\imlses are highly vulnerable to adversarial manipulations. Specifically, we present ADV^2, a new class of attacks that generate adversarial inputs not only misleading target DNNs but also deceiving their coupled interpretation models. Through empirical evaluation against four major types of IDLSes on benchmark datasets and in security-critical applications (e.g., skin cancer diagnosis), we demonstrate that with ADV^2 the adversary is able to arbitrarily designate an input's prediction and interpretation. Further, with both analytical and empirical evidence, we identify the prediction-interpretation gap as one root cause of this vulnerability -- a DNN and its interpretation model are often misaligned, resulting in the possibility of exploiting both models simultaneously. Finally, we explore potential countermeasures against ADV^2, including leveraging its low transferability and incorporating it in an adversarial training framework. Our findings shed light on designing and operating IDLSes in a more secure and informative fashion, leading to several promising research directions.",
            "keywords": [
                "Interpretable Deep Learning",
                "Adversarial Attacks",
                "Interpretation Models",
                "Prediction-Interpretation Gap",
                "Security Vulnerabilities"
            ]
        },
        "url": "URL#2332753",
        "sema_paperId": "6e85c80aae6457a76bb719c2d2d303abcc682a29"
    },
    {
        "@score": "1",
        "@id": "2332754",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "234/4023",
                        "text": "Mengya Zhang"
                    },
                    {
                        "@pid": "158/4724",
                        "text": "Xiaokuan Zhang"
                    },
                    {
                        "@pid": "77/3503",
                        "text": "Yinqian Zhang"
                    },
                    {
                        "@pid": "49/4102-1",
                        "text": "Zhiqiang Lin 0001"
                    }
                ]
            },
            "title": "TXSPECTOR: Uncovering Attacks in Ethereum from Transactions.",
            "venue": "USENIX Security Symposium",
            "pages": "2775-2792",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhangZZL20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/zhang-mengya",
            "url": "https://dblp.org/rec/conf/uss/ZhangZZL20",
            "abstract": "The invention of Ethereum smart contract has enabled the blockchain users to customize computing logic in transactions. However, similar to traditional computer programs, smart contracts have vulnerabilities, which can be exploited to cause \ufb01nancial loss of contract owners. While there are many software tools for detecting vulnerabilities in the smart contract bytecode, few have focused on transactions. In this paper, we propose T X S PECTOR , a generic, logic-driven framework to investigate Ethereum transactions for attack detection. At a high level, T X S PECTOR replays history transactions and records EVM bytecode-level traces, and then encodes the control and data dependencies into logic relations. Instead of setting a pre-de\ufb01ned set of functionalities, T X S PECTOR allows users to specify customized rules to uncover various types of attacks in the transactions. We have built a prototype of T X S PECTOR and evaluated it for the detection of three Ethereum attacks that exploit: ( i ) the Re-entrancy vulnerability, ( ii ) the UncheckedCall vulnerability, and ( iii ) the Suicidal vulnerability. The results demonstrate that T X S PECTOR can effectively detect attacks in the transactions and, as a byproduct, the corresponding vulnerabilities in the smart contracts. We also show how T X S PECTOR can be used for forensic analysis on transactions, and present Detection Rules for detecting other types of attacks in addition to the three focused Ethereum attacks.",
            "keywords": [
                "Ethereum Transactions",
                "Smart Contract Vulnerabilities",
                "Attack Detection",
                "Re-entrancy Vulnerability",
                "Forensic Analysis"
            ]
        },
        "url": "URL#2332754",
        "sema_paperId": "497333b72147b47bed7f6352a9456fc70447cc91"
    },
    {
        "@score": "1",
        "@id": "2332755",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "11/11005",
                        "text": "Xiaofeng Zheng"
                    },
                    {
                        "@pid": "223/6794",
                        "text": "Chaoyi Lu"
                    },
                    {
                        "@pid": "126/1801",
                        "text": "Jian Peng"
                    },
                    {
                        "@pid": "89/8437",
                        "text": "Qiushi Yang"
                    },
                    {
                        "@pid": "183/5826",
                        "text": "Dongjie Zhou"
                    },
                    {
                        "@pid": "89/10754",
                        "text": "Baojun Liu"
                    },
                    {
                        "@pid": "267/1308",
                        "text": "Keyu Man"
                    },
                    {
                        "@pid": "07/6713-1",
                        "text": "Shuang Hao 0001"
                    },
                    {
                        "@pid": "36/5143",
                        "text": "Haixin Duan"
                    },
                    {
                        "@pid": "31/8302",
                        "text": "Zhiyun Qian"
                    }
                ]
            },
            "title": "Poison Over Troubled Forwarders: A Cache Poisoning Attack Targeting DNS Forwarding Devices.",
            "venue": "USENIX Security Symposium",
            "pages": "577-593",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhengLPYZLMHDQ20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/zheng",
            "url": "https://dblp.org/rec/conf/uss/ZhengLPYZLMHDQ20",
            "abstract": "In today\u2019s DNS infrastructure, DNS forwarders are devices standing in between DNS clients and recursive resolvers. The devices often serve as ingress servers for DNS clients, and instead of resolving queries, they pass the DNS requests to other servers. Because of the advantages and several use cases, DNS forwarders are widely deployed and queried by Internet users. However, studies have shown that DNS for-warders can be more vulnerable devices in the DNS infrastructure. In this paper, we present a cache poisoning attack targeting DNS forwarders. Through this attack, attackers can inject rogue records of arbitrary victim domain names using a controlled domain, and circumvent widely-deployed cache poisoning defences. By performing tests on popular home router models and DNS software, we \ufb01nd several vulnerable implementations, including those of large vendors (e.g., D-Link, Linksys, dnsmasq and MS DNS). Further, through a nationwide measurement, we estimate the population of Chinese mobile clients which are using vulnerable DNS for-warders. We have been reporting the issue to the affected vendors, and so far have received positive feedback from three of them. Our work further demonstrates that DNS for-warders can be a soft spot in the DNS infrastructure, and calls for attention as well as implementation guidelines from the community.",
            "keywords": [
                "DNS Forwarding",
                "Cache Poisoning",
                "DNS Vulnerabilities",
                "Rogue Records",
                "Network Security"
            ]
        },
        "url": "URL#2332755",
        "sema_paperId": "a0ac3769ac83aab7b1a32c5b00a9f427c534565a"
    },
    {
        "@score": "1",
        "@id": "2332756",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "00/5012-22",
                        "text": "Jie Zhou 0022"
                    },
                    {
                        "@pid": "126/6581",
                        "text": "Yufei Du"
                    },
                    {
                        "@pid": "219/9076",
                        "text": "Zhuojia Shen"
                    },
                    {
                        "@pid": "207/9117",
                        "text": "Lele Ma"
                    },
                    {
                        "@pid": "03/2122",
                        "text": "John Criswell"
                    },
                    {
                        "@pid": "17/9458",
                        "text": "Robert J. Walls"
                    }
                ]
            },
            "title": "Silhouette: Efficient Protected Shadow Stacks for Embedded Systems.",
            "venue": "USENIX Security Symposium",
            "pages": "1219-1236",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhouDSMCW20",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/zhou-jie",
            "url": "https://dblp.org/rec/conf/uss/ZhouDSMCW20",
            "abstract": "Microcontroller-based embedded systems are increasingly used for applications that can have serious and immediate consequences if compromised--including automobile control systems, smart locks, drones, and implantable medical devices. Due to resource and execution-time constraints, C is the primary language used for programming these devices. Unfortunately, C is neither type-safe nor memory-safe, and control-flow hijacking remains a prevalent threat. This paper presents Silhouette: a compiler-based defense that efficiently guarantees the integrity of return addresses--significantly reducing the attack surface for control-flow hijacking. Silhouette provides an incorruptible shadow stack for return addresses using special store instructions found on ARM processors. Specifically, Silhouette transforms regular store instructions into unprivileged equivalents, restricting the untrusted subset of the program's memory accesses to unprivileged memory while simultaneously allowing security instrumentation to access security-critical data structures--all without the need for expensive context switching, hardware changes, or information hiding. Combined with its checks on forward control flow and memory access configuration, Silhouette ensures that all functions return to the correct caller. We implemented Silhouette for the ARMv7-M architecture, but our techniques are applicable to other common embedded ARM architectures. Our evaluation shows that Silhouette incurs a geometric mean of 1.2% and 3.6% performance overhead on two benchmark suites. Furthermore, we prototyped Silhouette-Invert, an alternative implementation of Silhouette, which incurs just 0.2% and 1.9% performance overhead, at the cost of a minor hardware change.",
            "keywords": [
                "Embedded Systems Security",
                "Control-Flow Hijacking",
                "Shadow Stack",
                "Compiler-based Defense",
                "ARM Architecture"
            ]
        },
        "url": "URL#2332756",
        "sema_paperId": "155c5022ae8ea4fee965c9f59fa0bd9106cb6bdc"
    },
    {
        "@score": "1",
        "@id": "2332757",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "167/0431",
                        "text": "Shunfan Zhou"
                    },
                    {
                        "@pid": "55/11040",
                        "text": "Zhemin Yang"
                    },
                    {
                        "@pid": "87/11054",
                        "text": "Jie Xiang"
                    },
                    {
                        "@pid": "28/8733",
                        "text": "Yinzhi Cao"
                    },
                    {
                        "@pid": "02/1640-2",
                        "text": "Min Yang 0002"
                    },
                    {
                        "@pid": "48/2168-9",
                        "text": "Yuan Zhang 0009"
                    }
                ]
            },
            "title": "An Ever-evolving Game: Evaluation of Real-world Attacks and Defenses in Ethereum Ecosystem.",
            "venue": "USENIX Security Symposium",
            "pages": "2793-2810",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhouYXCY020",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/zhou-shunfan",
            "url": "https://dblp.org/rec/conf/uss/ZhouYXCY020",
            "abstract": "Smart contract security has drawn much attention due to many severe incidents with huge ether and token losses. As a consequence, researchers have proposed to detect smart contract vulnerabilities via code analysis. However, code analysis only shows what contracts can be attacked, but not what have been attacked, and more importantly, what attacks have been prevented in the real world. In this paper, we present the \ufb01rst comprehensive measurement study to analyze real-world attacks and defenses adopted in the wild based on the transaction logs produced by unin-strumented Ethereum Virtual Machine (EVM). Speci\ufb01cally, our study decouples two important factors of an adversarial transaction\u2014i.e., (i) an adversarial action exploiting the vulnerable contract and (ii) an adversarial consequence like ether or token transfers resulted from the action\u2014for the analysis of attacks and defenses. The results of our study reveal a huge volume of attacks beyond what have been studied in the literature, e.g., those targeting new vulnerability types like airdrop hunting and those targeting zero-day variants of known vulnerabilities. Besides successful attacks, our study also shows attempted attacks that are prevented due to the deployments of defenses. As the nature of cyber-security, those defenses have also been evaded, mainly due to incomplete defense deployments. To summarize it, we believe that this is an ever-evolving game between adversaries obtaining illegal pro\ufb01ts and defenders shielding their own contracts.",
            "keywords": [
                "Smart Contract Security",
                "Ethereum Ecosystem",
                "Real-world Attacks",
                "Defense Mechanisms",
                "Vulnerability Analysis"
            ]
        },
        "url": "URL#2332757",
        "sema_paperId": "0ba3dcc4306012a277fcb41173beb36db4bc620f"
    },
    {
        "@score": "1",
        "@id": "2332758",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "189/8669",
                        "text": "Shuofei Zhu"
                    },
                    {
                        "@pid": "76/3568",
                        "text": "Jianjun Shi"
                    },
                    {
                        "@pid": "06/6358",
                        "text": "Limin Yang"
                    },
                    {
                        "@pid": "256/7750",
                        "text": "Boqin Qin"
                    },
                    {
                        "@pid": "40/9956",
                        "text": "Ziyi Zhang"
                    },
                    {
                        "@pid": "55/7502",
                        "text": "Linhai Song"
                    },
                    {
                        "@pid": "71/4292-11",
                        "text": "Gang Wang 0011"
                    }
                ]
            },
            "title": "Measuring and Modeling the Label Dynamics of Online Anti-Malware Engines.",
            "venue": "USENIX Security Symposium",
            "pages": "2361-2378",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhuSYQZS020",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/zhu",
            "url": "https://dblp.org/rec/conf/uss/ZhuSYQZS020",
            "abstract": "VirusTotal provides malware labels from a large set of anti-malware engines, and is heavily used by researchers for malware annotation and system evaluation. Since different engines often disagree with each other, researchers have used various methods to aggregate their labels. In this paper, we take a data-driven approach to categorize, reason, and validate common labeling methods used by researchers. We \ufb01rst survey 115 academic papers that use VirusTotal, and identify common methodologies. Then we collect the daily snapshots of VirusTotal labels for more than 14,000 \ufb01les (including a subset of manually veri\ufb01ed ground-truth) from 65 VirusTotal engines over a year. Our analysis validates the bene\ufb01ts of threshold-based label aggregation in stabilizing \ufb01les\u2019 labels, and also points out the impact of poorly-chosen thresholds. We show that hand-picked \u201ctrusted\u201d engines do not always perform well, and certain groups of engines are strongly correlated and should not be treated independently. Finally, we empirically show certain engines fail to perform in-depth analysis on submitted \ufb01les and can easily produce false positives. Based on our \ufb01ndings, we offer suggestions for future usage of VirusTotal for data annotation.",
            "keywords": [
                "Online Anti-Malware Engines",
                "VirusTotal",
                "Label Aggregation",
                "Malware Annotation",
                "Label Dynamics"
            ]
        },
        "url": "URL#2332758",
        "sema_paperId": "3a443ab720f73ae72f44ca54b6ef30648c543b3a"
    },
    {
        "@score": "1",
        "@id": "2332759",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "198/1504",
                        "text": "Peiyuan Zong"
                    },
                    {
                        "@pid": "69/5034",
                        "text": "Tao Lv"
                    },
                    {
                        "@pid": "39/2537-21",
                        "text": "Dawei Wang 0021"
                    },
                    {
                        "@pid": "272/7174",
                        "text": "Zizhuang Deng"
                    },
                    {
                        "@pid": "232/3062",
                        "text": "Ruigang Liang"
                    },
                    {
                        "@pid": "c/KaiChen12",
                        "text": "Kai Chen 0012"
                    }
                ]
            },
            "title": "FuzzGuard: Filtering out Unreachable Inputs in Directed Grey-box Fuzzing through Deep Learning.",
            "venue": "USENIX Security Symposium",
            "pages": "2255-2269",
            "year": "2020",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZongLWDL020",
            "ee": "https://www.usenix.org/conference/usenixsecurity20/presentation/zong",
            "url": "https://dblp.org/rec/conf/uss/ZongLWDL020",
            "abstract": "Recently, directed grey-box fuzzing (DGF) becomes popular in the \ufb01eld of software testing. Different from coverage-based fuzzing whose goal is to increase code coverage for triggering more bugs, DGF is designed to check whether a piece of potentially buggy code (e.g., string operations) really contains a bug. Ideally, all the inputs generated by DGF should reach the target buggy code until triggering the bug. It is a waste of time when executing with unreachable inputs. Unfortunately, in real situations, large numbers of the generated inputs cannot let a program execute to the target, greatly impacting the ef\ufb01ciency of fuzzing, especially when the buggy code is embedded in the code guarded by various constraints. In this paper, we propose a deep-learning-based approach to predict the reachability of inputs (i.e., miss the target or not) before executing the target program, helping DGF \ufb01ltering out the unreachable ones to boost the performance of fuzzing. To apply deep learning with DGF, we design a suite of new techniques (e.g., step-forwarding approach , representative data selection ) to solve the problems of unbalanced labeled data and insuf\ufb01cient time in the training process. Further, we implement the proposed approach called FuzzGuard and equip it with the state-of-the-art DGF (e.g., AFLGo). Evaluations on 45 real vulnerabilities show that FuzzGuard boosts the fuzzing ef\ufb01ciency",
            "keywords": [
                "Directed Grey-box Fuzzing",
                "Input Reachability",
                "Fuzzing Efficiency",
                "Deep Learning Prediction",
                "Unreachable Inputs Filtering"
            ]
        },
        "url": "URL#2332759",
        "sema_paperId": "fdb33a33e73799da546ac4e807e857fe3ad15af5"
    },
    {
        "@score": "1",
        "@id": "2345320",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "51/1639",
                        "text": "Srdjan Capkun"
                    },
                    {
                        "@pid": "23/2758",
                        "text": "Franziska Roesner"
                    }
                ]
            },
            "title": "29th USENIX Security Symposium, USENIX Security 2020, August 12-14, 2020",
            "venue": "USENIX Security Symposium",
            "publisher": "USENIX Association",
            "year": "2020",
            "type": "Editorship",
            "access": "open",
            "key": "conf/uss/2020",
            "ee": "https://www.usenix.org/conference/usenixsecurity20",
            "url": "https://dblp.org/rec/conf/uss/2020",
            "abstract": null
        },
        "url": "URL#2345320",
        "sema_paperId": "819a2bf88a639652e3a0e64eca971ad3a9f615de"
    }
]