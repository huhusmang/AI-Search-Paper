[
    {
        "@score": "1",
        "@id": "1887998",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "90/545-1",
                        "text": "Zhikun Zhang 0001"
                    },
                    {
                        "@pid": "145/3288-1",
                        "text": "Tianhao Wang 0001"
                    },
                    {
                        "@pid": "l/NinghuiLi",
                        "text": "Ninghui Li"
                    },
                    {
                        "@pid": "09/4857",
                        "text": "Jean Honorio"
                    },
                    {
                        "@pid": "b/MichaelBackes1",
                        "text": "Michael Backes 0001"
                    },
                    {
                        "@pid": "07/7178",
                        "text": "Shibo He"
                    },
                    {
                        "@pid": "55/2484-1",
                        "text": "Jiming Chen 0001"
                    },
                    {
                        "@pid": "06/6785-16",
                        "text": "Yang Zhang 0016"
                    }
                ]
            },
            "title": "PrivSyn: Differentially Private Data Synthesis.",
            "venue": "USENIX Security Symposium",
            "pages": "929-946",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/00010LH0H0021",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/zhang-zhikun",
            "url": "https://dblp.org/rec/conf/uss/00010LH0H0021",
            "abstract": "In differential privacy (DP), a challenging problem is to generate synthetic datasets that efficiently capture the useful information in the private data.  The synthetic dataset enables any task to be done without privacy concern and modification to existing algorithms.  In this paper, we present PrivSyn, the first automatic synthetic data generation method that can handle general tabular datasets (with 100 attributes and domain size > 2500). PrivSyn is composed of a new method to automatically and privately identify correlations in the data, and a novel method to generate sample data from a dense graphic model.  We extensively evaluate different methods on multiple datasets to demonstrate the performance of our method.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-zhang-zhikun.pdf",
            "keywords": [
                "Differential Privacy",
                "Synthetic Data Generation",
                "Data Synthesis",
                "Tabular Datasets",
                "Correlation Identification"
            ]
        },
        "url": "URL#1887998"
    },
    {
        "@score": "1",
        "@id": "1887999",
        "info": {
            "authors": {
                "author": {
                    "@pid": "44/6965",
                    "text": "Susan Landau 0001"
                }
            },
            "title": "Susan Landau, Tufts University.",
            "venue": "USENIX Security Symposium",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/000121",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/keynote-landau",
            "url": "https://dblp.org/rec/conf/uss/000121",
            "abstract": "Dr. Anthony Fauci ticked off the timeline: \"First notice at the end of December, hit China in January, hit the rest of the world in February, March, April, May, early June.\" COVID spread like wildfire. This disease turned out to be Fauci's \"worst nightmare.\"\nPandemics end because we shut down the infection source, eradicate it, or vaccinate against it.  But if these techniques don't work, then we contact trace. For COVID-19, a disease that spreads presymptomically and respiratorily, contact-tracing apps seem to be an optimal way to harness technology in stopping spread.\nApps were launched in Singapore beginning in March 2020, privacy-protective apps made their appearance in Europe and the US beginning in June. In some locations, the apps are effectively required, but where they are not, adoption is low. What's going on? Are the apps efficacious? And if so, why aren't they being used?\nIs this a security failure? A privacy failure? A usability issue?  The next pandemic will be different from COVID-19. Now is the time to learn what medical and social interventions we should make.",
            "pdf_url": "",
            "keywords": [
                "Pandemic Response",
                "Contact Tracing",
                "COVID-19",
                "Privacy Protection",
                "App Adoption Issues"
            ]
        },
        "url": "URL#1887999",
        "sema_paperId": "5c32b7bd65907fccd6e301f709bbf81c8a81f1d5"
    },
    {
        "@score": "1",
        "@id": "1888000",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "186/5066",
                        "text": "Kevin Bock 0001"
                    },
                    {
                        "@pid": "301/5908",
                        "text": "Abdulrahman Alaraj"
                    },
                    {
                        "@pid": "273/6852",
                        "text": "Yair Fax"
                    },
                    {
                        "@pid": "301/5903",
                        "text": "Kyle Hurley"
                    },
                    {
                        "@pid": "60/8733",
                        "text": "Eric Wustrow"
                    },
                    {
                        "@pid": "03/6428",
                        "text": "Dave Levin"
                    }
                ]
            },
            "title": "Weaponizing Middleboxes for TCP Reflected Amplification.",
            "venue": "USENIX Security Symposium",
            "pages": "3345-3361",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0001AFHWL21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/bock",
            "url": "https://dblp.org/rec/conf/uss/0001AFHWL21",
            "abstract": "Re\ufb02ective ampli\ufb01cation attacks are a powerful tool in the arsenal of a DDoS attacker, but to date have almost exclusively targeted UDP-based protocols. In this paper, we demonstrate that non-trivial TCP-based ampli\ufb01cation is possible and can be orders of magnitude more effective than well-known UDP-based ampli\ufb01cation. By taking advantage of TCP-non-compliance in network middleboxes, we show that attackers can induce middleboxes to respond and amplify network traf-\ufb01c. With the novel application of a recent genetic algorithm, we discover and maximize the ef\ufb01cacy of new TCP-based re\ufb02ective ampli\ufb01cation attacks, and present several packet sequences that cause network middleboxes to respond with substantially more packets than we send. We scanned the entire IPv4 Internet to measure how many IP addresses permit re\ufb02ected ampli\ufb01cation. We \ufb01nd hundreds of thousands of IP addresses that offer ampli\ufb01cation factors greater than 100 \u00d7 . Through our Internet-wide measurements, we explore several open questions regarding DoS attacks, including the root cause of so-called \u201cmega ampli\ufb01ers\u201d. We also report on network phenomena that causes some of the TCP-based attacks to be so effective as to technically have in\ufb01nite ampli\ufb01cation factor (after the attacker sends a constant number of bytes, the re\ufb02ector generates traf\ufb01c inde\ufb01nitely). We have made our code publicly available.",
            "keywords": [
                "DDoS Attacks",
                "TCP Amplification",
                "Reflective Amplification",
                "Network Middleboxes",
                "Mega Amplifiers"
            ]
        },
        "url": "URL#1888000",
        "sema_paperId": "114fd91c1a1731ab0ca9908782ee90934d6b5426"
    },
    {
        "@score": "1",
        "@id": "1888001",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "133/5336-1",
                        "text": "Chong Xiang 0001"
                    },
                    {
                        "@pid": "199/2164",
                        "text": "Arjun Nitin Bhagoji"
                    },
                    {
                        "@pid": "187/5613",
                        "text": "Vikash Sehwag"
                    },
                    {
                        "@pid": "39/6266",
                        "text": "Prateek Mittal"
                    }
                ]
            },
            "title": "PatchGuard: A Provably Robust Defense against Adversarial Patches via Small Receptive Fields and Masking.",
            "venue": "USENIX Security Symposium",
            "pages": "2237-2254",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0001BSM21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/xiang",
            "url": "https://dblp.org/rec/conf/uss/0001BSM21",
            "abstract": "Localized adversarial patches aim to induce misclassification in machine learning models by arbitrarily modifying pixels within a restricted region of an image. Such attacks can be realized in the physical world by attaching the adversarial patch to the object to be misclassified, and defending against such attacks is an unsolved/open problem. In this paper, we propose a general defense framework called PatchGuard that can achieve high provable robustness while maintaining high clean accuracy against localized adversarial patches. The cornerstone of PatchGuard involves the use of CNNs with small receptive fields to impose a bound on the number of features corrupted by an adversarial patch. Given a bounded number of corrupted features, the problem of designing an adversarial patch defense reduces to that of designing a secure feature aggregation mechanism. Towards this end, we present our robust masking defense that robustly detects and masks corrupted features to recover the correct prediction. Notably, we can prove the robustness of our defense against any adversary within our threat model. Our extensive evaluation on ImageNet, ImageNette (a 10-class subset of ImageNet), and CIFAR-10 datasets demonstrates that our defense achieves state-of-the-art performance in terms of both provable robust accuracy and clean accuracy.",
            "keywords": [
                "Adversarial Patches",
                "Robustness",
                "Feature Aggregation",
                "Masking Defense",
                "Localized Attacks"
            ]
        },
        "url": "URL#1888001",
        "sema_paperId": "68560fdb5a93b3cb416e96babd86a0f8c0f9a8b1"
    },
    {
        "@score": "1",
        "@id": "1888002",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "166/8773-1",
                        "text": "Lorenzo Grassi 0001"
                    },
                    {
                        "@pid": "22/2499",
                        "text": "Dmitry Khovratovich"
                    },
                    {
                        "@pid": "39/16",
                        "text": "Christian Rechberger"
                    },
                    {
                        "@pid": "88/4138-5",
                        "text": "Arnab Roy 0005"
                    },
                    {
                        "@pid": "227/7790",
                        "text": "Markus Schofnegger"
                    }
                ]
            },
            "title": "Poseidon: A New Hash Function for Zero-Knowledge Proof Systems.",
            "venue": "USENIX Security Symposium",
            "pages": "519-535",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0001KR0S21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/grassi",
            "url": "https://dblp.org/rec/conf/uss/0001KR0S21",
            "abstract": "The area of practical computational integrity proof systems, like SNARKs, STARKs, Bulletproofs, is seeing a very dynamic development with several constructions having appeared recently with improved properties and relaxed setup requirements. Many use cases of such systems involve, often as their most expensive part, proving the knowledge of a preimage under a certain cryptographic hash function, which is expressed as a circuit over a large prime \ufb01eld. A notable example is a zero-knowledge proof of coin ownership in the Zcash cryptocurrency, where the inadequacy of the SHA-256 hash function for such a circuit caused a huge computational penalty. In this paper, we present a modular framework and concrete instances of cryptographic hash functions which work natively with GF ( p ) objects. Our hash function P OSEIDON uses up to 8x fewer constraints per message bit than Pedersen Hash. Our construction is not only expressed compactly as a circuit, but can also be tailored for various proof systems using specially crafted polynomials, thus bringing another boost in performance. We demonstrate this by implementing a 1-out-of-a-billion membership proof with Merkle trees in less than a second by using Bulletproofs.",
            "keywords": [
                "Cryptographic Hash Functions",
                "Zero-Knowledge Proofs",
                "SNARKs",
                "Performance Optimization",
                "Poseidon Hash Function"
            ]
        },
        "url": "URL#1888002",
        "sema_paperId": "56fb9ca04c3c6c0a1b972d7b4d825ebcda81c459"
    },
    {
        "@score": "1",
        "@id": "1888003",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "243/2583-1",
                        "text": "Daniel Perez 0001"
                    },
                    {
                        "@pid": "46/2924",
                        "text": "Benjamin Livshits"
                    }
                ]
            },
            "title": "Smart Contract Vulnerabilities: Vulnerable Does Not Imply Exploited.",
            "venue": "USENIX Security Symposium",
            "pages": "1325-1341",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0001L21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/perez",
            "url": "https://dblp.org/rec/conf/uss/0001L21",
            "abstract": "In recent years, we have seen a great deal of both academic and practical interest in the topic of vulnerabilities in smart contracts, particularly those developed for the Ethereum blockchain. While most of the work has focused on detecting vulnerable contracts, in this paper, we focus on \ufb01nding how many of these vulnerable contracts have actually been exploited . We survey the 23,327 vulnerable contracts reported by six recent academic projects and \ufb01nd that, despite the amounts at stake, only 1.98% of them have been exploited since deployment. This corresponds to at most 8,487 ETH (~1.7 million USD 1 ), or only 0.27% of the 3 million ETH (600 million USD) at stake. We explain these results by demonstrating that the funds are very concentrated in a small number of contracts which are not exploitable in practice.",
            "keywords": [
                "Smart Contract Vulnerabilities",
                "Ethereum Blockchain",
                "Exploitation Analysis",
                "Vulnerable Contracts",
                "Fund Concentration"
            ]
        },
        "url": "URL#1888003",
        "sema_paperId": "7a6c6756655c18cfd9ecbe529ae62a557ffbbd94"
    },
    {
        "@score": "1",
        "@id": "1888004",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "84/8554-1",
                        "text": "Wanrong Zhang 0001"
                    },
                    {
                        "@pid": "136/8442",
                        "text": "Shruti Tople"
                    },
                    {
                        "@pid": "70/4765",
                        "text": "Olga Ohrimenko"
                    }
                ]
            },
            "title": "Leakage of Dataset Properties in Multi-Party Machine Learning.",
            "venue": "USENIX Security Symposium",
            "pages": "2687-2704",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0001TO21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/zhang-wanrong",
            "url": "https://dblp.org/rec/conf/uss/0001TO21",
            "abstract": "Secure multi-party machine learning allows several parties to build a model on their pooled data to increase utility while not explicitly sharing data with each other. We show that such multi-party computation can cause leakage of global dataset properties between the parties even when parties obtain only black-box access to the final model. In particular, a ``curious'' party can infer the distribution of sensitive attributes in other parties' data with high accuracy. This raises concerns regarding the confidentiality of properties pertaining to the whole dataset as opposed to individual data records. We show that our attack can leak population-level properties in datasets of different types, including tabular, text, and graph data. To understand and measure the source of leakage, we consider several models of correlation between a sensitive attribute and the rest of the data. Using multiple machine learning models, we show that leakage occurs even if the sensitive attribute is not included in the training data and has a low correlation with other attributes or the target variable.",
            "keywords": [
                "Multi-Party Machine Learning",
                "Data Confidentiality",
                "Dataset Property Leakage",
                "Sensitive Attribute Inference",
                "Population-Level Properties"
            ]
        },
        "url": "URL#1888004",
        "sema_paperId": "f835f21a43365c9ce6fecb9ee708d93510e5ea3c"
    },
    {
        "@score": "1",
        "@id": "1888005",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "58/2521-2",
                        "text": "Chenglong Fu 0002"
                    },
                    {
                        "@pid": "81/583-1",
                        "text": "Qiang Zeng 0001"
                    },
                    {
                        "@pid": "22/5535",
                        "text": "Xiaojiang Du"
                    }
                ]
            },
            "title": "HAWatcher: Semantics-Aware Anomaly Detection for Appified Smart Homes.",
            "venue": "USENIX Security Symposium",
            "pages": "4223-4240",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/00020D21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/fu-chenglong",
            "url": "https://dblp.org/rec/conf/uss/00020D21",
            "abstract": "As IoT devices are integrated via automation and coupled with the physical environment, anomalies in an appified smart home, whether due to attacks or device malfunctions, may lead to severe consequences. Priorworks that utilize data mining techniques to detect anomalies suffer from high false alarm rates and missing many real anomalies. Our observation is that data mining-based approaches miss a large chunk of information about automation programs (also called smart apps ) and devices. We propose Home Automation Watcher (HAWatcher), a semantics-aware anomaly detection system for appified smart homes. HAWatcher models a smart home\u2019s normal behaviors based on both event logs and semantics. Given a home, HAWatcher generates hypothetical correlations according to semantic information, such as apps, device types, relations and installation locations, and verifies them with event logs. The mined correlations are refined using correlations extracted from the installed smart apps. The refined correlations are used by a Shadow Execution engine to simulate the smart home\u2019s normal behaviors. During run-time, inconsistencies between devices\u2019 real-world states and simulated states are reported as anomalies. We evaluate our prototype on the SmartThings platform in four real-world testbeds and test it against totally 62 different anomaly cases. The results show that HAWatcher achieves high accuracy, significantly outperforming prior approaches.",
            "keywords": [
                "Smart Home Automation",
                "Anomaly Detection",
                "IoT Device Management",
                "Semantics-Aware Monitoring",
                "Event Log Analysis"
            ]
        },
        "url": "URL#1888005",
        "sema_paperId": "b36c6cd1725016f736ad0e6f8f4092a97dd7a34f"
    },
    {
        "@score": "1",
        "@id": "1888006",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "125/3714-2",
                        "text": "Hang Hu 0002"
                    },
                    {
                        "@pid": "175/5282",
                        "text": "Steve T. K. Jan"
                    },
                    {
                        "@pid": "w/YangWang5",
                        "text": "Yang Wang 0005"
                    },
                    {
                        "@pid": "71/4292-11",
                        "text": "Gang Wang 0011"
                    }
                ]
            },
            "title": "Assessing Browser-level Defense against IDN-based Phishing.",
            "venue": "USENIX Security Symposium",
            "pages": "3739-3756",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0002JW021",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/hu-hang",
            "url": "https://dblp.org/rec/conf/uss/0002JW021",
            "abstract": "Internationalized Domain Names (IDN) allow people around the world to use their native languages for domain names. Unfortunately, because characters from different languages can look like each other, IDNs have been used to imperson-ate popular domains for phishing, i.e. , IDN homograph. To mitigate this risk, browsers have recently introduced defense policies. However, it is not yet well understood regarding how these policies are constructed and how effective they are. In this paper, we present an empirical analysis of browser IDN policies, and a user study to understand user perception of homograph IDNs. We focus on 5 major web browsers (Chrome, Firefox, Safari, Microsoft Edge, and IE), and 2 mobile browsers (Android Chrome and iOS Safari) and analyze their current and historical versions released from January 2015 to April 2020. By treating each browser instance as a black box, we develop an automated tool to test the browser policies with over 9,000 testing cases. We \ufb01nd that all the tested browsers have weaknesses in their rules, leaving opportunities for attackers to craft homograph IDNs to impersonate target websites while bypassing browsers\u2019 defense. In addition, a browser\u2019s defense is not always getting stricter over time. For example, we observe Chrome has reversed its rules to re-allow certain homograph IDNs. Finally, our user study shows that the homograph IDNs that can bypass browsers\u2019 defense are still highly deceptive to users. Overall, our results suggest the need to improve the current defense against IDN homograph.",
            "keywords": [
                "Internationalized Domain Names (IDN)",
                "Phishing",
                "Homograph Attacks",
                "Browser Defense Policies",
                "User Perception"
            ]
        },
        "url": "URL#1888006",
        "sema_paperId": "68b05f7cc9489de4e59add73879c7d4ffa339b57"
    },
    {
        "@score": "1",
        "@id": "1888007",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "190/3392-2",
                        "text": "Bingyu Shen 0002"
                    },
                    {
                        "@pid": "47/5973",
                        "text": "Lili Wei"
                    },
                    {
                        "@pid": "137/8952",
                        "text": "Chengcheng Xiang"
                    },
                    {
                        "@pid": "141/4725",
                        "text": "Yudong Wu"
                    },
                    {
                        "@pid": "252/3943",
                        "text": "Mingyao Shen"
                    },
                    {
                        "@pid": "99/2747-1",
                        "text": "Yuanyuan Zhou 0001"
                    },
                    {
                        "@pid": "96/8378",
                        "text": "Xinxin Jin"
                    }
                ]
            },
            "title": "Can Systems Explain Permissions Better? Understanding Users&apos; Misperceptions under Smartphone Runtime Permission Model.",
            "venue": "USENIX Security Symposium",
            "pages": "751-768",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0002WXWS0J21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/shen-bingyu",
            "url": "https://dblp.org/rec/conf/uss/0002WXWS0J21",
            "abstract": ". Abstract Current smartphone operating systems enable users to manage permissions according to their personal preferences with a runtime permission model. Nonetheless, the systems provide very limited information when requesting permissions, making it dif\ufb01cult for users to understand permissions\u2019 capabilities and potentially induced risks. In this paper, we \ufb01rst investigated to what extent current system-provided information can help users understand the scope of permissions and their potential risks. We took a mixed-methods approach by collecting real permission settings from 4,636 Android users, an interview study of 20 participants, and large-scale Internet surveys of 1559 users. Our study identi\ufb01ed several common misunderstandings on the runtime permission model among users. We found that only a very small percentage (6.1%) of users can infer the scope of permission groups accurately from the system-provided information. This indicates that the information provided by current systems is far from suf\ufb01cient. We thereby explored what extra information that systems can provide to help users make more informed permission decisions. By surveying users\u2019 common concerns on apps\u2019 permission requests, we identi\ufb01ed \ufb01ve types of information (i.e., decision factors) that are helpful for users\u2019 decisions. We further studied the impact and helpfulness of the factors to users\u2019 permission decisions with both positive and negative messages. Our study shows that the background access factor helps most while the grant rate helps the least. Based on the \ufb01ndings, we provide suggestions for system designers to enhance future systems with more permission information.",
            "keywords": [
                "Smartphone Permissions",
                "Runtime Permission Model",
                "User Misunderstandings",
                "Permission Decision Factors",
                "User Awareness"
            ]
        },
        "url": "URL#1888007",
        "sema_paperId": "c3db98a70c74afec2c6b598d8b1d8626d0062849"
    },
    {
        "@score": "1",
        "@id": "1888008",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "29/6643-10",
                        "text": "Jie Huang 0010"
                    },
                    {
                        "@pid": "b/MichaelBackes1",
                        "text": "Michael Backes 0001"
                    },
                    {
                        "@pid": "31/7561",
                        "text": "Sven Bugiel"
                    }
                ]
            },
            "title": "A11y and Privacy don&apos;t have to be mutually exclusive: Constraining Accessibility Service Misuse on Android.",
            "venue": "USENIX Security Symposium",
            "pages": "3631-3648",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/00100B21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/huang",
            "url": "https://dblp.org/rec/conf/uss/00100B21",
            "abstract": "Accessibility features of Android are crucial in assisting people with disabilities or impairment to navigate their devices. However, the same, powerful features are commonly misused by shady apps for malevolent purposes, such as stealing data from other apps. Unfortunately, existing defenses do not allow apps to protect themselves and at the same time to be fully inclusive to users with accessibility needs. \nTo enhance the privacy protection of the user while preserving the accessibility features for assistive apps, we introduce an extension to Android\u2019s accessibility framework. Our design is based on a study of how accessibility features are used in 95 existing accessibility apps of different types (malware, utility, and a11y). Based on those insights, we propose to model the usage of the accessibility framework as a pipeline of code modules, which are all sandboxed on the system-side. By policing the data flows of those modules, we achieve a more fine-grained control over the access to accessibility features and the way they are used in apps, allowing a balance between accessibility functionality for dependent users and reduced privacy risks. We demonstrate the feasibility of our solution by migrating two real-world apps to our privacy-enhanced accessibility framework.",
            "keywords": [
                "Android Accessibility",
                "Privacy Protection",
                "Accessibility Service Misuse",
                "Assistive Apps",
                "Data Flow Control"
            ]
        },
        "url": "URL#1888008",
        "sema_paperId": "aeb92795c66da5cba98da7ea3be7cee28fa9f5c8"
    },
    {
        "@score": "1",
        "@id": "1888009",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "69/5011-26",
                        "text": "Wei Zhou 0026"
                    },
                    {
                        "@pid": "137/5266",
                        "text": "Le Guan"
                    },
                    {
                        "@pid": "21/6121-5",
                        "text": "Peng Liu 0005"
                    },
                    {
                        "@pid": "83/6530-1",
                        "text": "Yuqing Zhang 0001"
                    }
                ]
            },
            "title": "Automatic Firmware Emulation through Invalidity-guided Knowledge Inference.",
            "venue": "USENIX Security Symposium",
            "pages": "2007-2024",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0026G0Z21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/zhou",
            "url": "https://dblp.org/rec/conf/uss/0026G0Z21",
            "abstract": "Emulating firmware for microcontrollers is challenging due to the tight coupling between the hardware and firmware. This has greatly impeded the application of dynamic analysis tools to firmware analysis. The state-of-the-art work automatically models unknown peripherals by observing their access patterns, and then leverages heuristics to calculate the appropriate responses when unknown peripheral registers are accessed. However, we empirically found that this approach and the corresponding heuristics are frequently insufficient to emulate firmware. In this work, we propose a new approach called uEmu to emulate firmware with unknown peripherals. Unlike existing work that attempts to build a general model for each peripheral, our approach learns how to correctly emulate firmware execution at individual peripheral access points. It takes the image as input and symbolically executes it by representing unknown peripheral registers as symbols. During symbolic execution, it infers the rules to respond to unknown peripheral accesses. These rules are stored in a knowledge base, which is referred to during the dynamic firmware analysis. uEmu achieved a passing rate of 95% in a set of unit tests for peripheral drivers without any manual assistance. We also evaluated uEmu with real-world firmware samples and new bugs were discovered.",
            "keywords": [
                "Firmware Emulation",
                "Microcontroller Analysis",
                "Dynamic Analysis Tools",
                "Peripheral Access Modeling",
                "Knowledge Inference"
            ]
        },
        "url": "URL#1888009",
        "sema_paperId": "2012e124acee13a6071571438fffdc638e0fb769"
    },
    {
        "@score": "1",
        "@id": "1888010",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "65/4423-57",
                        "text": "Chen Chen 0057"
                    },
                    {
                        "@pid": "157/8155",
                        "text": "Anrin Chakraborti"
                    },
                    {
                        "@pid": "s/RaduSion",
                        "text": "Radu Sion"
                    }
                ]
            },
            "title": "PEARL: Plausibly Deniable Flash Translation Layer using WOM coding.",
            "venue": "USENIX Security Symposium",
            "pages": "1109-1126",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0057CS21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/chen-chen",
            "url": "https://dblp.org/rec/conf/uss/0057CS21",
            "abstract": "When adversaries are powerful enough to coerce users to reveal encryption keys, encryption alone becomes insufficient for data protection. Plausible deniability (PD) mechanisms resolve this by enabling users to hide the mere existence of sensitive data, often by providing plausible \"cover texts\" or \"public data volumes\" hosted on the same device. \nUnfortunately, with the increasing prevalence of (NAND) flash as a high-performance cost-effective storage medium, PD becomes even more challenging in the presence of realistic adversaries who can usually access a device at multiple points in time (\"multi-snapshot\"). This is because read/write operations to flash do not result in intuitive corresponding changes to the underlying device state. The problem is further compounded by the fact that this behavior is mostly proprietary. For example, in a majority of commercially-available flash devices, an issued delete or overwrite operation from the upper layers almost certainly won't result in an actual immediate erase of the underlying flash cells. \nTo address these challenges, we designed a new class of write-once memory (WOM) codes to store hidden bits in the same physical locations as other public bits. This is made possible by the inherent nature of NAND flash and the possibility of issuing multiple writes to target cells that have not previous been written to in existing pages. \nWe designed PEARL, a general-purpose Flash Translation Layer (FTL) that allows users to plausibly deniably store hidden data in NAND flash devices. We implemented and evaluated PEARL on a widely used simulator FlashSim (Kim et al. 2019). PEARL performs well on real-world workloads, comparably to non-PD baselines. PEARL is the first system that achieves strong plausible deniability for NAND flash devices, secure against realistic multi-snapshot adversaries.",
            "keywords": [
                "Plausible Deniability",
                "Flash Translation Layer",
                "Write-Once Memory Coding",
                "NAND Flash Storage",
                "Multi-Snapshot Adversaries"
            ]
        },
        "url": "URL#1888010",
        "sema_paperId": "f6de98f6af04e6aa92eb464a9c10f82299990c08"
    },
    {
        "@score": "1",
        "@id": "1888011",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "138/6356",
                        "text": "Yousra Aafer"
                    },
                    {
                        "@pid": "87/6465",
                        "text": "Wei You"
                    },
                    {
                        "@pid": "65/2709-4",
                        "text": "Yi Sun 0004"
                    },
                    {
                        "@pid": "55/4736",
                        "text": "Yu Shi"
                    },
                    {
                        "@pid": "95/3760-1",
                        "text": "Xiangyu Zhang 0001"
                    },
                    {
                        "@pid": "77/6178-1",
                        "text": "Heng Yin 0001"
                    }
                ]
            },
            "title": "Android SmartTVs Vulnerability Discovery via Log-Guided Fuzzing.",
            "venue": "USENIX Security Symposium",
            "pages": "2759-2776",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AaferYSS0Y21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/aafer",
            "url": "https://dblp.org/rec/conf/uss/AaferYSS0Y21",
            "abstract": "The recent rise of Smart IoT devices has opened new doors for cyber criminals to achieve damages unique to the ecosys-tem. SmartTVs, the most widely adopted home-based IoT devices, are no exception. Albeit their popularity, little has been done to evaluate their security and associated risks. To proactively address the problem, we propose a systematic evaluation of Android SmartTVs security. We overcome a number of prominent challenges such as most of the added TV related functionalities are (partially) implemented in the native layer and many security problems only manifest themselves on the physical aspect without causing any misbehaviors inside the OS. We develop a novel dynamic fuzzing approach, which features an on-the-\ufb02y log-based input speci\ufb01cation derivation and feedback collection. Our solution further introduces a novel external observer that monitors the TV-related physical symptoms (i.e., visual and auditory) to detect potential physical anomalies. We leverage our technique to analyze 11 Android TV Boxes. Our analysis reveals 37 unique vulnerabilities, leading to high-impact cyber threats (e.g., corrupting critical boot environment settings and accessing highly-sensitive data), memory corruptions, and even visual and auditory disturbances (e.g., persistent display content corruption and audio muting).",
            "keywords": [
                "Android SmartTV Security",
                "Dynamic Fuzzing",
                "Vulnerability Discovery",
                "IoT Device Risks",
                "Physical Anomalies Detection"
            ]
        },
        "url": "URL#1888011",
        "sema_paperId": "7ba29bbd8e84542e9a8e58cb5598f821f4e9c3bb"
    },
    {
        "@score": "1",
        "@id": "1888012",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "184/1776",
                        "text": "Muhammad Abubakar"
                    },
                    {
                        "@pid": "205/3202",
                        "text": "Adil Ahmad"
                    },
                    {
                        "@pid": "11/3119-1",
                        "text": "Pedro Fonseca 0001"
                    },
                    {
                        "@pid": "59/5539",
                        "text": "Dongyan Xu"
                    }
                ]
            },
            "title": "SHARD: Fine-Grained Kernel Specialization with Context-Aware Hardening.",
            "venue": "USENIX Security Symposium",
            "pages": "2435-2452",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AbubakarAFX21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/abubakar",
            "url": "https://dblp.org/rec/conf/uss/AbubakarAFX21",
            "abstract": "With growing hardware complexity and ever-evolving user requirements, the kernel is increasingly bloated which increases its attack surface. Despite its large size, for speci\ufb01c applications and workloads, only a small subset of the kernel code is actually required. Kernel specialization approaches exploit this observation to either harden the kernel or restrict access to its code (debloating) on a per-application basis. However, existing approaches suffer from coarse specialization granularity and lack strict enforcement which limits their effectiveness. This paper presents S HARD , a practical framework to enforce \ufb01ne-grain kernel specialization. S HARD specializes at both the application and system call levels to signi\ufb01cantly restrict the kernel code exposed to attackers. Furthermore, S HARD introduces context-aware hardening to dynamically enable code hardening during suspicious execution contexts. S HARD implements an instance of a context-aware hardening scheme using control-\ufb02ow integrity (CFI), which provides near-native performance for non-hardened executions and strong security guarantees. Our analysis of the kernel attack surface reduction with S HARD as well as concrete attacks shows that S HARD exposes 181 \u00d7 less kernel code than the native kernel, an order of magnitude better than existing work, and prevents 90% of the evaluated attacks. Our evaluation shows that the average performance overhead of S HARD on real-world applications is moderate\u201410% to 36% on NG-INX, 3% to 10% on Redis, and 0% to 2.7% on the SPEC CPU 2006 benchmarks.",
            "keywords": [
                "Kernel Specialization",
                "Context-Aware Hardening",
                "Kernel Attack Surface Reduction",
                "Fine-Grained Specialization",
                "Control-Flow Integrity (CFI)"
            ]
        },
        "url": "URL#1888012",
        "sema_paperId": "387be7c8b928b2dfc60be5d91968d5cca223ad37"
    },
    {
        "@score": "1",
        "@id": "1888013",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "301/5830",
                        "text": "Bhupendra Acharya"
                    },
                    {
                        "@pid": "133/2036",
                        "text": "Phani Vadrevu"
                    }
                ]
            },
            "title": "PhishPrint: Evading Phishing Detection Crawlers by Prior Profiling.",
            "venue": "USENIX Security Symposium",
            "pages": "3775-3792",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AcharyaV21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/acharya",
            "url": "https://dblp.org/rec/conf/uss/AcharyaV21",
            "abstract": "Security companies often use web crawlers to detect phishing and other social engineering attack websites. We built a novel, scalable, low-cost framework named PhishPrint to enable the evaluation of such web security crawlers against multiple cloaking attacks. PhishPrint is unique in that it completely avoids the use of any simulated phishing sites and blocklisting measurements. Instead, it uses web pages with benign content to pro\ufb01le security crawlers. We used PhishPrint to evaluate 23 security crawlers including highly ubiquitous services such as Google Safe Browsing and Microsoft Outlook e-mail scanners. Our 70-day evaluation found several previously unknown cloaking weaknesses across the crawler ecosystem. In particular, we show that all the crawlers\u2019 browsers are either not supporting advanced \ufb01ngerprinting related web APIs (such as Canvas API) or are severely lacking in \ufb01ngerprint diversity thus exposing them to new \ufb01ngerprinting-based cloaking attacks. We con\ufb01rmed the practical impact of our \ufb01ndings by deploying 20 evasive phishing web pages that exploit the found weaknesses. 18 of the pages managed to survive inde\ufb01nitely despite aggressive self-reporting of the pages to all crawlers. We con\ufb01rmed the speci\ufb01city of these attack vectors with 1150 volunteers as well as 467K web users. We also proposed countermeasures that all crawlers should take up in terms of both their crawling and reporting infrastructure. We have relayed the found weaknesses to all entities through an elaborate vulnerability disclosure process that resulted in some remedial actions as well as multiple vulnerability rewards.",
            "keywords": [
                "Phishing Detection",
                "Cloaking Attacks",
                "Web Crawlers",
                "Fingerprinting",
                "Vulnerability Disclosure"
            ]
        },
        "url": "URL#1888013",
        "sema_paperId": "fa056260f9e42ef5f580ae323df1b1f725e1effb"
    },
    {
        "@score": "1",
        "@id": "1888014",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "161/1767",
                        "text": "Mansour Ahmadi"
                    },
                    {
                        "@pid": "228/8232",
                        "text": "Reza Mirzazade Farkhani"
                    },
                    {
                        "@pid": "202/1974",
                        "text": "Ryan Williams"
                    },
                    {
                        "@pid": "81/7428",
                        "text": "Long Lu"
                    }
                ]
            },
            "title": "Finding Bugs Using Your Own Code: Detecting Functionally-similar yet Inconsistent Code.",
            "venue": "USENIX Security Symposium",
            "pages": "2025-2040",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AhmadiFWL21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/ahmadi",
            "url": "https://dblp.org/rec/conf/uss/AhmadiFWL21",
            "abstract": "Probabilistic classi\ufb01cation has shown success in detecting known types of software bugs. However, the works following this approach tend to require a large amount of specimenstotraintheirmodels. Wepresentanewmachine learning-based bug detection technique that does not require any external code or samples for training. Instead, our technique learns from the very codebase on which the bug detection is performed, and therefore, obviates the need for the cumbersome task of gathering and cleansing training samples (e.g., buggy code of certain kinds). The key idea behind our technique is a novel two-step clustering process applied on a given codebase. This clustering process identi\ufb01es code snippets in a project that are functionally-similar yet appear in inconsistent forms. Such inconsistencies are found to cause a wide range of bugs, anything from missing checks to unsafe type conversions. Unlike previous works, our technique is generic and not speci\ufb01c to one type of inconsistency or bug. We prototyped our technique and evaluated it using 5 popular open source software, including QEMU and OpenSSL. With a minimal amount of manual analysis on the inconsistencies detected by our tool, we discovered 22 new unique bugs, despite the fact that many of these programs are constantly undergoing bug scans and new bugs in them are believed to be rare.",
            "keywords": [
                "Bug Detection",
                "Code Consistency",
                "Clustering Process",
                "Functionally-similar Code",
                "Inconsistent Code Snippets"
            ]
        },
        "url": "URL#1888014",
        "sema_paperId": "bec43d2bd1315f89cfb0d5848b9296c6920fbb89"
    },
    {
        "@score": "1",
        "@id": "1888015",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "301/5902",
                        "text": "Mohammad M. Ahmadpanah"
                    },
                    {
                        "@pid": "37/1881",
                        "text": "Daniel Hedin"
                    },
                    {
                        "@pid": "25/7796",
                        "text": "Musard Balliu"
                    },
                    {
                        "@pid": "301/5809",
                        "text": "Lars Eric Olsson"
                    },
                    {
                        "@pid": "s/AndreiSabelfeld",
                        "text": "Andrei Sabelfeld"
                    }
                ]
            },
            "title": "SandTrap: Securing JavaScript-driven Trigger-Action Platforms.",
            "venue": "USENIX Security Symposium",
            "pages": "2899-2916",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AhmadpanahHBOS21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/ahmadpanah",
            "url": "https://dblp.org/rec/conf/uss/AhmadpanahHBOS21",
            "abstract": "Trigger-Action Platforms (TAPs) seamlessly connect a wide variety of otherwise unconnected devices and services, ranging from IoT devices to cloud services and social networks. TAPs raise critical security and privacy concerns because a TAP is effectively a \u201cperson-in-the-middle\u201d between trigger and action services. Third-party code, routinely deployed as \u201capps\u201d on TAPs, further exacerbates these concerns. This paper focuses on JavaScript-driven TAPs. We show that the popular IFTTT and Zapier platforms and an open-source alternative Node-RED are susceptible to attacks ranging from ex\ufb01ltrating data from unsuspecting users to taking over the entire platform. We report on the changes by the platforms in response to our \ufb01ndings and present an empirical study to assess the implications for Node-RED. Motivated by the need for a secure yet \ufb02exible way to integrate third-party JavaScript apps, we propose SandTrap, a novel JavaScript monitor that securely combines the Node.js vm module with fully structural proxy-based two-sided membranes to enforce \ufb01ne-grained access control policies. To aid developers, SandTrap includes a policy generation mechanism. We instantiate SandTrap to IFTTT, Zapier, and Node-RED and illustrate on a set of benchmarks how SandTrap enforces a variety of policies while incurring a tolerable runtime overhead.",
            "keywords": [
                "Trigger-Action Platforms",
                "JavaScript Security",
                "Access Control Policies",
                "Data Exfiltration",
                "SandTrap"
            ]
        },
        "url": "URL#1888015",
        "sema_paperId": "25434e937f9a2ebd6f827fb373f761d1bc4d69a3"
    },
    {
        "@score": "1",
        "@id": "1888016",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "198/9755",
                        "text": "Omer Akgul"
                    },
                    {
                        "@pid": "45/661-4",
                        "text": "Wei Bai 0004"
                    },
                    {
                        "@pid": "301/5878",
                        "text": "Shruti Das"
                    },
                    {
                        "@pid": "20/7983",
                        "text": "Michelle L. Mazurek"
                    }
                ]
            },
            "title": "Evaluating In-Workflow Messages for Improving Mental Models of End-to-End Encryption.",
            "venue": "USENIX Security Symposium",
            "pages": "447-464",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Akgul0DM21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/akgul",
            "url": "https://dblp.org/rec/conf/uss/Akgul0DM21",
            "abstract": "As large messaging providers increasingly adopt end-to-end encryption, private communication is readily available to more users than ever before. However, misunderstandings of end-to-end encryption\u2019s bene\ufb01ts and shortcomings limit people\u2019s ability to make informed choices about how and when to use these services. This paper explores the potential of using short educational messages, built into messaging work\ufb02ows, to improve users\u2019 functional mental models of secure communication. A preliminary survey study (n = 461) \ufb01nds that such messages, when used in isolation, can e \ufb00 ectively improve understanding of several key concepts. We then conduct a longitudinal study (n = 61) to test these messages in a more realistic environment: embedded into a secure messaging app. In this second study, we do not \ufb01nd statistically signi\ufb01cant evidence of improvement in mental models; however, qualitative evidence from participant interviews suggests that if made more salient, such messages could have potential to improve users\u2019 understanding.",
            "keywords": [
                "End-to-End Encryption",
                "User Education",
                "Mental Models",
                "Secure Messaging",
                "In-Workflow Messages"
            ]
        },
        "url": "URL#1888016",
        "sema_paperId": "2ed1831a380186fc01b58c6d9419ed1674b51d42"
    },
    {
        "@score": "1",
        "@id": "1888017",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "228/7702",
                        "text": "Nils Albartus"
                    },
                    {
                        "@pid": "287/7747",
                        "text": "Clemens Nasenberg"
                    },
                    {
                        "@pid": "272/7352",
                        "text": "Florian Stolz"
                    },
                    {
                        "@pid": "135/0314",
                        "text": "Marc Fyrbiak"
                    },
                    {
                        "@pid": "p/ChristofPaar",
                        "text": "Christof Paar"
                    },
                    {
                        "@pid": "23/2353",
                        "text": "Russell Tessier"
                    }
                ]
            },
            "title": "On the Design and Misuse of Microcoded (Embedded) Processors - A Cautionary Note.",
            "venue": "USENIX Security Symposium",
            "pages": "267-284",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AlbartusNSFPT21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/albartus",
            "url": "https://dblp.org/rec/conf/uss/AlbartusNSFPT21",
            "abstract": "Today's microprocessors often rely on microcode updates to address issues such as security or functional patches.  Unfortunately, microcode update flexibility opens up new attack vectors through malicious microcode alterations. Such attacks share many features with hardware Trojans and have similar devastating consequences for system security. However, due to microcode's opaque nature, little is known in the open literature about the capabilities and limitations of microcode Trojans.We introduce the design of a microcoded RISC-V processor architecture together with a microcode development and evaluation environment. Even though microcode typically has almost complete control of the processor hardware, the design of meaningful microcode Trojans is not straightforward. This somewhat counter-intuitive insight is due to the lack of information at the hardware level about the semantics of executed software. In three security case studies we demonstrate how to overcome these issues and give insights on how to design meaningful microcode Trojans that undermine system security. To foster future research and applications, we publicly release our implementation and evaluation platform.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-albartus.pdf",
            "keywords": [
                "Microcoded Processors",
                "RISC-V Architecture",
                "Microcode Trojans",
                "Security Vulnerabilities",
                "Malicious Microcode Alterations"
            ]
        },
        "url": "URL#1888017"
    },
    {
        "@score": "1",
        "@id": "1888018",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "92/7397",
                        "text": "Martin R. Albrecht"
                    },
                    {
                        "@pid": "27/7270",
                        "text": "Jorge Blasco"
                    },
                    {
                        "@pid": "217/9278",
                        "text": "Rikke Bjerg Jensen"
                    },
                    {
                        "@pid": "208/7022",
                        "text": "Lenka Marekov\u00e1"
                    }
                ]
            },
            "title": "Collective Information Security in Large-Scale Urban Protests: the Case of Hong Kong.",
            "venue": "USENIX Security Symposium",
            "pages": "3363-3380",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AlbrechtBJM21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/albrecht",
            "url": "https://dblp.org/rec/conf/uss/AlbrechtBJM21",
            "abstract": "The Anti-Extradition Law Amendment Bill protests in Hong Kong present a rich context for exploring information security practices among protesters due to their large-scale urban setting and highly digitalised nature. We conducted in-depth, semi-structured interviews with 11 participants of these protests. Research findings reveal how protesters favoured Telegram and relied on its security for internal communication and organisation of on-the-ground collective action; were organised in small private groups and large public groups to enable collective action; adopted tactics and technologies that enable pseudonymity; and developed a variety of strategies to detect compromises and to achieve forms of forward secrecy and post-compromise security when group members were (presumed) arrested. We further show how group administrators had assumed the roles of leaders in these 'leaderless' protests and were critical to collective protest efforts.",
            "keywords": [
                "Information Security",
                "Urban Protests",
                "Digital Communication",
                "Collective Action",
                "Pseudonymity Strategies"
            ]
        },
        "url": "URL#1888018",
        "sema_paperId": "c8135211f4dd4ce21c832481ec9f96eac26cc8d9"
    },
    {
        "@score": "1",
        "@id": "1888019",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "243/2808",
                        "text": "Fatemah Alharbi"
                    },
                    {
                        "@pid": "147/1575",
                        "text": "Arwa Alrawais"
                    },
                    {
                        "@pid": "227/4806",
                        "text": "Abdulrahman Bin Rabiah"
                    },
                    {
                        "@pid": "07/11488",
                        "text": "Silas Richelson"
                    },
                    {
                        "@pid": "86/2654",
                        "text": "Nael B. Abu-Ghazaleh"
                    }
                ]
            },
            "title": "CSProp: Ciphertext and Signature Propagation Low-Overhead Public-Key Cryptosystem for IoT Environments.",
            "venue": "USENIX Security Symposium",
            "pages": "609-626",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AlharbiARRA21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/alharbi",
            "url": "https://dblp.org/rec/conf/uss/AlharbiARRA21",
            "abstract": "Cryptographic operations can be prohibitively expensive for IoT and other resource-constrained devices. We introduce a new cryptographic primitive which we call Ciphertext and Signature Propagation (CSProp) in order to deliver security to the weak end-devices. CSProp is a cryptographic propagation algorithm whereby an untrusted machine sitting upstream of a lightweight device can modify an authenticated message so it can be efficiently verified. Unlike proxy-based solutions, this upstream machine is stateless and untrusted (making it possible for any device to serve that role), and the propagated signature is mathematically guaranteed to be valid only if the original signature is also valid. CSProp relies on RSA security and can be used to optimize any operations using the public key such as signature validation and encryption, which our experiments show are the most common public key operations in IoT settings. We test CSProp by using it to extend DNSSEC to edge devices (validation), and to optimize the performance of TLS (validation and encryption) on a range of resource constrained devices. CSProp reduces DNSSEC validation latency by 78x and energy consumption by 47x on the Raspberry Pi Zero. It reduces TLS handshake latency and energy by an average of 8x each. On an Arduino-based IoT board, CSProp significantly outperforms traditional RSA public key operations (e.g., 57x and 36x reductions in latency and energy consumption, respectively, for encryption).",
            "pdf_url": "https://www.usenix.org/system/files/sec21-alharbi.pdf",
            "keywords": [
                "Public-Key Cryptography",
                "IoT Security",
                "Cryptographic Optimization",
                "Signature Propagation",
                "Resource-Constrained Devices"
            ]
        },
        "url": "URL#1888019",
        "sema_paperId": "52f23c752df720fd445de6db5d76bf41f7f531ab"
    },
    {
        "@score": "1",
        "@id": "1888020",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "256/9109",
                        "text": "Asra Ali"
                    },
                    {
                        "@pid": "08/11136",
                        "text": "Tancr\u00e8de Lepoint"
                    },
                    {
                        "@pid": "04/773",
                        "text": "Sarvar Patel"
                    },
                    {
                        "@pid": "07/5590-1",
                        "text": "Mariana Raykova 0001"
                    },
                    {
                        "@pid": "187/5645",
                        "text": "Phillipp Schoppmann"
                    },
                    {
                        "@pid": "125/0309",
                        "text": "Karn Seth"
                    },
                    {
                        "@pid": "176/7649",
                        "text": "Kevin Yeo"
                    }
                ]
            },
            "title": "Communication-Computation Trade-offs in PIR.",
            "venue": "USENIX Security Symposium",
            "pages": "1811-1828",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AliLP0SSY21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/ali",
            "url": "https://dblp.org/rec/conf/uss/AliLP0SSY21",
            "abstract": "We study the computation and communication costs and their possible trade-offs in various constructions for private information retrieval (PIR), including schemes based on homomorphic encryption and the Gentry\u2013Ramzan PIR (ICALP'05).We improve over the construction of SealPIR (S&P'18) using compression techniques and a new oblivious expansion, which reduce the communication bandwidth by 80% while preserving essentially the same computation cost. We then present MulPIR, a PIR protocol additionally leveraging multiplicative homomorphism to implement the recursion steps in PIR. While using the multiplicative homomorphism has been considered in prior work, we observe that in combination with our other techniques, it introduces a meaningful tradeoff by significantly reducing communication, at the cost of an increased computational cost for the server, when the databases have large entries. For some applications, we show that this could reduce the total monetary server cost by up to 35%.On the other end of the communication\u2013computation spectrum, we take a closer look at Gentry\u2013Ramzan PIR, a scheme with asymptotically optimal communication rate. Here, the bottleneck is the server's computation, which we manage to reduce significantly. Our optimizations enable a tunable tradeoff between communication and computation, which allows us to reduce server computation by as much as 85%, at the cost of an increased query size.Finally, we introduce new ways to handle PIR over sparse databases (keyword PIR), based on different hashing techniques. We implement all of our constructions, and compare their communication and computation overheads with respect to each other for several application scenarios.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-ali.pdf",
            "keywords": [
                "Private Information Retrieval",
                "Communication-Computational Trade-offs",
                "Homomorphic Encryption",
                "Gentry-Ramzan PIR",
                "Sparse Databases"
            ]
        },
        "url": "URL#1888020"
    },
    {
        "@score": "1",
        "@id": "1888021",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "222/3040",
                        "text": "Maxwell Aliapoulios"
                    },
                    {
                        "@pid": "284/0642",
                        "text": "Cameron Ballard"
                    },
                    {
                        "@pid": "201/7550",
                        "text": "Rasika Bhalerao"
                    },
                    {
                        "@pid": "00/3175",
                        "text": "Tobias Lauinger"
                    },
                    {
                        "@pid": "58/4016",
                        "text": "Damon McCoy"
                    }
                ]
            },
            "title": "Swiped: Analyzing Ground-truth Data of a Marketplace for Stolen Debit and Credit Cards.",
            "venue": "USENIX Security Symposium",
            "pages": "4151-4168",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AliapouliosBBLM21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/aliapoulios",
            "url": "https://dblp.org/rec/conf/uss/AliapouliosBBLM21",
            "abstract": "This paper presents the first empirical study of ground-truth data from a major underground shop selling stolen credit and debit cards. To date, there is little quantitative knowledge about how this segment of the underground economy operates, despite it causing fraud losses estimated at billions of dollars a year. Our analysis of four years of leaked transactional data allows us to characterize this shop\u2019s business model, sellers, customers, and finances. The shop earned close to $104 M in gross revenue, and listed over 19 M unique card numbers for sale. Around 97% of the inventory was stolen magnetic stripe data, commonly used to produce counterfeit cards for in-person payments. Perhaps surprisingly, customers purchased only 40% of this inventory. In contrast, the shop sold 83% of its card-not-present inventory, used for online fraud, which appeared to be in short supply. Demand and pricing were not uniform, as buyers appeared to perceive some banks as having weaker countermeasures against fraud. Even multiple years into the U.S. EMV chip deployment, the supply of stolen magnetic stripe data continued to increase sharply. In particular, we identified a continuing supply of newly issued cards not equipped with EMV chips, especially among prepaid cards. Our findings suggest that improvements to EMV chip deployment in the U.S., combined with a limited supply of stolen card-not-present data, could be avenues to decreasing the revenue and profitability of this shop.",
            "keywords": [
                "Underground Economy",
                "Stolen Credit Cards",
                "Fraud Analysis",
                "EMV Chip Deployment",
                "Market Demand for Stolen Data"
            ]
        },
        "url": "URL#1888021",
        "sema_paperId": "2b67e45e39e0eff67dafbc951fb09142638807e6"
    },
    {
        "@score": "1",
        "@id": "1888022",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "127/7110",
                        "text": "Omar Alrawi"
                    },
                    {
                        "@pid": "239/8948",
                        "text": "Moses Ike"
                    },
                    {
                        "@pid": "265/5563",
                        "text": "Matthew Pruett"
                    },
                    {
                        "@pid": "248/1646",
                        "text": "Ranjita Pai Kasturi"
                    },
                    {
                        "@pid": "214/8468",
                        "text": "Srimanta Barua"
                    },
                    {
                        "@pid": "301/5807",
                        "text": "Taleb Hirani"
                    },
                    {
                        "@pid": "301/5859",
                        "text": "Brennan Hill"
                    },
                    {
                        "@pid": "150/5240",
                        "text": "Brendan Saltaformaggio"
                    }
                ]
            },
            "title": "Forecasting Malware Capabilities From Cyber Attack Memory Images.",
            "venue": "USENIX Security Symposium",
            "pages": "3523-3540",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AlrawiIPKBHHS21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/alrawi-forecasting",
            "url": "https://dblp.org/rec/conf/uss/AlrawiIPKBHHS21",
            "abstract": "The remediation of ongoing cyber attacks relies upon timely malware analysis, which aims to uncover malicious functionalities that have not yet executed. Unfortunately, this requires repeated context switching between different tools and incurs a high cognitive load on the analyst, slowing down the investigation and giving attackers an advantage. We present Forecast, a post-detection technique to enable incident responders to automatically predict capabilities which malware have staged for execution. Forecast is based on a probabilistic model that allows Forecast to discover capabilities and also weigh each capability according to its relative likelihood of execution (i.e., forecasts). Forecast leverages the execution context of the ongoing attack (from the malware\u2019s memory image) to guide a symbolic analysis of the malware\u2019s code. We performed extensive evaluations, with 6,727 real-world malware and futuristic attacks aiming to subvert Forecast, showing the accuracy and robustness in predicting malware capabilities.",
            "keywords": [
                "Malware Analysis",
                "Cyber Attack Response",
                "Capability Prediction",
                "Symbolic Analysis",
                "Memory Image Analysis"
            ]
        },
        "url": "URL#1888022",
        "sema_paperId": "ee3b2ef11dac00d256430fe9c9608de58c129eaf"
    },
    {
        "@score": "1",
        "@id": "1888023",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "127/7110",
                        "text": "Omar Alrawi"
                    },
                    {
                        "@pid": "134/8710",
                        "text": "Charles Lever"
                    },
                    {
                        "@pid": "134/5637",
                        "text": "Kevin Valakuzhy"
                    },
                    {
                        "@pid": "301/5858",
                        "text": "Ryan Court"
                    },
                    {
                        "@pid": "29/8732",
                        "text": "Kevin Z. Snow"
                    },
                    {
                        "@pid": "50/6700",
                        "text": "Fabian Monrose"
                    },
                    {
                        "@pid": "26/216",
                        "text": "Manos Antonakakis"
                    }
                ]
            },
            "title": "The Circle Of Life: A Large-Scale Study of The IoT Malware Lifecycle.",
            "venue": "USENIX Security Symposium",
            "pages": "3505-3522",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AlrawiLVCSMA21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/alrawi-circle",
            "url": "https://dblp.org/rec/conf/uss/AlrawiLVCSMA21",
            "abstract": "Our current defenses against IoT malware may not be adequate to remediate an IoT malware attack similar to the Mirai botnet. This work seeks to investigate this matter by systematically and empirically studying the lifecycle of IoT malware and comparing it with traditional malware that target desktop and mobile platforms. We present a large-scale measurement of more than 166K Linux-based IoT malware samples collected over a year. We compare our results with prior works by systematizing desktop and mobile malware studies into a novel framework and answering key questions about defense readiness. Based on our findings, we deduce that the required technology to defend against IoT malware is available, but we conclude that there are insufficient efforts in place to deal with a large-scale IoT malware infection breakout.",
            "keywords": [
                "IoT Malware",
                "Malware Lifecycle",
                "Mirai Botnet",
                "Defense Mechanisms",
                "Large-Scale Measurement"
            ]
        },
        "url": "URL#1888023",
        "sema_paperId": "fb049e00e920edbe2e8b7cd2ca3fc5f4e6c33a9a"
    },
    {
        "@score": "1",
        "@id": "1888024",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "301/5823",
                        "text": "Abdulellah Alsaheel"
                    },
                    {
                        "@pid": "167/0416",
                        "text": "Yuhong Nan"
                    },
                    {
                        "@pid": "172/8745",
                        "text": "Shiqing Ma"
                    },
                    {
                        "@pid": "23/7122",
                        "text": "Le Yu"
                    },
                    {
                        "@pid": "248/1730",
                        "text": "Gregory Walkup"
                    },
                    {
                        "@pid": "143/2298",
                        "text": "Z. Berkay Celik"
                    },
                    {
                        "@pid": "95/3760-1",
                        "text": "Xiangyu Zhang 0001"
                    },
                    {
                        "@pid": "59/5539",
                        "text": "Dongyan Xu"
                    }
                ]
            },
            "title": "ATLAS: A Sequence-based Learning Approach for Attack Investigation.",
            "venue": "USENIX Security Symposium",
            "pages": "3005-3022",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AlsaheelNMYWC0X21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/alsaheel",
            "url": "https://dblp.org/rec/conf/uss/AlsaheelNMYWC0X21",
            "abstract": "Advanced Persistent Threats (APT) involve multiple attack steps over a long period, and their investigation requires analysis of myriad logs to identify their attack steps, which are a set of activities undertaken to run an APT attack. However, on a daily basis in an enterprise, intrusion detection systems generate many threat alerts of suspicious events (attack symptoms). Cyber analysts must investigate such events to determine whether an event is a part of an attack. With many alerts to investigate, cyber analysts often end up with alert fatigue, causing them to ignore a large number of alerts and miss true attack events. In this paper, we present ATLAS, a framework that constructs an end-to-end attack story from off-the-shelf audit logs. Our key observation is that different attacks may share similar abstract attack strategies, regardless of the vulnerabilities exploited and payloads executed. ATLAS leverages a novel combination of causality analysis, natural language processing, and machine learning techniques to build a sequence-based model, which establishes key patterns of attack and non-attack behaviors from a causal graph. At inference time, given a threat alert event, an attack symptom node in a causal graph is identified. ATLAS then constructs a set of candidate sequences associated with the symptom node, uses the sequence-based model to identify nodes in a sequence that contribute to the attack, and unifies the identified attack nodes to construct an attack story. We evaluated ATLAS with ten real-world APT attacks executed in a realistic virtual environment. ATLAS recovers attack steps and construct attack stories with an average of 91.06% precision, 97.29% recall, and 93.76% F1-score. Through this effort, we provide security investigators with a new means of identifying the attack events that make up the attack story. \u2217 The authors contributed equally.",
            "keywords": [
                "Attack Investigation",
                "Advanced Persistent Threats (APT)",
                "Causality Analysis",
                "Sequence-based Model",
                "Attack Story Construction"
            ]
        },
        "url": "URL#1888024",
        "sema_paperId": "92969e72abf7f8b5a8b5332667fbcda612ea01b1"
    },
    {
        "@score": "1",
        "@id": "1888025",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "252/4152",
                        "text": "Gaspard Anthoine"
                    },
                    {
                        "@pid": "78/264",
                        "text": "Jean-Guillaume Dumas"
                    },
                    {
                        "@pid": "271/0925",
                        "text": "M\u00e9lanie de Jonghe"
                    },
                    {
                        "@pid": "17/4789",
                        "text": "Aude Maignan"
                    },
                    {
                        "@pid": "76/1295",
                        "text": "Cl\u00e9ment Pernet"
                    },
                    {
                        "@pid": "252/4256",
                        "text": "Michael Hanling"
                    },
                    {
                        "@pid": "09/5926",
                        "text": "Daniel S. Roche"
                    }
                ]
            },
            "title": "Dynamic proofs of retrievability with low server storage.",
            "venue": "USENIX Security Symposium",
            "pages": "537-554",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AnthoineDJMPHR21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/anthoine",
            "url": "https://dblp.org/rec/conf/uss/AnthoineDJMPHR21",
            "abstract": "Proofs of Retrievability (PoRs) are protocols which allow a client to store data remotely and to efficiently ensure, via audits, that the entirety of that data is still intact. A dynamic PoR system also supports efficient retrieval and update of any small portion of the data. We propose new, simple protocols for dynamic PoR that are designed for practical efficiency, trading decreased persistent storage for increased server computation, and show in fact that this tradeoff is inherent via a lower bound proof of time-space for any PoR scheme. Notably, ours is the first dynamic PoR which does not require any special encoding of the data stored on the server, meaning it can be trivially composed with any database service or with existing techniques for encryption or redundancy. Our implementation and deployment on Google Cloud Platform demonstrates our solution is scalable: for example, auditing a 1TB file takes 16 minutes at a monetary cost of just $0.23 USD. We also present several further enhancements, reducing the amount of client storage, or the communication bandwidth, or allowing public verifiability, wherein any untrusted third party may conduct an audit.",
            "keywords": [
                "Proofs of Retrievability",
                "Dynamic PoR",
                "Server Storage Efficiency",
                "Data Integrity Audits",
                "Client-Server Interaction"
            ]
        },
        "url": "URL#1888025",
        "sema_paperId": "64a5435076b51215120350ed4dcadd55f27d0ea9"
    },
    {
        "@score": "1",
        "@id": "1888027",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "265/9073",
                        "text": "Lukas Aumayr"
                    },
                    {
                        "@pid": "128/4640",
                        "text": "Pedro Moreno-Sanchez"
                    },
                    {
                        "@pid": "12/3394",
                        "text": "Aniket Kate"
                    },
                    {
                        "@pid": "25/3571",
                        "text": "Matteo Maffei"
                    }
                ]
            },
            "title": "Blitz: Secure Multi-Hop Payments Without Two-Phase Commits.",
            "venue": "USENIX Security Symposium",
            "pages": "4043-4060",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AumayrMKM21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/aumayr",
            "url": "https://dblp.org/rec/conf/uss/AumayrMKM21",
            "abstract": "Payment-channel networks (PCN) are the most prominent approach to tackle the scalability issues of current permissionless blockchains. A PCN reduces the load on-chain by allowing arbitrarily many off-chain multi-hop payments (MHPs) between any two users connected through a path of payment channels. Unfortunately, current MHP protocols are far from satisfactory. One-round MHPs (e.g., Interledger) are insecure as a malicious intermediary can steal the payment funds. Two-round MHPs (e.g., Lightning Network (LN)) follow the 2-phase-commit paradigm as in databases to overcome this issue. However, when tied with economical incentives, 2-phase-commit brings other security threats (i.e., wormhole attacks), staggered collateral (i.e., funds are locked for a time proportional to the payment path length) and dependency on specific scripting language functionality (e.g., Hash Time-Lock Contracts) that hinders a wider deployment in practice. We present Blitz, a novel MHP protocol that demonstrates for the first time that we can achieve the best of the two worlds: a single round MHP where no malicious intermediary can steal coins. Moreover, Blitz provides the same privacy for sender and receiver as current MHP protocols do, is not prone to the wormhole attack and requires only constant collateral. Additionally, we construct MHPs using only digital signatures and a timelock functionality, both available at the core of virtually every cryptocurrency today. We provide the cryptographic details of Blitz and we formally prove its security. Furthermore, our experimental evaluation on a LN snapshot shows that (i) staggered collateral in LN leads to in between 4x and 33x more unsuccessful payments than the constant collateral in Blitz; (ii) Blitz reduces the size of the payment contract by 26%; and (iii) Blitz prevents up to 0.3 BTC (3397 USD in October 2020) in fees being stolen over a three day period as it avoids wormhole attacks by design.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-aumayr.pdf",
            "keywords": [
                "Payment-Channel Networks",
                "Multi-Hop Payments",
                "Security Protocols",
                "Wormhole Attacks",
                "Constant Collateral"
            ]
        },
        "url": "URL#1888027"
    },
    {
        "@score": "1",
        "@id": "1888028",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "180/5458",
                        "text": "Erin Avllazagaj"
                    },
                    {
                        "@pid": "187/8969",
                        "text": "Ziyun Zhu"
                    },
                    {
                        "@pid": "15/6037",
                        "text": "Leyla Bilge"
                    },
                    {
                        "@pid": "56/490",
                        "text": "Davide Balzarotti"
                    },
                    {
                        "@pid": "01/4921",
                        "text": "Tudor Dumitras"
                    }
                ]
            },
            "title": "When Malware Changed Its Mind: An Empirical Study of Variable Program Behaviors in the Real World.",
            "venue": "USENIX Security Symposium",
            "pages": "3487-3504",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AvllazagajZBBD21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/avllazagaj",
            "url": "https://dblp.org/rec/conf/uss/AvllazagajZBBD21",
            "abstract": "Behavioral program analysis is widely used for understanding malware behavior, for creating rule-based detectors, and for clustering samples into malware families. However, this approach is ineffective when the behavior of individual samples changes across different executions, owing to environment sensitivity, evasive techniques or time variability. While the inability to observe the complete behavior of a program is a well-known limitation of dynamic analysis, the prevalence of this behavior variability in the wild, and the behavior components that are most affected by it, are still unknown. As the behavioral traces are typically collected by executing the samples in a controlled environment, the models created and tested using such traces do not account for the broad range of behaviors observed in the wild, and may result in a false sense of security. In this paper we conduct the first quantitative analysis of behavioral variability in Windows malware, PUP and benign samples, using a novel dataset of 7.6M execution traces, recorded in 5.4M real hosts from 113 countries. We analyze program behaviors at multiple granularities, and we show how they change across hosts and across time. We then analyze the invariant parts of the malware behaviors, and we show how this affects the effectiveness of malware detection using a common class of behavioral rules. Our findings have actionable implications for malware clustering and detection, and they emphasize that program behavior in the wild depends on a subtle interplay of factors that may only be observed at scale, by monitoring malware on real hosts.",
            "keywords": [
                "Malware Behavior Analysis",
                "Behavioral Variability",
                "Dynamic Analysis",
                "Malware Detection",
                "Execution Traces"
            ]
        },
        "url": "URL#1888028",
        "sema_paperId": "613602959b348dfe48cd84e72992454854356532"
    },
    {
        "@score": "1",
        "@id": "1888029",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "287/4528",
                        "text": "Ahmadreza Azizi"
                    },
                    {
                        "@pid": "227/0788",
                        "text": "Ibrahim Asadullah Tahmid"
                    },
                    {
                        "@pid": "287/4144",
                        "text": "Asim Waheed"
                    },
                    {
                        "@pid": "278/0806",
                        "text": "Neal Mangaokar"
                    },
                    {
                        "@pid": "198/9527",
                        "text": "Jiameng Pu"
                    },
                    {
                        "@pid": "48/7429",
                        "text": "Mobin Javed"
                    },
                    {
                        "@pid": "42/1341",
                        "text": "Chandan K. Reddy"
                    },
                    {
                        "@pid": "24/604",
                        "text": "Bimal Viswanath"
                    }
                ]
            },
            "title": "T-Miner: A Generative Approach to Defend Against Trojan Attacks on DNN-based Text Classification.",
            "venue": "USENIX Security Symposium",
            "pages": "2255-2272",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AziziTWMPJRV21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/azizi",
            "url": "https://dblp.org/rec/conf/uss/AziziTWMPJRV21",
            "abstract": "Deep Neural Network (DNN) classifiers are known to be vulnerable to Trojan or backdoor attacks, where the classifier is manipulated such that it misclassifies any input containing an attacker-determined Trojan trigger. Backdoors compromise a model's integrity, thereby posing a severe threat to the landscape of DNN-based classification. While multiple defenses against such attacks exist for classifiers in the image domain, there have been limited efforts to protect classifiers in the text domain. \nWe present Trojan-Miner (T-Miner) -- a defense framework for Trojan attacks on DNN-based text classifiers. T-Miner employs a sequence-to-sequence (seq-2-seq) generative model that probes the suspicious classifier and learns to produce text sequences that are likely to contain the Trojan trigger. T-Miner then analyzes the text produced by the generative model to determine if they contain trigger phrases, and correspondingly, whether the tested classifier has a backdoor. T-Miner requires no access to the training dataset or clean inputs of the suspicious classifier, and instead uses synthetically crafted \"nonsensical\" text inputs to train the generative model. We extensively evaluate T-Miner on 1100 model instances spanning 3 ubiquitous DNN model architectures, 5 different classification tasks, and a variety of trigger phrases. We show that T-Miner detects Trojan and clean models with a 98.75% overall accuracy, while achieving low false positives on clean models. We also show that T-Miner is robust against a variety of targeted, advanced attacks from an adaptive attacker.",
            "keywords": [
                "Trojan Attacks",
                "Text Classification",
                "Backdoor Detection",
                "Generative Model",
                "DNN Defense Framework"
            ]
        },
        "url": "URL#1888029",
        "sema_paperId": "3ab9145d5134e4e89bcceb1c8a95f9f98c98c5ff"
    },
    {
        "@score": "1",
        "@id": "1888030",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "213/9150",
                        "text": "Eugene Bagdasaryan"
                    },
                    {
                        "@pid": "46/6275",
                        "text": "Vitaly Shmatikov"
                    }
                ]
            },
            "title": "Blind Backdoors in Deep Learning Models.",
            "venue": "USENIX Security Symposium",
            "pages": "1505-1521",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BagdasaryanS21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/bagdasaryan",
            "url": "https://dblp.org/rec/conf/uss/BagdasaryanS21",
            "abstract": "We investigate a new method for injecting backdoors into machine learning models, based on poisoning the loss-value computation in the model-training code. We use it to demonstrate new classes of backdoors strictly more powerful than those in prior literature: single-pixel and physical backdoors in ImageNet models, backdoors that switch the model to a covert, privacy-violating task, and backdoors that do not require inference-time input modifications. \nOur attack is \\emph{blind}: the attacker cannot modify the training data, nor observe the execution of his code, nor access the resulting model. Blind backdoor training uses multi-objective optimization to achieve high accuracy on both the main and backdoor tasks. Finally, we show how the blind attack can evade all known defenses, and propose new ones.",
            "keywords": [
                "Backdoor Injection",
                "Loss-Value Poisoning",
                "Multi-Objective Optimization",
                "Privacy Violating Tasks",
                "Blind Backdoor Attacks"
            ]
        },
        "url": "URL#1888030",
        "sema_paperId": "6f46322243a8318a9712bedf6a218e2df85c64fb"
    },
    {
        "@score": "1",
        "@id": "1888031",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "191/5905",
                        "text": "Raad Bahmani"
                    },
                    {
                        "@pid": "117/5967",
                        "text": "Ferdinand Brasser"
                    },
                    {
                        "@pid": "153/0574",
                        "text": "Ghada Dessouky"
                    },
                    {
                        "@pid": "224/9363",
                        "text": "Patrick Jauernig"
                    },
                    {
                        "@pid": "277/5702",
                        "text": "Matthias Klimmek"
                    },
                    {
                        "@pid": "s/AhmadRezaSadeghi",
                        "text": "Ahmad-Reza Sadeghi"
                    },
                    {
                        "@pid": "32/4934",
                        "text": "Emmanuel Stapf"
                    }
                ]
            },
            "title": "CURE: A Security Architecture with CUstomizable and Resilient Enclaves.",
            "venue": "USENIX Security Symposium",
            "pages": "1073-1090",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BahmaniBDJKSS21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/bahmani",
            "url": "https://dblp.org/rec/conf/uss/BahmaniBDJKSS21",
            "abstract": "Security architectures providing Trusted Execution Environments (TEEs) have been an appealing research subject for a wide range of computer systems, from low-end embedded devices to powerful cloud servers. The goal of these architectures is to protect sensitive services in isolated execution contexts, called enclaves. Unfortunately, existing TEE solutions suffer from significant design shortcomings. First, they follow a one-size-fits-all approach offering only a single enclave type, however, different services need flexible enclaves that can adjust to their demands. Second, they cannot efficiently support emerging applications (e.g., Machine Learning as a Service), which require secure channels to peripherals (e.g., accelerators), or the computational power of multiple cores. Third, their protection against cache side-channel attacks is either an afterthought or impractical, i.e., no fine-grained mapping between cache resources and individual enclaves is provided. \nIn this work, we propose CURE, the first security architecture, which tackles these design challenges by providing different types of enclaves: (i) sub-space enclaves provide vertical isolation at all execution privilege levels, (ii) user-space enclaves provide isolated execution to unprivileged applications, and (iii) self-contained enclaves allow isolated execution environments that span multiple privilege levels. Moreover, CURE enables the exclusive assignment of system resources, e.g., peripherals, CPU cores, or cache resources to single enclaves. CURE requires minimal hardware changes while significantly improving the state of the art of hardware-assisted security architectures. We implemented CURE on a RISC-V-based SoC and thoroughly evaluated our prototype in terms of hardware and performance overhead. CURE imposes a geometric mean performance overhead of 15.33% on standard benchmarks.",
            "keywords": [
                "Trusted Execution Environments",
                "Customizable Enclaves",
                "Cache Side-Channel Attacks",
                "Resource Isolation",
                "RISC-V Security Architecture"
            ]
        },
        "url": "URL#1888031",
        "sema_paperId": "3f800641a2b3bb9efa66bf6549942b0bd2a1bdda"
    },
    {
        "@score": "1",
        "@id": "1888032",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "161/7805",
                        "text": "Jia-Ju Bai"
                    },
                    {
                        "@pid": "150/1609",
                        "text": "Tuo Li"
                    },
                    {
                        "@pid": "67/10639",
                        "text": "Kangjie Lu"
                    },
                    {
                        "@pid": "h/ShiMinHu",
                        "text": "Shi-Min Hu 0001"
                    }
                ]
            },
            "title": "Static Detection of Unsafe DMA Accesses in Device Drivers.",
            "venue": "USENIX Security Symposium",
            "pages": "1629-1645",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BaiLL021",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/bai",
            "url": "https://dblp.org/rec/conf/uss/BaiLL021",
            "abstract": "Direct Memory Access (DMA) is a popular mechanism for improving hardware I/O performance, and it has been widely used by many existing device drivers. However, DMA accesses can be unsafe, from two aspects. First, without proper synchronization of DMA buffers with hardware registers and CPU cache, the buffer data stored in CPU cache and hardware registers can be inconsistent, which can cause unexpected hardware behaviors. Second, a malfunctioning or untrusted hardware device can write bad data into system memory, which can trigger security bugs (such as buffer over\ufb02ow and invalid-pointer access), if the driver uses the data without correct validation. To detect unsafe DMA accesses, some key challenges need to be solved. For example, because each DMA access is implemented as a regular variable access in the driver code, identifying DMA accesses is dif\ufb01cult. In this paper, we propose a static-analysis approach named SADA, to automatically and accurately detect unsafe DMA accesses in device drivers. SADA consists of three basic steps. First, SADA uses a \ufb01eld-based alias analysis to identify DMA accesses, according to the information of DMA-buffer creation. Second, SADA uses a \ufb02ow-sensitive and pattern-based analysis to check the safety of each DMA access, to detect possible unsafe DMA accesses. Finally, SADA uses an SMT solver to validate the code-path condition of each possible unsafe DMA access, to drop false positives. We have evaluated SADA on the driver code of Linux 5.6, and found 284 real unsafe DMA accesses. Among them, we highlight that 121 can trigger buffer-over\ufb02ow bugs and 36 can trigger invalid-pointer accesses causing arbitrary read or write. We have reported these unsafe DMA accesses to Linux driver developers, and 105 of them have been con\ufb01rmed.",
            "keywords": [
                "DMA Access Safety",
                "Device Driver Security",
                "Static Analysis",
                "Buffer Overflow",
                "Invalid Pointer Access"
            ]
        },
        "url": "URL#1888032",
        "sema_paperId": "57b2d431a440993ee264712abf075c186d9caf2b"
    },
    {
        "@score": "1",
        "@id": "1888034",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "b/DavidABasin",
                        "text": "David A. Basin"
                    },
                    {
                        "@pid": "35/4406",
                        "text": "Ralf Sasse"
                    },
                    {
                        "@pid": "180/7312",
                        "text": "Jorge Toro-Pozo"
                    }
                ]
            },
            "title": "Card Brand Mixup Attack: Bypassing the PIN in non-Visa Cards by Using Them for Visa Transactions.",
            "venue": "USENIX Security Symposium",
            "pages": "179-194",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BasinST21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/basin",
            "url": "https://dblp.org/rec/conf/uss/BasinST21",
            "abstract": "Most EMV transactions require online authorization by the card issuer. Namely, the merchant\u2019s payment terminal sends an authorization request to the card issuer over a payment network, typically operated by the company that brands the card such as Visa or Mastercard. In this paper we show that it is possible to induce a mismatch between the card brand and the payment network, from the terminal\u2019s perspective. The resulting card brand mixup attack has serious security consequences. In particular, it enables criminals to use a vic-tim\u2019s Mastercard contactless card to pay for expensive goods without knowing the card\u2019s PIN. Concretely, the attacker fools the terminal into believing that the card being used is a Visa card and then applies the recent PIN bypass attack that we reported on Visa. We have built an Android application and successfully used it to carry out this attack for transactions with both Mastercard debit and credit cards, including a transaction for over 400 USD with a Maestro debit card. Finally, we extend our formal model of the EMV contactless protocol to machine-check \ufb01xes to the issues found.",
            "keywords": [
                "EMV Transactions",
                "Card Brand Mixup Attack",
                "PIN Bypass",
                "Contactless Payment Security",
                "Mastercard Vulnerability"
            ]
        },
        "url": "URL#1888034",
        "sema_paperId": "7ad05c4864b0f943e80a0e2fc18770c9659e174d"
    },
    {
        "@score": "1",
        "@id": "1888035",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "248/1645",
                        "text": "Hugo L. J. Bijmans"
                    },
                    {
                        "@pid": "248/1711",
                        "text": "Tim M. Booij"
                    },
                    {
                        "@pid": "301/5876",
                        "text": "Anneke Schwedersky"
                    },
                    {
                        "@pid": "301/5916",
                        "text": "Aria Nedgabat"
                    },
                    {
                        "@pid": "224/9337",
                        "text": "Rolf van Wegberg"
                    }
                ]
            },
            "title": "Catching Phishers By Their Bait: Investigating the Dutch Phishing Landscape through Phishing Kit Detection.",
            "venue": "USENIX Security Symposium",
            "pages": "3757-3774",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BijmansBSNW21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/bijmans",
            "url": "https://dblp.org/rec/conf/uss/BijmansBSNW21",
            "abstract": "Off-the-shelf, easy-to-deploy phishing kits are believed to lower the threshold for criminal entrepreneurs going phishing. That is, the practice of harvesting user credentials by tricking victims into disclosing these on fraudulent websites. But, how do these kits impact the phishing landscape? And, how often are they used? We leverage the use of TLS certi\ufb01cates by phishers to uncover possible Dutch phishing domains aimed at the \ufb01nancial sector between September 2020 and January 2021. We collect 70 different Dutch phishing kits in the un-derground economy, and identify 10 distinct kit families. We create unique \ufb01ngerprints of these kits to measure their prevalence in the wild. With this novel method, we identify 1,363 Dutch phishing domains that deploy these phishing kits, and capture their end-to-end life cycle \u2013 from domain registration, kit deployment, to take-down. We \ufb01nd the median uptime of phishing domains to be just 24 hours, indicating that phishers do act fast. Our analysis of the deployed phishing kits reveals that only a small number of different kits are in use. We discover that phishers increase their luring capabilities by using decoy pages to trick victims into disclosing their credentials. In this paper, we paint a comprehensive picture of the tactics, techniques and procedures (TTP) prevalent in the Dutch phishing landscape and present public policy takeaways for anti-phishing initiatives.",
            "keywords": [
                "Phishing Kits",
                "Phishing Domains",
                "Dutch Phishing Landscape",
                "Credential Harvesting",
                "Phishing Tactics and Techniques"
            ]
        },
        "url": "URL#1888035",
        "sema_paperId": "fc1629a712593327cf4df2ead11c7d677acb6d58"
    },
    {
        "@score": "1",
        "@id": "1888036",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "52/8356",
                        "text": "Igor Bilogrevic"
                    },
                    {
                        "@pid": "301/5887",
                        "text": "Balazs Engedy"
                    },
                    {
                        "@pid": "301/5806",
                        "text": "Judson L. Porter III"
                    },
                    {
                        "@pid": "t/NinaTaft",
                        "text": "Nina Taft"
                    },
                    {
                        "@pid": "301/5844",
                        "text": "Kamila Hasanbega"
                    },
                    {
                        "@pid": "301/5869",
                        "text": "Andrew Paseltiner"
                    },
                    {
                        "@pid": "301/5877",
                        "text": "Hwi Kyoung Lee"
                    },
                    {
                        "@pid": "40/202",
                        "text": "Edward Jung"
                    },
                    {
                        "@pid": "301/5805",
                        "text": "Meggyn Watkins"
                    },
                    {
                        "@pid": "301/5850",
                        "text": "P. J. McLachlan"
                    },
                    {
                        "@pid": "163/4653",
                        "text": "Jason James"
                    }
                ]
            },
            "title": "&quot;Shhh...be quiet!&quot; Reducing the Unwanted Interruptions of Notification Permission Prompts on Chrome.",
            "venue": "USENIX Security Symposium",
            "pages": "769-784",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BilogrevicEPTHP21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/bilogrevic",
            "url": "https://dblp.org/rec/conf/uss/BilogrevicEPTHP21",
            "abstract": "Push noti\ufb01cations can be a very useful feature. On web browsers, they allow users to receive timely updates even if the website is not currently open. On Chrome, the feature has become extremely popular since its inception in 2015, but it is also the least likely to be accepted by users. Chrome telemetry shows that, although 74% of all permission prompts are about noti\ufb01cations, they are also the least likely to be granted with only a 10% grant rate on desktop and 21% grant rate on Android. In order to preserve its utility for websites and to reduce unwanted interruptions and potential abuses for the users, we designed and tested both a novel UI and its activation mechanism for noti\ufb01cation permission prompts in Chrome. To understand how users interact with such prompts, we conducted two large-scale studies with more than 300 million users in the wild. The \ufb01rst study showed that most of them block or ignore the prompts across all types of web-sites, which prompted us to rethink its UI and activation logic. The second study, based on an A/B test using behavioral data from more than 40 million users who interacted with more than 100 million prompts on more than 70 thousand websites, show that the new prompt is very effective at reducing unwanted interruptions and their frequency (up to 30% fewer unnecessary actions on the prompts), with a minimal impact (less than 5%) on the grant rates, across all types of users and websites. We achieve these results thanks to a novel adaptive activation mechanism coupled with a block list of interrupting websites,",
            "keywords": [
                "Web Notifications",
                "User Interaction",
                "Permission Prompts",
                "UI Design",
                "User Experience"
            ]
        },
        "url": "URL#1888036",
        "sema_paperId": "6317e4f3680b64479fba1ddfbd977ba8347b937c"
    },
    {
        "@score": "1",
        "@id": "1888037",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "224/9340",
                        "text": "Henry Birge-Lee"
                    },
                    {
                        "@pid": "56/4499-54",
                        "text": "Liang Wang 0054"
                    },
                    {
                        "@pid": "123/3270",
                        "text": "Daniel McCarney"
                    },
                    {
                        "@pid": "301/5892",
                        "text": "Roland Shoemaker"
                    },
                    {
                        "@pid": "r/JenniferRexford",
                        "text": "Jennifer Rexford"
                    },
                    {
                        "@pid": "39/6266",
                        "text": "Prateek Mittal"
                    }
                ]
            },
            "title": "Experiences Deploying Multi-Vantage-Point Domain Validation at Let&apos;s Encrypt.",
            "venue": "USENIX Security Symposium",
            "pages": "4311-4327",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Birge-LeeWMSRM21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/birge-lee",
            "url": "https://dblp.org/rec/conf/uss/Birge-LeeWMSRM21",
            "abstract": "An attacker can obtain a valid TLS certi\ufb01cate for a domain by hijacking communication between a certi\ufb01cate authority (CA) and a victim domain. Performing domain validation from multiple vantage points can defend against these attacks. We explore the design space of multi-vantage-point domain validation to achieve 1) security via suf\ufb01ciently diverse vantage points, (2) performance by ensuring low latency and overhead in certi\ufb01cate issuance, (3) manageability by complying with CA/Browser forum requirements, and requiring minimal changes to CA operations, and (4) a low benign failure rate for legitimate requests. Our open-source implementation was deployed by the Let\u2019s Encrypt CA in February 2020, and has since secured the issuance of more than 300 million certi\ufb01cates. We show our approach has negligible latency and communication overhead, and a benign failure rate comparable to conventional designs with one vantage point. Finally, we evaluate the security improvements using a combination of ethically conducted real-world BGP hijacks, Internet-scale traceroute experiments, and a novel BGP simulation framework. We show that multi-vantage-point domain validation can thwart the vast majority of BGP attacks. Our work motivates the deployment of multi-vantage-point domain validation across the CA ecosystem to strengthen TLS certi\ufb01cate issuance and user privacy.",
            "keywords": [
                "Multi-Vantage-Point Domain Validation",
                "TLS Certificate Issuance",
                "BGP Hijacking",
                "Certificate Authority Security",
                "User Privacy Protection"
            ]
        },
        "url": "URL#1888037",
        "sema_paperId": "f846fc154f2711d0fa6b2a41a500e0c820369d16"
    },
    {
        "@score": "1",
        "@id": "1888038",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "181/5327",
                        "text": "Michael Brengel"
                    },
                    {
                        "@pid": "08/6024",
                        "text": "Christian Rossow"
                    }
                ]
            },
            "title": "YARIX: Scalable YARA-based Malware Intelligence.",
            "venue": "USENIX Security Symposium",
            "pages": "3541-3558",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BrengelR21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/brengel",
            "url": "https://dblp.org/rec/conf/uss/BrengelR21",
            "abstract": "YARA is the industry standard to search for patterns in malware data sets. Malware analysts heavily rely on YARA rules to identify speci\ufb01c threats, e.g., by scanning unknown malware samples for patterns that are characteristic for a certain malware strain. While YARA is tremendously useful to in-spect individual \ufb01les, its run time grows linearly with the number of input \ufb01les, resulting in prohibitive performance penalties in large malware corpora. We present Y AR I X , a methodology to ef\ufb01ciently reveal \ufb01les matching arbitrary YARA rules. In order to scale to large malware corpora, Y AR I X uses an inverted n -gram index that maps \ufb01xed-length byte sequences to lists of \ufb01les in which they appear. To ef\ufb01ciently query such corpora, Y AR I X optimizes YARA searches by transforming YARA rules into index lookups to obtain a set of candidate \ufb01les that potentially match the rule. Given the storage demands that arise when indexing binary \ufb01les, Y AR I X compresses the disk footprint with variable byte delta encoding, abstracts from \ufb01le offsets, and leverages a novel grouping-based compression methodology. This completeness-preserving approximation will then be scanned using YARA to get the actual set of matching \ufb01les. Using 32M malware samples and 1404 YARA rules, we show that Y AR I X scales in both disk footprint and search performance. The index requires just \u2248 74% of the space required for storing the malware samples. Querying Y AR I X with a YARA rule in our test setup is \ufb01ve orders of magnitude faster than using standard sequential YARA scans.",
            "keywords": [
                "Malware Analysis",
                "YARA Rules",
                "Scalability",
                "Inverted N-gram Index",
                "Search Performance"
            ]
        },
        "url": "URL#1888038",
        "sema_paperId": "6b5cf2506919bb8c25b9bb6d24e7ef787115aa44"
    },
    {
        "@score": "1",
        "@id": "1888039",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "76/6564",
                        "text": "Marcus Brinkmann"
                    },
                    {
                        "@pid": "224/9346",
                        "text": "Christian Dresen"
                    },
                    {
                        "@pid": "248/1716",
                        "text": "Robert Merget"
                    },
                    {
                        "@pid": "216/6088",
                        "text": "Damian Poddebniak"
                    },
                    {
                        "@pid": "80/1239-7",
                        "text": "Jens M\u00fcller 0007"
                    },
                    {
                        "@pid": "27/8331",
                        "text": "Juraj Somorovsky"
                    },
                    {
                        "@pid": "58/5730",
                        "text": "J\u00f6rg Schwenk"
                    },
                    {
                        "@pid": "43/11495",
                        "text": "Sebastian Schinzel"
                    }
                ]
            },
            "title": "ALPACA: Application Layer Protocol Confusion - Analyzing and Mitigating Cracks in TLS Authentication.",
            "venue": "USENIX Security Symposium",
            "pages": "4293-4310",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BrinkmannDMP0SS21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/brinkmann",
            "url": "https://dblp.org/rec/conf/uss/BrinkmannDMP0SS21",
            "abstract": "TLS is widely used to add confidentiality, authenticity and integrity to application layer protocols such as HTTP, SMTP, IMAP, POP3, and FTP. However, TLS does not bind a TCP connection to the intended application layer protocol. This allows a man-in-the-middle attacker to redirect TLS traffic to a different TLS service endpoint on another IP address and/or port. For example, if subdomains share a wildcard certificate, an attacker can redirect traffic from one subdomain to another, resulting in a valid TLS session. This breaks the authentication of TLS and cross-protocol attacks may be possible where the behavior of one service may compromise the security of the other at the application layer. In this paper, we investigate cross-protocol attacks on TLS in general and conduct a systematic case study on web servers, redirecting HTTPS requests from a victim\u2019s web browser to SMTP, IMAP, POP3, and FTP servers. We show that in realistic scenarios, the attacker can extract session cookies and other private user data or execute arbitrary JavaScript in the context of the vulnerable web server, therefore bypassing TLS and web application security. We evaluate the real-world attack surface of web browsers and widely-deployed email and FTP servers in lab experiments and with internet-wide scans. We find that 1.4M web servers are generally vulnerable to cross-protocol attacks, i.e., TLS application data confusion is possible. Of these, 114k web servers can be attacked using an exploitable application server. Finally, we discuss the effectiveness of TLS extensions such as Application Layer Protocol Negotiation (ALPN) and Server Name Indiciation (SNI) in mitigating these and other cross-protocol attacks.",
            "keywords": [
                "TLS Authentication",
                "Cross-Protocol Attacks",
                "Application Layer Protocols",
                "Man-in-the-Middle Attacks",
                "TLS Application Data Confusion"
            ]
        },
        "url": "URL#1888039",
        "sema_paperId": "2ab7bbdb89f98535a1447c0bc909f3eaadf2a93d"
    },
    {
        "@score": "1",
        "@id": "1888040",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "294/4488",
                        "text": "Alexander Bulekov"
                    },
                    {
                        "@pid": "220/2510",
                        "text": "Rasoul Jahanshahi"
                    },
                    {
                        "@pid": "27/3108",
                        "text": "Manuel Egele"
                    }
                ]
            },
            "title": "Saphire: Sandboxing PHP Applications with Tailored System Call Allowlists.",
            "venue": "USENIX Security Symposium",
            "pages": "2881-2898",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BulekovJE21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/bulekov",
            "url": "https://dblp.org/rec/conf/uss/BulekovJE21",
            "abstract": "Interpreted languages, such as PHP, power a host of platform-independent applications, including websites, instant messengers, video games, and development environments. With the \ufb02ourishing popularity of these applications, attackers have honed in on \ufb01nding and exploiting vulnerabilities in interpreted code. Generally, all parts of an interpreted application execute with uniform and super\ufb02uous privileges, increasing the potential damage from an exploit. This lack of privilege-separation is in stark violation of the principle of least privilege(PoLP). Despite 1,980 web app remote code execution (RCE) vulnerabilities discovered in 2018 alone [25], current defenses rely on incomplete detection of vulnerable code, or extensive collections of benign inputs. Considering the limitations of bug-\ufb01nding systems, the violation of the PoLP exposes systems to unnecessarily-high risks. In this paper, we identify the current challenges with applying the PoLP to interpreted PHP applications, and propose a novel generic approach for automatically deriving system-call policies for individual interpreted programs. This effectively reduces the attack surface (i.e., set of system-calls) an exploit can leverage to the system-calls the script needs to perform its benign functionality. We name our implementation of this approach, Saphire, and thoroughly evaluate the prototype with respect to its security and performance characteristics. Our evaluation on 21 known vulnerable web apps and plugins shows that Saphire successfully prevents RCE exploits, and is able to do so with negligible performance overhead (i.e., <2% in the worst case) for real-world web apps. Saphire performs its service without causing false positives over automatically and manually generated benign traf\ufb01c to each web app.",
            "keywords": [
                "PHP Application Security",
                "System Call Policies",
                "Remote Code Execution (RCE)",
                "Principle of Least Privilege (PoLP)",
                "Sandboxing"
            ]
        },
        "url": "URL#1888040",
        "sema_paperId": "8606135dfcf7a5e1c88eaf32c891fa9e940166bf"
    },
    {
        "@score": "1",
        "@id": "1888041",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "13/8970",
                        "text": "Patricia Arias Cabarcos"
                    },
                    {
                        "@pid": "222/8416",
                        "text": "Thilo Habrich"
                    },
                    {
                        "@pid": "98/11488",
                        "text": "Karen Becker"
                    },
                    {
                        "@pid": "b/ChristianBecker",
                        "text": "Christian Becker 0001"
                    },
                    {
                        "@pid": "69/2809",
                        "text": "Thorsten Strufe"
                    }
                ]
            },
            "title": "Inexpensive Brainwave Authentication: New Techniques and Insights on User Acceptance.",
            "venue": "USENIX Security Symposium",
            "pages": "55-72",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CabarcosHB0S21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/arias-cabarcos",
            "url": "https://dblp.org/rec/conf/uss/CabarcosHB0S21",
            "abstract": "Brainwaves have proved to be unique enough across individuals to be useful as biometrics. They also provide promising advantages over traditional means of authentication, such as resistance to external observability, revocability, and intrinsic liveness detection. However, most of the research so far has been conducted with expensive, bulky, medical-grade helmets, which offer limited applicability for everyday usage. With the aim to bring brainwave authentication and its bene\ufb01ts closer to real world deployment, we investigate brain biometrics with consumer devices. We conduct a comprehensive experiment that compares \ufb01ve authentication tasks on a user sample up to 10 times larger than those from previous studies, introducing three novel techniques based on cognitive semantic processing. We analyze both the performance and usability of the different options and use this evidence to elicit design and research recommendations. Our results show that it is possible to achieve Equal Error Rates of 14.5% (a reduction between 37%-44% with respect to existing approaches) based on brain responses to images with current inexpensive technology. With regard to adoption, users call for simpler devices, faster authentication, and better privacy.",
            "keywords": [
                "Brainwave Authentication",
                "Biometrics",
                "Cognitive Semantic Processing",
                "User Acceptance",
                "Equal Error Rate"
            ]
        },
        "url": "URL#1888041",
        "sema_paperId": "87a996d6ebf6482ac255021fbb02489d427db0dd"
    },
    {
        "@score": "1",
        "@id": "1888043",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "146/9100",
                        "text": "Xiaoyu Cao"
                    },
                    {
                        "@pid": "24/5124-1",
                        "text": "Jinyuan Jia 0001"
                    },
                    {
                        "@pid": "03/9437",
                        "text": "Neil Zhenqiang Gong"
                    }
                ]
            },
            "title": "Data Poisoning Attacks to Local Differential Privacy Protocols.",
            "venue": "USENIX Security Symposium",
            "pages": "947-964",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CaoJG21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/cao-xiaoyu",
            "url": "https://dblp.org/rec/conf/uss/CaoJG21",
            "abstract": "Local Differential Privacy (LDP) protocols enable an untrusted data collector to perform privacy-preserving data analytics. In particular, each user locally perturbs its data to preserve privacy before sending it to the data collector, who aggregates the perturbed data to obtain statistics of interest. In the past several years, researchers from multiple communities\u2014such as security, database, and theoretical computer science\u2014have proposed many LDP protocols. These studies mainly focused on improving the utility of the LDP protocols. However, the security of LDP protocols is largely unexplored.\nIn this work, we aim to bridge this gap. We focus on LDP protocols for frequency estimation and heavy hitter identification, which are two basic data analytics tasks. Specifically, we show that an attacker can inject fake users into an LDP protocol and the fake users send carefully crafted data to the data collector such that the LDP protocol estimates high frequencies for arbitrary attacker-chosen items or identifies them as heavy hitters. We call our attacks data poisoning attacks. We theoretically and/or empirically show the effectiveness of our attacks. We also explore three countermeasures against our attacks. Our experimental results show that they can effectively defend against our attacks in some scenarios but have limited effectiveness in others, highlighting the needs for new defenses against our attacks.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-cao-xiaoyu.pdf",
            "keywords": [
                "Local Differential Privacy",
                "Data Poisoning Attacks",
                "Frequency Estimation",
                "Heavy Hitter Identification",
                "Privacy-Preserving Data Analytics"
            ]
        },
        "url": "URL#1888043"
    },
    {
        "@score": "1",
        "@id": "1888044",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "301/5889",
                        "text": "Weicheng Cao"
                    },
                    {
                        "@pid": "228/8982",
                        "text": "Chunqiu Xia"
                    },
                    {
                        "@pid": "91/8283",
                        "text": "Sai Teja Peddinti"
                    },
                    {
                        "@pid": "l/DavidLie",
                        "text": "David Lie"
                    },
                    {
                        "@pid": "t/NinaTaft",
                        "text": "Nina Taft"
                    },
                    {
                        "@pid": "169/3376",
                        "text": "Lisa M. Austin"
                    }
                ]
            },
            "title": "A Large Scale Study of User Behavior, Expectations and Engagement with Android Permissions.",
            "venue": "USENIX Security Symposium",
            "pages": "803-820",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CaoXPLTA21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/cao-weicheng",
            "url": "https://dblp.org/rec/conf/uss/CaoXPLTA21",
            "abstract": "We conduct a global study on the behaviors, expectations and engagement of 1,719 participants across 10 countries and regions towards Android application permissions. Participants were recruited using mobile advertising and used an application we designed for 30 days. Our app samples user behaviors (decisions made), rationales (via in-situ surveys), expectations, and attitudes, as well as some app provided explanations. We study the grant and deny decisions our users make, and build mixed effect logistic regression models to illustrate the many factors that influence this decision making. Among several interesting findings, we observed that users facing an unexpected permission request are more than twice as likely to deny it compared to a user who expects it, and that permission requests accompanied by an explanation have a deny rate that is roughly half the deny rate of app permission requests without explanations. These findings remain true even when controlling for other factors. To the best of our knowledge, this may be the first study of actual privacy behavior (not stated behavior) for Android apps, with users using their own devices, across multiple continents.",
            "keywords": [
                "Android Permissions",
                "User Behavior",
                "Privacy Expectations",
                "Permission Requests",
                "User Engagement"
            ]
        },
        "url": "URL#1888044",
        "sema_paperId": "7435464635ddbe108e87ea93f3fb78ec701aeba1"
    },
    {
        "@score": "1",
        "@id": "1888045",
        "info": {
            "authors": {
                "author": {
                    "@pid": "145/1806",
                    "text": "Nicholas Carlini"
                }
            },
            "title": "Poisoning the Unlabeled Dataset of Semi-Supervised Learning.",
            "venue": "USENIX Security Symposium",
            "pages": "1577-1592",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Carlini21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/carlini-poisoning",
            "url": "https://dblp.org/rec/conf/uss/Carlini21",
            "abstract": "Semi-supervised machine learning models learn from a (small) set of labeled training examples, and a (large) set of unlabeled training examples. State-of-the-art models can reach within a few percentage points of fully-supervised training, while requiring 100x less labeled data.We study a new class of vulnerabilities: poisoning attacks that modify the unlabeled dataset. In order to be useful, un-labeled datasets are given strictly less review than labeled datasets, and adversaries can therefore poison them easily. By inserting maliciously-crafted unlabeled examples totaling just 0.1% of the dataset size, we can manipulate a model trained on this poisoned dataset to misclassify arbitrary examples at test time (as any desired label). Our attacks are highly effective across datasets and semi-supervised learning methods.We find that more accurate methods (thus more likely to be used) are significantly more vulnerable to poisoning attacks, and as such better training methods are unlikely to prevent this attack. To counter this we explore the space of defenses, and propose two methods that mitigate our attack.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-carlini-poisoning.pdf",
            "keywords": [
                "Semi-Supervised Learning",
                "Poisoning Attacks",
                "Unlabeled Dataset",
                "Model Manipulation",
                "Defenses Against Attacks"
            ]
        },
        "url": "URL#1888045"
    },
    {
        "@score": "1",
        "@id": "1888046",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "145/1806",
                        "text": "Nicholas Carlini"
                    },
                    {
                        "@pid": "158/7224",
                        "text": "Florian Tram\u00e8r"
                    },
                    {
                        "@pid": "218/6165",
                        "text": "Eric Wallace"
                    },
                    {
                        "@pid": "218/5156",
                        "text": "Matthew Jagielski"
                    },
                    {
                        "@pid": "154/6582",
                        "text": "Ariel Herbert-Voss"
                    },
                    {
                        "@pid": "115/5082",
                        "text": "Katherine Lee"
                    },
                    {
                        "@pid": "95/6569",
                        "text": "Adam Roberts"
                    },
                    {
                        "@pid": "211/7884",
                        "text": "Tom B. Brown"
                    },
                    {
                        "@pid": "s/DXSong",
                        "text": "Dawn Song"
                    },
                    {
                        "@pid": "e/UErlingsson",
                        "text": "\u00dalfar Erlingsson"
                    },
                    {
                        "@pid": "35/3425",
                        "text": "Alina Oprea"
                    },
                    {
                        "@pid": "149/0082",
                        "text": "Colin Raffel"
                    }
                ]
            },
            "title": "Extracting Training Data from Large Language Models.",
            "venue": "USENIX Security Symposium",
            "pages": "2633-2650",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CarliniTWJHLRBS21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/carlini-extracting",
            "url": "https://dblp.org/rec/conf/uss/CarliniTWJHLRBS21",
            "abstract": "It has become common to publish large (billion parameter) language models that have been trained on private datasets. This paper demonstrates that in such settings, an adversary can perform a training data extraction attack to recover individual training examples by querying the language model.We demonstrate our attack on GPT-2, a language model trained on scrapes of the public Internet, and are able to extract hundreds of verbatim text sequences from the model's training data. These extracted examples include (public) personally identifiable information (names, phone numbers, and email addresses), IRC conversations, code, and 128-bit UUIDs. Our attack is possible even though each of the above sequences are included in just one document in the training data.We comprehensively evaluate our extraction attack to understand the factors that contribute to its success. Worryingly, we find that larger models are more vulnerable than smaller models. We conclude by drawing lessons and discussing possible safeguards for training large language models.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-carlini-extracting.pdf",
            "keywords": [
                "Training Data Extraction",
                "Language Model Vulnerability",
                "Adversarial Attacks",
                "Data Privacy",
                "GPT-2"
            ]
        },
        "url": "URL#1888046"
    },
    {
        "@score": "1",
        "@id": "1888047",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "245/4979",
                        "text": "Sylvain Chatel"
                    },
                    {
                        "@pid": "66/7821",
                        "text": "Apostolos Pyrgelis"
                    },
                    {
                        "@pid": "33/5866",
                        "text": "Juan Ram\u00f3n Troncoso-Pastoriza"
                    },
                    {
                        "@pid": "h/JPHubaux",
                        "text": "Jean-Pierre Hubaux"
                    }
                ]
            },
            "title": "Privacy and Integrity Preserving Computations with CRISP.",
            "venue": "USENIX Security Symposium",
            "pages": "2111-2128",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChatelPTH21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/chatel",
            "url": "https://dblp.org/rec/conf/uss/ChatelPTH21",
            "abstract": "In the digital era, users share their personal data with service providers to obtain some utility, e.g., access to high-quality services. Yet, the induced information flows raise privacy and integrity concerns. Consequently, cautious users may want to protect their privacy by minimizing the amount of information they disclose to curious service providers. Service providers are interested in verifying the integrity of the users' data to improve their services and obtain useful knowledge for their business. In this work, we present a generic solution to the trade-off between privacy, integrity, and utility, by achieving authenticity verification of data that has been encrypted for offloading to service providers. Based on lattice-based homomorphic encryption and commitments, as well as zero-knowledge proofs, our construction enables a service provider to process and reuse third-party signed data in a privacy-friendly manner with integrity guarantees. We evaluate our solution on different use cases such as smart-metering, disease susceptibility, and location-based activity tracking, thus showing its promising applications. Our solution achieves broad generality, quantum-resistance, and relaxes some assumptions of state-of-the-art solutions without affecting performance.",
            "keywords": [
                "Privacy-Preserving Computation",
                "Integrity Verification",
                "Homomorphic Encryption",
                "Zero-Knowledge Proofs",
                "Data Authenticity"
            ]
        },
        "url": "URL#1888047",
        "sema_paperId": "5152e6db0d1695e980c252887e6c66f4d7b5d099"
    },
    {
        "@score": "1",
        "@id": "1888048",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "09/7487-1",
                        "text": "Yizheng Chen 0001"
                    },
                    {
                        "@pid": "58/9145-2",
                        "text": "Shiqi Wang 0002"
                    },
                    {
                        "@pid": "255/5076",
                        "text": "Weifan Jiang"
                    },
                    {
                        "@pid": "35/10805",
                        "text": "Asaf Cidon"
                    },
                    {
                        "@pid": "74/28",
                        "text": "Suman Jana"
                    }
                ]
            },
            "title": "Cost-Aware Robust Tree Ensembles for Security Applications.",
            "venue": "USENIX Security Symposium",
            "pages": "2291-2308",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Chen0JCJ21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/chen-yizheng",
            "url": "https://dblp.org/rec/conf/uss/Chen0JCJ21",
            "abstract": "Features of security classifiers have various costs to be manipulated. The costs are asymmetric across features and to the directions of changes, which cannot be precisely captured by existing cost models based on $L_p$-norm robustness. In this paper, we utilize such domain knowledge to increase the evasion cost against security classifiers, specifically, tree ensemble models that are widely used by security tasks. We propose a new cost modeling method to capture the domain knowledge of features as constraint, and then we integrate the cost-driven constraint into the node construction process to train robust tree ensembles. During the training process, we use the constraint to find data points that are likely to be perturbed given the costs of the features, and we optimize the quality of the trees using a new robust training algorithm. Our cost-aware training method can be applied to different types of tree ensembles, including random forest model that cannot be robustly trained by previous methods. Using twitter spam detection as the security application, our evaluation results show that training cost-aware robust model can rank high cost features as the most important ones, and increase the adaptive attack cost by 6.4X compared to the baseline. Our code is available at this https URL.",
            "keywords": [
                "Cost-Aware Robustness",
                "Tree Ensembles",
                "Security Classifiers",
                "Evasion Cost",
                "Adaptive Attack Cost"
            ]
        },
        "url": "URL#1888048",
        "sema_paperId": "1e2e225e87477d43cfbbad5456d6e3423ec6d523"
    },
    {
        "@score": "1",
        "@id": "1888049",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "227/9058",
                        "text": "Kaixiang Chen"
                    },
                    {
                        "@pid": "94/3019-8",
                        "text": "Chao Zhang 0008"
                    },
                    {
                        "@pid": "40/4177",
                        "text": "Tingting Yin"
                    },
                    {
                        "@pid": "277/8177",
                        "text": "Xingman Chen"
                    },
                    {
                        "@pid": "87/734",
                        "text": "Lei Zhao"
                    }
                ]
            },
            "title": "VScape: Assessing and Escaping Virtual Call Protections.",
            "venue": "USENIX Security Symposium",
            "pages": "1719-1736",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Chen0YCZ21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/chen-kaixiang",
            "url": "https://dblp.org/rec/conf/uss/Chen0YCZ21",
            "abstract": "Many control-\ufb02ow integrity (CFI) solutions have been proposed to protect indirect control transfers (ICT), including C++ virtual calls. Assessing the security guarantees of these defenses is thus important but hard. In practice, for a (strong) defense, it usually requires abundant manual efforts to assess whether it could be bypassed, when given a speci\ufb01c (weak) vulnerability. Existing automated exploit generation solutions, which are proposed to assess the exploitability of vulnerabilities, have not addressed this issue yet.In this paper, we point out that a wide range of virtual call protections, which do not break the C++ ABI (application binary interface), are vulnerable to an advanced attack COOPLUS, even if the given vulnerabilities are weak. Then, we present a solution VScape to assess the effectiveness of virtual call protections against this attack. We developed a prototype of VScape, and utilized it to assess 11 CFI solutions and 14 C++ applications (including Firefox and PyQt) with known vulnerabilities. Results showed that real-world applications have a large set of exploitable virtual calls, and VScape could be utilized to generate working exploits to bypass deployed defenses via weak vulnerabilities.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-chen-kaixiang.pdf",
            "keywords": [
                "Control-Flow Integrity",
                "C++ Virtual Calls",
                "Exploit Generation",
                "Vulnerability Assessment",
                "COOPLUS Attack"
            ]
        },
        "url": "URL#1888049"
    },
    {
        "@score": "1",
        "@id": "1888050",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "301/5879",
                        "text": "Xutong Chen"
                    },
                    {
                        "@pid": "166/4235",
                        "text": "Hassaan Irshad"
                    },
                    {
                        "@pid": "88/2827-4",
                        "text": "Yan Chen 0004"
                    },
                    {
                        "@pid": "21/2267",
                        "text": "Ashish Gehani"
                    },
                    {
                        "@pid": "75/3570",
                        "text": "Vinod Yegneswaran"
                    }
                ]
            },
            "title": "CLARION: Sound and Clear Provenance Tracking for Microservice Deployments.",
            "venue": "USENIX Security Symposium",
            "pages": "3989-4006",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChenI0GY21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/chen-xutong",
            "url": "https://dblp.org/rec/conf/uss/ChenI0GY21",
            "abstract": "Linux container-based microservices have emerged as an attractive alternative to virtualization as they reduce application footprints and facilitate more ef\ufb01cient resource utilization. Their popularity has also led to increased scrutiny of the underlying security properties and attack surface of container technology. Provenance-based analysis techniques have been proposed as an effective means toward comprehensive and high-assurance security control as they provide \ufb01ne-grained mechanisms to track data \ufb02ows across the system and detect unwanted or unexpected changes to data objects. However, existing provenance tracking techniques are limited in their ability to build sound and clear provenance in container network environments due to complexities introduced by namespace virtualization . We describe a namespace-and container-aware provenance tracking solution, called CLARION, that addresses the unique soundness and clarity challenges introduced by traditional provenance tracking solutions. Speci\ufb01cally, we \ufb01rst describe fragmentation and ambiguities introduced in provenance analysis tools by each of the Linux namespaces and propose solutions to address analysis soundness. Then we discuss the design of specialized semantics-summarization techniques that improve the clarity of provenance analysis. We have developed a prototype implementation of CLARION and evaluate its performance against a spectrum of container-speci\ufb01c attacks. The results demonstrate the utility of our sys-tem and how it outperforms the state-of-the-art provenance tracking systems by providing an accurate and concise view of data provenance in container environments.",
            "keywords": [
                "Microservice Security",
                "Provenance Tracking",
                "Container Environments",
                "Namespace Virtualization",
                "Data Flow Analysis"
            ]
        },
        "url": "URL#1888050",
        "sema_paperId": "25148cd5dc92ca721fe2aebdf43b1d80a27de56f"
    },
    {
        "@score": "1",
        "@id": "1888051",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "299/3289",
                        "text": "Paizhuo Chen"
                    },
                    {
                        "@pid": "13/7007",
                        "text": "Lei Li"
                    },
                    {
                        "@pid": "162/5529",
                        "text": "Zhice Yang"
                    }
                ]
            },
            "title": "Cross-VM and Cross-Processor Covert Channels Exploiting Processor Idle Power Management.",
            "venue": "USENIX Security Symposium",
            "pages": "733-750",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChenLY21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/chen-paizhuo",
            "url": "https://dblp.org/rec/conf/uss/ChenLY21",
            "abstract": "To achieve power-ef\ufb01cient computing, processors engage idle power management mechanisms to turn on/off idle components according to the dynamics of the workload. A pro-cessor\u2019s hardware components are classi\ufb01ed and managed through the core and the uncore. The uncore is the supporting hardware shared by the cores, hence the decision of turning it on/off depends on the cores\u2019 activities. Such dependency implies a covert channel threat in multi-core platforms. Specifically, the power status of the uncore re\ufb02ects the workload pattern of the active core, and it can be probed by any process running on the processor. This allows the process to infer the workload information of the active core. We show this covert channel can work across processors and violate VM isolation. We validate the channel in in-house testbeds as well as proprietary cloud servers.",
            "keywords": [
                "Covert Channels",
                "Power Management",
                "Multi-Core Processors",
                "VM Isolation",
                "Workload Inference"
            ]
        },
        "url": "URL#1888051",
        "sema_paperId": "4d4b27302672984cd0dc220536d4f1f4f863a1b8"
    },
    {
        "@score": "1",
        "@id": "1888052",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "198/6782",
                        "text": "Sanchuan Chen"
                    },
                    {
                        "@pid": "49/4102-1",
                        "text": "Zhiqiang Lin 0001"
                    },
                    {
                        "@pid": "77/3503",
                        "text": "Yinqian Zhang"
                    }
                ]
            },
            "title": "SelectiveTaint: Efficient Data Flow Tracking With Static Binary Rewriting.",
            "venue": "USENIX Security Symposium",
            "pages": "1665-1682",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChenLZ21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/chen-sanchuan",
            "url": "https://dblp.org/rec/conf/uss/ChenLZ21",
            "abstract": "Taint analysis has been widely used in many security applications such as exploit detection, information \ufb02ow tracking, malware analysis, and protocol reverse engineering. State-of-the-art taint analysis tools are usually built atop dynamic binary instrumentation, which instruments at every possible instruction, and rely on runtime information to decide whether a particular instruction involves taint or not, thereby usually having high performance overhead. This paper presents S ELECTIVE - T AINT , an ef\ufb01cient selective taint analysis framework for binary executables. The key idea is to selectively instrument the instructions involving taint analysis using static binary rewriting instead of dynamic binary instrumentation. At a high level, S ELECTIVE T AINT statically scans taint sources of interest in the binary code, leverages value set analysis to conservatively determine whether an instruction operand needs to be tainted or not, and then selectively taints the instructions of interest. We have implemented S ELECTIVE T AINT and evaluated it with a set of binary programs including 16 coreutils (focusing on \ufb01le I/O) and \ufb01ve network daemon programs (focusing on network I/O) such as nginx web server. Our evaluation results show that the binaries statically instrumented by S E - LECTIVE T AINT has superior performance compared to the state-of-the-art dynamic taint analysis frameworks (e.g., 1.7x faster than that of libdft ).",
            "keywords": [
                "Taint Analysis",
                "Static Binary Rewriting",
                "Dynamic Binary Instrumentation",
                "Performance Overhead",
                "Selective Instrumentation"
            ]
        },
        "url": "URL#1888052",
        "sema_paperId": "591f55151fb21597fd56bc5d2d19c158f1d3ddd5"
    },
    {
        "@score": "1",
        "@id": "1888053",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "239/4477",
                        "text": "Zitai Chen"
                    },
                    {
                        "@pid": "296/7450",
                        "text": "Georgios Vasilakis"
                    },
                    {
                        "@pid": "272/8308",
                        "text": "Kit Murdock"
                    },
                    {
                        "@pid": "301/5813",
                        "text": "Edward Dean"
                    },
                    {
                        "@pid": "190/2073",
                        "text": "David F. Oswald"
                    },
                    {
                        "@pid": "42/1707",
                        "text": "Flavio D. Garcia"
                    }
                ]
            },
            "title": "VoltPillager: Hardware-based fault injection attacks against Intel SGX Enclaves using the SVID voltage scaling interface.",
            "venue": "USENIX Security Symposium",
            "pages": "699-716",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChenVMDOG21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/chen-zitai",
            "url": "https://dblp.org/rec/conf/uss/ChenVMDOG21",
            "abstract": "Hardware-based fault injection attacks such as voltage and clock glitching have been thoroughly studied on embedded devices. Typical targets for such attacks include smartcards and low-power microcontrollers used in IoT devices. This paper presents the first hardware-based voltage glitching attack against a fully-fledged Intel CPU. The transition to complex CPUs is not trivial due to several factors, including: a complex operating system, large power consumption, multi-threading, and high clock speeds. To this end, we have built VoltPillager, a low-cost tool for injecting messages on the Serial Voltage Identification bus between the CPU and the voltage regulator on the motherboard. This allows us to precisely control the CPU core voltage. We leverage this powerful tool to mount fault-injection attacks that breach confidentiality and integrity of Intel SGX enclaves. We present proof-of-concept key-recovery attacks against cryptographic algorithms running inside SGX. We demonstrate that VoltPillager attacks are more powerful than recent software-only undervolting attacks against SGX (CVE-2019-11157) because they work on fully patched systems with all countermeasures against software undervolting enabled. Additionally, we are able to fault securitycritical operations by delaying memory writes. Mitigation of VoltPillager is not straightforward and may require a rethink of the SGX adversarial model where a cloud provider is untrusted and has physical access to the hardware.",
            "keywords": [
                "Hardware-based Attacks",
                "Fault Injection",
                "Intel SGX",
                "Voltage Glitching",
                "Cryptographic Key Recovery"
            ]
        },
        "url": "URL#1888053",
        "sema_paperId": "19147fdf21e0200e6eebe89663afd7b772ee2813"
    },
    {
        "@score": "1",
        "@id": "1888054",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "08/4315-1",
                        "text": "Libo Chen 0001"
                    },
                    {
                        "@pid": "123/2365",
                        "text": "Yanhao Wang"
                    },
                    {
                        "@pid": "222/1244",
                        "text": "Quanpu Cai"
                    },
                    {
                        "@pid": "301/5839",
                        "text": "Yunfan Zhan"
                    },
                    {
                        "@pid": "70/2543-4",
                        "text": "Hong Hu 0004"
                    },
                    {
                        "@pid": "301/5914",
                        "text": "Jiaqi Linghu"
                    },
                    {
                        "@pid": "276/0713",
                        "text": "Qinsheng Hou"
                    },
                    {
                        "@pid": "94/3019-8",
                        "text": "Chao Zhang 0008"
                    },
                    {
                        "@pid": "36/5143",
                        "text": "Haixin Duan"
                    },
                    {
                        "@pid": "44/3322",
                        "text": "Zhi Xue"
                    }
                ]
            },
            "title": "Sharing More and Checking Less: Leveraging Common Input Keywords to Detect Bugs in Embedded Systems.",
            "venue": "USENIX Security Symposium",
            "pages": "303-319",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChenWCZ0LH0DX21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/chen-libo",
            "url": "https://dblp.org/rec/conf/uss/ChenWCZ0LH0DX21",
            "abstract": "IoT devices have brought invaluable convenience to our daily life. However, their pervasiveness also amplifies the impact of security vulnerabilities. Many popular vulnerabilities of embedded systems reside in their vulnerable web services. Unfortunately, existing vulnerability detection methods cannot effectively nor efficiently analyze such web services: they either introduce heavy execution overheads or have many false positives and false negatives. In this paper, we propose a novel static taint checking solution, SaTC, to effectively detect security vulnerabilities in web services provided by embedded devices. Our key insight is that, string literals on web interfaces are commonly shared between front-end files and back-end binaries to encode user input. We thus extract such common keywords from the frontend, and use them to locate reference points in the back-end, which indicate the input entry. Then, we apply targeted dataflow analysis to accurately detect dangerous uses of the untrusted user input. We implemented a prototype of SaTC and evaluated it on 39 embedded system firmwares from six popular vendors. SaTC discovered 33 unknown bugs, of which 30 are confirmed by CVE/CNVD/PSV. Compared to the state-ofthe-art tool KARONTE, SaTC found significantly more bugs on the test set. It shows that, SaTC is effective in discovering bugs in embedded systems.",
            "keywords": [
                "Embedded Systems Security",
                "Vulnerability Detection",
                "Static Taint Analysis",
                "Web Services",
                "User Input Handling"
            ]
        },
        "url": "URL#1888054",
        "sema_paperId": "a828c46236a1433b1041480c478597d73446efc7"
    },
    {
        "@score": "1",
        "@id": "1888055",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "221/3017",
                        "text": "Binlin Cheng"
                    },
                    {
                        "@pid": "09/6585-2",
                        "text": "Jiang Ming 0002"
                    },
                    {
                        "@pid": "301/5851",
                        "text": "Erika A. Leal"
                    },
                    {
                        "@pid": "83/4184",
                        "text": "Haotian Zhang"
                    },
                    {
                        "@pid": "44/2489",
                        "text": "Jianming Fu"
                    },
                    {
                        "@pid": "30/4066",
                        "text": "Guojun Peng"
                    },
                    {
                        "@pid": "m/JeanYvesMarion",
                        "text": "Jean-Yves Marion"
                    }
                ]
            },
            "title": "Obfuscation-Resilient Executable Payload Extraction From Packed Malware.",
            "venue": "USENIX Security Symposium",
            "pages": "3451-3468",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Cheng0LZFPM21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/cheng-binlin",
            "url": "https://dblp.org/rec/conf/uss/Cheng0LZFPM21",
            "abstract": "Over the past two decades, packed malware is always a ve-ritable challenge to security analysts. Not only is determining the end of the unpacking increasingly dif\ufb01cult, but also advanced packers embed a variety of anti-analysis tricks to impede reverse engineering. As malware\u2019s APIs provide rich information about malicious behavior, one common anti-analysis strategy is API obfuscation, which removes the metadata of imported APIs from malware\u2019s PE header and complicates API name resolution from API callsites. In this way, even when security analysts obtain the unpacked code, a disassem-bler still fails to recognize imported API names, and the unpac-ked code cannot be successfully executed. Recently, generic binary unpacking has made breakthrough progress with noticeable performance improvement. However, reconstructing unpacked code\u2019s import tables, which is vital for further malware static/dynamic analyses, has largely been overlooked. Existing approaches are far from mature: they either can be easily evaded by various API obfuscation schemes (e.g., stolen code), or suffer from incomplete API coverage. In this paper, we aim to achieve the ultimate goal of Windows malware unpacking: recovering an executable malware program from the packed and obfuscated binary code. Based on the process memory when the original entry point (OEP) is",
            "keywords": [
                "Packed Malware",
                "API Obfuscation",
                "Executable Payload Extraction",
                "Malware Unpacking",
                "Reverse Engineering"
            ]
        },
        "url": "URL#1888055",
        "sema_paperId": "f37e00cf4c5e7466f515cf3650c238edfd834a65"
    },
    {
        "@score": "1",
        "@id": "1888056",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "63/4074",
                        "text": "Yushi Cheng"
                    },
                    {
                        "@pid": "39/1697-1",
                        "text": "Xiaoyu Ji 0001"
                    },
                    {
                        "@pid": "213/9461",
                        "text": "Lixu Wang"
                    },
                    {
                        "@pid": "44/8421",
                        "text": "Qi Pang"
                    },
                    {
                        "@pid": "91/699-1",
                        "text": "Yi-Chao Chen 0001"
                    },
                    {
                        "@pid": "10/3878-1",
                        "text": "Wenyuan Xu 0001"
                    }
                ]
            },
            "title": "mID: Tracing Screen Photos via Moir\u00e9 Patterns.",
            "venue": "USENIX Security Symposium",
            "pages": "2969-2986",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChengJWP0X21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/cheng-yushi",
            "url": "https://dblp.org/rec/conf/uss/ChengJWP0X21",
            "abstract": "Cyber-theft of trade secrets has become a serious business threat. Digital watermarking is a popular technique to assist in identifying the source of the \ufb01le leakage, whereby a unique watermark for each insider is hidden in sensitive \ufb01les. However, malicious insiders may use their smartphones to photograph the secret \ufb01le displayed on screens to remove the embedded hidden digital watermarks due to the optical noises introduced during photographing. To identify the leakage source despite such screen-photo-based leakage attacks , we leverage Moir\u00e9 pattern, an optical phenomenon resulted from the optical interaction between electronic screens and cameras. As such, we present mID , a new watermark-like technique that can create a carefully crafted Moir\u00e9 pattern on the photo when it is taken towards the screen. We design patterns that appear to be natural yet can be linked to the identity of the leaker. We implemented mID and evaluate it with 5 display devices and 6 smartphones from various manufacturers and models. The results demonstrate that mID can achieve an average bit error rate (BER) of 0 . 6% and can successfully identify an ID with an average accuracy of 96%, with little in\ufb02uence from the type of display devices, cameras, IDs, and ambient lights.",
            "keywords": [
                "Digital Watermarking",
                "Moir\u00e9 Patterns",
                "Trade Secret Protection",
                "Screen Photo Leakage",
                "Insider Threats"
            ]
        },
        "url": "URL#1888056",
        "sema_paperId": "ca9154fcb8fbc0fc519041df0376bdb8afc88a19"
    },
    {
        "@score": "1",
        "@id": "1888057",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "180/8231",
                        "text": "Haibo Cheng"
                    },
                    {
                        "@pid": "29/4801-2",
                        "text": "Wenting Li 0002"
                    },
                    {
                        "@pid": "37/1304-3",
                        "text": "Ping Wang 0003"
                    },
                    {
                        "@pid": "02/4329",
                        "text": "Chao-Hsien Chu"
                    },
                    {
                        "@pid": "126/6037",
                        "text": "Kaitai Liang"
                    }
                ]
            },
            "title": "Incrementally Updateable Honey Password Vaults.",
            "venue": "USENIX Security Symposium",
            "pages": "857-874",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChengL0CL21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/cheng-haibo",
            "url": "https://dblp.org/rec/conf/uss/ChengL0CL21",
            "abstract": "Password vault applications allow a user to store multiple passwords in a vault and choose a master password to encrypt the vault. In practice, attackers may steal the storage file of the vault and further compromise all stored passwords by offline guessing the master password. Honey vaults have been proposed to address the threat. By producing plausible-looking decoy vaults for wrong master passwords, honey vaults force attackers to shift offline guessing to online verifications. However, the existing honey vault schemes all suffer from intersection attacks in the multi-leakage case where an old version of the storage file (e.g., a backup) is stolen along with the current version. The attacker can offline identify the decoys and completely break the schemes. We design a generic construction based on a multi-similar-password model and further propose an incremental update mechanism. With our mechanism, the attacker cannot get any extra advantages from the old storage, and therefore degenerates to an attacker only with knowledge of the current version. To further evaluate the security in the traditional single-leakage case where only the current version is stolen, we investigate the theoretically optimal strategy for online verifications, and propose practical attacks. Targeting the existing schemes, our attacks crack 33%\u201355% of real vaults via only one-time online guess and achieve 85%\u201394% accuracy in distinguishing real vaults from decoys. In contrast, our de-sign reduces the values of the two metrics to 2% and 58% (close to the ideal values 0% and 50%), respectively. This indicates that the attackers needs to carry out 2.8x\u20137.5x online verifications to break our scheme. Since online verifications can be quickly detected and prevented, our design achieves a significant improvement on security.",
            "keywords": [
                "Honey Password Vaults",
                "Password Security",
                "Incremental Update Mechanism",
                "Multi-Leakage Attacks",
                "Decoy Vaults"
            ]
        },
        "url": "URL#1888057",
        "sema_paperId": "32c3e6036ac9ef3ada383a8b540876b6b9ea6dca"
    },
    {
        "@score": "1",
        "@id": "1888059",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "61/1413",
                        "text": "Sunny Consolvo"
                    },
                    {
                        "@pid": "15/3631",
                        "text": "Patrick Gage Kelley"
                    },
                    {
                        "@pid": "57/1705",
                        "text": "Tara Matthews"
                    },
                    {
                        "@pid": "68/8283",
                        "text": "Kurt Thomas"
                    },
                    {
                        "@pid": "294/4062",
                        "text": "Lee Dunn"
                    },
                    {
                        "@pid": "20/7004",
                        "text": "Elie Bursztein"
                    }
                ]
            },
            "title": "&quot;Why wouldn&apos;t someone think of democracy as a target?&quot;: Security practices &amp; challenges of people involved with U.S. political campaigns.",
            "venue": "USENIX Security Symposium",
            "pages": "1181-1198",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ConsolvoKMTDB21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/consolvo",
            "url": "https://dblp.org/rec/conf/uss/ConsolvoKMTDB21",
            "abstract": "People who are involved with political campaigns face increased digital security threats from well-funded, sophisticated attackers, especially nation-states. Improving political campaign security is a vital part of protecting democracy. To identify campaign security issues, we conducted qualitative research with 28 participants across the U.S. political spectrum to understand the digital security practices, challenges, and perceptions of people involved in campaigns. A main, overarching finding is that a unique combination of threats, constraints, and work culture lead people involved with political campaigns to use technologies from across platforms and domains in ways that leave them--and democracy--vulnerable to security attacks. Sensitive data was kept in a plethora of personal and work accounts, with ad hoc adoption of strong passwords, two-factor authentication, encryption, and access controls. No individual company, committee, organization, campaign, or academic institution can solve the identified problems on their own. To this end, we provide an initial understanding of this complex problem space and recommendations for how a diverse group of experts can begin working together to improve security for political campaigns.",
            "keywords": [
                "Political Campaign Security",
                "Digital Threats",
                "Nation-State Attacks",
                "Security Practices",
                "Data Vulnerability"
            ]
        },
        "url": "URL#1888059",
        "sema_paperId": "89e1e2af74b736f1f19c1e93477cf76033f00cf4"
    },
    {
        "@score": "1",
        "@id": "1888060",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "17/2282",
                        "text": "Cas Cremers"
                    },
                    {
                        "@pid": "167/7329",
                        "text": "Britta Hale"
                    },
                    {
                        "@pid": "218/7414",
                        "text": "Konrad Kohbrok"
                    }
                ]
            },
            "title": "The Complexities of Healing in Secure Group Messaging: Why Cross-Group Effects Matter.",
            "venue": "USENIX Security Symposium",
            "pages": "1847-1864",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CremersHK21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/cremers",
            "url": "https://dblp.org/rec/conf/uss/CremersHK21",
            "abstract": "Modern secure messaging protocols can offer strong security guarantees such as Post-Compromise Security (PCS) [18], which enables participants to heal after compromise. The core PCS mechanism in protocols like Signal [34] is designed for pairwise communication, making it inef\ufb01cient for large groups, while recently proposed designs for secure group messaging, ART [19], IETF\u2019s MLS Draft-11 [7]/TreeKEM [11], use group keys derived from tree structures to ef\ufb01ciently provide PCS to large groups. Until now, research on PCS designs only considered healing behaviour within a single group. In this work we provide the \ufb01rst analysis of the healing behaviour when a user participates in multiple groups. Sur-prisingly, our analysis reveals that the currently proposed protocols based on group keys, such as ART and TreeKEM/MLS Draft-11, provide signi\ufb01cantly weaker PCS guarantees than group protocols based on pairwise PCS channels. In fact, we show that if new users can be created dynamically, ART, TreeKEM, and MLS Draft-11 never fully heal authentication. We map the design space of healing mechanisms, analyz-ing security and overhead of possible solutions. This leads us to a promising solution based on (i) global updates that affect all current and future groups, and (ii) post-compromise secure signatures . Our solution allows group messaging protocols such ART and MLS to achieve substantially stronger PCS guarantees. We provide a security de\ufb01nition for post-compromise secure signatures and an instantiation.",
            "keywords": [
                "Secure Group Messaging",
                "Post-Compromise Security",
                "Healing Mechanisms",
                "Group Key Protocols",
                "Cross-Group Effects"
            ]
        },
        "url": "URL#1888060",
        "sema_paperId": "7f94043a5475cc663ef1e100e4304accf52c91c7"
    },
    {
        "@score": "1",
        "@id": "1888061",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "131/5969",
                        "text": "Patrick Cronin"
                    },
                    {
                        "@pid": "87/4866-1",
                        "text": "Xing Gao 0001"
                    },
                    {
                        "@pid": "06/4401",
                        "text": "Chengmo Yang"
                    },
                    {
                        "@pid": "81/4036-1",
                        "text": "Haining Wang 0001"
                    }
                ]
            },
            "title": "Charger-Surfing: Exploiting a Power Line Side-Channel for Smartphone Information Leakage.",
            "venue": "USENIX Security Symposium",
            "pages": "681-698",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Cronin0YW21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/cronin",
            "url": "https://dblp.org/rec/conf/uss/Cronin0YW21",
            "abstract": "Touchscreen-based mobile devices such as smartphones and tablets are used daily by billions of people for productivity and entertainment. This paper uncovers a new security threat posed by a side-channel leakage through the power line, called Charger-Sur\ufb01ng, which targets these touchscreen devices. We reveal that while a smartphone is charging, its power trace, which can be measured via the USB charging cable, leaks information about the dynamic content on its screen. This information can be utilized to determine the location on the touchscreen where an animation is played by the mobile OS to indicate, for instance, that a button press has been registered. We develop a portable, low cost power trace collection system for the side-channel construction. This leakage channel is thoroughly evaluated on various smartphones running Android or iOS, equipped with the two most commonly used screen technologies (LCD and OLED). We validate the effectiveness of Charger-Sur\ufb01ng by conducting a case study on a passcode unlock screen. Our experiments show that an adversary can exploit Charger-Sur\ufb01ng across a wide range of smartphone models to achieve an average accuracy of 98.7% for single button inference, and an average of 95.1% or 92.8% accuracy on the \ufb01rst attempt when cracking a victim\u2019s 4-digit or 6-digit passcode, respectively. The inference accuracy increases to 99.3% (4-digit) or 96.9% (6-digit) within \ufb01ve trials. We further demonstrate the robustness of Charger-Sur\ufb01ng in realistic settings and discuss countermeasures against it.",
            "keywords": [
                "Power Line Side-Channel",
                "Smartphone Security",
                "Information Leakage",
                "Charger-Surfing",
                "Passcode Cracking"
            ]
        },
        "url": "URL#1888061",
        "sema_paperId": "a219e57d2fe8b89a0c588a538595a3351c32b59f"
    },
    {
        "@score": "1",
        "@id": "1888062",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "197/3968",
                        "text": "Tianyu Cui"
                    },
                    {
                        "@pid": "13/10808",
                        "text": "Gaopeng Gou"
                    },
                    {
                        "@pid": "96/372-1",
                        "text": "Gang Xiong 0001"
                    },
                    {
                        "@pid": "74/2397-11",
                        "text": "Zhen Li 0011"
                    },
                    {
                        "@pid": "207/6586",
                        "text": "Mingxin Cui"
                    },
                    {
                        "@pid": "52/5716-49",
                        "text": "Chang Liu 0049"
                    }
                ]
            },
            "title": "SiamHAN: IPv6 Address Correlation Attacks on TLS Encrypted Traffic via Siamese Heterogeneous Graph Attention Network.",
            "venue": "USENIX Security Symposium",
            "pages": "4329-4346",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CuiGX0C021",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/cui",
            "url": "https://dblp.org/rec/conf/uss/CuiGX0C021",
            "abstract": "Unlike IPv4 addresses, which are typically masked by a NAT, IPv6 addresses could easily be correlated with users' activity, endangering their privacy. Mitigations to address this privacy concern have been deployed, making existing approaches for address-to-user correlation unreliable. This work demonstrates that an adversary could still correlate IPv6 addresses with users accurately, even with these protection mechanisms. To do this, we propose an IPv6 address correlation model \u2013 SiamHAN. The model uses a Siamese Heterogeneous Graph Attention Network to measure whether two IPv6 client addresses belong to the same user even if the user's traffic is protected by TLS encryption. Using a large real-world dataset, we show that, for the tasks of tracking target users and discovering unique users, the state-of-the-art techniques could achieve only 85% and 60% accuracy, respectively. However, SiamHAN exhibits 99% and 88% accuracy.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-cui.pdf",
            "keywords": [
                "IPv6 Address Correlation",
                "Privacy Protection",
                "TLS Encrypted Traffic",
                "Siamese Heterogeneous Graph Attention Network",
                "User Activity Tracking"
            ]
        },
        "url": "URL#1888062"
    },
    {
        "@score": "1",
        "@id": "1888063",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "188/4885",
                        "text": "Tianxiang Dai"
                    },
                    {
                        "@pid": "271/6045",
                        "text": "Philipp Jeitner"
                    },
                    {
                        "@pid": "94/7397",
                        "text": "Haya Schulmann"
                    },
                    {
                        "@pid": "90/308",
                        "text": "Michael Waidner"
                    }
                ]
            },
            "title": "The Hijackers Guide To The Galaxy: Off-Path Taking Over Internet Resources.",
            "venue": "USENIX Security Symposium",
            "pages": "3147-3164",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DaiJSW21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/dai",
            "url": "https://dblp.org/rec/conf/uss/DaiJSW21",
            "abstract": "Internet resources form the basic fabric of the digital society. They provide the fundamental platform for digital services and assets, e.g., for critical infrastructures, financial services, government. Whoever controls that fabric effectively controls the digital society.In this work we demonstrate that the current practices of Internet resources management, of IP addresses, domains, certificates and virtual platforms are insecure. Over long periods of time adversaries can maintain control over Internet resources which they do not own and perform stealthy manipulations, leading to devastating attacks. We show that network adversaries can take over and manipulate at least 68% of the assigned IPv4 address space as well as 31% of the top Alexa domains. We demonstrate such attacks by hijacking the accounts associated with the digital resources. For hijacking the accounts we launch off-path DNS cache poisoning attacks, to redirect the password recovery link to the adversarial hosts. We then demonstrate that the adversaries can manipulate the resources associated with these accounts. We find all the tested providers vulnerable to our attacks.We recommend mitigations for blocking the attacks that we present in this work. Nevertheless, the countermeasures cannot solve the fundamental problem - the management of the Internet resources should be revised to ensure that applying transactions cannot be done so easily and stealthily as is currently possible.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-dai.pdf",
            "keywords": [
                "Internet Resource Management",
                "Account Hijacking",
                "DNS Cache Poisoning",
                "IPv4 Address Space",
                "Domain Manipulation"
            ]
        },
        "url": "URL#1888063"
    },
    {
        "@score": "1",
        "@id": "1888064",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "201/6434",
                        "text": "Anders P. K. Dalskov"
                    },
                    {
                        "@pid": "05/4011-1",
                        "text": "Daniel Escudero 0001"
                    },
                    {
                        "@pid": "69/8323",
                        "text": "Marcel Keller"
                    }
                ]
            },
            "title": "Fantastic Four: Honest-Majority Four-Party Secure Computation With Malicious Security.",
            "venue": "USENIX Security Symposium",
            "pages": "2183-2200",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Dalskov0K21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/dalskov",
            "url": "https://dblp.org/rec/conf/uss/Dalskov0K21",
            "abstract": "This work introduces a novel four-party honest-majority MPC protocol with active security that achieves comparable efficiency to equivalent protocols in the same setting, while having a much simpler design and not relying on function-dependent preprocessing. Our initial protocol satisfies security with abort, but we present some extensions to achieve guaranteed output delivery. Unlike previous works, we do not achieve this by delegating the computation to one single party that is identified to be honest, which is likely to hinder the adoption of these technologies as it centralizes sensitive data. Instead, our novel approach guarantees termination of the protocol while ensuring that no single party (honest or corrupt) learns anything beyond the output.We implement our four-party protocol with abort in the MP-SPDZ framework for multi-party computation and benchmark multiple applications like MNIST classification training and ImageNet inference. Our results show that our four-party protocol performs similarly to an efficient honest-majority three-party protocol that only provides semi-honest/passive security, which suggests that adding a fourth party can be an effective method to achieve active security without harming performance.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-dalskov.pdf",
            "keywords": [
                "Multi-Party Computation",
                "Active Security",
                "Honest-Majority Protocol",
                "Guaranteed Output Delivery",
                "Malicious Security"
            ]
        },
        "url": "URL#1888064"
    },
    {
        "@score": "1",
        "@id": "1888065",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "301/5853",
                        "text": "Marc Damie"
                    },
                    {
                        "@pid": "153/5769",
                        "text": "Florian Hahn 0001"
                    },
                    {
                        "@pid": "43/8243",
                        "text": "Andreas Peter"
                    }
                ]
            },
            "title": "A Highly Accurate Query-Recovery Attack against Searchable Encryption using Non-Indexed Documents.",
            "venue": "USENIX Security Symposium",
            "pages": "143-160",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Damie0P21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/damie",
            "url": "https://dblp.org/rec/conf/uss/Damie0P21",
            "abstract": "Cloud data storage solutions offer customers cost-effective and reduced data management. While attractive, data security issues remain to be a core concern. Traditional encryption protects stored documents, but hinders simple functionalities such as keyword search. Therefore, searchable encryption schemes have been proposed to allow for the search on encrypted data. Efficient schemes leak at least the access pattern (the accessed documents per keyword search), which is known to be exploitable in query recovery attacks assuming the attacker has a significant amount of background knowledge on the stored documents. Existing attacks can only achieve decent results with strong adversary models (e.g. at least 20% of previously known documents or require additional knowledge such as on query frequencies) and they give no metric to evaluate the certainty of recovered queries. This hampers their practical utility and questions their relevance in the real-world.\n\t\nWe propose a refined score attack which achieves query recovery rates of around 85% without requiring exact background knowledge on stored documents; a distributionally similar, but otherwise different (i.e. non-indexed), dataset suffices. The attack starts with very few known queries (around 10 known queries in our experiments over different datasets of varying size) and then iteratively recovers further queries with confidence scores by adding previously recovered queries that had high confidence scores to the set of known queries.  Additional to high recovery rates, our approach yields interpretable results in terms of confidence scores.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-damie.pdf",
            "keywords": [
                "Searchable Encryption",
                "Query Recovery Attack",
                "Access Pattern Leakage",
                "Non-Indexed Documents",
                "Confidence Scores"
            ]
        },
        "url": "URL#1888065"
    },
    {
        "@score": "1",
        "@id": "1888066",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "230/7753",
                        "text": "Hailun Ding"
                    },
                    {
                        "@pid": "228/2025",
                        "text": "Shenao Yan"
                    },
                    {
                        "@pid": "154/5678",
                        "text": "Juan Zhai"
                    },
                    {
                        "@pid": "172/8745",
                        "text": "Shiqing Ma"
                    }
                ]
            },
            "title": "ELISE: A Storage Efficient Logging System Powered by Redundancy Reduction and Representation Learning.",
            "venue": "USENIX Security Symposium",
            "pages": "3023-3040",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DingYZM21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/ding",
            "url": "https://dblp.org/rec/conf/uss/DingYZM21",
            "abstract": "Log is a key enabler of many security applications including but not limited to security auditing and forensic analysis. Due to the rapid growth of modern computing infrastructure size, software systems are generating more and more logs every day. Moreover, the duration of recent cyber attacks like Advanced Persistent Threats (APTs) is becoming longer, and their targets consist of many connected organizations instead of a single one. This requires the analysis on logs from different sources and long time periods. Storing such large sized log \ufb01les is becoming more important and also challenging than ever. Existing logging systems are either inef\ufb01cient (i.e., high storage overhead) or designed for limited security applications (i.e., no support for general security analysis). In this paper, we propose E LISE , a storage ef\ufb01cient logging system built on top of a novel lossless data compression technique, which naturally supports all types of security analysis. It features lossless log compression using a novel log \ufb01le preprocessing and Deep Neural Network (DNN) based method to learn optimal character encoding. On average, E LISE can achieve 3 and 2 times better compression results compared with existing state-of-the-art methods Gzip and DeepZip, respectively, showing a promising future research direction.",
            "keywords": [
                "Log Management",
                "Data Compression",
                "Security Analysis",
                "Redundancy Reduction",
                "Representation Learning"
            ]
        },
        "url": "URL#1888066",
        "sema_paperId": "6e222291578d39c77381a671ff6b9e8b62634670"
    },
    {
        "@score": "1",
        "@id": "1888067",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "123/9696",
                        "text": "Evan Downing"
                    },
                    {
                        "@pid": "160/6851",
                        "text": "Yisroel Mirsky"
                    },
                    {
                        "@pid": "200/1946",
                        "text": "Kyuhong Park"
                    },
                    {
                        "@pid": "29/5976",
                        "text": "Wenke Lee"
                    }
                ]
            },
            "title": "DeepReflect: Discovering Malicious Functionality through Binary Reconstruction.",
            "venue": "USENIX Security Symposium",
            "pages": "3469-3486",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DowningMPL21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/downing",
            "url": "https://dblp.org/rec/conf/uss/DowningMPL21",
            "abstract": "Deep learning has continued to show promising results for malware classi\ufb01cation. However, to identify key malicious behaviors, malware analysts are still tasked with reverse engineering unknown malware binaries using static analysis tools, which can take hours. Although machine learning can be used to help identify important parts of a binary, supervised approaches are impractical due to the expense of acquiring a suf\ufb01ciently large labeled dataset. To increase the productivity of static (or manual) reverse engineering, we propose D EEP R EFLECT : a tool for localizing and identifying malware components within a malicious binary. To localize malware components, we use an unsupervised deep neural network in a novel way, and classify the components through a semi-supervised cluster analysis, where analysts incrementally provide labels during their daily work \ufb02ow. The tool is practical since it requires no data labeling to train the localization model, and minimal/noninvasive labeling to train the classi\ufb01er incrementally. In our evaluation with \ufb01ve malware analysts on over 26k malware samples, we found that D EEP R EFLECT reduces the numberoffunctionsthatananalystneedstoreverseengineerby85%onaverage.Ourapproachalsodetects80%ofthemalware componentscomparedto43%whenusingasignature-based tool(CAPA).Furthermore,D EEP R EFLECT performs better with our proposed autoencoder than SHAP (an AI explanation tool). This is signi\ufb01cant because SHAP, a state-of-the-art method, requires a labeled dataset and autoencoders do not.",
            "keywords": [
                "Malware Analysis",
                "Binary Reconstruction",
                "Malware Component Localization",
                "Static Analysis Tools",
                "Semi-Supervised Classification"
            ]
        },
        "url": "URL#1888067",
        "sema_paperId": "757a48f7fd6fabe2d9823bbe51c9ac76d4501150"
    },
    {
        "@score": "1",
        "@id": "1888068",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "261/3603",
                        "text": "Thorsten Eisenhofer"
                    },
                    {
                        "@pid": "195/0263",
                        "text": "Lea Sch\u00f6nherr"
                    },
                    {
                        "@pid": "64/5428",
                        "text": "Joel Frank"
                    },
                    {
                        "@pid": "285/5174",
                        "text": "Lars Speckemeier"
                    },
                    {
                        "@pid": "44/3463",
                        "text": "Dorothea Kolossa"
                    },
                    {
                        "@pid": "h/ThorstenHolz",
                        "text": "Thorsten Holz"
                    }
                ]
            },
            "title": "Dompteur: Taming Audio Adversarial Examples.",
            "venue": "USENIX Security Symposium",
            "pages": "2309-2326",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/EisenhoferSFSKH21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/eisenhofer",
            "url": "https://dblp.org/rec/conf/uss/EisenhoferSFSKH21",
            "abstract": "Adversarial examples seem to be inevitable. These specifically crafted inputs allow attackers to arbitrarily manipulate machine learning systems. Even worse, they often seem harmless to human observers. In our digital society, this poses a significant threat. For example, Automatic Speech Recognition (ASR) systems, which serve as hands-free interfaces to many kinds of systems, can be attacked with inputs incomprehensible for human listeners. The research community has unsuccessfully tried several approaches to tackle this problem. In this paper we propose a different perspective: We accept the presence of adversarial examples against ASR systems, but we require them to be perceivable by human listeners. By applying the principles of psychoacoustics, we can remove semantically irrelevant information from the ASR input and train a model that resembles human perception more closely. We implement our idea in a tool named DOMPTEUR and demonstrate that our augmented system, in contrast to an unmodified baseline, successfully focuses on perceptible ranges of the input signal. This change forces adversarial examples into the audible range, while using minimal computational overhead and preserving benign performance. To evaluate our approach, we construct an adaptive attacker that actively tries to avoid our augmentations and demonstrate that adversarial examples from this attacker remain clearly perceivable. Finally, we substantiate our claims by performing a hearing test with crowd-sourced human listeners.",
            "keywords": [
                "Audio Adversarial Examples",
                "Automatic Speech Recognition",
                "Psychoacoustics",
                "Perceptible Inputs",
                "Human Listener Evaluation"
            ]
        },
        "url": "URL#1888068",
        "sema_paperId": "94f87e472c6ba9aaa37590877dc4615a92784ef3"
    },
    {
        "@score": "1",
        "@id": "1888069",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "301/5896",
                        "text": "Yusra Elbitar"
                    },
                    {
                        "@pid": "40/1587",
                        "text": "Michael Schilling 0001"
                    },
                    {
                        "@pid": "294/4401",
                        "text": "Trung Tin Nguyen"
                    },
                    {
                        "@pid": "b/MichaelBackes1",
                        "text": "Michael Backes 0001"
                    },
                    {
                        "@pid": "31/7561",
                        "text": "Sven Bugiel"
                    }
                ]
            },
            "title": "Explanation Beats Context: The Effect of Timing &amp; Rationales on Users&apos; Runtime Permission Decisions.",
            "venue": "USENIX Security Symposium",
            "pages": "785-802",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Elbitar0N0B21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/elbitar",
            "url": "https://dblp.org/rec/conf/uss/Elbitar0N0B21",
            "abstract": "Current mobile platforms leave it up to the app developer to decide when to request permissions (timing) and whether to provide explanations why and how users\u2019 private data are accessed (rationales) . Given these liberties, it is important to understand how developers should use timing and ratio-nales to effectively assist users in their permission decisions. While guidelines and recommendations for developers exist, no study has systematically investigated the actual in\ufb02u-ence of timing, rationales, and their combinations on users\u2019 decision-making process. In this work, we conducted a comparative online study with 473 participants who were asked to interact with mockup apps drawn from a pool of 120 variations of 30 apps. The study design was guided by devel-opers\u2019 current permission request practices derived from a dynamic analysis of the top apps on Google Play . Our results show that there is a clear interplay between timing and rationales on users\u2019 permission decisions and the evaluation of their decisions, making the effect of rationales stronger when shown upfront and limiting the effect of timing when rationales are present. We therefore suggest adaptation to the available guidelines. We also \ufb01nd that permission decisions depend on the individuality of users, indicating that there is no one-\ufb01ts-all permission request strategy, upon we suggest better individual support and outline one possible solution.",
            "keywords": [
                "Mobile Permissions",
                "User Decision-Making",
                "Permission Timing",
                "Permission Rationales",
                "Individual User Differences"
            ]
        },
        "url": "URL#1888069",
        "sema_paperId": "cb7f8fe994fe6e871a332fc8fa729b014e3c9c17"
    },
    {
        "@score": "1",
        "@id": "1888070",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "198/0935",
                        "text": "Saba Eskandarian"
                    },
                    {
                        "@pid": "87/8037",
                        "text": "Henry Corrigan-Gibbs"
                    },
                    {
                        "@pid": "36/2133",
                        "text": "Matei Zaharia"
                    },
                    {
                        "@pid": "b/DanBoneh",
                        "text": "Dan Boneh"
                    }
                ]
            },
            "title": "Express: Lowering the Cost of Metadata-hiding Communication with Cryptographic Privacy.",
            "venue": "USENIX Security Symposium",
            "pages": "1775-1792",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/EskandarianCZB21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/eskandarian",
            "url": "https://dblp.org/rec/conf/uss/EskandarianCZB21",
            "abstract": "Existing systems for metadata-hiding messaging that provide cryptographic privacy properties have either high communication costs, high computation costs, or both. In this paper, we introduce Express, a metadata-hiding communication system that significantly reduces both communication and computation costs. Express is a two-server system that provides cryptographic security against an arbitrary number of malicious clients and one malicious server. In terms of communication, Express only incurs a constant-factor overhead per message sent regardless of the number of users, whereas previous cryptographically-secure systems Pung and Riposte had communication costs proportional to roughly the square root of the number of users. In terms of computation, Express only uses symmetric key cryptographic primitives and makes both practical and asymptotic improvements on protocols employed by prior work. These improvements enable Express to increase message throughput, reduce latency, and consume over 100x less bandwidth than Pung and Riposte, dropping the end to end cost of running a realistic whistleblowing application by 6x.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-eskandarian.pdf",
            "keywords": [
                "Metadata-hiding Communication",
                "Cryptographic Privacy",
                "Two-server System",
                "Communication Cost Reduction",
                "Whistleblowing Application"
            ]
        },
        "url": "URL#1888070"
    },
    {
        "@score": "1",
        "@id": "1888071",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "250/6496",
                        "text": "Florian M. Farke"
                    },
                    {
                        "@pid": "294/0161",
                        "text": "David G. Balash"
                    },
                    {
                        "@pid": "177/0313",
                        "text": "Maximilian Golla"
                    },
                    {
                        "@pid": "36/3665",
                        "text": "Markus D\u00fcrmuth"
                    },
                    {
                        "@pid": "94/1554",
                        "text": "Adam J. Aviv"
                    }
                ]
            },
            "title": "Are Privacy Dashboards Good for End Users? Evaluating User Perceptions and Reactions to Google&apos;s My Activity.",
            "venue": "USENIX Security Symposium",
            "pages": "483-500",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/FarkeBGDA21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/farke",
            "url": "https://dblp.org/rec/conf/uss/FarkeBGDA21",
            "abstract": "Privacy dashboards and transparency tools help users review and manage the data collected about them online. Since 2016, Google has offered such a tool, My Activity, which allows users to review and delete their activity data from Google services. We conducted an online survey with $n = 153$ participants to understand if Google's My Activity, as an example of a privacy transparency tool, increases or decreases end-users' concerns and benefits regarding data collection. While most participants were aware of Google's data collection, the volume and detail was surprising, but after exposure to My Activity, participants were significantly more likely to be both less concerned about data collection and to view data collection more beneficially. Only $25\\,\\%$ indicated that they would change any settings in the My Activity service or change any behaviors. This suggests that privacy transparency tools are quite beneficial for online services as they garner trust with their users and improve their perceptions without necessarily changing users' behaviors. At the same time, though, it remains unclear if such transparency tools actually improve end user privacy by sufficiently assisting or motivating users to change or review data collection settings.",
            "keywords": [
                "Privacy Dashboards",
                "User Perceptions",
                "Data Collection",
                "Transparency Tools",
                "Google My Activity"
            ]
        },
        "url": "URL#1888071",
        "sema_paperId": "2e740918b4084786d4f9135cddacfb121e7baa46"
    },
    {
        "@score": "1",
        "@id": "1888072",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "228/8232",
                        "text": "Reza Mirzazade Farkhani"
                    },
                    {
                        "@pid": "161/1767",
                        "text": "Mansour Ahmadi"
                    },
                    {
                        "@pid": "81/7428",
                        "text": "Long Lu"
                    }
                ]
            },
            "title": "PTAuth: Temporal Memory Safety via Robust Points-to Authentication.",
            "venue": "USENIX Security Symposium",
            "pages": "1037-1054",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/FarkhaniAL21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/mirzazade",
            "url": "https://dblp.org/rec/conf/uss/FarkhaniAL21",
            "abstract": "Temporal memory corruptions are commonly exploited software vulnerabilities that can lead to powerful attacks. Despite significant progress made by decades of research on mitigation techniques, existing countermeasures fall short due to either limited coverage or overly high overhead. Furthermore, they require external mechanisms (e.g., spatial memory safety) to protect their metadata. Otherwise, their protection can be bypassed or disabled. To address these limitations, we present robust points-to authentication, a novel runtime scheme for detecting all kinds of temporal memory corruptions. We built a prototype system, called PTAuth, that realizes this scheme on ARM architectures. PTAuth contains a customized compiler for code analysis and instrumentation and a runtime library for performing the points-to authentication as a protected program runs. PTAuth leverages the Pointer Authentication Code (PAC) feature, provided by the ARMv8.3 and later CPUs, which serves as a simple hardware-based encryption primitive. PTAuth uses minimal in-memory metadata and protects its metadata without requiring spatial memory safety. We report our evaluation of PTAuth in terms of security, robustness and performance using 150 vulnerable programs from Juliet test suite and the SPEC CPU2006 benchmarks. PTAuth detects all three categories of heap-based temporal memory corruptions, generates zero false alerts, and slows down program execution by 26% (this number was measured based on software-emulated PAC; it is expected to decrease to 20% when using hardware-based PAC). We also show that PTAuth incurs 2% memory overhead thanks to the efficient use of metadata.",
            "keywords": [
                "Temporal Memory Safety",
                "Points-to Authentication",
                "Memory Corruption",
                "ARM Architecture",
                "Runtime Detection"
            ]
        },
        "url": "URL#1888072",
        "sema_paperId": "721c1785c35ffb64a20d8c13edf18cc25339d9f2"
    },
    {
        "@score": "1",
        "@id": "1888073",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "133/6699",
                        "text": "Peng Fei"
                    },
                    {
                        "@pid": "62/4119-1",
                        "text": "Zhou Li 0001"
                    },
                    {
                        "@pid": "w/ZhiyingWang-1",
                        "text": "Zhiying Wang 0001"
                    },
                    {
                        "@pid": "89/2407-7",
                        "text": "Xiao Yu 0007"
                    },
                    {
                        "@pid": "95/7132-1",
                        "text": "Ding Li 0001"
                    },
                    {
                        "@pid": "36/10085",
                        "text": "Kangkook Jee"
                    }
                ]
            },
            "title": "SEAL: Storage-efficient Causality Analysis on Enterprise Logs with Query-friendly Compression.",
            "venue": "USENIX Security Symposium",
            "pages": "2987-3004",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/FeiL000J21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/fei",
            "url": "https://dblp.org/rec/conf/uss/FeiL000J21",
            "abstract": "Causality analysis automates attack forensic and facilitates behavioral detection by associating causally related but temporally distant system events. Despite its proven usefulness, the analysis suffers from the innate big data challenge to store and process a colossal amount of system events that are constantly collected from hundreds of thousands of end-hosts in a realistic network. In addition, the effectiveness of the analysis to discover security breaches relies on the assumption that comprehensive historical events over a long span are stored. Hence, it is imminent to address the scalability issue in order to make causality analysis practical and applicable to the enterprise-level environment. In this work, we present SEAL, a novel data compression approach for causality analysis. Based on information-theoretic observations on system event data, our approach achieves lossless compression and supports near real-time retrieval of historic events. In the compression step, the causality graph induced by the system logs is investigated, and abundant edge reduction potentials are explored. In the query step, for maximal speed, decompression is opportunistically executed. Experiments on two real-world datasets show that SEAL offers 2.63x and 12.94x data size reduction, respectively. Besides, 89% of the queries are faster on the compressed dataset than the uncompressed one, and SEAL returns exactly the same query results as the uncompressed data.",
            "keywords": [
                "Causality Analysis",
                "Data Compression",
                "Enterprise Logs",
                "Scalability",
                "Query Performance"
            ]
        },
        "url": "URL#1888073",
        "sema_paperId": "5d4a1497248a6321bd1ac86c66d535421ff2275c"
    },
    {
        "@score": "1",
        "@id": "1888074",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "238/5097",
                        "text": "Kimberly Ferguson-Walter"
                    },
                    {
                        "@pid": "196/9817",
                        "text": "Maxine Major"
                    },
                    {
                        "@pid": "301/5868",
                        "text": "Chelsea K. Johnson"
                    },
                    {
                        "@pid": "301/5875",
                        "text": "Daniel H. Muhleman"
                    }
                ]
            },
            "title": "Examining the Efficacy of Decoy-based and Psychological Cyber Deception.",
            "venue": "USENIX Security Symposium",
            "pages": "1127-1144",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Ferguson-Walter21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/ferguson-walter",
            "url": "https://dblp.org/rec/conf/uss/Ferguson-Walter21",
            "abstract": "The threat of cyber attacks is a growing concern across the world, leading to an increasing need for sophisticated cyber defense techniques. Attackers often rely on direct observation of cyber environments. This reliance provides opportunities for defenders to affect attacker perception and behavior by plying the powerful tools of defensive cyber deception. In this paper we analyze data from a controlled experiment designed to understand how defensive deception, both cyber and psychological, affects attackers [16]. Over 130 professional red teamers participated in a network penetration test in which both the presence and explicit mention of deceptive defensive techniques were controlled. While a detailed description of the experimental design and execution along with preliminary results related to red teamer characteristics has been published, it did not address any of the main hypotheses. Granted access to the cyber and self-report data collected from the ex-periment, this publication begins to address theses hypotheses by investigating the effectiveness of decoy systems for cyber defense through comparison of various measures of participant forward progress across the four experimental conditions. Results presented in this paper support a new \ufb01nding that the combination of the presence of decoys and information that deception is present has the greatest impact on cyber attack behavior, when compared to a control condition in which no deception was used.",
            "keywords": [
                "Cyber Deception",
                "Decoy Systems",
                "Red Teaming",
                "Defensive Cybersecurity",
                "Attacker Behavior"
            ]
        },
        "url": "URL#1888074",
        "sema_paperId": "342a3a6439326a142b1b32fb60db9e352d51e6a3"
    },
    {
        "@score": "1",
        "@id": "1888075",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "252/5052",
                        "text": "Andrea Fioraldi"
                    },
                    {
                        "@pid": "32/9698",
                        "text": "Daniele Cono D&apos;Elia"
                    },
                    {
                        "@pid": "56/490",
                        "text": "Davide Balzarotti"
                    }
                ]
            },
            "title": "The Use of Likely Invariants as Feedback for Fuzzers.",
            "venue": "USENIX Security Symposium",
            "pages": "2829-2846",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/FioraldiDB21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/fioraldi",
            "url": "https://dblp.org/rec/conf/uss/FioraldiDB21",
            "abstract": "While fuzz testing proved to be a very effective technique to \ufb01nd software bugs, open challenges still exist. One of the its main limitations is the fact that popular coverage-guided designs are optimized to reach different parts of the program under test, but struggle when reachability alone is insuf\ufb01cient to trigger a vulnerability. In reality, many bugs require a speci\ufb01c program state that involve not only the control \ufb02ow, but also the values of some of the program variables. Unfortunately, alternative exploration strategies that have been proposed in the past to capture the program state are of little help in practice, as they immediately result in a state explosion. In this paper, we propose a new feedback mechanism that augments code coverage by taking into account the usual values and relationships among program variables. For this purpose, we learn likely invariants over variables at the basic-block level, and partition the program state space accordingly. Our feedback can distinguish when an input violates one or more invariants and reward it, thus re\ufb01ning the program state approximation that code coverage normally offers. We implemented our technique in a prototype called I NVS C OV , developed on top of LLVM and AFL ++ . Our experiments show that our approach can \ufb01nd more, and different, bugs with respect to fuzzers that use a pure code-coverage feedback. Furthermore, they led to the discovery of two vulnerabilities in a library tested daily on OSS-Fuzz, and still present at the time in its latest version.",
            "keywords": [
                "Fuzz Testing",
                "Program State Exploration",
                "Code Coverage",
                "Likely Invariants",
                "Software Vulnerabilities"
            ]
        },
        "url": "URL#1888075",
        "sema_paperId": "68c1ccd4965515c582af31ec88c4f372e340cde7"
    },
    {
        "@score": "1",
        "@id": "1888076",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "169/1723",
                        "text": "Xiaoqin Fu"
                    },
                    {
                        "@pid": "117/7062",
                        "text": "Haipeng Cai"
                    }
                ]
            },
            "title": "FlowDist: Multi-Staged Refinement-Based Dynamic Information Flow Analysis for Distributed Software Systems.",
            "venue": "USENIX Security Symposium",
            "pages": "2093-2110",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/FuC21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/fu-xiaoqin",
            "url": "https://dblp.org/rec/conf/uss/FuC21",
            "abstract": "Dynamic information \ufb02ow analysis (DIFA) supports various security applications such as malware analysis and vulnerability discovery. Yet traditional DIFA approaches have limited utility for distributed software due to applicability , portability , and scalability barriers. We present F LOW D IST , a DIFA for common distributed software that overcomes these challenges. F LOW D IST works at purely application level to avoid platform customizations hence achieve high portability . It infers implicit, interprocess dependencies from global partially ordered execution events to address applicability to distributed software. Most of all, it introduces a multi-staged re\ufb01nement-based scheme for application-level DIFA, where an otherwise expensive data \ufb02ow analysis is reduced by method-level results from a cheap pre-analysis, to achieve high scalability while remaining effective. Our evaluation of F LOW D IST on 12 real-world distributed systems against two peer tools revealed its superior effectiveness with practical ef\ufb01ciency and scalability. It has found 18 known and 24 new vulnerabilities, with 17 con\ufb01rmed and 2 \ufb01xed. We also present and evaluate two alternative designs of F LOW D IST for both design justi\ufb01cation and diverse subject accommodations.",
            "keywords": [
                "Dynamic Information Flow Analysis",
                "Distributed Software Systems",
                "Multi-Staged Refinement",
                "Vulnerability Discovery",
                "Interprocess Dependencies"
            ]
        },
        "url": "URL#1888076",
        "sema_paperId": "e67e2b8da752cad93cf415864d85c4f04fb91b07"
    },
    {
        "@score": "1",
        "@id": "1888078",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "237/1642",
                        "text": "Sivanarayana Gaddam"
                    },
                    {
                        "@pid": "54/10551",
                        "text": "Atul Luykx"
                    },
                    {
                        "@pid": "04/4646-1",
                        "text": "Rohit Sinha 0001"
                    },
                    {
                        "@pid": "52/2914",
                        "text": "Gaven J. Watson"
                    }
                ]
            },
            "title": "Reducing HSM Reliance in Payments through Proxy Re-Encryption.",
            "venue": "USENIX Security Symposium",
            "pages": "4061-4078",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GaddamL0W21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/gaddam",
            "url": "https://dblp.org/rec/conf/uss/GaddamL0W21",
            "abstract": "Credit and debit-card payments are typically authenticated with PINs. Once entered into a terminal, the PIN is sent as an encrypted PIN block across a payments network to the destination bank, which decrypts and verifies the PIN block. Each node in the payments network routes the PIN block to the next node by decrypting the block with its own key, and then re-encrypting the PIN block with the next node's key; nodes establish shared secret keys with their neighbors to do so. This decrypt-then-encrypt operation over PIN blocks is known as PIN translation, and it is currently performed in Hardware Security Modules (HSMs) to avoid possible PIN exposure. However, HSMs incur heavy acquisition and operational expenses.\nIntroduced at EUROCRYPT '98, proxy re-encryption (PRE) is a cryptographic primitive which can re-encrypt without exposing sensitive data. We perform an extensive study of PRE as applied to PIN translation, and show through formalization, security analysis, and an implementation study that PRE is a practical alternative to HSMs. With PRE, we eliminate the need for HSMs during re-encryption of a PIN, thus greatly reducing the number of HSMs needed by each participant in the payments ecosystem. Along the way we conduct practice-oriented PRE research, with novel theoretical contributions to resolve issues in comparing so-called honest re-encryption to chosen ciphertext PRE security, and a new efficient PRE scheme achieving a type of chosen ciphertext security.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-gaddam.pdf",
            "keywords": [
                "Proxy Re-Encryption",
                "PIN Translation",
                "Payment Authentication",
                "Hardware Security Modules",
                "Cryptographic Security"
            ]
        },
        "url": "URL#1888078"
    },
    {
        "@score": "1",
        "@id": "1888079",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "146/8907",
                        "text": "Yipeng Gao"
                    },
                    {
                        "@pid": "81/7020",
                        "text": "Haichang Gao"
                    },
                    {
                        "@pid": "252/8377",
                        "text": "Sainan Luo"
                    },
                    {
                        "@pid": "203/0404",
                        "text": "Yang Zi"
                    },
                    {
                        "@pid": "42/6194",
                        "text": "Shudong Zhang"
                    },
                    {
                        "@pid": "301/5846",
                        "text": "Wenjie Mao"
                    },
                    {
                        "@pid": "37/1304-3",
                        "text": "Ping Wang 0003"
                    },
                    {
                        "@pid": "74/2768",
                        "text": "Yulong Shen"
                    },
                    {
                        "@pid": "37/6136",
                        "text": "Jeff Yan"
                    }
                ]
            },
            "title": "Research on the Security of Visual Reasoning CAPTCHA.",
            "venue": "USENIX Security Symposium",
            "pages": "3291-3308",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GaoGLZZMWSY21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/gao",
            "url": "https://dblp.org/rec/conf/uss/GaoGLZZMWSY21",
            "abstract": "CAPTCHA is an effective mechanism for protecting computers from malicious bots. With the development of deep learning techniques, current mainstream text-based CAPTCHAs have been proven to be insecure. Therefore, a major effort has been directed toward developing image-based CAPTCHAs, and image-based visual reasoning is emerging as a new direction of such development. Recently, Tencent deployed the Visual Turing Test (VTT) CAPTCHA. This appears to have been the first application of a visual reasoning scheme. Subsequently, other CAPTCHA service providers (Geetest, NetEase, Dingxiang, etc.) have proposed their own visual reasoning schemes to defend against bots. It is, therefore, natural to ask a fundamental question: are visual reasoning CAPTCHAs as secure as their designers expect? This paper presents the first attempt to solve visual reasoning CAPTCHAs. We implemented a holistic attack and a modular attack, which achieved overall success rates of 67.3% and 88.0% on VTT CAPTCHA, respectively. The results show that visual reasoning CAPTCHAs are not as secure as anticipated; this latest effort to use novel, hard AI problems for CAPTCHAs has not yet succeeded. Based on the lessons we learned from our attacks, we also offer some guidelines for designing visual CAPTCHAs with better security.",
            "keywords": [
                "Visual Reasoning CAPTCHA",
                "Image-based CAPTCHA",
                "Bot Detection",
                "Holistic Attack",
                "Modular Attack"
            ]
        },
        "url": "URL#1888079",
        "sema_paperId": "0269a3b827b857fc4b18a78a13bd6c9fa13588ac"
    },
    {
        "@score": "1",
        "@id": "1888080",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "277/3441",
                        "text": "Barbara Gigerl"
                    },
                    {
                        "@pid": "190/7521",
                        "text": "Vedad Hadzic"
                    },
                    {
                        "@pid": "203/4230",
                        "text": "Robert Primas"
                    },
                    {
                        "@pid": "91/4831",
                        "text": "Stefan Mangard"
                    },
                    {
                        "@pid": "80/1300",
                        "text": "Roderick Bloem"
                    }
                ]
            },
            "title": "Coco: Co-Design and Co-Verification of Masked Software Implementations on CPUs.",
            "venue": "USENIX Security Symposium",
            "pages": "1469-1468",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GigerlHPMB21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/gigerl",
            "url": "https://dblp.org/rec/conf/uss/GigerlHPMB21",
            "abstract": "The protection of cryptographic implementations against power analysis attacks is of critical importance for many applications in embedded systems. The typical approach of protecting against these attacks is to implement algorithmic countermeasures, like masking. However, implementing these countermeasures in a secure and correct manner is challenging. Masking schemes require the independent processing of secret shares, which is a property that is often violated by CPU microarchitectures in practice. In order to write leakage-free code, the typical approach in practice is to iteratively explore instruction sequences and to empirically verify whether there is leakage caused by the hardware for this instruction sequence or not. Clearly, this approach is neither efficient, nor does it lead to rigorous security statements.In this paper, we overcome the current situation and present the first approach for co-design and co-verification of masked software implementations on CPUs. First, we present Coco, a tool that allows us to provide security proofs at the gate-level for the execution of a masked software implementation on a concrete CPU. Using Coco, we analyze the popular 32-bit RISC-V Ibex core, identify all design aspects that violate the security of our tested masked software implementations and perform corrections, mostly in hardware. The resulting secured Ibex core has an area overhead around 10%, the runtime of software on this core is largely unaffected, and the formal verification with Coco of an, e.g., first-order masked Keccak S-box running on the secured Ibex core takes around 156 seconds. To demonstrate the effectiveness of our suggested design modifications, we perform practical leakage assessments using an FPGA evaluation board.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-gigerl.pdf",
            "keywords": [
                "Cryptographic Implementations",
                "Power Analysis Attacks",
                "Masked Software",
                "Co-Design",
                "Co-Verification"
            ]
        },
        "url": "URL#1888080"
    },
    {
        "@score": "1",
        "@id": "1888081",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "177/0313",
                        "text": "Maximilian Golla"
                    },
                    {
                        "@pid": "150/5927",
                        "text": "Grant Ho"
                    },
                    {
                        "@pid": "301/5867",
                        "text": "Marika Lohmus"
                    },
                    {
                        "@pid": "301/5865",
                        "text": "Monica Pulluri"
                    },
                    {
                        "@pid": "141/9244",
                        "text": "Elissa M. Redmiles"
                    }
                ]
            },
            "title": "Driving 2FA Adoption at Scale: Optimizing Two-Factor Authentication Notification Design Patterns.",
            "venue": "USENIX Security Symposium",
            "pages": "109-126",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GollaHLPR21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/golla",
            "url": "https://dblp.org/rec/conf/uss/GollaHLPR21",
            "abstract": "Two-factor authentication (2FA) is one of the primary mechanisms for defending end-user accounts against phishing and password reuse attacks. Unfortunately, getting users to adopt 2FA remains a dif\ufb01cult challenge. While prior work at the intersection of measurement and usability has examined how to persuade people to avoid dangerous behavior (e. g., clicking through TLS warnings), relatively little work has conducted measurements at industry scale about how to persuade people to adopt protective behaviors. In this work, we focus on improving end user security in the wild by examining whether (i) messaging that addresses users\u2019 motivations, mental models, and concerns about 2FA and (ii) UX design patterns found effective in other \ufb01elds can effectively improve 2FA adoption. To do so, we conduct a series of large-scale in-the-wild, controlled messaging experiments on Facebook, with an average of 622 , 419 participants per experiment. Based on our results, we distill a set of best-practice design patterns for most effectively encouraging protective behavior, in the context of promoting 2FA adoption. Finally, we suggest concrete directions for future work on encouraging digital security behavior through security prompts.",
            "keywords": [
                "Two-Factor Authentication",
                "User Adoption",
                "Security Messaging",
                "UX Design Patterns",
                "Digital Security Behavior"
            ]
        },
        "url": "URL#1888081",
        "sema_paperId": "bf0cc4293e16748b2779f752130c52400e8f4d1e"
    },
    {
        "@score": "1",
        "@id": "1888082",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "41/136",
                        "text": "Bogdan Groza"
                    },
                    {
                        "@pid": "237/7528",
                        "text": "Lucian Popa 0003"
                    },
                    {
                        "@pid": "81/10328",
                        "text": "Pal-Stefan Murvay"
                    },
                    {
                        "@pid": "38/4086",
                        "text": "Yuval Elovici"
                    },
                    {
                        "@pid": "56/5380",
                        "text": "Asaf Shabtai"
                    }
                ]
            },
            "title": "CANARY - a reactive defense mechanism for Controller Area Networks based on Active RelaYs.",
            "venue": "USENIX Security Symposium",
            "pages": "4259-4276",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Groza0MES21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/groza",
            "url": "https://dblp.org/rec/conf/uss/Groza0MES21",
            "abstract": "We are rethinking the decades-old design of the CAN bus by incorporating reactive defense capabilities in it. While its reliability and cost effectiveness turned CAN into the most widely used in-vehicle communication interface, its topology, physical layer and arbitration mechanism make it impossible to prevent certain types of adversarial activities on the bus. For example, DoS attacks cannot be stopped as the physical layer gives equal rights to all the connected ECUs and an adversary may exploit this by \ufb02ooding the network with high priority frames or cause transmission errors which may move honest ECUs into the bus-off state. In response to this, we propose a reactive mechanism based on relays placed along the bus that will change the network topology in case of an attack, i.e., a moving target defense mechanism, allowing a bus guardian to \ufb01lter and redirect legitimate traf\ufb01c. We take care of physical properties of the bus and keep the 120 \u03a9 load constant at the end of the lines whenever relays are triggered to modify the topology of the bus. We build a proof-of-concept implementation and test it in a laboratory setup with automotive-grade controllers that demonstrates its functionality over collected real-world in-vehicle traf\ufb01c. Our experiments show that despite short term disturbances when the relays are triggered, the frame loss is effectively zero.",
            "keywords": [
                "Controller Area Network (CAN)",
                "Reactive Defense Mechanism",
                "DoS Attacks",
                "Network Topology Modification",
                "Bus Guardian"
            ]
        },
        "url": "URL#1888082",
        "sema_paperId": "604c7b23df3b3c0f0685d957ce1768d25421b747"
    },
    {
        "@score": "1",
        "@id": "1888083",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "76/5349-3",
                        "text": "Cheng Guo 0003"
                    },
                    {
                        "@pid": "157/4001",
                        "text": "Brianne Campbell"
                    },
                    {
                        "@pid": "50/6916",
                        "text": "Apu Kapadia"
                    },
                    {
                        "@pid": "r/MichaelKReiter",
                        "text": "Michael K. Reiter"
                    },
                    {
                        "@pid": "87/1275",
                        "text": "Kelly Caine"
                    }
                ]
            },
            "title": "Effect of Mood, Location, Trust, and Presence of Others on Video-Based Social Authentication.",
            "venue": "USENIX Security Symposium",
            "pages": "1-18",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GuoCKRC21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/guo",
            "url": "https://dblp.org/rec/conf/uss/GuoCKRC21",
            "abstract": "Current fallback authentication mechanisms are unreliable (e.g., security questions are easy to guess) and need improvement. Social authentication shows promise as a novel form of fallback authentication. In this paper, we report the results of a four-week study that explored people\u2019s perceived willingness to use video chat as a form of social authentication. We investigated whether people\u2019s mood, location, and trust, and the presence of others affected perceived willingness to use video chat to authenticate. We found that participants who were alone, reported a more positive mood, and had more trust in others reported more willingness to use video chat as an authentication method. Participants also reported more willingness to help others to authenticate via video chat than to initiate a video chat authentication session themselves. Our results provide initial insights into human-computer interaction issues that could stem from using video chat as a fallback authentication method within a small social network of people (e.g., family members and close friends) who know each other well and trust each other.",
            "keywords": [
                "Social Authentication",
                "Video Chat",
                "User Trust",
                "Mood Influence",
                "Presence of Others"
            ]
        },
        "url": "URL#1888083",
        "sema_paperId": "cd43921cdb7238bce8ef95a2537134392d771858"
    },
    {
        "@score": "1",
        "@id": "1888084",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "182/6753",
                        "text": "Xueyuan Han"
                    },
                    {
                        "@pid": "89/2407-7",
                        "text": "Xiao Yu 0007"
                    },
                    {
                        "@pid": "144/4204",
                        "text": "Thomas F. J.-M. Pasquier"
                    },
                    {
                        "@pid": "95/7132-1",
                        "text": "Ding Li 0001"
                    },
                    {
                        "@pid": "27/5932",
                        "text": "Junghwan Rhee"
                    },
                    {
                        "@pid": "90/1843",
                        "text": "James W. Mickens"
                    },
                    {
                        "@pid": "s/MargoISeltzer",
                        "text": "Margo I. Seltzer"
                    },
                    {
                        "@pid": "08/57",
                        "text": "Haifeng Chen"
                    }
                ]
            },
            "title": "SIGL: Securing Software Installations Through Deep Graph Learning.",
            "venue": "USENIX Security Symposium",
            "pages": "2345-2362",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Han0P0RMSC21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/han-xueyuan",
            "url": "https://dblp.org/rec/conf/uss/Han0P0RMSC21",
            "abstract": "Many users implicitly assume that software can only be exploited after it is installed. However, recent supply-chain attacks demonstrate that application integrity must be ensured during installation itself. We introduce SIGL, a new tool for detecting malicious behavior during software installation. SIGL collects traces of system call activity, building a data provenance graph that it analyzes using a novel autoencoder architecture with a graph long short-term memory network (graph LSTM) for the encoder and a standard multilayer perceptron for the decoder. SIGL flags suspicious installations as well as the specific installation-time processes that are likely to be malicious. Using a test corpus of 625 malicious installers containing real-world malware, we demonstrate that SIGL has a detection accuracy of 96%, outperforming similar systems from industry and academia by up to 87% in precision and recall and 45% in accuracy. We also demonstrate that SIGL can pinpoint the processes most likely to have triggered malicious behavior, works on different audit platforms and operating systems, and is robust to training data contamination and adversarial attack. It can be used with application-specific models, even in the presence of new software versions, as well as application-agnostic meta-models that encompass a wide range of applications and installers.",
            "keywords": [
                "Software Installation Security",
                "Malicious Behavior Detection",
                "Data Provenance Graph",
                "Supply-Chain Attacks",
                "Installation-Time Processes"
            ]
        },
        "url": "URL#1888084",
        "sema_paperId": "2d9568045e326fa1b103d4c2a9d6d20751c40418"
    },
    {
        "@score": "1",
        "@id": "1888085",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "207/6588",
                        "text": "HyungSeok Han"
                    },
                    {
                        "@pid": "301/5906",
                        "text": "Andrew Wesie"
                    },
                    {
                        "@pid": "63/8731",
                        "text": "Brian Pak"
                    }
                ]
            },
            "title": "Precise and Scalable Detection of Use-after-Compacting-Garbage-Collection Bugs.",
            "venue": "USENIX Security Symposium",
            "pages": "2059-2074",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HanWP21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/han-hyungseok",
            "url": "https://dblp.org/rec/conf/uss/HanWP21",
            "abstract": "Compacting garbage collection ( compact-gc ) is a method that improves memory utilization and reduces memory fragmentation by rearranging live objects and updating their references using an address table. A critical use-after-free bug may exist if an object reference that is not registered in the address table is used after compact-gc , as the live object may be moved but the reference will not be updated after compact-gc . We refer to this as a use-after-compact-gc ( use-after-cgc ) bug. Prior tools have attempted to statically detect these bugs with target-speci\ufb01c heuristics. However, due to their path-insensitive analysis and imprecise target-speci\ufb01c heuristics, they have high false-positives and false-negatives. In this paper, we present a precise and scalable static analyzer, named CGSan, for \ufb01nding use-after-cgc bugs. CGSan detects use-after-cgc bug candidates by intra-procedural static symbolic taint analysis and checks their feasibility by under-constrained directed symbolic execution. To mitigate the in-completeness of intra-procedural analysis, we employ a type-based taint policy. For scalability, we propose using directed inter-procedural control-\ufb02ow graphs, which reduce search spaces by excluding paths irrelevant to checking feasibility, and directed scheduling, which prioritizes paths to quickly check feasibility. We evaluated CGSan on Google V8 and Mozilla SpiderMonkey, and we found 13 unique use-after-cgc bugs with only 2 false-positives while two prior tools missed 10 bugs and had 34 false-positives in total.",
            "keywords": [
                "Compacting Garbage Collection",
                "Static Analysis",
                "Use-after-Compact-GC Bugs",
                "Symbolic Execution",
                "Taint Analysis"
            ]
        },
        "url": "URL#1888085",
        "sema_paperId": "a3c0c4ce3460d7986a52c4994f523aade2ca2a7a"
    },
    {
        "@score": "1",
        "@id": "1888086",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "267/5358",
                        "text": "Zhaokun Han"
                    },
                    {
                        "@pid": "50/7693",
                        "text": "Muhammad Yasin"
                    },
                    {
                        "@pid": "79/9006",
                        "text": "Jeyavijayan (JV) Rajendran"
                    }
                ]
            },
            "title": "Does logic locking work with EDA tools?",
            "venue": "USENIX Security Symposium",
            "pages": "1055-1072",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HanYR21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/han-zhaokun",
            "url": "https://dblp.org/rec/conf/uss/HanYR21",
            "abstract": "Logic locking is a promising solution against emerging hardware security threats, which entails protecting a Boolean circuit using a \u201ckeying\u201d mechanism. The latest and hitherto unbroken logic-locking techniques are based on the \u201ccorrupt-and-correct (CAC)\u201d principle, offering provable security against input-output query attacks. However, it remains unclear whether these techniques are susceptible to structural attacks. This paper exploits the properties of integrated circuit (IC) design tools, also termed electronic design automation (EDA) tools, to undermine the security of the CAC techniques. Our proposed attack can break all the CAC techniques, including the unbroken CACrem technique that 40+ hackers taking part in a competition for more than three months could not break. Our attack can break circuits processed with any EDA tools, which is alarming because, until now, none of the EDA tools can render a secure locking solution: logic locking cannot make use of the existing EDA tools. We also provide a security property to ensure resilience against structural attacks. The commonly-used circuits can satisfy this property but only in a few cases where they cannot even defeat brute-force; thus, questions arise on the use of these circuits as benchmarks to evaluate logic locking and other security techniques.",
            "keywords": [
                "Logic Locking",
                "Electronic Design Automation (EDA)",
                "Corrupt-and-Correct (CAC)",
                "Structural Attacks",
                "Security Resilience"
            ]
        },
        "url": "URL#1888086",
        "sema_paperId": "1f4b60f453763314e25e5d34850e773885552c40"
    },
    {
        "@score": "1",
        "@id": "1888087",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "199/2650",
                        "text": "Julie M. Haney"
                    },
                    {
                        "@pid": "132/9687",
                        "text": "Yasemin Acar"
                    },
                    {
                        "@pid": "26/11234",
                        "text": "Susanne Furman"
                    }
                ]
            },
            "title": "&quot;It&apos;s the Company, the Government, You and I&quot;: User Perceptions of Responsibility for Smart Home Privacy and Security.",
            "venue": "USENIX Security Symposium",
            "pages": "411-428",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HaneyAF21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/haney",
            "url": "https://dblp.org/rec/conf/uss/HaneyAF21",
            "abstract": "Smart home technology may expose adopters to increased risk to network security, information privacy, and physical safety. However, users may lack understanding of the privacy and security implications. Additionally, manufacturers often fail to provide transparency and configuration options, and few government-provided guidelines have yet to be widely adopted. This results in little meaningful mitigation action to protect users\u2019 security and privacy. But how can this situation be improved and by whom? It is currently unclear where perceived responsibility for smart home privacy and security lies. To address this gap, we conducted an in-depth interview study of 40 smart home adopters to explore where they assign responsibility and how their perceptions of responsibility relate to their concerns and mitigations. Results reveal that participants\u2019 perceptions of responsibility reflect an interdependent relationship between consumers, manufacturers, and third parties such as the government. However, perceived breakdowns and gaps in the relationship result in users being concerned about their security and privacy. Based on our results, we suggest ways in which these actors can address gaps and better support each other.",
            "keywords": [
                "Smart Home Technology",
                "Privacy and Security",
                "User Responsibility",
                "Manufacturer Transparency",
                "Government Guidelines"
            ]
        },
        "url": "URL#1888087",
        "sema_paperId": "1b8f7bdf11d44ba8a74f3e5d69410285ee7b4627"
    },
    {
        "@score": "1",
        "@id": "1888088",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "227/7262-1",
                        "text": "Xinlei He 0001"
                    },
                    {
                        "@pid": "24/5124-1",
                        "text": "Jinyuan Jia 0001"
                    },
                    {
                        "@pid": "b/MichaelBackes1",
                        "text": "Michael Backes 0001"
                    },
                    {
                        "@pid": "03/9437",
                        "text": "Neil Zhenqiang Gong"
                    },
                    {
                        "@pid": "06/6785-16",
                        "text": "Yang Zhang 0016"
                    }
                ]
            },
            "title": "Stealing Links from Graph Neural Networks.",
            "venue": "USENIX Security Symposium",
            "pages": "2669-2686",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HeJ0G021",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/he-xinlei",
            "url": "https://dblp.org/rec/conf/uss/HeJ0G021",
            "abstract": "Graph data, such as social networks and chemical networks, contains a wealth of information that can help to build powerful applications. To fully unleash the power of graph data, a family of machine learning models, namely graph neural networks (GNNs), is introduced. Empirical results show that GNNs have achieved state-of-the-art performance in various tasks. \nGraph data is the key to the success of GNNs. High-quality graph is expensive to collect and often contains sensitive information, such as social relations. Various research has shown that machine learning models are vulnerable to attacks against their training data. Most of these models focus on data from the Euclidean space, such as images and texts. Meanwhile, little attention has been paid to the security and privacy risks of graph data used to train GNNs. \nIn this paper, we aim at filling the gap by proposing the first link stealing attacks against graph neural networks. Given a black-box access to a GNN model, the goal of an adversary is to infer whether there exists a link between any pair of nodes in the graph used to train the model. We propose a threat model to systematically characterize the adversary's background knowledge along three dimensions. By combination, we obtain a comprehensive taxonomy of 8 different link stealing attacks. We propose multiple novel methods to realize these attacks. Extensive experiments over 8 real-world datasets show that our attacks are effective at inferring links, e.g., AUC (area under the ROC curve) is above 0.95 in multiple cases.",
            "keywords": [
                "Graph Neural Networks",
                "Link Stealing Attacks",
                "Graph Data Privacy",
                "Adversarial Inference",
                "Threat Model"
            ]
        },
        "url": "URL#1888088",
        "sema_paperId": "e4b1d7553020258d7e537e2cfa53865359389eac"
    },
    {
        "@score": "1",
        "@id": "1888089",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "255/9138",
                        "text": "Yingzhe He"
                    },
                    {
                        "@pid": "134/8681",
                        "text": "Guozhu Meng"
                    },
                    {
                        "@pid": "c/KaiChen12",
                        "text": "Kai Chen 0012"
                    },
                    {
                        "@pid": "156/0804",
                        "text": "Xingbo Hu"
                    },
                    {
                        "@pid": "01/10388",
                        "text": "Jinwen He"
                    }
                ]
            },
            "title": "DRMI: A Dataset Reduction Technology based on Mutual Information for Black-box Attacks.",
            "venue": "USENIX Security Symposium",
            "pages": "1901-1918",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HeM0HH21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/he-yingzhe",
            "url": "https://dblp.org/rec/conf/uss/HeM0HH21",
            "abstract": "It is non-trivial to attack deep neural networks in black-box settings without any model detail disclosed. Prior studies on black-box attacks leverage a number of queries to the target model for probing the target model or generating adversarial examples. Queries are usually limited and costly so that the adversary probably fails to mount an effective attack. However, not all the queries have to be made since there exist repetitions or redundancies that induce many inef\ufb01cient queries. Therefore, it leaves a lot of room for data reduction and more ef\ufb01cient queries. To this end, we \ufb01rst propose to use mutual information to measure the data redundancy between two data samples, and then develop a data reduction technique based on mutual information, termed as D R M I . We implement an ef\ufb01cient optimization algorithm in D R M I , so as to obtain a particular subset of data samples, of which the mutual information in between is minimized. We conduct extensive experiments on MNIST, CIFAR10, and ImageNet, and six types of deep neural networks, and evaluate D R M I in model extraction and adversarial attacks. The results demonstrate its high effectiveness in these attacks, surpassing a state-of-the-art approach by raising 7% of model accuracy and two times more transferability of adversarial examples. Through the comparison experiments with other three strategies, we identify what properties of data have been preserved and removed, to some extent reveal the essences of deep neural networks.",
            "keywords": [
                "Black-box Attacks",
                "Data Reduction",
                "Mutual Information",
                "Model Extraction",
                "Adversarial Examples"
            ]
        },
        "url": "URL#1888089",
        "sema_paperId": "3b6e3b46fe03de41a05e29cc49f9eaab210ff297"
    },
    {
        "@score": "1",
        "@id": "1888090",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "228/1460",
                        "text": "Ningyu He"
                    },
                    {
                        "@pid": "08/7975",
                        "text": "Ruiyi Zhang"
                    },
                    {
                        "@pid": "50/8499-1",
                        "text": "Haoyu Wang 0001"
                    },
                    {
                        "@pid": "68/5597-12",
                        "text": "Lei Wu 0012"
                    },
                    {
                        "@pid": "53/1565",
                        "text": "Xiapu Luo"
                    },
                    {
                        "@pid": "07/6300-1",
                        "text": "Yao Guo 0001"
                    },
                    {
                        "@pid": "y/TingYu-1",
                        "text": "Ting Yu 0001"
                    },
                    {
                        "@pid": "80/6988",
                        "text": "Xuxian Jiang"
                    }
                ]
            },
            "title": "EOSAFE: Security Analysis of EOSIO Smart Contracts.",
            "venue": "USENIX Security Symposium",
            "pages": "1271-1288",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HeZ00L0YJ21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/he-ningyu",
            "url": "https://dblp.org/rec/conf/uss/HeZ00L0YJ21",
            "abstract": ".",
            "keywords": [
                "EOSIO Smart Contracts",
                "Blockchain Security",
                "Smart Contract Vulnerabilities",
                "Security Analysis",
                "EOSAFE Tool"
            ]
        },
        "url": "URL#1888090",
        "sema_paperId": "e1d925eb2b0cf0f1259b87b361d0d0351f19760d"
    },
    {
        "@score": "1",
        "@id": "1888091",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "248/1693",
                        "text": "Alexander Heinrich"
                    },
                    {
                        "@pid": "95/1816",
                        "text": "Matthias Hollick"
                    },
                    {
                        "@pid": "06/3872-3",
                        "text": "Thomas Schneider 0003"
                    },
                    {
                        "@pid": "183/6724",
                        "text": "Milan Stute"
                    },
                    {
                        "@pid": "157/4432",
                        "text": "Christian Weinert"
                    }
                ]
            },
            "title": "PrivateDrop: Practical Privacy-Preserving Authentication for Apple AirDrop.",
            "venue": "USENIX Security Symposium",
            "pages": "3577-3594",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HeinrichH0SW21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/heinrich",
            "url": "https://dblp.org/rec/conf/uss/HeinrichH0SW21",
            "abstract": "Apple's offline file-sharing service AirDrop is integrated into more than 1.5 billion end-user devices worldwide. We discovered two design flaws in the underlying protocol that allow attackers to learn the phone numbers and email addresses of both sender and receiver devices. As a remediation, we study the applicability of private set intersection (PSI) to mutual authentication, which is similar to contact discovery in mobile messengers. We propose a novel optimized PSI-based protocol called PrivateDrop that addresses the specific challenges of offline resource-constrained operation and integrates seamlessly into the current AirDrop protocol stack. Using our native PrivateDrop implementation for iOS and macOS, we experimentally demonstrate that PrivateDrop preserves AirDrop's exemplary user experience with an authentication delay well below one second. We responsibly disclosed our findings to Apple and open-sourced our PrivateDrop implementation.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-heinrich.pdf",
            "keywords": [
                "Privacy-Preserving Authentication",
                "File Sharing Protocols",
                "Apple AirDrop",
                "Private Set Intersection (PSI)",
                "User Privacy Vulnerabilities"
            ]
        },
        "url": "URL#1888091"
    },
    {
        "@score": "1",
        "@id": "1888092",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "150/5927",
                        "text": "Grant Ho"
                    },
                    {
                        "@pid": "145/2075",
                        "text": "Mayank Dhiman"
                    },
                    {
                        "@pid": "12/8302",
                        "text": "Devdatta Akhawe"
                    },
                    {
                        "@pid": "p/VernPaxson",
                        "text": "Vern Paxson"
                    },
                    {
                        "@pid": "s/StefanSavage",
                        "text": "Stefan Savage"
                    },
                    {
                        "@pid": "v/GeoffreyMVoelker",
                        "text": "Geoffrey M. Voelker"
                    },
                    {
                        "@pid": "42/5626",
                        "text": "David A. Wagner 0001"
                    }
                ]
            },
            "title": "Hopper: Modeling and Detecting Lateral Movement.",
            "venue": "USENIX Security Symposium",
            "pages": "3093-3110",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HoDAPSV021",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/ho",
            "url": "https://dblp.org/rec/conf/uss/HoDAPSV021",
            "abstract": "In successful enterprise attacks, adversaries often need to gain access to additional machines beyond their initial point of compromise, a set of internal movements known as lateral movement. We present Hopper, a system for detecting lateral movement based on commonly available enterprise logs. Hopper constructs a graph of login activity among internal machines and then identifies suspicious sequences of loginsthat correspond to lateral movement. To understand the larger context of each login, Hopper employs an inference algorithm to identify the broader path(s) of movement that each login belongs to and the causal user responsible for performing a path's logins. Hopper then leverages this path inference algorithm, in conjunction with a set of detection rules and a new anomaly scoring algorithm, to surface the login paths most likely to reflect lateral movement. On a 15-month enterprise dataset consisting of over 780 million internal logins, Hop-per achieves a 94.5% detection rate across over 300 realistic attack scenarios, including one red team attack, while generating an average of<9 alerts per day. In contrast, to detect the same number of attacks, prior state-of-the-art systems would need to generate nearly 8x as many false positives.",
            "keywords": [
                "Lateral Movement Detection",
                "Enterprise Log Analysis",
                "Login Activity Graph",
                "Anomaly Scoring Algorithm",
                "Path Inference Algorithm"
            ]
        },
        "url": "URL#1888092",
        "sema_paperId": "a56defcc764340732bbe8674cf8b9440e355b504"
    },
    {
        "@score": "1",
        "@id": "1888093",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "179/2240",
                        "text": "Nguyen Phong Hoang"
                    },
                    {
                        "@pid": "208/4182",
                        "text": "Arian Akhavan Niaki"
                    },
                    {
                        "@pid": "143/5671",
                        "text": "Jakub Dalek"
                    },
                    {
                        "@pid": "41/11468",
                        "text": "Jeffrey Knockel"
                    },
                    {
                        "@pid": "294/4645",
                        "text": "Pellaeon Lin"
                    },
                    {
                        "@pid": "48/879",
                        "text": "Bill Marczak"
                    },
                    {
                        "@pid": "129/5380",
                        "text": "Masashi Crete-Nishihata"
                    },
                    {
                        "@pid": "52/2893",
                        "text": "Phillipa Gill"
                    },
                    {
                        "@pid": "09/1231",
                        "text": "Michalis Polychronakis"
                    }
                ]
            },
            "title": "How Great is the Great Firewall? Measuring China&apos;s DNS Censorship.",
            "venue": "USENIX Security Symposium",
            "pages": "3381-3398",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HoangNDKLMCGP21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/hoang",
            "url": "https://dblp.org/rec/conf/uss/HoangNDKLMCGP21",
            "abstract": "The DNS filtering apparatus of China's Great Firewall (GFW) has evolved considerably over the past two decades. However, most prior studies of China's DNS filtering were performed over short time periods, leading to unnoticed changes in the GFW's behavior. In this study, we introduce GFWatch, a large-scale, longitudinal measurement platform capable of testing hundreds of millions of domains daily, enabling continuous monitoring of the GFW's DNS filtering behavior. We present the results of running GFWatch over a nine-month period, during which we tested an average of 411M domains per day and detected a total of 311K domains censored by GFW's DNS filter. To the best of our knowledge, this is the largest number of domains tested and censored domains discovered in the literature. We further reverse engineer regular expressions used by the GFW and find 41K innocuous domains that match these filters, resulting in overblocking of their content. We also observe bogus IPv6 and globally routable IPv4 addresses injected by the GFW, including addresses owned by US companies, such as Facebook, Dropbox, and Twitter. Using data from GFWatch, we studied the impact of GFW blocking on the global DNS system. We found 77K censored domains with DNS resource records polluted in popular public DNS resolvers, such as Google and Cloudflare. Finally, we propose strategies to detect poisoned responses that can (1) sanitize poisoned DNS records from the cache of public DNS resolvers, and (2) assist in the development of circumvention tools to bypass the GFW's DNS censorship.",
            "keywords": [
                "DNS Censorship",
                "Great Firewall",
                "Domain Filtering",
                "Internet Censorship",
                "GFWatch"
            ]
        },
        "url": "URL#1888093",
        "sema_paperId": "bf820d51f54152e2571f850ea67a23330043bb51"
    },
    {
        "@score": "1",
        "@id": "1888094",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "31/7616",
                        "text": "Changhui Hu"
                    },
                    {
                        "@pid": "48/1097-2",
                        "text": "Jin Li 0002"
                    },
                    {
                        "@pid": "22/8078",
                        "text": "Zheli Liu"
                    },
                    {
                        "@pid": "43/8066-4",
                        "text": "Xiaojie Guo 0004"
                    },
                    {
                        "@pid": "80/2983-7",
                        "text": "Yu Wei 0007"
                    },
                    {
                        "@pid": "39/7802",
                        "text": "Xuan Guang"
                    },
                    {
                        "@pid": "96/4724",
                        "text": "Grigorios Loukides"
                    },
                    {
                        "@pid": "34/5882",
                        "text": "Changyu Dong"
                    }
                ]
            },
            "title": "How to Make Private Distributed Cardinality Estimation Practical, and Get Differential Privacy for Free.",
            "venue": "USENIX Security Symposium",
            "pages": "965-982",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Hu0LGWGLD21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/hu-changhui",
            "url": "https://dblp.org/rec/conf/uss/Hu0LGWGLD21",
            "abstract": "Secure computation is a promising privacy enhancing technology, but it is often not scalable enough for data intensive applications. On the other hand, the use of sketches has gained  popularity in data mining, because sketches often give rise to highly efficient and scalable sub-linear algorithms. It is natural to ask: what if we put secure computation and sketches together? We investigated the question and the findings are interesting: we can get security, we can get scalability, and somewhat unexpectedly, we can also get differential privacy\u2014for free. Our study started from building a secure computation protocol based on the Flajolet-Martin (FM) sketches, for solving the Private Distributed Cardinality Estimation (PDCE) problem, which is a fundamental problem with applications ranging from crowd tracking to network monitoring. The state of art protocol for PDCE (Fenske et al. CCS '17) is computationally expensive and not scalable enough to cope with big data applications, which prompted us to design a better protocol. Our further analysis revealed that if the cardinality to be estimated is large enough, our protocol can achieve (\u03f5,\u03b4) differential privacy automatically, without requiring any additional manipulation of the output. The result signifies a new approach for achieving differential privacy that departs from the mainstream approach (i.e. adding noise to the result). Free differential privacy can be achieved because of two reasons: secure computation minimizes information leakage, and the intrinsic estimation variance of the FM sketch makes the output of our protocol uncertain. We further show that the result is not just theoretical: the minimal cardinality for differential privacy to hold is only 102 \u2013 104 for typical parameters.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-hu-changhui.pdf",
            "keywords": [
                "Private Distributed Cardinality Estimation",
                "Secure Computation",
                "Flajolet-Martin Sketches",
                "Differential Privacy",
                "Information Leakage"
            ]
        },
        "url": "URL#1888094"
    },
    {
        "@score": "1",
        "@id": "1888095",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "203/0829",
                        "text": "Shengtuo Hu"
                    },
                    {
                        "@pid": "150/3272",
                        "text": "Qi Alfred Chen"
                    },
                    {
                        "@pid": "174/9967",
                        "text": "Jiachen Sun"
                    },
                    {
                        "@pid": "214/8299",
                        "text": "Yiheng Feng"
                    },
                    {
                        "@pid": "91/584",
                        "text": "Z. Morley Mao"
                    },
                    {
                        "@pid": "45/2939",
                        "text": "Henry X. Liu"
                    }
                ]
            },
            "title": "Automated Discovery of Denial-of-Service Vulnerabilities in Connected Vehicle Protocols.",
            "venue": "USENIX Security Symposium",
            "pages": "3219-3236",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HuCSFML21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/hu-shengtuo",
            "url": "https://dblp.org/rec/conf/uss/HuCSFML21",
            "abstract": "With the development of the emerging Connected Vehicle (CV) technology, vehicles can wirelessly communicate with traf\ufb01c infrastructure and other vehicles to exchange safety and mobility information in real time. However, the integrated communication capability inevitably increases the attack surface of vehicles, which can be exploited to cause safety hazard on the road. Thus, it is highly desirable to systematically understand design-level \ufb02aws in the current CV network stack as well as in CV applications, and the corresponding security/safety consequences so that these \ufb02aws can be proactively discovered and addressed before large-scale deployment. In this paper, we design CVAnalyzer , a system for discovering design-level \ufb02aws for availability violations of the CV network stack, as well as quantifying the corresponding security/safety consequences. To achieve this, CVAna-lyzer combines the attack discovery capability of a general model checker and the quantitative threat assessment capability of a probabilistic model checker. Using CVAnalyzer , we successfully uncovered 4 new DoS (Denial-of-Service) vulnerabilities of the latest CV network protocols and 14 new DoS vulnerabilities of two CV platoon management protocols. Our quanti\ufb01cation results show that these attacks can have as high as 99% success rates, and in the worst case can at least double the delay in packet processing, violating the latency requirement in CV communication. We implemented and validated all attacks in a real-world testbed, and also analyzed the fundamental causes to propose potential solutions. We have reported our \ufb01ndings in the CV network protocols to the IEEE 1609 Working Group, and the group has acknowledged the discovered vulnerabilities and plans to adopt our solutions.",
            "keywords": [
                "Connected Vehicle Technology",
                "Denial-of-Service Vulnerabilities",
                "CV Network Stack",
                "Attack Discovery",
                "Quantitative Threat Assessment"
            ]
        },
        "url": "URL#1888095",
        "sema_paperId": "5c344796fc0d7c87bec0148a0711b80b2b47eb9b"
    },
    {
        "@score": "1",
        "@id": "1888096",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "213/7298",
                        "text": "Nicolas Huaman"
                    },
                    {
                        "@pid": "242/6900",
                        "text": "Bennet von Skarczinski"
                    },
                    {
                        "@pid": "184/6096",
                        "text": "Christian Stransky"
                    },
                    {
                        "@pid": "203/1800",
                        "text": "Dominik Wermke"
                    },
                    {
                        "@pid": "132/9687",
                        "text": "Yasemin Acar"
                    },
                    {
                        "@pid": "242/6958",
                        "text": "Arne Drei\u00dfigacker"
                    },
                    {
                        "@pid": "38/9378",
                        "text": "Sascha Fahl"
                    }
                ]
            },
            "title": "A Large-Scale Interview Study on Information Security in and Attacks against Small and Medium-sized Enterprises.",
            "venue": "USENIX Security Symposium",
            "pages": "1235-1252",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HuamanSSWADF21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/huaman",
            "url": "https://dblp.org/rec/conf/uss/HuamanSSWADF21",
            "abstract": "Cybercrime is on the rise. Attacks by hackers, organized crime and nation-state adversaries are an economic threat for companies world-wide. Small and medium-sized enterprises (SMEs) have increasingly become victims of cyber-attacks in recent years. SMEs often lack the awareness and resources to deploy extensive information security measures. However, the health of SMEs is critical for society: For example, in Germany, 38.8% of all employees work in SMEs, which contributed 31.9% of the German annual gross domestic product in 2018. Many guidelines and recommendations encourage companies to invest more into their information security measures. However, there is a lack of understanding of the adoption of security measures in SMEs, their risk perception with regards to cybercrime and their experiences with cyberattacks. To address this gap in research, we performed 5,000 computer-assisted telephone-interviews (CATIs) with representatives of SMEs in Germany. We report on their experiences with cybercrime, management of information security and risk perception. We present and discuss empirical results of the adoption of both technical and organizational security measures and risk awareness in SMEs. We \ufb01nd that many technical security measures and basic awareness have been deployed in the majority of companies. We uncover differences in reporting cybercrime incidences for SMEs based on their industry sector, company size and security awareness. We conclude our work with a discussion of recommendations for future research, industry and policy makers.",
            "keywords": [
                "Information Security",
                "Cybercrime",
                "Small and Medium-sized Enterprises",
                "Risk Perception",
                "Security Measures Adoption"
            ]
        },
        "url": "URL#1888096",
        "sema_paperId": "03d194191db4727cc3821c0fd4ac5b97fcddc898"
    },
    {
        "@score": "1",
        "@id": "1888097",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "277/3612",
                        "text": "Daniel Hugenroth"
                    },
                    {
                        "@pid": "148/2880",
                        "text": "Martin Kleppmann"
                    },
                    {
                        "@pid": "29/361",
                        "text": "Alastair R. Beresford"
                    }
                ]
            },
            "title": "Rollercoaster: An Efficient Group-Multicast Scheme for Mix Networks.",
            "venue": "USENIX Security Symposium",
            "pages": "3433-3450",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HugenrothKB21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/hugenroth",
            "url": "https://dblp.org/rec/conf/uss/HugenrothKB21",
            "abstract": "Mix network designs such as Loopix provide strong metadata anonymity guarantees that are crucial across many applications. However, because they limit the rate at which messages can be sent by each user, they incur high delays when sending many messages to multiple recipients \u2013 for instance, in decentralised collaborative apps. In this paper we present an ef\ufb01cient multicast scheme named Rollercoaster that reduces the time for delivering a message to all members of a group of size m from O ( m ) to O ( log m ) . Rollercoaster can be deployed without modi\ufb01ca-tions to the underlying mix network, allowing it to bene\ufb01t from the anonymity set provided by existing users. We further develop an extension that achieves the same asymptotic guarantees in the presence of unreliable group members. While the scheme is applicable to many mix network designs, we evaluate it for the Loopix network, which is the most advanced and practical design to date. For this evaluation we developed a network simulator that allows fast, reproducible, and inspectable runs while eliminating external in\ufb02uences.",
            "keywords": [
                "Mix Networks",
                "Metadata Anonymity",
                "Group Multicast",
                "Message Delivery Efficiency",
                "Loopix Network"
            ]
        },
        "url": "URL#1888097",
        "sema_paperId": "5a9eede07ec7194e075513fa347a80094c6d7333"
    },
    {
        "@score": "1",
        "@id": "1888098",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "227/2207",
                        "text": "Shehzeen Hussain"
                    },
                    {
                        "@pid": "194/3168",
                        "text": "Paarth Neekhara"
                    },
                    {
                        "@pid": "89/4032",
                        "text": "Shlomo Dubnov"
                    },
                    {
                        "@pid": "29/3483",
                        "text": "Julian J. McAuley"
                    },
                    {
                        "@pid": "k/FarinazKoushanfar",
                        "text": "Farinaz Koushanfar"
                    }
                ]
            },
            "title": "WaveGuard: Understanding and Mitigating Audio Adversarial Examples.",
            "venue": "USENIX Security Symposium",
            "pages": "2273-2290",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HussainNDMK21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/hussain",
            "url": "https://dblp.org/rec/conf/uss/HussainNDMK21",
            "abstract": "There has been a recent surge in adversarial attacks on deep learning based automatic speech recognition (ASR) systems. These attacks pose new challenges to deep learning security and have raised significant concerns in deploying ASR systems in safety-critical applications. In this work, we introduce WaveGuard: a framework for detecting adversarial inputs that are crafted to attack ASR systems. Our framework incorporates audio transformation functions and analyses the ASR transcriptions of the original and transformed audio to detect adversarial inputs. We demonstrate that our defense framework is able to reliably detect adversarial examples constructed by four recent audio adversarial attacks, with a variety of audio transformation functions. With careful regard for best practices in defense evaluations, we analyze our proposed defense and its strength to withstand adaptive and robust attacks in the audio domain. We empirically demonstrate that audio transformations that recover audio from perceptually informed representations can lead to a strong defense that is robust against an adaptive adversary even in a complete white-box setting. Furthermore, WaveGuard can be used out-of-the box and integrated directly with any ASR model to efficiently detect audio adversarial examples, without the need for model retraining.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-hussain.pdf",
            "keywords": [
                "Audio Adversarial Examples",
                "Automatic Speech Recognition",
                "Adversarial Attacks",
                "Detection Framework",
                "WaveGuard"
            ]
        },
        "url": "URL#1888098"
    },
    {
        "@score": "1",
        "@id": "1888099",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "244/2598",
                        "text": "Jacob Imola"
                    },
                    {
                        "@pid": "37/9269",
                        "text": "Takao Murakami"
                    },
                    {
                        "@pid": "56/6435",
                        "text": "Kamalika Chaudhuri"
                    }
                ]
            },
            "title": "Locally Differentially Private Analysis of Graph Statistics.",
            "venue": "USENIX Security Symposium",
            "pages": "983-1000",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ImolaMC21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/imola",
            "url": "https://dblp.org/rec/conf/uss/ImolaMC21",
            "abstract": "Differentially private analysis of graphs is widely used for releasing statistics from sensitive graphs while still preserving user privacy. Most existing algorithms however are in a centralized privacy model, where a trusted data curator holds the entire graph. As this model raises a number of privacy and security issues \u2013 such as, the trustworthiness of the curator and the possibility of data breaches, it is desirable to consider algorithms in a more decentralized local model where no server holds the entire graph.In this work, we consider a local model, and present algorithms for counting subgraphs \u2013 a fundamental task for analyzing the connection patterns in a graph \u2013 with LDP (Local Differential Privacy). For triangle counts, we present algorithms that use one and two rounds of interaction, and show that an additional round can significantly improve the utility. For k-star counts, we present an algorithm that achieves an order optimal estimation error in the non-interactive local model. We provide new lower-bounds on the estimation error for general graph statistics including triangle counts and k-star counts. Finally, we perform extensive experiments on two real datasets, and show that it is indeed possible to accurately estimate subgraph counts in the local differential privacy model.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-imola.pdf",
            "keywords": [
                "Local Differential Privacy",
                "Graph Statistics",
                "Subgraph Counting",
                "Triangle Counts",
                "k-Star Counts"
            ]
        },
        "url": "URL#1888099"
    },
    {
        "@score": "1",
        "@id": "1888100",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "227/0738",
                        "text": "Liz Izhikevich"
                    },
                    {
                        "@pid": "64/4885",
                        "text": "Renata Teixeira"
                    },
                    {
                        "@pid": "143/5673",
                        "text": "Zakir Durumeric"
                    }
                ]
            },
            "title": "LZR: Identifying Unexpected Internet Services.",
            "venue": "USENIX Security Symposium",
            "pages": "3111-3128",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/IzhikevichTD21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/izhikevich",
            "url": "https://dblp.org/rec/conf/uss/IzhikevichTD21",
            "abstract": "Internet-wide scanning is a commonly used research technique that has helped uncover real-world attacks, \ufb01nd cryptographic weaknesses, and understand both operator and mis-creant behavior. Studies that employ scanning have largely assumed that services are hosted on their IANA-assigned ports, overlooking the study of services on unusual ports. In this work, we investigate where Internet services are deployed in practice and evaluate the security posture of services on unexpected ports. We show protocol deployment is more diffuse than previously believed and that protocols run on many additional ports beyond their primary IANA-assigned port. For example, only 3% of HTTP and 6% of TLS services run on ports 80 and 443, respectively. Services on non-standard ports are more likely to be insecure, which results in studies dramatically underestimating the security posture of Internet hosts. Building on our observations, we introduce LZR (\u201cLaser\u201d), a system that identi\ufb01es 99% of identi\ufb01able unexpected services in \ufb01ve handshakes and dramatically reduces the time needed to perform application-layer scans on ports with few responsive expected services (e.g., 5500% speedup on 27017/MongoDB). We conclude with recommendations for future studies.",
            "keywords": [
                "Internet Scanning",
                "Unexpected Ports",
                "Service Deployment",
                "Security Posture",
                "LZR System"
            ]
        },
        "url": "URL#1888100",
        "sema_paperId": "0de86c27c2647f85edc00d029e969d517b939c3d"
    },
    {
        "@score": "1",
        "@id": "1888101",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "301/5827",
                        "text": "Mohit Kumar Jangid"
                    },
                    {
                        "@pid": "05/1884",
                        "text": "Guoxing Chen"
                    },
                    {
                        "@pid": "77/3503",
                        "text": "Yinqian Zhang"
                    },
                    {
                        "@pid": "49/4102-1",
                        "text": "Zhiqiang Lin 0001"
                    }
                ]
            },
            "title": "Towards Formal Verification of State Continuity for Enclave Programs.",
            "venue": "USENIX Security Symposium",
            "pages": "573-590",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/JangidCZL21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/jangid",
            "url": "https://dblp.org/rec/conf/uss/JangidCZL21",
            "abstract": "Trusted Execution Environments such as Intel SGX provide software applications with hardware support for preventing attacks from privileged software. However, these applications are still subject to rollback or replay attacks due to their lack of state continuity protection from the hardware. Therefore, maintaining state continuity has become a burden of software developers, which is not only challenging to implement but also dif\ufb01cult to validate. In this paper, we make the \ufb01rst attempt towards formally verifying the property of state continuity for SGX enclave programs by leveraging the symbolic veri\ufb01cation tool, Tamarin Prover, to model SGX-speci\ufb01c program semantics and operations, and verify the property of state continuity with respect to monotonic counters, global variables, and sealed data, respectively. We apply this method to analyze these three types of state continuity issues exhibited in three open-source SGX applications. We show that our method can successfully identify the \ufb02aws that lead to failures of maintaining state continuity, and formally verify the corrected implementation with respect to the desired property. The discovered \ufb02aws have been reported to the developers and some have been addressed.",
            "keywords": [
                "Trusted Execution Environments",
                "Intel SGX",
                "State Continuity",
                "Formal Verification",
                "Rollback Attacks"
            ]
        },
        "url": "URL#1888101",
        "sema_paperId": "3c6757d7e1e42410c563d09ad0a64e61ef8fbce6"
    },
    {
        "@score": "1",
        "@id": "1888102",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "14/7561",
                        "text": "Rob Jansen"
                    },
                    {
                        "@pid": "224/9243",
                        "text": "Justin Tracey"
                    },
                    {
                        "@pid": "04/6434",
                        "text": "Ian Goldberg"
                    }
                ]
            },
            "title": "Once is Never Enough: Foundations for Sound Statistical Inference in Tor Network Experimentation.",
            "venue": "USENIX Security Symposium",
            "pages": "3415-3432",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/JansenTG21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/jansen",
            "url": "https://dblp.org/rec/conf/uss/JansenTG21",
            "abstract": "Tor is a popular low-latency anonymous communication system that focuses on usability and performance: a faster network will attract more users, which in turn will improve the anonymity of everyone using the system. The standard practice for previous research attempting to enhance Tor performance is to draw conclusions from the observed results of a single simulation for standard Tor and for each research variant.  But because the simulations are run in sampled Tor networks, it is possible that sampling error alone could cause the observed effects.  Therefore, we call into question the practical meaning of any conclusions that are drawn without considering the statistical significance of the reported results.\nIn this paper, we build foundations upon which we improve the Tor experimental method.  First, we present a new Tor network modeling methodology that produces more representative Tor networks as well as new and improved experimentation tools that run Tor simulations faster and at a larger scale than was previously possible. We showcase these contributions by running simulations with 6,489 relays and 792k simultaneously active users, the largest known Tor network simulations and the first at a network scale of 100%.  Second, we present new statistical methodologies through which we: (i) show that running multiple simulations in independently sampled networks is necessary in order to produce informative results; and (ii) show how to use the results from multiple simulations to conduct sound statistical inference.  We present a case study using 420 simulations to demonstrate how to apply our methodologies to a concrete set of Tor experiments and how to analyze the results.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-jansen.pdf",
            "keywords": [
                "Tor Network",
                "Statistical Inference",
                "Network Simulation",
                "Performance Evaluation",
                "Sampling Error"
            ]
        },
        "url": "URL#1888102"
    },
    {
        "@score": "1",
        "@id": "1888103",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "271/6045",
                        "text": "Philipp Jeitner"
                    },
                    {
                        "@pid": "94/7397",
                        "text": "Haya Schulmann"
                    }
                ]
            },
            "title": "Injection Attacks Reloaded: Tunnelling Malicious Payloads over DNS.",
            "venue": "USENIX Security Symposium",
            "pages": "3165-3182",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/JeitnerS21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/jeitner",
            "url": "https://dblp.org/rec/conf/uss/JeitnerS21",
            "abstract": "The traditional design principle for Internet protocols indicates: \u201cBe strict when sending and tolerant when receiv-ing\u201d [RFC1958], and DNS is no exception to this. The transparency of DNS in handling the DNS records, also standardised speci\ufb01cally for DNS [RFC3597], is one of the key features that made it such a popular platform facilitating a constantly increasing number of new applications. An application simply creates a new DNS record and can instantly start dis-tributing it over DNS without requiring any changes to the DNS servers and platforms. Our Internet wide study con\ufb01rms that more than 1.3M (96% of tested) open DNS resolvers are standard compliant and treat DNS records transparently. In this work we show that this \u2018transparency\u2019 introduces a severe vulnerability in the Internet: we demonstrate a new method to launch string injection attacks by encoding malicious payloads into DNS records. We show how to weaponise such DNS records to attack popular applications. For instance, we apply string injection to launch a new type of DNS cache poisoning attack, which we evaluated against a population of open resolvers and found 105K to be vulnerable. Such cache poisoning cannot be prevented with common setups of DNSSEC. Our attacks apply to internal as well as to public services, for instance, we reveal that all eduroam services are vulnerable to our injection attacks, allowing us to launch exploits ranging from unauthorised access to eduroam networks to resource starvation. Depending on the application, our attacks cause system crashes, data corruption and leak-age, degradation of security, and can introduce remote code execution and arbitrary errors.",
            "keywords": [
                "DNS Security",
                "Injection Attacks",
                "Cache Poisoning",
                "Malicious Payloads",
                "eduroam Vulnerabilities"
            ]
        },
        "url": "URL#1888103",
        "sema_paperId": "35bf1cffa93c77bb38b4034b235f78d155191386"
    },
    {
        "@score": "1",
        "@id": "1888104",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "138/4316",
                        "text": "Yuede Ji"
                    },
                    {
                        "@pid": "45/7864",
                        "text": "Mohamed Elsabagh"
                    },
                    {
                        "@pid": "98/3414-2",
                        "text": "Ryan Johnson 0002"
                    },
                    {
                        "@pid": "14/5349",
                        "text": "Angelos Stavrou"
                    }
                ]
            },
            "title": "DEFInit: An Analysis of Exposed Android Init Routines.",
            "venue": "USENIX Security Symposium",
            "pages": "3685-3702",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/JiE0S21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/ji",
            "url": "https://dblp.org/rec/conf/uss/JiE0S21",
            "abstract": "During the booting process of an Android device, a special daemon called Init is launched by the kernel as the \ufb01rst user-space process. Android allows vendors to extend the behavior of Init by introducing custom routines in .rc \ufb01les. These Init routines can also be triggered by privileged pre-installed apps in a certain manner to accomplish privileged functionalities. However, as these pre-installed apps may fail to properly protect access to code sites triggering these Init routines, the capabilities of these routines may leak to unprivileged apps, resulting in crossing security boundaries set by the system. To this end, this study aims at investigating the prevalence of these Init routines and their security impact. We present DEFI NIT as a tool to help automate the process of identifying Init routines exposed by pre-installed apps and estimating their potential security impact. Our \ufb01ndings are alarming. We found that custom Init routines added by vendors were substantial and had signi\ufb01cant security impact. On a data set of 259 \ufb01rmware from the top 21 vendors worldwide, we iden-ti\ufb01ed 1 , 947 exposed custom Init routines in 101 \ufb01rmware from 13 vendors. Of these routines, 515 performed at least one sensitive action. We veri\ufb01ed 89 instances spanning 30 \ufb01rmware from 6 vendors, allowing unprivileged apps to perform sensitive functionalities without user interaction, including disabling SELinux enforcement, snif\ufb01ng network traf\ufb01c, reading system logs, among others.",
            "keywords": [
                "Android Init Routines",
                "Security Vulnerabilities",
                "Privileged Apps",
                "Exposed Routines",
                "Sensitive Actions"
            ]
        },
        "url": "URL#1888104",
        "sema_paperId": "76f13004d628ebd899e38970bc76230e723a844b"
    },
    {
        "@score": "1",
        "@id": "1888105",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "255/4934",
                        "text": "Hengrui Jia"
                    },
                    {
                        "@pid": "250/9674",
                        "text": "Christopher A. Choquette-Choo"
                    },
                    {
                        "@pid": "179/2245",
                        "text": "Varun Chandrasekaran"
                    },
                    {
                        "@pid": "162/1405",
                        "text": "Nicolas Papernot"
                    }
                ]
            },
            "title": "Entangled Watermarks as a Defense against Model Extraction.",
            "venue": "USENIX Security Symposium",
            "pages": "1937-1954",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/JiaCCP21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/jia",
            "url": "https://dblp.org/rec/conf/uss/JiaCCP21",
            "abstract": "Machine learning involves expensive data collection and training procedures. Model owners may be concerned that valuable intellectual property can be leaked if adversaries mount model extraction attacks. As it is difficult to defend against model extraction without sacrificing significant prediction accuracy, watermarking instead leverages unused model capacity to have the model overfit to outlier input-output pairs. Such pairs are watermarks, which are not sampled from the task distribution and are only known to the defender. The defender then demonstrates knowledge of the input-output pairs to claim ownership of the model at inference. The effectiveness of watermarks remains limited because they are distinct from the task distribution and can thus be easily removed through compression or other forms of knowledge transfer.\nWe introduce Entangled Watermarking Embeddings (EWE). Our approach encourages the model to learn features for classifying data that is sampled from the task distribution and data that encodes watermarks. An adversary attempting to remove watermarks that are entangled with legitimate data is also forced to sacrifice performance on legitimate data. Experiments on MNIST, Fashion-MNIST, CIFAR-10, and Speech Commands validate that the defender can claim model ownership with 95% confidence with less than 100 queries to the stolen copy, at a modest cost below 0.81 percentage points on average in the defended model's performance.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-jia.pdf",
            "keywords": [
                "Model Extraction Defense",
                "Watermarking",
                "Intellectual Property Protection",
                "Entangled Watermarks",
                "Adversarial Attacks"
            ]
        },
        "url": "URL#1888105"
    },
    {
        "@score": "1",
        "@id": "1888106",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "226/7196",
                        "text": "Pengfei Jing"
                    },
                    {
                        "@pid": "266/5623",
                        "text": "Qiyi Tang 0003"
                    },
                    {
                        "@pid": "301/5905",
                        "text": "Yuefeng Du 0006"
                    },
                    {
                        "@pid": "68/2052-1",
                        "text": "Lei Xue 0001"
                    },
                    {
                        "@pid": "53/1565",
                        "text": "Xiapu Luo"
                    },
                    {
                        "@pid": "12/2633-6",
                        "text": "Ting Wang 0006"
                    },
                    {
                        "@pid": "50/8847",
                        "text": "Sen Nie"
                    },
                    {
                        "@pid": "49/10149",
                        "text": "Shi Wu"
                    }
                ]
            },
            "title": "Too Good to Be Safe: Tricking Lane Detection in Autonomous Driving with Crafted Perturbations.",
            "venue": "USENIX Security Symposium",
            "pages": "3237-3254",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Jing0D0L0NW21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/jing",
            "url": "https://dblp.org/rec/conf/uss/Jing0D0L0NW21",
            "abstract": "Autonomous driving is developing rapidly and has achieved promising performance by adopting machine learning algorithms to finish various tasks automatically. Lane detection is one of the major tasks because its result directly affects the steering decisions. Although recent studies have discovered some vulnerabilities in autonomous vehicles, to the best of our knowledge, none has investigated the security of lane detection module in real vehicles. In this paper, we conduct the first investigation on the lane detection module in a real vehicle, and reveal that the over-sensitivity of the target module can be exploited to launch attacks on the vehicle. More precisely, an over-sensitive lane detection module may regard small markings on the road surface, which are introduced by an adversary, as a valid lane and then drive the vehicle in the wrong direction. It is challenging to design such small road markings that should be perceived by the lane detection module but unnoticeable to the driver. Manual manipulation of the road markings to launch attacks on the lane detection module is very labor-intensive and error-prone. We propose a novel two-stage approach to automatically determine such road markings after tackling several technical challenges. Our approach first decides the optimal perturbations on the camera image and then maps them to road markings in physical world. We conduct extensive experiments on a Tesla Model S vehicle, and the experimental results show that the lane detection module can be deceived by very unobtrusive perturbations to create a lane, thus misleading the vehicle in auto-steer mode.",
            "keywords": [
                "Autonomous Driving",
                "Lane Detection",
                "Adversarial Perturbations",
                "Vehicle Safety",
                "Road Marking Manipulation"
            ]
        },
        "url": "URL#1888106",
        "sema_paperId": "b586a90c2e6a59a81700c41e2caaeb428d8978cb"
    },
    {
        "@score": "1",
        "@id": "1888107",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "246/5332-1",
                        "text": "Evan Johnson 0001"
                    },
                    {
                        "@pid": "248/1655",
                        "text": "Maxwell Bland"
                    },
                    {
                        "@pid": "174/2169",
                        "text": "Yifei Zhu"
                    },
                    {
                        "@pid": "34/3008",
                        "text": "Joshua Mason"
                    },
                    {
                        "@pid": "14/8302",
                        "text": "Stephen Checkoway"
                    },
                    {
                        "@pid": "s/StefanSavage",
                        "text": "Stefan Savage"
                    },
                    {
                        "@pid": "l/KirillLevchenko",
                        "text": "Kirill Levchenko"
                    }
                ]
            },
            "title": "Jetset: Targeted Firmware Rehosting for Embedded Systems.",
            "venue": "USENIX Security Symposium",
            "pages": "321-338",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/JohnsonBZMCSL21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/johnson",
            "url": "https://dblp.org/rec/conf/uss/JohnsonBZMCSL21",
            "abstract": "The ability to execute code in an emulator is a fundamental part of modern vulnerability testing. Unfortunately, this poses a challenge for many embedded systems, where firmware expects to interact with hardware devices specific to the target. Getting embedded system firmware to run outside its native environment, termed rehosting, requires emulating these hardware devices with enough accuracy to convince the firmware that it is executing on the target hardware. However, full fidelity emulation of target devices (which requires considerable engineering effort) may not be necessary to boot the firmware to a point of interest for an analyst (for example, a point where fuzzer input can be injected). We hypothesized that, for the firmware to boot successfully, it is sufficient to emulate only the behavior expected by the firmware, and that this behavior could be inferred automatically. To test this hypothesis, we developed and implemented Jetset, a system that uses symbolic execution to infer what behavior firmware expects from a target device. Jetset can generate devices models for hardware peripherals in C, allowing an analyst to boot the firmware in an emulator (e.g., QEMU). We successfully applied Jetset to thirteen distinct pieces of firmware together representing three architectures, three application domains (power grid, avionics, and consumer electronics), and five different operating systems. We also demonstrate how Jetset-assisted rehosting facilitates fuzztesting, a common security analysis technique, on an avionics embedded system, in which we found a previously unknown privilege escalation vulnerability.",
            "keywords": [
                "Embedded Systems",
                "Firmware Rehosting",
                "Symbolic Execution",
                "Device Emulation",
                "Fuzz Testing"
            ]
        },
        "url": "URL#1888107",
        "sema_paperId": "4a8e6ac750589612fd2cb141cf4de9216f21a42c"
    },
    {
        "@score": "1",
        "@id": "1888108",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "162/0178",
                        "text": "Ben Kaiser"
                    },
                    {
                        "@pid": "266/7921",
                        "text": "Jerry Wei"
                    },
                    {
                        "@pid": "236/2164",
                        "text": "Eli Lucherini"
                    },
                    {
                        "@pid": "44/765",
                        "text": "Kevin Lee"
                    },
                    {
                        "@pid": "13/3509",
                        "text": "J. Nathan Matias"
                    },
                    {
                        "@pid": "116/8542",
                        "text": "Jonathan R. Mayer"
                    }
                ]
            },
            "title": "Adapting Security Warnings to Counter Online Disinformation.",
            "venue": "USENIX Security Symposium",
            "pages": "1163-1180",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KaiserWLLMM21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/kaiser",
            "url": "https://dblp.org/rec/conf/uss/KaiserWLLMM21",
            "abstract": "Disinformation is proliferating on the internet, and platforms are responding by attaching warnings to content. There is little evidence, however, that these warnings help users identify or avoid disinformation. In this work, we adapt methods and results from the information security warning literature in order to design and evaluate effective disinformation warnings. \nIn an initial laboratory study, we used a simulated search task to examine contextual and interstitial disinformation warning designs. We found that users routinely ignore contextual warnings, but users notice interstitial warnings--and respond by seeking information from alternative sources. \nWe then conducted a follow-on crowdworker study with eight interstitial warning designs. We confirmed a significant impact on user information-seeking behavior, and we found that a warning's design could effectively inform users or convey a risk of harm. We also found, however, that neither user comprehension nor fear of harm moderated behavioral effects. \nOur work provides evidence that disinformation warnings can -- when designed well -- help users identify and avoid disinformation. We show a path forward for designing effective warnings, and we contribute repeatable methods for evaluating behavioral effects. We also surface a possible dilemma: disinformation warnings might be able to inform users and guide behavior, but the behavioral effects might result from user experience friction, not informed decision making.",
            "keywords": [
                "Disinformation Warnings",
                "Information Seeking Behavior",
                "User Comprehension",
                "Behavioral Effects",
                "Risk of Harm"
            ]
        },
        "url": "URL#1888108",
        "sema_paperId": "879425fc9b8b78956eb6333b6969723e3ca9780e"
    },
    {
        "@score": "1",
        "@id": "1888109",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "154/3627",
                        "text": "Mohammad Taha Khan"
                    },
                    {
                        "@pid": "245/3351",
                        "text": "Christopher Tran 0001"
                    },
                    {
                        "@pid": "171/1758",
                        "text": "Shubham Singh"
                    },
                    {
                        "@pid": "301/5820",
                        "text": "Dimitri Vasilkov"
                    },
                    {
                        "@pid": "20/4340",
                        "text": "Chris Kanich"
                    },
                    {
                        "@pid": "66/9786",
                        "text": "Blase Ur"
                    },
                    {
                        "@pid": "01/5750",
                        "text": "Elena Zheleva"
                    }
                ]
            },
            "title": "Helping Users Automatically Find and Manage Sensitive, Expendable Files in Cloud Storage.",
            "venue": "USENIX Security Symposium",
            "pages": "1145-1162",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Khan0SVKUZ21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/khan-mohammad",
            "url": "https://dblp.org/rec/conf/uss/Khan0SVKUZ21",
            "abstract": "With the ubiquity of data breaches, forgotten-about \ufb01les stored in the cloud create latent privacy risks. We take a holistic approach to help users identify sensitive, unwanted \ufb01les in cloud storage. We \ufb01rst conducted 17 qualitative interviews to characterize factors that make humans perceive a \ufb01le as sensitive, useful, and worthy of either protection or deletion. Building on our \ufb01ndings, we conducted a primarily quantitative online study. We showed 108 long-term users of Google Drive or Dropbox a selection of \ufb01les from their accounts. They labeled and explained these \ufb01les\u2019 sensitivity, usefulness, and desired management (whether they wanted to keep, delete, or protect them). For each \ufb01le, we collected many metadata and content features, building a training dataset of 3,525 labeled \ufb01les. We then built Aletheia, which predicts a \ufb01le\u2019s perceived sensitivity and usefulness, as well as its desired management. Aletheia improves over state-of-the-art baselines by 26% to 159%, predicting users\u2019 desired \ufb01le-management decisions with 79% accuracy. Notably, predicting subjective perceptions of usefulness and sensitivity led to a 10% absolute accuracy improvement in predicting desired \ufb01le-management decisions. Aletheia\u2019s performance validates a human-centric approach to feature selection when using inference techniques on subjective security-related tasks. It also improves upon the state of the art in minimizing the attack surface of cloud accounts.",
            "keywords": [
                "Cloud Storage Management",
                "Sensitive File Identification",
                "User Perception of Sensitivity",
                "File Management Decisions",
                "Privacy Risks in Cloud Storage"
            ]
        },
        "url": "URL#1888109",
        "sema_paperId": "56ce2de26c6e3ad429426d9cf2e1721fa913824f"
    },
    {
        "@score": "1",
        "@id": "1888110",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "271/4490",
                        "text": "Arslan Khan"
                    },
                    {
                        "@pid": "155/0040",
                        "text": "Hyungsub Kim"
                    },
                    {
                        "@pid": "45/7986",
                        "text": "Byoungyoung Lee"
                    },
                    {
                        "@pid": "59/5539",
                        "text": "Dongyan Xu"
                    },
                    {
                        "@pid": "99/3883",
                        "text": "Antonio Bianchi"
                    },
                    {
                        "@pid": "159/0537",
                        "text": "Dave (Jing) Tian"
                    }
                ]
            },
            "title": "M2MON: Building an MMIO-based Security Reference Monitor for Unmanned Vehicles.",
            "venue": "USENIX Security Symposium",
            "pages": "285-302",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KhanKLXBT21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/khan-arslan",
            "url": "https://dblp.org/rec/conf/uss/KhanKLXBT21",
            "abstract": "Unmanned Vehicles (UVs) often consist of multiple Micro Controller Units (MCUs) as peripherals to interact with the physical world, including GPS sensors, barometers, motors, etc. While the attack vectors for UV vary, a number of UV attacks aim to impact the physical world either from the cyber or the physical space, e.g., hijacking the mission of UVs via malicious ground control commands or GPS spoo\ufb01ng. This provides us an opportunity to build a uni\ufb01ed and generic security framework defending against multiple kinds of UV attacks by monitoring the system\u2019s I/O activities. Accordingly, we build a security reference monitor for UVs by hooking into the memory-mapped I/O (MMIO), namely M2M ON . Instead of building upon existing RTOS, we implement M2M ON as a microkernel running in the privileged mode intercepting MMIOs while pushing the RTOS and applications into the unprivileged mode. We further instantiate an MMIO \ufb01rewall using M2M ON and demonstrate how to implement a secure Extended Kalman Filter (EKF) within M2M ON . Our evaluation on a real-world UV system shows that M2M ON incurs an 8.85% runtime overhead. Furthermore, M2M ON -based \ufb01rewall is able to defend against different cyber and physical attacks. The M2M ON microkernel contains less than 4K LoC comparing to the 3M LoC RTOS used in our evaluation. We believe M2M ON provides the \ufb01rst step towards building a trusted and practical security reference monitor for UVs.",
            "keywords": [
                "Unmanned Vehicles",
                "Security Reference Monitor",
                "Memory-Mapped I/O",
                "Cyber-Physical Attacks",
                "MMIO Firewall"
            ]
        },
        "url": "URL#1888110",
        "sema_paperId": "60df1e00195f2ab38788a066a45a0532a8ab1df7"
    },
    {
        "@score": "1",
        "@id": "1888111",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "275/2625",
                        "text": "Rishabh Khandelwal"
                    },
                    {
                        "@pid": "227/2845",
                        "text": "Thomas Linden"
                    },
                    {
                        "@pid": "17/9886",
                        "text": "Hamza Harkous"
                    },
                    {
                        "@pid": "97/535",
                        "text": "Kassem Fawaz"
                    }
                ]
            },
            "title": "PriSEC: A Privacy Settings Enforcement Controller.",
            "venue": "USENIX Security Symposium",
            "pages": "465-482",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KhandelwalLHF21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/khandelwal",
            "url": "https://dblp.org/rec/conf/uss/KhandelwalLHF21",
            "abstract": "Online privacy settings aim to provide users with control over their data. However, in their current state, they suffer from usability and reachability issues. The recent push towards automatically analyzing privacy notices has not ac-companied a similar effort for the more critical case of privacy settings. So far, the best efforts targeted the special case of making opt-out pages more reachable. In this work, we present PriSEC, a Privacy Settings Enforcement Controller that leverages machine learning techniques towards a new paradigm for automatically enforcing web privacy controls. PriSEC goes beyond \ufb01nding the webpages with privacy settings to discovering \ufb01ne-grained options, presenting them in a searchable, centralized interface, and \u2013 most importantly \u2013 enforcing them on-demand with minimal user intervention. We overcome the open nature of web development through novel algorithms that leverage the invariant behavior and rendering of webpages. We evaluate the performance of PriSEC to \ufb01nd that it precisely annotates the privacy controls for 94.3% of the control pages in our evaluation set. To demonstrate the usability of PriSEC, we conduct a user study with 148 participants. We show an average reduction of 3.75x in the time taken to adjust privacy settings compared to the baseline system.",
            "keywords": [
                "Privacy Settings",
                "User Control",
                "Web Privacy",
                "Usability Issues",
                "Privacy Enforcement"
            ]
        },
        "url": "URL#1888111",
        "sema_paperId": "e4cb9cb3bfeeaca77e5ada54e3fe63043bee5176"
    },
    {
        "@score": "1",
        "@id": "1888112",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "246/4771",
                        "text": "Soheil Khodayari"
                    },
                    {
                        "@pid": "35/9056",
                        "text": "Giancarlo Pellegrino"
                    }
                ]
            },
            "title": "JAW: Studying Client-side CSRF with Hybrid Property Graphs and Declarative Traversals.",
            "venue": "USENIX Security Symposium",
            "pages": "2525-2542",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KhodayariP21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/khodayari",
            "url": "https://dblp.org/rec/conf/uss/KhodayariP21",
            "abstract": "Client-side CSRF is a new type of CSRF vulnerability where the adversary can trick the client-side JavaScript program to send a forged HTTP request to a vulnerable target site by modifying the program\u2019s input parameters. We have little-to-no knowledge of this new vulnerability, and exploratory security evaluations of JavaScript-based web applications are impeded by the scarcity of reliable and scalable testing techniques. This paper presents JAW, a framework that enables the analysis of modern web applications against client-side CSRF leveraging declarative traversals on hybrid property graphs , a canonical, hybrid model for JavaScript programs. We use JAW to evaluate the prevalence of client-side CSRF vulnerabilities among all (i.e., 106) web applications from the Bitnami catalog, covering over 228M lines of JavaScript code. Our approach uncovers 12,701 forgeable client-side requests affecting 87 web applications in total. For 203 forgeable requests, we successfully created client-side CSRF exploits against seven web applications that can execute arbitrary server-side state-changing operations or enable cross-site scripting and SQL injection, that are not reachable via the classical attack vectors. Finally, we analyzed the forgeable requests and iden-ti\ufb01ed 25 request templates, highlighting the \ufb01elds that can be manipulated and the type of manipulation.",
            "keywords": [
                "Client-side CSRF",
                "Web Application Vulnerabilities",
                "JavaScript Security",
                "Hybrid Property Graphs",
                "Declarative Traversals"
            ]
        },
        "url": "URL#1888112",
        "sema_paperId": "98e7231a3917fb06206ef85ec010fc59060269f3"
    },
    {
        "@score": "1",
        "@id": "1888113",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "157/5259",
                        "text": "Taegyu Kim"
                    },
                    {
                        "@pid": "41/9886",
                        "text": "Vireshwar Kumar"
                    },
                    {
                        "@pid": "27/5932",
                        "text": "Junghwan Rhee"
                    },
                    {
                        "@pid": "301/5888",
                        "text": "Jizhou Chen"
                    },
                    {
                        "@pid": "78/5052",
                        "text": "Kyungtae Kim"
                    },
                    {
                        "@pid": "122/2010",
                        "text": "Chung Hwan Kim"
                    },
                    {
                        "@pid": "59/5539",
                        "text": "Dongyan Xu"
                    },
                    {
                        "@pid": "159/0537",
                        "text": "Dave (Jing) Tian"
                    }
                ]
            },
            "title": "PASAN: Detecting Peripheral Access Concurrency Bugs within Bare-Metal Embedded Applications.",
            "venue": "USENIX Security Symposium",
            "pages": "249-266",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KimKRCKKXT21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/kim",
            "url": "https://dblp.org/rec/conf/uss/KimKRCKKXT21",
            "abstract": "Concurrency bugs might be one of the most challenging software defects to detect and debug due to their non-deterministic triggers caused by task scheduling and interrupt handling. While different tools have been proposed to address concurrency issues, protecting peripherals in embedded systems from concurrent accesses impose unique challenges. A na\u00efve lock protection on a certain memory-mapped I/O (MMIO) address still allows concurrent accesses to other MMIO addresses of a peripheral. Meanwhile, embedded peripherals such as sensors often employ some internal state machines to achieve certain functionalities. As a result, improper locking can lead to the corruption of peripherals\u2019 on-going jobs (we call transaction corruption ) thus corrupted sensor values or failed jobs. In this paper, we propose a static analysis tool namely PAS AN to detect peripheral access concurrency issues for embedded systems. PAS AN automatically \ufb01nds the MMIO address range of each peripheral device using the parser-ready memory layout documents, extracts the peripheral\u2019s internal state machines using the corresponding device drivers, and detects concurrency bugs of peripheral accesses automatically. We evaluate PAS AN on seven different embedded platforms, including multiple real time operating systems (RTOSes) and robotic aerial vehicles (RAVs). PAS AN found 17 true positive concurrency bugs in total from three different platforms with the bug detection rates ranging from 40% to 100%. We have reported all our \ufb01ndings to the corresponding parties. To the best of our knowledge, PAS AN is the \ufb01rst static analysis tool detecting the intrinsic problems in concurrent peripheral accesses for embedded systems.",
            "keywords": [
                "Embedded Systems",
                "Concurrency Bugs",
                "Peripheral Access",
                "Static Analysis",
                "Transaction Corruption"
            ]
        },
        "url": "URL#1888113",
        "sema_paperId": "328f7c7d299b157f1e5f44040c752ba852223e04"
    },
    {
        "@score": "1",
        "@id": "1888114",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "296/1611",
                        "text": "Ofek Kirzner"
                    },
                    {
                        "@pid": "40/944",
                        "text": "Adam Morrison 0001"
                    }
                ]
            },
            "title": "An Analysis of Speculative Type Confusion Vulnerabilities in the Wild.",
            "venue": "USENIX Security Symposium",
            "pages": "2399-2416",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Kirzner021",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/kirzner",
            "url": "https://dblp.org/rec/conf/uss/Kirzner021",
            "abstract": "Spectre v1 attacks, which exploit conditional branch misprediction, are often identified with attacks that bypass array bounds checking to leak data from a victim's memory. Generally, however, Spectre v1 attacks can exploit any conditional branch misprediction that makes the victim execute code incorrectly. In this paper, we investigate speculative type confusion, a Spectre v1 attack vector in which branch mispredictions make the victim execute with variables holding values of the wrong type and thereby leak memory content.\nWe observe that speculative type confusion can be inadvertently introduced by a compiler, making it extremely hard for programmers to reason about security and manually apply Spectre mitigations. We thus set out to determine the extent to which speculative type confusion affects the Linux kernel. Our analysis finds exploitable and potentially-exploitable arbitrary memory disclosure vulnerabilities. We also find many latent vulnerabilities, which could become exploitable due to innocuous system changes, such as coding style changes.\nOur results suggest that Spectre mitigations which rely on statically/manually identifying \"bad\" code patterns need to be rethought, and more comprehensive mitigations are needed.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-kirzner.pdf",
            "keywords": [
                "Speculative Type Confusion",
                "Spectre v1",
                "Memory Disclosure",
                "Linux Kernel Vulnerabilities",
                "Compiler Introduced Vulnerabilities"
            ]
        },
        "url": "URL#1888114"
    },
    {
        "@score": "1",
        "@id": "1888116",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "61/210",
                        "text": "Dmitry Kogan"
                    },
                    {
                        "@pid": "87/8037",
                        "text": "Henry Corrigan-Gibbs"
                    }
                ]
            },
            "title": "Private Blocklist Lookups with Checklist.",
            "venue": "USENIX Security Symposium",
            "pages": "875-892",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KoganC21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/kogan",
            "url": "https://dblp.org/rec/conf/uss/KoganC21",
            "abstract": "This paper presents Checklist, a system for private blocklist lookups. In Checklist, a client can determine whether a particular string appears on a server-held blocklist of strings, without leaking its string to the server. Checklist is the first blocklist-lookup system that (1) leaks no information about the client's string to the server, (2) does not require the client to store the blocklist in its entirety, and (3) allows the server to respond to the client's query in time sublinear in the blocklist size. To make this possible, we construct a new two-server private-information-retrieval protocol that is both asymptotically and concretely faster, in terms of server-side time, than those of prior work. We evaluate Checklist in the context of Google's \"Safe Browsing\" blocklist, which all major browsers use to prevent web clients from visiting malware-hosting URLs. Today, lookups to this blocklist leak partial hashes of a subset of clients' visited URLs to Google's servers. We have modified Firefox to perform Safe-Browsing blocklist lookups via Checklist servers, which eliminates the leakage of partial URL hashes from the Firefox client to the blocklist servers. This privacy gain comes at the cost of increasing communication by a factor of 3.3\u00d7, and the server-side compute costs by 9.8\u00d7. Checklist reduces end-to-end server-side costs by 6.7\u00d7, compared to what would be possible with prior state-of-the-art two-server private information retrieval.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-kogan.pdf",
            "keywords": [
                "Private Blocklist Lookups",
                "Privacy-Preserving Protocols",
                "Information Retrieval",
                "Client-Server Communication",
                "Safe Browsing"
            ]
        },
        "url": "URL#1888116"
    },
    {
        "@score": "1",
        "@id": "1888117",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "160/3825",
                        "text": "Nishat Koti"
                    },
                    {
                        "@pid": "265/5970",
                        "text": "Mahak Pancholi"
                    },
                    {
                        "@pid": "64/3169",
                        "text": "Arpita Patra"
                    },
                    {
                        "@pid": "187/5691",
                        "text": "Ajith Suresh"
                    }
                ]
            },
            "title": "SWIFT: Super-fast and Robust Privacy-Preserving Machine Learning.",
            "venue": "USENIX Security Symposium",
            "pages": "2651-2668",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KotiPPS21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/koti",
            "url": "https://dblp.org/rec/conf/uss/KotiPPS21",
            "abstract": "Performing machine learning (ML) computation on private data while maintaining data privacy, aka Privacy-preserving Machine Learning (PPML), is an emergent field of research. Recently, PPML has seen a visible shift towards the adoption of the Secure Outsourced Computation (SOC) paradigm due to the heavy computation that it entails. In the SOC paradigm, computation is outsourced to a set of powerful and specially equipped servers that provide service on a pay-per-use basis. In this work, we propose SWIFT, a robust PPML framework for a range of ML algorithms in SOC setting, that guarantees output delivery to the users irrespective of any adversarial behaviour. Robustness, a highly desirable feature,   evokes user participation without the fear of denial of service.\nAt the heart of our framework lies a highly-efficient, maliciously-secure, three-party computation (3PC) over rings that provides guaranteed output delivery (GOD) in the honest-majority setting.  To the best of our knowledge, SWIFT is the first robust and efficient  PPML framework in the 3PC setting. SWIFT is as fast as (and is strictly better in some cases than) the best-known 3PC framework BLAZE (Patra et al. NDSS '20), which only achieves fairness. We extend our 3PC framework for four parties (4PC). In this regime, SWIFT is as fast as the best known fair 4PC framework Trident (Chaudhari et al. NDSS '20) and twice faster than the best-known robust 4PC framework FLASH (Byali et al. PETS '20).\nWe demonstrate our framework's practical relevance by benchmarking popular ML algorithms such as Logistic Regression and deep Neural Networks such as VGG16 and LeNet, both over a 64-bit ring in a WAN setting. For deep NN, our results testify to our claims that we provide improved security guarantee while incurring no additional overhead for 3PC and obtaining 2x improvement for 4PC.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-koti.pdf",
            "keywords": [
                "Privacy-preserving Machine Learning",
                "Secure Outsourced Computation",
                "Robustness",
                "Guaranteed Output Delivery",
                "Three-party Computation"
            ]
        },
        "url": "URL#1888117"
    },
    {
        "@score": "1",
        "@id": "1888118",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "170/0453",
                        "text": "Thilo Krachenfels"
                    },
                    {
                        "@pid": "01/8532",
                        "text": "Tuba Kiyan"
                    },
                    {
                        "@pid": "139/7378",
                        "text": "Shahin Tajik"
                    },
                    {
                        "@pid": "98/117",
                        "text": "Jean-Pierre Seifert"
                    }
                ]
            },
            "title": "Automatic Extraction of Secrets from the Transistor Jungle using Laser-Assisted Side-Channel Attacks.",
            "venue": "USENIX Security Symposium",
            "pages": "627-644",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KrachenfelsKTS21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/krachenfels",
            "url": "https://dblp.org/rec/conf/uss/KrachenfelsKTS21",
            "abstract": "The security of modern electronic devices relies on secret keys stored on secure hardware modules as the root-of-trust (RoT). Extracting those keys would break the security of the entire system. As shown before, sophisticated side-channel analysis (SCA) attacks, using chip failure analysis (FA) techniques, can extract data from on-chip memory cells. However, since the chip's layout is unknown to the adversary in practice, secret key localization and reverse engineering are onerous tasks. Consequently, hardware vendors commonly believe that the ever-growing physical complexity of the integrated circuit (IC) designs can be a natural barrier against potential adversaries. In this work, we present a novel approach that can extract the secret key without any knowledge of the IC's layout, and independent from the employed memory technology as key storage. We automate the\u2014traditionally very labor-intensive\u2014reverse engineering and data extraction process. To that end, we demonstrate that black-box measurements captured using laser-assisted SCA techniques from a training device with known key can be used to profile the device for a later key prediction on other victim devices with unknown keys. To showcase the potential of our approach, we target keys on three different hardware platforms, which are utilized as RoT in different products.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-krachenfels.pdf",
            "keywords": [
                "Side-Channel Attacks",
                "Laser-Assisted Techniques",
                "Secret Key Extraction",
                "Reverse Engineering",
                "Integrated Circuit Security"
            ]
        },
        "url": "URL#1888118"
    },
    {
        "@score": "1",
        "@id": "1888119",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "02/11141",
                        "text": "Anunay Kulshrestha"
                    },
                    {
                        "@pid": "116/8542",
                        "text": "Jonathan R. Mayer"
                    }
                ]
            },
            "title": "Identifying Harmful Media in End-to-End Encrypted Communication: Efficient Private Membership Computation.",
            "venue": "USENIX Security Symposium",
            "pages": "893-910",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KulshresthaM21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/kulshrestha",
            "url": "https://dblp.org/rec/conf/uss/KulshresthaM21",
            "abstract": "End-to-endencryption (E2EE) poses a challenge forautomated detection of harmful media,such as child sexual abuse material and extremist content. The predominant approach at present, perceptual hash matching, is not viable because in E2EE a communications service cannot access user content. In this work, we explore the technical feasibility of privacy-preserving perceptual hash matching for E2EE services. We begin by formalizing the problem space and identifying fundamental limitations for protocols. Next, we evaluate the predictive performance of common perceptual hash functions to understand privacy risks to E2EE users and contextualize errors associated with the protocols we design. Our primary contribution is a set of constructions for privacy-preserving perceptual hash matching. We design and evaluate client-side constructions for scenarios where disclosing the set of harmful hashes is acceptable. We then design and evaluate interactive protocols that optionally protect the hash set and do not disclose matches to users. The constructions that we propose are practical for deployment on mobile devices and introduce a limited additional risk of false negatives.",
            "keywords": [
                "End-to-End Encryption",
                "Harmful Media Detection",
                "Privacy-Preserving Protocols",
                "Perceptual Hash Matching",
                "Child Sexual Abuse Material"
            ]
        },
        "url": "URL#1888119",
        "sema_paperId": "a03342d346655722befae957c4daf50c2249d610"
    },
    {
        "@score": "1",
        "@id": "1888120",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "301/5837",
                        "text": "Jochem van de Laarschot"
                    },
                    {
                        "@pid": "224/9337",
                        "text": "Rolf van Wegberg"
                    }
                ]
            },
            "title": "Risky Business? Investigating the Security Practices of Vendors on an Online Anonymous Market using Ground-Truth Data.",
            "venue": "USENIX Security Symposium",
            "pages": "4079-4095",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LaarschotW21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/van-de-laarschot",
            "url": "https://dblp.org/rec/conf/uss/LaarschotW21",
            "abstract": "Cybercriminal entrepreneurs on online anonymous markets rely on security mechanisms to thwart investigators in at-tributing their illicit activities. Earlier work indicates that \u2013 despite the high-risk criminal context \u2013 cybercriminals may turn to poor security practices due to competing business incentives. This claim has not yet been supported through empirical, quantitative analysis on ground-truth data. In this paper, we investigate the security practices on Hansa Market (2015-2017) and measure the prevalence of poor security practices across the vendor population ( n = 1 , 733). We create \u2018vendor types\u2019 based on latent pro\ufb01le analysis, clustering vendors that are similar regarding their experience, activity on other markets, and the amount of physical and digital items sold. We then analyze how these types of vendors differ in their security practices. To that end, we capture their password strength and password uniqueness, 2FA usage, PGP adoption and key strength, PGP-key reuse and the traceability of their cash-out. We \ufb01nd that insecure practices are prevalent across all types of vendors. Yet, between them large differences exist. Rather counter-intuitively, Hansa Market vendors that sell digital items \u2013 like stolen credit cards or malware \u2013 resort to insecure practices more often than vendors selling drugs. We discuss possible explanations, including that vendors of illicit digital items may perceive their risk to be lower than vendors of illicit physical items.",
            "keywords": [
                "Online Anonymous Markets",
                "Cybercriminal Security Practices",
                "Vendor Behavior",
                "Hansa Market Analysis",
                "Poor Security Practices"
            ]
        },
        "url": "URL#1888120",
        "sema_paperId": "7f520b4379f5cb3267805ac8572fd88a0c28b8a1"
    },
    {
        "@score": "1",
        "@id": "1888121",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "239/4292",
                        "text": "Nitya Lakshmanan"
                    },
                    {
                        "@pid": "227/7176",
                        "text": "Nishant Budhdev"
                    },
                    {
                        "@pid": "75/8333",
                        "text": "Min Suk Kang"
                    },
                    {
                        "@pid": "28/6329",
                        "text": "Mun Choon Chan"
                    },
                    {
                        "@pid": "02/3721-1",
                        "text": "Jun Han 0001"
                    }
                ]
            },
            "title": "A Stealthy Location Identification Attack Exploiting Carrier Aggregation in Cellular Networks.",
            "venue": "USENIX Security Symposium",
            "pages": "3899-3916",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LakshmananBKCH21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/lakshmanan",
            "url": "https://dblp.org/rec/conf/uss/LakshmananBKCH21",
            "abstract": "We present the SLIC that achieves \ufb01ne-grained location tracking (e.g., \ufb01nding indoor walking paths) of targeted cellular user devices in a passive manner. The attack exploits a new side channel in modern cellular systems through a universally available feature called carrier aggregation (CA). CA enables higher cellular data rates by allowing multiple base stations on different carrier frequencies to concurrently transmit to a single user. We discover that a passive adversary can learn the side channel \u2014 namely, the number of actively transmitting base stations for any user of interest in the same macrocell. We then show that a time series of this side channel can consti-tute a highly unique \ufb01ngerprint of a walking path, which can be used to identify the path taken by a target cellular user. We \ufb01rst demonstrate the collection of the new side channel and a small-scale path identi\ufb01cation attack in an existing LTE-A network with up to three CA capability (i.e., three base stations can be coordinated for concurrent transmission), showing the feasibility of SLIC in the current cellular networks. We then emulate a near-future 5G network environment with up to nine CA capability in various multi-story buildings in our institution. SLIC shows up to 98.4% of path-identi\ufb01cation accuracy among 100 different walking paths in a large of\ufb01ce building. Through testing in various building structures, we con\ufb01rm that the attack is effective in typical of\ufb01ce building environments; e.g., corridors, open spaces. We present com-plete and partial countermeasures and discuss some practical cell deployment suggestions",
            "keywords": [
                "Cellular Networks",
                "Carrier Aggregation",
                "Location Tracking",
                "Passive Adversary",
                "Path Identification Attack"
            ]
        },
        "url": "URL#1888121",
        "sema_paperId": "f3519dd7ad0162d7496d239947d7b37cb77ea2d1"
    },
    {
        "@score": "1",
        "@id": "1888122",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "167/2160",
                        "text": "Pierre Laperdrix"
                    },
                    {
                        "@pid": "134/8950",
                        "text": "Oleksii Starov"
                    },
                    {
                        "@pid": "40/3858",
                        "text": "Quan Chen"
                    },
                    {
                        "@pid": "22/1459",
                        "text": "Alexandros Kapravelos"
                    },
                    {
                        "@pid": "04/8280",
                        "text": "Nick Nikiforakis"
                    }
                ]
            },
            "title": "Fingerprinting in Style: Detecting Browser Extensions via Injected Style Sheets.",
            "venue": "USENIX Security Symposium",
            "pages": "2507-2524",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LaperdrixSCKN21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/laperdrix",
            "url": "https://dblp.org/rec/conf/uss/LaperdrixSCKN21",
            "abstract": "Browser extensions enhance the web experience and have seen great adoption from users in the past decade. At the same time, past research has shown that online trackers can use various techniques to infer the presence of installed extensions and abuse them to track users as well as uncover sensitive information about them. In this work we present a novel extension-\ufb01ngerprinting vector showing how style modi\ufb01cations from browser extensions can be abused to identify installed extensions. We propose a pipeline that analyzes extensions both statically and dynamically and pinpoints their injected style sheets. Based on these, we craft a set of triggers that uniquely identify browser extensions from the context of the visited page. We analyzed 116K extensions from Chrome\u2019s Web Store and report that 6,645 of them inject style sheets on any website that users visit. Our pipeline has created triggers that uniquely identify 4,446 of these extensions, 1,074 (24%) of which could not be \ufb01ngerprinted with previous techniques. Given the power of this new extension-\ufb01ngerprinting vector, we propose speci\ufb01c countermeasures against style \ufb01ngerprinting that have minimal impact on the overall user experience.",
            "keywords": [
                "Browser Extensions",
                "Fingerprinting",
                "Style Sheets",
                "User Tracking",
                "Countermeasures"
            ]
        },
        "url": "URL#1888122",
        "sema_paperId": "d04f889b2b5f1e2cf27ed555f578c02b2738606d"
    },
    {
        "@score": "1",
        "@id": "1888123",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "301/5833",
                        "text": "Leona Lassak"
                    },
                    {
                        "@pid": "301/5825",
                        "text": "Annika Hildebrandt"
                    },
                    {
                        "@pid": "177/0313",
                        "text": "Maximilian Golla"
                    },
                    {
                        "@pid": "66/9786",
                        "text": "Blase Ur"
                    }
                ]
            },
            "title": "&quot;It&apos;s Stored, Hopefully, on an Encrypted Server&quot;: Mitigating Users&apos; Misconceptions About FIDO2 Biometric WebAuthn.",
            "venue": "USENIX Security Symposium",
            "pages": "91-108",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LassakHGU21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/lassak",
            "url": "https://dblp.org/rec/conf/uss/LassakHGU21",
            "abstract": "While prior attempts at passwordless authentication on the web have required specialized hardware, FIDO2\u2019s WebAuthn protocol lets users sign into websites with their smartphone. Users authenticate locally via the phone\u2019s unlock mechanism. Their phone then uses public-key cryptography to authenticate to the website. Using biometrics (e.g., \ufb01ngerprint, face) for this local authentication can be convenient, yet may engender misconceptions that discourage adoption. Through three complementary studies, we characterized and sought to mitigate misconceptions about biometric WebAuthn. We also compared it to non-biometric WebAuthn and traditional passwords. First, 42 crowdworkers used biometric WebAuthn to sign into a website and then completed surveys. Critically, 67% of participants incorrectly thought their biometrics were sent to the website, creating security concerns. In remote focus groups, 27 crowdworkers then co-designed short no-ti\ufb01cations to mitigate biometric WebAuthn misconceptions. Through a 345-participant online study, we found that some noti\ufb01cations improved perceptions of biometric WebAuthn and partially addressed misconceptions, yet key misconceptions about where the biometric is stored partially persisted. Nonetheless, participants were willing to adopt biometric WebAuthn over non-biometric WebAuthn or passwords. Our work identi\ufb01es directions for increasing the adoption of bio-metric WebAuthn by highlighting its security and usability.",
            "keywords": [
                "FIDO2",
                "Biometric Authentication",
                "WebAuthn",
                "User Misconceptions",
                "Passwordless Authentication"
            ]
        },
        "url": "URL#1888123",
        "sema_paperId": "cecb164c2b22e353a8de94af6314461204a57d15"
    },
    {
        "@score": "1",
        "@id": "1888124",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "236/6363",
                        "text": "Yu Tsung Lee"
                    },
                    {
                        "@pid": "22/4463",
                        "text": "William Enck"
                    },
                    {
                        "@pid": "91/8378",
                        "text": "Haining Chen"
                    },
                    {
                        "@pid": "24/687",
                        "text": "Hayawardh Vijayakumar"
                    },
                    {
                        "@pid": "l/NinghuiLi",
                        "text": "Ninghui Li"
                    },
                    {
                        "@pid": "31/8302",
                        "text": "Zhiyun Qian"
                    },
                    {
                        "@pid": "04/10838",
                        "text": "Daimeng Wang"
                    },
                    {
                        "@pid": "119/7710",
                        "text": "Giuseppe Petracca"
                    },
                    {
                        "@pid": "45/576",
                        "text": "Trent Jaeger"
                    }
                ]
            },
            "title": "PolyScope: Multi-Policy Access Control Analysis to Compute Authorized Attack Operations in Android Systems.",
            "venue": "USENIX Security Symposium",
            "pages": "2579-2596",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LeeECVLQWPJ21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/lee-yu-tsung",
            "url": "https://dblp.org/rec/conf/uss/LeeECVLQWPJ21",
            "abstract": "Android\u2019s filesystem access control provides a foundation for system integrity. It combines mandatory (e.g., SEAndroid) and discretionary (e.g., Unix permissions) access control, protecting both the Android platform from Android/OEM services and Android/OEM services from third-party applications. However, OEMs often introduce vulnerabilities when they add market-differentiating features and fail to correctly reconfigure this complex combination of policies. In this paper, we propose the PolyScope tool to triage Android systems for vulnerabilities using their filesystem access control policies by: (1) identifying the resources that subjects are authorized to use that may be modified by their adversaries, both with and without policy manipulations, and (2) determining the attack operations on those resources that are actually available to adversaries to reveal the specific cases that need vulnerability testing. A key insight is that adversaries may exploit discretionary elements in Android access control to expand the permissions available to themselves and/or victims to launch attack operations, which we call permission expansion. We apply PolyScope to five Google and five OEM Android releases and find that permission expansion increases the privilege available to launch attacks, sometimes by more than 10x, but a significant fraction (about 15-20%) cannot be converted into attack operations due to other system configurations. Based on this analysis, we describe two previously unknown vulnerabilities and show how PolyScope helps OEMs triage the complex combination of access control policies down to attack operations worthy of testing.",
            "keywords": [
                "Android Security",
                "Access Control Policies",
                "Permission Expansion",
                "Vulnerability Analysis",
                "Filesystem Access Control"
            ]
        },
        "url": "URL#1888124",
        "sema_paperId": "6cf8657af6ed2c8fbab2e0a34656ac9e9f73fb9d"
    },
    {
        "@score": "1",
        "@id": "1888125",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "49/6554",
                        "text": "Hyunjoo Lee"
                    },
                    {
                        "@pid": "57/5486",
                        "text": "Jiyeon Lee"
                    },
                    {
                        "@pid": "248/1658",
                        "text": "Daejun Kim"
                    },
                    {
                        "@pid": "74/28",
                        "text": "Suman Jana"
                    },
                    {
                        "@pid": "45/4154",
                        "text": "Insik Shin"
                    },
                    {
                        "@pid": "09/3668",
                        "text": "Sooel Son"
                    }
                ]
            },
            "title": "AdCube: WebVR Ad Fraud and Practical Confinement of Third-Party Ads.",
            "venue": "USENIX Security Symposium",
            "pages": "2543-2560",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LeeLKJSS21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/lee-hyunjoo",
            "url": "https://dblp.org/rec/conf/uss/LeeLKJSS21",
            "abstract": "Web technology has evolved to offer 360-degree immersive browsing experiences. This new technology, called WebVR, enables virtual reality by rendering a three-dimensional world on an HTML canvas. Unfortunately, there exists no browser-supported way of sharing this canvas between different parties. Assuming an abusive ad service provider who exploits this absence, we present four new ad fraud attack methods. Our user study demonstrates that the success rates of our attacks range from 88.23% to 100%, con\ufb01rming their effectiveness. To mitigate the presented threats, we propose AdCube, which allows publishers to specify the behaviors of third-party ad code and enforce this speci\ufb01cation. We show that AdCube is able to block the presented threats with a small page loading latency of 236 msec and a negligible frame-per-second (FPS) drop for nine WebVR of\ufb01cial demo sites.",
            "keywords": [
                "WebVR",
                "Ad Fraud",
                "Third-Party Ads",
                "AdCube",
                "Immersive Browsing"
            ]
        },
        "url": "URL#1888125",
        "sema_paperId": "99d92cd3c4a32f339e5368ef95514f7890aba78b"
    },
    {
        "@score": "1",
        "@id": "1888126",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "301/5818",
                        "text": "Yoochan Lee"
                    },
                    {
                        "@pid": "19/10203",
                        "text": "Changwoo Min"
                    },
                    {
                        "@pid": "45/7986",
                        "text": "Byoungyoung Lee"
                    }
                ]
            },
            "title": "ExpRace: Exploiting Kernel Races through Raising Interrupts.",
            "venue": "USENIX Security Symposium",
            "pages": "2363-2380",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LeeML21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/lee-yoochan",
            "url": "https://dblp.org/rec/conf/uss/LeeML21",
            "abstract": "A kernel data race is notoriously challenging to detect, re-produce, and diagnose, mainly caused by nondeterministic thread interleaving. The kernel data race has a critical security implication since it often leads to memory corruption, which can be abused to launch privilege escalation attacks. Interestingly, due to the challenges above, the exploitation of the kernel data race is also challenging. Specifically, we find that some kernel races are nearly impossible to exploit due to their unique requirement on execution orders, which are almost impossible to happen without manual intervention. This paper develops a generic exploitation technique for kernel data races. To this end, we first analyze kernel data races, which finds an intrinsic condition classifying easy-to-exploit and hard-to-exploit races. Then we develop E XP R ACE , a generic race exploitation technique for modern kernels, including Linux, Microsoft Windows, and MAC OS X. E XP R ACE turns hard-to-exploit races into easy-to-exploit races by manipulating an interrupt mechanism during the exploitation. According to our evaluation with 10 real-world hard-to-exploit races, E XP R ACE was able to exploit all of those within 10 to 118 seconds, while an exploitation without E XP R ACE failed for all given 24 hours.",
            "keywords": [
                "Kernel Data Races",
                "Exploitation Techniques",
                "Interrupt Mechanism",
                "Privilege Escalation Attacks",
                "Hard-to-Exploit Races"
            ]
        },
        "url": "URL#1888126",
        "sema_paperId": "a1f40062fa1ebb39965c1b0c23c487ca12053f6e"
    },
    {
        "@score": "1",
        "@id": "1888127",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "173/9806",
                        "text": "Gwangmu Lee"
                    },
                    {
                        "@pid": "88/1458",
                        "text": "Woochul Shim"
                    },
                    {
                        "@pid": "45/7986",
                        "text": "Byoungyoung Lee"
                    }
                ]
            },
            "title": "Constraint-guided Directed Greybox Fuzzing.",
            "venue": "USENIX Security Symposium",
            "pages": "3559-3576",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LeeSL21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/lee-gwangmu",
            "url": "https://dblp.org/rec/conf/uss/LeeSL21",
            "abstract": "Directed greybox fuzzing is an augmented fuzzing technique intended for the targeted usages such as crash reproduction and proof-of-concept generation, which gives directed-ness to fuzzing by driving the seeds toward the designated program locations called target sites. However, we find that directed greybox fuzzing can still su ff er from the long fuzzing time before exposing the targeted crash, because it does not consider the ordered target sites and the data conditions. This paper presents constraint-guided directed greybox fuzzing that aims to satisfy a sequence of constraints rather than merely reaching a set of target sites. Constraint-guided grey-box fuzzing defines a constraint as the combination of a target site and the data conditions, and drives the seeds to satisfy the constraints in the specified order. We automatically generate the constraints with seven types of crash dumps and four types of patch changelogs, and evaluate the prototype system CAFL against the representative directed greybox fuzzing system AFLGo with 47 real-world crashes and 12 patch changelogs. The evaluation shows CAFL outperforms AFLGo by 2.88x for crash reproduction, and better performs in PoC generation as the constraints get explicit.",
            "keywords": [
                "Directed Greybox Fuzzing",
                "Crash Reproduction",
                "Constraint-guided Fuzzing",
                "Program Analysis",
                "Proof-of-Concept Generation"
            ]
        },
        "url": "URL#1888127",
        "sema_paperId": "ebc9ddadf858c861c243ecd604da18370bd66338"
    },
    {
        "@score": "1",
        "@id": "1888128",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "256/9139",
                        "text": "Ryan Lehmkuhl"
                    },
                    {
                        "@pid": "161/3103",
                        "text": "Pratyush Mishra"
                    },
                    {
                        "@pid": "153/9906",
                        "text": "Akshayaram Srinivasan"
                    },
                    {
                        "@pid": "91/275",
                        "text": "Raluca Ada Popa"
                    }
                ]
            },
            "title": "Muse: Secure Inference Resilient to Malicious Clients.",
            "venue": "USENIX Security Symposium",
            "pages": "2201-2218",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LehmkuhlMSP21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/lehmkuhl",
            "url": "https://dblp.org/rec/conf/uss/LehmkuhlMSP21",
            "abstract": "The increasing adoption of machine learning inference in applications has led to a corresponding increase in concerns about the privacy guarantees offered by existing mechanisms for inference. Such concerns have motivated the construction of efficient secure inference protocols that allow parties to perform inference without revealing their sensitive information. Recently, there has been a proliferation of such proposals, rapidly improving efficiency.  However, most of these protocols assume that the client is semi-honest, that is, the client does not deviate from the protocol; yet in practice, clients are many, have varying incentives, and can behave arbitrarily.\nTo demonstrate that a malicious client can completely break the security of semi-honest protocols, we first develop a new model-extraction attack against many state-of-the-art secure inference protocols. Our attack enables a malicious client to learn model weights with 22x--312x fewer queries than the best black-box model-extraction attack and scales to much deeper networks.\nMotivated by the severity of our attack, we design and implement MUSE, an efficient two-party secure inference protocol resilient to malicious clients. MUSE introduces a novel cryptographic protocol for conditional disclosure of secrets to switch between authenticated additive secret shares and garbled circuit labels, and an improved Beaver's triple generation procedure which is 8x--12.5x faster than existing techniques. \nThese protocols allow MUSE to push a majority of its cryptographic overhead into a preprocessing phase: compared to the equivalent semi-honest protocol (which is close to state-of-the-art), MUSE's online phase is only 1.7x--2.2x slower and uses 1.4x more communication. Overall, MUSE is 13.4x--21x faster and uses 2x--3.6x less communication than existing secure inference protocols which defend against malicious clients.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-lehmkuhl.pdf",
            "keywords": [
                "Secure Inference",
                "Malicious Clients",
                "Model-Extraction Attack",
                "Cryptographic Protocols",
                "MUSE"
            ]
        },
        "url": "URL#1888128"
    },
    {
        "@score": "1",
        "@id": "1888129",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "207/6590",
                        "text": "Julia Len"
                    },
                    {
                        "@pid": "139/2372",
                        "text": "Paul Grubbs"
                    },
                    {
                        "@pid": "26/3399",
                        "text": "Thomas Ristenpart"
                    }
                ]
            },
            "title": "Partitioning Oracle Attacks.",
            "venue": "USENIX Security Symposium",
            "pages": "195-212",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LenGR21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/len",
            "url": "https://dblp.org/rec/conf/uss/LenGR21",
            "abstract": "In this paper we introduce partitioning oracles, a new class of decryption error oracles which, conceptually, take a ciphertext as input and output whether the decryption key belongs to some known subset of keys. Partitioning oracles can arise when encryption schemes are not committing with respect to their keys. We detail adaptive chosen ciphertext attacks that exploit partitioning oracles to efficiently recover passwords and de-anonymize anonymous communications. The attacks utilize efficient key multi-collision algorithms\u2014a cryptanalytic goal that we define\u2014against widely used authenticated encryption with associated data (AEAD) schemes, including AES-GCM, XSalsa20/Poly1305, and ChaCha20/Poly1305.\nWe build a practical partitioning oracle attack that quickly recovers passwords from Shadowsocks proxy servers. We also survey early implementations of the OPAQUE protocol for password-based key exchange, and show how many could be vulnerable to partitioning oracle attacks due to incorrectly using non-committing AEAD. Our results suggest that the community should standardize and make widely available key-committing AEAD to avoid such vulnerabilities.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-len.pdf",
            "keywords": [
                "Partitioning Oracles",
                "Decryption Error Oracles",
                "Adaptive Chosen Ciphertext Attacks",
                "Key Multi-Collision Algorithms",
                "Password Recovery"
            ]
        },
        "url": "URL#1888129"
    },
    {
        "@score": "1",
        "@id": "1888130",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "127/3636",
                        "text": "Jingjie Li"
                    },
                    {
                        "@pid": "147/6281",
                        "text": "Amrita Roy Chowdhury 0001"
                    },
                    {
                        "@pid": "97/535",
                        "text": "Kassem Fawaz"
                    },
                    {
                        "@pid": "76/2864-1",
                        "text": "Younghyun Kim 0001"
                    }
                ]
            },
            "title": "Kal\u03b5ido: Real-Time Privacy Control for Eye-Tracking Systems.",
            "venue": "USENIX Security Symposium",
            "pages": "1793-1810",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Li0FK21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/li-jingjie",
            "url": "https://dblp.org/rec/conf/uss/Li0FK21",
            "abstract": "Recent advances in sensing and computing technologies have led to the rise of eye-tracking platforms. Ranging from mo-biles to high-end mixed reality headsets, a wide spectrum of interactive systems now employs eye-tracking. However, eye gaze data is a rich source of sensitive information that can reveal an individual\u2019s physiological and psychological traits. Prior approaches to protecting eye-tracking data suffer from two major drawbacks: they are either incompatible with the current eye-tracking ecosystem or provide no formal privacy guarantee. In this paper, we propose Kal e ido , an eye-tracking data processing system that (1) provides a formal privacy guarantee, (2) integrates seamlessly with existing eye-tracking ecosystems, and (3) operates in real-time. Kal e ido acts as an intermediary protection layer in the software stack of eye-tracking systems. We conduct a comprehensive user study and trace-based analysis to evaluate Kal e ido . Our user study shows that the users enjoy a satisfactory level of utility from Kal e ido . Additionally, we present empirical evidence of Kal e ido \u2019s effectiveness in thwarting real-world attacks on eye-tracking data.",
            "keywords": [
                "Eye-Tracking Systems",
                "Privacy Protection",
                "Real-Time Data Processing",
                "User Study",
                "Data Security"
            ]
        },
        "url": "URL#1888130",
        "sema_paperId": "0397e2a1372090491b9ee5e369395ee4628f47a6"
    },
    {
        "@score": "1",
        "@id": "1888131",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "185/7953",
                        "text": "Yeting Li"
                    },
                    {
                        "@pid": "200/0201",
                        "text": "Zixuan Chen"
                    },
                    {
                        "@pid": "224/1601",
                        "text": "Jialun Cao"
                    },
                    {
                        "@pid": "25/9771",
                        "text": "Zhiwu Xu 0001"
                    },
                    {
                        "@pid": "266/6164",
                        "text": "Qiancheng Peng"
                    },
                    {
                        "@pid": "75/248",
                        "text": "Haiming Chen"
                    },
                    {
                        "@pid": "92/11199",
                        "text": "Liyuan Chen"
                    },
                    {
                        "@pid": "c/SCCheung",
                        "text": "Shing-Chi Cheung"
                    }
                ]
            },
            "title": "ReDoSHunter: A Combined Static and Dynamic Approach for Regular Expression DoS Detection.",
            "venue": "USENIX Security Symposium",
            "pages": "3847-3864",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiCC0PCCC21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/li-yeting",
            "url": "https://dblp.org/rec/conf/uss/LiCC0PCCC21",
            "abstract": "Regular expression Denial of Service (ReDoS) is a class of algorithmic complexity attacks using the regular expressions (regexes) that cause the typical backtracking-based matching algorithms to run super-linear time. Due to the wide adoption of regexes in computation, ReDoS poses a pervasive and serious security threat. Early detection of ReDoS-vulnerable regexes in software is thus vital. Existing detection approaches mainly fall into two categories: static and dynamic analysis. However, they all suffer from either poor precision or poor recall in the detection of vulnerable regexes. The problem of accurately detecting vulnerable regexes at high precision and high recall remains unsolved. Furthermore, we observed that many ReDoS-vulnerable regex contain more than one vulnerability in reality. Another problem with existing approaches is that they are incapable of detecting multiple vulnerabilities in one regex. To address these two problems, we propose ReDoSHunter, a ReDoS-vulnerable regex detection framework that can effectively pinpoint the multiple vulnerabilities in a vulnerable regex, and generate examples of attack-triggering strings. Re-DoSHunter is driven by \ufb01ve vulnerability patterns derived from massive vulnerable regexes. Besides pinpointing vulnerabilities, ReDoSHunter can assess the degree (i.e., exponential or polynomial) of the vulnerabilities detected. Our experiment results show that ReDoSHunter achieves 100% precision and 100% recall in the detection of ReDoS-vulnerable regexes in three large-scale datasets with 37,651 regexes. It signi\ufb01cantly outperforms seven state-of-the-art techniques.",
            "keywords": [
                "Regular Expression Denial of Service",
                "ReDoS Detection",
                "Static and Dynamic Analysis",
                "Vulnerability Patterns",
                "Attack-Triggering Strings"
            ]
        },
        "url": "URL#1888131",
        "sema_paperId": "1489a44dffb32982e949bec0ba04beb1a3f4a752"
    },
    {
        "@score": "1",
        "@id": "1888132",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "26/379",
                        "text": "Xing Li"
                    },
                    {
                        "@pid": "88/2827",
                        "text": "Yan Chen"
                    },
                    {
                        "@pid": "49/4102",
                        "text": "Zhiqiang Lin"
                    },
                    {
                        "@pid": "49/67",
                        "text": "Xiao Wang"
                    },
                    {
                        "@pid": "129/5511",
                        "text": "Jim Hao Chen"
                    }
                ]
            },
            "title": "Automatic Policy Generation for Inter-Service Access Control of Microservices.",
            "venue": "USENIX Security Symposium",
            "pages": "3971-3988",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiCLWC21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/li-xing",
            "url": "https://dblp.org/rec/conf/uss/LiCLWC21",
            "abstract": "Cloud applications today are often composed of many mi-croservices. To prevent a microservice from being abused by other (compromised) microservices, inter-service access con-trol is applied. However, the complexity of \ufb01ne-grained access control policies, along with the large-scale and dynamic nature of microservices, makes the current manual con\ufb01guration-based access control unsuitable. This paper presents A U - TO A RMOR , the \ufb01rst attempt to automate inter-service access control policy generation for microservices, with two fundamental techniques: (1) a static analysis-based request extraction mechanism that automatically obtains the invocation logic among microservices, and (2) a graph-based policy management mechanism that generates corresponding access con-trol policies with on-demand policy update. Our evaluation on popular microservice applications shows that A UTO A RMOR is able to generate \ufb01ne-grained inter-service access control policies and update them timely based on changes in the application, with only a minor runtime overhead. By seamlessly integrating with the lifecycle of microservices, it does not require any changes to existing code and infrastructures.",
            "keywords": [
                "Microservices",
                "Access Control Policies",
                "Policy Generation",
                "Static Analysis",
                "Graph-based Management"
            ]
        },
        "url": "URL#1888132",
        "sema_paperId": "c9e4ae67eb448d92348bba5d9016a5858bb0e121"
    },
    {
        "@score": "1",
        "@id": "1888133",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "156/2830",
                        "text": "Yuwei Li"
                    },
                    {
                        "@pid": "07/8388",
                        "text": "Shouling Ji"
                    },
                    {
                        "@pid": "55/6958",
                        "text": "Yuan Chen"
                    },
                    {
                        "@pid": "276/0091",
                        "text": "Sizhuang Liang"
                    },
                    {
                        "@pid": "168/2469",
                        "text": "Wei-Han Lee"
                    },
                    {
                        "@pid": "262/2747",
                        "text": "Yueyao Chen"
                    },
                    {
                        "@pid": "248/1663",
                        "text": "Chenyang Lyu"
                    },
                    {
                        "@pid": "97/8329-1",
                        "text": "Chunming Wu 0001"
                    },
                    {
                        "@pid": "12/6354",
                        "text": "Raheem Beyah"
                    },
                    {
                        "@pid": "76/185-1",
                        "text": "Peng Cheng 0001"
                    },
                    {
                        "@pid": "67/10639",
                        "text": "Kangjie Lu"
                    },
                    {
                        "@pid": "12/2633-6",
                        "text": "Ting Wang 0006"
                    }
                ]
            },
            "title": "UNIFUZZ: A Holistic and Pragmatic Metrics-Driven Platform for Evaluating Fuzzers.",
            "venue": "USENIX Security Symposium",
            "pages": "2777-2794",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiJCLLCLWBCL021",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/li-yuwei",
            "url": "https://dblp.org/rec/conf/uss/LiJCLLCLWBCL021",
            "abstract": "A flurry of fuzzing tools (fuzzers) have been proposed in the literature, aiming at detecting software vulnerabilities effectively and efficiently. To date, it is however still challenging to compare fuzzers due to the inconsistency of the benchmarks, performance metrics, and/or environments for evaluation, which buries the useful insights and thus impedes the discovery of promising fuzzing primitives. In this paper, we design and develop UNIFUZZ, an open-source and metrics-driven platform for assessing fuzzers in a comprehensive and quantitative manner. Specifically, UNIFUZZ to date has incorporated 35 usable fuzzers, a benchmark of 20 real-world programs, and six categories of performance metrics. We first systematically study the usability of existing fuzzers, find and fix a number of flaws, and integrate them into UNIFUZZ. Based on the study, we propose a collection of pragmatic performance metrics to evaluate fuzzers from six complementary perspectives. Using UNIFUZZ, we conduct in-depth evaluations of several prominent fuzzers including AFL [1], AFLFast [2], Angora [3], Honggfuzz [4], MOPT [5], QSYM [6], T-Fuzz [7] and VUzzer64 [8]. We find that none of them outperforms the others across all the target programs, and that using a single metric to assess the performance of a fuzzer may lead to unilateral conclusions, which demonstrates the significance of comprehensive metrics. Moreover, we identify and investigate previously overlooked factors that may significantly affect a fuzzer's performance, including instrumentation methods and crash analysis tools. Our empirical results show that they are critical to the evaluation of a fuzzer. We hope that our findings can shed light on reliable fuzzing evaluation, so that we can discover promising fuzzing primitives to effectively facilitate fuzzer designs in the future.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-li-yuwei.pdf",
            "keywords": [
                "Fuzzing Tools",
                "Software Vulnerabilities",
                "Performance Metrics",
                "Fuzzer Evaluation",
                "UNIFUZZ"
            ]
        },
        "url": "URL#1888133"
    },
    {
        "@score": "1",
        "@id": "1888134",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "184/8320",
                        "text": "Shih-Wei Li"
                    },
                    {
                        "@pid": "204/3560",
                        "text": "Xupeng Li"
                    },
                    {
                        "@pid": "155/8148",
                        "text": "Ronghui Gu"
                    },
                    {
                        "@pid": "n/JasonNieh",
                        "text": "Jason Nieh"
                    },
                    {
                        "@pid": "301/5895",
                        "text": "John Zhuang Hui"
                    }
                ]
            },
            "title": "Formally Verified Memory Protection for a Commodity Multiprocessor Hypervisor.",
            "venue": "USENIX Security Symposium",
            "pages": "3953-3970",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiLGNH21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/li-shih-wei",
            "url": "https://dblp.org/rec/conf/uss/LiLGNH21",
            "abstract": "Hypervisors are widely deployed by cloud computing providers to support virtual machines, but their growing complexity poses a security risk, as large codebases contain many vulnerabilities. We present SeKVM, a layered Linux KVM hypervisor architecture that has been formally verified on multiprocessor hardware. Using layers, we isolate KVM\u2019s trusted computing base into a small core such that only the core needs to be verified to ensure KVM\u2019s security guarantees. Using layers, we model hardware features at different levels of abstraction tailored to each layer of software. Lower hypervisor layers that configure and control hardware are verified using a novel machine model that includes multiprocessor memory management hardware such as multi-level shared page tables, tagged TLBs, and a coherent cache hierarchy with cache bypass support. Higher hypervisor layers that build on the lower layers are then verified using a more abstract and simplified model, taking advantage of layer encapsulation to reduce proof burden. Furthermore, layers provide modularity to reduce verification effort across multiple implementation versions. We have retrofitted and verified multiple versions of KVM on Arm multiprocessor hardware, proving the correctness of the implementations and that they contain no vulnerabilities that can affect KVM\u2019s security guarantees. Our work is the first machine-checked proof for a commodity hypervisor using multiprocessor memory management hardware. SeKVM requires only modest KVM modifications and incurs only modest performance overhead versus unmodified KVM on real application workloads.",
            "keywords": [
                "Hypervisor Verification",
                "Multiprocessor Architecture",
                "KVM",
                "Memory Management Security",
                "Formal Verification"
            ]
        },
        "url": "URL#1888134",
        "sema_paperId": "ad320d4d95c9a0f92271d7adc0babd81735a9c85"
    },
    {
        "@score": "1",
        "@id": "1888135",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "157/4437",
                        "text": "Mengyuan Li"
                    },
                    {
                        "@pid": "77/3503",
                        "text": "Yinqian Zhang"
                    },
                    {
                        "@pid": "144/3253",
                        "text": "Huibo Wang"
                    },
                    {
                        "@pid": "181/2763",
                        "text": "Kang Li"
                    },
                    {
                        "@pid": "15/8296",
                        "text": "Yueqiang Cheng"
                    }
                ]
            },
            "title": "CIPHERLEAKS: Breaking Constant-time Cryptography on AMD SEV via the Ciphertext Side Channel.",
            "venue": "USENIX Security Symposium",
            "pages": "717-732",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiZWLC21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/li-mengyuan",
            "url": "https://dblp.org/rec/conf/uss/LiZWLC21",
            "abstract": "AMD\u2019s Secure Encrypted Virtualization (SEV) is a hardware extension available in AMD\u2019s EPYC server processors to support con\ufb01dential cloud computing. While various prior studies have demonstrated attacks against SEV by exploiting its lack of encryption in the VM control block or the lack of integrity protection of the encrypted memory and nested page tables, these issues have been addressed in the subsequent releases of SEV-Encrypted State (SEV-ES) and SEV-Secure Nested Paging (SEV-SNP). In this paper, we study a previously unexplored vulnerability of SEV, including both SEV-ES and SEV-SNP. The vulnerability is dubbed ciphertext side channels, which allows the privileged adversary to infer the guest VM\u2019s execution states or recover certain plaintext. To demonstrate the severity of the vulnerability, we present the C IPHER L EAKS attack, which exploits the ciphertext side channel to steal private keys from the constant-time implementation of the RSA and the ECDSA in the latest OpenSSL library.",
            "keywords": [
                "AMD SEV",
                "Ciphertext Side Channel",
                "Constant-time Cryptography",
                "CIPHERLEAKS Attack",
                "Private Key Recovery"
            ]
        },
        "url": "URL#1888135",
        "sema_paperId": "5fac175bb3d08259c11ff27b64f69106f01bc93b"
    },
    {
        "@score": "1",
        "@id": "1888136",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "188/5871",
                        "text": "Hans Liljestrand"
                    },
                    {
                        "@pid": "149/2426",
                        "text": "Thomas Nyman"
                    },
                    {
                        "@pid": "131/6896",
                        "text": "Lachlan J. Gunn"
                    },
                    {
                        "@pid": "48/6310",
                        "text": "Jan-Erik Ekberg"
                    },
                    {
                        "@pid": "39/2508",
                        "text": "N. Asokan"
                    }
                ]
            },
            "title": "PACStack: an Authenticated Call Stack.",
            "venue": "USENIX Security Symposium",
            "pages": "357-374",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiljestrandNGEA21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/liljestrand",
            "url": "https://dblp.org/rec/conf/uss/LiljestrandNGEA21",
            "abstract": "A popular run-time attack technique is to compromise the control-flow integrity of a program by modifying function return addresses on the stack. So far, shadow stacks have proven to be essential for comprehensively preventing return address manipulation. Shadow stacks record return addresses in integrity-protected memory secured with hardware-assistance or software access control. Software shadow stacks incur high overheads or trade off security for efficiency. Hardware-assisted shadow stacks are efficient and secure, but require the deployment of special-purpose hardware.\nWe present authenticated call stack (ACS), an approach that uses chained message authentication codes (MACs). Our prototype, PACStack, uses the ARMv8.3-A general purpose hardware mechanism for pointer authentication (PA) to implement ACS. Via a rigorous security analysis, we show that PACStack achieves security comparable to hardware-assisted shadow stacks without requiring dedicated hardware. We demonstrate that PACStack's performance overhead is small (\u22483%).",
            "pdf_url": "https://www.usenix.org/system/files/sec21-liljestrand.pdf",
            "keywords": [
                "Control-Flow Integrity",
                "Authenticated Call Stack",
                "Return Address Manipulation",
                "Pointer Authentication",
                "Performance Overhead"
            ]
        },
        "url": "URL#1888136"
    },
    {
        "@score": "1",
        "@id": "1888137",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "77/1513-1",
                        "text": "Yun Lin 0001"
                    },
                    {
                        "@pid": "301/5834",
                        "text": "Ruofan Liu"
                    },
                    {
                        "@pid": "87/2495",
                        "text": "Dinil Mon Divakaran"
                    },
                    {
                        "@pid": "301/5821",
                        "text": "Jun Yang Ng"
                    },
                    {
                        "@pid": "301/5849",
                        "text": "Qing Zhou Chan"
                    },
                    {
                        "@pid": "229/8110",
                        "text": "Yiwen Lu"
                    },
                    {
                        "@pid": "301/5838",
                        "text": "Yuxuan Si"
                    },
                    {
                        "@pid": "21/3626",
                        "text": "Fan Zhang"
                    },
                    {
                        "@pid": "33/6517",
                        "text": "Jin Song Dong"
                    }
                ]
            },
            "title": "Phishpedia: A Hybrid Deep Learning Based Approach to Visually Identify Phishing Webpages.",
            "venue": "USENIX Security Symposium",
            "pages": "3793-3810",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LinLDNCLSZD21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/lin",
            "url": "https://dblp.org/rec/conf/uss/LinLDNCLSZD21",
            "abstract": "Recent years have seen the development of phishing detection and identification approaches to defend against phishing attacks. Phishing detection solutions often report binary results, i.e., phishing or not, without any explanation. In contrast, phishing identification approaches identify phishing webpages by visually comparing webpages with predefined legitimate references and report phishing along with its target brand, thereby having explainable results. However, there are technical challenges in visual analyses that limit existing solutions from being effective (with high accuracy) and efficient (with low runtime overhead), to be put to practical use. In this work, we design a hybrid deep learning system, Phishpedia, to address two prominent technical challenges in phishing identification, i.e., (i) accurate recognition of identity logos on webpage screenshots, and (ii) matching logo variants of the same brand. Phishpedia achieves both high accuracy and low runtime overhead. And very importantly, different from common approaches, Phishpedia does not require training on any phishing samples. We carry out extensive experiments using real phishing data; the results demonstrate that Phishpedia significantly outperforms baseline identification approaches (EMD, PhishZoo, and LogoSENSE) in accurately and efficiently identifying phishing pages. We also deployed Phishpedia with CertStream service and discovered 1,704 new real phishing websites within 30 days, significantly more than other solutions; moreover, 1,133 of them are not reported by any engines in VirusTotal.",
            "keywords": [
                "Phishing Detection",
                "Phishing Identification",
                "Visual Analysis",
                "Logo Recognition",
                "Explainable Results"
            ]
        },
        "url": "URL#1888137",
        "sema_paperId": "15d06f25f1af95db15d7252dfdc953f176c68d52"
    },
    {
        "@score": "1",
        "@id": "1888138",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "195/5202",
                        "text": "Shinan Liu"
                    },
                    {
                        "@pid": "29/1059",
                        "text": "Xiang Cheng"
                    },
                    {
                        "@pid": "162/4998",
                        "text": "Hanchao Yang"
                    },
                    {
                        "@pid": "64/10521",
                        "text": "Yuanchao Shu"
                    },
                    {
                        "@pid": "301/5804",
                        "text": "Xiaoran Weng"
                    },
                    {
                        "@pid": "33/5440-7",
                        "text": "Ping Guo 0007"
                    },
                    {
                        "@pid": "162/5539",
                        "text": "Kexiong Curtis Zeng"
                    },
                    {
                        "@pid": "71/4292-11",
                        "text": "Gang Wang 0011"
                    },
                    {
                        "@pid": "10/3200",
                        "text": "Yaling Yang"
                    }
                ]
            },
            "title": "Stars Can Tell: A Robust Method to Defend against GPS Spoofing Attacks using Off-the-shelf Chipset.",
            "venue": "USENIX Security Symposium",
            "pages": "3935-3952",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiuCYSWGZ0Y21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/liu-shinan",
            "url": "https://dblp.org/rec/conf/uss/LiuCYSWGZ0Y21",
            "abstract": "The GPS has empowered billions of users and various critical infrastructures with its positioning and time services. However, GPS spoo\ufb01ng attacks also become a growing threat to GPS-dependent systems. Existing detection methods either require expensive hardware modi\ufb01cations to current GPS devices or lack the basic robustness against sophisticated attacks, hurting their adoption and usage in practice. In this paper, we propose a novel GPS spoo\ufb01ng detection framework that works with off-the-shelf GPS chipsets. Our basic idea is to rotate a one-side-blocked GPS receiver to derive the angle-of-arrival (AoAs) of received signals and compare them with the GPS constellation (consists of tens of GPS satellites). We \ufb01rst demonstrate the effectiveness of this idea by implementing a smartphone prototype and evaluating it against a real spoofer in various \ufb01eld experiments (in both open air and urban canyon environments). Our method achieves a high accuracy (95%\u2013100%) in 5 seconds. Then we implement an adaptive attack, assuming the attacker becomes aware of our defense method and actively modulates the spoo\ufb01ng signals accordingly. We study this adaptive attack and propose enhancement methods (using the rotation speed as the \u201csecret key\u201d) to fortify the defense. Further experiments are conducted",
            "keywords": [
                "GPS Spoofing Detection",
                "Angle-of-Arrival",
                "Off-the-shelf Chipsets",
                "Adaptive Attacks",
                "Field Experiments"
            ]
        },
        "url": "URL#1888138",
        "sema_paperId": "b36565abd7e51601273bbd64a5be361128b50d01"
    },
    {
        "@score": "1",
        "@id": "1888139",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "166/6255",
                        "text": "Zaoxing Liu"
                    },
                    {
                        "@pid": "192/2227",
                        "text": "Hun Namkung"
                    },
                    {
                        "@pid": "94/8398",
                        "text": "Georgios Nikolaidis"
                    },
                    {
                        "@pid": "05/5543",
                        "text": "Jeongkeun Lee"
                    },
                    {
                        "@pid": "55/4381",
                        "text": "Changhoon Kim"
                    },
                    {
                        "@pid": "68/3340-8",
                        "text": "Xin Jin 0008"
                    },
                    {
                        "@pid": "14/4758",
                        "text": "Vladimir Braverman"
                    },
                    {
                        "@pid": "89/6345",
                        "text": "Minlan Yu"
                    },
                    {
                        "@pid": "45/4044",
                        "text": "Vyas Sekar"
                    }
                ]
            },
            "title": "Jaqen: A High-Performance Switch-Native Approach for Detecting and Mitigating Volumetric DDoS Attacks with Programmable Switches.",
            "venue": "USENIX Security Symposium",
            "pages": "3829-3846",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiuNNLK0BYS21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/liu-zaoxing",
            "url": "https://dblp.org/rec/conf/uss/LiuNNLK0BYS21",
            "abstract": "The emergence of programmable switches offers a new opportunity to revisit ISP-scale defenses for volumetric DDoS attacks. In theory, these can offer better cost vs. performance vs. \ufb02exibility trade-offs relative to proprietary hardware and virtual appliances. However, the ISP setting creates unique challenges in this regard\u2014we need to run a broad spectrum of detection and mitigation functions natively on the programmable switch hardware and respond to dynamic adaptive attacks at scale. Thus, prior efforts in using programmable switches that assume out-of-band detection and/or use switches merely as accelerators for speci\ufb01c tasks are no longer suf\ufb01cient, and as such, this potential remains unrealized. To tackle these challenges, we design and implement Jaqen, a switch-native approach for volumetric DDoS defense that can run detection and mitigation functions entirely inline on switches, without relying on additional data plane hardware. We design switch-optimized, resource-ef\ufb01cient detection and mitigation building blocks. We design a \ufb02exible API to construct a wide spectrum of best-practice (and future) defense strategies that ef\ufb01ciently use switch capabilities. We build a network-wide resource manager that quickly adapts to the attack posture changes. Our experiments show that Jaqen is orders of magnitude more performant than existing systems: Jaqen can handle large-scale hybrid and dynamic attacks within seconds, and mitigate them effectively at high line-rates (380 Gbps).",
            "keywords": [
                "Programmable Switches",
                "DDoS Defense",
                "Volumetric Attacks",
                "Detection and Mitigation",
                "Network Resource Management"
            ]
        },
        "url": "URL#1888139",
        "sema_paperId": "47d7625005f19ffcfa92b890e7578af9433b27ea"
    },
    {
        "@score": "1",
        "@id": "1888140",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "22/7702",
                        "text": "Binbin Liu"
                    },
                    {
                        "@pid": "225/3498",
                        "text": "Junfu Shen"
                    },
                    {
                        "@pid": "09/6585-2",
                        "text": "Jiang Ming 0002"
                    },
                    {
                        "@pid": "12/5985",
                        "text": "Qilong Zheng"
                    },
                    {
                        "@pid": "181/2820-47",
                        "text": "Jing Li 0047"
                    },
                    {
                        "@pid": "158/2764",
                        "text": "Dongpeng Xu 0001"
                    }
                ]
            },
            "title": "MBA-Blast: Unveiling and Simplifying Mixed Boolean-Arithmetic Obfuscation.",
            "venue": "USENIX Security Symposium",
            "pages": "1701-1718",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiuS0ZLX21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/liu-binbin",
            "url": "https://dblp.org/rec/conf/uss/LiuS0ZLX21",
            "abstract": "Mixed Boolean-Arithmetic (MBA) obfuscation is a method to perform a semantics-preserving transformation from a simple expression to a representation that is hard to understand and analyze. More speci\ufb01cally, this obfuscation technique consists of the mixture usage of arithmetic operations (e.g., ADD and IMUL) and Boolean operations (e.g., AND, OR, and NOT). Binary code with MBA obfuscation can effectively hide the secret data/algorithm from both static and dynamic reverse engineering, including advanced analyses utilizing SMT solvers. Unfortunately, deobfuscation research against MBA is still in its infancy: state-of-the-art solutions such as pattern matching, bit-blasting, and program synthesis either suffer from severe performance penalties, are designed for speci\ufb01c MBA patterns, or generate too many false simpli\ufb01ca-tion results in practice. In this paper, we \ufb01rst demystify the underlying mechanism of MBA obfuscation. Our in-depth study reveals a hidden two-way feature regarding MBA transformation between 1-bit and n-bit variables. We exploit this feature and propose a viable solution to ef\ufb01ciently deobfuscate code with MBA obfuscation. Our key insight is that MBA transformations behave in the same way on 1-bit and n-bit variables. We provide a mathematical proof to guarantee the correctness of this \ufb01nding. We further develop a novel technique to simplify MBA expressions to a normal simple form by arithmetic reduction in 1-bit space. We have implemented this idea as an open-source prototype, named MBA-Blast , and evaluated it on a comprehensive dataset with about 10 , 000 MBA expressions. We also tested our method in real-world, binary code deobfuscation scenarios, which demonstrate that MBA-Blast can assist human analysts to harness the full strength of SMT solvers. Compared with existing work, MBA-Blast is the most generic and ef\ufb01cient MBA deobfuscation technique; it has a solid theoretical underpinning, as well as, the highest success rate with negligible overhead.",
            "keywords": [
                "Mixed Boolean-Arithmetic Obfuscation",
                "Code Deobfuscation",
                "SMT Solvers",
                "Mathematical Proof",
                "MBA-Blast"
            ]
        },
        "url": "URL#1888140",
        "sema_paperId": "22c57a317821495b1942d5a39c460b4e15bbfabf"
    },
    {
        "@score": "1",
        "@id": "1888141",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "271/9833",
                        "text": "Jiadong Lou"
                    },
                    {
                        "@pid": "24/6114-1",
                        "text": "Xu Yuan 0001"
                    },
                    {
                        "@pid": "181/2597-17",
                        "text": "Ning Zhang 0017"
                    }
                ]
            },
            "title": "Messy States of Wiring: Vulnerabilities in Emerging Personal Payment Systems.",
            "venue": "USENIX Security Symposium",
            "pages": "3273-3289",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LouYZ21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/lou",
            "url": "https://dblp.org/rec/conf/uss/LouYZ21",
            "abstract": "This paper presents our study on an emerging paradigm of payment service that allows individual merchants to leverage the personal transfer service in third-party platforms to support commercial transactions. This is made possible by leveraging an additional order management system, collectively named Personal Payment System (PPS) . To gain a better understanding of these emerging systems, we conducted a systematic study on 35 PPS s covering over 11740 mer-chant clients supporting more than 20 million customers. By examining the documentation, available source codes, and demos, we extracted a common abstracted model for PPS and discovered seven categories of vulnerabilities in the existing personal payment protocol design and system implementation. It is alarming that all PPS s under study have at least one vulnerability. To further dissect these potential weaknesses, we present the corresponding attack methods to exploit the discovered vulnerabilities. To validate our proposed attacks, we conducted four successful real attacks to illustrate the severe consequences. We have responsibly disclosed the newly discovered vulnerabilities, with some patched after our reporting.",
            "keywords": [
                "Personal Payment Systems",
                "Payment Protocol Vulnerabilities",
                "Merchant Transactions",
                "Order Management Systems",
                "Exploitable Vulnerabilities"
            ]
        },
        "url": "URL#1888141",
        "sema_paperId": "d0b937319db7c2413798904691d52f593518b08f"
    },
    {
        "@score": "1",
        "@id": "1888142",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "250/8972",
                        "text": "Kevin Loughlin"
                    },
                    {
                        "@pid": "223/0804",
                        "text": "Ian Neal"
                    },
                    {
                        "@pid": "182/6469",
                        "text": "Jiacheng Ma 0001"
                    },
                    {
                        "@pid": "301/5874",
                        "text": "Elisa Tsai"
                    },
                    {
                        "@pid": "150/7488",
                        "text": "Ofir Weisse"
                    },
                    {
                        "@pid": "27/3820",
                        "text": "Satish Narayanasamy"
                    },
                    {
                        "@pid": "31/11029",
                        "text": "Baris Kasikci"
                    }
                ]
            },
            "title": "DOLMA: Securing Speculation with the Principle of Transient Non-Observability.",
            "venue": "USENIX Security Symposium",
            "pages": "1397-1414",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LoughlinNMTWNK21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/loughlin",
            "url": "https://dblp.org/rec/conf/uss/LoughlinNMTWNK21",
            "abstract": "Modern processors allow attackers to leak data during transient (i.e., mis-speculated) execution through microarchitectural covert timing channels. While initial defenses were channel-speci\ufb01c, recent solutions employ speculative information \ufb02ow control in an attempt to automatically mitigate attacks via any channel. However, we demonstrate that the current state-of-the-art defense fails to mitigate attacks using speculative stores, still allowing arbitrary data leakage during transient execution. Furthermore, we show that the state of the art does not scale to protect data in registers, incurring 30 . 8\u201363 . 4% overhead on SPEC 2017, depending on the threat model. We then present D OLMA , the \ufb01rst defense to automatically provide comprehensive protection against all known transient execution attacks. D OLMA combines a lightweight speculative information \ufb02ow control scheme with a set of secure performance optimizations. By enforcing a novel principle of transient non-observability , D OLMA ensures that a time slice on a core provides a unit of isolation in the context of existing attacks. Accordingly, D OLMA can allow speculative TLB/L1 cache accesses and variable-time arithmetic without loss of security. On SPEC 2017, D OLMA achieves comprehensive protection of data in memory at 10 . 2\u201329 . 7% overhead, adding protection for data in registers at 22 . 6\u201342 . 2% overhead (8 . 2\u2013 21 . 2% less than the state of the art, with greater security).",
            "keywords": [
                "Transient Execution Attacks",
                "Speculative Information Flow Control",
                "Microarchitectural Covert Timing Channels",
                "Data Leakage Mitigation",
                "Transient Non-Observability"
            ]
        },
        "url": "URL#1888142",
        "sema_paperId": "646589d8a76bc738ce2d6cb9fc851b20f581a79f"
    },
    {
        "@score": "1",
        "@id": "1888143",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "172/6496",
                        "text": "Giulio Lovisotto"
                    },
                    {
                        "@pid": "248/8006",
                        "text": "Henry Turner"
                    },
                    {
                        "@pid": "130/3410",
                        "text": "Ivo Sluganovic"
                    },
                    {
                        "@pid": "117/8959",
                        "text": "Martin Strohmeier"
                    },
                    {
                        "@pid": "87/2623",
                        "text": "Ivan Martinovic"
                    }
                ]
            },
            "title": "SLAP: Improving Physical Adversarial Examples with Short-Lived Adversarial Perturbations.",
            "venue": "USENIX Security Symposium",
            "pages": "1865-1882",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LovisottoTSSM21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/lovisotto",
            "url": "https://dblp.org/rec/conf/uss/LovisottoTSSM21",
            "abstract": "Whilst significant research effort into adversarial examples (AE) has emerged in recent years, the main vector to realize these attacks in the real-world currently relies on static adversarial patches, which are limited in their conspicuousness and can not be modified once deployed. In this paper, we propose Short-Lived Adversarial Perturbations (SLAP), a novel technique that allows adversaries to realize robust, dynamic real-world AE from a distance. As we show in this paper, such attacks can be achieved using a light projector to shine a specifically crafted adversarial image in order to perturb real-world objects and transform them into AE. This allows the adversary greater control over the attack compared to adversarial patches: (i) projections can be dynamically turned on and off or modified at will, (ii) projections do not suffer from the locality constraint imposed by patches, making them harder to detect. We study the feasibility of SLAP in the self-driving scenario, targeting both object detector and traffic sign recognition tasks. We demonstrate that the proposed method generates AE that are robust to different environmental conditions for several networks and lighting conditions: we successfully cause misclassifications of state-of-the-art networks such as Yolov3 and Mask-RCNN with up to 98% success rate for a variety of angles and distances. Additionally, we demonstrate that AE generated with SLAP can bypass SentiNet, a recent AE detection method which relies on the fact that adversarial patches generate highly salient and localized areas in the input images.",
            "keywords": [
                "Adversarial Examples",
                "Dynamic Perturbations",
                "Object Detection",
                "Traffic Sign Recognition",
                "Robustness Against Detection"
            ]
        },
        "url": "URL#1888143",
        "sema_paperId": "23811906b2fc98b2591f1d9f69d57814d5151108"
    },
    {
        "@score": "1",
        "@id": "1888144",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "198/3346",
                        "text": "Zane Ma"
                    },
                    {
                        "@pid": "34/3008",
                        "text": "Joshua Mason"
                    },
                    {
                        "@pid": "26/216",
                        "text": "Manos Antonakakis"
                    },
                    {
                        "@pid": "143/5673",
                        "text": "Zakir Durumeric"
                    },
                    {
                        "@pid": "359/0958",
                        "text": "Michael D. Bailey"
                    }
                ]
            },
            "title": "What&apos;s in a Name? Exploring CA Certificate Control.",
            "venue": "USENIX Security Symposium",
            "pages": "4383-4400",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MaMADB21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/ma",
            "url": "https://dblp.org/rec/conf/uss/MaMADB21",
            "abstract": "TLS clients rely on a supporting PKI in which certi\ufb01cate authorities (CAs)\u2014trusted organizations\u2014validate and cryptographically attest to the identities of web servers. A client\u2019s con\ufb01dence that it is connecting to the right server depends entirely on the set of CAs that it trusts. However, as we demonstrate in this work, the identity speci\ufb01ed in CA certi\ufb01cates is frequently inaccurate due to lax naming requirements, ownership changes, and long-lived certi\ufb01cates. This not only mud-dles client selection of trusted CAs, but also prevents PKI operators and researchers from correctly attributing CA certi\ufb01cate issues to CA organizations. To help Web PKI participants understand the organizations that control each CA certi\ufb01cate, we develop Fides, a system that models and clusters CA operational behavior in order to detect CA certi\ufb01cates under shared operational control. We label the clusters that Fides uncovers, and build a new database of CA ownership that corrects the CA operator for 241 CA certi\ufb01cates, and expands coverage to 651 new CA certi\ufb01cates, leading to a more complete picture of CA certi\ufb01cate control.",
            "keywords": [
                "Public Key Infrastructure",
                "Certificate Authorities",
                "Certificate Control",
                "Operational Behavior",
                "CA Ownership"
            ]
        },
        "url": "URL#1888144",
        "sema_paperId": "b29a86e71565a39da9da0fe658177d224bb3e952"
    },
    {
        "@score": "1",
        "@id": "1888145",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "145/1710",
                        "text": "Max Maass"
                    },
                    {
                        "@pid": "264/7948",
                        "text": "Alina St\u00f6ver"
                    },
                    {
                        "@pid": "207/3391",
                        "text": "Henning Prid\u00f6hl"
                    },
                    {
                        "@pid": "138/4860",
                        "text": "Sebastian Bretthauer"
                    },
                    {
                        "@pid": "37/5937",
                        "text": "Dominik Herrmann"
                    },
                    {
                        "@pid": "95/1816",
                        "text": "Matthias Hollick"
                    },
                    {
                        "@pid": "131/4959",
                        "text": "Indra Spiecker"
                    }
                ]
            },
            "title": "Effective Notification Campaigns on the Web: A Matter of Trust, Framing, and Support.",
            "venue": "USENIX Security Symposium",
            "pages": "2489-2506",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MaassSPBHHS21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/maass",
            "url": "https://dblp.org/rec/conf/uss/MaassSPBHHS21",
            "abstract": "Misconfigurations and outdated software are a major cause of compromised websites and data leaks. Past research has proposed and evaluated sending automated security notifications to the operators of misconfigured websites, but encountered issues with reachability, mistrust, and a perceived lack of importance. In this paper, we seek to understand the determinants of effective notifications. We identify a data protection misconfiguration that affects 12.7 % of the 1.3 million websites we scanned and opens them up to legal liability. Using a subset of 4754 websites, we conduct a multivariate randomized controlled notification experiment, evaluating contact medium, sender, and framing of the message. We also include a link to a public web-based self-service tool that is run by us in disguise and conduct an anonymous survey of the notified website owners (N=477) to understand their perspective. We find that framing a misconfiguration as a problem of legal compliance can increase remediation rates, especially when the notification is sent as a letter from a legal research group, achieving remediation rates of 76.3 % compared to 33.9 % for emails sent by computer science researchers warning about a privacy issue. Across all groups, 56.6 % of notified owners remediated the issue, compared to 9.2 % in the control group. In conclusion, we present factors that lead website owners to trust a notification, show what framing of the notification brings them into action, and how they can be supported in remediating the issue.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-maass.pdf",
            "keywords": [
                "Web Security Notifications",
                "Data Protection Misconfiguration",
                "Legal Compliance",
                "Remediation Rates",
                "Trust in Notifications"
            ]
        },
        "url": "URL#1888145"
    },
    {
        "@score": "1",
        "@id": "1888146",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "276/6652",
                        "text": "Kotaro Matsuoka"
                    },
                    {
                        "@pid": "237/9504",
                        "text": "Ryotaro Banno"
                    },
                    {
                        "@pid": "51/4199",
                        "text": "Naoki Matsumoto"
                    },
                    {
                        "@pid": "48/4595-1",
                        "text": "Takashi Sato 0001"
                    },
                    {
                        "@pid": "179/7914",
                        "text": "Song Bian 0001"
                    }
                ]
            },
            "title": "Virtual Secure Platform: A Five-Stage Pipeline Processor over TFHE.",
            "venue": "USENIX Security Symposium",
            "pages": "4007-4024",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MatsuokaBMS021",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/matsuoka",
            "url": "https://dblp.org/rec/conf/uss/MatsuokaBMS021",
            "abstract": "We present Virtual Secure Platform (VSP), the first comprehensive platform that implements a multi-opcode general-purpose sequential processor over Fully Homomorphic Encryption (FHE) for Secure Multi-Party Computation (SMPC). VSP protects both the data and functions on which the data are evaluated from the adversary in a secure computation offloading situation like cloud computing. We proposed a complete processor architecture with a five-stage pipeline, which improves the performance of the VSP by providing more parallelism in circuit evaluation. In addition, we also designed a custom Instruction Set Architecture (ISA) to reduce the gate count of our processor, along with an entire set of toolchains to ensure that arbitrary C programs can be compiled into our custom ISA. In order to speed up instruction evaluation over VSP, CMUX Memory based ROM and RAM constructions over FHE are also proposed. Our experiments show both the pipelined architecture and the CMUX Memory are effective in improving the performance of the proposed processor. We provide an fully open-source implementation of VSP which attains a per-instruction latency of less than 1 second. We show that compared to the best existing processor over FHE, our implementation runs nearly 1,600\u00d7 faster.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-matsuoka.pdf",
            "keywords": [
                "Fully Homomorphic Encryption",
                "Secure Multi-Party Computation",
                "Pipeline Processor",
                "Custom Instruction Set Architecture",
                "Performance Optimization"
            ]
        },
        "url": "URL#1888146"
    },
    {
        "@score": "1",
        "@id": "1888147",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "36/111-1",
                        "text": "Peter Mayer 0001"
                    },
                    {
                        "@pid": "218/0356",
                        "text": "Yixin Zou"
                    },
                    {
                        "@pid": "08/7562",
                        "text": "Florian Schaub"
                    },
                    {
                        "@pid": "94/1554",
                        "text": "Adam J. Aviv"
                    }
                ]
            },
            "title": "&quot;Now I&apos;m a bit angry: &quot; Individuals&apos; Awareness, Perception, and Responses to Data Breaches that Affected Them.",
            "venue": "USENIX Security Symposium",
            "pages": "393-410",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MayerZSA21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/mayer",
            "url": "https://dblp.org/rec/conf/uss/MayerZSA21",
            "abstract": "Despite the prevalence of data breaches, there is a limited understanding of individuals\u2019 awareness, perception, and responses to breaches that affect them. We provide novel insights into this topic through an online study ( n =413) in which we presented participants with up to three data breaches that had exposed their email addresses and other personal information. Overall, 73% of participants were affected by at least one breach, 5.36 breaches on average. Many participants attributed the cause of being affected by a breach to their poor email and security practices; only 14% correctly attributed the cause to external factors such as breached organizations and hackers. Participants were unaware of 74% of displayed breaches and expressed various emotions when learning about them. While some reported intending to take action, most participants believed the breach would not impact them. Our fndings underline the need for user-friendly tools to improve consumers\u2019 resilience against breaches and accountability for breached organizations to provide more proactive post-breach communications and mitigations.",
            "keywords": [
                "Data Breaches",
                "User Awareness",
                "Personal Information Security",
                "Breach Response",
                "Post-Breach Communication"
            ]
        },
        "url": "URL#1888147",
        "sema_paperId": "05b7b1b3e155dc63e7769fd868cfc1e3487fae58"
    },
    {
        "@score": "1",
        "@id": "1888148",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "205/2107",
                        "text": "Allison McDonald"
                    },
                    {
                        "@pid": "224/9156",
                        "text": "Catherine Barwulor"
                    },
                    {
                        "@pid": "20/7983",
                        "text": "Michelle L. Mazurek"
                    },
                    {
                        "@pid": "08/7562",
                        "text": "Florian Schaub"
                    },
                    {
                        "@pid": "141/9244",
                        "text": "Elissa M. Redmiles"
                    }
                ]
            },
            "title": "&quot;It&apos;s stressful having all these phones&quot;: Investigating Sex Workers&apos; Safety Goals, Risks, and Practices Online.",
            "venue": "USENIX Security Symposium",
            "pages": "375-392",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/McDonaldBMSR21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/mcdonald",
            "url": "https://dblp.org/rec/conf/uss/McDonaldBMSR21",
            "abstract": "We investigate how a population of end-users with especially salient security and privacy risks \u2014 sex workers \u2014 conceptualizes and manages their digital safety. The commercial sex industry is increasingly Internet-mediated. As such, sex workers are facing new challenges in protecting their digital privacy and security and avoiding serious consequences such as stalking, blackmail, and social exclusion. Through interviews ( n =29) and a survey ( n =65) with sex workers in European countries where sex work is legal and regulated, we \ufb01nd that sex workers have well-de\ufb01ned safety goals and clear awareness of the risks to their safety: clients, de\ufb01cient legal protections, and hostile digital platforms. In response to these risks, our participants developed complex strategies for protecting their safety, but use few tools speci\ufb01cally designed for security and privacy. Our results suggest that if even high-risk users with clear risk conceptions view existing tools as insuf\ufb01ciently effective to merit the cost of use, these tools are not actually addressing their real security needs. Our \ufb01ndings underscore the importance of more holistic design of security tools to address both online and of\ufb02ine axes of safety.",
            "keywords": [
                "Digital Safety",
                "Sex Workers",
                "Privacy Risks",
                "Safety Strategies",
                "Online Security Tools"
            ]
        },
        "url": "URL#1888148",
        "sema_paperId": "d804394dff63e5d9f35f069807cf29dcc25e4848"
    },
    {
        "@score": "1",
        "@id": "1888149",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "168/2334",
                        "text": "Carlo Meijer"
                    },
                    {
                        "@pid": "20/11342",
                        "text": "Veelasha Moonsamy"
                    },
                    {
                        "@pid": "146/0907",
                        "text": "Jos Wetzels"
                    }
                ]
            },
            "title": "Where&apos;s Crypto?: Automated Identification and Classification of Proprietary Cryptographic Primitives in Binary Code.",
            "venue": "USENIX Security Symposium",
            "pages": "555-572",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MeijerMW21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/meijer",
            "url": "https://dblp.org/rec/conf/uss/MeijerMW21",
            "abstract": "The continuing use of proprietary cryptography in embedded systems across many industry verticals, from physical access control systems and telecommunications to machine-to-machine authentication, presents a significant obstacle to black-box security-evaluation efforts. In-depth security analysis requires locating and classifying the algorithm in often very large binary images, thus rendering manual inspection, even when aided by heuristics, time consuming. \nIn this paper, we present a novel approach to automate the identification and classification of (proprietary) cryptographic primitives within binary code. Our approach is based on Data Flow Graph (DFG) isomorphism, previously proposed by Lestringant et al. Unfortunately, their DFG isomorphism approach is limited to known primitives only, and relies on heuristics for selecting code fragments for analysis. By combining the said approach with symbolic execution, we overcome all limitations of their work, and are able to extend the analysis into the domain of unknown, proprietary cryptographic primitives. To demonstrate that our proposal is practical, we develop various signatures, each targeted at a distinct class of cryptographic primitives, and present experimental evaluations for each of them on a set of binaries, both publicly available (and thus providing reproducible results), and proprietary ones. Lastly, we provide a free and open-source implementation of our approach, called Where's Crypto?, in the form of a plug-in for the popular IDA disassembler.",
            "keywords": [
                "Proprietary Cryptography",
                "Binary Code Analysis",
                "Data Flow Graph Isomorphism",
                "Symbolic Execution",
                "Cryptographic Primitive Identification"
            ]
        },
        "url": "URL#1888149",
        "sema_paperId": "5a68952a3dcb008f67c6df013fe919d40a503bea"
    },
    {
        "@score": "1",
        "@id": "1888150",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "248/1716",
                        "text": "Robert Merget"
                    },
                    {
                        "@pid": "76/6564",
                        "text": "Marcus Brinkmann"
                    },
                    {
                        "@pid": "18/1188",
                        "text": "Nimrod Aviram"
                    },
                    {
                        "@pid": "27/8331",
                        "text": "Juraj Somorovsky"
                    },
                    {
                        "@pid": "75/9215",
                        "text": "Johannes Mittmann"
                    },
                    {
                        "@pid": "58/5730",
                        "text": "J\u00f6rg Schwenk"
                    }
                ]
            },
            "title": "Raccoon Attack: Finding and Exploiting Most-Significant-Bit-Oracles in TLS-DH(E).",
            "venue": "USENIX Security Symposium",
            "pages": "213-230",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MergetBASMS21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/merget",
            "url": "https://dblp.org/rec/conf/uss/MergetBASMS21",
            "abstract": "Diffie-Hellman key exchange (DHKE) is a widely adopted method for exchanging cryptographic key material in real-world protocols like TLS-DH(E). Past attacks on TLS-DH(E) focused on weak parameter choices or missing parameter validation. The confidentiality of the computed DH share, the premaster secret, was never questioned; DHKE is used as a generic method to avoid the security pitfalls of TLS-RSA.\nWe show that due to a subtle issue in the key derivation of all TLS-DH(E) cipher suites in versions up to TLS 1.2, the premaster secret of a TLS-DH(E) session may, under certain circumstances, be leaked to an adversary. Our main result is a novel side-channel attack, named Raccoon attack, which exploits a timing vulnerability in TLS-DH(E), leaking the most significant bits of the shared Diffie-Hellman secret. The root cause for this side channel is that the TLS standard encourages non-constant-time processing of the DH secret. If the server reuses ephemeral keys, this side channel may allow an attacker to recover the premaster secret by solving an instance of the Hidden Number Problem. The Raccoon attack takes advantage of uncommon DH modulus sizes, which depend on the properties of the used hash functions. We describe a fully feasible remote attack against an otherwise-secure TLS configuration: OpenSSL with a 1032-bit DH modulus. Fortunately, such moduli are not commonly used on the Internet.\nFurthermore, with our large-scale scans we have identified implementation-level issues in production-grade TLS implementations that allow for executing the same attack by directly observing the contents of server responses, without resorting to timing measurements.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-merget.pdf",
            "keywords": [
                "TLS-DH(E)",
                "Diffie-Hellman Key Exchange",
                "Raccoon Attack",
                "Side-Channel Attack",
                "Premaster Secret Leakage"
            ]
        },
        "url": "URL#1888150"
    },
    {
        "@score": "1",
        "@id": "1888152",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "168/9447",
                        "text": "Soo-Jin Moon"
                    },
                    {
                        "@pid": "224/2470",
                        "text": "Yucheng Yin"
                    },
                    {
                        "@pid": "172/1323",
                        "text": "Rahul Anand Sharma"
                    },
                    {
                        "@pid": "05/4612",
                        "text": "Yifei Yuan"
                    },
                    {
                        "@pid": "170/1882",
                        "text": "Jonathan M. Spring"
                    },
                    {
                        "@pid": "45/4044",
                        "text": "Vyas Sekar"
                    }
                ]
            },
            "title": "Accurately Measuring Global Risk of Amplification Attacks using AmpMap.",
            "venue": "USENIX Security Symposium",
            "pages": "3881-3898",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MoonYSYSS21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/moon",
            "url": "https://dblp.org/rec/conf/uss/MoonYSYSS21",
            "abstract": "Many recent DDoS attacks rely on amplification, where an attacker induces public servers to generate a large volume of network traffic to a victim. In this paper, we argue for a low-footprint Internet health monitoring service that can systematically and continuously quantify this risk to inform mitigation efforts. Unfortunately, the problem is challenging because amplification is a complex function of query (header) values and server instances. As such, existing techniques that enumerate the total number of servers or focus on a specific amplification-inducing query are fundamentally imprecise. In designing AmpMap, we leverage key structural insights to develop an efficient approach that searches across the space of protocol headers and servers. Using AmpMap, we scanned thousands of servers for 6 UDP-based protocols. We find that relying on prior recommendations to block or rate-limit specific queries still leaves open substantial residual risk as they miss many other amplification-inducing query patterns. We also observe significant variability across servers and protocols, and thus prior approaches that rely on server census can substantially misestimate amplification risk.",
            "keywords": [
                "DDoS Attacks",
                "Amplification Attacks",
                "Internet Health Monitoring",
                "AmpMap",
                "UDP-based Protocols"
            ]
        },
        "url": "URL#1888152",
        "sema_paperId": "23b6895cad5f2a619597a08b853a854e8cd61e08"
    },
    {
        "@score": "1",
        "@id": "1888153",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "224/4374",
                        "text": "Marius Musch"
                    },
                    {
                        "@pid": "82/359",
                        "text": "Martin Johns"
                    }
                ]
            },
            "title": "U Can&apos;t Debug This: Detecting JavaScript Anti-Debugging Techniques in the Wild.",
            "venue": "USENIX Security Symposium",
            "pages": "2935-2950",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MuschJ21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/musch",
            "url": "https://dblp.org/rec/conf/uss/MuschJ21",
            "abstract": "Through security contests such as Pwn2Own, we are constantly reminded that no complex piece of software should ever be considered secure. As we execute untrusted code in our browser every day, browser exploits written in JavaScript remain a constant threat to the security of our systems. In particular, evasive malware that detects analysis systems and then changes its behavior is a well-known problem. However, there are also anti-debugging techniques that interfere with the manual analysis of a website in a real browser. These techniques try to prevent, or at least slow down, any attempts at manually inspecting and debugging the JavaScript code of a website. For example, such a technique could constantly trigger breakpoints at random locations to effectively hinder single-stepping while debugging the code. More cunningly, it could also find out whether the browser\u2019s integrated Developer Tools are open by using certain sidechannels available in JavaScript. With this knowledge, it is possible to subtly alter or suppress any malicious behavior while under analysis. In this paper, we systematically explore this phenomenon. To this end, we introduce 9 anti-debugging techniques and discuss their advantages and drawbacks. We then conduct a large-scale study on 6 of them, to investigate the prevalence of these techniques in the wild. We find that as many as 1 out of 550 websites contain severe anti-debugging measures, with multiple of these techniques active on the same site. Moreover, we present a novel approach based on a deterministic website replay and a comparison of JavaScript code coverage. The approach can automatically detect the remaining 3 timingbased anti-debugging techniques, which use side-channels to learn if the DevTools are open. In a targeted study on 2000 websites with anti-debugging techniques, we discover over 200 of them indeed execute different code when under analysis.",
            "keywords": [
                "JavaScript Security",
                "Anti-Debugging Techniques",
                "Malware Evasion",
                "Browser Exploits",
                "Code Analysis"
            ]
        },
        "url": "URL#1888153",
        "sema_paperId": "4137a5d49d416dc0028ed2e539cf90f02fc776c2"
    },
    {
        "@score": "1",
        "@id": "1888154",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "168/9038",
                        "text": "Stefan Nagy"
                    },
                    {
                        "@pid": "06/6439",
                        "text": "Anh Nguyen-Tuong"
                    },
                    {
                        "@pid": "88/5011",
                        "text": "Jason D. Hiser"
                    },
                    {
                        "@pid": "d/JWDavidson",
                        "text": "Jack W. Davidson"
                    },
                    {
                        "@pid": "09/2334",
                        "text": "Matthew Hicks"
                    }
                ]
            },
            "title": "Breaking Through Binaries: Compiler-quality Instrumentation for Better Binary-only Fuzzing.",
            "venue": "USENIX Security Symposium",
            "pages": "1683-1700",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/NagyNHDH21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/nagy",
            "url": "https://dblp.org/rec/conf/uss/NagyNHDH21",
            "abstract": "Coverage-guided fuzzing is one of the most effective software security testing techniques. Fuzzing takes on one of two forms: compiler-based or binary-only, depending on the availability of source code. While the fuzzing community has improved compiler-based fuzzing with performanceand feedback-enhancing program transformations, binaryonly fuzzing lags behind due to the semantic and performance limitations of instrumenting code at the binary level. Many fuzzing use cases are binary-only (i.e., closed source). Thus, applying fuzzing-enhancing program transformations to binary-only fuzzing\u2014without sacrificing performance\u2014 remains a compelling challenge. This paper examines the properties required to achieve compiler-quality binary-only fuzzing instrumentation. Based on our findings, we design FIBRE: a platform for applying fuzzing-enhancing program transformation to binary-only targets\u2014maintaining compiler-level performance. We showcase FIBRE\u2019s capabilities in an implementation for the popular fuzzer AFL, including five compiler-style fuzzing-enhancing transformations, and evaluate it against the leading binaryonly fuzzing instrumenters AFL-QEMU and AFL-Dyninst. Across LAVA-M and real-world targets, FIBRE improves crash-finding by 26\u201396% and 37\u2013131%; and throughput by 48\u201378% and 159\u2013203% compared to AFL-Dyninst and AFLQEMU, respectively\u2014while maintaining compiler-level of overhead of 27%. We also show that FIBRE supports realworld openand closed-source software of varying size (10K\u2013 100MB), complexity (100\u20131M basic blocks), platform (Linux and Windows), and format (e.g., stripped and PIC).",
            "keywords": [
                "Binary-only Fuzzing",
                "Coverage-guided Fuzzing",
                "Fuzzing Instrumentation",
                "Compiler-quality Transformations",
                "FIBRE Platform"
            ]
        },
        "url": "URL#1888154",
        "sema_paperId": "ac67d5cb691ab748a4e826e577ac11dbd197177b"
    },
    {
        "@score": "1",
        "@id": "1888155",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "205/8037",
                        "text": "Yoshimichi Nakatsuka"
                    },
                    {
                        "@pid": "205/2579",
                        "text": "Ercan Ozturk"
                    },
                    {
                        "@pid": "30/9784",
                        "text": "Andrew Paverd"
                    },
                    {
                        "@pid": "08/1183",
                        "text": "Gene Tsudik"
                    }
                ]
            },
            "title": "CACTI: Captcha Avoidance via Client-side TEE Integration.",
            "venue": "USENIX Security Symposium",
            "pages": "2561-2578",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/NakatsukaOPT21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/nakatsuka",
            "url": "https://dblp.org/rec/conf/uss/NakatsukaOPT21",
            "abstract": "Preventing abuse of web services by bots is an increasingly important problem, as abusive activities grow in both volume and variety. CAPTCHAs are the most common way for thwarting bot activities. However, they are often ineffective against bots and frustrating for humans. In addition, some recent CAPTCHA techniques diminish user privacy. Meanwhile, client-side Trusted Execution Environments (TEEs) are becoming increasingly widespread (notably, ARM TrustZone and Intel SGX), allowing establishment of trust in a small part (trust anchor or TCB) of client-side hardware. This prompts the question: can a TEE help reduce (or remove entirely) user burden of solving CAPTCHAs?In this paper, we design CACTI: CAPTCHA Avoidance via Client-side TEE Integration. Using client-side TEEs, CACTI allows legitimate clients to generate unforgeable rate-proofs demonstrating how frequently they have performed specific actions. These rate-proofs can be sent to web servers in lieu of solving CAPTCHAs. CACTI provides strong client privacy guarantees, since the information is only sent to the visited website and authenticated using a group signature scheme. Our evaluations show that overall latency of generating and verifying a CACTI rate-proof is less than 0.25 sec, while CACTI's bandwidth overhead is over 98% lower than that of current CAPTCHA systems.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-nakatsuka.pdf",
            "keywords": [
                "Client-side TEE",
                "CAPTCHA Avoidance",
                "Rate-Proofs",
                "User Privacy",
                "Bot Prevention"
            ]
        },
        "url": "URL#1888155"
    },
    {
        "@score": "1",
        "@id": "1888156",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "201/9230",
                        "text": "Shravan Narayan"
                    },
                    {
                        "@pid": "199/4885",
                        "text": "Craig Disselkoen"
                    },
                    {
                        "@pid": "241/6242",
                        "text": "Daniel Moghimi"
                    },
                    {
                        "@pid": "208/7309",
                        "text": "Sunjay Cauligi"
                    },
                    {
                        "@pid": "246/5332-1",
                        "text": "Evan Johnson 0001"
                    },
                    {
                        "@pid": "25/2650",
                        "text": "Zhao Gang"
                    },
                    {
                        "@pid": "161/0161",
                        "text": "Anjo Vahldiek-Oberwagner"
                    },
                    {
                        "@pid": "70/4571",
                        "text": "Ravi Sahita"
                    },
                    {
                        "@pid": "35/1061",
                        "text": "Hovav Shacham"
                    },
                    {
                        "@pid": "t/DeanMTullsen",
                        "text": "Dean M. Tullsen"
                    },
                    {
                        "@pid": "91/6118",
                        "text": "Deian Stefan"
                    }
                ]
            },
            "title": "Swivel: Hardening WebAssembly against Spectre.",
            "venue": "USENIX Security Symposium",
            "pages": "1433-1450",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/NarayanDMCJGVSS21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/narayan",
            "url": "https://dblp.org/rec/conf/uss/NarayanDMCJGVSS21",
            "abstract": "We describe Swivel, a new compiler framework for hardening WebAssembly (Wasm) against Spectre attacks. Outside the browser, Wasm has become a popular lightweight, in-process sandbox and is, for example, used in production to isolate different clients on edge clouds and function-as-a-service platforms. Unfortunately, Spectre attacks can bypass Wasm's isolation guarantees. Swivel hardens Wasm against this class of attacks by ensuring that potentially malicious code can neither use Spectre attacks to break out of the Wasm sandbox nor coerce victim code\u2014another Wasm client or the embedding process\u2014to leak secret data.We describe two Swivel designs, a software-only approach that can be used on existing CPUs, and a hardware-assisted approach that uses extension available in Intel\u00ae 11th generation CPUs. For both, we evaluate a randomized approach that mitigates Spectre and a deterministic approach that eliminates Spectre altogether. Our randomized implementations impose under 10.3% overhead on the Wasm-compatible subset of SPEC 2006, while our deterministic implementations impose overheads between 3.3% and 240.2%. Though high on some benchmarks, Swivel's overhead is still between 9\u00d7 and 36.3\u00d7 smaller than existing defenses that rely on pipeline fences.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-narayan.pdf",
            "keywords": [
                "WebAssembly Security",
                "Spectre Attacks",
                "Sandbox Isolation",
                "Compiler Framework",
                "Mitigation Techniques"
            ]
        },
        "url": "URL#1888156"
    },
    {
        "@score": "1",
        "@id": "1888157",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "187/8997",
                        "text": "Milad Nasr"
                    },
                    {
                        "@pid": "225/5499",
                        "text": "Alireza Bahramali"
                    },
                    {
                        "@pid": "22/1797",
                        "text": "Amir Houmansadr"
                    }
                ]
            },
            "title": "Defeating DNN-Based Traffic Analysis Systems in Real-Time With Blind Adversarial Perturbations.",
            "venue": "USENIX Security Symposium",
            "pages": "2705-2722",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/NasrBH21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/nasr",
            "url": "https://dblp.org/rec/conf/uss/NasrBH21",
            "abstract": "Deep neural networks (DNNs) are commonly used for various traf\ufb01c analysis problems, such as website \ufb01ngerprinting and \ufb02ow correlation, as they outperform traditional (e.g., statistical) techniques by large margins. However, deep neural networks are known to be vulnerable to adversarial examples: adversarial inputs to the model that get labeled incorrectly by the model due to small adversarial perturbations. In this paper, for the \ufb01rst time, we show that an adversary can defeat DNN-based traf\ufb01c analysis techniques by applying adversarial perturbations on the patterns of live network traf\ufb01c. Applying adversarial perturbations (examples) on traf\ufb01c analysis classi\ufb01ers faces two major challenges. First, the per-turbing party (i.e., the adversary) should be able to apply the adversarial network perturbations on live traf\ufb01c, with no need to buffering traf\ufb01c or having some prior knowledge about up-coming network packets. We design a systematic approach to create adversarial perturbations that are independent of their target network connections, and therefore can be applied in real-time on live traf\ufb01c. We therefore call such adversarial perturbations blind . Second, unlike image",
            "keywords": [
                "Traffic Analysis",
                "Adversarial Perturbations",
                "Deep Neural Networks",
                "Real-Time Application",
                "Blind Adversarial Techniques"
            ]
        },
        "url": "URL#1888157",
        "sema_paperId": "b4e5e2e3e145cf8d9df9ac0711ff46f5ec79b529"
    },
    {
        "@score": "1",
        "@id": "1888158",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "269/4540",
                        "text": "Lucien K. L. Ng"
                    },
                    {
                        "@pid": "c/ShermanSMChow",
                        "text": "Sherman S. M. Chow"
                    }
                ]
            },
            "title": "GForce: GPU-Friendly Oblivious and Rapid Neural Network Inference.",
            "venue": "USENIX Security Symposium",
            "pages": "2147-2164",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/NgC21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/ng",
            "url": "https://dblp.org/rec/conf/uss/NgC21",
            "abstract": "Neural-network classification is getting more pervasive. It captures data of the subjects to be classified, e.g., appearance for facial recognition, which is personal and often sensitive. Oblivious inference protects the data privacy of both the query and the model. However, it is not as fast and as accurate as its plaintext counterpart. A recent cryptographic solution Delphi (Usenix Security 2020) strives for low latency by using GPU on linear layers and replacing some non-linear units in the model at a price of accuracy. It can handle a query on CIFAR100 with \u223c68% accuracy in 14s or \u223c66% accuracy in 2.6s. We propose GForce, tackling the latency issue from the root causes instead of approximating non-linear computations. With the SWALP training approach (ICML 2019), we propose stochastic rounding and truncation (SRT) layers, which fuse quantization with dequantization between non-linear and linear layers and free us from floating-point operations for efficiency. They also ensure high accuracy while working over the severely-finite cryptographic field. We further propose a suite of GPU-friendly secure online/offline protocols for common operations, including comparison and wrap-around handling, which benefit non-linear layers, including our SRT. With our two innovations, GForce supports VGG-16, attaining \u223c73% accuracy over CIFAR-100 for the first time, in 0.4s. Compared with the prior best non-approximated solution (Usenix Security 2018), GForce speeds up non-linear layers in VGG by >34\u00d7. Our techniques shed light on a new direction that utilizes GPU throughout the model to minimize latency.",
            "keywords": [
                "Oblivious Inference",
                "GPU Acceleration",
                "Neural Network Privacy",
                "Latency Reduction",
                "Stochastic Rounding and Truncation (SRT)"
            ]
        },
        "url": "URL#1888158",
        "sema_paperId": "b91e076a75f58b398487b1ce1d2f4fc7e9fa6660"
    },
    {
        "@score": "1",
        "@id": "1888159",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "294/4401",
                        "text": "Trung Tin Nguyen"
                    },
                    {
                        "@pid": "b/MichaelBackes1",
                        "text": "Michael Backes 0001"
                    },
                    {
                        "@pid": "47/11331",
                        "text": "Ninja Marnau"
                    },
                    {
                        "@pid": "136/8343",
                        "text": "Ben Stock"
                    }
                ]
            },
            "title": "Share First, Ask Later (or Never?) Studying Violations of GDPR&apos;s Explicit Consent in Android Apps.",
            "venue": "USENIX Security Symposium",
            "pages": "3667-3684",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Nguyen0MS21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/nguyen",
            "url": "https://dblp.org/rec/conf/uss/Nguyen0MS21",
            "abstract": "Since the General Data Protection Regulation (GDPR) went into effect in May 2018, online services are required to obtain users\u2019 explicit consent before sharing users\u2019 personal data with third parties that use the data for their own purposes. While violations of this legal basis on the Web have been studied in-depth, the community lacks insight into such violations in the mobile ecosystem. We perform the \ufb01rst large-scale measurement on Android apps in the wild to understand the current state of the violation of GDPR\u2019s explicit consent. Speci\ufb01cally, we build a semi-automated pipeline to detect data sent out to the Internet without prior consent and apply it to a set of 86,163 Android apps. Based on the domains that receive data protected under the GDPR without prior consent, we collaborate with a legal scholar to assess if these contacted domains are third-party data controllers. Doing so, we \ufb01nd 24,838 apps send personal data towards data controllers without the user\u2019s explicit prior consent. To understand the reasons behind this, we run a noti-\ufb01cation campaign to inform affected developers and gather insights from their responses. We then conduct an in-depth analysis of violating apps as well as the corresponding third parties\u2019 documentation and privacy policies. Based on the responses and our analysis of available documentation, we derive concrete recommendations for all involved entities in the ecosystem to allow data subjects to exercise their fundamental rights and freedoms.",
            "keywords": [
                "GDPR Compliance",
                "Mobile Data Privacy",
                "Explicit Consent",
                "Android Apps",
                "Data Sharing Violations"
            ]
        },
        "url": "URL#1888159",
        "sema_paperId": "ecbb1ab32495cdfd2a57e1532aa0422a2555f99d"
    },
    {
        "@score": "1",
        "@id": "1888162",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "133/2390",
                        "text": "Marten Oltrogge"
                    },
                    {
                        "@pid": "213/7298",
                        "text": "Nicolas Huaman"
                    },
                    {
                        "@pid": "251/3013",
                        "text": "Sabrina Amft"
                    },
                    {
                        "@pid": "132/9687",
                        "text": "Yasemin Acar"
                    },
                    {
                        "@pid": "b/MichaelBackes1",
                        "text": "Michael Backes 0001"
                    },
                    {
                        "@pid": "38/9378",
                        "text": "Sascha Fahl"
                    }
                ]
            },
            "title": "Why Eve and Mallory Still Love Android: Revisiting TLS (In)Security in Android Applications.",
            "venue": "USENIX Security Symposium",
            "pages": "4347-4364",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/OltroggeHAA0F21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/oltrogge",
            "url": "https://dblp.org/rec/conf/uss/OltroggeHAA0F21",
            "abstract": "Android applications have a long history of being vulnerable to man-in-the-middle attacks due to insecure custom TLS certi\ufb01cate validation implementations. To resolve this, Google deployed the Network Security Con\ufb01guration (NSC), a con\ufb01guration-based approach to increase custom certi\ufb01-cate validation logic security, and implemented safeguards in Google Play to block insecure applications. In this paper, we perform a large-scale in-depth investigation of the effectiveness of these countermeasures: First, we investigate the security of 99,212 NSC settings \ufb01les in 1,335,322 Google Play apps using static code and manual analysis techniques. We \ufb01nd that 88.87% of the apps using custom NSC settings downgrade security compared to the default settings, and only 0.67% implement certi\ufb01cate pinning. Second, we penetrate Google Play\u2019s protection mechanisms by trying to publish apps that are vulnerable to man-in-the-middle attacks. In contrast to of\ufb01cial announcements by Google, we found that Play does not effectively block vulnerable apps. Finally, we performed a static code analysis study of 15,000 apps and \ufb01nd that 5,511 recently published apps still contain vulnerable certi\ufb01cate validation code. Overall, we attribute most of the problems we \ufb01nd to insuf-\ufb01cient support for developers, missing clari\ufb01cation of security risks in of\ufb01cial documentation, and inadequate security checks for vulnerable applications in Google Play.",
            "keywords": [
                "Android Application Security",
                "TLS Certificate Validation",
                "Man-in-the-Middle Attacks",
                "Network Security Configuration",
                "Vulnerable Applications"
            ]
        },
        "url": "URL#1888162",
        "sema_paperId": "2f7459cd30a0d086a602367600e0727270a5905b"
    },
    {
        "@score": "1",
        "@id": "1888163",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "178/1987",
                        "text": "Jeremiah Onaolapo"
                    },
                    {
                        "@pid": "54/854",
                        "text": "Nektarios Leontiadis"
                    },
                    {
                        "@pid": "52/8336",
                        "text": "Despoina Magka"
                    },
                    {
                        "@pid": "86/8823",
                        "text": "Gianluca Stringhini"
                    }
                ]
            },
            "title": "SocialHEISTing: Understanding Stolen Facebook Accounts.",
            "venue": "USENIX Security Symposium",
            "pages": "4115-4132",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/OnaolapoLMS21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/onaolapo",
            "url": "https://dblp.org/rec/conf/uss/OnaolapoLMS21",
            "abstract": "Online social network (OSN) accounts are often more user-centric than other types of online accounts (e.g., email accounts) because they present a number of demographic attributes such as age, gender, location, and occupation. While these attributes allow for more meaningful online interactions, they can also be used by malicious parties to craft various types of abuse. To understand the effects of demographic attributes on attacker behavior in stolen social accounts, we devised a method to instrument and monitor such accounts. We then created, instrumented, and deployed more than 1000 Facebook accounts, and exposed them to criminals. Our re-sults con\ufb01rm that victim demographic traits indeed in\ufb02uence the way cybercriminals abuse their accounts. For example, we \ufb01nd that cybercriminals that access teen accounts write messages and posts more than the ones accessing adult accounts, and attackers that compromise male accounts perform disruptive activities such as changing some of their pro\ufb01le information more than the ones that access female accounts. This knowledge could potentially help online services develop new models to characterize benign and malicious activity across various demographic attributes, and thus automatically classify future activity.",
            "keywords": [
                "Social Network Security",
                "Account Compromise",
                "Demographic Attributes",
                "Cybercriminal Behavior",
                "Facebook Account Abuse"
            ]
        },
        "url": "URL#1888163",
        "sema_paperId": "c250f002fa75fc2c81380da234436cafa1a2a844"
    },
    {
        "@score": "1",
        "@id": "1888164",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "147/1534",
                        "text": "Simon Oya"
                    },
                    {
                        "@pid": "26/5304",
                        "text": "Florian Kerschbaum"
                    }
                ]
            },
            "title": "Hiding the Access Pattern is Not Enough: Exploiting Search Pattern Leakage in Searchable Encryption.",
            "venue": "USENIX Security Symposium",
            "pages": "127-142",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/OyaK21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/oya",
            "url": "https://dblp.org/rec/conf/uss/OyaK21",
            "abstract": "Recent Searchable Symmetric Encryption (SSE) schemes enable secure searching over an encrypted database stored in a server while limiting the information leaked to the server. These schemes focus on hiding the access pattern, which refers to the set of documents that match the client's queries. This provides protection against current attacks that largely depend on this leakage to succeed. However, most SSE constructions also leak whether or not two queries aim for the same keyword, also called the search pattern. \nIn this work, we show that search pattern leakage can severely undermine current SSE defenses. We propose an attack that leverages both access and search pattern leakage, as well as some background and query distribution information, to recover the keywords of the queries performed by the client. Our attack follows a maximum likelihood estimation approach, and is easy to adapt against SSE defenses that obfuscate the access pattern. We empirically show that our attack is efficient, it outperforms other proposed attacks, and it completely thwarts two out of the three defenses we evaluate it against, even when these defenses are set to high privacy regimes. These findings highlight that hiding the search pattern, a feature that most constructions are lacking, is key towards providing practical privacy guarantees in SSE.",
            "keywords": [
                "Searchable Symmetric Encryption",
                "Access Pattern Leakage",
                "Search Pattern Leakage",
                "Privacy Guarantees",
                "Keyword Recovery Attack"
            ]
        },
        "url": "URL#1888164",
        "sema_paperId": "20b0f87f8f90af5aca242d3282291cc4c32cfb40"
    },
    {
        "@score": "1",
        "@id": "1888165",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "224/9301",
                        "text": "Riccardo Paccagnella"
                    },
                    {
                        "@pid": "286/6495",
                        "text": "Licheng Luo"
                    },
                    {
                        "@pid": "25/8166",
                        "text": "Christopher W. Fletcher"
                    }
                ]
            },
            "title": "Lord of the Ring(s): Side Channel Attacks on the CPU On-Chip Ring Interconnect Are Practical.",
            "venue": "USENIX Security Symposium",
            "pages": "645-662",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PaccagnellaLF21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/paccagnella",
            "url": "https://dblp.org/rec/conf/uss/PaccagnellaLF21",
            "abstract": "We introduce the first microarchitectural side channel attacks that leverage contention on the CPU ring interconnect. There are two challenges that make it uniquely difficult to exploit this channel. First, little is known about the ring interconnect's functioning and architecture. Second, information that can be learned by an attacker through ring contention is noisy by nature and has coarse spatial granularity. To address the first challenge, we perform a thorough reverse engineering of the sophisticated protocols that handle communication on the ring interconnect. With this knowledge, we build a cross-core covert channel over the ring interconnect with a capacity of over 4 Mbps from a single thread, the largest to date for a cross-core channel not relying on shared memory. To address the second challenge, we leverage the fine-grained temporal patterns of ring contention to infer a victim program's secrets. We demonstrate our attack by extracting key bits from vulnerable EdDSA and RSA implementations, as well as inferring the precise timing of keystrokes typed by a victim user.",
            "keywords": [
                "Microarchitectural Attacks",
                "Side Channel Attacks",
                "CPU Ring Interconnect",
                "Cross-Core Covert Channel",
                "Information Leakage"
            ]
        },
        "url": "URL#1888165",
        "sema_paperId": "b455870ae376073245601d07d76d186021a7f278"
    },
    {
        "@score": "1",
        "@id": "1888166",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "237/9883",
                        "text": "Dario Pasquini"
                    },
                    {
                        "@pid": "151/8251",
                        "text": "Marco Cianfriglia"
                    },
                    {
                        "@pid": "66/3575",
                        "text": "Giuseppe Ateniese"
                    },
                    {
                        "@pid": "81/1604",
                        "text": "Massimo Bernaschi"
                    }
                ]
            },
            "title": "Reducing Bias in Modeling Real-world Password Strength via Deep Learning and Dynamic Dictionaries.",
            "venue": "USENIX Security Symposium",
            "pages": "821-838",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PasquiniCAB21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/pasquini",
            "url": "https://dblp.org/rec/conf/uss/PasquiniCAB21",
            "abstract": "Password security hinges on an in-depth understanding of the techniques adopted by attackers. Unfortunately, real-world adversaries resort to pragmatic guessing strategies such as dictionary attacks that are inherently difficult to model in password security studies. In order to be representative of the actual threat, dictionary attacks must be thoughtfully configured and tuned. However, this process requires a domain-knowledge and expertise that cannot be easily replicated. The consequence of inaccurately calibrating dictionary attacks is the unreliability of password security analyses, impaired by a severe measurement bias.In the present work, we introduce a new generation of dictionary attacks that is consistently more resilient to inadequate configurations. Requiring no supervision or domain-knowledge, this technique automatically approximates the advanced guessing strategies adopted by real-world attackers. To achieve this: (1) We use deep neural networks to model the proficiency of adversaries in building attack configurations. (2) Then, we introduce dynamic guessing strategies within dictionary attacks. These mimic experts' ability to adapt their guessing strategies on the fly by incorporating knowledge on their targets.Our techniques enable more robust and sound password strength estimates within dictionary attacks, eventually reducing overestimation in modeling real-world threats in password security.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-pasquini.pdf",
            "keywords": [
                "Password Security",
                "Dictionary Attacks",
                "Adversarial Guessing Strategies",
                "Measurement Bias",
                "Dynamic Guessing Strategies"
            ]
        },
        "url": "URL#1888166"
    },
    {
        "@score": "1",
        "@id": "1888167",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "64/3169",
                        "text": "Arpita Patra"
                    },
                    {
                        "@pid": "06/3872-3",
                        "text": "Thomas Schneider 0003"
                    },
                    {
                        "@pid": "187/5691",
                        "text": "Ajith Suresh"
                    },
                    {
                        "@pid": "268/5150",
                        "text": "Hossein Yalame"
                    }
                ]
            },
            "title": "ABY2.0: Improved Mixed-Protocol Secure Two-Party Computation.",
            "venue": "USENIX Security Symposium",
            "pages": "2165-2182",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Patra0SY21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/patra",
            "url": "https://dblp.org/rec/conf/uss/Patra0SY21",
            "abstract": "Secure Multi-party Computation (MPC) allows a set of mutually distrusting parties to jointly evaluate a function on their private inputs while maintaining input privacy. In this work, we improve semi-honest secure two-party computation (2PC) over rings, with a focus on the efficiency of the online phase. \nWe propose an efficient mixed-protocol framework, outperforming the state-of-the-art 2PC framework of ABY. Moreover, we extend our techniques to multi-input multiplication gates without inflating the online communication, i.e., it remains independent of the fan-in. Along the way, we construct efficient protocols for several primitives such as scalar product, matrix multiplication, comparison, maxpool, and equality testing. The online communication of our scalar product is two ring elements irrespective of the vector dimension, which is a feature achieved for the first time in the 2PC literature.\nThe practicality of our new set of protocols is showcased with four applications: i) AES S-box, ii) Circuit-based Private Set Intersection, iii) Biometric Matching, and iv) Privacy-preserving Machine Learning (PPML). Most notably, for PPML, we implement and benchmark training and inference of Logistic Regression and Neural Networks over LAN and WAN networks. For training, we improve online runtime (both for LAN and WAN) over SecureML (Mohassel et al., IEEE S&P '17) in the range 1.5x\u20136.1x, while for inference, the improvements are in the range of 2.5x\u2013754.3x.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-patra.pdf",
            "keywords": [
                "Secure Multi-party Computation",
                "Two-Party Computation",
                "Mixed-Protocol Framework",
                "Online Communication Efficiency",
                "Privacy-preserving Applications"
            ]
        },
        "url": "URL#1888167"
    },
    {
        "@score": "1",
        "@id": "1888168",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "166/1105",
                        "text": "Katharina Pfeffer"
                    },
                    {
                        "@pid": "159/0752",
                        "text": "Alexandra Mai"
                    },
                    {
                        "@pid": "138/2614",
                        "text": "Adrian Dabrowski"
                    },
                    {
                        "@pid": "180/3909",
                        "text": "Matthias Gusenbauer"
                    },
                    {
                        "@pid": "170/0259",
                        "text": "Philipp Schindler"
                    },
                    {
                        "@pid": "w/EdgarRWeippl",
                        "text": "Edgar R. Weippl"
                    },
                    {
                        "@pid": "f/MichaelFranz",
                        "text": "Michael Franz"
                    },
                    {
                        "@pid": "128/4803",
                        "text": "Katharina Krombholz"
                    }
                ]
            },
            "title": "On the Usability of Authenticity Checks for Hardware Security Tokens.",
            "venue": "USENIX Security Symposium",
            "pages": "37-54",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PfefferMDGSWFK21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/pfeffer",
            "url": "https://dblp.org/rec/conf/uss/PfefferMDGSWFK21",
            "abstract": "The \ufb01nal responsibility to verify whether a newly purchased hardware security token (HST) is authentic and unmodi\ufb01ed lies with the end user. However, recently reported attacks on such tokens suggest that users cannot take the security guarantees of their HSTs for granted, even despite widely deployed authenticity checks. We present the \ufb01rst comprehensive market review evaluating the effectiveness and usability of authenticity checks for the most commonly used HSTs. Furthermore, we conducted a survey ( n = 194) to examine users\u2019 perceptions and usage of these checks. We found that due to a lack of transparency and information, users often do not carry out\u2014or even are not aware of\u2014essential checks but rely on less meaningful methods. Moreover, our results con\ufb01rm that currently deployed authenticity checks suffer from improperly perceived effectiveness and cannot mitigate all variants of distribution attacks. Furthermore, some authenticity concepts of different manufacturers contradict each other. In order to address these challenges, we suggest (i) a combination of conventional and novel authenticity checks, and (ii) a user-centered, transparent design.",
            "keywords": [
                "Hardware Security Tokens",
                "Authenticity Checks",
                "User Awareness",
                "Security Attacks",
                "Usability Challenges"
            ]
        },
        "url": "URL#1888168",
        "sema_paperId": "d54fbf24652fb07ccc10522d1b4c2abb59bacaa1"
    },
    {
        "@score": "1",
        "@id": "1888169",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "39/10311",
                        "text": "Rishabh Poddar"
                    },
                    {
                        "@pid": "190/1205",
                        "text": "Sukrit Kalra"
                    },
                    {
                        "@pid": "164/3366",
                        "text": "Avishay Yanai"
                    },
                    {
                        "@pid": "277/5307",
                        "text": "Ryan Deng"
                    },
                    {
                        "@pid": "91/275",
                        "text": "Raluca Ada Popa"
                    },
                    {
                        "@pid": "h/JosephMHellerstein",
                        "text": "Joseph M. Hellerstein"
                    }
                ]
            },
            "title": "Senate: A Maliciously-Secure MPC Platform for Collaborative Analytics.",
            "venue": "USENIX Security Symposium",
            "pages": "2129-2146",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PoddarKYDPH21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/poddar",
            "url": "https://dblp.org/rec/conf/uss/PoddarKYDPH21",
            "abstract": "Many organizations stand to benefit from pooling their data together in order to draw mutually beneficial insights\u2014e.g., for fraud detection across banks, better medical studies across hospitals, etc. However, such organizations are often prevented from sharing their data with each other by privacy concerns, regulatory hurdles, or business competition.\nWe present Senate, a system that allows multiple parties to collaboratively run analytical SQL queries without revealing their individual data to each other. Unlike prior works on secure multi-party computation (MPC) that assume that all parties are semi-honest, Senate protects the data even in the presence of malicious adversaries. At the heart of Senate lies a new MPC decomposition protocol that decomposes the cryptographic MPC computation into smaller units, some of which can be executed by subsets of parties and in parallel, while preserving its security guarantees. Senate then provides a new query planning algorithm that decomposes and plans the cryptographic computation effectively, achieving a performance of up to 145 \u00d7 faster than the state-of-the-art.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-poddar.pdf",
            "keywords": [
                "Secure Multi-Party Computation",
                "Collaborative Analytics",
                "Malicious Adversaries",
                "Data Privacy",
                "SQL Query Processing"
            ]
        },
        "url": "URL#1888169"
    },
    {
        "@score": "1",
        "@id": "1888170",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "216/6088",
                        "text": "Damian Poddebniak"
                    },
                    {
                        "@pid": "224/9447",
                        "text": "Fabian Ising"
                    },
                    {
                        "@pid": "161/6292",
                        "text": "Hanno B\u00f6ck"
                    },
                    {
                        "@pid": "43/11495",
                        "text": "Sebastian Schinzel"
                    }
                ]
            },
            "title": "Why TLS is better without STARTTLS: A Security Analysis of STARTTLS in the Email Context.",
            "venue": "USENIX Security Symposium",
            "pages": "4365-4382",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PoddebniakIBS21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/poddebniak",
            "url": "https://dblp.org/rec/conf/uss/PoddebniakIBS21",
            "abstract": "TLS is one of today\u2019s most widely used and best-analyzed encryption technologies. However, for historical reasons, TLS for email protocols is often not used directly but negotiated via STARTTLS . This additional negotiation adds complexity and was prone to security vulnerabilities such as na\u00efve STARTTLS stripping or command injection attacks in the past. We perform the \ufb01rst structured analysis of STARTTLS in SMTP, POP3, and IMAP and introduce EAST, a semi-automatic testing toolkit with more than 100 test cases covering a wide range of variants of STARTTLS stripping, command and response injections, tampering attacks, and UI spoo\ufb01ng attacks for email protocols. Our analysis focuses on the con\ufb01dentiality and integrity of email submission (email client to SMTP server) and email retrieval (email client to POP3 or IMAP server). While some of our \ufb01ndings are also relevant for email transport (from one SMTP server to another), the security implications in email submission and retrieval are more critical because these connections involve not only individual email messages but also user credentials that allow access to a user\u2019s email archive. We used EAST to analyze 28 email clients and 23 servers. In total, we reported over 40 STARTTLS issues, some of which allow mailbox spoo\ufb01ng, credential stealing, and even the hosting of HTTPS with a cross-protocol attack on IMAP. We conducted an Internet-wide scan for the particularly dangerous command injection attack and found that 320.000 email servers (2% of all email servers) are affected. Surpris-ingly, several clients were vulnerable to STARTTLS stripping attacks. In total, only 3 out of 28 clients did not show any STARTTLS-speci\ufb01c security issues. Even though the command injection attack received multiple CVEs in the past, EAST detected eight new instances",
            "keywords": [
                "Email Security",
                "STARTTLS",
                "Email Protocols",
                "Vulnerabilities",
                "Command Injection"
            ]
        },
        "url": "URL#1888170",
        "sema_paperId": "5f375af08fceb4936bea1946d2db6aaaadef52d1"
    },
    {
        "@score": "1",
        "@id": "1888171",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "195/3349",
                        "text": "Ivan Puddu"
                    },
                    {
                        "@pid": "155/4732-1",
                        "text": "Moritz Schneider 0001"
                    },
                    {
                        "@pid": "266/1494",
                        "text": "Miro Haller"
                    },
                    {
                        "@pid": "51/1639",
                        "text": "Srdjan Capkun"
                    }
                ]
            },
            "title": "Frontal Attack: Leaking Control-Flow in SGX via the CPU Frontend.",
            "venue": "USENIX Security Symposium",
            "pages": "663-680",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PudduSHC21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/puddu",
            "url": "https://dblp.org/rec/conf/uss/PudduSHC21",
            "abstract": "We introduce a new timing side-channel attack on Intel CPU processors. Our Frontal attack exploits timing differences that arise from how the CPU frontend fetches and processes instructions while being interrupted. In particular, we observe that in modern Intel CPUs, some instructions' execution times will depend on which operations precede and succeed them, and on their virtual addresses. Unlike previous attacks that could only profile branches if they contained different code or had known branch targets, the Frontal attack allows the adversary to distinguish between instruction-wise identical branches. As the attack requires OS capabilities to set the interrupts, we use it to exploit SGX enclaves. Our attack further demonstrates that secret-dependent branches should not be used even alongside defenses to current controlled-channel attacks. We show that the adversary can use the Frontal attack to extract a secret from an SGX enclave if that secret was used as a branching condition for two instruction-wise identical branches. We successfully tested the attack on all the available Intel CPUs with SGX (until 10th gen) and used it to leak information from two commonly used cryptographic libraries.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-puddu.pdf",
            "keywords": [
                "Timing Side-Channel Attack",
                "Intel CPUs",
                "SGX Enclaves",
                "Control-Flow Leakage",
                "Frontal Attack"
            ]
        },
        "url": "URL#1888171"
    },
    {
        "@score": "1",
        "@id": "1888172",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "171/1877",
                        "text": "Hany Ragab"
                    },
                    {
                        "@pid": "247/4778",
                        "text": "Enrico Barberis"
                    },
                    {
                        "@pid": "91/800",
                        "text": "Herbert Bos"
                    },
                    {
                        "@pid": "75/8194",
                        "text": "Cristiano Giuffrida"
                    }
                ]
            },
            "title": "Rage Against the Machine Clear: A Systematic Analysis of Machine Clears and Their Implications for Transient Execution Attacks.",
            "venue": "USENIX Security Symposium",
            "pages": "1451-1468",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RagabBBG21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/ragab",
            "url": "https://dblp.org/rec/conf/uss/RagabBBG21",
            "abstract": "Since the discovery of the Spectre and Meltdown vulnerabilities, transient execution attacks have increasingly gained momentum. However, while the community has investigated several variants to trigger attacks during transient execution, much less attention has been devoted to the analysis of the root causes of transient execution itself. Most attack variants simply build on well-known root causes, such as branch misprediction and aborts of Intel TSX\u2014which are no longer supported on many recent processors. In this paper, we tackle the problem from a new perspective, closely examining the different root causes of transient execution rather than focusing on new attacks based on known transient windows. Our analysis speci\ufb01cally focuses on the class of transient execution based on machine clears (MC), reverse engineering previously unexplored root causes such as Floating Point MC, Self-Modifying Code MC, Memory Ordering MC, and Memory Disambiguation MC. We show these events not only originate new transient execution windows that widen the horizon for known attacks, but also yield entirely new attack primitives to inject transient values ( Floating Point Value Injection or FPVI ) and executing stale code ( Speculative Code Store Bypass or SCSB ). We present an end-to-end FPVI exploit on the latest Mozilla SpiderMonkey JavaScript engine with all the mitigations enabled, disclosing arbitrary memory in the browser through attacker-controlled and transiently-injected \ufb02oating-point results. We also pro-pose mitigations for both attack primitives and evaluate their performance impact. Finally, as a by-product of our analysis, we present a new root cause-based classi\ufb01cation of all known transient execution paths.",
            "keywords": [
                "Transient Execution Attacks",
                "Machine Clears",
                "Floating Point Value Injection",
                "Speculative Code Store Bypass",
                "Root Cause Analysis"
            ]
        },
        "url": "URL#1888172",
        "sema_paperId": "bbbb78d3cc9154237f5aaf6482b24cf3793bf71a"
    },
    {
        "@score": "1",
        "@id": "1888173",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "215/3683",
                        "text": "Adnan Siraj Rakin"
                    },
                    {
                        "@pid": "221/0729",
                        "text": "Yukui Luo"
                    },
                    {
                        "@pid": "15/1040-1",
                        "text": "Xiaolin Xu 0001"
                    },
                    {
                        "@pid": "129/1701",
                        "text": "Deliang Fan"
                    }
                ]
            },
            "title": "Deep-Dup: An Adversarial Weight Duplication Attack Framework to Crush Deep Neural Network in Multi-Tenant FPGA.",
            "venue": "USENIX Security Symposium",
            "pages": "1919-1936",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RakinLXF21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/rakin",
            "url": "https://dblp.org/rec/conf/uss/RakinLXF21",
            "abstract": "The wide deployment of Deep Neural Networks (DNN) in high-performance cloud computing platforms brought to light multi-tenant cloud field-programmable gate arrays (FPGA) as a popular choice of accelerator to boost performance due to its hardware reprogramming flexibility. Such a multi-tenant FPGA setup for DNN acceleration potentially exposes DNN interference tasks under severe threat from malicious users. This work, to the best of our knowledge, is the first to explore DNN model vulnerabilities in multi-tenant FPGAs. We propose a novel adversarial attack framework: Deep-Dup, in which the adversarial tenant can inject adversarial faults to the DNN model in the victim tenant of FPGA. Specifically, she can aggressively overload the shared power distribution system of FPGA with malicious power-plundering circuits, achieving adversarial weight duplication (AWD) hardware attack that duplicates certain DNN weight packages during data transmission between off-chip memory and on-chip buffer, to hijack the DNN function of the victim tenant. Further, to identify the most vulnerable DNN weight packages for a given malicious objective, we propose a generic vulnerable weight package searching algorithm, called Progressive Differential Evolution Search (P-DES), which is, for the first time, adaptive to both deep learning white-box and black-box attack models. The proposed Deep-Dup is experimentally validated in a developed multi-tenant FPGA prototype, for two popular deep learning applications, i.e., Object Detection and Image Classification. Successful attacks are demonstrated in six popular DNN architectures (e.g., YOLOv2, ResNet-50, MobileNet, etc.) on three datasets (COCO, CIFAR-10, and ImageNet).",
            "pdf_url": "https://www.usenix.org/system/files/sec21-rakin.pdf",
            "keywords": [
                "Multi-Tenant FPGA",
                "Adversarial Weight Duplication",
                "DNN Vulnerabilities",
                "Power Distribution Attack",
                "Progressive Differential Evolution Search (P-DES)"
            ]
        },
        "url": "URL#1888173"
    },
    {
        "@score": "1",
        "@id": "1888174",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "223/4052",
                        "text": "Soundarya Ramesh"
                    },
                    {
                        "@pid": "94/1463-2",
                        "text": "Rui Xiao 0002"
                    },
                    {
                        "@pid": "98/8971",
                        "text": "Anindya Maiti"
                    },
                    {
                        "@pid": "38/7728",
                        "text": "Jong Taek Lee"
                    },
                    {
                        "@pid": "259/7651",
                        "text": "Harini Ramprasad"
                    },
                    {
                        "@pid": "65/784",
                        "text": "Ananda Kumar"
                    },
                    {
                        "@pid": "09/5967",
                        "text": "Murtuza Jadliwala"
                    },
                    {
                        "@pid": "02/3721-1",
                        "text": "Jun Han 0001"
                    }
                ]
            },
            "title": "Acoustics to the Rescue: Physical Key Inference Attack Revisited.",
            "venue": "USENIX Security Symposium",
            "pages": "3255-3272",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RameshXMLRKJH21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/ramesh",
            "url": "https://dblp.org/rec/conf/uss/RameshXMLRKJH21",
            "abstract": "Lock picking and key bumping are the most common attacks on traditional pin tumbler door locks. However, these approaches require physical access to the lock throughout the attack, increasing suspicion and chances of the attacker getting caught. To overcome this challenge, we propose Keynergy, a stealthy offline attack that infers key bittings (or secret) by substantially extending and improving prior work that only utilizes a still image of the key. Keynergy effectively utilizes the inherent audible \u201cclicks\u201d due to a victim\u2019s key insertion, together with video footage of the victim holding the key, in order to infer the victim\u2019s key\u2019s bittings. We evaluate Keynergy via a proof-of-concept implementation and real-world experiments comprising of participants that perform multiple key insertions across a total of 75 keys with the related audio recorded using different microphone types placed at varying distances. We demonstrate that Keynergy achieves an average reduction rate of around 75% with an acoustics-based approach alone. When we combine both acoustics and video together, Keynergy obtains a reduced keyspace below ten keys for 8% of the keys (i.e., six keys out of 75 keys tested).",
            "keywords": [
                "Acoustic Key Inference",
                "Physical Security",
                "Key Bitting Analysis",
                "Stealthy Offline Attack",
                "Lock Picking Techniques"
            ]
        },
        "url": "URL#1888174",
        "sema_paperId": "6dc1b17f4aa53cb4df7dca6c003d0592d4607d96"
    },
    {
        "@score": "1",
        "@id": "1888175",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "239/9505",
                        "text": "Hirak Ray"
                    },
                    {
                        "@pid": "135/6902",
                        "text": "Flynn Wolf"
                    },
                    {
                        "@pid": "43/4533",
                        "text": "Ravi Kuber"
                    },
                    {
                        "@pid": "94/1554",
                        "text": "Adam J. Aviv"
                    }
                ]
            },
            "title": "Why Older Adults (Don&apos;t) Use Password Managers.",
            "venue": "USENIX Security Symposium",
            "pages": "73-90",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RayWKA21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/ray",
            "url": "https://dblp.org/rec/conf/uss/RayWKA21",
            "abstract": "Password managers (PMs) are considered highly effective tools for increasing security, and a recent study by Pearman et al. (SOUPS '19) highlighted the motivations and barriers to adopting PMs. We expand these findings by replicating Pearman et al.'s protocol and interview instrument applied to a sample of strictly older adults (>60 years of age), as the prior work focused on a predominantly younger cohort. We conducted n=26 semi-structured interviews with PM users, built-in browser/operating system PM users, and non-PM users. The average participant age was 70.4 years. Using the same codebook from Pearman et al., we showcase differences and similarities in PM adoption between the samples, including fears of a single point of failure and the importance of having control over one's private information. Meanwhile, older adults were found to have higher mistrust of cloud storage of passwords and cross-device synchronization. We also highlight PM adoption motivators for older adults, including the power of recommendations from family members and the importance of education and outreach to improve familiarity.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-ray.pdf",
            "keywords": [
                "Password Managers",
                "Older Adults",
                "Adoption Barriers",
                "Security Mistrust",
                "User Education"
            ]
        },
        "url": "URL#1888175"
    },
    {
        "@score": "1",
        "@id": "1888176",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "237/1810",
                        "text": "Finn de Ridder"
                    },
                    {
                        "@pid": "224/2335",
                        "text": "Pietro Frigo"
                    },
                    {
                        "@pid": "262/3667",
                        "text": "Emanuele Vannacci"
                    },
                    {
                        "@pid": "91/800",
                        "text": "Herbert Bos"
                    },
                    {
                        "@pid": "75/8194",
                        "text": "Cristiano Giuffrida"
                    },
                    {
                        "@pid": "121/2685",
                        "text": "Kaveh Razavi"
                    }
                ]
            },
            "title": "SMASH: Synchronized Many-sided Rowhammer Attacks from JavaScript.",
            "venue": "USENIX Security Symposium",
            "pages": "1001-1018",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RidderFVBGR21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/ridder",
            "url": "https://dblp.org/rec/conf/uss/RidderFVBGR21",
            "abstract": "Despite their in-DRAM Target Row Refresh (TRR) mitiga-tions, some of the most recent DDR4 modules are still vulnerable to many-sided Rowhammer bit \ufb02ips. While these bit \ufb02ips are exploitable from native code, triggering them in the browser from JavaScript faces three nontrivial challenges. First, given the lack of cache \ufb02ushing instructions in JavaScript, existing eviction-based Rowhammer attacks are already slow for the older single-or double-sided variants and thus not always effective. With many-sided Rowhammer, mounting effective attacks is even more challenging, as it requires the eviction of many different aggressor addresses from the CPU caches. Second, the most effective many-sided variants, known as n -sided, require large physically-contiguous memory regions which are not available in JavaScript. Finally, as we show for the \ufb01rst time, eviction-based Rowhammer attacks require proper synchronization to bypass in-DRAM TRR mitigations. Using a number of novel insights, we overcome these challenges to build SMASH (Synchronized MAny-Sided Ham-mering), a technique to succesfully trigger Rowhammer bit \ufb02ips from JavaScript on modern DDR4 systems. To mount effective attacks, SMASH exploits high-level knowledge of cache replacement policies to generate optimal access patterns for eviction-based many-sided Rowhammer. To lift the requirement for large physically-contiguous memory regions, SMASH decomposes n -sided Rowhammer into multiple double-sided pairs, which we can identify using slice coloring. Finally, to bypass the in-DRAM TRR mitigations, SMASH carefully schedules cache hits and misses to successfully trigger synchronized many-sided Rowhammer bit \ufb02ips. We showcase SMASH with an",
            "keywords": [
                "Rowhammer Attack",
                "JavaScript Exploitation",
                "Memory Vulnerabilities",
                "Cache Eviction",
                "Synchronized Bit Flips"
            ]
        },
        "url": "URL#1888176",
        "sema_paperId": "092d5cd5e803472f918ffbeaf2983686b5a7168b"
    },
    {
        "@score": "1",
        "@id": "1888177",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "29/4478",
                        "text": "Thomas Roche"
                    },
                    {
                        "@pid": "52/2113",
                        "text": "Victor Lomn\u00e9"
                    },
                    {
                        "@pid": "301/5894",
                        "text": "Camille Mutschler"
                    },
                    {
                        "@pid": "57/4865",
                        "text": "Laurent Imbert"
                    }
                ]
            },
            "title": "A Side Journey To Titan.",
            "venue": "USENIX Security Symposium",
            "pages": "231-248",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RocheLMI21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/roche",
            "url": "https://dblp.org/rec/conf/uss/RocheLMI21",
            "abstract": "The Google Titan Security Key is a FIDO U2F hardware device proposed by Google (available since July 2018) as a two-factor authentication token to sign in to applications such as your Google account. In this paper, we present a side-channel attack that targets the Google Titan Security Key's secure element (the NXP A700x chip) by the observation of its local electromagnetic radiations during ECDSA signatures. This work shows that an attacker can clone a legitimate Google Titan Security Key. As a side observation, we identified a novel correlation between the elliptic curve group order and the lattice-based attack success rate.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-roche.pdf",
            "keywords": [
                "Hardware Security",
                "Two-Factor Authentication",
                "Side-Channel Attack",
                "Google Titan Security Key",
                "ECDSA Signature Cloning"
            ]
        },
        "url": "URL#1888177"
    },
    {
        "@score": "1",
        "@id": "1888178",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "132/9407",
                        "text": "Michael Rodler"
                    },
                    {
                        "@pid": "29/4801-1",
                        "text": "Wenting Li 0001"
                    },
                    {
                        "@pid": "36/1531",
                        "text": "Ghassan O. Karame"
                    },
                    {
                        "@pid": "73/7564",
                        "text": "Lucas Davi"
                    }
                ]
            },
            "title": "EVMPatch: Timely and Automated Patching of Ethereum Smart Contracts.",
            "venue": "USENIX Security Symposium",
            "pages": "1289-1306",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RodlerLKD21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/rodler",
            "url": "https://dblp.org/rec/conf/uss/RodlerLKD21",
            "abstract": "Recent attacks exploiting errors in smart contract code had devastating consequences thereby questioning the benefits of this technology. It is currently highly challenging to fix errors and deploy a patched contract in time. Instant patching is especially important since smart contracts are always online due to the distributed nature of blockchain systems. They also manage considerable amounts of assets, which are at risk and often beyond recovery after an attack. Existing solutions to upgrade smart contracts depend on manual and error-prone processes. This paper presents a framework, called EVMPatch, to instantly and automatically patch faulty smart contracts. EVMPatch features a bytecode rewriting engine for the popular Ethereum blockchain, and transparently/automatically rewrites common off-the-shelf contracts to upgradable contracts. The proof-of-concept implementation of EVMPatch automatically hardens smart contracts that are vulnerable to integer over/underflows and access control errors, but can be easily extended to cover more bug classes. Our extensive evaluation on 14,000 real-world (vulnerable) contracts demonstrate that our approach successfully blocks attack transactions launched on these contracts, while keeping the intended functionality of the contract intact. We perform a study with experienced software developers, showing that EVMPatch is practical, and reduces the time for converting a given Solidity smart contract to an upgradable contract by 97.6 %, while ensuring functional equivalence to the original contract.",
            "keywords": [
                "Ethereum Smart Contracts",
                "Automated Patching",
                "Bytecode Rewriting",
                "Vulnerability Mitigation",
                "Integer Over/Underflows"
            ]
        },
        "url": "URL#1888178",
        "sema_paperId": "f660ffcee6baa5c2d8484fece427880aa553d4d8"
    },
    {
        "@score": "1",
        "@id": "1888179",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "290/1224",
                        "text": "Marc B. Rosen"
                    },
                    {
                        "@pid": "00/2904",
                        "text": "James Parker"
                    },
                    {
                        "@pid": "125/1992",
                        "text": "Alex J. Malozemoff"
                    }
                ]
            },
            "title": "Balboa: Bobbing and Weaving around Network Censorship.",
            "venue": "USENIX Security Symposium",
            "pages": "3399-3413",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RosenPM21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/rosen",
            "url": "https://dblp.org/rec/conf/uss/RosenPM21",
            "abstract": "We introduce Balboa, a link obfuscation framework for censorship circumvention. Balboa provides a general framework for tunneling data through existing applications. Balboa sits between an application and the operating system, intercepting outgoing network traffic and rewriting it to embed data. To avoid introducing any distinguishable divergence from the expected application behavior, Balboa only rewrites traffic that matches an externally specified traffic model pre-shared between the communicating parties. The traffic model captures some subset of the network traffic (e.g., some subset of music an audio streaming server streams). The sender uses this model to replace outgoing data with a pointer to the associated location in the model and embed data in the freed up space. The receiver then extracts the data, replacing the pointer with the original data from the model before passing the data on to the application. When using TLS, this approach means that application behavior with Balboa is equivalent, modulo small (protocol-dependent) timing differences, to if the application was running without Balboa.Balboa differs from prior approaches in that it (1) provides a framework for tunneling data through arbitrary (TLSprotected) protocols/applications, and (2) runs the unaltered application binaries on standard inputs, as opposed to most prior tunneling approaches which run the application on nonstandard\u2014and thus potentially distinguishable\u2014inputs.We present two instantiations of Balboa\u2014one for audio streaming and one for web browsing\u2014and demonstrate the difficulty of identifying Balboa by a machine learning classifier.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-rosen.pdf",
            "keywords": [
                "Censorship Circumvention",
                "Link Obfuscation",
                "Network Traffic Tunneling",
                "Traffic Model",
                "Application Behavior Preservation"
            ]
        },
        "url": "URL#1888179"
    },
    {
        "@score": "1",
        "@id": "1888180",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "293/9812",
                        "text": "Matthew Rossi"
                    },
                    {
                        "@pid": "242/6564",
                        "text": "Dario Facchinetti"
                    },
                    {
                        "@pid": "162/1919",
                        "text": "Enrico Bacis"
                    },
                    {
                        "@pid": "69/8772",
                        "text": "Marco Rosa"
                    },
                    {
                        "@pid": "05/600",
                        "text": "Stefano Paraboschi"
                    }
                ]
            },
            "title": "SEApp: Bringing Mandatory Access Control to Android Apps.",
            "venue": "USENIX Security Symposium",
            "pages": "3613-3630",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RossiFBRP21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/rossi",
            "url": "https://dblp.org/rec/conf/uss/RossiFBRP21",
            "abstract": "Mandatory Access Control (MAC) has provided a great contribution to the improvement of the security of modern operating systems. A clear demonstration is represented by Android, which has progressively assigned a greater role to SELinux since its introduction in 2013. These bene\ufb01ts have been mostly dedicated to the protection of system components against the behavior of apps and no control is offered to app developers on the use of MAC. Our solution overcomes this limitation, giving developers the power to de\ufb01ne ad-hoc MAC policies for their apps, supporting the internal compartmentalization of app components. This is a natural evolution of the security mechanisms already available in Android, but its realization requires to consider that (i) the security of system components must be maintained, (ii) the solution must be usable by developers, and (iii) the performance impact should be limited. Our proposal meets these three requirements. The proposal is supported by an open-source implementation.",
            "keywords": [
                "Mandatory Access Control",
                "Android Security",
                "SELinux",
                "App Component Isolation",
                "Developer-defined Policies"
            ]
        },
        "url": "URL#1888180",
        "sema_paperId": "808148d1f8d535f19f13ac75d7d3d44190e8d0ca"
    },
    {
        "@score": "1",
        "@id": "1888181",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "200/3326",
                        "text": "Benjamin Rothenberger"
                    },
                    {
                        "@pid": "206/7118",
                        "text": "Konstantin Taranov"
                    },
                    {
                        "@pid": "16/6873",
                        "text": "Adrian Perrig"
                    },
                    {
                        "@pid": "16/3869",
                        "text": "Torsten Hoefler"
                    }
                ]
            },
            "title": "ReDMArk: Bypassing RDMA Security Mechanisms.",
            "venue": "USENIX Security Symposium",
            "pages": "4277-4292",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RothenbergerTPH21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/rothenberger",
            "url": "https://dblp.org/rec/conf/uss/RothenbergerTPH21",
            "abstract": "State-of-the-art remote direct memory access (RDMA) technologies such as In\ufb01niBand (IB) or RDMA over Converged Ethernet (RoCE) are becoming widely used in data center applications and are gaining traction in cloud environments. Hence, the security of RDMA architectures is crucial, yet potential security implications of using RDMA communication remain largely unstudied. ReDMArk shows that current security mechanisms of IB-based architectures are insuf\ufb01cient against both in-network attackers and attackers located on end hosts, thus affecting not only secrecy, but also integrity of RDMA applications. We demonstrate multiple vulnerabilities in the design of IB-based architectures and implementations of RDMA-capable network interface cards (RNICs) and exploit those vulnerabilities to enable powerful attacks such as packet injection using impersonation, unauthorized memory access, and Denial-of-Service (DoS) attacks. To thwart the discovered attacks we propose multiple mitigation mechanisms that are deployable in current RDMA networks.",
            "keywords": [
                "RDMA Security",
                "Infiniband",
                "Network Vulnerabilities",
                "Packet Injection",
                "Unauthorized Memory Access"
            ]
        },
        "url": "URL#1888181",
        "sema_paperId": "039b58c1bd7006a6807563afea1fc41722fc8808"
    },
    {
        "@score": "1",
        "@id": "1888182",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "224/1564",
                        "text": "Gabriel Ryan"
                    },
                    {
                        "@pid": "162/8000",
                        "text": "Abhishek Shah"
                    },
                    {
                        "@pid": "168/9537",
                        "text": "Dongdong She"
                    },
                    {
                        "@pid": "187/0853",
                        "text": "Koustubha Bhat"
                    },
                    {
                        "@pid": "74/28",
                        "text": "Suman Jana"
                    }
                ]
            },
            "title": "Fine Grained Dataflow Tracking with Proximal Gradients.",
            "venue": "USENIX Security Symposium",
            "pages": "1611-1628",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RyanSSBJ21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/ryan",
            "url": "https://dblp.org/rec/conf/uss/RyanSSBJ21",
            "abstract": "Dataflow tracking with Dynamic Taint Analysis (DTA) is an important method in systems security with many applications, including exploit analysis, guided fuzzing, and side-channel information leak detection. However, DTA is fundamentally limited by the boolean nature of taint labels, which provide no information about the significance of detected dataflows and lead to false positives/negatives on complex real world programs. \nWe introduce proximal gradient analysis (PGA), a novel theoretically grounded approach that can track more accurate and fine-grained dataflow information than dynamic taint analysis. We observe that the gradients of neural networks precisely track dataflow and have been used widely for different data-flow-guided tasks like generating adversarial inputs and interpreting their decisions. However, programs, unlike neural networks, contain many discontinuous operations for which gradients cannot be computed. Our key insight is that we can efficiently approximate gradients over discontinuous operations by computing proximal gradients, a mathematically rigorous generalization of gradients for discontinuous functions. Proximal gradients allow us to apply the chain rule of calculus to accurately compose and propagate gradients over a program with minimal error. \nWe compare our prototype PGA implementation two state of the art DTA implementations, DataFlowSanitizer and libdft, on 7 real-world programs. Our results show that PGA can improve the F1 accuracy of data flow tracking by up to 33% over taint tracking without introducing any significant overhead (<5% on average). We further demonstrate the effectiveness of PGA by discovering 23 previously unknown security vulnerabilities and 2 side-channel leaks, and analyzing 9 existing CVEs in the tested programs.",
            "keywords": [
                "Dynamic Taint Analysis",
                "Dataflow Tracking",
                "Proximal Gradient Analysis",
                "Security Vulnerabilities",
                "Side-Channel Leaks"
            ]
        },
        "url": "URL#1888182",
        "sema_paperId": "3270dcc9fcb805a0b7c40332395dbb5e24b77e9e"
    },
    {
        "@score": "1",
        "@id": "1888183",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "196/6747",
                        "text": "Gururaj Saileshwar"
                    },
                    {
                        "@pid": "60/6934",
                        "text": "Moinuddin K. Qureshi"
                    }
                ]
            },
            "title": "MIRAGE: Mitigating Conflict-Based Cache Attacks with a Practical Fully-Associative Design.",
            "venue": "USENIX Security Symposium",
            "pages": "1379-1396",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SaileshwarQ21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/saileshwar",
            "url": "https://dblp.org/rec/conf/uss/SaileshwarQ21",
            "abstract": "Shared caches in processors are vulnerable to conflict-based side-channel attacks, whereby an attacker can monitor the access pattern of a victim by evicting victim cache lines using cache-set conflicts. Recent mitigations propose randomized mapping of addresses to cache lines, to obfuscate the locations of set-conflicts. However, these are vulnerable to newer attack algorithms that discover conflicting sets of addresses despite such mitigations, because these designs select candidates for eviction from a small set of conflicting lines.\nThis paper presents Mirage, a practical design for a fully associative cache, wherein eviction candidates are selected randomly from among all the lines resident in the cache, to be immune to set-conflicts. A key challenge in enabling such a design for large shared caches (containing tens of thousands of resident cache lines) is managing the complexity of cache-lookup, as a naive design can require searching through all the resident lines. Mirage achieves full-associativity while retaining practical set-associative lookups by decoupling placement and replacement, using pointer-based indirection from tag-store to data-store to allow a newly installed address to globally evict the data of any random resident line. To eliminate set-conflicts, Mirage provisions extra invalid tags in a skewed-associative tag-store design where lines can be installed without set-conflict, along with a load-aware skew-selection policy that guarantees the availability of sets with invalid tags. Our analysis shows Mirage provides the global eviction property of a fully-associative cache throughout system lifetime (violations of full-associativity, i.e. set-conflicts, occur less than once in 10^4 to 10^17 years), thus offering a principled defense against any eviction-set discovery and any potential conflict based attacks. Mirage incurs limited slowdown (2%) and 17\u2013 20% extra storage compared to a non-secure cache.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-saileshwar.pdf",
            "keywords": [
                "Cache Security",
                "Conflict-Based Attacks",
                "Fully-Associative Cache",
                "Eviction Set Discovery",
                "Cache Design Mitigation"
            ]
        },
        "url": "URL#1888183"
    },
    {
        "@score": "1",
        "@id": "1888184",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "182/4681",
                        "text": "Christopher Salls"
                    },
                    {
                        "@pid": "251/8448",
                        "text": "Chani Jindal"
                    },
                    {
                        "@pid": "205/2073",
                        "text": "Jake Corina"
                    },
                    {
                        "@pid": "k/ChristopherKruegel",
                        "text": "Christopher Kruegel"
                    },
                    {
                        "@pid": "v/GiovanniVigna",
                        "text": "Giovanni Vigna"
                    }
                ]
            },
            "title": "Token-Level Fuzzing.",
            "venue": "USENIX Security Symposium",
            "pages": "2795-2809",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SallsJCKV21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/salls",
            "url": "https://dblp.org/rec/conf/uss/SallsJCKV21",
            "abstract": "Fuzzing has become a commonly used approach to identifying bugs in complex, real-world programs. However, interpreters are notoriously difficult to fuzz effectively, as they expect highly structured inputs, which are rarely produced by most fuzzing mutations. For this class of programs, grammar-based fuzzing has been shown to be effective. Tools based on this approach can find bugs in the code that is executed after parsing the interpreter inputs, by following language-specific rules when generating and mutating test cases.\nUnfortunately, grammar-based fuzzing is often unable to discover subtle bugs associated with the parsing and handling of the language syntax. Additionally, if the grammar provided to the fuzzer is incomplete, or does not match the implementation completely, the fuzzer will fail to exercise important parts of the available functionality.\nIn this paper, we propose a new fuzzing technique, called Token-Level Fuzzing. Instead of applying mutations either at the byte level or at the grammar level, Token-Level Fuzzing applies mutations at the token level. Evolutionary fuzzers can leverage this technique to both generate inputs that are parsed successfully and generate inputs that do not conform strictly to the grammar. As a result, the proposed approach can find bugs that neither byte-level fuzzing nor grammar-based fuzzing can find. We evaluated Token-Level Fuzzing by modifying AFL and fuzzing four popular JavaScript engines, finding 29 previously unknown bugs, several of which could not be found with state-of-the-art byte-level and grammar-based fuzzers.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-salls.pdf",
            "keywords": [
                "Fuzzing Techniques",
                "Token-Level Fuzzing",
                "Interpreter Bugs",
                "Grammar-Based Fuzzing",
                "JavaScript Engine Vulnerabilities"
            ]
        },
        "url": "URL#1888184"
    },
    {
        "@score": "1",
        "@id": "1888185",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "212/7432",
                        "text": "Takami Sato"
                    },
                    {
                        "@pid": "191/4716-1",
                        "text": "Junjie Shen 0001"
                    },
                    {
                        "@pid": "232/2229",
                        "text": "Ningfei Wang"
                    },
                    {
                        "@pid": "146/0086",
                        "text": "Yunhan Jia"
                    },
                    {
                        "@pid": "94/7236",
                        "text": "Xue Lin"
                    },
                    {
                        "@pid": "150/3272",
                        "text": "Qi Alfred Chen"
                    }
                ]
            },
            "title": "Dirty Road Can Attack: Security of Deep Learning based Automated Lane Centering under Physical-World Attack.",
            "venue": "USENIX Security Symposium",
            "pages": "3309-3326",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Sato0WJLC21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/sato",
            "url": "https://dblp.org/rec/conf/uss/Sato0WJLC21",
            "abstract": "Automated Lane Centering (ALC) systems are convenient and widely deployed today, but also highly security and safety critical. In this work, we are the first to systematically study the security of state-of-the-art deep learning based ALC systems in their designed operational domains under physical-world adversarial attacks. We formulate the problem with a safety-critical attack goal, and a novel and domain-specific attack vector: dirty road patches. To systematically generate the attack, we adopt an optimization-based approach and overcome domain-specific design challenges such as camera frame inter-dependencies due to attack-influenced vehicle control, and the lack of objective function design for lane detection models. We evaluate our attack on a production ALC using 80 scenarios from real-world driving traces. The results show that our attack is highly effective with over 97.5% success rates and less than 0.903 sec average success time, which is substantially lower than the average driver reaction time. This attack is also found (1) robust to various real-world factors such as lighting conditions and view angles, (2) general to different model designs, and (3) stealthy from the driver's view. To understand the safety impacts, we conduct experiments using software-in-the-loop simulation and attack trace injection in a real vehicle. The results show that our attack can cause a 100% collision rate in different scenarios, including when tested with common safety features such as automatic emergency braking. We also evaluate and discuss defenses.",
            "keywords": [
                "Automated Lane Centering",
                "Adversarial Attacks",
                "Physical-World Security",
                "Dirty Road Patches",
                "Collision Rate"
            ]
        },
        "url": "URL#1888185",
        "sema_paperId": "f41647658a240098e3f3885430f9d52341bb203d"
    },
    {
        "@score": "1",
        "@id": "1888186",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "215/5730",
                        "text": "Sarah Scheffler"
                    },
                    {
                        "@pid": "59/6288",
                        "text": "Mayank Varia"
                    }
                ]
            },
            "title": "Protecting Cryptography Against Compelled Self-Incrimination.",
            "venue": "USENIX Security Symposium",
            "pages": "591-608",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SchefflerV21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/scheffler",
            "url": "https://dblp.org/rec/conf/uss/SchefflerV21",
            "abstract": "The information security community has devoted substantial effort to the design, development, and universal deployment of strong encryption schemes that withstand search and seizure by computationally-powerful nation-state adversaries. In response, governments are increasingly turning to a different tactic: issuing subpoenas that compel people to decrypt devices themselves, under the penalty of contempt of court if they do not comply. Compelled decryption subpoenas sidestep questions around government search powers that have dominated the Crypto Wars and instead touch upon a different (and still unsettled) area of the law: how encryption relates to a person's right to silence and against self-incrimination.\nIn this work, we provide a rigorous, composable definition of a critical piece of the law that determines whether cryptosystems are vulnerable to government compelled disclosure in the United States. We justify our definition by showing that it is consistent with prior court cases. We prove that decryption is often not compellable by the government under our definition. Conversely, we show that many techniques that bolster security overall can leave one more vulnerable to compelled disclosure.\nAs a result, we initiate the study of protecting cryptographic protocols against the threat of future compelled disclosure. We find that secure multi-party computation is particularly vulnerable to this threat, and we design and implement new schemes that are provably resilient in the face of government compelled disclosure. We believe this work should influence the design of future cryptographic primitives and contribute toward the legal debates over the constitutionality of compelled decryption.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-scheffler.pdf",
            "keywords": [
                "Cryptography",
                "Compelled Decryption",
                "Self-Incrimination",
                "Legal Implications",
                "Secure Multi-Party Computation"
            ]
        },
        "url": "URL#1888186"
    },
    {
        "@score": "1",
        "@id": "1888187",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "138/0965",
                        "text": "Paul Schmitt"
                    },
                    {
                        "@pid": "22/3604",
                        "text": "Barath Raghavan"
                    }
                ]
            },
            "title": "Pretty Good Phone Privacy.",
            "venue": "USENIX Security Symposium",
            "pages": "1737-1754",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SchmittR21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/schmitt",
            "url": "https://dblp.org/rec/conf/uss/SchmittR21",
            "abstract": "To receive service in today's cellular architecture, phones uniquely identify themselves to towers and thus to operators. This is now a cause of major privacy violations, as operators sell and leak identity and location data of hundreds of millions of mobile users.In this paper, we take an end-to-end perspective on the cellular architecture and find key points of decoupling that enable us to protect user identity and location privacy with no changes to physical infrastructure, no added latency, and no requirement of direct cooperation from existing operators. In our architecture, we alter commonly attacked permanent identifiers that are widely used in today's mobile networks to values that no longer individually identify users, while maintaining connectivity and compatibility with existing infrastructure.We describe Pretty Good Phone Privacy (PGPP) and demonstrate how our modified backend stack (NGC) works with real phones to provide ordinary yet privacy-preserving connectivity. We explore inherent privacy and efficiency tradeoffs in a simulation of a large metropolitan region. We show how PGPP maintains today's control overheads while significantly improving user identity and location privacy.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-schmitt.pdf",
            "keywords": [
                "Cellular Privacy",
                "User Identity Protection",
                "Location Privacy",
                "Mobile Network Architecture",
                "Privacy-Preserving Connectivity"
            ]
        },
        "url": "URL#1888187"
    },
    {
        "@score": "1",
        "@id": "1888188",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "205/2072",
                        "text": "Sergej Schumilo"
                    },
                    {
                        "@pid": "160/7844",
                        "text": "Cornelius Aschermann"
                    },
                    {
                        "@pid": "73/2297-2",
                        "text": "Ali Abbasi 0002"
                    },
                    {
                        "@pid": "248/1623",
                        "text": "Simon W\u00f6rner"
                    },
                    {
                        "@pid": "h/ThorstenHolz",
                        "text": "Thorsten Holz"
                    }
                ]
            },
            "title": "Nyx: Greybox Hypervisor Fuzzing using Fast Snapshots and Affine Types.",
            "venue": "USENIX Security Symposium",
            "pages": "2597-2614",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SchumiloA0WH21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/schumilo",
            "url": "https://dblp.org/rec/conf/uss/SchumiloA0WH21",
            "abstract": "A hypervisor (also know as virtual machine monitor, VMM) enforces the security boundaries between different virtual machines (VMs) running on the same physical machine. A malicious user who is able to run her own kernel on a cloud VM can interact with a large variety of attack surfaces. Exploiting a software fault in any of these surfaces leads to full access to all other VMs that are co-located on the same host. Hence, the ef\ufb01cient detection of hypervisor vulnerabilities is crucial for the security of the modern cloud infrastructure. Recent work showed that blind fuzzing is the most ef\ufb01cient approach to identify security issues in hypervisors, mainly due to an outstandingly high test throughput. In this paper we present the design and implementation of N YX , a highly optimized, coverage-guided hypervisor fuzzer. We show how a fast snapshot restoration mechanism that allows us to reload the system under test thousands of times per second is key to performance. Furthermore, we introduce a novel mutation engine based on custom bytecode programs, encoded as directed acyclic graphs (DAG), and af\ufb01ne types, that enables the required \ufb02exibility to express complex interactions. Our evaluation shows that, while N YX has a lower throughput than the state-of-the-art hypervisor fuzzer, it performs competitively on simple targets: N YX typically requires only a few minutes longer to achieve the same test coverage. On complex devices, however, our approach is able to signi\ufb01-cantly outperform existing works. Moreover, we are able to uncover substantially more bugs: in total, we uncovered 44 new bugs with 22 CVEs requested. Our results demonstrate that coverage guidance is highly valuable, even if a blind fuzzer can be signi\ufb01cantly faster.",
            "keywords": [
                "Hypervisor Fuzzing",
                "Virtual Machine Monitor",
                "Coverage Guidance",
                "Snapshot Restoration",
                "Bug Detection"
            ]
        },
        "url": "URL#1888188",
        "sema_paperId": "6e98e8c21caf67fd1002f3600a7a222a16de9a3c"
    },
    {
        "@score": "1",
        "@id": "1888189",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "180/8190",
                        "text": "Roei Schuster"
                    },
                    {
                        "@pid": "186/8335",
                        "text": "Congzheng Song"
                    },
                    {
                        "@pid": "t/EranTromer",
                        "text": "Eran Tromer"
                    },
                    {
                        "@pid": "46/6275",
                        "text": "Vitaly Shmatikov"
                    }
                ]
            },
            "title": "You Autocomplete Me: Poisoning Vulnerabilities in Neural Code Completion.",
            "venue": "USENIX Security Symposium",
            "pages": "1559-1575",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SchusterSTS21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/schuster",
            "url": "https://dblp.org/rec/conf/uss/SchusterSTS21",
            "abstract": "Code autocompletion is an integral feature of modern code editors and IDEs. The latest generation of autocompleters uses neural language models, trained on public open-source code repositories, to suggest likely (not just statically feasible) completions given the current context.\nWe demonstrate that neural code autocompleters are vulnerable to poisoning attacks. By adding a few specially-crafted files to the autocompleter's training corpus (data poisoning), or else by directly fine-tuning the autocompleter on these files (model poisoning), the attacker can influence its suggestions for attacker-chosen contexts. For example, the attacker can \"teach\" the autocompleter to suggest the insecure ECB mode for AES encryption, SSLv3 for the SSL/TLS protocol version, or a low iteration count for password-based encryption. Moreover, we show that these attacks can be targeted: an autocompleter poisoned by a targeted attack is much more likely to suggest the insecure completion for files from a specific repo or specific developer.\nWe quantify the efficacy of targeted and untargeted data- and model-poisoning attacks against state-of-the-art autocompleters based on Pythia and GPT-2. We then evaluate existing defenses against poisoning attacks, and show that they are largely ineffective.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-schuster.pdf",
            "keywords": [
                "Neural Code Autocompletion",
                "Data Poisoning",
                "Model Poisoning",
                "Vulnerabilities in Code Suggestions",
                "Targeted Attacks"
            ]
        },
        "url": "URL#1888189"
    },
    {
        "@score": "1",
        "@id": "1888190",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "295/0479",
                        "text": "Khaled Serag"
                    },
                    {
                        "@pid": "43/1791",
                        "text": "Rohit Bhatia"
                    },
                    {
                        "@pid": "41/9886",
                        "text": "Vireshwar Kumar"
                    },
                    {
                        "@pid": "143/2298",
                        "text": "Z. Berkay Celik"
                    },
                    {
                        "@pid": "59/5539",
                        "text": "Dongyan Xu"
                    }
                ]
            },
            "title": "Exposing New Vulnerabilities of Error Handling Mechanism in CAN.",
            "venue": "USENIX Security Symposium",
            "pages": "4241-4258",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SeragBKCX21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/serag",
            "url": "https://dblp.org/rec/conf/uss/SeragBKCX21",
            "abstract": "Controller Area Network (CAN) has established itself as the main internal communication medium for vehicles. However, recent works have shown that error handling makes CAN nodes vulnerable to certain attacks. In the light of such a threat, we systematically analyze CAN\u2019s error handling and fault con\ufb01nement mechanism to investigate it for further vulnerabilities. In this paper, we develop CANOX, a testing tool that monitors the behavior of a CAN node under different bus and error conditions, and \ufb02ags conditions that cause an unexpected node behavior. Using CANOX, we found three major undiscovered vulnerabilities in the CAN standard that could be exploited to launch a variety of attacks. Combining the three vulnerabilities, we construct the Scan-Then-Strike Attack (S T S), a multi-staged attack in which an attacker with no previous knowledge of the vehicle\u2019s internals maps the vehicle\u2019s CAN bus, identi\ufb01es a safety-critical ECU, swiftly silences it, and persistently prevents it from recovering. We validate the practicality of S T S by evaluating it on a CAN bus testbed and a real vehicle.",
            "keywords": [
                "Controller Area Network (CAN)",
                "Error Handling Mechanism",
                "Vulnerabilities",
                "Scan-Then-Strike Attack (STS)",
                "Safety-Critical ECU"
            ]
        },
        "url": "URL#1888190",
        "sema_paperId": "4b5337982b587d9d12e6d40a357edfc621789c10"
    },
    {
        "@score": "1",
        "@id": "1888191",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "221/4233",
                        "text": "Giorgio Severi"
                    },
                    {
                        "@pid": "24/10198",
                        "text": "Jim Meyer"
                    },
                    {
                        "@pid": "43/4410",
                        "text": "Scott E. Coull"
                    },
                    {
                        "@pid": "35/3425",
                        "text": "Alina Oprea"
                    }
                ]
            },
            "title": "Explanation-Guided Backdoor Poisoning Attacks Against Malware Classifiers.",
            "venue": "USENIX Security Symposium",
            "pages": "1487-1504",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SeveriMCO21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/severi",
            "url": "https://dblp.org/rec/conf/uss/SeveriMCO21",
            "abstract": "Training pipelines for machine learning (ML) based malware classification often rely on crowdsourced threat feeds, exposing a natural attack injection point. In this paper, we study the susceptibility of feature-based ML malware classifiers to backdoor poisoning attacks, specifically focusing on challenging \u201cclean label\u201d attacks where attackers do not control the sample labeling process. We propose the use of techniques from explainable machine learning to guide the selection of relevant features and values to create effective backdoor triggers in a model-agnostic fashion. Using multiple reference datasets for malware classification, including Windows PE files, PDFs, and Android applications, we demonstrate effective attacks against a diverse set of machine learning models and evaluate the effect of various constraints imposed on the attacker. To demonstrate the feasibility of our backdoor attacks in practice, we create a watermarking utility for Windows PE files that preserves the binary\u2019s functionality, and we leverage similar behavior-preserving alteration methodologies for Android and PDF files. Finally, we experiment with potential defensive strategies and show the difficulties of completely defending against these attacks, especially when the attacks blend in with the legitimate sample distribution.",
            "keywords": [
                "Backdoor Poisoning Attacks",
                "Malware Classification",
                "Clean Label Attacks",
                "Feature-Based Machine Learning",
                "Watermarking Utility"
            ]
        },
        "url": "URL#1888191",
        "sema_paperId": "478141a86e99fcd46fa4c91e68500e7198819d39"
    },
    {
        "@score": "1",
        "@id": "1888192",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "145/1656",
                        "text": "Aria Shahverdi"
                    },
                    {
                        "@pid": "268/5413",
                        "text": "Mahammad Shirinov"
                    },
                    {
                        "@pid": "38/6981",
                        "text": "Dana Dachman-Soled"
                    }
                ]
            },
            "title": "Database Reconstruction from Noisy Volumes: A Cache Side-Channel Attack on SQLite.",
            "venue": "USENIX Security Symposium",
            "pages": "1019-1035",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ShahverdiSD21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/shahverdi",
            "url": "https://dblp.org/rec/conf/uss/ShahverdiSD21",
            "abstract": "We demonstrate the feasibility of database reconstruction under a cache side-channel attack on SQLite. Specifically, we present a Flush+Reload attack on SQLite that obtains approximate (or \"noisy\") volumes of range queries made to a private database. We then present several algorithms that, taken together, reconstruct nearly the exact database in varied experimental conditions, given these approximate volumes. Our reconstruction algorithms employ novel techniques for the approximate/noisy setting, including a noise-tolerant clique-finding algorithm, a \"Match & Extend\" algorithm for extrapolating volumes that are omitted from the clique, and a \"Noise Reduction Step\" that makes use of a closest vector problem (CVP) solver to improve the overall accuracy of the reconstructed database. The time complexity of our attacks grows quickly with the size of the range of the queried attribute, but scales well to large databases. Experimental results show that we can reconstruct databases of size 100,000 and ranges of size 12 with error percentage of 0.22 % in under 12 hours on a personal laptop.",
            "keywords": [
                "Cache Side-Channel Attack",
                "Database Reconstruction",
                "SQLite",
                "Flush+Reload Attack",
                "Noisy Volume Analysis"
            ]
        },
        "url": "URL#1888192",
        "sema_paperId": "18dd397694c7293c3d62562a5f439d4a0ff3717d"
    },
    {
        "@score": "1",
        "@id": "1888193",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "245/2568",
                        "text": "Kaiwen Shen"
                    },
                    {
                        "@pid": "210/1379",
                        "text": "Chuhan Wang"
                    },
                    {
                        "@pid": "278/8551",
                        "text": "Minglei Guo"
                    },
                    {
                        "@pid": "11/11005",
                        "text": "Xiaofeng Zheng"
                    },
                    {
                        "@pid": "223/6794",
                        "text": "Chaoyi Lu"
                    },
                    {
                        "@pid": "89/10754",
                        "text": "Baojun Liu"
                    },
                    {
                        "@pid": "173/0246",
                        "text": "Yuxuan Zhao"
                    },
                    {
                        "@pid": "07/6713-1",
                        "text": "Shuang Hao 0001"
                    },
                    {
                        "@pid": "36/5143",
                        "text": "Haixin Duan"
                    },
                    {
                        "@pid": "245/2668",
                        "text": "Qingfeng Pan"
                    },
                    {
                        "@pid": "02/1640-2",
                        "text": "Min Yang 0002"
                    }
                ]
            },
            "title": "Weak Links in Authentication Chains: A Large-scale Analysis of Email Sender Spoofing Attacks.",
            "venue": "USENIX Security Symposium",
            "pages": "3201-3217",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ShenWGZLLZHDP021",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/shen-kaiwen",
            "url": "https://dblp.org/rec/conf/uss/ShenWGZLLZHDP021",
            "abstract": "As a fundamental communicative service, email is playing an important role in both individual and corporate communications, which also makes it one of the most frequently attack vectors. An email's authenticity is based on an authentication chain involving multiple protocols, roles and services, the inconsistency among which creates security threats. Thus, it depends on the weakest link of the chain, as any failed part can break the whole chain-based defense.This paper systematically analyzes the transmission of an email and identifies a series of new attacks capable of bypassing SPF, DKIM, DMARC and user-interface protections. In particular, by conducting a \"cocktail\" joint attack, more realistic emails can be forged to penetrate the celebrated email services, such as Gmail and Outlook. We conduct a large-scale experiment on 30 popular email services and 23 email clients, and find that all of them are vulnerable to certain types of new attacks. We have duly reported the identified vulnerabilities to the related email service providers, and received positive responses from 11 of them, including Gmail, Yahoo, iCloud and Alibaba. Furthermore, we propose key mitigating measures to defend against the new attacks. Therefore, this work is of great value for identifying email spoofing attacks and improving the email ecosystem's overall security.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-shen-kaiwen.pdf",
            "keywords": [
                "Email Authentication",
                "Email Spoofing",
                "SPF",
                "DKIM",
                "DMARC"
            ]
        },
        "url": "URL#1888193"
    },
    {
        "@score": "1",
        "@id": "1888195",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "230/4243",
                        "text": "Anatoly Shusterman"
                    },
                    {
                        "@pid": "55/8814",
                        "text": "Ayush Agarwal"
                    },
                    {
                        "@pid": "207/7931",
                        "text": "Sioli O&apos;Connell"
                    },
                    {
                        "@pid": "98/8283",
                        "text": "Daniel Genkin"
                    },
                    {
                        "@pid": "69/39",
                        "text": "Yossi Oren"
                    },
                    {
                        "@pid": "90/10901",
                        "text": "Yuval Yarom"
                    }
                ]
            },
            "title": "Prime+Probe 1, JavaScript 0: Overcoming Browser-based Side-Channel Defenses.",
            "venue": "USENIX Security Symposium",
            "pages": "2863-2880",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ShustermanAOGOY21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/shusterman",
            "url": "https://dblp.org/rec/conf/uss/ShustermanAOGOY21",
            "abstract": "The \"eternal war in cache\" has reached browsers, with multiple cache-based side-channel attacks and countermeasures being suggested. A common approach for countermeasures is to disable or restrict JavaScript features deemed essential for carrying out attacks.\nTo assess the effectiveness of this approach, in this work we seek to identify those JavaScript features which are essential for carrying out a cache-based attack. We develop a sequence of attacks with progressively decreasing dependency on JavaScript features, culminating in the first browser-based side-channel attack which is constructed entirely from Cascading Style Sheets (CSS) and HTML, and works even when script execution is completely blocked. We then show that  avoiding JavaScript  features makes our techniques architecturally agnostic,  resulting in microarchitectural website fingerprinting attacks that work across hardware platforms including Intel Core, AMD Ryzen, Samsung Exynos, and Apple M1 architectures.\nAs a final contribution, we evaluate our techniques in hardened browser environments including the Tor browser, DeterFox (Cao et al., CCS 2017), and Chrome Zero (Schwartz et al., NDSS 2018). We confirm that none of these approaches completely defend against our attacks. We further argue that the protections of Chrome Zero need to be more comprehensively applied, and that the performance and user experience of Chrome Zero will be severely degraded if this approach is taken.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-shusterman.pdf",
            "keywords": [
                "Browser Security",
                "Cache-based Attacks",
                "Side-channel Attacks",
                "JavaScript Limitations",
                "Microarchitectural Fingerprinting"
            ]
        },
        "url": "URL#1888195"
    },
    {
        "@score": "1",
        "@id": "1888196",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "286/5330",
                        "text": "Ravindu De Silva"
                    },
                    {
                        "@pid": "65/4357",
                        "text": "Mohamed Nabeel"
                    },
                    {
                        "@pid": "205/7762",
                        "text": "Charith Elvitigala"
                    },
                    {
                        "@pid": "115/8715",
                        "text": "Issa Khalil"
                    },
                    {
                        "@pid": "y/TingYu-1",
                        "text": "Ting Yu 0001"
                    },
                    {
                        "@pid": "01/3590",
                        "text": "Chamath Keppitiyagama"
                    }
                ]
            },
            "title": "Compromised or Attacker-Owned: A Large Scale Classification and Study of Hosting Domains of Malicious URLs.",
            "venue": "USENIX Security Symposium",
            "pages": "3721-3738",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SilvaNEKYK21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/desilva",
            "url": "https://dblp.org/rec/conf/uss/SilvaNEKYK21",
            "abstract": "The mitigation action against a malicious website may differ greatly depending on how that site is hosted. If it is hosted under a private apex domain, where all its subdomains and pages are under the apex domain owner\u2019s direct control, we could block at the apex domain level. If it is hosted under a public apex domain though (e.g., a web hosting service provider), it would be more appropriate to block at the subdo-main level. Further, for the former case, the private apex domain may be legitimate but compromised, or may be attacker-generated, which, again, would warrant different mitigation actions: attacker-owned apex domains could be blocked permanently, while only temporarily for compromised ones. In this paper, we study over eight hundred million Virus-Total (VT) URL scans from Aug. 1, 2019 to Nov. 18, 2019 and build the \ufb01rst content agnostic machine learning models to distinguish between the above mentioned different types of apex domains hosting malicious websites. Speci\ufb01cally, we \ufb01rst build a highly accurate model to distinguish between public and private apex domains. Then we build additional models to further distinguish compromised domains from attacker-owned ones. Utilizing our trained models, we conduct a large-scale study of the host domains of malicious websites . We observe that even though public apex domains are less than 1% of the apexes hosting malicious websites, they amount to a whopping 46.5% malicious web pages seen in VT URL feeds during our study period. 19.5% of these public malicious websites are compromised.",
            "keywords": [
                "Malicious URLs",
                "Apex Domain Classification",
                "Compromised Domains",
                "Attacker-Owned Domains",
                "URL Scanning Analysis"
            ]
        },
        "url": "URL#1888196",
        "sema_paperId": "91bba6db6dcad3f5cebbd2bd2633ff91ec56b73f"
    },
    {
        "@score": "1",
        "@id": "1888197",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "250/9298",
                        "text": "Akash Deep Singh"
                    },
                    {
                        "@pid": "67/136-1",
                        "text": "Luis Garcia 0001"
                    },
                    {
                        "@pid": "185/9311",
                        "text": "Joseph Noor"
                    },
                    {
                        "@pid": "s/ManiBSrivastava",
                        "text": "Mani B. Srivastava"
                    }
                ]
            },
            "title": "I Always Feel Like Somebody&apos;s Sensing Me! A Framework to Detect, Identify, and Localize Clandestine Wireless Sensors.",
            "venue": "USENIX Security Symposium",
            "pages": "1829-1846",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SinghGNS21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/singh",
            "url": "https://dblp.org/rec/conf/uss/SinghGNS21",
            "abstract": "Author(s): Singh, Akash Deep | Advisor(s): Srivastava, Mani B | Abstract: The increasing ubiquity of low-cost wireless sensors in smart homes and buildings has enabled users to easily deploy systems to remotely monitor and control their environments. However, this raises privacy concerns for third-party occupants, such as a hotel room guest who may be unaware of deployed clandestine sensors. Previous methods focused on specific modalities such as detecting cameras but do not provide a generalizable and comprehensive method to capture arbitrary sensors which may be \"spying\" on a user. In this work, we seek to determine whether one can walk in a room and detect any wireless sensor monitoring an individual. As such, we propose SnoopDog, a framework to not only detect wireless sensors that are actively monitoring a user, but also classify and localize each device. SnoopDog works by establishing causality between patterns in observable wireless traffic and a trusted sensor in the same space, e.g., an inertial measurement unit (IMU) that captures a user's movement. Once causality is established, SnoopDog performs packet inspection to inform the user about the monitoring device. Finally, SnoopDog localizes the clandestine device in a 2D plane using a novel trial-based localization technique. We evaluated SnoopDog across several devices and various modalities and were able to detect causality 96.6% percent of the time, classify suspicious devices with 100% accuracy, and localize devices to a sufficiently reduced sub-space.",
            "keywords": [
                "Wireless Sensor Detection",
                "Privacy Concerns",
                "Clandestine Sensors",
                "Device Localization",
                "Causality Establishment"
            ]
        },
        "url": "URL#1888197",
        "sema_paperId": "b8b0a98bede282ba38d36a8b770cfad2be40a52e"
    },
    {
        "@score": "1",
        "@id": "1888198",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "187/9138",
                        "text": "Sunbeom So"
                    },
                    {
                        "@pid": "222/5868",
                        "text": "Seongjoon Hong"
                    },
                    {
                        "@pid": "13/7537",
                        "text": "Hakjoo Oh"
                    }
                ]
            },
            "title": "SmarTest: Effectively Hunting Vulnerable Transaction Sequences in Smart Contracts through Language Model-Guided Symbolic Execution.",
            "venue": "USENIX Security Symposium",
            "pages": "1361-1378",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SoHO21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/so",
            "url": "https://dblp.org/rec/conf/uss/SoHO21",
            "abstract": "We present S MAR T EST , a novel symbolic execution technique for effectively hunting vulnerable transaction sequences in smart contracts. Because smart contracts are stateful programs whose states are altered by transactions, diagnosing and understanding nontrivial vulnerabilities requires generating sequences of transactions that demonstrate the \ufb02aws. However, \ufb01nding such vulnerable transaction sequences is challenging as the number of possible combinations of trans-actions is intractably large. As a result, most existing tools for smart contract analysis use abstractions and merely point out the locations of vulnerabilities, which in turn imposes a steep burden on users of understanding the bugs, or have limited power in generating transaction sequences. In this paper, we aim to overcome this challenge by combining symbolic execution with a language model for vulnerable transaction sequences, so that symbolic execution effectively prioritizes program paths that are likely to reveal vulnerabilities. Experimental results with real-world smart contracts show that S MAR T EST signi\ufb01cantly outperforms existing tools by \ufb01nding more vulnerable transaction sequences including critical zero-day vulnerabilities.",
            "keywords": [
                "Smart Contract Analysis",
                "Symbolic Execution",
                "Vulnerable Transaction Sequences",
                "Zero-Day Vulnerabilities",
                "Vulnerability Detection"
            ]
        },
        "url": "URL#1888198",
        "sema_paperId": "06c3a76315b6e17e353963a08abcfd6c21c7fa10"
    },
    {
        "@score": "1",
        "@id": "1888199",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "129/2856",
                        "text": "Jeongseok Son"
                    },
                    {
                        "@pid": "301/5882",
                        "text": "Griffin Prechter"
                    },
                    {
                        "@pid": "39/10311",
                        "text": "Rishabh Poddar"
                    },
                    {
                        "@pid": "91/275",
                        "text": "Raluca Ada Popa"
                    },
                    {
                        "@pid": "04/418",
                        "text": "Koushik Sen"
                    }
                ]
            },
            "title": "ObliCheck: Efficient Verification of Oblivious Algorithms with Unobservable State.",
            "venue": "USENIX Security Symposium",
            "pages": "2219-2236",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SonPPPS21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/son",
            "url": "https://dblp.org/rec/conf/uss/SonPPPS21",
            "abstract": "Encryption of secret data prevents an adversary from learning sensitive information by observing the transferred data. Even though the data itself is encrypted, however, an attacker can watch which locations of the memory, disk, and network are accessed and infer a signi\ufb01cant amount of secret information. To defend attacks based on this access pattern leakage, a number of oblivious algorithms have been devised. These algorithms transform the access pattern in a way that the access sequences are independent of the secret input data. Since oblivious algorithms tend to be slow, a go-to optimization for algorithm designers is to leverage space unobservable to the attacker . However, one can easily miss a subtle detail and violate the oblivious property in the process of doing so. In this paper, we propose ObliCheck, a checker verifying whether a given algorithm is indeed oblivious. In contrast to existing checkers, ObliCheck distinguishes observable and unobservable state of an algorithm. It employs symbolic execution to check whether all execution paths exhibit the same observable behavior. To achieve accuracy and ef\ufb01ciency, ObliCheck introduces two key techniques: Optimistic State Merging to quickly check if the algorithm is oblivious, and Iterative State Unmerging to iteratively re\ufb01ne its judgment if the algorithm is reported as not oblivious. ObliCheck achieves \u00d7 4850 of performance improvement over conventional symbolic execution without sacri\ufb01cing accuracy.",
            "keywords": [
                "Oblivious Algorithms",
                "Access Pattern Leakage",
                "Symbolic Execution",
                "Observable Behavior",
                "ObliCheck"
            ]
        },
        "url": "URL#1888199",
        "sema_paperId": "8c5997dff2553d0736ac0331ea213e0d6e0dcade"
    },
    {
        "@score": "1",
        "@id": "1888200",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "150/3945",
                        "text": "Liwei Song"
                    },
                    {
                        "@pid": "39/6266",
                        "text": "Prateek Mittal"
                    }
                ]
            },
            "title": "Systematic Evaluation of Privacy Risks of Machine Learning Models.",
            "venue": "USENIX Security Symposium",
            "pages": "2615-2632",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SongM21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/song",
            "url": "https://dblp.org/rec/conf/uss/SongM21",
            "abstract": "Machine learning models are prone to memorizing sensitive data, making them vulnerable to membership inference attacks in which an adversary aims to guess if an input sample was used to train the model. In this paper, we show that prior work on membership inference attacks may severely underestimate the privacy risks by relying solely on training custom neural network classifiers to perform attacks and focusing only on the aggregate results over data samples, such as the attack accuracy. To overcome these limitations, we first propose to benchmark membership inference privacy risks by improving existing non-neural network based inference attacks and proposing a new inference attack method based on a modification of prediction entropy. We also propose benchmarks for defense mechanisms by accounting for adaptive adversaries with knowledge of the defense and also accounting for the trade-off between model accuracy and privacy risks. Using our benchmark attacks, we demonstrate that existing defense approaches are not as effective as previously reported. \nNext, we introduce a new approach for fine-grained privacy analysis by formulating and deriving a new metric called the privacy risk score. Our privacy risk score metric measures an individual sample's likelihood of being a training member, which allows an adversary to perform membership inference attacks with high confidence. We experimentally validate the effectiveness of the privacy risk score metric and demonstrate that the distribution of the privacy risk score across individual samples is heterogeneous. Finally, we perform an in-depth investigation for understanding why certain samples have high privacy risk scores, including correlations with model sensitivity, generalization error, and feature embeddings. Our work emphasizes the importance of a systematic and rigorous evaluation of privacy risks of machine learning models.",
            "keywords": [
                "Privacy Risks",
                "Membership Inference Attacks",
                "Privacy Risk Score",
                "Model Sensitivity",
                "Defense Mechanisms"
            ]
        },
        "url": "URL#1888200",
        "sema_paperId": "fd6e4d74b8df1eed41a0915c5d760fe3cfa58278"
    },
    {
        "@score": "1",
        "@id": "1888201",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "169/8186",
                        "text": "Michael A. Specter"
                    },
                    {
                        "@pid": "h/JAlexHalderman",
                        "text": "J. Alex Halderman"
                    }
                ]
            },
            "title": "Security Analysis of the Democracy Live Online Voting System.",
            "venue": "USENIX Security Symposium",
            "pages": "3077-3092",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SpecterH21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/specter-security",
            "url": "https://dblp.org/rec/conf/uss/SpecterH21",
            "abstract": "Democracy Live\u2019s OmniBallot platform is a web-based system for blank ballot delivery, ballot marking, and online voting. In early 2020, three states\u2014Delaware, West Virginia, and New Jersey\u2014announced that they would allow certain voters to cast votes online using OmniBallot, but, despite the well established risks of Internet voting, the system has never before undergone a public, independent security review. We reverse engineered the client-side portion of Omni-Ballot, as used in Delaware, in order to detail the system\u2019s operation and analyze its security. We \ufb01nd that OmniBallot uses a simplistic approach to Internet voting that is vulnerable to vote manipulation by malware on the voter\u2019s device and by insiders or other attackers who can compromise Democracy Live, Amazon, Google, or Cloud\ufb02are. In addition, Democracy Live, which had no privacy policy prior to our work, receives sensitive personally identi\ufb01able information\u2014including the voter\u2019s identity, ballot selections, and browser \ufb01ngerprint\u2014 that could be used to target political ads or disinformation campaigns. Even when OmniBallot is used to mark ballots that will be printed and returned in the mail, the software sends the voter\u2019s identity and ballot choices to Democracy Live, an unnecessary risk that jeopardizes the secret ballot. We recommend changes to make the platform safer for ballot delivery and marking. However, we conclude that using OmniBallot for electronic ballot return represents a severe risk to election security and could allow attackers to alter election results without detection. In response to our \ufb01ndings, Delaware and New Jersey halted their use of OmniBallot for online voting, but it remains available in other jurisdictions, as do similar tools that likely face the same serious risks.",
            "keywords": [
                "Online Voting Security",
                "Internet Voting Risks",
                "OmniBallot Vulnerabilities",
                "Election Integrity",
                "Ballot Privacy"
            ]
        },
        "url": "URL#1888201",
        "sema_paperId": "789ddce673aa1d0a77f0fd4a2e88418b10e8c9ec"
    },
    {
        "@score": "1",
        "@id": "1888202",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "169/8186",
                        "text": "Michael A. Specter"
                    },
                    {
                        "@pid": "123/8680",
                        "text": "Sunoo Park"
                    },
                    {
                        "@pid": "74/4531-1",
                        "text": "Matthew Green 0001"
                    }
                ]
            },
            "title": "KeyForge: Non-Attributable Email from Forward-Forgeable Signatures.",
            "venue": "USENIX Security Symposium",
            "pages": "1755-1773",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SpecterP021",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/specter-keyforge",
            "url": "https://dblp.org/rec/conf/uss/SpecterP021",
            "abstract": "Email breaches are commonplace, and they expose a wealth of personal, business, and political data whose release may have devastating consequences. Such damage is compounded by email\u2019s strong attributability: today, any attacker who gains access to your email can easily prove to others that the stolen messages are authentic, a property arising from a necessary anti-spam/anti-spoo\ufb01ng protocol called DKIM. This greatly increases attackers\u2019 capacity to do harm by selling the stolen information to third parties, blackmail, or publicly releasing intimate or sensitive messages \u2014 all with built-in cryptographic proof of authenticity. This paper introduces non-attributable email , which guarantees that a wide class of adversaries are unable to convince discerning third parties of the authenticity of stolen emails. We formally de\ufb01ne non-attributability, and present two system proposals \u2014 KeyForge and Time-Forge \u2014 that provably achieve non-attributability while maintaining the important spam/spoo\ufb01ng protections currently provided by DKIM. Finally, we implement both and evaluate their speed and bandwidth performance overhead. We demonstrate the practicality of KeyForge, which achieves reasonable veri\ufb01cation overhead while signing faster and requiring 42% less bandwidth per message than DKIM\u2019s RSA-2048.",
            "keywords": [
                "Non-Attributable Email",
                "Email Security",
                "Forward-Forgeable Signatures",
                "Data Breaches",
                "DKIM"
            ]
        },
        "url": "URL#1888202",
        "sema_paperId": "14548c43809caeca4825433304ba9cf7e380a6e2"
    },
    {
        "@score": "1",
        "@id": "1888203",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "117/7980",
                        "text": "Marco Squarcina"
                    },
                    {
                        "@pid": "154/7915",
                        "text": "Mauro Tempesta"
                    },
                    {
                        "@pid": "213/8814",
                        "text": "Lorenzo Veronese"
                    },
                    {
                        "@pid": "89/9526",
                        "text": "Stefano Calzavara"
                    },
                    {
                        "@pid": "25/3571",
                        "text": "Matteo Maffei"
                    }
                ]
            },
            "title": "Can I Take Your Subdomain? Exploring Same-Site Attacks in the Modern Web.",
            "venue": "USENIX Security Symposium",
            "pages": "2917-2934",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SquarcinaTVCM21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/squarcina",
            "url": "https://dblp.org/rec/conf/uss/SquarcinaTVCM21",
            "abstract": "Related-domain attackers control a sibling domain of their target web application, e.g., as the result of a subdomain takeover. Despite their additional power over traditional web attackers, related-domain attackers received only limited attention from the research community. In this paper we de\ufb01ne and quantify for the \ufb01rst time the threats that related-domain attackers pose to web application security. In particular, we \ufb01rst clarify the capabilities that related-domain attackers can acquire through different attack vectors, showing that different instances of the related-domain attacker concept are worth attention. We then study how these capabilities can be abused to compromise web application security by focusing on different angles, including cookies, CSP, CORS, postMessage, and domain relaxation. By building on this framework, we report on a large-scale security measurement on the top 50k domains from the Tranco list that led to the discovery of vulnerabilities in 887 sites, where we quanti\ufb01ed the threats posed by related-domain attackers to popular web applications.",
            "keywords": [
                "Related-Domain Attackers",
                "Web Application Vulnerabilities",
                "Same-Site Attacks",
                "Subdomain Takeover",
                "Security Measurement"
            ]
        },
        "url": "URL#1888203",
        "sema_paperId": "d8ddc9fb26837b917171de576085ad08bd19440e"
    },
    {
        "@score": "1",
        "@id": "1888204",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "183/6724",
                        "text": "Milan Stute"
                    },
                    {
                        "@pid": "248/1693",
                        "text": "Alexander Heinrich"
                    },
                    {
                        "@pid": "301/5907",
                        "text": "Jannik Lorenz"
                    },
                    {
                        "@pid": "95/1816",
                        "text": "Matthias Hollick"
                    }
                ]
            },
            "title": "Disrupting Continuity of Apple&apos;s Wireless Ecosystem Security: New Tracking, DoS, and MitM Attacks on iOS and macOS Through Bluetooth Low Energy, AWDL, and Wi-Fi.",
            "venue": "USENIX Security Symposium",
            "pages": "3917-3934",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/StuteHLH21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/stute",
            "url": "https://dblp.org/rec/conf/uss/StuteHLH21",
            "abstract": "Apple controls one of the largest mobile ecosystems, with 1.5 billion active devices worldwide, and offers twelve proprietary wireless Continuity services. Previous works have unveiled several security and privacy issues in the involved protocols. These works extensively studied AirDrop while the coverage of the remaining vast Continuity service space is still low. To facilitate the cumbersome reverse-engineering process, we describe the \ufb01rst guide on how to approach a structured analysis of the involved protocols using several vantage points available on macOS. Also, we develop a toolkit to automate parts of this otherwise manual process. Based on this guide, we analyze the full protocol stacks involved in three Continuity services, in particular, Handoff (HO), Universal Clipboard (UC), and Wi-Fi Password Sharing (PWS). We discover several vulnerabilities spanning from Bluetooth Low Energy (BLE) advertisements to Apple\u2019s proprietary authentication protocols. These \ufb02aws allow for device tracking via HO\u2019s mDNS responses, a denial-of-service (DoS) attack on HO and UC, a DoS attack on PWS that prevents Wi-Fi password entry, and a machine-in-the-middle (MitM) attack on PWS that connects a target to an attacker-controlled Wi-Fi network. Our PoC implementations demonstrate that the attacks can be mounted using affordable off-the-shelf hardware ($20 micro:bit and a Wi-Fi card). Finally, we suggest practical mitigations and share our \ufb01ndings with Apple, who have started to release \ufb01xes through iOS and macOS updates.",
            "keywords": [
                "Apple Wireless Continuity",
                "Bluetooth Low Energy",
                "Denial-of-Service Attacks",
                "Man-in-the-Middle Attacks",
                "Device Tracking Vulnerabilities"
            ]
        },
        "url": "URL#1888204",
        "sema_paperId": "37b7352a7a0edcbf9c8b2ab290c3483dff39578d"
    },
    {
        "@score": "1",
        "@id": "1888205",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "214/2382",
                        "text": "Liya Su"
                    },
                    {
                        "@pid": "148/9731",
                        "text": "Xinyue Shen"
                    },
                    {
                        "@pid": "247/3624",
                        "text": "Xiangyu Du"
                    },
                    {
                        "@pid": "129/1113",
                        "text": "Xiaojing Liao"
                    },
                    {
                        "@pid": "06/6268",
                        "text": "XiaoFeng Wang 0001"
                    },
                    {
                        "@pid": "34/8412",
                        "text": "Luyi Xing"
                    },
                    {
                        "@pid": "10/8471",
                        "text": "Baoxu Liu"
                    }
                ]
            },
            "title": "Evil Under the Sun: Understanding and Discovering Attacks on Ethereum Decentralized Applications.",
            "venue": "USENIX Security Symposium",
            "pages": "1307-1324",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SuSDL0XL21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/su",
            "url": "https://dblp.org/rec/conf/uss/SuSDL0XL21",
            "abstract": "The popularity of Ethereum decentralized applications (Dapps) also brings in new security risks: it has been re-ported that these Dapps have been under various kinds of attacks from cybercriminals to gain pro\ufb01t. To the best of our knowledge, little has been done so far to understand this new cybercrime, in terms of its scope, criminal footprints and attack operational intents, not to mention any efforts to investigate these attack incidents automatically on a large scale. In this paper, we performed the \ufb01rst measurement study on real-world Dapp attack instances to recover critical threat intelligence (e.g., kill chain and attack patterns). Utilizing such threat intelligence, we proposed the \ufb01rst technique DE-FIER to automatically investigate attack incidents on a large scale. Running DEFIER on 2.3 million transactions from 104 Ethereum on-chain Dapps, we were able to identify 476,342 exploit transactions on 85 target Dapps, which related to 75 0-day victim Dapps and 17K previously-unknown attacker EOAs. To the best of our knowledge, it is the largest Ethereum on-chain Dapp attack incidents dataset ever reported.",
            "keywords": [
                "Ethereum Dapps",
                "Cybercrime",
                "Attack Patterns",
                "Threat Intelligence",
                "Automated Incident Investigation"
            ]
        },
        "url": "URL#1888205",
        "sema_paperId": "931bd24d5903cff1c93fbae7d3afaf551ee64bd3"
    },
    {
        "@score": "1",
        "@id": "1888206",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "167/2164",
                        "text": "Zhibo Sun"
                    },
                    {
                        "@pid": "72/10989",
                        "text": "Adam Oest"
                    },
                    {
                        "@pid": "143/1850",
                        "text": "Penghui Zhang"
                    },
                    {
                        "@pid": "11/3908",
                        "text": "Carlos E. Rubio-Medrano"
                    },
                    {
                        "@pid": "150/5198",
                        "text": "Tiffany Bao"
                    },
                    {
                        "@pid": "127/9829",
                        "text": "Ruoyu Wang 0001"
                    },
                    {
                        "@pid": "11/7704-1",
                        "text": "Ziming Zhao 0001"
                    },
                    {
                        "@pid": "119/7712",
                        "text": "Yan Shoshitaishvili"
                    },
                    {
                        "@pid": "28/8280",
                        "text": "Adam Doup\u00e9"
                    },
                    {
                        "@pid": "a/GailJoonAhn",
                        "text": "Gail-Joon Ahn"
                    }
                ]
            },
            "title": "Having Your Cake and Eating It: An Analysis of Concession-Abuse-as-a-Service.",
            "venue": "USENIX Security Symposium",
            "pages": "4169-4186",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SunOZRB00SDA21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/sun-zhibo",
            "url": "https://dblp.org/rec/conf/uss/SunOZRB00SDA21",
            "abstract": "Concession Abuse as a Service (CAaaS) is a growing scam service in underground forums that defrauds online retailers through the systematic abuse of their return policies (via social engineering) and the exploitation of loopholes in company protocols. Timely detection of such scams is dif\ufb01cult as they are fueled by an extensive suite of criminal services, such as credential theft, document forgery, and fake shipments. Ultimately, the scam enables malicious actors to steal arbitrary goods from merchants with minimal investment. In this paper, we perform in-depth manual and automated analysis of public and private messages from four large underground forums to identify the malicious actors involved in CAaaS, carefully study the operation of the scam, and de\ufb01ne attributes to \ufb01ngerprint the scam and inform mitigation strategies. Additionally, we surveyed users to evaluate their attitudes toward these mitigations and understand the factors that merchants should consider before implementing these strategies. We \ufb01nd that the scam is easy to scale\u2014and can bypass traditional anti-fraud efforts\u2014and thus poses a notable threat to online retailers.",
            "keywords": [
                "Concession Abuse as a Service",
                "Online Retail Fraud",
                "Return Policy Exploitation",
                "Social Engineering Scams",
                "Mitigation Strategies"
            ]
        },
        "url": "URL#1888206",
        "sema_paperId": "58bbcd3d116f9717bdb3381bb1c0b0d631dcfaef"
    },
    {
        "@score": "1",
        "@id": "1888207",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "184/5980",
                        "text": "Zhichuang Sun"
                    },
                    {
                        "@pid": "123/7388",
                        "text": "Ruimin Sun"
                    },
                    {
                        "@pid": "81/7428",
                        "text": "Long Lu"
                    },
                    {
                        "@pid": "31/3833",
                        "text": "Alan Mislove"
                    }
                ]
            },
            "title": "Mind Your Weight(s): A Large-scale Study on Insufficient Machine Learning Model Protection in Mobile Apps.",
            "venue": "USENIX Security Symposium",
            "pages": "1955-1972",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SunSLM21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/sun-zhichuang",
            "url": "https://dblp.org/rec/conf/uss/SunSLM21",
            "abstract": "On-device machine learning (ML) is quickly gaining popularity among mobile apps. It allows offline model inference while preserving user privacy. However, ML models, considered as core intellectual properties of model owners, are now stored on billions of untrusted devices and subject to potential thefts. Leaked models can cause both severe financial loss and security consequences. \nThis paper presents the first empirical study of ML model protection on mobile devices. Our study aims to answer three open questions with quantitative evidence: How widely is model protection used in apps? How robust are existing model protection techniques? How much can (stolen) models cost? To that end, we built a simple app analysis pipeline and analyzed 46,753 popular apps collected from the US and Chinese app markets. We identified 1,468 ML apps spanning all popular app categories. We found that, alarmingly, 41% of ML apps do not protect their models at all, which can be trivially stolen from app packages. Even for those apps that use model protection or encryption, we were able to extract the models from 66% of them via unsophisticated dynamic analysis techniques. The extracted models are mostly commercial products and used for face recognition, liveness detection, ID/bank card recognition, and malware detection. We quantitatively estimated the potential financial impact of a leaked model, which can amount to millions of dollars for different stakeholders. \nOur study reveals that on-device models are currently at high risk of being leaked; attackers are highly motivated to steal such models. Drawn from our large-scale study, we report our insights into this emerging security problem and discuss the technical challenges, hoping to inspire future research on robust and practical model protection for mobile devices.",
            "keywords": [
                "On-device Machine Learning",
                "Model Protection",
                "Mobile App Security",
                "Model Theft",
                "Financial Impact of Leaked Models"
            ]
        },
        "url": "URL#1888207",
        "sema_paperId": "14905fdf49fc73edb099f331c72546ab0e3d2242"
    },
    {
        "@score": "1",
        "@id": "1888208",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "224/9374",
                        "text": "Seyed Mohammadjavad Seyed Talebi"
                    },
                    {
                        "@pid": "154/8284-1",
                        "text": "Zhihao Yao 0001"
                    },
                    {
                        "@pid": "20/8069",
                        "text": "Ardalan Amiri Sani"
                    },
                    {
                        "@pid": "31/8302",
                        "text": "Zhiyun Qian"
                    },
                    {
                        "@pid": "97/5374",
                        "text": "Daniel Austin"
                    }
                ]
            },
            "title": "Undo Workarounds for Kernel Bugs.",
            "venue": "USENIX Security Symposium",
            "pages": "2381-2398",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/TalebiYSQA21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/talebi",
            "url": "https://dblp.org/rec/conf/uss/TalebiYSQA21",
            "abstract": "OS kernels are full of bugs resulting in security, reliability, and usability issues. Several kernel fuzzers have recently been developed to find these bugs and have proven to be effective. Yet, bugs take several months to be patched once they are discovered. In this window of vulnerability, bugs continue to pose concerns. We present workarounds for kernel bugs, called bowknots, which maintain the functionality of the system even when bugs are triggered, are applicable to many kernel bugs, do not cause noticeable performance overhead, and have a small kernel footprint. The key idea behind bowknots is to undo the side effects of the in-flight syscall that triggers a bug, effectively neutralizing the syscall. We also present a static analysis tool, called Hecaton, that generates bowknots automatically and inserts them into the kernel. Through extensive evaluations on the kernel of Android devices as well as x86 upstream kernels, we demonstrate that bowknots are effective in mitigating kernel bugs and vulnerabilities. We also show that Hecaton is capable of generating the right bowknots fully automatically in majority of cases, and requires minimal help from the analyst for the rest. Finally, we demonstrate the benefits of bowknots in improving the efficiency of kernel fuzzing by eliminating repetitive reboots.",
            "keywords": [
                "Kernel Bugs",
                "Operating System Kernels",
                "Workarounds",
                "Bowknots",
                "Static Analysis Tool"
            ]
        },
        "url": "URL#1888208",
        "sema_paperId": "7c92c47721cb7dbada47b712372110a300f39986"
    },
    {
        "@score": "1",
        "@id": "1888209",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "89/6413",
                        "text": "Xin Tan"
                    },
                    {
                        "@pid": "48/2168-9",
                        "text": "Yuan Zhang 0009"
                    },
                    {
                        "@pid": "150/6685",
                        "text": "Xiyu Yang"
                    },
                    {
                        "@pid": "67/10639",
                        "text": "Kangjie Lu"
                    },
                    {
                        "@pid": "02/1640-2",
                        "text": "Min Yang 0002"
                    }
                ]
            },
            "title": "Detecting Kernel Refcount Bugs with Two-Dimensional Consistency Checking.",
            "venue": "USENIX Security Symposium",
            "pages": "2471-2488",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Tan0YL021",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/tan",
            "url": "https://dblp.org/rec/conf/uss/Tan0YL021",
            "abstract": "In the Linux kernel, reference counting (refcount) has become a default mechanism that manages resource objects. A refcount of a tracked object is incremented when a new reference is assigned and decremented when a reference becomes invalid. Since the kernel manages a large number of shared resources, refcount is prevalent. Due to the inherent complexity of the kernel and resource sharing, developers often fail to properly update refcounts, leading to refcount bugs. Researchers have shown that refcount bugs can cause critical security impacts like privilege escalation; however, the detection of refcount bugs remains an open problem. In this paper, we propose CID , a new mechanism that employs two-dimensional consistency checking to automatically detect refcount bugs. By checking if callers consistently use a refcount function, CID detects deviating cases as potential bugs; by checking how a caller uses a refcount function, CID infers the condition-aware rules for the function to correspondingly operate the refcount, and thus a violating case is a potential bug. More importantly, CID \u2019s consistency checking does not require complicated semantic understanding, inter-procedural data-\ufb02ow tracing, or refcount-operation reasoning. CID also features an automated mechanism that systematically identi\ufb01es refcount \ufb01elds and functions in the whole kernel. We implement CID and apply it to the Linux kernel. The tool found 44 new refcount bugs that may cause severe security issues, most of which have been con\ufb01rmed by the maintainers.",
            "keywords": [
                "Linux Kernel",
                "Reference Counting",
                "Refcount Bugs",
                "Consistency Checking",
                "Security Vulnerabilities"
            ]
        },
        "url": "URL#1888209",
        "sema_paperId": "ba8b5634d56919d903106f13a4c94ff878e82f7a"
    },
    {
        "@score": "1",
        "@id": "1888210",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "77/1147-1",
                        "text": "Di Tang 0001"
                    },
                    {
                        "@pid": "06/6268",
                        "text": "XiaoFeng Wang 0001"
                    },
                    {
                        "@pid": "90/3951",
                        "text": "Haixu Tang"
                    },
                    {
                        "@pid": "66/6560",
                        "text": "Kehuan Zhang"
                    }
                ]
            },
            "title": "Demon in the Variant: Statistical Analysis of DNNs for Robust Backdoor Contamination Detection.",
            "venue": "USENIX Security Symposium",
            "pages": "1541-1558",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Tang0TZ21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/tang-di",
            "url": "https://dblp.org/rec/conf/uss/Tang0TZ21",
            "abstract": "A security threat to deep neural networks (DNN) is backdoor contamination, in which an adversary poisons the training data of a target model to inject a Trojan so that images carrying a specific trigger will always be classified into a specific label. Prior research on this problem assumes the dominance of the trigger in an image's representation, which causes any image with the trigger to be recognized as a member in the target class. Such a trigger also exhibits unique features in the representation space and can therefore be easily separated from legitimate images. Our research, however, shows that simple target contamination can cause the representation of an attack image to be less distinguishable from that of legitimate ones, thereby evading existing defenses against the backdoor infection. \nIn our research, we show that such a contamination attack actually subtly changes the representation distribution for the target class, which can be captured by a statistic analysis. More specifically, we leverage an EM algorithm to decompose an image into its identity part (e.g., person, traffic sign) and variation part within a class (e.g., lighting, poses). Then we analyze the distribution in each class, identifying those more likely to be characterized by a mixture model resulted from adding attack samples to the legitimate image pool. Our research shows that this new technique effectively detects data contamination attacks, including the new one we propose, and is also robust against the evasion attempts made by a knowledgeable adversary.",
            "keywords": [
                "Backdoor Contamination",
                "Trojan Injection",
                "Representation Distribution",
                "Data Contamination Detection",
                "Evasion Attacks"
            ]
        },
        "url": "URL#1888210",
        "sema_paperId": "fde9b77b36f678f4455e13a63d1f8d8148187f2a"
    },
    {
        "@score": "1",
        "@id": "1888211",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "199/7027",
                        "text": "Zhe Tao"
                    },
                    {
                        "@pid": "81/10809",
                        "text": "Aseem Rastogi"
                    },
                    {
                        "@pid": "170/4838",
                        "text": "Naman Gupta"
                    },
                    {
                        "@pid": "48/1784",
                        "text": "Kapil Vaswani"
                    },
                    {
                        "@pid": "68/1945",
                        "text": "Aditya V. Thakur"
                    }
                ]
            },
            "title": "DICE*: A Formally Verified Implementation of DICE Measured Boot.",
            "venue": "USENIX Security Symposium",
            "pages": "1091-1107",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/TaoRGVT21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/tao",
            "url": "https://dblp.org/rec/conf/uss/TaoRGVT21",
            "abstract": "Measured boot is an important class of boot protocols that ensure that each layer of firmware and software in a device\u2019s chain of trust is measured, and the measurements are reliably recorded for subsequent verification. This paper presents DICE?, a formal specification as well as a formally verified implementation of DICE, an industry standard measured boot protocol. DICE? is proved to be functionally correct, memorysafe, and resistant to timingand cache-based side-channels. A key component of DICE? is a verified certificate creation library for a fragment of X.509. We have integrated DICE? into the boot firmware of an STM32H753ZI micro-controller. Our evaluation shows that using a fully verified implementation has minimal to no effect on the code size and boot time when compared to an existing unverified implementation.",
            "keywords": [
                "Measured Boot",
                "DICE Protocol",
                "Formal Verification",
                "Microcontroller Security",
                "Certificate Creation Library"
            ]
        },
        "url": "URL#1888211",
        "sema_paperId": "7203660a3b04a2b23f507ca87b8eda9208272ddd"
    },
    {
        "@score": "1",
        "@id": "1888213",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "72/2304",
                        "text": "Mary Theofanos"
                    },
                    {
                        "@pid": "33/993",
                        "text": "Yee-Yin Choong"
                    },
                    {
                        "@pid": "301/5915",
                        "text": "Olivia Murphy"
                    }
                ]
            },
            "title": "&apos;Passwords Keep Me Safe&apos; - Understanding What Children Think about Passwords.",
            "venue": "USENIX Security Symposium",
            "pages": "19-35",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/TheofanosCM21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/theofanos",
            "url": "https://dblp.org/rec/conf/uss/TheofanosCM21",
            "abstract": "Children use technology from a very young age, and often have to authenticate. The goal of this study is to explore children\u2019s practices, perceptions, and knowledge regarding passwords. Given the limited work to date and the fact that the world\u2019s cyber posture and culture will be dependent on today\u2019s youth, it is imperative to conduct cybersecurity research with children. We conducted the first large-scale survey of 1,505 3 rd to 12 th graders from schools across the United States. Not surprisingly, children have fewer passwords than adults. We found that children have complicated relationships with passwords: on one hand, their perceptions about passwords and statements about password behavior are appropriate; on the other hand, however, they simultaneously do not tend to make strong passwords, and practice bad password behavior such as sharing passwords with friends. We conclude with a call for cybersecurity education to bridge the gap between students\u2019 password knowledge with their password behavior, while continuing to provide and promote security understandings.",
            "keywords": [
                "Cybersecurity Education",
                "Children's Password Behavior",
                "Password Management",
                "User Authentication",
                "Password Knowledge Gap"
            ]
        },
        "url": "URL#1888213",
        "sema_paperId": "1744730f73cd46ecab8ba1987f17302006fcbdd0"
    },
    {
        "@score": "1",
        "@id": "1888215",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "205/2241",
                        "text": "William J. Tolley"
                    },
                    {
                        "@pid": "301/5885",
                        "text": "Beau Kujath"
                    },
                    {
                        "@pid": "154/3627",
                        "text": "Mohammad Taha Khan"
                    },
                    {
                        "@pid": "50/7563",
                        "text": "Narseo Vallina-Rodriguez"
                    },
                    {
                        "@pid": "c/JRCrandall",
                        "text": "Jedidiah R. Crandall"
                    }
                ]
            },
            "title": "Blind In/On-Path Attacks and Applications to VPNs.",
            "venue": "USENIX Security Symposium",
            "pages": "3129-3146",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/TolleyKKVC21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/tolley",
            "url": "https://dblp.org/rec/conf/uss/TolleyKKVC21",
            "abstract": "Protecting network protocols within an encrypted tunnel, using technologies such as Virtual Private Networks (VPNs), is increasingly important to millions of users needing solutions to evade censorship or protect their traf\ufb01c against in/on-path observers/attackers. In this paper, we present a series of attacks from two threat models: an attacker that can inject spoofed packets into the network stack of a VPN client (called client-side), and an attacker that can spoof packets on the Internet and send them to a VPN server (called server-side). In both cases, we assume that the attacker is in/on-path, and can count encrypted bytes or packets over time. In both threat models, we demonstrate attacks to infer the existence of, interfere with, or inject data into TCP connections forwarded through the encrypted VPN tunnel. In the server-side threat model, we also demonstrate an attack to hijack tunneled DNS queries and completely remove the protections of the VPN tunnel. For the attacks presented in this paper, we (1) assess their feasibility in terms of packet rates and timing; (2) test their applicability against a broad range of VPN technologies, types, and vendors; and (3) consider practical issues with respect to real-world attacks. We followed an ethical disclosure process for all attacks presented in this paper. Client-side attacks were addressed with two CVEs and partially mitigated by a series of updates from some operating system and VPN client vendors. Server-side attacks have not been addressed and are still feasible with all operating systems and VPN servers that we tested.",
            "keywords": [
                "VPN Security",
                "Network Attacks",
                "In/On-Path Observers",
                "Packet Injection",
                "DNS Hijacking"
            ]
        },
        "url": "URL#1888215",
        "sema_paperId": "b67b24bc0d8562a5f0b7bd071eb0014e5b4882db"
    },
    {
        "@score": "1",
        "@id": "1888216",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "169/2279",
                        "text": "Christof Ferreira Torres"
                    },
                    {
                        "@pid": "211/3955",
                        "text": "Ramiro Camino"
                    },
                    {
                        "@pid": "05/6228",
                        "text": "Radu State"
                    }
                ]
            },
            "title": "Frontrunner Jones and the Raiders of the Dark Forest: An Empirical Study of Frontrunning on the Ethereum Blockchain.",
            "venue": "USENIX Security Symposium",
            "pages": "1343-1359",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/TorresCS21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/torres",
            "url": "https://dblp.org/rec/conf/uss/TorresCS21",
            "abstract": "Ethereum prospered the inception of a plethora of smart contract applications, ranging from gambling games to decentralized finance. However, Ethereum is also considered a highly adversarial environment, where vulnerable smart contracts will eventually be exploited. Recently, Ethereum's pool of pending transaction has become a far more aggressive environment. In the hope of making some profit, attackers continuously monitor the transaction pool and try to frontrun their victims' transactions by either displacing or suppressing them, or strategically inserting their transactions. This paper aims to shed some light into what is known as a dark forest and uncover these predators' actions. We present a methodology to efficiently measure the three types of frontrunning: displacement, insertion, and suppression. We perform a largescale analysis on more than 11M blocks and identify almost 200K attacks with an accumulated profit of 18.41M USD for the attackers, providing evidence that frontrunning is both, lucrative and a prevalent issue.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-torres.pdf",
            "keywords": [
                "Ethereum Blockchain",
                "Frontrunning",
                "Smart Contracts",
                "Transaction Pool Attacks",
                "Dark Forest"
            ]
        },
        "url": "URL#1888216"
    },
    {
        "@score": "1",
        "@id": "1888217",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "216/6267",
                        "text": "Muoi Tran"
                    },
                    {
                        "@pid": "301/5862",
                        "text": "Akshaye Shenoi"
                    },
                    {
                        "@pid": "75/8333",
                        "text": "Min Suk Kang"
                    }
                ]
            },
            "title": "On the Routing-Aware Peering against Network-Eclipse Attacks in Bitcoin.",
            "venue": "USENIX Security Symposium",
            "pages": "1253-1270",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/TranSK21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/tran",
            "url": "https://dblp.org/rec/conf/uss/TranSK21",
            "abstract": "Safeguarding blockchain peer-to-peer (P2P) networks is more critical than ever in light of recent network attacks. Bitcoin has been successfully handling traditional Sybil and eclipse attacks; however, a recent Erebus attack [57] shows that effectively eclipsing a Bitcoin node is possible when the attack is combined with a network-Sybil capability; i.e., a malicious transit network can create millions or more Sybil identities. Given the immediate availability and stealthiness of the Erebus attack, Bitcoin Core has quickly implemented a few simple protocol/parameter changes to mitigate it. Our large-scale evaluations of these quick patches and three similar carefully-designed protocol tweaks confirm that, unfortunately, no simple solution can effectively handle the attack. This paper focuses on a more fundamental solution called routing-aware peering (or RAP), a proven silver bullet in detecting and circumventing similar network adversaries in other P2P networks. However, we show that, contrary to our expectation, preventing the Erebus attacks with RAP is only wishful thinking. We discover that Erebus adversaries can exploit a tiny portion of route inference errors in any RAP implementations, which gives an asymmetric advantage to the network adversaries and renders all RAP approaches ineffective. To that end, we propose an integrated defense framework that composes the available simple protocol tweaks and RAP implementation. In particular, we show that a highly customizable defense profile is required for individual Bitcoin nodes because RAP\u2019s efficacy depends significantly on where a Bitcoin node is located on the Internet topology. We present an algorithm that outputs a custom optimal defense profile that prevents most of Erebus attacks from the top-100 large transit networks.",
            "keywords": [
                "Blockchain Security",
                "Erebus Attack",
                "Routing-Aware Peering",
                "Network-Eclipse Attacks",
                "Defense Framework"
            ]
        },
        "url": "URL#1888217",
        "sema_paperId": "db7f8535fe9dba9ff23b19ca0d574cf54dee9fe5"
    },
    {
        "@score": "1",
        "@id": "1888218",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "195/4184",
                        "text": "Dimitrios Tychalas"
                    },
                    {
                        "@pid": "267/9798",
                        "text": "Hadjer Benkraouda"
                    },
                    {
                        "@pid": "56/1494",
                        "text": "Michail Maniatakos"
                    }
                ]
            },
            "title": "ICSFuzz: Manipulating I/Os and Repurposing Binary Code to Enable Instrumented Fuzzing in ICS Control Applications.",
            "venue": "USENIX Security Symposium",
            "pages": "2847-2862",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/TychalasBM21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/tychalas",
            "url": "https://dblp.org/rec/conf/uss/TychalasBM21",
            "abstract": "Industrial Control Systems (ICS) have seen a rapid proliferation in the last decade ampli\ufb01ed by the advent of the 4th Industrial Revolution. At the same time, several notable cyber-security incidents in industrial environments have underlined the lack of depth in security evaluation of industrial devices such as Programmable Logic Controllers (PLC). Modern PLCs are based on widely used microprocessors and deploy commodity operating systems (e.g., ARM on Linux). Thus, threats from the information technology domain can be readily ported to industrial environments. PLC application bi-naries in particular have never been considered as regular programs able to introduce traditional security threats, such as buffer over\ufb02ows. In this work, we investigate the feasibility of exploiting PLC binaries as well as their surrounding PLC-speci\ufb01c environment. We examine binaries produced by all available IEC 61131-3 control system programming languages for compilation-based differences and introduced vulnerabilities. Driven by this analysis, we develop a fuzzing framework to perform security evaluation of the PLC binaries along with the host functions they interact with. Fuzzing such non-executable binaries is non-trivial, as they operate with real-time constraints and receive their inputs from peripherals. To prove the correctness of our fuzzing tool, we use a database of in-house developed binaries in addition to functional control applications collected from online repositories. We showcase the ef\ufb01cacy of our technique by demonstrating uncovered vulnerabilities in both control application binaries and their runtime system. Furthermore, we demonstrate an exploitation methodology for an in-house as well as a regular control binary, based on the uncovered vulnerabilities.",
            "keywords": [
                "Industrial Control Systems",
                "Programmable Logic Controllers",
                "Fuzzing Framework",
                "Binary Vulnerabilities",
                "Real-time Constraints"
            ]
        },
        "url": "URL#1888218",
        "sema_paperId": "91fb808f9becab09431e167f20397e8b2104e27c"
    },
    {
        "@score": "1",
        "@id": "1888219",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "205/3765",
                        "text": "Benjamin E. Ujcich"
                    },
                    {
                        "@pid": "164/3347",
                        "text": "Samuel Jero"
                    },
                    {
                        "@pid": "137/3754",
                        "text": "Richard Skowyra"
                    },
                    {
                        "@pid": "126/3601",
                        "text": "Adam Bates 0001"
                    },
                    {
                        "@pid": "s/WilliamHSanders",
                        "text": "William H. Sanders"
                    },
                    {
                        "@pid": "14/5114",
                        "text": "Hamed Okhravi"
                    }
                ]
            },
            "title": "Causal Analysis for Software-Defined Networking Attacks.",
            "venue": "USENIX Security Symposium",
            "pages": "3183-3200",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/UjcichJS0SO21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/ujcich",
            "url": "https://dblp.org/rec/conf/uss/UjcichJS0SO21",
            "abstract": ",",
            "keywords": [
                "Software-Defined Networking",
                "Causal Analysis",
                "Network Attacks",
                "Threat Detection",
                "Vulnerability Assessment"
            ]
        },
        "url": "URL#1888219",
        "sema_paperId": "f5137d7e1f1c32d7fc30ee9ed903f9d9de8b5570"
    },
    {
        "@score": "1",
        "@id": "1888220",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "190/7677",
                        "text": "Enis Ulqinaku"
                    },
                    {
                        "@pid": "172/9115",
                        "text": "Hala Assal"
                    },
                    {
                        "@pid": "157/0157",
                        "text": "AbdelRahman Abdou"
                    },
                    {
                        "@pid": "26/2669",
                        "text": "Sonia Chiasson"
                    },
                    {
                        "@pid": "51/1639",
                        "text": "Srdjan Capkun"
                    }
                ]
            },
            "title": "Is Real-time Phishing Eliminated with FIDO? Social Engineering Downgrade Attacks against FIDO Protocols.",
            "venue": "USENIX Security Symposium",
            "pages": "3811-3828",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/UlqinakuAACC21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/ulqinaku",
            "url": "https://dblp.org/rec/conf/uss/UlqinakuAACC21",
            "abstract": "FIDO's U2F is a web-authentication mechanism designed to mitigate real-time phishing\u2014an attack that undermines multi-factor authentication by allowing an attacker to relay second-factor one-time tokens from the victim user to the legitimate website in real-time. A U2F dongle is simple to use, and is designed to restrain users from using it incorrectly. We show that social engineering attacks allow an adversary to downgrade FIDO's U2F to alternative authentication mechanisms. Websites allow such alternatives to handle dongle malfunction or loss. All FIDO-supporting websites in Alexa's top 100 allow choosing alternatives to FIDO, and are thus potentially vulnerable to real-time phishing attacks. We crafted a phishing website that mimics Google login's page and implements a FIDO-downgrade attack. We then ran a carefully-designed user study to test the effect on users. We found that, when using FIDO as their second authentication factor, 55% of participants fell for real-time phishing, and another 35% would potentially be susceptible to the attack in practice.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-ulqinaku.pdf",
            "keywords": [
                "FIDO Protocols",
                "Real-time Phishing",
                "Social Engineering",
                "Authentication Downgrade",
                "User Vulnerability"
            ]
        },
        "url": "URL#1888220"
    },
    {
        "@score": "1",
        "@id": "1888221",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "62/11127",
                        "text": "Erkam Uzun"
                    },
                    {
                        "@pid": "38/860",
                        "text": "Simon P. Chung"
                    },
                    {
                        "@pid": "65/6001",
                        "text": "Vladimir Kolesnikov"
                    },
                    {
                        "@pid": "32/3349",
                        "text": "Alexandra Boldyreva"
                    },
                    {
                        "@pid": "29/5976",
                        "text": "Wenke Lee"
                    }
                ]
            },
            "title": "Fuzzy Labeled Private Set Intersection with Applications to Private Real-Time Biometric Search.",
            "venue": "USENIX Security Symposium",
            "pages": "911-928",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/UzunCKBL21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/uzun",
            "url": "https://dblp.org/rec/conf/uss/UzunCKBL21",
            "abstract": "The explosive growth of biometrics use (e.g., in surveillance) poses a persistent challenge to keep biometric data private without sacri\ufb01cing the apps\u2019 functionality. We consider private querying of a real-life biometric scan (e.g., a person\u2019s face) against a private biometric database. The querier learns only the label(s) of a matching scan(s) (e.g. a person\u2019s name), and the database server learns nothing. We formally de\ufb01ne Fuzzy Labeled Private Set Intersection (FLPSI), a primitive computing the intersection of noisy input sets by considering closeness/similarity instead of equality. Our FLPSI protocol\u2019s communication is sublinear in database size and is concretely ef\ufb01cient. We implement it and apply it to facial search by integrating with our \ufb01ne-tuned toolchain that maps face images into Hamming space. We have implemented and extensively tested our system, achieving high performance with concretely small network usage: for a 10K-row database, the query response time over WAN (resp. fast LAN) is 146ms (resp. 47ms), transferring 12.1MB; of\ufb02ine precomputation (with no communication) time is 0.94s. FLPSI scales well: for a 1M-row database, on-line time is 1.66s (WAN) and 1.46s (fast LAN) with 40.8MB of data transfer in online phase and 37.5s in of\ufb02ine precom-putation. This improves the state-of-the-art work (SANNS) by 9 \u2212 25 \u00d7 (on WAN) and 1 . 2 \u2212 4 \u00d7 (on fast LAN). Our false non-matching rate is 0.75% for at most 10 false matches over 1M-row DB, which is comparable to underlying plaintext matching algorithm.",
            "keywords": [
                "Biometric Privacy",
                "Private Set Intersection",
                "Fuzzy Matching",
                "Facial Recognition",
                "Real-Time Search"
            ]
        },
        "url": "URL#1888221",
        "sema_paperId": "ece97e34e435364207f57be46be0c50efe8845d2"
    },
    {
        "@score": "1",
        "@id": "1888222",
        "info": {
            "authors": {
                "author": {
                    "@pid": "130/3608",
                    "text": "Mathy Vanhoef"
                }
            },
            "title": "Fragment and Forge: Breaking Wi-Fi Through Frame Aggregation and Fragmentation.",
            "venue": "USENIX Security Symposium",
            "pages": "161-178",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Vanhoef21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/vanhoef",
            "url": "https://dblp.org/rec/conf/uss/Vanhoef21",
            "abstract": "In this paper, we present three design flaws in the 802.11 standard that underpins Wi-Fi. One design flaw is in the frame aggregation functionality, and another two are in the frame fragmentation functionality. These design flaws enable an adversary to forge encrypted frames in various ways, which in turn enables exfiltration of sensitive data. We also discovered common implementation flaws related to aggregation and fragmentation, which further worsen the impact of our attacks. Our results affect all protected Wi-Fi networks, ranging from WEP all the way to WPA3, meaning the discovered flaws have been part of Wi-Fi since its release in 1997. In our experiments, all devices were vulnerable to one or more of our attacks, confirming that all Wi-Fi devices are likely affected. Finally, we present a tool to test whether devices are affected by any of the vulnerabilities, and we discuss countermeasures to prevent our attacks.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-vanhoef.pdf",
            "keywords": [
                "Wi-Fi Security",
                "802.11 Standard",
                "Frame Aggregation",
                "Frame Fragmentation",
                "Vulnerability Exploitation"
            ]
        },
        "url": "URL#1888222"
    },
    {
        "@score": "1",
        "@id": "1888223",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "223/7708",
                        "text": "Jose Rodrigo Sanchez Vicarte"
                    },
                    {
                        "@pid": "71/4292-11",
                        "text": "Gang Wang 0011"
                    },
                    {
                        "@pid": "25/8166",
                        "text": "Christopher W. Fletcher"
                    }
                ]
            },
            "title": "Double-Cross Attacks: Subverting Active Learning Systems.",
            "venue": "USENIX Security Symposium",
            "pages": "1593-1610",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Vicarte0F21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/vicarte",
            "url": "https://dblp.org/rec/conf/uss/Vicarte0F21",
            "abstract": "Active learning is widely used in data labeling services to support real-world machine learning applications. By selecting and labeling the samples that have the highest impact on model retraining, active learning can reduce labeling efforts, and thus reduce cost. In this paper, we present a novel attack called Double Cross , which aims to manipulate data labeling and model training in active learning settings. To perform a double-cross attack, the adversary crafts inputs with a special trigger pattern and sends the triggered inputs to the victim model retraining pipeline. The goals of the triggered inputs are (1) to get selected for labeling and retraining by the victim; (2) to subsequently mis-lead human annotators into assigning an adversary-selected label; and (3) to change the victim model\u2019s behavior after retraining occurs. After retraining, the attack causes the victim to mislabel any samples with this trigger pattern to the adversary-chosen label. At the same time, labeling other samples, without the trigger pattern, is not affected. We develop a trigger generation method that simultaneously achieves these three goals. We evaluate the attack on multiple existing image classi\ufb01ers and demonstrate that both gray-box and black-box attacks are successful. Furthermore, we perform experiments on a real-world machine learning platform (Amazon Sage-Maker) to evaluate the attack with human annotators in the loop, to con\ufb01rm the practicality of the attack. Finally, we discuss the implications of the results and the open research questions moving forward.",
            "keywords": [
                "Active Learning",
                "Data Labeling Manipulation",
                "Adversarial Attacks",
                "Model Retraining",
                "Trigger Patterns"
            ]
        },
        "url": "URL#1888223",
        "sema_paperId": "ae519f1a490388fd89a58f2162ba5b86c788aa6a"
    },
    {
        "@score": "1",
        "@id": "1888224",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "59/2227",
                        "text": "Yan Wang"
                    },
                    {
                        "@pid": "94/3019-8",
                        "text": "Chao Zhang 0008"
                    },
                    {
                        "@pid": "125/0591",
                        "text": "Zixuan Zhao"
                    },
                    {
                        "@pid": "190/2804",
                        "text": "Bolun Zhang"
                    },
                    {
                        "@pid": "33/10782",
                        "text": "Xiaorui Gong"
                    },
                    {
                        "@pid": "10/328",
                        "text": "Wei Zou"
                    }
                ]
            },
            "title": "MAZE: Towards Automated Heap Feng Shui.",
            "venue": "USENIX Security Symposium",
            "pages": "1647-1664",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Wang0ZZGZ21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/wang-yan",
            "url": "https://dblp.org/rec/conf/uss/Wang0ZZGZ21",
            "abstract": "A large number of memory corruption vulnerabilities, e.g., heap over\ufb02ow and use after free (UAF), could only be exploited in speci\ufb01c heap layouts via techniques like heap feng shui. To pave the way for automated exploit generation (AEG), automated heap layout manipulation is demanded. In this paper, we present a novel solution M AZE to manipulate proof-of-concept (POC) samples\u2019 heap layouts. It \ufb01rst identi\ufb01es heap layout primitives (i.e., input fragments or code snippets) available for users to manipulate the heap. Then, it applies a novel Dig & Fill algorithm, which models the problem as a Linear Diophantine Equation and solves it de-terministically, to infer a primitive operation sequence that is able to generate target heap layout. We implemented a prototype of M AZE based on the analysis engine S2E, and evaluated it on the PHP, Python and Perl interpreters and a set of CTF (capture the \ufb02ag) programs, as well as a large micro-benchmark. Results showed that M AZE could generate expected heap layouts for over 90% of them.",
            "keywords": [
                "Heap Manipulation",
                "Memory Corruption",
                "Automated Exploit Generation",
                "Heap Feng Shui",
                "Heap Layout Primitives"
            ]
        },
        "url": "URL#1888224",
        "sema_paperId": "a4abee04dd7fe52630282069ed758614ea5a1f45"
    },
    {
        "@score": "1",
        "@id": "1888225",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "156/1247",
                        "text": "Qinying Wang"
                    },
                    {
                        "@pid": "07/8388",
                        "text": "Shouling Ji"
                    },
                    {
                        "@pid": "39/5423-1",
                        "text": "Yuan Tian 0001"
                    },
                    {
                        "@pid": "139/6932-2",
                        "text": "Xuhong Zhang 0002"
                    },
                    {
                        "@pid": "79/7820",
                        "text": "Binbin Zhao"
                    },
                    {
                        "@pid": "301/5831",
                        "text": "Yuhong Kan"
                    },
                    {
                        "@pid": "301/5811",
                        "text": "Zhaowei Lin"
                    },
                    {
                        "@pid": "231/4918",
                        "text": "Changting Lin"
                    },
                    {
                        "@pid": "d/ShuiguangDeng",
                        "text": "Shuiguang Deng"
                    },
                    {
                        "@pid": "l/AlexXLiu",
                        "text": "Alex X. Liu"
                    },
                    {
                        "@pid": "12/6354",
                        "text": "Raheem Beyah"
                    }
                ]
            },
            "title": "MPInspector: A Systematic and Automatic Approach for Evaluating the Security of IoT Messaging Protocols.",
            "venue": "USENIX Security Symposium",
            "pages": "4205-4222",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WangJT0ZKLLDLB21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/wang-qinying",
            "url": "https://dblp.org/rec/conf/uss/WangJT0ZKLLDLB21",
            "abstract": "Facilitated by messaging protocols (MP), many home devices are connected to the Internet, bringing convenience and accessibility to customers. However, most deployed MPs on IoT platforms are fragmented, which are not implemented carefully to support secure communication. To the best of our knowledge, there is no systematic solution to perform automatic security checks on MP implementations yet.To bridge the gap, we present MPInspector, the first automatic and systematic solution for vetting the security of MP implementations. MPInspector combines model learning with formal analysis and operates in three stages: (a) using parameter semantics extraction and interaction logic extraction to automatically infer the state machine of an MP implementation, (b) generating security properties based on meta properties and the state machine, and (c) applying automatic property based formal verification to identify property violations. We evaluate MPInspector on three popular MPs, including MQTT, CoAP and AMQP, implemented on nine leading IoT platforms. It identifies 252 property violations, leveraging which we further identify eleven types of attacks under two realistic attack scenarios. In addition, we demonstrate that MPInspector is lightweight (the average overhead of end-to-end analysis is ~4.5 hours) and effective with a precision of 100% in identifying property violations.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-wang-qinying.pdf",
            "keywords": [
                "IoT Messaging Protocols",
                "Security Evaluation",
                "Automatic Security Checks",
                "Property Violations",
                "Model Learning and Formal Analysis"
            ]
        },
        "url": "URL#1888225"
    },
    {
        "@score": "1",
        "@id": "1888226",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "220/3081",
                        "text": "Ke Coby Wang"
                    },
                    {
                        "@pid": "r/MichaelKReiter",
                        "text": "Michael K. Reiter"
                    }
                ]
            },
            "title": "Using Amnesia to Detect Credential Database Breaches.",
            "venue": "USENIX Security Symposium",
            "pages": "839-855",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WangR21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/wang-ke-coby",
            "url": "https://dblp.org/rec/conf/uss/WangR21",
            "abstract": "Known approaches for using decoy passwords (honeywords) to detect credential database breaches su \ufb00 er from the need for a trusted component to recognize decoys when entered in login attempts, and from an attacker\u2019s ability to test stolen passwords at other sites to identify user-chosen passwords based on their reuse at those sites. Amnesia is a framework that resolves these di \ufb03 culties. Amnesia requires no secret state to detect the entry of honeywords and additionally allows a site to monitor for the entry of its decoy passwords elsewhere. We quantify the bene\ufb01ts of Amnesia using probabilistic model checking and the practicality of this framework through measurements of a working implementation.",
            "keywords": [
                "Credential Database Breaches",
                "Honeywords",
                "Amnesia Framework",
                "Decoy Passwords",
                "Password Reuse Detection"
            ]
        },
        "url": "URL#1888226",
        "sema_paperId": "e97a1a360da1653d0ec3cd6742f3a272b3455da2"
    },
    {
        "@score": "1",
        "@id": "1888227",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "217/2370",
                        "text": "Jice Wang"
                    },
                    {
                        "@pid": "80/6791-7",
                        "text": "Yue Xiao 0007"
                    },
                    {
                        "@pid": "60/8494",
                        "text": "Xueqiang Wang"
                    },
                    {
                        "@pid": "167/0416",
                        "text": "Yuhong Nan"
                    },
                    {
                        "@pid": "34/8412",
                        "text": "Luyi Xing"
                    },
                    {
                        "@pid": "129/1113",
                        "text": "Xiaojing Liao"
                    },
                    {
                        "@pid": "174/6633",
                        "text": "Jinwei Dong"
                    },
                    {
                        "@pid": "46/5224",
                        "text": "Nicol\u00e1s Serrano"
                    },
                    {
                        "@pid": "122/4355",
                        "text": "Haoran Lu"
                    },
                    {
                        "@pid": "06/6268",
                        "text": "XiaoFeng Wang 0001"
                    },
                    {
                        "@pid": "83/6530-1",
                        "text": "Yuqing Zhang 0001"
                    }
                ]
            },
            "title": "Understanding Malicious Cross-library Data Harvesting on Android.",
            "venue": "USENIX Security Symposium",
            "pages": "4133-4150",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WangXWNXLDSL0Z21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/wang-jice",
            "url": "https://dblp.org/rec/conf/uss/WangXWNXLDSL0Z21",
            "abstract": "Recent years have witnessed the rise of security risks of libraries integrated in mobile apps, which are reported to steal private user data from the host apps and the app backend servers. Their security implications, however, have never been fully understood. In our research, we brought to light a new attack vector long been ignored yet with serious privacy impacts \u2013 malicious libraries strategically target other vendors\u2019 SDKs integrated in the same host app to harvest private user data (e.g., Facebook\u2019s user pro\ufb01le). Using a methodology that incorporates semantic analysis on an SDK\u2019s Terms of Services (ToS, which describes restricted data access and sharing policies) and code analysis on cross-library interactions, we were able to investigate 1.3 million Google Play apps and the ToSes from 40 highly-popular SDKs, leading to the discovery of 42 distinct libraries stealthily harvesting data from 16 popular SDKs, which affect more than 19K apps with a total of 9 billion downloads. Our study further sheds light on the under-ground ecosystem behind such library-based data harvesting (e.g., monetary incentives for SDK integration), their unique strategies (e.g., hiding data in crash reports and using C2 server to schedule data ex\ufb01ltration) and signi\ufb01cant impacts.",
            "keywords": [
                "Malicious Libraries",
                "Data Harvesting",
                "Android SDKs",
                "Privacy Risks",
                "Cross-library Interactions"
            ]
        },
        "url": "URL#1888227",
        "sema_paperId": "deca6fb918bbc8c4d60d94d38aebdbe86ad887b1"
    },
    {
        "@score": "1",
        "@id": "1888228",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "82/8599",
                        "text": "Yuchen Wang"
                    },
                    {
                        "@pid": "43/4074",
                        "text": "Zhenfeng Zhang"
                    },
                    {
                        "@pid": "36/8126",
                        "text": "Yongquan Xie"
                    }
                ]
            },
            "title": "Privacy-Preserving and Standard-Compatible AKA Protocol for 5G.",
            "venue": "USENIX Security Symposium",
            "pages": "3595-3612",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WangZX21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/wang-yuchen",
            "url": "https://dblp.org/rec/conf/uss/WangZX21",
            "abstract": "The 3GPP consortium has published the Authentication and Key Agreement protocol for the 5th generation (5G) mobile communication system (i.e., 5G-AKA) by Technical Specification (TS) 33.501. It introduces public key encryption to conceal the so-called SUPIs so as to enhance mobile users\u2019 privacy. However, 5G-AKA is only privacy-preserving at the presence of passive attackers, and is still vulnerable to the linkability attacks from active attackers. An active attacker can track target mobile phones via performing these attacks, which puts the privacy of users at risk. In this paper, we propose a privacy-preserving solution for the AKA protocol of 5G system denoted by 5G-AKA\u2032. It is resistant to linkability attacks performed by active attackers, and is compatible with the SIM cards and currently deployed Serving Networks (SNs). In particular, we first conduct an analysis on the known linkability attacks in 5G-AKA, and find out a root cause of all attacks. Then, we design a countermeasure with the inherent key encapsulation mechanism of ECIES (i.e., ECIES-KEM), and use the shared key established by ECIES-KEM to encrypt the challenges sent by a Home Network (HN). With this measure, a target User Equipment (UE) who receives a message replayed from its previously attended sessions behaves as non-target UEs, which prevents the attacker from distinguishing the UE by linking it with its previous sessions. Moreover, 5G-AKA\u2032 does not raise additional bandwidth cost, and only introduces limited additional time costs from 0.02% to 0.03%. Finally, we use a stateof-the-art formal verification tool, Tamarin prover, to prove that 5G-AKA\u2032 achieves the desired security goals of privacy, authentication and secrecy.",
            "keywords": [
                "5G Mobile Communication",
                "Privacy Preservation",
                "Authentication and Key Agreement",
                "Linkability Attacks",
                "ECIES-KEM"
            ]
        },
        "url": "URL#1888228",
        "sema_paperId": "7f734a749af6f8584ab8845cd7b3b5d20e1770cc"
    },
    {
        "@score": "1",
        "@id": "1888229",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "04/10838",
                        "text": "Daimeng Wang"
                    },
                    {
                        "@pid": "181/2621",
                        "text": "Zheng Zhang"
                    },
                    {
                        "@pid": "49/6156-12",
                        "text": "Hang Zhang 0012"
                    },
                    {
                        "@pid": "31/8302",
                        "text": "Zhiyun Qian"
                    },
                    {
                        "@pid": "k/SrikanthVKrishnamurthy",
                        "text": "Srikanth V. Krishnamurthy"
                    },
                    {
                        "@pid": "86/2654",
                        "text": "Nael B. Abu-Ghazaleh"
                    }
                ]
            },
            "title": "SyzVegas: Beating Kernel Fuzzing Odds with Reinforcement Learning.",
            "venue": "USENIX Security Symposium",
            "pages": "2741-2758",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WangZZQKA21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/wang-daimeng",
            "url": "https://dblp.org/rec/conf/uss/WangZZQKA21",
            "abstract": "Fuzzing embeds a large number of decisions requiring \ufb01ne-tuned and hard-coded parameters to maximize its ef\ufb01ciency. This is especially true for kernel fuzzing due to (1) OS ker-nels\u2019 sheer size and complexity, (2) a unique syscall interface that requires special handling (e.g., encoding explicit dependencies among syscalls), and (3) behaviors of inputs (i.e., test cases) are often not reproducible due to the stateful nature of OS kernels. Hence, Syzkaller [14], the state-of-art gray-box kernel fuzzer, incorporates numerous procedures, decision points, and hard-coded parameters master-crafted by domain experts. Unfortunately, hard-coded strategies cannot adjust to factors such as different fuzzing environments/targets and the dynamically changing potency of tasks and/or seeds, limiting the overall effectiveness of the fuzzer. In this paper, we propose S YZ V EGAS , a fuzzer that dynamically and automatically adapts two of the most critical decision points in Syzkaller, task selection and seed selection , to remarkably improve coverage reached per unit-time. S YZ V EGAS \u2019s adaptation leverages multi-armed-bandit (MAB) algorithms along with a novel reward assessment model. Our extensive evaluations of S YZ V EGAS on the latest Linux Kernel and its subsystems demonstrate that it (i) \ufb01nds up to 38.7% more coverage than the default Syzkaller, (ii) better discovers bugs/crashes (8 more unique crashes) and (iii) has very low 2.1% performance overhead. We reported our \ufb01ndings to Google\u2019s",
            "keywords": [
                "Kernel Fuzzing",
                "Dynamic Adaptation",
                "Multi-Armed Bandit",
                "Task Selection",
                "Seed Selection"
            ]
        },
        "url": "URL#1888229",
        "sema_paperId": "30155b1fa0eb7ee5ea8048457e5206a7262469ce"
    },
    {
        "@score": "1",
        "@id": "1888230",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "239/0184",
                        "text": "Noel Warford"
                    },
                    {
                        "@pid": "293/9864",
                        "text": "Collins W. Munyendo"
                    },
                    {
                        "@pid": "294/0172",
                        "text": "Ashna Mediratta"
                    },
                    {
                        "@pid": "94/1554",
                        "text": "Adam J. Aviv"
                    },
                    {
                        "@pid": "20/7983",
                        "text": "Michelle L. Mazurek"
                    }
                ]
            },
            "title": "Strategies and Perceived Risks of Sending Sensitive Documents.",
            "venue": "USENIX Security Symposium",
            "pages": "1217-1234",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WarfordMMAM21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/warford",
            "url": "https://dblp.org/rec/conf/uss/WarfordMMAM21",
            "abstract": "People are frequently required to send documents, forms, or other materials containing sensitive data (e.g., personal information, medical records, financial data) to remote parties, sometimes without a formal procedure to do so securely. The specific transmission mechanisms end up relying on the knowledge and preferences of the parties involved. Through two online surveys ($n=60$ and $n=250$), we explore the various methods used to transmit sensitive documents, as well as the perceived risk and satisfaction with those methods. We find that users are more likely to recognize risk to data-at-rest after receipt (but not at the sender, namely, themselves). When not using an online portal provided by the recipient, participants primarily envision transmitting sensitive documents in person or via email, and have little experience using secure, privacy-preserving alternatives. Despite recognizing general risks, participants express high privacy satisfaction and convenience with actually experienced situations. These results suggest opportunities to design new solutions to promote securely sending sensitive materials, perhaps as new utilities within standard email workflows.",
            "keywords": [
                "Document Transmission",
                "Sensitive Data",
                "Privacy Risks",
                "User Satisfaction",
                "Secure Communication Methods"
            ]
        },
        "url": "URL#1888230",
        "sema_paperId": "5cc1e7d8708f8b76fe3465739a109c343ed0478d"
    },
    {
        "@score": "1",
        "@id": "1888231",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "04/5465-7",
                        "text": "Daniel Weber 0007"
                    },
                    {
                        "@pid": "23/5695-2",
                        "text": "Ahmad Ibrahim 0002"
                    },
                    {
                        "@pid": "127/4008",
                        "text": "Hamed Nemati"
                    },
                    {
                        "@pid": "08/1117-1",
                        "text": "Michael Schwarz 0001"
                    },
                    {
                        "@pid": "08/6024",
                        "text": "Christian Rossow"
                    }
                ]
            },
            "title": "Osiris: Automated Discovery of Microarchitectural Side Channels.",
            "venue": "USENIX Security Symposium",
            "pages": "1415-1432",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Weber0NSR21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/weber",
            "url": "https://dblp.org/rec/conf/uss/Weber0NSR21",
            "abstract": "In the last years, a series of side channels have been discovered on CPUs. These side channels have been used in powerful attacks, e.g., on cryptographic implementations, or as building blocks in transient-execution attacks such as Spectre or Meltdown. However, in many cases, discovering side channels is still a tedious manual process.In this paper, we present Osiris, a fuzzing-based framework to automatically discover microarchitectural side channels. Based on a machine-readable specification of a CPU's ISA, Osiris generates instruction-sequence triples and automatically tests whether they form a timing-based side channel. Furthermore, Osiris evaluates their usability as a side channel in transient-execution attacks, i.e., as the microarchitectural encoding for attacks like Spectre. In total, we discover four novel timing-based side channels on Intel and AMD CPUs. Based on these side channels, we demonstrate exploitation in three case studies. We show that our microarchitectural KASLR break using non-temporal loads, FlushConflict, even works on the new Intel Ice Lake and Comet Lake microarchitectures. We present a cross-core cross-VM covert channel that is not relying on the memory subsystem and transmits up to 1 kbit/s. We demonstrate this channel on the AWS cloud, showing that it is stealthy and noise resistant. Finally, we demonstrate Stream+Reload, a covert channel for transient-execution attacks that, on average, allows leaking 7.83 bytes within a transient window, improving state-of-the-art attacks that only leak up to 3 bytes.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-weber.pdf",
            "keywords": [
                "Microarchitectural Side Channels",
                "Fuzzing Framework",
                "Transient-Execution Attacks",
                "Timing-Based Side Channels",
                "Covert Channels"
            ]
        },
        "url": "URL#1888231"
    },
    {
        "@score": "1",
        "@id": "1888232",
        "info": {
            "authors": {
                "author": {
                    "@pid": "146/8098",
                    "text": "Mingkui Wei"
                }
            },
            "title": "Domain Shadowing: Leveraging Content Delivery Networks for Robust Blocking-Resistant Communications.",
            "venue": "USENIX Security Symposium",
            "pages": "3327-3343",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Wei21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/wei",
            "url": "https://dblp.org/rec/conf/uss/Wei21",
            "abstract": "We debut domain shadowing , a novel censorship evasion technique leveraging content delivery networks (CDNs). Domain shadowing exploits the fact that CDNs allow their customers to claim arbitrary domains as the back-end. By setting the front-end of a CDN service as an allowed domain and the back-end a blocked one, a censored user can access resources of the blocked domain with all \u201cindicators\u201d, including the connecting URL, the SNI of the TLS connection, and the Host header of the HTTP(S) request, appear to belong to the allowed domain. Furthermore, we demonstrate that domain shadowing can be proliferated by domain fronting , a censorship evasion technique popularly used a few years ago, making it even more dif\ufb01cult to block. Compared with existing censorship evasion solutions, domain shadowing is lightweight, incurs negligible overhead, and does not require dedicated third-party support. As a proof of concept, we implemented domain shadowing as a Firefox browser extension and demonstrated its capability in circumventing censorship within a heavily censored country known by its strict censor-ship policies and advanced technologies.",
            "keywords": [
                "Censorship Evasion",
                "Domain Shadowing",
                "Content Delivery Networks",
                "Blocking-Resistant Communications",
                "Domain Fronting"
            ]
        },
        "url": "URL#1888232",
        "sema_paperId": "7a0d1b64ed78d06d6dd9ee685a7a943b606ac11a"
    },
    {
        "@score": "1",
        "@id": "1888233",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "251/1580",
                        "text": "Chenkai Weng"
                    },
                    {
                        "@pid": "86/8501-2",
                        "text": "Kang Yang 0002"
                    },
                    {
                        "@pid": "17/1712",
                        "text": "Xiang Xie"
                    },
                    {
                        "@pid": "k/JonathanKatz",
                        "text": "Jonathan Katz"
                    },
                    {
                        "@pid": "150/9413",
                        "text": "Xiao Wang 0012"
                    }
                ]
            },
            "title": "Mystique: Efficient Conversions for Zero-Knowledge Proofs with Applications to Machine Learning.",
            "venue": "USENIX Security Symposium",
            "pages": "501-518",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Weng0XK021",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/weng",
            "url": "https://dblp.org/rec/conf/uss/Weng0XK021",
            "abstract": "Recent progress in interactive zero-knowledge (ZK) proofs has improved the efficiency of proving large-scale computations significantly. Nevertheless, real-life applications (e.g., in the context of private inference using deep neural networks) often involve highly complex computations, and existing ZK protocols lack the expressiveness and scalability to prove results about such computations efficiently.In this paper, we design, develop, and evaluate a ZK system (Mystique) that allows for efficient conversions between arithmetic and Boolean values, between publicly committed and privately authenticated values, and between fixed-point and floating-point numbers. Targeting large-scale neural-network inference, we also present an improved ZK protocol for matrix multiplication that yields a 7\u00d7 improvement compared to the state-of-the-art. Finally, we incorporate Mystique in Rosetta, a TensorFlow-based privacy-preserving framework.Mystique is able to prove correctness of an inference on a private image using a committed (private) ResNet-101 model in 28 minutes, and can do the same task when the model is public in 5 minutes, with only a 0.02% decrease in accuracy compared to a non-ZK execution when testing on the CIFAR10 dataset. Our system is the first to support ZK proofs about neural-network models with over 100 layers with virtually no loss of accuracy.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-weng.pdf",
            "keywords": [
                "Zero-Knowledge Proofs",
                "Privacy-Preserving Inference",
                "Arithmetic and Boolean Conversions",
                "Matrix Multiplication Protocol",
                "Neural Network Model Verification"
            ]
        },
        "url": "URL#1888233"
    },
    {
        "@score": "1",
        "@id": "1888234",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "74/2693",
                        "text": "Brian Wickman"
                    },
                    {
                        "@pid": "70/2543-4",
                        "text": "Hong Hu 0004"
                    },
                    {
                        "@pid": "119/7670",
                        "text": "Insu Yun"
                    },
                    {
                        "@pid": "249/5571",
                        "text": "Daehee Jang"
                    },
                    {
                        "@pid": "295/1721",
                        "text": "Jungwon Lim"
                    },
                    {
                        "@pid": "145/0912",
                        "text": "Sanidhya Kashyap"
                    },
                    {
                        "@pid": "38/8882",
                        "text": "Taesoo Kim"
                    }
                ]
            },
            "title": "Preventing Use-After-Free Attacks with Fast Forward Allocation.",
            "venue": "USENIX Security Symposium",
            "pages": "2453-2470",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Wickman0YJLKK21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/wickman",
            "url": "https://dblp.org/rec/conf/uss/Wickman0YJLKK21",
            "abstract": "Memory-unsafe languages are widely used to implement critical systems like kernels and browsers, leading to thousands of memory safety issues every year. A use-after-free bug is a temporal memory error where the program accidentally visits a freed memory location. Recent studies show that useafter-free is one of the most exploited memory vulnerabilities. Unfortunately, previous efforts to mitigate use-after-free bugs are not widely deployed in real-world programs due to either inadequate accuracy or high performance overhead. In this paper, we propose to resurrect the idea of one-time allocation (OTA) and provide a practical implementation with efficient execution and moderate memory overhead. With onetime allocation, the memory manager always returns a distinct memory address for each request. Since memory locations are not reused, attackers cannot reclaim freed objects, and thus cannot exploit use-after-free bugs. We utilize two techniques to render OTA practical: batch page management and the fusion of bump-pointer and fixed-size bins memory allocation styles. Batch page management helps reduce the number of system calls which negatively impact performance, while blending the two allocation methods mitigates the memory overhead and fragmentation issues. We implemented a prototype, called FFmalloc, to demonstrate our techniques. We evaluated FFmalloc on widely used benchmarks and real-world large programs. FFmalloc successfully blocked all tested useafter-free attacks while introducing moderate overhead. The results show that OTA can be a strong and practical solution to thwart use-after-free threats.",
            "keywords": [
                "Memory Safety",
                "Use-After-Free",
                "One-Time Allocation",
                "Memory Management",
                "FFmalloc"
            ]
        },
        "url": "URL#1888234",
        "sema_paperId": "84a5cded18241d329ce8340fbe1f86e4957f8eba"
    },
    {
        "@score": "1",
        "@id": "1888235",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "135/6902",
                        "text": "Flynn Wolf"
                    },
                    {
                        "@pid": "94/1554",
                        "text": "Adam J. Aviv"
                    },
                    {
                        "@pid": "43/4533",
                        "text": "Ravi Kuber"
                    }
                ]
            },
            "title": "Security Obstacles and Motivations for Small Businesses from a CISO&apos;s Perspective.",
            "venue": "USENIX Security Symposium",
            "pages": "1199-1216",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WolfAK21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/wolf",
            "url": "https://dblp.org/rec/conf/uss/WolfAK21",
            "abstract": "Small businesses (SBs) are often ill-informed and under-resourced against increasing online threats. Chief Information Security Of\ufb01cers (CISOs) have a key role in contextualizing trade-offs between competing costs and priorities for SB management. To explore the challenges CISOs face when guiding SBs towards improved security we conducted two interview studies. Firstly, an exploratory study with CISOs with SB experience to identify themes related to their work (n=8). Secondly, we re\ufb01ned our methods and conducted broader structured interviews with a larger non-overlapping group of similarly quali\ufb01ed SB CISOs (n=19) to validate those themes and extend outcomes. We found CISOs con\ufb01rmed common observations that SBs are generally unprepared for online threats, and uninformed about issues such as insurance and regulation. We also found that despite perceived usability problems with language and formatting, the effectiveness of government-authored guidance (a key reference source for CISOs and SBs) was deemed on par with commercial resources. These observations yield recommendations for better formatting, prioritizing, and timing of security guidance for SBs, such as better tailoring checklists, investment suggestions, and scenario-based exercises.",
            "keywords": [
                "Small Business Security",
                "Chief Information Security Officer",
                "Cyber Threat Preparedness",
                "Security Guidance Effectiveness",
                "Insurance and Regulation Awareness"
            ]
        },
        "url": "URL#1888235",
        "sema_paperId": "77644a9066e169fd74c235b8adec729c3b561def"
    },
    {
        "@score": "1",
        "@id": "1888236",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "201/9210",
                        "text": "Seunghoon Woo"
                    },
                    {
                        "@pid": "25/6543",
                        "text": "Dongwook Lee"
                    },
                    {
                        "@pid": "285/4792",
                        "text": "Sunghan Park"
                    },
                    {
                        "@pid": "75/4485",
                        "text": "Heejo Lee"
                    },
                    {
                        "@pid": "13/1169",
                        "text": "Sven Dietrich"
                    }
                ]
            },
            "title": "V0Finder: Discovering the Correct Origin of Publicly Reported Software Vulnerabilities.",
            "venue": "USENIX Security Symposium",
            "pages": "3041-3058",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WooLPLD21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/woo",
            "url": "https://dblp.org/rec/conf/uss/WooLPLD21",
            "abstract": "Common Vulnerabilities and Exposures (CVEs) are used to ensure con\ufb01dence among developers, to share information about software vulnerabilities, and to provide a baseline for security measures. Therefore, the correctness of CVE reports is crucial for detecting and patching software vulnerabilities. In this paper, we introduce the concept of \u201cVulnerability Zero\u201d (VZ), the software where a vulnerability \ufb01rst originated. We then present V0Finder , a precise mechanism for discovering the VZ of a vulnerability, including software name and its version. V0Finder utilizes code-based analysis to identify reuse relations, which specify the direction of vulnerability propagation, among vulnerable software. V0Finder constructs a graph from all the identi\ufb01ed directions and traces backward to the root of that graph to \ufb01nd the VZ. We applied V0Finder to 5,671 CVE vulnerabilities collected from the National Vulnerability Database (NVD) and popular Bugzilla-based projects. V0Finder discovered VZs with high accuracy of 98% precision and 95% recall. Furthermore, V0Finder identi\ufb01ed 96 CVEs with incorrect information related to their respective VZs. We con\ufb01rmed that the incorrect VZ causes prolonged patch updates of vulnerable software; the patch update of CVEs with the incorrect VZ information takes 2 years, while the patch update of CVEs with the correct VZ takes less than a year on average. Such in-correctly identi\ufb01ed VZ hinders the objective of the CVE and causes confusion rather than \u201censuring con\ufb01dence\u201d among developers. Our analysis shows that V0Finder can enhance the credibility of information provided by the CVEs.",
            "keywords": [
                "Software Vulnerability Analysis",
                "Vulnerability Zero",
                "CVE Accuracy",
                "Vulnerability Propagation",
                "Patch Update Delays"
            ]
        },
        "url": "URL#1888236",
        "sema_paperId": "efdf06a28afcbd90a8dc5d6e8d28aa13a4b1b50f"
    },
    {
        "@score": "1",
        "@id": "1888237",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "03/5595",
                        "text": "Xian Wu"
                    },
                    {
                        "@pid": "144/1238-2",
                        "text": "Wenbo Guo 0002"
                    },
                    {
                        "@pid": "01/6961",
                        "text": "Hua Wei"
                    },
                    {
                        "@pid": "40/6431",
                        "text": "Xinyu Xing"
                    }
                ]
            },
            "title": "Adversarial Policy Training against Deep Reinforcement Learning.",
            "venue": "USENIX Security Symposium",
            "pages": "1883-1900",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Wu0WX21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/wu-xian",
            "url": "https://dblp.org/rec/conf/uss/Wu0WX21",
            "abstract": "Reinforcement learning is a set of goal-oriented learning algorithms, through which an agent could learn to behave in an environment, by performing certain actions and observing the reward which it gets from those actions. Integrated with deep neural networks, it becomes deep reinforcement learning, a new paradigm of learning methods. Recently, deep reinforcement learning demonstrates great potential in many applications such as playing video games, mastering GO competition, and even performing autonomous pilot. However, coming together with these great successes is adversarial attacks, in which an adversary could force a well-trained agent to behave abnormally by tampering the input to the agent's policy network or training an adversarial agent to exploit the weakness of the victim. In this work, we show existing adversarial attacks against reinforcement learning either work in an impractical setting or perform less effectively when being launched in a two-agent zero-sum game. Motivated by this, we propose a new method to train adversarial agents. Technically speaking, our approach extends the Proximal Policy Optimization (PPO) algorithm and then utilizes an explainable AI technique to guide an attacker to train an adversarial agent. In comparison with the adversarial agent trained by the state-of-the-art technique, we show that our adversarial agent exhibits a much stronger capability in exploiting the weakness of victim agents. Besides, we demonstrate that our adversarial attack introduces less variation in the training process and exhibits less sensitivity to the selection of initial states.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-wu-xian.pdf",
            "keywords": [
                "Adversarial Policy Training",
                "Deep Reinforcement Learning",
                "Proximal Policy Optimization",
                "Adversarial Attacks",
                "Two-Agent Zero-Sum Game"
            ]
        },
        "url": "URL#1888237"
    },
    {
        "@score": "1",
        "@id": "1888238",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "248/1662",
                        "text": "Qiushi Wu"
                    },
                    {
                        "@pid": "248/1695",
                        "text": "Aditya Pakki"
                    },
                    {
                        "@pid": "207/7884",
                        "text": "Navid Emamdoost"
                    },
                    {
                        "@pid": "29/4899",
                        "text": "Stephen McCamant"
                    },
                    {
                        "@pid": "67/10639",
                        "text": "Kangjie Lu"
                    }
                ]
            },
            "title": "Understanding and Detecting Disordered Error Handling with Precise Function Pairing.",
            "venue": "USENIX Security Symposium",
            "pages": "2041-2058",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WuPEML21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/wu-qiushi",
            "url": "https://dblp.org/rec/conf/uss/WuPEML21",
            "abstract": "Software programs may frequently encounter various errors such as allocation failures. Error handling aims to gracefully deal with the errors to avoid security and reliability issues, thus it is prevalent and vital. However, because of its complexity and corner cases, error handling itself is often erroneous, and prior research has primarily focused on finding bugs in the handling part, such as incorrect error-code returning or missing error propagation. In this paper, we propose and investigate a class of bugs in error-handling code from a different perspective. In particular, we find that programs often perform \u201ccleanup\u201d operations before the actual error handling, such as freeing memory or decreasing refcount. Critical bugs occur when these operations are performed (1) in an incorrect order, (2) redundantly, or (3) inadequately. We refer to such bugs as Disordered Error Handling (DiEH). Our investigation reveals that DiEH bugs are not only common but can also cause security problems such as privilege escalation, memory corruption, and denial-of-service. Based on the findings from the investigation, we then develop a system, HERO (Handling ERrors Orderly), to automatically detect DiEH. The core of HERO is a novel technique that precisely pairs both common and custom functions based on the unique error-handling structures, which allows us to infer expected cleanup functions. With HERO, we found 239 DiEH bugs in the Linux kernel, the FreeBSD kernel, and OpenSSL, which can cause security and reliability issues. The evaluation results show that DiEH is critical and widely exists in system software, and HERO is effective in detecting DiEH. We also believe that the precise function pairing is of independent interest in other research areas such as temporal-rule inference and race detection.",
            "keywords": [
                "Error Handling",
                "Disordered Error Handling",
                "Software Reliability",
                "Memory Management",
                "Security Vulnerabilities"
            ]
        },
        "url": "URL#1888238",
        "sema_paperId": "d06bd628b038cdfcc57f707d3aef0630558c3250"
    },
    {
        "@score": "1",
        "@id": "1888239",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "16/5608",
                        "text": "Jianliang Wu"
                    },
                    {
                        "@pid": "40/5102",
                        "text": "Ruoyu Wu"
                    },
                    {
                        "@pid": "133/5077",
                        "text": "Daniele Antonioli"
                    },
                    {
                        "@pid": "31/1273",
                        "text": "Mathias Payer"
                    },
                    {
                        "@pid": "32/7125",
                        "text": "Nils Ole Tippenhauer"
                    },
                    {
                        "@pid": "59/5539",
                        "text": "Dongyan Xu"
                    },
                    {
                        "@pid": "159/0537",
                        "text": "Dave (Jing) Tian"
                    },
                    {
                        "@pid": "99/3883",
                        "text": "Antonio Bianchi"
                    }
                ]
            },
            "title": "LIGHTBLUE: Automatic Profile-Aware Debloating of Bluetooth Stacks.",
            "venue": "USENIX Security Symposium",
            "pages": "339-356",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WuWAPTXTB21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/wu-jianliang",
            "url": "https://dblp.org/rec/conf/uss/WuWAPTXTB21",
            "abstract": "The Bluetooth standard is ubiquitously supported by computers, smartphones, and IoT devices. Due to its complexity, implementations require large codebases, which are prone to security vulnerabilities, such as the recently discovered BlueBorne and BadBluetooth attacks. While de\ufb01ned by the standard, most of the Bluetooth functionality, as de\ufb01ned by different Bluetooth pro\ufb01les, is not required in the common usage scenarios. Starting from this observation, we implement L IGHT B LUE , a framework performing automatic, pro\ufb01le-aware debloating of Bluetooth stacks, allowing users to automatically minimize their Bluetooth attack surface by removing unneeded Blue-tooth features. L IGHT B LUE starts with a target Bluetooth application, detects the associated Bluetooth pro\ufb01les, and applies a combination of control-\ufb02ow and data-\ufb02ow analysis to remove unused code within a Bluetooth host code. Furthermore, to debloat the Bluetooth \ufb01rmware, L IGHT B LUE extracts the used Host Controller Interface (HCI) commands and patches the HCI dispatcher in the Bluetooth \ufb01rmware automatically, so that the Bluetooth \ufb01rmware avoids processing unneeded HCI commands. We evaluate L IGHT B LUE on four different Bluetooth hosts and three different Bluetooth controllers. Our evaluation shows that L IGHT B LUE achieves between 32% and 50% code reduction in the Bluetooth host code and between 57% and 83% HCI command reduction",
            "keywords": [
                "Bluetooth Security",
                "Debloating",
                "Bluetooth Stacks",
                "Profile-Aware Analysis",
                "HCI Command Reduction"
            ]
        },
        "url": "URL#1888239",
        "sema_paperId": "d6f469e488ed2575b38022df01b99686fa4b36a4"
    },
    {
        "@score": "1",
        "@id": "1888240",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "224/9296",
                        "text": "Zhaohan Xi"
                    },
                    {
                        "@pid": "252/5223",
                        "text": "Ren Pang"
                    },
                    {
                        "@pid": "07/8388",
                        "text": "Shouling Ji"
                    },
                    {
                        "@pid": "12/2633-6",
                        "text": "Ting Wang 0006"
                    }
                ]
            },
            "title": "Graph Backdoor.",
            "venue": "USENIX Security Symposium",
            "pages": "1523-1540",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/XiPJ021",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/xi",
            "url": "https://dblp.org/rec/conf/uss/XiPJ021",
            "abstract": "One intriguing property of deep neural networks (DNNs) is their inherent vulnerability to backdoor attacks -- a trojaned model responds to trigger-embedded inputs in a highly predictable manner while functioning normally otherwise. Surprisingly, despite the plethora of prior work on DNNs for continuous data (e.g., images), little is known about the vulnerability of graph neural networks (GNNs) for discrete-structured data (e.g., graphs), which is highly concerning given their increasing use in security-sensitive domains. To bridge this gap, we present GTA, the first backdoor attack on GNNs. Compared with prior work, GTA departs in significant ways: graph-oriented -- it defines triggers as specific subgraphs, including both topological structures and descriptive features, entailing a large design spectrum for the adversary; input-tailored -- it dynamically adapts triggers to individual graphs, thereby optimizing both attack effectiveness and evasiveness; downstream model-agnostic -- it can be readily launched without knowledge regarding downstream models or fine-tuning strategies; and attack-extensible -- it can be instantiated for both transductive (e.g., node classification) and inductive (e.g., graph classification) tasks, constituting severe threats for a range of security-critical applications (e.g., toxic chemical classification). Through extensive evaluation using benchmark datasets and state-of-the-art models, we demonstrate the effectiveness of GTA: for instance, on pre-trained, off-the-shelf GNNs, GTA attains over 99.2% attack success rate with merely less than 0.3% accuracy drop. We further provide analytical justification for its effectiveness and discuss potential countermeasures, pointing to several promising research directions.",
            "keywords": [
                "Graph Neural Networks",
                "Backdoor Attack",
                "Trojaned Model",
                "Trigger Subgraphs",
                "Attack Effectiveness"
            ]
        },
        "url": "URL#1888240",
        "sema_paperId": "c09b6e62362988127f8d8a4243a0227bfd0770ca"
    },
    {
        "@score": "1",
        "@id": "1888241",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "71/1116",
                        "text": "Feng Xiao"
                    },
                    {
                        "@pid": "312/6561",
                        "text": "Jianwei Huang"
                    },
                    {
                        "@pid": "301/5880",
                        "text": "Yichang Xiong"
                    },
                    {
                        "@pid": "153/5855",
                        "text": "Guangliang Yang 0001"
                    },
                    {
                        "@pid": "70/2543-4",
                        "text": "Hong Hu 0004"
                    },
                    {
                        "@pid": "64/1147",
                        "text": "Guofei Gu"
                    },
                    {
                        "@pid": "29/5976",
                        "text": "Wenke Lee"
                    }
                ]
            },
            "title": "Abusing Hidden Properties to Attack the Node.js Ecosystem.",
            "venue": "USENIX Security Symposium",
            "pages": "2951-2968",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/XiaoHXY0GL21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/xiao",
            "url": "https://dblp.org/rec/conf/uss/XiaoHXY0GL21",
            "abstract": "Nowadays, Node.js has been widely used in the development of server-side and desktop programs (e.g., Skype), with its cross-platform and high-performance execution environment of JavaScript. In past years, it has been reported other dynamic programming languages (e.g., PHP and Ruby) are unsafe on sharing objects. However, this security risk is not well studied and understood in JavaScript and Node.js programs. In this paper, we \ufb01ll the gap by conducting the \ufb01rst systematic study on the communication process between client-and server-side code in Node.js programs. We extensively identify several new vulnerabilities in popular Node.js programs. To demonstrate their security implications, we design and develop a novel feasible attack, named hidden property abusing (HPA). Our further analysis shows HPA attacks are subtly different from existing \ufb01ndings regarding exploitation and attack effects. Through HPA attacks, a remote web attacker may obtain dangerous abilities, such as stealing con\ufb01dential data, bypassing security checks, and launching DoS (Denial of Service) attacks. To help Node.js developers vet their programs against HPA, we design a novel vulnerability detection and veri\ufb01cation tool, named L YNX , that utilizes hybrid program analysis to automatically reveal HPA vulnerabilities and even synthesize exploits. We apply L YNX on a set of widely-used Node.js programs and identify 15 previously unknown vulnerabilities. We have reported all of our \ufb01ndings to the Node.js community. 10 of them have been assigned with CVE, and 8 of them are rated as \u201cCritical\u201d or \u201cHigh\u201d severity. This indicates HPA attacks can cause serious security threats.",
            "keywords": [
                "Node.js Security",
                "Hidden Property Abusing",
                "Vulnerability Detection",
                "Remote Code Exploitation",
                "Denial of Service (DoS)"
            ]
        },
        "url": "URL#1888241",
        "sema_paperId": "b2f8c8a1c291f969775e38402a7181c6d3b1da71"
    },
    {
        "@score": "1",
        "@id": "1888242",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "217/0857",
                        "text": "Jiarong Xing"
                    },
                    {
                        "@pid": "85/10347",
                        "text": "Wenqing Wu"
                    },
                    {
                        "@pid": "59/146-1",
                        "text": "Ang Chen 0001"
                    }
                ]
            },
            "title": "Ripple: A Programmable, Decentralized Link-Flooding Defense Against Adaptive Adversaries.",
            "venue": "USENIX Security Symposium",
            "pages": "3865-3881",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/XingWC21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/xing",
            "url": "https://dblp.org/rec/conf/uss/XingWC21",
            "abstract": "Link-\ufb02ooding attacks (LFAs) aim to cut off an edge network from the Internet by congesting core network links. Such an adversary can further change the attack strategy dynamically (e.g., target links, traf\ufb01c types) to evade mitigation and launch persistent attacks. We develop Ripple , a programmable, decentralized link-\ufb02ooding defense against dynamic adversaries. Ripple can be programmed using a declarative policy language to emulate a range of state-of-the-art SDN defenses, but it enables the defenses to shapeshift on their own without a central controller. To achieve this, Ripple develops new defense primitives in programmable switches, which are con\ufb01gured by the policy language to implement a desired defense. The Ripple compiler generates a distributed set of switch programs to extract a panoramic view of attack signals and act against them in a fully decentralized manner, enabling successive waves of defenses against fast-changing attacks. We show that Ripple has low overheads, and that it can effectively recover traf\ufb01c throughput where SDN-based defenses fail.",
            "keywords": [
                "Link-Flooding Defense",
                "Decentralized Defense",
                "Programmable Switches",
                "Dynamic Adversaries",
                "Traffic Throughput Recovery"
            ]
        },
        "url": "URL#1888242",
        "sema_paperId": "5284a70431248c1da4d92894b34c1ceb3440d7b7"
    },
    {
        "@score": "1",
        "@id": "1888243",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "301/5873",
                        "text": "Teng Xu 0009"
                    },
                    {
                        "@pid": "185/5623",
                        "text": "Gerard Goossen"
                    },
                    {
                        "@pid": "301/5832",
                        "text": "Huseyin Kerem Cevahir"
                    },
                    {
                        "@pid": "301/5917",
                        "text": "Sara Khodeir"
                    },
                    {
                        "@pid": "169/6253",
                        "text": "Yingyezhe Jin"
                    },
                    {
                        "@pid": "53/10825",
                        "text": "Frank Li 0001"
                    },
                    {
                        "@pid": "217/9308",
                        "text": "Shawn Shan"
                    },
                    {
                        "@pid": "88/7407",
                        "text": "Sagar Patel"
                    },
                    {
                        "@pid": "38/7225",
                        "text": "David Freeman 0001"
                    },
                    {
                        "@pid": "61/1749",
                        "text": "Paul Pearce"
                    }
                ]
            },
            "title": "Deep Entity Classification: Abusive Account Detection for Online Social Networks.",
            "venue": "USENIX Security Symposium",
            "pages": "4097-4114",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/XuGCKJ0SPFP21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/xu-teng",
            "url": "https://dblp.org/rec/conf/uss/XuGCKJ0SPFP21",
            "abstract": "Online social networks (OSNs) attract attackers that use abusive accounts to conduct malicious activities for economic, political, and personal gain. In response, OSNs often deploy abusive account classi\ufb01ers using machine learning (ML) approaches. However, a practical, effective ML-based defense requires carefully engineering features that are robust to adversarial manipulation, obtaining enough ground truth labeled data for model training, and designing a system that can scale to all active accounts on an OSN (potentially in the billions). To address these challenges we present Deep Entity Classi\ufb01-cation (DEC) , an ML framework that detects abusive accounts in OSNs that have evaded other, traditional abuse detection systems. We leverage the insight that while accounts in isolation may be dif\ufb01cult to classify, their embeddings in the social graph\u2014the network structure, properties, and behaviors of themselves and those around them\u2014are fundamentally dif-\ufb01cult for attackers to replicate or manipulate at scale . Our system:",
            "keywords": [
                "Online Social Networks",
                "Abusive Account Detection",
                "Malicious Activities",
                "Social Graph Embeddings",
                "Adversarial Manipulation"
            ]
        },
        "url": "URL#1888243",
        "sema_paperId": "8d714852f4ef35a410f2de4fb5fddcdcd2992290"
    },
    {
        "@score": "1",
        "@id": "1888244",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "09/0",
                        "text": "Min Xu"
                    },
                    {
                        "@pid": "301/5856",
                        "text": "Armin Namavari"
                    },
                    {
                        "@pid": "68/158",
                        "text": "David Cash"
                    },
                    {
                        "@pid": "26/3399",
                        "text": "Thomas Ristenpart"
                    }
                ]
            },
            "title": "Searching Encrypted Data with Size-Locked Indexes.",
            "venue": "USENIX Security Symposium",
            "pages": "4025-4042",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/XuNCR21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/xu-min",
            "url": "https://dblp.org/rec/conf/uss/XuNCR21",
            "abstract": "We investigate a simple but overlooked folklore approach for searching encrypted documents held at an untrusted service: Just stash an index (with unstructured encryption) at the service and download it for updating and searching. This approach is simple to deploy, enables rich search support beyond unsorted keyword lookup, requires no persistent client state, and (intuitively at least) provides excellent security compared with approaches like dynamic searchable symmetric encryption (DSSE). This work first shows that implementing this construct securely is more subtle than it appears, and that naive implementations with commodity indexes are insecure due to the leakage of the byte-length of the encoded index. We then develop a set of techniques for encoding indexes, called size-locking, that eliminates this leakage. Our key idea is to fix the size of indexes to depend only on features that are safe to leak. We further develop techniques for securely partitioning indexes into smaller pieces that are downloaded, trading leakage for large increases in performance in a measured way. We implement our systems and evaluate that they provide search quality matching plaintext systems, support for stateless clients, and resistance to damaging injection attacks.",
            "keywords": [
                "Encrypted Search",
                "Size-Locked Indexes",
                "Dynamic Searchable Symmetric Encryption",
                "Index Encoding Techniques",
                "Data Leakage Prevention"
            ]
        },
        "url": "URL#1888244",
        "sema_paperId": "749968a2d3d78e54094590c2d73ff7a36e869402"
    },
    {
        "@score": "1",
        "@id": "1888245",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "185/6250",
                        "text": "Carter Yagemann"
                    },
                    {
                        "@pid": "265/5563",
                        "text": "Matthew Pruett"
                    },
                    {
                        "@pid": "38/860",
                        "text": "Simon P. Chung"
                    },
                    {
                        "@pid": "301/5826",
                        "text": "Kennon Bittick"
                    },
                    {
                        "@pid": "150/5240",
                        "text": "Brendan Saltaformaggio"
                    },
                    {
                        "@pid": "29/5976",
                        "text": "Wenke Lee"
                    }
                ]
            },
            "title": "ARCUS: Symbolic Root Cause Analysis of Exploits in Production Systems.",
            "venue": "USENIX Security Symposium",
            "pages": "1989-2006",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YagemannPCBSL21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/yagemann",
            "url": "https://dblp.org/rec/conf/uss/YagemannPCBSL21",
            "abstract": "End-host runtime monitors (e.g., CFI, system call IDS) \ufb02ag processes in response to symptoms of a possible attack. Unfortunately, the symptom (e.g., invalid control transfer) may occur long after the root cause (e.g., buffer over\ufb02ow), creating a gap whereby bug reports received by developers contain (at best) a snapshot of the process long after it executed the buggy instructions. To help system administrators provide developers with more concise reports, we propose ARCUS, an automated framework that performs root cause analysis over the execution \ufb02agged by the end-host monitor. ARCUS works by testing \u201cwhat if\u201d questions to detect vulnerable states, systematically localizing bugs to their concise root cause while \ufb01nding additional enforceable checks at the program binary level to demonstrably block them. Using hardware-supported processor tracing, ARCUS decouples the cost of analysis from host performance. We have implemented ARCUS and evaluated it on 31 vulnerabilities across 20 programs along with over 9,000 test cases from the RIPE and Juliet suites. ARCUS identi\ufb01es the root cause of all tested exploits \u2014 with 0 false positives or negatives \u2014 and even \ufb01nds 4 new 0-day vulnerabilities in traces averaging 4,000,000 basic blocks. ARCUS handles programs compiled from upwards of 810,000 lines of C/C++ code without needing concrete inputs or re-execution.",
            "keywords": [
                "Root Cause Analysis",
                "End-Host Monitors",
                "Vulnerability Detection",
                "Automated Framework",
                "Symbolic Analysis"
            ]
        },
        "url": "URL#1888245",
        "sema_paperId": "50697de979081a2d605d63b490568b1dd76398e1"
    },
    {
        "@score": "1",
        "@id": "1888246",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "06/6358",
                        "text": "Limin Yang"
                    },
                    {
                        "@pid": "144/1238-2",
                        "text": "Wenbo Guo 0002"
                    },
                    {
                        "@pid": "254/0865",
                        "text": "Qingying Hao"
                    },
                    {
                        "@pid": "47/849",
                        "text": "Arridhana Ciptadi"
                    },
                    {
                        "@pid": "10/5418",
                        "text": "Ali Ahmadzadeh"
                    },
                    {
                        "@pid": "40/6431",
                        "text": "Xinyu Xing"
                    },
                    {
                        "@pid": "71/4292-11",
                        "text": "Gang Wang 0011"
                    }
                ]
            },
            "title": "CADE: Detecting and Explaining Concept Drift Samples for Security Applications.",
            "venue": "USENIX Security Symposium",
            "pages": "2327-2344",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Yang0HCAX021",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/yang-limin",
            "url": "https://dblp.org/rec/conf/uss/Yang0HCAX021",
            "abstract": "Concept drift poses a critical challenge to deploy machine learning models to solve practical security problems. Due to the dynamic behavior changes of attackers (and/or the benign counterparts), the testing data distribution is often shifting from the original training data over time, causing major failures to the deployed model. To combat concept drift, we present a novel system CADE aiming to 1) detect drifting samples that deviate from existing classes, and 2) provide explanations to reason the detected drift. Unlike traditional approaches (that require a large number of new labels to determine concept drift statistically), we aim to identify individual drifting samples as they arrive. Recognizing the challenges introduced by the high-dimensional outlier space, we propose to map the data samples into a low-dimensional space and automatically learn a distance function to measure the dissimilarity between samples. Using contrastive learning, we can take full advantage of existing labels in the training dataset to learn how to compare and contrast pairs of samples. To reason the meaning of the detected drift, we develop a distance-based explanation method. We show that explaining \u201cdistance\u201d is much more effective than traditional methods that focus on explaining a \u201cdecision boundary\u201d in this problem context. We evaluate CADE with two case studies: Android malware classification and network intrusion detection. We further work with a security company to test CADE on its malware database. Our results show that CADE can effectively detect drifting samples and provide semantically meaningful explanations.",
            "keywords": [
                "Concept Drift Detection",
                "Security Applications",
                "Malware Classification",
                "Network Intrusion Detection",
                "Distance-Based Explanation"
            ]
        },
        "url": "URL#1888246",
        "sema_paperId": "2cf435278f4a3d44660d13e502b69bc0f1dbc539"
    },
    {
        "@score": "1",
        "@id": "1888247",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "130/6977",
                        "text": "Ronghai Yang"
                    },
                    {
                        "@pid": "231/6763",
                        "text": "Xianbo Wang"
                    },
                    {
                        "@pid": "97/467",
                        "text": "Cheng Chi"
                    },
                    {
                        "@pid": "39/2537",
                        "text": "Dawei Wang"
                    },
                    {
                        "@pid": "172/2564",
                        "text": "Jiawei He"
                    },
                    {
                        "@pid": "301/5860",
                        "text": "Siming Pang"
                    },
                    {
                        "@pid": "l/WingCheongLau",
                        "text": "Wing Cheong Lau"
                    }
                ]
            },
            "title": "Scalable Detection of Promotional Website Defacements in Black Hat SEO Campaigns.",
            "venue": "USENIX Security Symposium",
            "pages": "3703-3720",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YangWCWHPL21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/yang-ronghai",
            "url": "https://dblp.org/rec/conf/uss/YangWCWHPL21",
            "abstract": "Miscreants from online underground economies regularly exploit website vulnerabilities and inject fraudulent content into victim web pages to promote illicit goods and services. Scalable detection of such promotional website defacements remains an open problem despite their prevalence in Black Hat Search Engine Optimization (SEO) campaigns. Adver-saries often manage to inject content in a stealthy manner by obfuscating the description of illicit products and/or the presence of defacements to make them undetectable. In this paper, we design and implement DM O S - a Defacement Monitoring System which protects websites from promotional defacements at scale. Our design is based on two key observations: Firstly, for effective advertising, the obfuscated jargons of illicit goods or services need to be easily understood by their target customers ( e.g. , sharing similar shape or pronunciation). Secondly, to promote the underground business, the defacements are crafted to boost search engine ranking of the defaced web pages while trying to stay stealthy from the maintainers and legitimate users of the compromised websites. Leveraging these insights, we \ufb01rst follow the human convention and design a jargon normalization algorithm to map obfuscated jargons to their original forms. We then develop a tag embedding mechanism, which enables DM O S to focus more on those not-so-visually-obvious, yet site-ranking in\ufb02u-ential HTML tags ( e.g. , title , meta ). Consequently, DM O S can reliably detect illicit content hidden in compromised web pages. In particular, we have deployed DM O S as a cloud-based monitoring service for a \ufb01ve-month trial run. It has analyzed more than 38 million web pages across 7000+ commercial Chinese websites and found defacements in 11% of these websites. It achieves a",
            "keywords": [
                "Defacement Detection",
                "Black Hat SEO",
                "Promotional Website Defacements",
                "Jargon Normalization",
                "HTML Tag Analysis"
            ]
        },
        "url": "URL#1888247",
        "sema_paperId": "945f9ab5338f26adf4bf754c950ef2cac5e39bd3"
    },
    {
        "@score": "1",
        "@id": "1888248",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "25/2975",
                        "text": "Man-Ki Yoon"
                    },
                    {
                        "@pid": "239/5467",
                        "text": "Mengqi Liu 0001"
                    },
                    {
                        "@pid": "175/3324-23",
                        "text": "Hao Chen 0023"
                    },
                    {
                        "@pid": "33/1183",
                        "text": "Jung-Eun Kim"
                    },
                    {
                        "@pid": "s/ZhongShao",
                        "text": "Zhong Shao"
                    }
                ]
            },
            "title": "Blinder: Partition-Oblivious Hierarchical Scheduling.",
            "venue": "USENIX Security Symposium",
            "pages": "2417-2434",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Yoon00KS21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/yoon",
            "url": "https://dblp.org/rec/conf/uss/Yoon00KS21",
            "abstract": "Hierarchical scheduling enables modular reasoning about the temporal behavior of individual applications by partitioning CPU time and thus isolating potential misbehavior. However, conventional time-partitioning mechanisms fail to achieve strong temporal isolation from a security perspective; variations in the executions of partitions can be perceived by others, which enables an algorithmic covert timing-channel between partitions that are completely isolated from each other in the utilization of time. Thus, we present a run-time algorithm that makes partitions oblivious to others\u2019 varying behaviors even when an adversary has full control over their timings. It enables the use of dynamic time-partitioning mechanisms that provide improved responsiveness, while guaranteeing the algorithmic-level non-interference that static approaches would achieve. From an implementation on an open-source operating system, we evaluate the costs of the solution in terms of the responsiveness as well as scheduling overhead.",
            "keywords": [
                "Hierarchical Scheduling",
                "Temporal Isolation",
                "Dynamic Time-Partitioning",
                "Covert Timing-Channel",
                "Algorithmic Non-Interference"
            ]
        },
        "url": "URL#1888248",
        "sema_paperId": "0e65f84e9e7360d6b460dc3b1febf617463bb532"
    },
    {
        "@score": "1",
        "@id": "1888249",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "64/35",
                        "text": "Filip Zag\u00f3rski"
                    },
                    {
                        "@pid": "271/8517",
                        "text": "Grant McClearn"
                    },
                    {
                        "@pid": "271/8045",
                        "text": "Sarah Morin"
                    },
                    {
                        "@pid": "58/3906",
                        "text": "Neal McBurnett"
                    },
                    {
                        "@pid": "p/PLVora",
                        "text": "Poorvi L. Vora"
                    }
                ]
            },
            "title": "Minerva- An Efficient Risk-Limiting Ballot Polling Audit.",
            "venue": "USENIX Security Symposium",
            "pages": "3059-3076",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZagorskiMMMV21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/zagorski",
            "url": "https://dblp.org/rec/conf/uss/ZagorskiMMMV21",
            "abstract": "Evidence-based elections aim to produce trustworthy and compelling evidence of the correctness of election outcomes, enabling the detection of problems with high probability. They require a well-curated voter-veri\ufb01ed paper trail, compliance audits, and a rigorous tabulation audit of the election outcome, known as a risk-limiting audit (RLA). This paper focuses on ballot polling RLAs which can require that a very large sample of ballots be drawn. The main ballot polling RLA in use today, BRAVO, is designed for use when single ballots are drawn at random and a decision regarding whether to stop the audit or draw another ballot is taken after each ballot draw. But in practice, ballot polling audits draw many ballots in a single round before determining whether to stop. Direct application of B RAVO to large rounds results in considerable inef\ufb01ciency. We present M INERVA , a risk-limiting audit that addresses this problem. When compared to the B RAVO stopping rule being applied at the end of the round, for a \ufb01rst-round with 90% stopping probability, M INERVA halves the number of ballots required across all state margins in the 2020 US Presidential election. When compared to the B RAVO stopping rule being applied after examination of individual ballots, M INERVA reduces the number of ballots by about a quarter. M INERVA requires that round sizes are predetermined; this does not appear to be a drawback for large \ufb01rst rounds which have been typical choices for election of\ufb01cials. Ballot-polling audits are the leading option in most states. M INERVA",
            "keywords": [
                "Risk-Limiting Audits",
                "Ballot Polling",
                "Election Integrity",
                "Statistical Sampling",
                "Minerva"
            ]
        },
        "url": "URL#1888249",
        "sema_paperId": "9a644917538b13720be494814f44d2d5375fa418"
    },
    {
        "@score": "1",
        "@id": "1888250",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "26/4189-37",
                        "text": "Han Zhang 0037"
                    },
                    {
                        "@pid": "189/1235",
                        "text": "Abhijith Anilkumar"
                    },
                    {
                        "@pid": "38/2612",
                        "text": "Matt Fredrikson"
                    },
                    {
                        "@pid": "84/1053",
                        "text": "Yuvraj Agarwal"
                    }
                ]
            },
            "title": "Capture: Centralized Library Management for Heterogeneous IoT Devices.",
            "venue": "USENIX Security Symposium",
            "pages": "4187-4204",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhangAFA21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/zhang-han",
            "url": "https://dblp.org/rec/conf/uss/ZhangAFA21",
            "abstract": "With their growing popularity, Internet-of-Things (IoT) devices have become attractive targets for attack. Like most modern software systems, IoT device \ufb01rmware depends on external third-party libraries extensively, increasing the attack surface of IoT devices. Furthermore, we \ufb01nd that the risk is compounded by inconsistent library management practices and delays in applying security updates\u2014sometimes hundreds of days behind the public availability of critical patches\u2014by device vendors. Worse yet, because these dependencies are \u201cbaked into\u201d the vendor-controlled \ufb01rmware, even security-conscious users are unable to take matters into their own hands when it comes to good security hygiene. We present Capture , a novel architecture for deploying IoT device \ufb01rmware that addresses this problem by allowing devices on a local network to leverage a centralized hub with third-party libraries that are managed and kept up-to-date by a single trusted entity. An IoT device supporting Capture comprises of two components: Capture-enabled \ufb01rmware on the device and a remote driver that uses third-party libraries on the Capture hub in the local network. To ensure isolation, we introduce a novel Virtual Device Entity (VDE) interface that facilitates access control between mutually-distrustful devices that reside on the same hub. Our evaluation on a prototype implementation of Capture, along with 9 devices and 3 automation applets ported to our framework, shows that our approach incurs low overhead in most cases ( < 15% increased latency, < 10% additional resources). We show that a single Capture Hub with modest hardware can support hundreds of devices, keeping their shared libraries up-to-date.",
            "keywords": [
                "IoT Device Management",
                "Centralized Library Management",
                "Firmware Security",
                "Third-Party Library Vulnerabilities",
                "Virtual Device Entity (VDE)"
            ]
        },
        "url": "URL#1888250",
        "sema_paperId": "2724b2b23fb1b1200f914cd37b82dc020c957a97"
    },
    {
        "@score": "1",
        "@id": "1888251",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "52/5264",
                        "text": "Xing Zhang"
                    },
                    {
                        "@pid": "224/2480",
                        "text": "Jiongyi Chen"
                    },
                    {
                        "@pid": "97/164",
                        "text": "Chao Feng"
                    },
                    {
                        "@pid": "24/7930",
                        "text": "Ruilin Li"
                    },
                    {
                        "@pid": "277/4739",
                        "text": "Yunfei Su"
                    },
                    {
                        "@pid": "13/5236",
                        "text": "Bin Zhang"
                    },
                    {
                        "@pid": "33/2568-1",
                        "text": "Jing Lei 0001"
                    },
                    {
                        "@pid": "57/1674",
                        "text": "Chaojing Tang"
                    }
                ]
            },
            "title": "Reducing Test Cases with Attention Mechanism of Neural Networks.",
            "venue": "USENIX Security Symposium",
            "pages": "2075-2092",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhangCFLSZLT21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/zhang-xing",
            "url": "https://dblp.org/rec/conf/uss/ZhangCFLSZLT21",
            "abstract": ",",
            "keywords": [
                "Test Case Reduction",
                "Attention Mechanism",
                "Neural Network Optimization",
                "Software Testing",
                "Automated Testing"
            ]
        },
        "url": "URL#1888251",
        "sema_paperId": "ed09a30e370e95b27ca103a909856ff9bfdd5ac9"
    },
    {
        "@score": "1",
        "@id": "1888252",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "200/7275",
                        "text": "Cen Zhang"
                    },
                    {
                        "@pid": "227/9139",
                        "text": "Xingwei Lin"
                    },
                    {
                        "@pid": "204/3729",
                        "text": "Yuekang Li"
                    },
                    {
                        "@pid": "73/7055",
                        "text": "Yinxing Xue"
                    },
                    {
                        "@pid": "301/5829",
                        "text": "Jundong Xie"
                    },
                    {
                        "@pid": "147/5824-1",
                        "text": "Hongxu Chen 0001"
                    },
                    {
                        "@pid": "256/4514",
                        "text": "Xinlei Ying"
                    },
                    {
                        "@pid": "301/5814",
                        "text": "Jiashui Wang"
                    },
                    {
                        "@pid": "51/3710-3",
                        "text": "Yang Liu 0003"
                    }
                ]
            },
            "title": "APICraft: Fuzz Driver Generation for Closed-source SDK Libraries.",
            "venue": "USENIX Security Symposium",
            "pages": "2811-2828",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhangLLXXCYW021",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/zhang-cen",
            "url": "https://dblp.org/rec/conf/uss/ZhangLLXXCYW021",
            "abstract": "Fuzz drivers are needed for fuzzing libraries. A fuzz driver is a program which can execute library functions by feeding them with inputs provided by the fuzzer. In practice, fuzz drivers are written by security experts and the drivers\u2019 quality depends on the skill of their authors. To relieve manual efforts and ensure test quality, different techniques have been proposed to automatically generate fuzz drivers. However, existing techniques mostly rely on static analysis of source code, leaving the fuzz driver generation for closed-source SDK libraries an open problem. Fuzz driver generation for closed-source libraries is faced with two major challenges: 1) only limited information can be extracted from the library; 2) the semantic relations among API functions are complex yet their correctness needs to be ensured. To address these challenges, we propose APIC RAFT , an automated fuzz driver generation technique. The core strategy of APIC RAFT is collect \u2013 combine . First, APIC RAFT leverages both static and dynamic information (headers, binaries, and traces) to collect control and data dependencies for API functions in a practical manner. Then, it uses a multi-objective genetic algorithm to combine the collected dependencies and build high-quality fuzz drivers. We implemented APIC RAFT as a fuzz driver generation framework and evaluated it with \ufb01ve attack surfaces from the macOS SDK. In the evaluation, the fuzz drivers generated by APIC RAFT demonstrate superior code coverage than the manually written ones, with an improvement of 64% on average. We further carried out a long-term fuzzing campaign with the fuzz drivers generated by APIC RAFT . After around eight month\u2019s fuzzing, we\u2019ve so far discovered 142 vulnerabilities with 54 assigned CVEs in macOS SDK, which can affect popular Apple products such as Safari , Messages , Preview and so on.",
            "keywords": [
                "Fuzz Driver Generation",
                "Closed-source SDK Libraries",
                "Automated Testing",
                "API Function Dependencies",
                "Vulnerability Discovery"
            ]
        },
        "url": "URL#1888252",
        "sema_paperId": "f803962b938fe2dafc5a98fcbcebb56cde04a405"
    },
    {
        "@score": "1",
        "@id": "1888253",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "181/2621",
                        "text": "Zheng Zhang"
                    },
                    {
                        "@pid": "49/6156-12",
                        "text": "Hang Zhang 0012"
                    },
                    {
                        "@pid": "31/8302",
                        "text": "Zhiyun Qian"
                    },
                    {
                        "@pid": "91/8881",
                        "text": "Billy Lau"
                    }
                ]
            },
            "title": "An Investigation of the Android Kernel Patch Ecosystem.",
            "venue": "USENIX Security Symposium",
            "pages": "3649-3666",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhangZQL21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/zhang-zheng",
            "url": "https://dblp.org/rec/conf/uss/ZhangZQL21",
            "abstract": "open-source projects are often reused in commercial software. Android, a popular mobile operating system, is a great example that has fostered an ecosystem of open-source kernels. However, due to the largely decentralized and fragmented nature, patch propagation from the upstream through multiple layers to end devices can be severely delayed. In this paper, we undertake a thorough investigation of the patch propagation behaviors in the entire Android kernel ecosystem. By analyzing the CVEs and patches available since the inception of the Android security bulletin, as well as open-source upstream kernels ( e.g., Linux and AOSP) and hundreds of mostly binary OEM kernels ( e.g., by Samsung), we \ufb01nd that the delays of patches are largely due to the current patching practices and the lack of knowledge about which upstream commits being security-critical. Unfortunately, we \ufb01nd that the gap between the \ufb01rst publicly available patch and its \ufb01nal application on end devices is often months and even years, leaving a large attack window for experienced hackers to exploit the unpatched vulnerabilities.",
            "keywords": [
                "Android Kernel Ecosystem",
                "Patch Propagation",
                "Open-source Software",
                "Security Vulnerabilities",
                "Patch Delay"
            ]
        },
        "url": "URL#1888253",
        "sema_paperId": "1f9d473382d9e646574f95c03aaa2babeb62a161"
    },
    {
        "@score": "1",
        "@id": "1888254",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "94/4314",
                        "text": "Wenting Zheng"
                    },
                    {
                        "@pid": "277/5307",
                        "text": "Ryan Deng"
                    },
                    {
                        "@pid": "160/1002",
                        "text": "Weikeng Chen"
                    },
                    {
                        "@pid": "91/275",
                        "text": "Raluca Ada Popa"
                    },
                    {
                        "@pid": "55/925",
                        "text": "Aurojit Panda"
                    },
                    {
                        "@pid": "s/IonStoica",
                        "text": "Ion Stoica"
                    }
                ]
            },
            "title": "Cerebro: A Platform for Multi-Party Cryptographic Collaborative Learning.",
            "venue": "USENIX Security Symposium",
            "pages": "2723-2740",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhengDCPPS21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/zheng",
            "url": "https://dblp.org/rec/conf/uss/ZhengDCPPS21",
            "abstract": "Many organizations need large amounts of high quality data for their applications, and one way to acquire such data is to combine datasets from multiple parties. Since these organizations often own sensitive data that cannot be shared in the clear with others due to policy regulation and business competition, there is increased interest in utilizing secure multi-party computation (MPC). MPC allows multiple parties to jointly compute a function without revealing their inputs to each other. We present Cerebro, an end-to-end collaborative learning platform that enables parties to compute learning tasks without sharing plaintext data. By taking an end-to-end approach to the system design, Cerebro allows multiple parties with complex economic relationships to safely collaborate on machine learning computation through the use of release policies and auditing, while also enabling users to achieve good performance without manually navigating the complex performance tradeoffs between MPC protocols.",
            "pdf_url": "https://www.usenix.org/system/files/sec21-zheng.pdf",
            "keywords": [
                "Secure Multi-Party Computation",
                "Collaborative Learning",
                "Data Privacy",
                "Performance Tradeoffs",
                "Release Policies"
            ]
        },
        "url": "URL#1888254"
    },
    {
        "@score": "1",
        "@id": "1888255",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "125/1789",
                        "text": "Yuankun Zhu"
                    },
                    {
                        "@pid": "15/8296",
                        "text": "Yueqiang Cheng"
                    },
                    {
                        "@pid": "160/7471",
                        "text": "Husheng Zhou"
                    },
                    {
                        "@pid": "131/1381",
                        "text": "Yantao Lu"
                    }
                ]
            },
            "title": "Hermes Attack: Steal DNN Models with Lossless Inference Accuracy.",
            "venue": "USENIX Security Symposium",
            "pages": "1973-1988",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhuCZL21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/zhu",
            "url": "https://dblp.org/rec/conf/uss/ZhuCZL21",
            "abstract": "Deep Neural Networks (DNNs) models become one of the most valuable enterprise assets due to their critical roles in all aspects of applications. With the trend of privatization deployment of DNN models, the data leakage of the DNN models is becoming increasingly serious and widespread. All existing model-extraction attacks can only leak parts of targeted DNN models with low accuracy or high overhead. In this paper, we first identify a new attack surface -- unencrypted PCIe traffic, to leak DNN models. Based on this new attack surface, we propose a novel model-extraction attack, namely Hermes Attack, which is the first attack to fully steal the whole victim DNN model. The stolen DNN models have the same hyper-parameters, parameters, and semantically identical architecture as the original ones. It is challenging due to the closed-source CUDA runtime, driver, and GPU internals, as well as the undocumented data structures and the loss of some critical semantics in the PCIe traffic. Additionally, there are millions of PCIe packets with numerous noises and chaos orders. Our Hermes Attack addresses these issues by huge reverse engineering efforts and reliable semantic reconstruction, as well as skillful packet selection and order correction. We implement a prototype of the Hermes Attack, and evaluate two sequential DNN models (i.e., MINIST and VGG) and one consequential DNN model (i.e., ResNet) on three NVIDIA GPU platforms, i.e., NVIDIA Geforce GT 730, NVIDIA Geforce GTX 1080 Ti, and NVIDIA Geforce RTX 2080 Ti. The evaluation results indicate that our scheme is able to efficiently and completely reconstruct ALL of them with making inferences on any one image. Evaluated with Cifar10 test dataset that contains 10,000 images, the experiment results show that the stolen models have the same inference accuracy as the original ones (i.e., lossless inference accuracy).",
            "keywords": [
                "Model Extraction Attack",
                "DNN Model Theft",
                "PCIe Traffic Analysis",
                "Hermes Attack",
                "Lossless Inference Accuracy"
            ]
        },
        "url": "URL#1888255",
        "sema_paperId": "980451bad2ecb99c5d932e8c05d992a12324dad8"
    },
    {
        "@score": "1",
        "@id": "1888256",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "218/0356",
                        "text": "Yixin Zou"
                    },
                    {
                        "@pid": "205/2107",
                        "text": "Allison McDonald"
                    },
                    {
                        "@pid": "301/5898",
                        "text": "Julia Narakornpichit"
                    },
                    {
                        "@pid": "75/11301",
                        "text": "Nicola Dell"
                    },
                    {
                        "@pid": "26/3399",
                        "text": "Thomas Ristenpart"
                    },
                    {
                        "@pid": "36/8412",
                        "text": "Kevin A. Roundy"
                    },
                    {
                        "@pid": "08/7562",
                        "text": "Florian Schaub"
                    },
                    {
                        "@pid": "79/9389",
                        "text": "Acar Tamersoy"
                    }
                ]
            },
            "title": "The Role of Computer Security Customer Support in Helping Survivors of Intimate Partner Violence.",
            "venue": "USENIX Security Symposium",
            "pages": "429-446",
            "year": "2021",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZouMNDRRST21",
            "ee": "https://www.usenix.org/conference/usenixsecurity21/presentation/zou",
            "url": "https://dblp.org/rec/conf/uss/ZouMNDRRST21",
            "abstract": "Technology plays an increasingly salient role in facilitating intimate partner violence (IPV). Customer support at computer security companies are receiving cases that involve tech-enabled IPV but might not be well equipped to handle these cases. To assess customer support\u2019s existing practices and identify areas for improvement, we conducted \ufb01ve focus groups with professionals who work with IPV survivors ( n = 17). IPV professionals made numerous suggestions, such as using trauma-informed language, avoiding promises to solve problems, and making referrals to resources and support organizations. To evaluate the practicality of these suggestions, we conducted four focus groups with customer support practitioners ( n = 11). Support practitioners expressed interest in training agents for IPV cases, but mentioned challenges in identifying potential survivors and frontline agents\u2019 limited capacity to help. We conclude with recommendations for computer security companies to better address tech-enabled IPV through training support agents, tracking the prevalence of these cases, and establishing partnerships with IPV advocates.",
            "keywords": [
                "Intimate Partner Violence",
                "Tech-Enabled Abuse",
                "Customer Support Training",
                "Trauma-Informed Practices",
                "Survivor Support Resources"
            ]
        },
        "url": "URL#1888256",
        "sema_paperId": "da2c7170b590372ec6840a189bb6c2ec7c77e10c"
    },
    {
        "@score": "1",
        "@id": "1900195",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "359/0958",
                        "text": "Michael D. Bailey"
                    },
                    {
                        "@pid": "93/655",
                        "text": "Rachel Greenstadt"
                    }
                ]
            },
            "title": "30th USENIX Security Symposium, USENIX Security 2021, August 11-13, 2021",
            "venue": "USENIX Security Symposium",
            "publisher": "USENIX Association",
            "year": "2021",
            "type": "Editorship",
            "access": "open",
            "key": "conf/uss/2021",
            "ee": "https://www.usenix.org/conference/usenixsecurity21",
            "url": "https://dblp.org/rec/conf/uss/2021",
            "abstract": null
        },
        "url": "URL#1900195",
        "sema_paperId": "e9f8f0d755d3bb703abcec5e5b9bd30213e8f057"
    }
]