[
    {
        "@score": "1",
        "@id": "3835574",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "b/MichaelBackes1",
                        "text": "Michael Backes 0001"
                    },
                    {
                        "@pid": "31/7561",
                        "text": "Sven Bugiel"
                    },
                    {
                        "@pid": "180/8205",
                        "text": "Erik Derr"
                    },
                    {
                        "@pid": "m/PatrickDrewMcDaniel",
                        "text": "Patrick D. McDaniel"
                    },
                    {
                        "@pid": "20/11088",
                        "text": "Damien Octeau"
                    },
                    {
                        "@pid": "183/6484",
                        "text": "Sebastian Weisgerber"
                    }
                ]
            },
            "title": "On Demystifying the Android Application Framework: Re-Visiting Android Permission Specification Analysis.",
            "venue": "USENIX Security Symposium",
            "pages": "1101-1118",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0001BDMOW16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/backes_android",
            "url": "https://dblp.org/rec/conf/uss/0001BDMOW16",
            "abstract": "In contrast to the Android application layer, Android\u2019s application framework\u2019s internals and their influence on the platform security and user privacy are still largely a black box for us. In this paper, we establish a static runtime model of the application framework in order to study its internals and provide the first high-level classification of the framework\u2019s protected resources. We thereby uncover design patterns that differ highly from the runtime model at the application layer. We demonstrate the benefits of our insights for security-focused analysis of the framework by re-visiting the important use-case of mapping Android permissions to framework/SDK API methods. We, in particular, present a novel mapping based on our findings that significantly improves on prior results in this area that were established based on insufficient knowledge about the framework\u2019s internals. Moreover, we introduce the concept of permission locality to show that although framework services follow the principle of separation of duty, the accompanying permission checks to guard sensitive operations violate it.",
            "keywords": [
                "Android Application Framework",
                "Permission Specification",
                "Static Runtime Model",
                "Framework Security Analysis",
                "Permission Locality"
            ]
        },
        "url": "URL#3835574",
        "sema_paperId": "186637434af350320f314feb576ddaae4b68560b"
    },
    {
        "@score": "1",
        "@id": "3835575",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "b/MichaelBackes1",
                        "text": "Michael Backes 0001"
                    },
                    {
                        "@pid": "124/6255",
                        "text": "Pascal Berrang"
                    },
                    {
                        "@pid": "185/1719",
                        "text": "Anna Hecksteden"
                    },
                    {
                        "@pid": "83/8816",
                        "text": "Mathias Humbert"
                    },
                    {
                        "@pid": "29/6542",
                        "text": "Andreas Keller"
                    },
                    {
                        "@pid": "60/2923",
                        "text": "Tim Meyer"
                    }
                ]
            },
            "title": "Privacy in Epigenetics: Temporal Linkability of MicroRNA Expression Profiles.",
            "venue": "USENIX Security Symposium",
            "pages": "1223-1240",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0001BHHKM16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/backes_epigenetics",
            "url": "https://dblp.org/rec/conf/uss/0001BHHKM16",
            "abstract": "The decreasing cost of molecular profiling tests, such as DNA sequencing, and the consequent increasing availability of biological data are revolutionizing medicine, but at the same time create novel privacy risks. The research community has already proposed a plethora of methods for protecting genomic data against these risks. However, the privacy risks stemming from epigenetics, which bridges the gap between the genome and our health characteristics, have been largely overlooked so far, even though epigenetic data such as microRNAs (miRNAs) are no less privacy sensitive. This lack of investigation is attributed to the common belief that the inherent temporal variability of miRNAs shields them from being tracked and linked over time. In this paper, we show that, contrary to this belief, miRNA expression profiles can be successfully tracked over time, despite their variability. Specifically, we show that two blood-based miRNA expression profiles taken with a time difference of one week from the same person can be matched with a success rate of 90%. We furthermore observe that this success rate stays almost constant when the time difference is increased from one week to one year. In order to mitigate the linkability threat, we propose and thoroughly evaluate two countermeasures: (i) hiding a subset of disease-irrelevant miRNA expressions, and (ii) probabilistically sanitizing the miRNA expression profiles. Our experiments show that the second mechanism provides a better trade-off between privacy and disease-prediction accuracy.",
            "keywords": [
                "Epigenetics",
                "MicroRNA",
                "Privacy Risks",
                "Temporal Linkability",
                "Data Sanitization"
            ]
        },
        "url": "URL#3835575",
        "sema_paperId": "e4e64c52e52a3e8b1a1d1baf0b117d8dca27a2c5"
    },
    {
        "@score": "1",
        "@id": "3835576",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "138/6356",
                        "text": "Yousra Aafer"
                    },
                    {
                        "@pid": "49/4478",
                        "text": "Xiao Zhang"
                    },
                    {
                        "@pid": "d/WenliangDu",
                        "text": "Wenliang Du"
                    }
                ]
            },
            "title": "Harvesting Inconsistent Security Configurations in Custom Android ROMs via Differential Analysis.",
            "venue": "USENIX Security Symposium",
            "pages": "1153-1168",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AaferZD16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/aafer",
            "url": "https://dblp.org/rec/conf/uss/AaferZD16",
            "abstract": "Android customization offers substantially different experiences and rich functionalities to users. Every party in the customization chain, such as vendors and carriers, modify the OS and the pre-installed apps to tailor their devices for a variety of models, regions, and custom services. However, these modifications do not come at no cost. Several existing studies demonstrate that modifying security configurations during the customization brings in critical security vulnerabilities. Albeit these serious consequences, little has been done to systematically study how Android customization can lead to security problems, and how severe the situation is. In this work, we systematically identified security features that, if altered during the customization, can introduce potential risks. We conducted a large scale differential analysis on 591 custom images to detect inconsistent security features. Our results show that these discrepancies are indeed prevalent among our collected images. We have further identified several risky patterns that warrant further investigation. We have designed attacks on real devices and confirmed that these inconsistencies can indeed lead to actual security breaches.",
            "keywords": [
                "Android Customization",
                "Security Configurations",
                "Differential Analysis",
                "Security Vulnerabilities",
                "Inconsistent Security Features"
            ]
        },
        "url": "URL#3835576",
        "sema_paperId": "feffbbbb3692f118a2fc3ce8d562f1be58d98ac4"
    },
    {
        "@score": "1",
        "@id": "3835578",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "128/2280",
                        "text": "Erdem Alkim"
                    },
                    {
                        "@pid": "65/7849",
                        "text": "L\u00e9o Ducas"
                    },
                    {
                        "@pid": "54/10299",
                        "text": "Thomas P\u00f6ppelmann"
                    },
                    {
                        "@pid": "30/1431",
                        "text": "Peter Schwabe"
                    }
                ]
            },
            "title": "Post-quantum Key Exchange - A New Hope.",
            "venue": "USENIX Security Symposium",
            "pages": "327-343",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AlkimDPS16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/alkim",
            "url": "https://dblp.org/rec/conf/uss/AlkimDPS16",
            "abstract": "At IEEE Security & Privacy 2015, Bos, Costello, Naehrig, and Stebila proposed an instantiation of Peik-ert\u2019s ring-learning-with-errors\u2013based (Ring-LWE) key-exchange protocol (PQCrypto 2014), together with an implementation integrated into OpenSSL, with the af-\ufb01rmed goal of providing post-quantum security for TLS. In this work we revisit their instantiation and stand-alone implementation. Speci\ufb01cally, we propose new parameters and a better suited error distribution, analyze the scheme\u2019s hardness against attacks by quantum computers in a conservative way, introduce a new and more ef\ufb01-cient error-reconciliation mechanism, and propose a defense against backdoors and all-for-the-price-of-one attacks. By these measures and for the same lattice dimen-sion, we more than double the security parameter, halve the communication overhead, and speed up computation by more than a factor of 8 in a portable C implementation and by more than a factor of 27 in an optimized implementation targeting current Intel CPUs. These speedups are achieved with comprehensive protection against timing attacks.",
            "keywords": [
                "Post-quantum Cryptography",
                "Key Exchange Protocols",
                "Ring-LWE",
                "Error Reconciliation",
                "Quantum Resistance"
            ]
        },
        "url": "URL#3835578",
        "sema_paperId": "ca815115e63d4562208e9dbc1d504ab8ae5d2439"
    },
    {
        "@score": "1",
        "@id": "3835579",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "66/3456",
                        "text": "Jos\u00e9 Bacelar Almeida"
                    },
                    {
                        "@pid": "06/5631",
                        "text": "Manuel Barbosa"
                    },
                    {
                        "@pid": "b/GBarthe",
                        "text": "Gilles Barthe"
                    },
                    {
                        "@pid": "57/10027",
                        "text": "Fran\u00e7ois Dupressoir"
                    },
                    {
                        "@pid": "76/5819",
                        "text": "Michael Emmi"
                    }
                ]
            },
            "title": "Verifying Constant-Time Implementations.",
            "venue": "USENIX Security Symposium",
            "pages": "53-70",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AlmeidaBBDE16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/almeida",
            "url": "https://dblp.org/rec/conf/uss/AlmeidaBBDE16",
            "abstract": "The first two authors were funded \nby Project \u201cTEC4Growth - Pervasive Intelligence, \nEnhancers and Proofs of Concept with Industrial \nImpact/NORTE-01-0145-FEDER-000020\u201d, which is fi- \nnanced by the North Portugal Regional Operational \nProgramme (NORTE 2020), under the PORTUGAL \n2020 Partnership Agreement, and through the European Regional Development Fund (ERDF). The third and \nfourth authors were supported by projects S2013/ICE2731 \nN-GREENS Software-CM and ONR Grants \nN000141210914 (AutoCrypt) and N000141512750 (SynCrypt). \nThe fourth author was also supported by FP7 \nMarie Cure Actions-COFUND 291803 (Amarout II). \nWe thank Peter Schwabe for providing us with a collection \nof negative examples. We thank Hovav Shacham, \nCraig Costello and Patrick Longa for helpful observations \non our verification results. TEC4Growth - Pervasive Intelligence, Enhancers and Proofs of Concept with Industrial Impact/NORTE-01-0145-FEDER-000020",
            "keywords": [
                "Constant-Time Implementations",
                "Verification",
                "Cryptographic Algorithms",
                "Security Proofs",
                "Negative Examples"
            ]
        },
        "url": "URL#3835579",
        "sema_paperId": "ccd00728bb3791912117a9c0df3df4bced555b27"
    },
    {
        "@score": "1",
        "@id": "3835580",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "131/5092",
                        "text": "Dennis Andriesse"
                    },
                    {
                        "@pid": "16/3283-38",
                        "text": "Xi Chen 0038"
                    },
                    {
                        "@pid": "119/2260",
                        "text": "Victor van der Veen"
                    },
                    {
                        "@pid": "55/6285",
                        "text": "Asia Slowinska"
                    },
                    {
                        "@pid": "91/800",
                        "text": "Herbert Bos"
                    }
                ]
            },
            "title": "An In-Depth Analysis of Disassembly on Full-Scale x86/x64 Binaries.",
            "venue": "USENIX Security Symposium",
            "pages": "583-600",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AndriesseCVSB16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/andriesse",
            "url": "https://dblp.org/rec/conf/uss/AndriesseCVSB16",
            "abstract": "It is well-known that static disassembly is an unsolved problem, but how much of a problem is it in real software\u2014for instance, for binary protection schemes? This work studies the accuracy of nine state-of-the-art disassemblers on 981 real-world compiler-generated binaries with a wide variety of properties. In contrast, prior work focuses on isolated corner cases; we show that this has led to a widespread and overly pessimistic view on the prevalence of complex constructs like inline data and overlapping code, leading reviewers and researchers to underestimate the potential of binary-based research. On the other hand, some constructs, such as function boundaries, are much harder to recover accurately than is reflected in the literature, which rarely discusses much needed error handling for these primitives. We study 30 papers recently published in six major security venues, and reveal a mismatch between expectations in the literature, and the actual capabilities of modern disassemblers. Our findings help improve future research by eliminating this mismatch.",
            "keywords": [
                "Binary Analysis",
                "Disassembly",
                "Compiler-Generated Binaries",
                "Function Boundaries",
                "Error Handling in Disassembly"
            ]
        },
        "url": "URL#3835580",
        "sema_paperId": "c36fd0fd0a15d9a2c9c111baa818de70250d345b"
    },
    {
        "@score": "1",
        "@id": "3835581",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "132/8480",
                        "text": "Sebastian Angel"
                    },
                    {
                        "@pid": "150/9448",
                        "text": "Riad S. Wahby"
                    },
                    {
                        "@pid": "164/5660",
                        "text": "Max Howald"
                    },
                    {
                        "@pid": "93/8373",
                        "text": "Joshua B. Leners"
                    },
                    {
                        "@pid": "185/1641",
                        "text": "Michael Spilo"
                    },
                    {
                        "@pid": "48/969",
                        "text": "Zhen Sun"
                    },
                    {
                        "@pid": "93/1054",
                        "text": "Andrew J. Blumberg"
                    },
                    {
                        "@pid": "00/2879",
                        "text": "Michael Walfish"
                    }
                ]
            },
            "title": "Defending against Malicious Peripherals with Cinch.",
            "venue": "USENIX Security Symposium",
            "pages": "397-414",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AngelWHLSSBW16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/angel",
            "url": "https://dblp.org/rec/conf/uss/AngelWHLSSBW16",
            "abstract": "Malicious peripherals designed to attack their host computers are a growing problem. Inexpensive and powerful peripherals that attach to plug-and-play buses have made such attacks easy to mount. Making matters worse, commodity operating systems lack coherent defenses, and users are often unaware of the scope of the problem. We present Cinch, a pragmatic response to this threat. Cinch uses virtualization to attach peripheral devices to a logically separate, untrusted machine, and includes an interposition layer between the untrusted machine and the protected one. This layer regulates interaction with devices according to user-configured policies. Cinch integrates with existing OSes, enforces policies that thwart real-world attacks, and has low overhead.",
            "keywords": [
                "Malicious Peripherals",
                "Virtualization",
                "Device Interaction Policies",
                "Interposition Layer",
                "Host Computer Security"
            ]
        },
        "url": "URL#3835581",
        "sema_paperId": "98fb42616329d534c0b0b0da8a1771a780ea7a52"
    },
    {
        "@score": "1",
        "@id": "3835582",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "65/6856",
                        "text": "Frederik Armknecht"
                    },
                    {
                        "@pid": "165/5539",
                        "text": "Ludovic Barman"
                    },
                    {
                        "@pid": "18/2317",
                        "text": "Jens-Matthias Bohli"
                    },
                    {
                        "@pid": "36/1531",
                        "text": "Ghassan O. Karame"
                    }
                ]
            },
            "title": "Mirror: Enabling Proofs of Data Replication and Retrievability in the Cloud.",
            "venue": "USENIX Security Symposium",
            "pages": "1051-1068",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ArmknechtBBK16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/armknecht",
            "url": "https://dblp.org/rec/conf/uss/ArmknechtBBK16",
            "abstract": "Proofs of Retrievability (POR) and Data Possession (PDP) are cryptographic protocols that enable a cloud provider to prove that data is correctly stored in the cloud. PDP have been recently extended to enable users to check in a single protocol that additional file replicas are stored as well. To conduct multi-replica PDP, users are however required to process, construct, and upload their data replicas by themselves. This incurs additional bandwidth overhead on both the service provider and the user and also poses new security risks for the provider. Namely, since uploaded files are typically encrypted, the provider cannot recognize if the uploaded content are indeed replicas. This limits the business models available to the provider, since e.g., reduced costs for storing replicas can be abused by users who upload different files-while claiming that they are replicas. \n \nIn this paper, we address this problem and propose a novel solution for proving data replication and retrievability in the cloud, Mirror, which allows to shift the burden of constructing replicas to the cloud provider itself-thus conforming with the current cloud model. We show that Mirror is secure against malicious users and a rational cloud provider. Finally, we implement a prototype based on Mirror, and evaluate its performance in a realistic cloud setting. Our evaluation results show that our proposal incurs tolerable overhead on the users and the cloud provider.",
            "keywords": [
                "Cloud Storage",
                "Data Replication",
                "Proofs of Retrievability",
                "Cryptographic Protocols",
                "Bandwidth Overhead"
            ]
        },
        "url": "URL#3835582",
        "sema_paperId": "5468cfa054c95df4dd6702f86899f36004fa9b75"
    },
    {
        "@score": "1",
        "@id": "3835583",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "18/1188",
                        "text": "Nimrod Aviram"
                    },
                    {
                        "@pid": "43/11495",
                        "text": "Sebastian Schinzel"
                    },
                    {
                        "@pid": "27/8331",
                        "text": "Juraj Somorovsky"
                    },
                    {
                        "@pid": "12/3207",
                        "text": "Nadia Heninger"
                    },
                    {
                        "@pid": "185/1685",
                        "text": "Maik Dankel"
                    },
                    {
                        "@pid": "185/1672",
                        "text": "Jens Steube"
                    },
                    {
                        "@pid": "166/6979",
                        "text": "Luke Valenta"
                    },
                    {
                        "@pid": "150/5960",
                        "text": "David Adrian"
                    },
                    {
                        "@pid": "h/JAlexHalderman",
                        "text": "J. Alex Halderman"
                    },
                    {
                        "@pid": "185/1686",
                        "text": "Viktor Dukhovni"
                    },
                    {
                        "@pid": "99/4992",
                        "text": "Emilia K\u00e4sper"
                    },
                    {
                        "@pid": "170/3520",
                        "text": "Shaanan Cohney"
                    },
                    {
                        "@pid": "131/5139",
                        "text": "Susanne Engels"
                    },
                    {
                        "@pid": "p/ChristofPaar",
                        "text": "Christof Paar"
                    },
                    {
                        "@pid": "83/1922",
                        "text": "Yuval Shavitt"
                    }
                ]
            },
            "title": "DROWN: Breaking TLS Using SSLv2.",
            "venue": "USENIX Security Symposium",
            "pages": "689-706",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AviramSSHDSVAHD16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/aviram",
            "url": "https://dblp.org/rec/conf/uss/AviramSSHDSVAHD16",
            "abstract": "We present DROWN, a novel cross-protocol attack on TLS that uses a server supporting SSLv2 as an oracle to decrypt modern TLS connections. We introduce two versions of the attack. The more general form exploits multiple unnoticed protocol flaws in SSLv2 to develop a new and stronger variant of the Bleichenbacher RSA padding-oracle attack. To decrypt a 2048-bit RSA TLS ciphertext, an attacker must observe 1,000 TLS handshakes, initiate 40,000 SSLv2 connections, and perform 250 offline work. The victim client never initiates SSLv2 connections. We implemented the attack and can decrypt a TLS 1.2 handshake using 2048bit RSA in under 8 hours, at a cost of $440 on Amazon EC2. Using Internet-wide scans, we find that 33% of all HTTPS servers and 22% of those with browser-trusted certificates are vulnerable to this protocol-level attack due to widespread key and certificate reuse. For an even cheaper attack, we apply our new techniques together with a newly discovered vulnerability in OpenSSL that was present in releases from 1998 to early 2015. Given an unpatched SSLv2 server to use as an oracle, we can decrypt a TLS ciphertext in one minute on a single CPU\u2014fast enough to enable man-in-the-middle attacks against modern browsers. We find that 26% of HTTPS servers are vulnerable to this attack. We further observe that the QUIC protocol is vulnerable to a variant of our attack that allows an attacker to impersonate a server indefinitely after performing as few as 217 SSLv2 connections and 258 offline work. We conclude that SSLv2 is not only weak, but actively harmful to the TLS ecosystem.",
            "keywords": [
                "TLS Protocol",
                "SSLv2 Vulnerability",
                "Cross-Protocol Attack",
                "Decryption Attack",
                "Bleichenbacher RSA Padding-Oracle Attack"
            ]
        },
        "url": "URL#3835583",
        "sema_paperId": "edc055c21a1b23ac5ca05f04a124070932ed66c5"
    },
    {
        "@score": "1",
        "@id": "3835584",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "99/5377",
                        "text": "Karel Bartos"
                    },
                    {
                        "@pid": "43/3969",
                        "text": "Michal Sofka"
                    },
                    {
                        "@pid": "60/1691",
                        "text": "Vojtech Franc"
                    }
                ]
            },
            "title": "Optimized Invariant Representation of Network Traffic for Detecting Unseen Malware Variants.",
            "venue": "USENIX Security Symposium",
            "pages": "807-822",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BartosSF16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/bartos",
            "url": "https://dblp.org/rec/conf/uss/BartosSF16",
            "abstract": "New and unseen polymorphic malware, zero-day attacks, or other types of advanced persistent threats are usually not detected by signature-based security devices, firewalls, or anti-viruses. This represents a challenge to the network security industry as the amount and variability of incidents has been increasing. Consequently, this complicates the design of learning-based detection systems relying on features extracted from network data. The problem is caused by different joint distribution of observation (features) and labels in the training and testing data sets. This paper proposes a classification system designed to detect both known as well as previously-unseen security threats. The classifiers use statistical feature representation computed from the network traffic and learn to recognize malicious behavior. The representation is designed and optimized to be invariant to the most common changes of malware behaviors. This is achieved in part by a feature histogram constructed for each group of HTTP flows (proxy log records) of a user visiting a particular hostname and in part by a feature self-similarity matrix computed for each group. The parameters of the representation (histogram bins) are optimized and learned based on the training samples along with the classifiers. The proposed classification system was deployed on large corporate networks, where it detected 2,090 new and unseen variants of malware samples with 90% precision (9 of 10 alerts were malicious), which is a considerable improvement when compared to the current flow-based approaches or existing signature-based web security devices.",
            "keywords": [
                "Network Traffic Analysis",
                "Polymorphic Malware Detection",
                "Zero-Day Attacks",
                "Feature Representation",
                "Malicious Behavior Recognition"
            ]
        },
        "url": "URL#3835584",
        "sema_paperId": "86ae7d4e6614054a51ec10745ae5930a58b6f2f6"
    },
    {
        "@score": "1",
        "@id": "3835585",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "150/5353",
                        "text": "Muhammad Ahmad Bashir"
                    },
                    {
                        "@pid": "93/7474",
                        "text": "Sajjad Arshad"
                    },
                    {
                        "@pid": "r/WilliamKRobertson",
                        "text": "William K. Robertson"
                    },
                    {
                        "@pid": "79/5135",
                        "text": "Christo Wilson"
                    }
                ]
            },
            "title": "Tracing Information Flows Between Ad Exchanges Using Retargeted Ads.",
            "venue": "USENIX Security Symposium",
            "pages": "481-496",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BashirARW16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/bashir",
            "url": "https://dblp.org/rec/conf/uss/BashirARW16",
            "abstract": "Numerous surveys have shown that Web users are concerned about the loss of privacy associated with online tracking. Alarmingly, these surveys also reveal that people are also unaware of the amount of data sharing that occurs between ad exchanges, and thus underestimate the privacy risks associated with online tracking.\nIn reality, the modern ad ecosystem is fueled by a flow of user data between trackers and ad exchanges. Although recent work has shown that ad exchanges routinely perform cookie matching with other exchanges, these studies are based on brittle heuristics that cannot detect all forms of information sharing, especially under adversarial conditions.\nIn this study, we develop a methodology that is able to detect client- and server-side flows of information between arbitrary ad exchanges. Our key insight is to leverage retargeted ads as a tool for identifying information flows. Intuitively, our methodology works because it relies on the semantics of how exchanges serve ads, rather than focusing on specific cookie matching mechanisms. Using crawled data on 35,448 ad impressions, we show that our methodology can successfully categorize four different kinds of information sharing behavior between ad exchanges, including cases where existing heuristic methods fail.\nWe conclude with a discussion of how our findings and methodologies can be leveraged to give users more control over what kind of ads they see and how their information is shared between ad exchanges.",
            "pdf_url": "",
            "keywords": [
                "Ad Exchanges",
                "Online Tracking",
                "Information Sharing",
                "Retargeted Ads",
                "Privacy Risks"
            ]
        },
        "url": "URL#3835585"
    },
    {
        "@score": "1",
        "@id": "3835586",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "09/5071",
                        "text": "Alex Biryukov"
                    },
                    {
                        "@pid": "22/2499",
                        "text": "Dmitry Khovratovich"
                    }
                ]
            },
            "title": "Egalitarian Computing.",
            "venue": "USENIX Security Symposium",
            "pages": "315-326",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BiryukovK16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/biryukov",
            "url": "https://dblp.org/rec/conf/uss/BiryukovK16",
            "abstract": "In this paper we explore several contexts where an adversary has an upper hand over the defender by using special hardware in an attack. These include password processing, hard-drive protection, cryptocurrency mining, resource sharing, code obfuscation, etc.\nWe suggest memory-hard computing as a generic paradigm, where every task is amalgamated with a certain procedure requiring intensive access to RAM both in terms of size and (very importantly) bandwidth, so that transferring the computation to GPU, FPGA, and even ASIC brings little or no cost reduction. Cryptographic schemes that run in this framework become egalitarian in the sense that both users and attackers are equal in the price-performance ratio conditions.\nBased on existing schemes like Argon2 and the recent generalized-birthday proof-of-work, we suggest a generic framework and two new schemes:\n\nMTP, a memory-hard Proof-of-Work based on the memory-hard function with fast verification and short proofs. It can be also used for memory-hard time-lock puzzles. \nMHE, the concept of memory-hard encryption, which utilizes available RAM to strengthen the encryption for the low-entropy keys (allowing to bring back 6 letter passwords). \n\nKeywords: MTP, MHE, Argon2, memory-hard, asymmetric, proof-of-work, botnets, encryption, timelock puzzles.",
            "pdf_url": "",
            "keywords": [
                "Memory-Hard Computing",
                "Cryptographic Schemes",
                "Proof-of-Work",
                "Memory-Hard Encryption",
                "Timelock Puzzles"
            ]
        },
        "url": "URL#3835586"
    },
    {
        "@score": "1",
        "@id": "3835588",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "74/5570-3",
                        "text": "Yue Cao 0003"
                    },
                    {
                        "@pid": "31/8302",
                        "text": "Zhiyun Qian"
                    },
                    {
                        "@pid": "88/845-2",
                        "text": "Zhongjie Wang 0002"
                    },
                    {
                        "@pid": "156/1148",
                        "text": "Tuan Dao"
                    },
                    {
                        "@pid": "k/SrikanthVKrishnamurthy",
                        "text": "Srikanth V. Krishnamurthy"
                    },
                    {
                        "@pid": "80/314",
                        "text": "Lisa M. Marvel"
                    }
                ]
            },
            "title": "Off-Path TCP Exploits: Global Rate Limit Considered Dangerous.",
            "venue": "USENIX Security Symposium",
            "pages": "209-225",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CaoQWDKM16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/cao",
            "url": "https://dblp.org/rec/conf/uss/CaoQWDKM16",
            "abstract": "In this paper, we report a subtle yet serious side channel vulnerability (CVE-2016-5696) introduced in a recent TCP specification. The specification is faithfully implemented in Linux kernel version 3.6 (from 2012) and beyond, and affects a wide range of devices and hosts. In a nutshell, the vulnerability allows a blind off-path attacker to infer if any two arbitrary hosts on the Internet are communicating using a TCP connection. Further, if the connection is present, such an off-path attacker can also infer the TCP sequence numbers in use, from both sides of the connection; this in turn allows the attacker to cause connection termination and perform data injection attacks. We illustrate how the attack can be leveraged to disrupt or degrade the privacy guarantees of an anonymity network such as Tor, and perform web connection hijacking. Through extensive experiments, we show that the attack is fast and reliable. On average, it takes about 40 to 60 seconds to finish and the success rate is 88% to 97%. Finally, we propose changes to both the TCP specification and implementation to eliminate the root cause of the problem.",
            "keywords": [
                "TCP Vulnerability",
                "Off-Path Attacks",
                "CVE-2016-5696",
                "Sequence Number Inference",
                "Anonymity Network Privacy"
            ]
        },
        "url": "URL#3835588",
        "sema_paperId": "e12b9115a614f50994e7a17c43b0d3b6c46b308e"
    },
    {
        "@score": "1",
        "@id": "3835589",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "145/1806",
                        "text": "Nicholas Carlini"
                    },
                    {
                        "@pid": "161/3103",
                        "text": "Pratyush Mishra"
                    },
                    {
                        "@pid": "162/9041",
                        "text": "Tavish Vaidya"
                    },
                    {
                        "@pid": "168/2335-1",
                        "text": "Yuankai Zhang 0001"
                    },
                    {
                        "@pid": "57/3752",
                        "text": "Micah Sherr"
                    },
                    {
                        "@pid": "82/3920",
                        "text": "Clay Shields"
                    },
                    {
                        "@pid": "42/5626",
                        "text": "David A. Wagner 0001"
                    },
                    {
                        "@pid": "72/1077",
                        "text": "Wenchao Zhou"
                    }
                ]
            },
            "title": "Hidden Voice Commands.",
            "venue": "USENIX Security Symposium",
            "pages": "513-530",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CarliniMVZSSWZ16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/carlini",
            "url": "https://dblp.org/rec/conf/uss/CarliniMVZSSWZ16",
            "abstract": "Voice interfaces are becoming more ubiquitous and are now the primary input method for many devices. We explore in this paper how they can be attacked with hidden voice commands that are unintelligible to human listeners but which are interpreted as commands by devices. \n \nWe evaluate these attacks under two different threat models. In the black-box model, an attacker uses the speech recognition system as an opaque oracle. We show that the adversary can produce difficult to understand commands that are effective against existing systems in the black-box model. Under the white-box model, the attacker has full knowledge of the internals of the speech recognition system and uses it to create attack commands that we demonstrate through user testing are not understandable by humans. \n \nWe then evaluate several defenses, including notifying the user when a voice command is accepted; a verbal challenge-response protocol; and a machine learning approach that can detect our attacks with 99.8% accuracy.",
            "keywords": [
                "Voice Interfaces",
                "Hidden Voice Commands",
                "Speech Recognition Attacks",
                "Black-box and White-box Models",
                "User Notification Defenses"
            ]
        },
        "url": "URL#3835589",
        "sema_paperId": "2efa63a6f629f27ef9f3001f1258c5632483ba25"
    },
    {
        "@score": "1",
        "@id": "3835590",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "125/3305",
                        "text": "Marco Caselli"
                    },
                    {
                        "@pid": "z/EmmanueleZambon",
                        "text": "Emmanuele Zambon"
                    },
                    {
                        "@pid": "150/8002",
                        "text": "Johanna Amann"
                    },
                    {
                        "@pid": "s/RobinSommer",
                        "text": "Robin Sommer"
                    },
                    {
                        "@pid": "46/306",
                        "text": "Frank Kargl"
                    }
                ]
            },
            "title": "Specification Mining for Intrusion Detection in Networked Control Systems.",
            "venue": "USENIX Security Symposium",
            "pages": "791-806",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CaselliZASK16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/caselli",
            "url": "https://dblp.org/rec/conf/uss/CaselliZASK16",
            "abstract": "This paper discusses a novel approach to specification-based intrusion detection in the field of networked control systems. Our approach reduces the substantial human effort required to deploy a specification-based intrusion detection system by automating the development of its specification rules. We observe that networked control systems often include comprehensive documentation used by operators to manage their infrastructures. Our approach leverages the same documentation to automatically derive the specification rules and continuously monitor network traffic. In this paper, we implement this approach for BACnet-based building automation systems and test its effectiveness against two real infrastructures deployed at the University of Twente and the Lawrence Berkeley National Laboratory (LBNL). Our implementation successfully identifies process control mistakes and potentially dangerous misconfigurations. This confirms the need for an improved monitoring of networked control system infrastructures.",
            "keywords": [
                "Networked Control Systems",
                "Intrusion Detection",
                "Specification Mining",
                "BACnet",
                "Process Control Monitoring"
            ]
        },
        "url": "URL#3835590",
        "sema_paperId": "f45664c8acac653b3eb649096bd61fb6f852342f"
    },
    {
        "@score": "1",
        "@id": "3835591",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "42/6163",
                        "text": "Kyong-Tak Cho"
                    },
                    {
                        "@pid": "s/KangGShin",
                        "text": "Kang G. Shin"
                    }
                ]
            },
            "title": "Fingerprinting Electronic Control Units for Vehicle Intrusion Detection.",
            "venue": "USENIX Security Symposium",
            "pages": "911-927",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChoS16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/cho",
            "url": "https://dblp.org/rec/conf/uss/ChoS16",
            "abstract": "As more software modules and external interfaces are getting added on vehicles, new attacks and vulnerabilities are emerging. Researchers have demonstrated how to compromise in-vehicle Electronic Control Units (ECUs) and control the vehicle maneuver. To counter these vulnerabilities, various types of defense mechanisms have been proposed, but they have not been able to meet the need of strong protection for safety-critical ECUs against in-vehicle network attacks. To mitigate this deficiency, we propose an anomaly-based intrusion detection system (IDS), called Clock-based IDS (CIDS). It measures and then exploits the intervals of periodic in-vehicle messages for fingerprinting ECUs. The thus-derived fingerprints are then used for constructing a baseline of ECUs' clock behaviors with the Recursive Least Squares (RLS) algorithm. Based on this baseline, CIDS uses Cumulative Sum (CUSUM) to detect any abnormal shifts in the identification errors - a clear sign of intrusion. This allows quick identification of in-vehicle network intrusions with a low false-positive rate of 0.055%. Unlike state-of-the-art IDSs, if an attack is detected, CIDS's fingerprinting of ECUs also facilitates a rootcause analysis; identifying which ECU mounted the attack. Our experiments on a CAN bus prototype and on real vehicles have shown CIDS to be able to detect a wide range of in-vehicle network attacks.",
            "keywords": [
                "Vehicle Intrusion Detection",
                "Electronic Control Units (ECUs)",
                "Anomaly-based Intrusion Detection System",
                "Clock-based Fingerprinting",
                "In-vehicle Network Attacks"
            ]
        },
        "url": "URL#3835591",
        "sema_paperId": "a3bfe87159938a96d3f2037ff0fe10adca0d21b0"
    },
    {
        "@score": "1",
        "@id": "3835593",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "98/4160",
                        "text": "Victor Costan"
                    },
                    {
                        "@pid": "49/7863",
                        "text": "Ilia A. Lebedev"
                    },
                    {
                        "@pid": "14/3973",
                        "text": "Srinivas Devadas"
                    }
                ]
            },
            "title": "Sanctum: Minimal Hardware Extensions for Strong Software Isolation.",
            "venue": "USENIX Security Symposium",
            "pages": "857-874",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CostanLD16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/costan",
            "url": "https://dblp.org/rec/conf/uss/CostanLD16",
            "abstract": "Sanctum offers the same promise as Intel\u2019s Software Guard Extensions (SGX), namely strong provable isolation of software modules running concurrently and sharing resources, but protects against an important class of additional software attacks that infer private information from a program\u2019s memory access patterns. Sanctum shuns unnecessary complexity, leading to a simpler security analysis. We follow a principled approach to eliminating entire attack surfaces through isolation, rather than plugging attack-specific privacy leaks. Most of Sanctum\u2019s logic is implemented in trusted software, which does not perform cryptographic operations using keys, and is easier to analyze than SGX\u2019s opaque microcode, which does. Our prototype targets a Rocket RISC-V core, an open implementation that allows any researcher to reason about its security properties. Sanctum\u2019s extensions can be adapted to other processor cores, because we do not change any major CPU building block. Instead, we add hardware at the interfaces between generic building blocks, without impacting cycle time. Sanctum demonstrates that strong software isolation is achievable with a surprisingly small set of minimally invasive hardware changes, and a very reasonable overhead.",
            "keywords": [
                "Software Isolation",
                "Hardware Extensions",
                "Memory Access Patterns",
                "Security Analysis",
                "RISC-V Architecture"
            ]
        },
        "url": "URL#3835593",
        "sema_paperId": "a6b03eaccbe40bd3a0e0e9bd3cacdc97afe06791"
    },
    {
        "@score": "1",
        "@id": "3835594",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "185/1654",
                        "text": "Stefano Cristalli"
                    },
                    {
                        "@pid": "144/4297",
                        "text": "Mattia Pagnozzi"
                    },
                    {
                        "@pid": "123/3219",
                        "text": "Mariano Graziano"
                    },
                    {
                        "@pid": "33/2316",
                        "text": "Andrea Lanzi"
                    },
                    {
                        "@pid": "56/490",
                        "text": "Davide Balzarotti"
                    }
                ]
            },
            "title": "Micro-Virtualization Memory Tracing to Detect and Prevent Spraying Attacks.",
            "venue": "USENIX Security Symposium",
            "pages": "431-446",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CristalliPGLB16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/stefano",
            "url": "https://dblp.org/rec/conf/uss/CristalliPGLB16",
            "abstract": "Spraying is a common payload delivery technique used by attackers to execute arbitrary code in presence of Address Space Layout Randomisation (ASLR). In this paper we present Graffiti, an efficient hypervisorbased memory analysis framework for the detection and prevention of spraying attacks. Compared with previous solutions, our system is the first to offer an efficient, complete, extensible, and OS independent protection against all spraying techniques known to date. We developed a prototype open source framework based on our approach, and we thoroughly evaluated it against all known variations of spraying attacks on two operating systems: Linux and Microsoft Windows. Our tool can be applied out of the box to protect any application, and its overhead can be tuned according to the application behavior and to the desired level of protection.",
            "keywords": [
                "Micro-Virtualization",
                "Memory Tracing",
                "Spraying Attacks",
                "Hypervisor-based Protection",
                "Address Space Layout Randomisation (ASLR)"
            ]
        },
        "url": "URL#3835594",
        "sema_paperId": "3c6147a0a6627c2ab6e61ad1d4d81e2f1db9b08c"
    },
    {
        "@score": "1",
        "@id": "3835595",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "146/8228",
                        "text": "Sergej Dechand"
                    },
                    {
                        "@pid": "31/11426",
                        "text": "Dominik Sch\u00fcrmann"
                    },
                    {
                        "@pid": "185/1721",
                        "text": "Karoline Busse"
                    },
                    {
                        "@pid": "132/9687",
                        "text": "Yasemin Acar"
                    },
                    {
                        "@pid": "38/9378",
                        "text": "Sascha Fahl"
                    },
                    {
                        "@pid": "88/5808-1",
                        "text": "Matthew Smith 0001"
                    }
                ]
            },
            "title": "An Empirical Study of Textual Key-Fingerprint Representations.",
            "venue": "USENIX Security Symposium",
            "pages": "193-208",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DechandSBAF016",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/dechand",
            "url": "https://dblp.org/rec/conf/uss/DechandSBAF016",
            "abstract": "Many security protocols still rely on manual fingerprint comparisons for authentication. The most well-known and widely used key-fingerprint representation are hexadecimal strings as used in various security tools. With the introduction of end-to-end security in WhatsApp and other messengers, the discussion on how to best represent key-fingerprints for users is receiving a lot of interest. We conduct a 1047 participant study evaluating six different textual key-fingerprint representations with regards to their performance and usability. We focus on textual fingerprints as the most robust and deployable representation. Our findings show that the currently used hexadecimal representation is more prone to partial preimage attacks in comparison to others. Based on our findings, we make the recommendation that two alternative representations should be adopted. The highest attack detection rate and best usability perception is achieved with a sentence-based encoding. If language-based representations are not acceptable, a simple numeric approach still outperforms the hexadecimal representation.",
            "keywords": [
                "Key-Fingerprint Representation",
                "Textual Fingerprints",
                "Usability Evaluation",
                "Partial Preimage Attacks",
                "Authentication Protocols"
            ]
        },
        "url": "URL#3835595",
        "sema_paperId": "cf19802f752be6153ed60eec93e827aecd7d0950"
    },
    {
        "@score": "1",
        "@id": "3835597",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "138/8987",
                        "text": "Benjamin Dowling"
                    },
                    {
                        "@pid": "67/675",
                        "text": "Douglas Stebila"
                    },
                    {
                        "@pid": "64/5417",
                        "text": "Greg Zaverucha"
                    }
                ]
            },
            "title": "Authenticated Network Time Synchronization.",
            "venue": "USENIX Security Symposium",
            "pages": "823-840",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DowlingSZ16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/dowling",
            "url": "https://dblp.org/rec/conf/uss/DowlingSZ16",
            "abstract": "The Network Time Protocol (NTP) is used by many network-connected devices to synchronize device time with remote servers. Many security features depend on the device knowing the current time, for example in deciding whether a certificate is still valid. Currently, most services implement NTP without authentication, and the authentication mechanisms available in the standard have not been formally analyzed, require a pre-shared key, or are known to have cryptographic weaknesses. In this paper we present an authenticated version of NTP, called ANTP, to protect against desynchronization attacks. To make ANTP suitable for large-scale deployments, it is designed to minimize server-side public-key operations by infrequently performing a key exchange using public key cryptography, then relying solely on symmetric cryptography for subsequent time synchronization requests; moreover, it does so without requiring server-side per-connection state. Additionally, ANTP ensures that authentication does not degrade accuracy of time synchronization. We measured the performance of ANTP by implementing it in OpenNTPD using OpenSSL. Compared to plain NTP, ANTP\u2019s symmetric crypto reduces the server throughput (connections/second) for time synchronization requests by a factor of only 1.6. We analyzed the security of ANTP using a novel provable security framework that involves adversary control of time, and show that ANTP achieves secure time synchronization under standard cryptographic assumptions; our framework may also be used to analyze other candidates for securing NTP.",
            "keywords": [
                "Network Time Protocol",
                "Authenticated Time Synchronization",
                "Desynchronization Attacks",
                "Public Key Cryptography",
                "Symmetric Cryptography"
            ]
        },
        "url": "URL#3835597",
        "sema_paperId": "1db2b38efb2abc34b28ae313b8705a37a041d024"
    },
    {
        "@score": "1",
        "@id": "3835598",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "150/8306",
                        "text": "Kun Du"
                    },
                    {
                        "@pid": "54/4089",
                        "text": "Hao Yang"
                    },
                    {
                        "@pid": "62/4119-1",
                        "text": "Zhou Li 0001"
                    },
                    {
                        "@pid": "36/5143",
                        "text": "Hai-Xin Duan"
                    },
                    {
                        "@pid": "66/6560",
                        "text": "Kehuan Zhang"
                    }
                ]
            },
            "title": "The Ever-Changing Labyrinth: A Large-Scale Analysis of Wildcard DNS Powered Blackhat SEO.",
            "venue": "USENIX Security Symposium",
            "pages": "245-262",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DuYLDZ16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/du",
            "url": "https://dblp.org/rec/conf/uss/DuYLDZ16",
            "abstract": "Blackhat Search Engine Optimization (SEO) has been widely used to promote spam or malicious web sites. Traditional blackhat SEO campaigns often target hot keywords and establish link networks by spamming popular forums or compromising vulnerable sites. However, such SEO campaigns are actively disrupted by search engines providers, making the operational cost much higher in recent years. In this paper, we reveal a new type of blackhat SEO infrastructure (called \u201cspider pool\u201d) which seeks a different operational model. The owners of spider pools use cheap domains with low PR (PageRank) values to construct link networks and poison longtail keywords. To get better rankings of their promoted content, the owners have to reduce the indexing latencies by search engines. To this end, they abuse wildcard DNS to create virtually infinite sites and construct complicated loop structure to force search-engine crawlers to visit them relentlessly. We carried out a comprehensive study to understand this emerging threat. As a starting point, we infiltrated a spider pool service and built a detection system to explore all the recruited SEO domains to learn how they were orchestrated. Exploiting the unique features of the spider pool, we developed a scanner which examined over 13 million domains under 22 TLDs/SLDs and discovered over 458K SEO domains. Finally, we measured the spider-pool ecosystem on top of these domains and analyzed the crawling results from 21 spider pools. The measurement result reveals their infrastructure features, customer categories and impact on search engines. We hope our study could inspire new mitigation methods and improve the ranking or indexing metrics from search engines.",
            "keywords": [
                "Blackhat SEO",
                "Wildcard DNS",
                "Spider Pool",
                "SEO Domains",
                "Search Engine Crawling"
            ]
        },
        "url": "URL#3835598",
        "sema_paperId": "88a0a5f7dab7ca987d17d3bbdb4e49d3fbf439bc"
    },
    {
        "@score": "1",
        "@id": "3835599",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "13/10811",
                        "text": "Eslam Elnikety"
                    },
                    {
                        "@pid": "161/0164",
                        "text": "Aastha Mehta"
                    },
                    {
                        "@pid": "161/0161",
                        "text": "Anjo Vahldiek-Oberwagner"
                    },
                    {
                        "@pid": "45/6786-1",
                        "text": "Deepak Garg 0001"
                    },
                    {
                        "@pid": "d/PDruschel",
                        "text": "Peter Druschel"
                    }
                ]
            },
            "title": "Thoth: Comprehensive Policy Compliance in Data Retrieval Systems.",
            "venue": "USENIX Security Symposium",
            "pages": "637-654",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ElniketyMV0D16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/elnikety",
            "url": "https://dblp.org/rec/conf/uss/ElniketyMV0D16",
            "abstract": "Data retrieval systems process data from many sources, each subject to its own data use policy. Ensuring compliance with these policies despite bugs, misconfiguration, or operator error in a large, complex, and fast evolving system is a major challenge. Thoth provides an efficient, kernel-level compliance layer for data use policies. Declarative policies are attached to the systems\u2019 input and output files, key-value tuples, and network connections, and specify the data\u2019s integrity and confidentiality requirements. Thoth tracks the flow of data through the system, and enforces policy regardless of bugs, misconfigurations, compromises in application code, or actions by unprivileged operators. Thoth requires minimal changes to an existing system and has modest overhead, as we show using a prototype Thoth-enabled data retrieval system based on the popular Apache Lucene.",
            "keywords": [
                "Data Retrieval Systems",
                "Policy Compliance",
                "Data Flow Tracking",
                "Integrity and Confidentiality",
                "Kernel-Level Enforcement"
            ]
        },
        "url": "URL#3835599",
        "sema_paperId": "2449a067370ca24353ee8e9fd5e8187cf08ca8f7"
    },
    {
        "@score": "1",
        "@id": "3835600",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "97/535",
                        "text": "Kassem Fawaz"
                    },
                    {
                        "@pid": "10/5900",
                        "text": "Kyu-Han Kim"
                    },
                    {
                        "@pid": "s/KangGShin",
                        "text": "Kang G. Shin"
                    }
                ]
            },
            "title": "Protecting Privacy of BLE Device Users.",
            "venue": "USENIX Security Symposium",
            "pages": "1205-1221",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/FawazKS16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/fawaz",
            "url": "https://dblp.org/rec/conf/uss/FawazKS16",
            "abstract": "Bluetooth Low Energy (BLE) has emerged as an attractive technology to enable Internet of Things (IoTs) to interact with others in their vicinity. Our study of the behavior of more than 200 types of BLE-equipped devices has led to a surprising discovery: the BLE protocol, despite its privacy provisions, fails to address the most basic threat of all\u2014hiding the device\u2019s presence from curious adversaries. Revealing the device\u2019s existence is the stepping stone toward more serious threats that include user profiling/fingerprinting, behavior tracking, inference of sensitive information, and exploitation of known vulnerabilities on the device. With thousands of manufacturers and developers around the world, it is very challenging, if not impossible, to envision the viability of any privacy or security solution that requires changes to the devices or the BLE protocol. In this paper, we propose a new device-agnostic system, called BLE-Guardian, that protects the privacy of the users/environments equipped with BLE devices/IoTs. It enables the users and administrators to control those who discover, scan and connect to their devices. We have implemented BLE-Guardian using Ubertooth One, an off-the-shelf open Bluetooth development platform, facilitating its broad deployment. Our evaluation with real devices shows that BLE-Guardian effectively protects the users\u2019 privacy while incurring little overhead on the communicating BLE-devices.",
            "keywords": [
                "Bluetooth Low Energy (BLE)",
                "Privacy Protection",
                "Device Discovery",
                "User Profiling",
                "BLE-Guardian"
            ]
        },
        "url": "URL#3835600",
        "sema_paperId": "558380e0cba2c5bcda7d4d94e23f215ede0e910f"
    },
    {
        "@score": "1",
        "@id": "3835602",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "16/10817",
                        "text": "Earlence Fernandes"
                    },
                    {
                        "@pid": "153/5789",
                        "text": "Justin Paupore"
                    },
                    {
                        "@pid": "125/0358",
                        "text": "Amir Rahmati"
                    },
                    {
                        "@pid": "153/5772",
                        "text": "Daniel Simionato"
                    },
                    {
                        "@pid": "82/4386",
                        "text": "Mauro Conti"
                    },
                    {
                        "@pid": "p/AtulPrakash",
                        "text": "Atul Prakash 0001"
                    }
                ]
            },
            "title": "FlowFence: Practical Data Protection for Emerging IoT Application Frameworks.",
            "venue": "USENIX Security Symposium",
            "pages": "531-548",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/FernandesPRSCP16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/fernandes",
            "url": "https://dblp.org/rec/conf/uss/FernandesPRSCP16",
            "abstract": "Emerging IoT programming frameworks enable building apps that compute on sensitive data produced by smart homes and wearables. However, these frameworks only support permission-based access control on sensitive data, which is ineffective at controlling how apps use data once they gain access. To address this limitation, we present FlowFence, a system that requires consumers of sensitive data to declare their intended data flow patterns, which it enforces with low overhead, while blocking all other undeclared flows. FlowFence achieves this by explicitly embedding data flows and the related control flows within app structure. Developers use Flow-Fence support to split their apps into two components: (1) A set of Quarantined Modules that operate on sensitive data in sandboxes, and (2) Code that does not operate on sensitive data but orchestrates execution by chaining Quarantined Modules together via taint-tracked opaque handles-references to data that can only be dereferenced inside sandboxes. We studied three existing IoT frameworks to derive key functionality goals for Flow-Fence, and we then ported three existing IoT apps. Securing these apps using FlowFence resulted in an average increase in size from 232 lines to 332 lines of source code. Performance results on ported apps indicate that FlowFence is practical: A face-recognition based door-controller app incurred a 4.9% latency overhead to recognize a face and unlock a door.",
            "keywords": [
                "IoT Application Frameworks",
                "Data Flow Control",
                "Sensitive Data Protection",
                "Quarantined Modules",
                "Taint Tracking"
            ]
        },
        "url": "URL#3835602",
        "sema_paperId": "dff67e4bb1276f89ab663ceb6c9bb25ca8cf3dec"
    },
    {
        "@score": "1",
        "@id": "3835604",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "42/1707",
                        "text": "Flavio D. Garcia"
                    },
                    {
                        "@pid": "190/2073",
                        "text": "David F. Oswald"
                    },
                    {
                        "@pid": "56/1351",
                        "text": "Timo Kasper"
                    },
                    {
                        "@pid": "185/1629",
                        "text": "Pierre Pavlid\u00e8s"
                    }
                ]
            },
            "title": "Lock It and Still Lose It - on the (In)Security of Automotive Remote Keyless Entry Systems.",
            "venue": "USENIX Security Symposium",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GarciaOKP16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/garcia",
            "url": "https://dblp.org/rec/conf/uss/GarciaOKP16",
            "abstract": "While most automotive immobilizer systems have been shown to be insecure in the last few years, the security of remote keyless entry systems (to lock and unlock a car) based on rolling codes has received less attention. In this paper, we close this gap and present vulnerabilities in keyless entry schemes used by major manufacturers. In our first case study, we show that the security of the keyless entry systems of most VW Group vehicles manufactured between 1995 and today relies on a few, global master keys. We show that by recovering the cryptographic algorithms and keys from electronic control units, an adversary is able to clone a VW Group remote control and gain unauthorized access to a vehicle by eavesdropping a single signal sent by the original remote. Secondly, we describe the Hitag2 rolling code scheme (used in vehicles made by Alfa Romeo, Chevrolet, Peugeot, Lancia, Opel, Renault, and Ford among others) in full detail. We present a novel correlation-based attack on Hitag2, which allows recovery of the cryptographic key and thus cloning of the remote control with four to eight rolling codes and a few minutes of computation on a laptop. Our findings affect millions of vehicles worldwide and could explain unsolved insurance cases of theft from allegedly locked vehicles.",
            "keywords": [
                "Automotive Security",
                "Remote Keyless Entry",
                "Vulnerability Assessment",
                "Rolling Code Attacks",
                "Key Cloning"
            ]
        },
        "url": "URL#3835604",
        "sema_paperId": "67acd40c4dbc19669886361fb8bcff43b038c224"
    },
    {
        "@score": "1",
        "@id": "3835605",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "129/9491",
                        "text": "Christina Garman"
                    },
                    {
                        "@pid": "74/4531-1",
                        "text": "Matthew Green 0001"
                    },
                    {
                        "@pid": "185/1661",
                        "text": "Gabriel Kaptchuk"
                    },
                    {
                        "@pid": "129/9500",
                        "text": "Ian Miers"
                    },
                    {
                        "@pid": "129/9487",
                        "text": "Michael Rushanan"
                    }
                ]
            },
            "title": "Dancing on the Lip of the Volcano: Chosen Ciphertext Attacks on Apple iMessage.",
            "venue": "USENIX Security Symposium",
            "pages": "655-672",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Garman0KMR16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/garman",
            "url": "https://dblp.org/rec/conf/uss/Garman0KMR16",
            "abstract": "Apple's iMessage is one of the most widely-deployed end-to-end encrypted messaging protocols. Despite its broad deployment, the encryption protocols used by iMessage have never been subjected to rigorous crypt-analysis. In this paper, we conduct a thorough analysis of iMessage to determine the security of the protocol against a variety of attacks. Our analysis shows that iMessage has significant vulnerabilities that can be exploited by a sophisticated attacker. In particular, we outline a novel chosen ciphertext attack on Huffman compressed data, which allows retrospective decryption of some iMessage payloads in less than 218 queries. The practical implication of these attacks is that any party who gains access to iMessage ciphertexts may potentially decrypt them remotely and after the fact. We additionally describe mitigations that will prevent these attacks on the protocol, without breaking backwards compatibility. Apple has deployed our mitigations in the latest iOS and OS X releases.",
            "keywords": [
                "End-to-End Encryption",
                "iMessage Protocol",
                "Chosen Ciphertext Attack",
                "Cryptanalysis",
                "Huffman Compression Vulnerabilities"
            ]
        },
        "url": "URL#3835605",
        "sema_paperId": "ad1ecf8b4a020bead176f8a7ab2d56f50b3b77bf"
    },
    {
        "@score": "1",
        "@id": "3835606",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "136/5992",
                        "text": "Irene Giacomelli"
                    },
                    {
                        "@pid": "177/2255",
                        "text": "Jesper Madsen"
                    },
                    {
                        "@pid": "o/ClaudioOrlandi",
                        "text": "Claudio Orlandi"
                    }
                ]
            },
            "title": "ZKBoo: Faster Zero-Knowledge for Boolean Circuits.",
            "venue": "USENIX Security Symposium",
            "pages": "1069-1083",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GiacomelliMO16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/giacomelli",
            "url": "https://dblp.org/rec/conf/uss/GiacomelliMO16",
            "abstract": "In this paper we describe ZKBoo1, a proposal for practically efficient zero-knowledge arguments especially tailored for Boolean circuits and report on a proof-ofconcept implementation. As an highlight, we can generate (resp. verify) a non-interactive proof for the SHA-1 circuit in approximately 13ms (resp. 5ms), with a proof size of 444KB. Our techniques are based on the \u201cMPC-in-the-head\u201d approach to zero-knowledge of Ishai et al. (IKOS), which has been successfully used to achieve significant asymptotic improvements. Our contributions include: \u25e6 A thorough analysis of the different variants of IKOS, which highlights their pros and cons for practically relevant soundness parameters; \u25e6 A generalization and simplification of their approach, which leads to faster \u03a3-protocols (that can be made non-interactive using the Fiat-Shamir heuristic) for statements of the form \u201cI know x such that y = \u03c6(x)\u201d (where \u03c6 is a circuit and y a public value); \u25e6 A case study, where we provide explicit protocols, implementations and benchmarking of zero-knowledge protocols for the SHA-1 and SHA-256 circuits.",
            "keywords": [
                "Zero-Knowledge Proofs",
                "Boolean Circuits",
                "Non-Interactive Proofs",
                "MPC-in-the-Head",
                "SHA-1 and SHA-256 Protocols"
            ]
        },
        "url": "URL#3835606",
        "sema_paperId": "75f5acbbd9ee8d1b133b707d79a2cf4a93351780"
    },
    {
        "@score": "1",
        "@id": "3835607",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "147/2244",
                        "text": "Tom van Goethem"
                    },
                    {
                        "@pid": "130/3608",
                        "text": "Mathy Vanhoef"
                    },
                    {
                        "@pid": "85/6647",
                        "text": "Frank Piessens"
                    },
                    {
                        "@pid": "13/86",
                        "text": "Wouter Joosen"
                    }
                ]
            },
            "title": "Request and Conquer: Exposing Cross-Origin Resource Size.",
            "venue": "USENIX Security Symposium",
            "pages": "447-462",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GoethemVPJ16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/goethem",
            "url": "https://dblp.org/rec/conf/uss/GoethemVPJ16",
            "abstract": "Numerous initiatives are encouraging website owners to enable and enforce TLS encryption for the communication between the server and their users. Although this encryption, when configured properly, completely prevents adversaries from disclosing the content of the traffic, certain features are not concealed, most notably the size of messages. As modern-day web applications tend to provide users with a view that is tailored to the information they entrust these web services with, it is clear that knowing the size of specific resources, an adversary can easily uncover personal and sensitive information. In this paper, we explore various techniques that can be employed to reveal the size of resources. As a result of this in-depth analysis, we discover several design flaws in the storage mechanisms of browsers, which allows an adversary to expose the exact size of any resource in mere seconds. Furthermore, we report on a novel size-exposing technique against Wi-Fi networks. We evaluate the severity of our attacks, and show their worrying consequences in multiple real-world attack scenarios. Furthermore, we propose an improved design for browser storage, and explore other viable solutions that can thwart size-exposing attacks.",
            "keywords": [
                "Cross-Origin Resource Size",
                "TLS Encryption",
                "Size-Exposing Attacks",
                "Browser Storage Mechanisms",
                "Wi-Fi Network Vulnerabilities"
            ]
        },
        "url": "URL#3835607",
        "sema_paperId": "f2ce83e32ef5973d3a78673cec22e81e86dc72b4"
    },
    {
        "@score": "1",
        "@id": "3835608",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "150/5208",
                        "text": "Enes G\u00f6ktas"
                    },
                    {
                        "@pid": "150/5154",
                        "text": "Robert Gawlik"
                    },
                    {
                        "@pid": "153/5832",
                        "text": "Benjamin Kollenda"
                    },
                    {
                        "@pid": "51/4565",
                        "text": "Elias Athanasopoulos"
                    },
                    {
                        "@pid": "44/3319",
                        "text": "Georgios Portokalidis"
                    },
                    {
                        "@pid": "75/8194",
                        "text": "Cristiano Giuffrida"
                    },
                    {
                        "@pid": "91/800",
                        "text": "Herbert Bos"
                    }
                ]
            },
            "title": "Undermining Information Hiding (and What to Do about It).",
            "venue": "USENIX Security Symposium",
            "pages": "105-119",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GoktasGKAPGB16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/goktas",
            "url": "https://dblp.org/rec/conf/uss/GoktasGKAPGB16",
            "abstract": "In the absence of hardware-supported segmentation, many state-of-the-art defenses resort to \u201chiding\u201d sensitive information at a random location in a very large address space. This paper argues that information hiding is a weak isolation model and shows that attackers can find hidden information, such as CPI\u2019s SafeStacks, in seconds\u2014by means of thread spraying. Thread spraying is a novel attack technique which forces the victim program to allocate many hidden areas. As a result, the attacker has a much better chance to locate these areas and compromise the defense. We demonstrate the technique by means of attacks on Firefox, Chrome, and MySQL. In addition, we found that it is hard to remove all sensitive information (such as pointers to the hidden region) from a program and show how residual sensitive information allows attackers to bypass defenses completely. We also show how we can harden information hiding techniques by means of an Authenticating Page Mapper (APM) which builds on a user-level page-fault handler to authenticate arbitrary memory reads/writes in the virtual address space. APM bootstraps protected applications with a minimum-sized safe area. Every time the program accesses this area, APM authenticates the access operation, and, if legitimate, expands the area on demand. We demonstrate that APM hardens information hiding significantly while increasing the overhead, on average, 0.3% on baseline SPEC CPU 2006, 0.0% on SPEC with SafeStack and 1.4% on SPEC with CPI.",
            "keywords": [
                "Information Hiding",
                "Memory Safety",
                "Thread Spraying",
                "Attack Techniques",
                "Authenticating Page Mapper (APM)"
            ]
        },
        "url": "URL#3835608",
        "sema_paperId": "3013fc25ace9eca344cb936124a42171d72b95ec"
    },
    {
        "@score": "1",
        "@id": "3835609",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "03/9437",
                        "text": "Neil Zhenqiang Gong"
                    },
                    {
                        "@pid": "35/837-45",
                        "text": "Bin Liu 0045"
                    }
                ]
            },
            "title": "You Are Who You Know and How You Behave: Attribute Inference Attacks via Users&apos; Social Friends and Behaviors.",
            "venue": "USENIX Security Symposium",
            "pages": "979-995",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GongL16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/gong",
            "url": "https://dblp.org/rec/conf/uss/GongL16",
            "abstract": "We propose new privacy attacks to infer attributes (e.g., locations, occupations, and interests) of online social network users. Our attacks leverage seemingly innocent user information that is publicly available in online social networks to infer missing attributes of targeted users. Given the increasing availability of (seemingly innocent) user information online, our results have serious implications for Internet privacy -- private attributes can be inferred from users' publicly available data unless we take steps to protect users from such inference attacks. \nTo infer attributes of a targeted user, existing inference attacks leverage either the user's publicly available social friends or the user's behavioral records (e.g., the webpages that the user has liked on Facebook, the apps that the user has reviewed on Google Play), but not both. As we will show, such inference attacks achieve limited success rates. However, the problem becomes qualitatively different if we consider both social friends and behavioral records. To address this challenge, we develop a novel model to integrate social friends and behavioral records and design new attacks based on our model. We theoretically and experimentally demonstrate the effectiveness of our attacks. For instance, we observe that, in a real-world large-scale dataset with 1.1 million users, our attack can correctly infer the cities a user lived in for 57% of the users, via confidence estimation, we are able to increase the attack success rate to over 90% if the attacker selectively attacks a half of the users. Moreover, we show that our attack can correctly infer attributes for significantly more users than previous attacks.",
            "keywords": [
                "Privacy Attacks",
                "Social Networks",
                "Attribute Inference",
                "User Behavior",
                "Data Privacy"
            ]
        },
        "url": "URL#3835609",
        "sema_paperId": "03508376a5b1352e132e78a4dfa86236d6a096a2"
    },
    {
        "@score": "1",
        "@id": "3835610",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "168/8164",
                        "text": "Jamie Hayes"
                    },
                    {
                        "@pid": "11/1148",
                        "text": "George Danezis"
                    }
                ]
            },
            "title": "k-fingerprinting: A Robust Scalable Website Fingerprinting Technique.",
            "venue": "USENIX Security Symposium",
            "pages": "1187-1203",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HayesD16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/hayes",
            "url": "https://dblp.org/rec/conf/uss/HayesD16",
            "abstract": "Website fingerprinting enables an attacker to infer which web page a client is browsing through encrypted or anonymized network connections. We present a new website fingerprinting technique based on random decision forests and evaluate performance over standard web pages as well as Tor hidden services, on a larger scale than previous works. Our technique, k-fingerprinting, performs better than current state-of-the-art attacks even against website fingerprinting defenses, and we show that it is possible to launch a website fingerprinting attack in the face of a large amount of noisy data. We can correctly determine which of 30 monitored hidden services a client is visiting with 85% true positive rate (TPR), a false positive rate (FPR) as low as 0.02%, from a world size of 100,000 unmonitored web pages. We further show that error rates vary widely between web resources, and thus some patterns of use will be predictably more vulnerable to attack than others.",
            "keywords": [
                "Website Fingerprinting",
                "Random Decision Forests",
                "Tor Hidden Services",
                "True Positive Rate",
                "False Positive Rate"
            ]
        },
        "url": "URL#3835610",
        "sema_paperId": "b10c4f0ccade4e584415f407f5a9c115a607f9e0"
    },
    {
        "@score": "1",
        "@id": "3835612",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "74/28",
                        "text": "Suman Jana"
                    },
                    {
                        "@pid": "185/1666",
                        "text": "Yuan Jochen Kang"
                    },
                    {
                        "@pid": "185/1635",
                        "text": "Samuel Roth"
                    },
                    {
                        "@pid": "74/1969",
                        "text": "Baishakhi Ray"
                    }
                ]
            },
            "title": "Automatically Detecting Error Handling Bugs Using Error Specifications.",
            "venue": "USENIX Security Symposium",
            "pages": "345-362",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/JanaKRR16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/jana",
            "url": "https://dblp.org/rec/conf/uss/JanaKRR16",
            "abstract": "Incorrect error handling in security-sensitive code often leads to severe security vulnerabilities. Implementing correct error handling is repetitive and tedious especially in languages like C that do not support any exception handling primitives. This makes it very easy for the developers to unwittingly introduce error handling bugs. Moreover, error handling bugs are hard to detect and locate using existing bug-finding techniques because many of these bugs do not display any obviously erroneous behaviors (e.g., crash and assertion failure) but cause subtle inaccuracies. In this paper, we design, implement, and evaluate EPEX, a tool that uses error specifications to identify and symbolically explore different error paths and reports bugs when any errors are handled incorrectly along these paths. The key insights behind our approach are: (i) real-world programs often handle errors only in a limited number of ways and (ii) most functions have simple and consistent error specifications. This allows us to create a simple oracle that can detect a large class of error handling bugs across a wide range of programs. We evaluated EPEX on 867,000 lines of C Code from four different open-source SSL/TLS libraries (OpenSSL, GnuTLS, mbedTLS, and wolfSSL) and 5 different applications that use SSL/TLS API (Apache httpd, cURL, Wget, LYNX, and Mutt). EPEx discovered 102 new error handling bugs across these programs\u2014at least 53 of which lead to security flaws that break the security guarantees of SSL/TLS. EPEX has a low false positive rate (28 out of 130 reported bugs) as well as a low false negative rate (20 out of 960 reported correct error handling cases).",
            "keywords": [
                "Error Handling Bugs",
                "Security Vulnerabilities",
                "C Programming",
                "Error Specifications",
                "Symbolic Exploration"
            ]
        },
        "url": "URL#3835612",
        "sema_paperId": "13702681da7d276b2891c961f842c4f08dee82a6"
    },
    {
        "@score": "1",
        "@id": "3835613",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "150/8000",
                        "text": "Yaoqi Jia"
                    },
                    {
                        "@pid": "77/11487",
                        "text": "Tarik Moataz"
                    },
                    {
                        "@pid": "136/8442",
                        "text": "Shruti Tople"
                    },
                    {
                        "@pid": "90/105",
                        "text": "Prateek Saxena"
                    }
                ]
            },
            "title": "OblivP2P: An Oblivious Peer-to-Peer Content Sharing System.",
            "venue": "USENIX Security Symposium",
            "pages": "945-962",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/JiaMTS16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/jia",
            "url": "https://dblp.org/rec/conf/uss/JiaMTS16",
            "abstract": "Peer-to-peer (P2P) systems are predominantly used to distribute trust, increase availability and improve performance. A number of content-sharing P2P systems, for file-sharing applications (e.g., BitTorrent and Storj) and more recent peer-assisted CDNs (e.g., Akamai Netsession), are finding wide deployment. A major security concern with content-sharing P2P systems is the risk of long-term traffic analysis\u2014a widely accepted challenge with few known solutions. In this paper, we propose a new approach to protecting against persistent, global traffic analysis in P2P content sharing systems. Our approach advocates for hiding data access patterns, making P2P systems oblivious. We propose OBLIVP2P\u2014 a construction for a scalable distributed ORAM protocol, usable in a real P2P setting. Our protocol achieves the following results. First, we show that our construction retains the (linear) scalability of the original P2P network w.r.t the number of peers. Second, our experiments simulating about 16,384 peers on 15 Deterlab nodes can process up to 7 requests of 512KB each per second, suggesting usability in moderately latency-sensitive applications as-is. The bottlenecks remaining are purely computational (not bandwidth). Third, our experiments confirm that in our construction, no centralized infrastructure is a bottleneck \u2014 essentially, ensuring that the network and computational overheads can be completely offloaded to the P2P network. Finally, our construction is highly parallelizable, which implies that remaining computational bottlenecks can be drastically reduced if OBLIVP2P is deployed on a network with many real machines.",
            "keywords": [
                "Peer-to-Peer Systems",
                "Content Sharing",
                "Traffic Analysis",
                "Oblivious Data Access",
                "Scalable ORAM Protocol"
            ]
        },
        "url": "URL#3835613",
        "sema_paperId": "d926b9bc9f64817703bf5f55eb9d1d6bf38e9546"
    },
    {
        "@score": "1",
        "@id": "3835616",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "151/4105",
                        "text": "Amin Kharraz"
                    },
                    {
                        "@pid": "93/7474",
                        "text": "Sajjad Arshad"
                    },
                    {
                        "@pid": "34/1145",
                        "text": "Collin Mulliner"
                    },
                    {
                        "@pid": "r/WilliamKRobertson",
                        "text": "William K. Robertson"
                    },
                    {
                        "@pid": "k/EnginKirda",
                        "text": "Engin Kirda"
                    }
                ]
            },
            "title": "UNVEIL: A Large-Scale, Automated Approach to Detecting Ransomware.",
            "venue": "USENIX Security Symposium",
            "pages": "757-772",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KharrazAMRK16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/kharaz",
            "url": "https://dblp.org/rec/conf/uss/KharrazAMRK16",
            "abstract": "Although the concept of ransomware is not new (i.e., such attacks date back at least as far as the 1980s), this type of malware has recently experienced a resurgence in popularity. In fact, in the last few years, a number of high-profile ransomware attacks were reported, such as the large-scale attack against Sony that prompted the company to delay the release of the film \u201cThe Interview.\u201d Ransomware typically operates by locking the desktop of the victim to render the system inaccessible to the user, or by encrypting, overwriting, or deleting the user\u2019s files. However, while many generic malware detection systems have been proposed, none of these systems have attempted to specifically address the ransomware detection problem.\nIn this paper, we present a novel dynamic analysis system called UNVEIL that is specifically designed to detect ransomware. The key insight of the analysis is that in order to mount a successful attack, ransomware must tamper with a user\u2019s files or desktop. UNVEIL automatically generates an artificial user environment, and detects when ransomware interacts with user data. In parallel, the approach tracks changes to the system\u2019s desktop that indicate ransomware-like behavior. Our evaluation shows that UNVEIL significantly improves the state of the art, and is able to identify previously unknown evasive ransomware that was not detected by the antimalware industry.",
            "pdf_url": "",
            "keywords": [
                "Ransomware Detection",
                "Dynamic Analysis",
                "Malware Analysis",
                "User Data Interaction",
                "Evasive Ransomware"
            ]
        },
        "url": "URL#3835616"
    },
    {
        "@score": "1",
        "@id": "3835619",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "131/5093",
                        "text": "David Kohlbrenner"
                    },
                    {
                        "@pid": "35/1061",
                        "text": "Hovav Shacham"
                    }
                ]
            },
            "title": "Trusted Browsers for Uncertain Times.",
            "venue": "USENIX Security Symposium",
            "pages": "463-480",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KohlbrennerS16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/kohlbrenner",
            "url": "https://dblp.org/rec/conf/uss/KohlbrennerS16",
            "abstract": "JavaScript in one origin can use timing channels in browsers to learn sensitive information about a user\u2019s interaction with other origins, violating the browser\u2019s compartmentalization guarantees. Browser vendors have attempted to close timing channels by trying to rewrite sensitive code to run in constant time and by reducing the resolution of reference clocks. We argue that these ad-hoc efforts are unlikely to succeed. We show techniques that increase the effective resolution of degraded clocks by two orders of magnitude, and we present and evaluate multiple, new implicit clocks: techniques by which JavaScript can time events without consulting an explicit clock at all. We show how \u201cfuzzy time\u201d ideas in the trusted operating systems literature can be adapted to building trusted browsers, degrading all clocks and reducing the bandwidth of all timing channels. We describe the design of a next-generation browser, called Fermata, in which all timing sources are completely mediated. As a proof of feasibility, we present Fuzzyfox, a fork of the Firefox browser that implements many of the Fermata principles within the constraints of today\u2019s browser architecture. We show that Fuzzyfox achieves sufficient compatibility and performance for deployment today by privacysensitive users.",
            "keywords": [
                "Timing Channels",
                "Browser Security",
                "Privacy Preservation",
                "Fuzzy Time",
                "Fermata Browser"
            ]
        },
        "url": "URL#3835619",
        "sema_paperId": "4754a7bcf4c4252b0ff6171a559ca7b26010fbb8"
    },
    {
        "@score": "1",
        "@id": "3835620",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "176/5301",
                        "text": "Eleftherios Kokoris-Kogias"
                    },
                    {
                        "@pid": "14/11314",
                        "text": "Philipp Jovanovic"
                    },
                    {
                        "@pid": "176/5570",
                        "text": "Nicolas Gailly"
                    },
                    {
                        "@pid": "176/5341",
                        "text": "Ismail Khoffi"
                    },
                    {
                        "@pid": "122/9716",
                        "text": "Linus Gasser"
                    },
                    {
                        "@pid": "f/BryanFord",
                        "text": "Bryan Ford"
                    }
                ]
            },
            "title": "Enhancing Bitcoin Security and Performance with Strong Consistency via Collective Signing.",
            "venue": "USENIX Security Symposium",
            "pages": "279-296",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Kokoris-KogiasJ16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/kogias",
            "url": "https://dblp.org/rec/conf/uss/Kokoris-KogiasJ16",
            "abstract": "While showing great promise, Bitcoin requires users to wait tens of minutes for transactions to commit, and even then, offering only probabilistic guarantees. This paper introduces ByzCoin, a novel Byzantine consensus protocol that leverages scalable collective signing to commit Bitcoin transactions irreversibly within seconds. ByzCoin achieves Byzantine consensus while preserving Bitcoin's open membership by dynamically forming hash power-proportionate consensus groups that represent recently-successful block miners. ByzCoin employs communication trees to optimize transaction commitment and verification under normal operation while guaranteeing safety and liveness under Byzantine faults, up to a near-optimal tolerance of f faulty group members among 3f + 2 total. ByzCoin mitigates double spending and selfish mining attacks by producing collectively signed transaction blocks within one minute of transaction submission. Tree-structured communication further reduces this latency to less than 30 seconds. Due to these optimizations, ByzCoin achieves a throughput higher than PayPal currently handles, with a confirmation latency of 15-20 seconds.",
            "keywords": [
                "Byzantine Consensus",
                "Collective Signing",
                "Transaction Commitment",
                "Double Spending",
                "Selfish Mining Attacks"
            ]
        },
        "url": "URL#3835620",
        "sema_paperId": "efd99fe3b5b620d89aa03201199c45988c688670"
    },
    {
        "@score": "1",
        "@id": "3835621",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "44/10958",
                        "text": "Platon Kotzias"
                    },
                    {
                        "@pid": "15/6037",
                        "text": "Leyla Bilge"
                    },
                    {
                        "@pid": "35/3587",
                        "text": "Juan Caballero"
                    }
                ]
            },
            "title": "Measuring PUP Prevalence and PUP Distribution through Pay-Per-Install Services.",
            "venue": "USENIX Security Symposium",
            "pages": "739-756",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KotziasBC16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/kotzias",
            "url": "https://dblp.org/rec/conf/uss/KotziasBC16",
            "abstract": "Potentially unwanted programs (PUP) such as adware and rogueware, while not outright malicious, exhibit intrusive behavior that generates user complaints and makes security vendors flag them as undesirable. PUP has been little studied in the research literature despite recent indications that its prevalence may have surpassed that of malware. In this work we perform the first systematic study of PUP prevalence and its distribution through pay-perinstall (PPI) services, which link advertisers that want to promote their programs with affiliate publishers willing to bundle their programs with offers for other software. Using AV telemetry information comprising of 8 billion events on 3.9 million real hosts during a 19 month period, we discover that over half (54%) of the examined hosts have PUP installed. PUP publishers are highly popular, e.g., the top two PUP publishers rank 15 and 24 amongst all software publishers (benign and PUP). Furthermore, we analyze the who-installs-who relationships, finding that 65% of PUP downloads are performed by other PUP and that 24 PPI services distribute over a quarter of all PUP. We also examine the top advertiser programs distributed by the PPI services, observing that they are dominated by adware running in the browser (e.g., toolbars, extensions) and rogueware. Finally, we investigate the PUP-malware relationships in the form of malware installations by PUP and PUP installations by malware. We conclude that while such events exist, PUP distribution is largely disjoint from malware distribution.",
            "keywords": [
                "Potentially Unwanted Programs (PUP)",
                "Pay-Per-Install Services",
                "PUP Prevalence",
                "PUP Distribution",
                "Adware and Rogueware"
            ]
        },
        "url": "URL#3835621",
        "sema_paperId": "32f19bbd4bdb9a3eb13db81017a85af523e9789b"
    },
    {
        "@score": "1",
        "@id": "3835624",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "136/8449",
                        "text": "Ada Lerner"
                    },
                    {
                        "@pid": "150/5058",
                        "text": "Anna Kornfeld Simpson"
                    },
                    {
                        "@pid": "k/TadayoshiKohno",
                        "text": "Tadayoshi Kohno"
                    },
                    {
                        "@pid": "23/2758",
                        "text": "Franziska Roesner"
                    }
                ]
            },
            "title": "Internet Jones and the Raiders of the Lost Trackers: An Archaeological Study of Web Tracking from 1996 to 2016.",
            "venue": "USENIX Security Symposium",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LernerSKR16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/lerner",
            "url": "https://dblp.org/rec/conf/uss/LernerSKR16",
            "abstract": "Though web tracking and its privacy implications have received much attention in recent years, that attention has come relatively recently in the history of the web and lacks full historical context. In this paper, we present longitudinal measurements of third-party web tracking behaviors from 1996 to present (2016). Our tool, TrackingExcavator, leverages a key insight: that the Internet Archive\u2019s Wayback Machine opens the pos-sibility for a retrospective analysis of tracking over time. We contribute an evaluation of the Wayback Machine\u2019s view of past third-party requests, which we \ufb01nd is imperfect \u2014 we evaluate its limitations and unearth lessons and strategies for overcoming them. Applying these strategies in our measurements, we discover (among other \ufb01ndings) that third-party tracking on the web has increased in prevalence and complexity since the \ufb01rst third-party tracker that we observe in 1996, and we see the spread of the most popular trackers to an increasing percentage of the most popular sites on the web. We argue that an understanding of the ecosystem\u2019s historical trends \u2014 which we provide for the \ufb01rst time at this scale in our work \u2014 is important to any technical and policy discussions surrounding tracking.",
            "keywords": [
                "Web Tracking",
                "Privacy Implications",
                "Longitudinal Analysis",
                "Third-Party Trackers",
                "Historical Trends"
            ]
        },
        "url": "URL#3835624",
        "sema_paperId": "d896fe7a868a10efade1ed9f55f68db2a80574fa"
    },
    {
        "@score": "1",
        "@id": "3835625",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "53/10825",
                        "text": "Frank Li 0001"
                    },
                    {
                        "@pid": "143/5673",
                        "text": "Zakir Durumeric"
                    },
                    {
                        "@pid": "31/10907",
                        "text": "Jakub Czyz"
                    },
                    {
                        "@pid": "87/9567",
                        "text": "Mohammad Karami"
                    },
                    {
                        "@pid": "359/0958",
                        "text": "Michael D. Bailey"
                    },
                    {
                        "@pid": "58/4016",
                        "text": "Damon McCoy"
                    },
                    {
                        "@pid": "s/StefanSavage",
                        "text": "Stefan Savage"
                    },
                    {
                        "@pid": "p/VernPaxson",
                        "text": "Vern Paxson"
                    }
                ]
            },
            "title": "You&apos;ve Got Vulnerability: Exploring Effective Vulnerability Notifications.",
            "venue": "USENIX Security Symposium",
            "pages": "1033-1050",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiDCKBMSP16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/li",
            "url": "https://dblp.org/rec/conf/uss/LiDCKBMSP16",
            "abstract": "Security researchers can send vulnerability notifications to take proactive measures in securing systems at scale. However, the factors affecting a notification\u2019s efficacy have not been deeply explored. In this paper, we report on an extensive study of notifying thousands of parties of security issues present within their networks, with an aim of illuminating which fundamental aspects of notifications have the greatest impact on efficacy. The vulnerabilities used to drive our study span a range of protocols and considerations: exposure of industrial control systems; apparent firewall omissions for IPv6-based services; and exploitation of local systems in DDoS amplification attacks. We monitored vulnerable systems for several weeks to determine their rate of remediation. By comparing with experimental controls, we analyze the impact of a number of variables: choice of party to contact (WHOIS abuse contacts versus national CERTs versus US-CERT), message verbosity, hosting an information website linked to in the message, and translating the message into the notified party\u2019s local language. We also assess the outcome of the emailing process itself (bounces, automated replies, human replies, silence) and characterize the sentiments and perspectives expressed in both the human replies and an optional anonymous survey that accompanied our notifications. We find that various notification regimens do result in different outcomes. The best observed process was directly notifying WHOIS contacts with detailed information in the message itself. These notifications had a statistically significant impact on improving remediation, and human replies were largely positive. However, the majority of notified contacts did not take action, and even when they did, remediation was often only partial. Repeat notifications did not further patching. These results are promising but ultimately modest, behooving the security community to more deeply investigate ways to improve the effectiveness of vulnerability notifications.",
            "keywords": [
                "Vulnerability Notifications",
                "Security Remediation",
                "Notification Efficacy",
                "Human Responses",
                "Proactive Security Measures"
            ]
        },
        "url": "URL#3835625",
        "sema_paperId": "49a8f9e8ed7dbd8382dbd30aa81321281cd54c07"
    },
    {
        "@score": "1",
        "@id": "3835626",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "172/1127",
                        "text": "Moritz Lipp"
                    },
                    {
                        "@pid": "166/1494",
                        "text": "Daniel Gruss"
                    },
                    {
                        "@pid": "128/5169",
                        "text": "Raphael Spreitzer"
                    },
                    {
                        "@pid": "136/6642",
                        "text": "Cl\u00e9mentine Maurice"
                    },
                    {
                        "@pid": "91/4831",
                        "text": "Stefan Mangard"
                    }
                ]
            },
            "title": "ARMageddon: Cache Attacks on Mobile Devices.",
            "venue": "USENIX Security Symposium",
            "pages": "549-564",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LippGSMM16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/lipp",
            "url": "https://dblp.org/rec/conf/uss/LippGSMM16",
            "abstract": "In the last 10 years, cache attacks on Intel x86 CPUs have gained increasing attention among the scientific community and powerful techniques to exploit cache side channels have been developed. However, modern smartphones use one or more multi-core ARM CPUs that have a different cache organization and instruction set than Intel x86 CPUs. So far, no cross-core cache attacks have been demonstrated on non-rooted Android smartphones. In this work, we demonstrate how to solve key challenges to perform the most powerful cross-core cache attacks Prime+Probe, Flush+Reload, Evict+Reload, and Flush+Flush on non-rooted ARM-based devices without any privileges. Based on our techniques, we demonstrate covert channels that outperform state-of-the-art covert channels on Android by several orders of magnitude. Moreover, we present attacks to monitor tap and swipe events as well as keystrokes, and even derive the lengths of words entered on the touchscreen. Eventually, we are the first to attack cryptographic primitives implemented in Java. Our attacks work across CPUs and can even monitor cache activity in the ARM TrustZone from the normal world. The techniques we present can be used to attack hundreds of millions of Android devices.",
            "keywords": [
                "Cache Attacks",
                "ARM Architecture",
                "Cross-Core Attacks",
                "Non-Rooted Android",
                "Covert Channels"
            ]
        },
        "url": "URL#3835626",
        "sema_paperId": "55c1aacbbbb4655effa3733275104f92b07eb815"
    },
    {
        "@score": "1",
        "@id": "3835627",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "185/1690",
                        "text": "Giorgi Maisuradze"
                    },
                    {
                        "@pid": "b/MichaelBackes1",
                        "text": "Michael Backes 0001"
                    },
                    {
                        "@pid": "08/6024",
                        "text": "Christian Rossow"
                    }
                ]
            },
            "title": "What Cannot Be Read, Cannot Be Leveraged? Revisiting Assumptions of JIT-ROP Defenses.",
            "venue": "USENIX Security Symposium",
            "pages": "139-156",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Maisuradze0R16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/maisuradze",
            "url": "https://dblp.org/rec/conf/uss/Maisuradze0R16",
            "abstract": "Despite numerous attempts to mitigate code-reuse attacks, Return-Oriented Programming (ROP) is still at the core of exploiting memory corruption vulnerabilities. Most notably, in JIT-ROP, an attacker dynamically searches for suitable gadgets in executable code pages, even if they have been randomized. JIT-ROP seemingly requires that (i) code is readable (to find gadgets at run time) and (ii) executable (to mount the overall attack). As a response, Execute-no-Read (XnR) schemes have been proposed to revoke the read privilege of code, such that an adversary can no longer inspect the code after fine-grained code randomizations have been applied. \n \nWe revisit these \"inherent\" requirements for mounting JIT-ROP attacks. We show that JIT-ROP attacks can be mounted without ever reading any code fragments, but instead by injecting predictable gadgets via a JIT compiler by carefully triggering useful displacement values in control flow instructions. We show that defenses deployed in all major browsers (Chrome, MS IE, Firefox) do not protect against such gadgets, nor do the current XnR implementations protect against code injection attacks. To extend XnR's guarantees against JIT-compiled gadgets, we propose a defense that replaces potentially dangerous direct control flow instructions with indirect ones at an overall performance overhead of less than 2% and a code-size overhead of 26% on average.",
            "keywords": [
                "JIT-ROP",
                "Code Reuse Attacks",
                "Execute-no-Read (XnR)",
                "Control Flow Integrity",
                "Gadget Injection"
            ]
        },
        "url": "URL#3835627",
        "sema_paperId": "ed95c6b3c78f9da6dca56ce33eeb6f21d1116b1e"
    },
    {
        "@score": "1",
        "@id": "3835628",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "138/1005",
                        "text": "William Melicher"
                    },
                    {
                        "@pid": "66/9786",
                        "text": "Blase Ur"
                    },
                    {
                        "@pid": "71/9965",
                        "text": "Sean M. Segreti"
                    },
                    {
                        "@pid": "05/6177",
                        "text": "Saranga Komanduri"
                    },
                    {
                        "@pid": "32/3440",
                        "text": "Lujo Bauer"
                    },
                    {
                        "@pid": "c/NicolasChristin",
                        "text": "Nicolas Christin"
                    },
                    {
                        "@pid": "03/1595",
                        "text": "Lorrie Faith Cranor"
                    }
                ]
            },
            "title": "Fast, Lean, and Accurate: Modeling Password Guessability Using Neural Networks.",
            "venue": "USENIX Security Symposium",
            "pages": "175-191",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MelicherUSKBCC16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/melicher",
            "url": "https://dblp.org/rec/conf/uss/MelicherUSKBCC16",
            "abstract": "Human-chosen text passwords, today\u2019s dominant form of authentication, are vulnerable to guessing attacks. Unfortunately, existing approaches for evaluating password strength by modeling adversarial password guessing are either inaccurate or orders of magnitude too large and too slow for real-time, client-side password checking. We propose using artificial neural networks to model text passwords\u2019 resistance to guessing attacks and explore how different architectures and training methods impact neural networks\u2019 guessing effectiveness. We show that neural networks can often guess passwords more effectively than state-of-the-art approaches, such as probabilistic context-free grammars and Markov models. We also show that our neural networks can be highly compressed\u2014to as little as hundreds of kilobytes\u2014 without substantially worsening guessing effectiveness. Building on these results, we implement in JavaScript the first principled client-side model of password guessing, which analyzes a password\u2019s resistance to a guessing attack of arbitrary duration with sub-second latency. Together, our contributions enable more accurate and practical password checking than was previously possible.",
            "pdf_url": "",
            "keywords": [
                "Password Guessability",
                "Neural Network Modeling",
                "Password Strength Evaluation",
                "Client-side Authentication",
                "Guessing Attack Resistance"
            ]
        },
        "url": "URL#3835628"
    },
    {
        "@score": "1",
        "@id": "3835629",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "136/8334",
                        "text": "Adwait Nadkarni"
                    },
                    {
                        "@pid": "167/0165",
                        "text": "Benjamin Andow"
                    },
                    {
                        "@pid": "22/4463",
                        "text": "William Enck"
                    },
                    {
                        "@pid": "j/SomeshJha",
                        "text": "Somesh Jha"
                    }
                ]
            },
            "title": "Practical DIFC Enforcement on Android.",
            "venue": "USENIX Security Symposium",
            "pages": "1119-1136",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/NadkarniAEJ16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/nadkarni",
            "url": "https://dblp.org/rec/conf/uss/NadkarniAEJ16",
            "abstract": "Smartphone users often use private and enterprise data with untrusted third party applications. The fundamental lack of secrecy guarantees in smartphone OSes, such as Android, exposes this data to the risk of unauthorized exfiltration. A natural solution is the integration of secrecy guarantees into the OS. In this paper, we describe the challenges for decentralized information flow control (DIFC) enforcement on Android. We propose contextsensitive DIFC enforcement via lazy polyinstantiation and practical and secure network export through domain declassification. Our DIFC system, Weir, is backwards compatible by design, and incurs less than 4 ms overhead for component startup. With Weir, we demonstrate practical and secure DIFC enforcement on Android.",
            "keywords": [
                "Decentralized Information Flow Control",
                "Android Security",
                "Data Exfiltration",
                "Context-Sensitive Enforcement",
                "Lazy Polyinstantiation"
            ]
        },
        "url": "URL#3835629",
        "sema_paperId": "e0a771a362194217222af64db4f42b987ffbf3bf"
    },
    {
        "@score": "1",
        "@id": "3835630",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "42/5782",
                        "text": "Gabi Nakibly"
                    },
                    {
                        "@pid": "176/5129",
                        "text": "Jaime Schcolnik"
                    },
                    {
                        "@pid": "176/5050",
                        "text": "Yossi Rubin"
                    }
                ]
            },
            "title": "Website-Targeted False Content Injection by Network Operators.",
            "venue": "USENIX Security Symposium",
            "pages": "227-244",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/NakiblySR16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/nakibly",
            "url": "https://dblp.org/rec/conf/uss/NakiblySR16",
            "abstract": "It is known that some network operators inject false content into users\u2019 network traffic. Yet all previous works that investigate this practice focus on edge ISPs (Internet Service Providers), namely, those that provide Internet access to end users. Edge ISPs that inject false content affect their customers only. However, in this work we show that not only edge ISPs may inject false content, but also non-edge network operators. These operators can potentially alter the traffic of all Internet users who visit predetermined websites. We expose this practice by inspecting a large amount of traffic originating from several networks. Our study is based on the observation that the forged traffic is injected in an out-of-band manner: the network operators do not update the network packets in-path, but rather send the forged packets without dropping the legitimate ones. This creates a race between the forged and the legitimate packets as they arrive to the end user. This race can be identified and analyzed. Our analysis shows that the main purpose of content injection is to increase the network operators\u2019 revenue by inserting advertisements to websites. Nonetheless, surprisingly, we have also observed numerous cases of injected malicious content. We publish representative samples of the injections to facilitate continued analysis of this practice by the security community.",
            "pdf_url": "",
            "keywords": [
                "Network Traffic Manipulation",
                "Content Injection",
                "Non-Edge ISPs",
                "Malicious Content",
                "Advertisement Insertion"
            ]
        },
        "url": "URL#3835630"
    },
    {
        "@score": "1",
        "@id": "3835631",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "70/6029",
                        "text": "Terry Nelms"
                    },
                    {
                        "@pid": "60/6768",
                        "text": "Roberto Perdisci"
                    },
                    {
                        "@pid": "26/216",
                        "text": "Manos Antonakakis"
                    },
                    {
                        "@pid": "73/3162",
                        "text": "Mustaque Ahamad"
                    }
                ]
            },
            "title": "Towards Measuring and Mitigating Social Engineering Software Download Attacks.",
            "venue": "USENIX Security Symposium",
            "pages": "773-789",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/NelmsPAA16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/nelms",
            "url": "https://dblp.org/rec/conf/uss/NelmsPAA16",
            "abstract": "Presented on September 2, 2016 at 12:00 p.m. in the Klaus Advanced Computing Building, Room 1116W.",
            "keywords": [
                "Social Engineering",
                "Software Download Attacks",
                "User Awareness",
                "Mitigation Strategies",
                "Threat Assessment"
            ]
        },
        "url": "URL#3835631",
        "sema_paperId": "a4d1109c7c0fb8c6d7d7feb7fec1f1a816b55539"
    },
    {
        "@score": "1",
        "@id": "3835634",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "70/4765",
                        "text": "Olga Ohrimenko"
                    },
                    {
                        "@pid": "119/7702",
                        "text": "Felix Schuster"
                    },
                    {
                        "@pid": "f/CedricFournet",
                        "text": "C\u00e9dric Fournet"
                    },
                    {
                        "@pid": "161/0164",
                        "text": "Aastha Mehta"
                    },
                    {
                        "@pid": "15/2312",
                        "text": "Sebastian Nowozin"
                    },
                    {
                        "@pid": "48/1784",
                        "text": "Kapil Vaswani"
                    },
                    {
                        "@pid": "35/6770",
                        "text": "Manuel Costa"
                    }
                ]
            },
            "title": "Oblivious Multi-Party Machine Learning on Trusted Processors.",
            "venue": "USENIX Security Symposium",
            "pages": "619-636",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/OhrimenkoSFMNVC16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/ohrimenko",
            "url": "https://dblp.org/rec/conf/uss/OhrimenkoSFMNVC16",
            "abstract": "Privacy-preserving multi-party machine learning allows multiple organizations to perform collaborative data analytics while guaranteeing the privacy of their individual datasets. Using trusted SGX-processors for this task yields high performance, but requires a careful selection, adaptation, and implementation of machine-learning algorithms to provably prevent the exploitation of any side channels induced by data-dependent access patterns. \n \nWe propose data-oblivious machine learning algorithms for support vector machines, matrix factorization, neural networks, decision trees, and k-means clustering. We show that our efficient implementation based on Intel Skylake processors scales up to large, realistic datasets, with overheads several orders of magnitude lower than with previous approaches based on advanced cryptographic multi-party computation schemes.",
            "keywords": [
                "Privacy-Preserving Machine Learning",
                "Multi-Party Computation",
                "Trusted Execution Environments",
                "Data-Oblivious Algorithms",
                "Side Channel Attacks"
            ]
        },
        "url": "URL#3835634",
        "sema_paperId": "7aaede70f5efcb1542a80707c1f0f8b01955a7d2"
    },
    {
        "@score": "1",
        "@id": "3835635",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "175/6391",
                        "text": "Angelos Oikonomopoulos"
                    },
                    {
                        "@pid": "51/4565",
                        "text": "Elias Athanasopoulos"
                    },
                    {
                        "@pid": "91/800",
                        "text": "Herbert Bos"
                    },
                    {
                        "@pid": "75/8194",
                        "text": "Cristiano Giuffrida"
                    }
                ]
            },
            "title": "Poking Holes in Information Hiding.",
            "venue": "USENIX Security Symposium",
            "pages": "121-138",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/OikonomopoulosA16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/oikonomopoulos",
            "url": "https://dblp.org/rec/conf/uss/OikonomopoulosA16",
            "abstract": "ASLR is no longer a strong defense in itself, but it still serves as a foundation for sophisticated defenses that use randomization for pseudo-isolation. Crucially, these defenses hide sensitive information (such as shadow stacks and safe regions) at a random position in a very large address space. Previous attacks on randomization-based information hiding rely on complicated side channels and/or probing of the mapped memory regions. Assuming no weaknesses exist in the implementation of hidden regions, the attacks typically lead to many crashes or other visible side-effects. For this reason, many researchers still consider the pseudo-isolation offered by ASLR sufficiently strong in practice. We introduce powerful new primitives to show that this faith in ASLR-based information hiding is misplaced, and that attackers can break ASLR and find hidden regions on 32 bit and 64 bit Linux systems quickly with very few malicious inputs. Rather than building on memory accesses that probe the allocated memory areas, we determine the sizes of the unallocated holes in the address space by repeatedly allocating large chunks of memory. Given the sizes, an attacker can infer the location of the hidden region with few or no side-effects. We show that allocation oracles are pervasive and evaluate our primitives on real-world server applications.",
            "keywords": [
                "ASLR",
                "Information Hiding",
                "Memory Allocation",
                "Address Space Randomization",
                "Allocation Oracles"
            ]
        },
        "url": "URL#3835635",
        "sema_paperId": "38d5f91d76cd4c23c5382c07b34885e7b51118f4"
    },
    {
        "@score": "1",
        "@id": "3835636",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "132/6974",
                        "text": "Peter Pessl"
                    },
                    {
                        "@pid": "166/1494",
                        "text": "Daniel Gruss"
                    },
                    {
                        "@pid": "136/6642",
                        "text": "Cl\u00e9mentine Maurice"
                    },
                    {
                        "@pid": "08/1117-1",
                        "text": "Michael Schwarz 0001"
                    },
                    {
                        "@pid": "91/4831",
                        "text": "Stefan Mangard"
                    }
                ]
            },
            "title": "DRAMA: Exploiting DRAM Addressing for Cross-CPU Attacks.",
            "venue": "USENIX Security Symposium",
            "pages": "565-581",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PesslGMSM16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/pessl",
            "url": "https://dblp.org/rec/conf/uss/PesslGMSM16",
            "abstract": "In cloud computing environments, multiple tenants are often co-located on the same multi-processor system. Thus, preventing information leakage between tenants is crucial. While the hypervisor enforces software isolation, shared hardware, such as the CPU cache or memory bus, can leak sensitive information. For security reasons, shared memory between tenants is typically disabled. Furthermore, tenants often do not share a physical CPU. In this setting, cache attacks do not work and only a slow cross-CPU covert channel over the memory bus is known. In contrast, we demonstrate a high-speed covert channel as well as the first side-channel attack working across processors and without any shared memory. To build these attacks, we use the undocumented DRAM address mappings. \nWe present two methods to reverse engineer the mapping of memory addresses to DRAM channels, ranks, and banks. One uses physical probing of the memory bus, the other runs entirely in software and is fully automated. Using this mapping, we introduce DRAMA attacks, a novel class of attacks that exploit the DRAM row buffer that is shared, even in multi-processor systems. Thus, our attacks work in the most restrictive environments. First, we build a covert channel with a capacity of up to 2 Mbps, which is three to four orders of magnitude faster than memory-bus-based channels. Second, we build a side-channel template attack that can automatically locate and monitor memory accesses. Third, we show how using the DRAM mappings improves existing attacks and in particular enables practical Rowhammer attacks on DDR4.",
            "keywords": [
                "DRAM Addressing",
                "Cross-CPU Attacks",
                "Covert Channels",
                "Side-Channel Attacks",
                "Rowhammer"
            ]
        },
        "url": "URL#3835636",
        "sema_paperId": "f64be08ad745701791f99bba6b28b3e5dc2d7362"
    },
    {
        "@score": "1",
        "@id": "3835638",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "117/1992",
                        "text": "Daniel Plohmann"
                    },
                    {
                        "@pid": "140/0794",
                        "text": "Khaled Yakdan"
                    },
                    {
                        "@pid": "185/1675",
                        "text": "Michael Klatt"
                    },
                    {
                        "@pid": "58/6398",
                        "text": "Johannes Bader"
                    },
                    {
                        "@pid": "61/2236",
                        "text": "Elmar Gerhards-Padilla"
                    }
                ]
            },
            "title": "A Comprehensive Measurement Study of Domain Generating Malware.",
            "venue": "USENIX Security Symposium",
            "pages": "263-278",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PlohmannYKBG16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/plohmann",
            "url": "https://dblp.org/rec/conf/uss/PlohmannYKBG16",
            "abstract": "Recent years have seen extensive adoption of domain generation algorithms (DGA) by modern botnets. The main goal is to generate a large number of domain names and then use a small subset for actual C&C communication. This makes DGAs very compelling for botmasters to harden the infrastructure of their botnets and make it resilient to blacklisting and attacks such as takedown efforts. While early DGAs were used as a backup communication mechanism, several new botnets use them as their primary communication method, making it extremely important to study DGAs in detail. \n \nIn this paper, we perform a comprehensive measurement study of the DGA landscape by analyzing 43 DGA-based malware families and variants. We also present a taxonomy for DGAs and use it to characterize and compare the properties of the studied families. By reimplementing the algorithms, we pre-compute all possible domains they generate, covering the majority of known and active DGAs. Then, we study the registration status of over 18 million DGA domains and show that corresponding malware families and related campaigns can be reliably identified by pre-computing future DGA domains. We also give insights into botmasters' strategies regarding domain registration and identify several pitfalls in previous takedown efforts of DGA-based botnets. We will share the dataset for future research and will also provide a web service to check domains for potential DGA identity.",
            "keywords": [
                "Domain Generation Algorithms",
                "DGA-based Malware",
                "Botnets",
                "Domain Registration Strategies",
                "Malware Takedown Efforts"
            ]
        },
        "url": "URL#3835638",
        "sema_paperId": "dae611e57d9c9cba04d4a9ad519685fba7ac51bb"
    },
    {
        "@score": "1",
        "@id": "3835640",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "82/5278",
                        "text": "Himanshu Raj"
                    },
                    {
                        "@pid": "17/3782",
                        "text": "Stefan Saroiu"
                    },
                    {
                        "@pid": "06/915",
                        "text": "Alec Wolman"
                    },
                    {
                        "@pid": "83/2709",
                        "text": "Ronald Aigner"
                    },
                    {
                        "@pid": "185/1684",
                        "text": "Jeremiah Cox"
                    },
                    {
                        "@pid": "51/3259",
                        "text": "Paul England"
                    },
                    {
                        "@pid": "185/1636",
                        "text": "Chris Fenner"
                    },
                    {
                        "@pid": "08/7452",
                        "text": "Kinshuman Kinshumann"
                    },
                    {
                        "@pid": "05/4085",
                        "text": "Jork L\u00f6ser"
                    },
                    {
                        "@pid": "185/1651",
                        "text": "Dennis Mattoon"
                    },
                    {
                        "@pid": "10/3956",
                        "text": "Magnus Nystr\u00f6m"
                    },
                    {
                        "@pid": "17/1389",
                        "text": "David Robinson"
                    },
                    {
                        "@pid": "185/1691",
                        "text": "Rob Spiger"
                    },
                    {
                        "@pid": "185/1599",
                        "text": "Stefan Thom"
                    },
                    {
                        "@pid": "185/1614",
                        "text": "David Wooten"
                    }
                ]
            },
            "title": "fTPM: A Software-Only Implementation of a TPM Chip.",
            "venue": "USENIX Security Symposium",
            "pages": "841-856",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RajSWACEFKLMNRS16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/raj",
            "url": "https://dblp.org/rec/conf/uss/RajSWACEFKLMNRS16",
            "abstract": "Commodity CPU architectures, such as ARM and Intel CPUs, have started to offer trusted computing features in their CPUs aimed at displacing dedicated trusted hardware. Unfortunately, these CPU architectures raise serious challenges to building trusted systems because they omit providing secure resources outside the CPU perimeter. This paper shows how to overcome these challenges to build software systems with security guarantees similar to those of dedicated trusted hardware. We present the design and implementation of a firmware-based TPM 2.0 (fTPM) leveraging ARM TrustZone. Our fTPM is the reference implementation of a TPM 2.0 used in millions of mobile devices. We also describe a set of mechanisms needed for the fTPM that can be useful for building more sophisticated trusted applications beyond just a TPM.",
            "keywords": [
                "Trusted Computing",
                "TPM 2.0",
                "Software Implementation",
                "ARM TrustZone",
                "Firmware-based TPM (fTPM)"
            ]
        },
        "url": "URL#3835640",
        "sema_paperId": "1ded02b4026f98c1dfdd0d63d79b5bdd108ac5d3"
    },
    {
        "@score": "1",
        "@id": "3835641",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "63/10367",
                        "text": "Ashay Rane"
                    },
                    {
                        "@pid": "65/1026",
                        "text": "Calvin Lin"
                    },
                    {
                        "@pid": "33/65",
                        "text": "Mohit Tiwari"
                    }
                ]
            },
            "title": "Secure, Precise, and Fast Floating-Point Operations on x86 Processors.",
            "venue": "USENIX Security Symposium",
            "pages": "71-86",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RaneLT16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/rane",
            "url": "https://dblp.org/rec/conf/uss/RaneLT16",
            "abstract": "Floating-point computations introduce several side channels. This paper describes the first solution that closes these side channels while preserving the precision of non-secure executions. Our solution exploits microarchitectural features of the x86 architecture along with novel compilation techniques to provide low overhead. Because of the details of x86 execution, the evaluation of floating-point side channel defenses is quite involved, but we show that our solution is secure, precise, and fast. Our solution closes more side channels than any prior solution. Despite the added security, our solution does not compromise on the precision of the floating-point operations. Finally, for a set of microkernels, our solution is an order of magnitude more efficient than the previous solution.",
            "keywords": [
                "Floating-Point Operations",
                "x86 Architecture",
                "Side Channel Attacks",
                "Microarchitectural Features",
                "Compilation Techniques"
            ]
        },
        "url": "URL#3835641",
        "sema_paperId": "7c015d202e3b48f06d708d93687dfa84a80a3eac"
    },
    {
        "@score": "1",
        "@id": "3835642",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "121/2685",
                        "text": "Kaveh Razavi"
                    },
                    {
                        "@pid": "68/86",
                        "text": "Ben Gras"
                    },
                    {
                        "@pid": "64/10928",
                        "text": "Erik Bosman"
                    },
                    {
                        "@pid": "p/BartPreneel",
                        "text": "Bart Preneel"
                    },
                    {
                        "@pid": "75/8194",
                        "text": "Cristiano Giuffrida"
                    },
                    {
                        "@pid": "91/800",
                        "text": "Herbert Bos"
                    }
                ]
            },
            "title": "Flip Feng Shui: Hammering a Needle in the Software Stack.",
            "venue": "USENIX Security Symposium",
            "pages": "1-18",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RazaviGBPGB16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/razavi",
            "url": "https://dblp.org/rec/conf/uss/RazaviGBPGB16",
            "abstract": "We introduce Flip Feng Shui (FFS), a new exploitation vector which allows an attacker to induce bit flips over arbitrary physical memory in a fully controlled way. FFS relies on hardware bugs to induce bit flips over memory and on the ability to surgically control the physical memory layout to corrupt attacker-targeted data anywhere in the software stack. We show FFS is possible today with very few constraints on the target data, by implementing an instance using the Rowhammer bug and memory deduplication (an OS feature widely deployed in production). Memory deduplication allows an attacker to reverse-map any physical page into a virtual page she owns as long as the page\u2019s contents are known. Rowhammer, in turn, allows an attacker to flip bits in controlled (initially unknown) locations in the target page. We show FFS is extremely powerful: a malicious VM in a practical cloud setting can gain unauthorized access to a co-hosted victim VM running OpenSSH. Using FFS, we exemplify end-to-end attacks breaking OpenSSH public-key authentication, and forging GPG signatures from trusted keys, thereby compromising the Ubuntu/Debian update mechanism. We conclude by discussing mitigations and future directions for FFS attacks.",
            "keywords": [
                "Flip Feng Shui",
                "Memory Exploitation",
                "Bit Flips",
                "Rowhammer",
                "Memory Deduplication"
            ]
        },
        "url": "URL#3835642",
        "sema_paperId": "f0e0fdaff62992e9145af5f492443f99c6773d04"
    },
    {
        "@score": "1",
        "@id": "3835643",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "117/3983",
                        "text": "Bradley Reaves"
                    },
                    {
                        "@pid": "183/1275",
                        "text": "Logan Blue"
                    },
                    {
                        "@pid": "14/3295",
                        "text": "Patrick Traynor"
                    }
                ]
            },
            "title": "AuthLoop: End-to-End Cryptographic Authentication for Telephony over Voice Channels.",
            "venue": "USENIX Security Symposium",
            "pages": "963-978",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ReavesBT16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/reaves",
            "url": "https://dblp.org/rec/conf/uss/ReavesBT16",
            "abstract": "Telephones remain a trusted platform for conducting some of our most sensitive exchanges. From banking to taxes, wide swathes of industry and government rely on telephony as a secure fall-back when attempting to confirm the veracity of a transaction. In spite of this, authentication is poorly managed between these systems, and in the general case it is impossible to be certain of the identity (i.e., Caller ID) of the entity at the other end of a call. We address this problem with AuthLoop, the first system to provide cryptographic authentication solely within the voice channel. We design, implement and characterize the performance of an in-band modem for executing a TLS-inspired authentication protocol, and demonstrate its abilities to ensure that the explicit single-sided authentication procedures pervading the web are also possible on all phones. We show experimentally that this protocol can be executed with minimal computational overhead and only a few seconds of user time (\u2248 9 instead of \u2248 97 seconds for a na\u0131\u0308ve implementation of TLS 1.2) over heterogeneous networks. In so doing, we demonstrate that strong end-to-end validation of Caller ID is indeed practical for all telephony networks.",
            "keywords": [
                "Telephony Security",
                "Cryptographic Authentication",
                "Caller ID Validation",
                "In-Band Modem",
                "TLS-Inspired Protocol"
            ]
        },
        "url": "URL#3835643",
        "sema_paperId": "dc15a796eb2fabe6cc119b495765cdcdf8e4be98"
    },
    {
        "@score": "1",
        "@id": "3835644",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "183/5983",
                        "text": "Peter Rindal"
                    },
                    {
                        "@pid": "r/MikeRosulek",
                        "text": "Mike Rosulek"
                    }
                ]
            },
            "title": "Faster Malicious 2-Party Secure Computation with Online/Offline Dual Execution.",
            "venue": "USENIX Security Symposium",
            "pages": "297-314",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RindalR16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/rindal",
            "url": "https://dblp.org/rec/conf/uss/RindalR16",
            "abstract": "We describe a highly optimized protocol for generalpurpose secure two-party computation (2PC) in the presence of malicious adversaries. Our starting point is a protocol of Kolesnikov et al. (TCC 2015). We adapt that protocol to the online/offline setting, where two parties repeatedly evaluate the same function (on possibly different inputs each time) and perform as much of the computation as possible in an offline preprocessing phase before their inputs are known. Along the way we develop several significant simplifications and optimizations to the protocol. We have implemented a prototype of our protocol and report on its performance. When two parties on Amazon servers in the same region use our implementation to securely evaluate the AES circuit 1024 times, the amortized cost per evaluation is 5.1ms offline + 1.3ms online. The total offline+online cost of our protocol is in fact less than the online cost of any reported protocol with malicious security. For comparison, our protocol\u2019s closest competitor (Lindell & Riva, CCS 2015) uses 74ms offline + 7ms online in an identical setup. Our protocol can be further tuned to trade performance for leakage. As an example, the performance in the above scenario improves to 2.4ms offline + 1.0ms online if we allow an adversary to learn a single bit about the honest party\u2019s input with probability 2\u221220 (but not violate any other security property, e.g. correctness).",
            "keywords": [
                "Secure Two-Party Computation",
                "Malicious Adversaries",
                "Online/Offline Protocol",
                "Performance Optimization",
                "AES Circuit Evaluation"
            ]
        },
        "url": "URL#3835644",
        "sema_paperId": "e5ef9cfcadf06746ebe36259d4053ebc827b1d33"
    },
    {
        "@score": "1",
        "@id": "3835646",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "150/5240",
                        "text": "Brendan Saltaformaggio"
                    },
                    {
                        "@pid": "43/1791",
                        "text": "Rohit Bhatia"
                    },
                    {
                        "@pid": "95/3760-1",
                        "text": "Xiangyu Zhang 0001"
                    },
                    {
                        "@pid": "59/5539",
                        "text": "Dongyan Xu"
                    },
                    {
                        "@pid": "64/775",
                        "text": "Golden G. Richard III"
                    }
                ]
            },
            "title": "Screen after Previous Screens: Spatial-Temporal Recreation of Android App Displays from Memory Images.",
            "venue": "USENIX Security Symposium",
            "pages": "1137-1151",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SaltaformaggioB16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/saltaformaggio",
            "url": "https://dblp.org/rec/conf/uss/SaltaformaggioB16",
            "abstract": "Smartphones are increasingly involved in cyber and real world crime investigations. In this paper, we demonstrate a powerful smartphone memory forensics technique, called RetroScope, which recovers multiple previous screens of an Android app \u2014 in the order they were displayed \u2014 from the phone\u2019s memory image. Different from traditional memory forensics, RetroScope enables spatial-temporal forensics, revealing the progression of the phone user\u2019s interactions with the app (e.g., a banking transaction, online chat, or document editing session). RetroScope achieves near perfect accuracy in both the recreation and ordering of reconstructed screens. Further, RetroScope is app-agnostic, requiring no knowledge about an app\u2019s internal data definitions or rendering logic. RetroScope is inspired by the observations that (1) app-internal data on previous screens exists much longer in memory than the GUI data structures that \u201cpackage\u201d them and (2) each app is able to perform context-free redrawing of its screens upon command from the Android framework. Based on these, RetroScope employs a novel interleaved re-execution engine to selectively reanimate an app\u2019s screen redrawing functionality from within a memory image. Our evaluation shows that RetroScope is able to recover full temporally-ordered sets of screens (each with 3 to 11 screens) for a variety of popular apps on a number of different Android devices.",
            "keywords": [
                "Memory Forensics",
                "Android Apps",
                "Spatial-Temporal Forensics",
                "Screen Reconstruction",
                "RetroScope"
            ]
        },
        "url": "URL#3835646",
        "sema_paperId": "6ba312de71765e1fc839ec27274acd62a62886db"
    },
    {
        "@score": "1",
        "@id": "3835649",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "153/5799",
                        "text": "WonJun Song"
                    },
                    {
                        "@pid": "40/309",
                        "text": "Hyunwoo Choi"
                    },
                    {
                        "@pid": "185/1638",
                        "text": "Junhong Kim"
                    },
                    {
                        "@pid": "185/1645",
                        "text": "Eunsoo Kim"
                    },
                    {
                        "@pid": "20/6892",
                        "text": "Yongdae Kim"
                    },
                    {
                        "@pid": "39/6945-1",
                        "text": "John Kim 0001"
                    }
                ]
            },
            "title": "PIkit: A New Kernel-Independent Processor-Interconnect Rootkit.",
            "venue": "USENIX Security Symposium",
            "pages": "37-51",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SongCKKKK16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/song",
            "url": "https://dblp.org/rec/conf/uss/SongCKKKK16",
            "abstract": "The goal of rootkit is often to hide malicious software running on a compromised machine. While there has been significant amount of research done on different rootkits, we describe a new type of rootkit that is kernel-independent \u2013 i.e., no aspect of the kernel is modified and no code is added to the kernel address space to install the rootkit. In this work, we present PIkit \u2013 Processor-Interconnect rootkit that exploits the vulnerable hardware features within multi-socket servers that are commonly used in datacenters and high-performance computing. In particular, PIkit exploits the DRAM address mapping table structure that determines the destination node of a memory request packet in the processorinterconnect. By modifying this mapping table appropriately, PIkit enables access to victim\u2019s memory address region without proper permission. Once PIkit is installed, only user-level code or payload is needed to carry out malicious activities. The malicious payload mostly consists of memory read and/or write instructions that appear like \u201cnormal\u201d user-space memory accesses and it becomes very difficult to detect such malicious payload. We describe the design and implementation of PIkit on both an AMD and an Intel x86 multi-socket servers that are commonly used. We discuss different malicious activities possible with PIkit and limitations of PIkit, as well as possible software and hardware solutions to PIkit.",
            "keywords": [
                "Rootkit",
                "Kernel-Independent",
                "Processor-Interconnect",
                "Memory Access Exploitation",
                "Data Center Security"
            ]
        },
        "url": "URL#3835649",
        "sema_paperId": "85cd7a41db3f19f20af9c6211788453c1ad0b203"
    },
    {
        "@score": "1",
        "@id": "3835650",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "136/8343",
                        "text": "Ben Stock"
                    },
                    {
                        "@pid": "35/9056",
                        "text": "Giancarlo Pellegrino"
                    },
                    {
                        "@pid": "08/6024",
                        "text": "Christian Rossow"
                    },
                    {
                        "@pid": "82/359",
                        "text": "Martin Johns"
                    },
                    {
                        "@pid": "b/MichaelBackes1",
                        "text": "Michael Backes 0001"
                    }
                ]
            },
            "title": "Hey, You Have a Problem: On the Feasibility of Large-Scale Web Vulnerability Notification.",
            "venue": "USENIX Security Symposium",
            "pages": "1015-1032",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/StockPRJ016",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/stock",
            "url": "https://dblp.org/rec/conf/uss/StockPRJ016",
            "abstract": "Large-scale discovery of thousands of vulnerable Web sites has become a frequent event, thanks to recent advances in security research and the rise in maturity of Internet-wide scanning tools. The issues related to disclosing the vulnerability information to the affected parties, however, have only been treated as a side note in prior research. In this paper, we systematically examine the feasibility and efficacy of large-scale notification campaigns. For this, we comprehensively survey existing communication channels and evaluate their usability in an automated notification process. Using a data set of over 44,000 vulnerable Web sites, we measure success rates, both with respect to the total number of fixed vulnerabilities and to reaching responsible parties, with the following high-level results: Although our campaign had a statistically significant impact compared to a control group, the increase in the fix rate of notified domains is marginal. If a notification report is read by the owner of the vulnerable application, the likelihood of a subsequent resolution of the issues is sufficiently high: about 40%. But, out of 35,832 transmitted vulnerability reports, only 2,064 (5.8%) were actually received successfully, resulting in an unsatisfactory overall fix rate, leaving 74.5% of Web applications exploitable after our month-long experiment. Thus, we conclude that currently no reliable notification channels exist, which significantly inhibits the success and impact of large-scale notification.",
            "keywords": [
                "Web Vulnerability Notification",
                "Internet-wide Scanning",
                "Vulnerability Disclosure",
                "Automated Notification Process",
                "Fix Rate of Vulnerabilities"
            ]
        },
        "url": "URL#3835650",
        "sema_paperId": "f7a03c7c3337639a59ff7d587ba30eed3fd997d9"
    },
    {
        "@score": "1",
        "@id": "3835651",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "97/7967",
                        "text": "Raoul Strackx"
                    },
                    {
                        "@pid": "85/6647",
                        "text": "Frank Piessens"
                    }
                ]
            },
            "title": "Ariadne: A Minimal Approach to State Continuity.",
            "venue": "USENIX Security Symposium",
            "pages": "875-892",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/StrackxP16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/strackx",
            "url": "https://dblp.org/rec/conf/uss/StrackxP16",
            "abstract": "Protected-module architectures such as Intel SGX provide strong isolation guarantees to sensitive parts of applications while the system is up and running. Unfortunately systems in practice crash, go down for reboots or lose power at unexpected moments in time. To deal with such events, additional security measures need to be taken to guarantee that stateful modules will either recover their state from the last stored state, or fail-stop on detection of tampering with that state. More specifically, protected-module architectures need to provide a security primitive that guarantees that (1) attackers cannot present a stale state as being fresh (i.e. rollback protection), (2) once a module accepted a specific input, it will continue execution on that input or never advance, and (3) an unexpected loss of power must never leave the system in a state from which it can never resume execution (i.e. liveness guarantee). We propose Ariadne, a solution to the state-continuity problem that achieves the theoretical lower limit of requiring only a single bit flip of non-volatile memory per state update. Ariadne can be easily adapted to the platform at hand. In low-end devices where non-volatile memory may wear out quickly and the bill of materials (BOM) needs to be minimized, Ariadne can take optimal use of non-volatile memory. On SGX-enabled processors, Ariadne can be readily deployed to protect stateful modules (e.g., as used by Haven and VC3).",
            "keywords": [
                "Protected-module Architectures",
                "State Continuity",
                "Rollback Protection",
                "Liveness Guarantee",
                "Non-volatile Memory"
            ]
        },
        "url": "URL#3835651",
        "sema_paperId": "dd9b9749008fed670680e9b86a795911e1f05155"
    },
    {
        "@score": "1",
        "@id": "3835652",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "57/810",
                        "text": "Petr Svenda"
                    },
                    {
                        "@pid": "185/1617",
                        "text": "Mat\u00fas Nemec"
                    },
                    {
                        "@pid": "185/1698",
                        "text": "Peter Sekan"
                    },
                    {
                        "@pid": "185/1699",
                        "text": "Rudolf Kvasnovsk\u00fd"
                    },
                    {
                        "@pid": "185/1639",
                        "text": "David Form\u00e1nek"
                    },
                    {
                        "@pid": "185/1625",
                        "text": "David Kom\u00e1rek"
                    },
                    {
                        "@pid": "97/3759",
                        "text": "Vashek Maty\u00e1s"
                    }
                ]
            },
            "title": "The Million-Key Question - Investigating the Origins of RSA Public Keys.",
            "venue": "USENIX Security Symposium",
            "pages": "893-910",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SvendaNSKFKM16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/svenda",
            "url": "https://dblp.org/rec/conf/uss/SvendaNSKFKM16",
            "abstract": "Can bits of an RSA public key leak information about design and\nimplementation choices such as the prime generation algorithm?\nWe analysed over 60 million freshly generated key pairs from 22\nopen- and closedsource libraries and from 16 different\nsmartcards, revealing significant leakage. The bias introduced\nby different choices is sufficiently large to classify a\nprobable library or smartcard with high accuracy based only on\nthe values of public keys. Such a classification can be used to\ndecrease the anonymity set of users of anonymous mailers or\noperators of linked Tor hidden services, to quickly detect keys\nfrom the same vulnerable library or to verify a claim of use of\nsecure hardware by a remote party. The classification of the\nkey origins of more than 10 million RSA-based IPv4 TLS keys and\n1.4 million PGP keys also provides an independent estimation of\nthe libraries that are most commonly used to generate the keys\nfound on the Internet. Our broad inspection provides a sanity\ncheck and deep insight regarding which of the recommendations\nfor RSA key pair generation are followed in practice, including\nclosed-source libraries and smartcards.",
            "keywords": [
                "RSA Public Key Analysis",
                "Key Generation Algorithms",
                "Information Leakage",
                "Library Classification",
                "Smartcard Vulnerabilities"
            ]
        },
        "url": "URL#3835652",
        "sema_paperId": "f512624ba05fb9d715b11d9d35649fd6220a4d44"
    },
    {
        "@score": "1",
        "@id": "3835654",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "68/8283",
                        "text": "Kurt Thomas"
                    },
                    {
                        "@pid": "185/1616",
                        "text": "Juan A. Elices Crespo"
                    },
                    {
                        "@pid": "162/2028",
                        "text": "Ryan Rasti"
                    },
                    {
                        "@pid": "145/2051",
                        "text": "Jean-Michel Picod"
                    },
                    {
                        "@pid": "185/1707",
                        "text": "Cait Phillips"
                    },
                    {
                        "@pid": "185/1608",
                        "text": "Marc-Andr\u00e9 Decoste"
                    },
                    {
                        "@pid": "85/6619",
                        "text": "Chris Sharp"
                    },
                    {
                        "@pid": "81/2242",
                        "text": "Fabio Tirelo"
                    },
                    {
                        "@pid": "06/1026",
                        "text": "Ali Tofigh"
                    },
                    {
                        "@pid": "185/1687",
                        "text": "Marc-Antoine Courteau"
                    },
                    {
                        "@pid": "13/6840",
                        "text": "Lucas Ballard"
                    },
                    {
                        "@pid": "17/4521",
                        "text": "Robert Shield"
                    },
                    {
                        "@pid": "165/5508",
                        "text": "Nav Jagpal"
                    },
                    {
                        "@pid": "25/3948",
                        "text": "Moheeb Abu Rajab"
                    },
                    {
                        "@pid": "94/2405",
                        "text": "Panayiotis Mavrommatis"
                    },
                    {
                        "@pid": "90/6745",
                        "text": "Niels Provos"
                    },
                    {
                        "@pid": "20/7004",
                        "text": "Elie Bursztein"
                    },
                    {
                        "@pid": "58/4016",
                        "text": "Damon McCoy"
                    }
                ]
            },
            "title": "Investigating Commercial Pay-Per-Install and the Distribution of Unwanted Software.",
            "venue": "USENIX Security Symposium",
            "pages": "721-739",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ThomasCRPPDSTTC16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/thomas",
            "url": "https://dblp.org/rec/conf/uss/ThomasCRPPDSTTC16",
            "abstract": "In this work, we explore the ecosystem of commercial pay-per-install (PPI) and the role it plays in the proliferation of unwanted software. Commercial PPI enables companies to bundle their applications with more popular software in return for a fee, effectively commoditizing access to user devices. We develop an analysis pipeline to track the business relationships underpinning four of the largest commercial PPI networks and classify the software families bundled. In turn, we measure their impact on end users and enumerate the distribution techniques involved. We find that unwanted ad injectors, browser settings hijackers, and \u201ccleanup\u201d utilities dominate the software families buying installs. Developers of these families pay $0.10\u2013$1.50 per install\u2014upfront costs that they recuperate by monetizing users without their consent or by charging exorbitant subscription fees. Based on Google Safe Browsing telemetry, we estimate that PPI networks drive over 60 million download attempts every week\u2014nearly three times that of malware. While anti-virus and browsers have rolled out defenses to protect users from unwanted software, we find evidence that PPI networks actively interfere with or evade detection. Our results illustrate the deceptive practices of some commercial PPI operators that persist today.",
            "keywords": [
                "Commercial Pay-Per-Install",
                "Unwanted Software",
                "Software Distribution",
                "Ad Injectors",
                "Browser Hijacking"
            ]
        },
        "url": "URL#3835654",
        "sema_paperId": "2152f9f91e798c23715fdce699b6a8f0f8d43170"
    },
    {
        "@score": "1",
        "@id": "3835655",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "159/0537",
                        "text": "Dave (Jing) Tian"
                    },
                    {
                        "@pid": "167/0436",
                        "text": "Nolen Scaife"
                    },
                    {
                        "@pid": "126/3601",
                        "text": "Adam Bates 0001"
                    },
                    {
                        "@pid": "82/1935",
                        "text": "Kevin R. B. Butler"
                    },
                    {
                        "@pid": "14/3295",
                        "text": "Patrick Traynor"
                    }
                ]
            },
            "title": "Making USB Great Again with USBFILTER.",
            "venue": "USENIX Security Symposium",
            "pages": "415-430",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/TianSBBT16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/tian",
            "url": "https://dblp.org/rec/conf/uss/TianSBBT16",
            "abstract": "USB provides ubiquitous plug-and-play connectivity for a wide range of devices. However, the complex nature of USB obscures the true functionality of devices from the user, and operating systems blindly trust any physically-attached device. This has led to a number of attacks, ranging from hidden keyboards to network adapters, that rely on the user being unable to identify all of the functions attached to the host. In this paper, we present USBFILTER, which provides the first packet-level access control for USB and can prevent unauthorized interfaces from successfully connecting to the host operating system. USBFILTER can trace individual USB packets back to their respective processes and block unauthorized access to any device. By instrumenting the host\u2019s USB stack between the device drivers and the USB controller, our system is able to filter packets at a granularity that previous works cannot \u2014 at the lowest possible level in the operating system. USBFILTER is not only able to block or permit specific device interfaces; it can also restrict interfaces to a particular application (e.g., only Skype can access my webcam). Furthermore, our experimental analysis shows that USBFILTER introduces a negligible (3-10\u03bcs) increase in latency while providing mediation of all USB packets on the host. Our system provides a level of granularity and extensibility that reduces the uncertainty of USB connectivity and ensures unauthorized devices are unable to communicate with the host.",
            "keywords": [
                "USB Security",
                "Access Control",
                "Packet Filtering",
                "Unauthorized Device Access",
                "USBFILTER"
            ]
        },
        "url": "URL#3835655",
        "sema_paperId": "1e088df31a61b54c883a9a7f21aa1e9fabd4362c"
    },
    {
        "@score": "1",
        "@id": "3835656",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "185/1711",
                        "text": "Santiago Torres-Arias"
                    },
                    {
                        "@pid": "159/0347",
                        "text": "Anil Kumar Ammula"
                    },
                    {
                        "@pid": "c/RezaCurtmola",
                        "text": "Reza Curtmola"
                    },
                    {
                        "@pid": "27/5136",
                        "text": "Justin Cappos"
                    }
                ]
            },
            "title": "On Omitting Commits and Committing Omissions: Preventing Git Metadata Tampering That (Re)introduces Software Vulnerabilities.",
            "venue": "USENIX Security Symposium",
            "pages": "379-395",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Torres-AriasACC16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/torres-arias",
            "url": "https://dblp.org/rec/conf/uss/Torres-AriasACC16",
            "abstract": "Metadata manipulation attacks represent a new threat class directed against Version Control Systems, such as the popular Git. This type of attack provides inconsistent views of a repository state to different developers, and deceives them into performing unintended operations with often negative consequences. These include omitting security patches, merging untested code into a production branch, and even inadvertently installing software containing known vulnerabilities. To make matters worse, the attacks are subtle by nature and leave no trace after being executed. We propose a defense scheme that mitigates these attacks by maintaining a cryptographically-signed log of relevant developer actions. By documenting the state of the repository at a particular time when an action is taken, developers are given a shared history, so irregularities are easily detected. Our prototype implementation of the scheme can be deployed immediately as it is backwards compatible and preserves current work\ufb02ows and use cases for Git users. An evaluation shows that the defense adds a modest overhead while offering sig-ni\ufb01cantly stronger security. We performed responsible disclosure of the attacks and are working with the Git community to \ufb01x these issues in an upcoming version of Git.",
            "keywords": [
                "Version Control Systems",
                "Git",
                "Metadata Manipulation",
                "Security Vulnerabilities",
                "Cryptographically-Signed Log"
            ]
        },
        "url": "URL#3835656",
        "sema_paperId": "f76861c9aad1f50df05cd183c4cac0a614a36b22"
    },
    {
        "@score": "1",
        "@id": "3835657",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "158/7224",
                        "text": "Florian Tram\u00e8r"
                    },
                    {
                        "@pid": "21/3626-22",
                        "text": "Fan Zhang 0022"
                    },
                    {
                        "@pid": "j/AriJuels",
                        "text": "Ari Juels"
                    },
                    {
                        "@pid": "r/MichaelKReiter",
                        "text": "Michael K. Reiter"
                    },
                    {
                        "@pid": "26/3399",
                        "text": "Thomas Ristenpart"
                    }
                ]
            },
            "title": "Stealing Machine Learning Models via Prediction APIs.",
            "venue": "USENIX Security Symposium",
            "pages": "601-618",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/TramerZJRR16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/tramer",
            "url": "https://dblp.org/rec/conf/uss/TramerZJRR16",
            "abstract": "Machine learning (ML) models may be deemed confidential due to their sensitive training data, commercial value, or use in security applications. Increasingly often, confidential ML models are being deployed with publicly accessible query interfaces. ML-as-a-service (\"predictive analytics\") systems are an example: Some allow users to train models on potentially sensitive data and charge others for access on a pay-per-query basis. \nThe tension between model confidentiality and public access motivates our investigation of model extraction attacks. In such attacks, an adversary with black-box access, but no prior knowledge of an ML model's parameters or training data, aims to duplicate the functionality of (i.e., \"steal\") the model. Unlike in classical learning theory settings, ML-as-a-service offerings may accept partial feature vectors as inputs and include confidence values with predictions. Given these practices, we show simple, efficient attacks that extract target ML models with near-perfect fidelity for popular model classes including logistic regression, neural networks, and decision trees. We demonstrate these attacks against the online services of BigML and Amazon Machine Learning. We further show that the natural countermeasure of omitting confidence values from model outputs still admits potentially harmful model extraction attacks. Our results highlight the need for careful ML model deployment and new model extraction countermeasures.",
            "keywords": [
                "Model Extraction Attacks",
                "ML-as-a-Service",
                "Black-Box Access",
                "Confidentiality of ML Models",
                "Prediction APIs"
            ]
        },
        "url": "URL#3835657",
        "sema_paperId": "8a95423d0059f7c5b1422f0ef1aa60b9e26aab7e"
    },
    {
        "@score": "1",
        "@id": "3835658",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "130/3608",
                        "text": "Mathy Vanhoef"
                    },
                    {
                        "@pid": "85/6647",
                        "text": "Frank Piessens"
                    }
                ]
            },
            "title": "Predicting, Decrypting, and Abusing WPA2/802.11 Group Keys.",
            "venue": "USENIX Security Symposium",
            "pages": "673-688",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/VanhoefP16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/vanhoef",
            "url": "https://dblp.org/rec/conf/uss/VanhoefP16",
            "abstract": "We analyze the generation and management of 802.11 group keys. These keys protect broadcast and multicast Wi-Fi traffic. We discovered several issues and illustrate their importance by decrypting all group (and unicast) traffic of a typical Wi-Fi network. First we argue that the 802.11 random number generator is flawed by design, and provides an insufficient amount of entropy. This is confirmed by predicting randomly generated group keys on several platforms. We then examine whether group keys are securely transmitted to clients. Here we discover a downgrade attack that forces usage of RC4 to encrypt the group key when transmitted in the 4-way handshake. The per-message RC4 key is the concatenation of a public 16-byte initialization vector with a secret 16-byte key, and the first 256 keystream bytes are dropped. We study this peculiar usage of RC4, and find that capturing 231 handshakes can be sufficient to recover (i.e., decrypt) a 128-bit group key. We also examine whether group traffic is properly isolated from unicast traffic. We find that this is not the case, and show that the group key can be used to inject and decrypt unicast traffic. Finally, we propose and study a new random number generator tailored for 802.11 platforms.",
            "keywords": [
                "Wi-Fi Security",
                "WPA2",
                "Group Key Management",
                "Random Number Generation",
                "Downgrade Attack"
            ]
        },
        "url": "URL#3835658",
        "sema_paperId": "c85b9acefb241eae4ce8a0dbc4863e43e09a1873"
    },
    {
        "@score": "1",
        "@id": "3835659",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "80/5862",
                        "text": "Amit Vasudevan"
                    },
                    {
                        "@pid": "79/5752",
                        "text": "Sagar Chaki"
                    },
                    {
                        "@pid": "m/PetrosManiatis",
                        "text": "Petros Maniatis"
                    },
                    {
                        "@pid": "89/161-1",
                        "text": "Limin Jia 0001"
                    },
                    {
                        "@pid": "d/AnupamDatta",
                        "text": "Anupam Datta"
                    }
                ]
            },
            "title": "\u00fcberSpark: Enforcing Verifiable Object Abstractions for Automated Compositional Security Analysis of a Hypervisor.",
            "venue": "USENIX Security Symposium",
            "pages": "87-104",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/VasudevanCMJD16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/vasudevan",
            "url": "https://dblp.org/rec/conf/uss/VasudevanCMJD16",
            "abstract": "We present uberSpark (uSpark), an innovative architecture for compositional verification of security properties of extensible hypervisors written in C and Assembly. uSpark comprises two key ideas: (i) endowing low-level system software with abstractions found in higher-level languages (e.g., objects, interfaces, function-call semantics for implementations of interfaces, access control on interfaces, concurrency and serialization), enforced using a combination of commodity hardware mechanisms and lightweight static analysis; and (ii) interfacing with platform hardware by programming in Assembly using an idiomatic style (called CASM) that is verifiable via tools aimed at C, while retaining its performance and low-level access to hardware. After verification, the C code is compiled using a certified compiler while the CASM code is translated into its corresponding Assembly instructions. Collectively, these innovations enable compositional verification of security invariants without sacrificing performance. We validate uSpark by building and verifying security invariants of an existing open-source commodity x86 micro-hypervisor and several of its extensions, and demonstrating only minor performance overhead with low verification costs.",
            "keywords": [
                "Hypervisor Security",
                "Compositional Verification",
                "Low-Level Abstractions",
                "Static Analysis",
                "Performance Overhead"
            ]
        },
        "url": "URL#3835659",
        "sema_paperId": "0d3c49f0d6743b03615bfcf546b5d015d32d4035"
    },
    {
        "@score": "1",
        "@id": "3835663",
        "info": {
            "authors": {
                "author": {
                    "@pid": "185/1597",
                    "text": "Daniel Lowe Wheeler"
                }
            },
            "title": "zxcvbn: Low-Budget Password Strength Estimation.",
            "venue": "USENIX Security Symposium",
            "pages": "157-173",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Wheeler16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/wheeler",
            "url": "https://dblp.org/rec/conf/uss/Wheeler16",
            "abstract": "For over 30 years, password requirements and feedback have largely remained a product of LUDS: counts of lowerand uppercase letters, digits and symbols. LUDS remains ubiquitous despite being a conclusively burdensome and ineffective security practice. zxcvbn is an alternative password strength estimator that is small, fast, and crucially no harder than LUDS to adopt. Using leaked passwords, we compare its estimations to the best of four modern guessing attacks and show it to be accurate and conservative at low magnitudes, suitable for mitigating online attacks. We find 1.5 MB of compressed storage is sufficient to accurately estimate the best-known guessing attacks up to 105 guesses, or 104 and 103 guesses, respectively, given 245 kB and 29 kB. zxcvbn can be adopted with 4 lines of code and downloaded in seconds. It runs in milliseconds and works as-is on web, iOS and Android.",
            "keywords": [
                "Password Strength Estimation",
                "zxcvbn",
                "Password Security",
                "Guessing Attacks",
                "Leaked Passwords"
            ]
        },
        "url": "URL#3835663",
        "sema_paperId": "f7403f27b0517be683836f9c1cb8b0f5a5d82b1a"
    },
    {
        "@score": "1",
        "@id": "3835664",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "79/10265",
                        "text": "Philipp Winter"
                    },
                    {
                        "@pid": "24/973",
                        "text": "Roya Ensafi"
                    },
                    {
                        "@pid": "02/1429",
                        "text": "Karsten Loesing"
                    },
                    {
                        "@pid": "87/840",
                        "text": "Nick Feamster"
                    }
                ]
            },
            "title": "Identifying and Characterizing Sybils in the Tor Network.",
            "venue": "USENIX Security Symposium",
            "pages": "1169-1185",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WinterELF16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/winter",
            "url": "https://dblp.org/rec/conf/uss/WinterELF16",
            "abstract": "Being a volunteer-run, distributed anonymity network, Tor is vulnerable to Sybil attacks. Little is known about real-world Sybils in the Tor network, and we lack practical tools and methods to expose Sybil attacks. In this work, we develop sybilhunter, a system for detecting Sybil relays based on their appearance, such as configuration; and behavior, such as uptime sequences. We used sybilhunter\u2019s diverse analysis techniques to analyze nine years of archived Tor network data, providing us with new insights into the operation of real-world attackers. Our findings include diverse Sybils, ranging from botnets, to academic research, and relays that hijacked Bitcoin transactions. Our work shows that existing Sybil defenses do not apply to Tor, it delivers insights into realworld attacks, and provides practical tools to uncover and characterize Sybils, making the network safer for its users.",
            "pdf_url": "",
            "keywords": [
                "Tor Network",
                "Sybils",
                "Anonymity",
                "Sybil Attacks",
                "Network Security"
            ]
        },
        "url": "URL#3835664"
    },
    {
        "@score": "1",
        "@id": "3835665",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "152/3962-1",
                        "text": "Yuan Xiao 0001"
                    },
                    {
                        "@pid": "158/4724",
                        "text": "Xiaokuan Zhang"
                    },
                    {
                        "@pid": "77/3503",
                        "text": "Yinqian Zhang"
                    },
                    {
                        "@pid": "04/3074",
                        "text": "Radu Teodorescu"
                    }
                ]
            },
            "title": "One Bit Flips, One Cloud Flops: Cross-VM Row Hammer Attacks and Privilege Escalation.",
            "venue": "USENIX Security Symposium",
            "pages": "19-35",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/XiaoZZT16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/xiao",
            "url": "https://dblp.org/rec/conf/uss/XiaoZZT16",
            "abstract": "Row hammer attacks exploit electrical interactions between neighboring memory cells in high-density dynamic random-access memory (DRAM) to induce memory errors. By rapidly and repeatedly accessing DRAMs with specific patterns, an adversary with limited privilege on the target machine may trigger bit flips in memory regions that he has no permission to access directly. In this paper, we explore row hammer attacks in cross-VM settings, in which a malicious VM exploits bit flips induced by row hammer attacks to crack memory isolation enforced by virtualization. To do so with high fidelity, we develop novel techniques to determine the physical address mapping in DRAMmodules at runtime (to improve the effectiveness of double-sided row hammer attacks), methods to exhaustively hammer a large fraction of physical memory from a guest VM (to collect exploitable vulnerable bits), and innovative approaches to break Xen paravirtualized memory isolation (to access arbitrary physical memory of the shared machine). Our study also suggests that the demonstrated row hammer attacks are applicable in modern public clouds where Xen paravirtualization technology is adopted. This shows that the presented cross-VM row hammer attacks are of practical importance.",
            "keywords": [
                "Row Hammer Attacks",
                "Cross-VM Exploitation",
                "Memory Isolation",
                "Privilege Escalation",
                "Xen Paravirtualization"
            ]
        },
        "url": "URL#3835665",
        "sema_paperId": "1114ef6ef315a23755740545ee46c5af0cf1e02c"
    },
    {
        "@score": "1",
        "@id": "3835666",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "14/5580-6",
                        "text": "Yi Xu 0006"
                    },
                    {
                        "@pid": "150/3079",
                        "text": "True Price"
                    },
                    {
                        "@pid": "19/6011",
                        "text": "Jan-Michael Frahm"
                    },
                    {
                        "@pid": "50/6700",
                        "text": "Fabian Monrose"
                    }
                ]
            },
            "title": "Virtual U: Defeating Face Liveness Detection by Building Virtual Models from Your Public Photos.",
            "venue": "USENIX Security Symposium",
            "pages": "497-512",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/XuPFM16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/xu",
            "url": "https://dblp.org/rec/conf/uss/XuPFM16",
            "abstract": "In this paper, we introduce a novel approach to bypass modern face authentication systems. More specifically, by leveraging a handful of pictures of the target user taken from social media, we show how to create realistic, textured, 3D facial models that undermine the security of widely used face authentication solutions. Our framework makes use of virtual reality (VR) systems, incorporating along the way the ability to perform animations (e.g., raising an eyebrow or smiling) of the facial model, in order to trick liveness detectors into believing that the 3D model is a real human face. The synthetic face of the user is displayed on the screen of the VR device, and as the device rotates and translates in the real world, the 3D face moves accordingly. To an observing face authentication system, the depth and motion cues of the display match what would be expected for a human face. \n \nWe argue that such VR-based spoofing attacks constitute a fundamentally new class of attacks that point to a serious weaknesses in camera-based authentication systems: Unless they incorporate other sources of verifiable data, systems relying on color image data and camera motion are prone to attacks via virtual realism. To demonstrate the practical nature of this threat, we conduct thorough experiments using an end-to-end implementation of our approach and show how it undermines the security of several face authentication solutions that include both motion-based and liveness detectors.",
            "keywords": [
                "Face Authentication",
                "Liveness Detection",
                "3D Facial Models",
                "Spoofing Attacks",
                "Virtual Reality"
            ]
        },
        "url": "URL#3835666",
        "sema_paperId": "70c0c064aaf1e66c70733db90541c965d996e84f"
    },
    {
        "@score": "1",
        "@id": "3835668",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "119/7670",
                        "text": "Insu Yun"
                    },
                    {
                        "@pid": "19/10203",
                        "text": "Changwoo Min"
                    },
                    {
                        "@pid": "142/8449",
                        "text": "Xujie Si"
                    },
                    {
                        "@pid": "150/5222",
                        "text": "Yeongjin Jang"
                    },
                    {
                        "@pid": "38/8882",
                        "text": "Taesoo Kim"
                    },
                    {
                        "@pid": "92/6794",
                        "text": "Mayur Naik"
                    }
                ]
            },
            "title": "APISan: Sanitizing API Usages through Semantic Cross-Checking.",
            "venue": "USENIX Security Symposium",
            "pages": "363-378",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YunMSJKN16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/yun",
            "url": "https://dblp.org/rec/conf/uss/YunMSJKN16",
            "abstract": "API misuse is a well-known source of bugs. Some of them (e.g., incorrect use of SSL API, and integer overflow of memory allocation size) can cause serious security vulnerabilities (e.g., man-in-the-middle (MITM) attack, and privilege escalation). Moreover, modern APIs, which are large, complex, and fast evolving, are error-prone. However, existing techniques to help finding bugs require manual effort by developers (e.g., providing specification or model) or are not scalable to large real-world software comprising millions of lines of code. In this paper, we present APIS AN , a tool that automatically infers correct API usages from source code without manual effort. The key idea in APIS AN is to extract likely correct usage patterns in four different aspects (e.g., causal relation, and semantic relation on arguments) by considering semantic constraints. APIS AN is tailored to check various properties with security implications. We applied APIS AN to 92 million lines of code, including Linux Kernel, and OpenSSL, found 76 previously unknown bugs, and provided patches for all the bugs.",
            "keywords": [
                "API Misuse",
                "Semantic Cross-Checking",
                "Bug Detection",
                "Security Vulnerabilities",
                "Automated Analysis"
            ]
        },
        "url": "URL#3835668",
        "sema_paperId": "abb6275033e81513b4549aeee979a51e29c5b42d"
    },
    {
        "@score": "1",
        "@id": "3835669",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "82/4816-1",
                        "text": "Yupeng Zhang 0001"
                    },
                    {
                        "@pid": "k/JonathanKatz",
                        "text": "Jonathan Katz"
                    },
                    {
                        "@pid": "p/CharalamposPapamanthou",
                        "text": "Charalampos Papamanthou"
                    }
                ]
            },
            "title": "All Your Queries Are Belong to Us: The Power of File-Injection Attacks on Searchable Encryption.",
            "venue": "USENIX Security Symposium",
            "pages": "707-720",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhangKP16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/zhang",
            "url": "https://dblp.org/rec/conf/uss/ZhangKP16",
            "abstract": "The goal of searchable encryption (SE) is to enable a client to execute searches over encrypted files stored on an untrusted server while ensuring some measure of privacy for both the encrypted files and the search queries. Most recent research has focused on developing efficient SE schemes at the expense of allowing some small, wellcharacterized \u201c(information) leakage\u201d to the server about the files and/or the queries. The practical impact of this leakage, however, remains unclear. We thoroughly study file-injection attacks\u2014in which the server sends files to the client that the client then encrypts and stores\u2014on the query privacy of singlekeyword and conjunctive SE schemes. We show such attacks can reveal the client\u2019s queries in their entirety using very few injected files, even for SE schemes having low leakage. We also demonstrate that natural countermeasures for preventing file-injection attacks can be easily circumvented. Our attacks outperform prior work significantly in terms of their effectiveness as well as in terms of their assumptions about the attacker\u2019s prior knowledge.",
            "keywords": [
                "Searchable Encryption",
                "File-Injection Attacks",
                "Query Privacy",
                "Information Leakage",
                "Conjunctive Search"
            ]
        },
        "url": "URL#3835669",
        "sema_paperId": "6b18ffd074e7d85869e5a3aaaf44bb8bd327e47c"
    },
    {
        "@score": "1",
        "@id": "3835670",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "170/3735",
                        "text": "Ruiyu Zhu"
                    },
                    {
                        "@pid": "75/6434-1",
                        "text": "Yan Huang 0001"
                    },
                    {
                        "@pid": "k/JonathanKatz",
                        "text": "Jonathan Katz"
                    },
                    {
                        "@pid": "s/AShelat",
                        "text": "Abhi Shelat"
                    }
                ]
            },
            "title": "The Cut-and-Choose Game and Its Application to Cryptographic Protocols.",
            "venue": "USENIX Security Symposium",
            "pages": "1085-1100",
            "year": "2016",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhuHKS16",
            "ee": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/zhu",
            "url": "https://dblp.org/rec/conf/uss/ZhuHKS16",
            "abstract": "The cut-and-choose technique plays a fundamental role in cryptographic-protocol design, especially for secure two-party computation in the malicious model. The basic idea is that one party constructs n versions of a message in a protocol (e.g., garbled circuits); the other party randomly checks some of them and uses the rest of them in the protocol. Most existing uses of cut-and-choose fix in advance the number of objects to be checked and in optimizing this parameter they fail to recognize the fact that checking and evaluating may have dramatically different costs. In this paper, we consider a refined cost model and formalize the cut-and-choose parameter selection problem as a constrained optimization problem. We analyze \u201ccut-and-choose games\u201d and show equilibrium strategies for the parties in these games. We then show how our methodology can be applied to improve the efficiency of three representative categories of secure-computation protocols based on cut-and-choose. We show improvements of up to an-order-of-magnitude in terms of bandwidth, and 12\u2013106% in terms of total time. Source code of our game solvers is available to download at https://github.com/cut-n-choose.",
            "keywords": [
                "Cut-and-Choose Technique",
                "Secure Two-Party Computation",
                "Malicious Model",
                "Cost Optimization",
                "Protocol Efficiency"
            ]
        },
        "url": "URL#3835670",
        "sema_paperId": "0ada489ea8cffd88d86108695eb6b7f0cee0f0c5"
    },
    {
        "@score": "1",
        "@id": "3849636",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "h/ThorstenHolz",
                        "text": "Thorsten Holz"
                    },
                    {
                        "@pid": "s/StefanSavage",
                        "text": "Stefan Savage"
                    }
                ]
            },
            "title": "25th USENIX Security Symposium, USENIX Security 16, Austin, TX, USA, August 10-12, 2016.",
            "venue": "USENIX Security Symposium",
            "publisher": "USENIX Association",
            "year": "2016",
            "type": "Editorship",
            "access": "open",
            "key": "conf/uss/2016",
            "ee": "https://www.usenix.org/conference/usenixsecurity16",
            "url": "https://dblp.org/rec/conf/uss/2016",
            "abstract": null
        },
        "url": "URL#3849636",
        "sema_paperId": "d9d0f090453ec939e694d7a02d0b77100cfc0d28"
    }
]