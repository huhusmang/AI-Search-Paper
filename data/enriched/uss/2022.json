[
    {
        "@score": "1",
        "@id": "1416819",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "79/4489-1",
                        "text": "Yufei Chen 0001"
                    },
                    {
                        "@pid": "48/4825-1",
                        "text": "Chao Shen 0001"
                    },
                    {
                        "@pid": "18/2771-1",
                        "text": "Cong Wang 0001"
                    },
                    {
                        "@pid": "06/6785-16",
                        "text": "Yang Zhang 0016"
                    }
                ]
            },
            "title": "Teacher Model Fingerprinting Attacks Against Transfer Learning.",
            "venue": "USENIX Security Symposium",
            "pages": "3593-3610",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/000100022",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/chen-yufei",
            "url": "https://dblp.org/rec/conf/uss/000100022",
            "abstract": "Transfer learning has become a common solution to address training data scarcity in practice. It trains a specified student model by reusing or fine-tuning early layers of a well-trained teacher model that is usually publicly available. However, besides utility improvement, the transferred public knowledge also brings potential threats to model confidentiality, and even further raises other security and privacy issues. In this paper, we present the first comprehensive investigation of the teacher model exposure threat in the transfer learning context, aiming to gain a deeper insight into the tension between public knowledge and model confidentiality. To this end, we propose a teacher model fingerprinting attack to infer the origin of a student model, i.e., the teacher model it transfers from. Specifically, we propose a novel optimization-based method to carefully generate queries to probe the student model to realize our attack. Unlike existing model reverse engineering approaches, our proposed fingerprinting method neither relies on fine-grained model outputs, e.g., posteriors, nor auxiliary information of the model architecture or training dataset. We systematically evaluate the effectiveness of our proposed attack. The empirical results demonstrate that our attack can accurately identify the model origin with few probing queries. Moreover, we show that the proposed attack can serve as a stepping stone to facilitating other attacks against machine learning models, such as model stealing.",
            "keywords": [
                "Transfer Learning",
                "Model Confidentiality",
                "Fingerprinting Attack",
                "Model Origin Inference",
                "Model Stealing"
            ]
        },
        "url": "URL#1416819",
        "sema_paperId": "c725eaed79d84ba73caaea3ae4d0e7298d3592d1"
    },
    {
        "@score": "1",
        "@id": "1416820",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "90/545-1",
                        "text": "Zhikun Zhang 0001"
                    },
                    {
                        "@pid": "50/6996-32",
                        "text": "Min Chen 0032"
                    },
                    {
                        "@pid": "b/MichaelBackes1",
                        "text": "Michael Backes 0001"
                    },
                    {
                        "@pid": "14/4412",
                        "text": "Yun Shen"
                    },
                    {
                        "@pid": "06/6785-16",
                        "text": "Yang Zhang 0016"
                    }
                ]
            },
            "title": "Inference Attacks Against Graph Neural Networks.",
            "venue": "USENIX Security Symposium",
            "pages": "4543-4560",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/000100S022",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/zhang-zhikun",
            "url": "https://dblp.org/rec/conf/uss/000100S022",
            "abstract": "Graph is an important data representation ubiquitously existing in the real world. However, analyzing the graph data is computationally difficult due to its non-Euclidean nature. Graph embedding is a powerful tool to solve the graph analytics problem by transforming the graph data into low-dimensional vectors. These vectors could also be shared with third parties to gain additional insights of what is behind the data. While sharing graph embedding is intriguing, the associated privacy risks are unexplored. In this paper, we systematically investigate the information leakage of the graph embedding by mounting three inference attacks. First, we can successfully infer basic graph properties, such as the number of nodes, the number of edges, and graph density, of the target graph with up to 0.89 accuracy. Second, given a subgraph of interest and the graph embedding, we can determine with high confidence that whether the subgraph is contained in the target graph. For instance, we achieve 0.98 attack AUC on the DD dataset. Third, we propose a novel graph reconstruction attack that can reconstruct a graph that has similar graph structural statistics to the target graph. We further propose an effective defense mechanism based on graph embedding perturbation to mitigate the inference attacks without noticeable performance degradation for graph classification tasks.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-zhang-zhikun.pdf",
            "keywords": [
                "Graph Neural Networks",
                "Graph Embedding",
                "Inference Attacks",
                "Information Leakage",
                "Graph Reconstruction Attack"
            ]
        },
        "url": "URL#1416820"
    },
    {
        "@score": "1",
        "@id": "1416821",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "168/6451-1",
                        "text": "Jiafan Wang 0001"
                    },
                    {
                        "@pid": "c/ShermanSMChow",
                        "text": "Sherman S. M. Chow"
                    }
                ]
            },
            "title": "Omnes pro uno: Practical Multi-Writer Encrypted Database.",
            "venue": "USENIX Security Symposium",
            "pages": "2371-2388",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0001C22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/wang-jiafan",
            "url": "https://dblp.org/rec/conf/uss/0001C22",
            "abstract": "Multi-writer encrypted databases allow a reader to search over data contributed by multiple writers securely. Public-key searchable encryption ( PKSE ) appears to be the right primi-tive. However, its search latency is not welcomed in practice for requiring public-key operations linear in the database size. In contrast, symmetric searchable encryption ( SSE ) realizes sublinear search, but it is inherently not multi-writer. This paper aims for the best of both SSE and PKSE , i.e. , sublinear search and multiple writers, by formalizing hybrid searchable encryption ( HSE ), with some seemingly con\ufb02ict-ing yet desirable features, requiring new insights to achieve. HSE , built on top of dynamic SSE ( DSSE ), should satisfy the de facto standard of forward privacy. Its multi-writer support makes the known approach (of secret state maintenance) fail. HSE should also feature con\ufb01ned search, ideally with search tokens of size independent of the writer subset size for each search. For these, we devise a partial rebuild technique and two building blocks (of independent interests) \u2013 identity-coupling key-aggregate encryption and epoch-based forward-private DSSE . Our evaluation over real-world datasets shows that HSE surpasses prior arts by orders of magnitude.",
            "keywords": [
                "Multi-Writer Encrypted Database",
                "Hybrid Searchable Encryption",
                "Symmetric Searchable Encryption",
                "Public-Key Searchable Encryption",
                "Search Latency"
            ]
        },
        "url": "URL#1416821",
        "sema_paperId": "56109f2476fee6e188c78bf5f22ad3afbdaea379"
    },
    {
        "@score": "1",
        "@id": "1416822",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "68/2052-1",
                        "text": "Lei Xue 0001"
                    },
                    {
                        "@pid": "14/3968",
                        "text": "Yangyang Liu"
                    },
                    {
                        "@pid": "29/10591",
                        "text": "Tianqi Li"
                    },
                    {
                        "@pid": "201/9069",
                        "text": "Kaifa Zhao"
                    },
                    {
                        "@pid": "10/3844-6",
                        "text": "Jianfeng Li 0006"
                    },
                    {
                        "@pid": "23/7122-2",
                        "text": "Le Yu 0002"
                    },
                    {
                        "@pid": "53/1565",
                        "text": "Xiapu Luo"
                    },
                    {
                        "@pid": "15/7381",
                        "text": "Yajin Zhou"
                    },
                    {
                        "@pid": "64/1147",
                        "text": "Guofei Gu"
                    }
                ]
            },
            "title": "SAID: State-aware Defense Against Injection Attacks on In-vehicle Network.",
            "venue": "USENIX Security Symposium",
            "pages": "1921-1938",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0001LLZLYLZG22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/xue-lei",
            "url": "https://dblp.org/rec/conf/uss/0001LLZLYLZG22",
            "abstract": "Modern vehicles are equipped with many ECU s (Electronic Control Unit) that are connected to the IVN (In-Vehicle Network) for controlling the vehicles. Meanwhile, various interfaces of vehicles, such as OBD-II port, T-Box, sensors, and telematics, implement the interaction between the IVN and external environment. Although rich value-added functionalities can be provided through these interfaces, such as diagnostics and OTA (Over The Air) updates, the adversary may also inject malicious data into IVN , thus causing severe safety is-sues. Even worse, existing defense approaches mainly focus on detecting the injection attacks launched from IVN , such as malicious/compromised ECU s, by analyzing CAN frames, and cannot defend against the higher layer MIA s (Message Injection Attacks) that can cause abnormal vehicle dynamics. In this paper, we propose a new state-aware abnormal message injection attack defense approach, named S AID . It detects the abnormal data to be injected into IVN by considering the data semantics and the vehicle dynamics and prevents the MIA s launched from devices connected to the vehicles, such as the compromised diagnostic tools and T-boxes. We develop a prototype of S AID for defending against MIA s and evaluate it using both real road data and simulation data. The experimental results show that S AID can defend against more than 99% of the network and service layer attack traf\ufb01c and all state layer MIA s, effectively enforcing the safety of vehicles.",
            "keywords": [
                "In-Vehicle Network",
                "Message Injection Attacks",
                "Electronic Control Units",
                "Data Semantics",
                "Vehicle Dynamics Safety"
            ]
        },
        "url": "URL#1416822",
        "sema_paperId": "5b2d286ffa591e2a6c8d49432a6fdbe1d913e7ab"
    },
    {
        "@score": "1",
        "@id": "1416823",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "133/5336-1",
                        "text": "Chong Xiang 0001"
                    },
                    {
                        "@pid": "208/0825",
                        "text": "Saeed Mahloujifar"
                    },
                    {
                        "@pid": "39/6266",
                        "text": "Prateek Mittal"
                    }
                ]
            },
            "title": "PatchCleanser: Certifiably Robust Defense against Adversarial Patches for Any Image Classifier.",
            "venue": "USENIX Security Symposium",
            "pages": "2065-2082",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0001MM22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/xiang",
            "url": "https://dblp.org/rec/conf/uss/0001MM22",
            "abstract": "The adversarial patch attack against image classification models aims to inject adversarially crafted pixels within a restricted image region (i.e., a patch) for inducing model misclassification. This attack can be realized in the physical world by printing and attaching the patch to the victim object; thus, it imposes a real-world threat to computer vision systems. To counter this threat, we design PatchCleanser as a certifiably robust defense against adversarial patches. In PatchCleanser, we perform two rounds of pixel masking on the input image to neutralize the effect of the adversarial patch. This image-space operation makes PatchCleanser compatible with any state-of-the-art image classifier for achieving high accuracy. Furthermore, we can prove that PatchCleanser will always predict the correct class labels on certain images against any adaptive white-box attacker within our threat model, achieving certified robustness. We extensively evaluate PatchCleanser on the ImageNet, ImageNette, and CIFAR-10 datasets and demonstrate that our defense achieves similar clean accuracy as state-of-the-art classification models and also significantly improves certified robustness from prior works. Remarkably, PatchCleanser achieves 83.9% top-1 clean accuracy and 62.1% top-1 certified robust accuracy against a 2%-pixel square patch anywhere on the image for the 1000-class ImageNet dataset.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-xiang.pdf",
            "keywords": [
                "Adversarial Patch Attack",
                "Image Classification",
                "Certified Robustness",
                "Pixel Masking",
                "PatchCleanser"
            ]
        },
        "url": "URL#1416823"
    },
    {
        "@score": "1",
        "@id": "1416824",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "197/6723-1",
                        "text": "Jinyu Gu 0001"
                    },
                    {
                        "@pid": "301/6313",
                        "text": "Bojun Zhu"
                    },
                    {
                        "@pid": "82/2094",
                        "text": "Mingyu Li"
                    },
                    {
                        "@pid": "221/3459",
                        "text": "Wentai Li"
                    },
                    {
                        "@pid": "01/615",
                        "text": "Yubin Xia"
                    },
                    {
                        "@pid": "31/6601-1",
                        "text": "Haibo Chen 0001"
                    }
                ]
            },
            "title": "A Hardware-Software Co-design for Efficient Intra-Enclave Isolation.",
            "venue": "USENIX Security Symposium",
            "pages": "3129-3145",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0001ZLLX022",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/gu-jinyu",
            "url": "https://dblp.org/rec/conf/uss/0001ZLLX022",
            "abstract": "The monolithic programming model has been favored for high compatibility and easing the programming for SGX en-claves, i.e., running the secure code with all dependent libraries or even library OSes (LibOSes). Yet, it inevitably bloats the trusted computing base (TCB) and thus deviates from the goal of high security. Introducing \ufb01ne-grained isolation can effectively mitigate TCB bloating while existing solutions face performance issues. We observe that the off-the-shelf Intel MPK is a perfect match for ef\ufb01cient intra-enclave isolation. Nonetheless, the trust models between MPK and SGX are incompatible by design. We hence propose L IGHT - E NCLAVE , which embraces non-intrusive extensions on existing SGX hardware to incorporate MPK securely and allows multiple light-enclaves isolated within one enclave. Experiments show that L IGHT E NCLAVE incurs up to 4% overhead when separating secret SSL keys for server applications and can signi\ufb01cantly improve the performance of Graphene-SGX and Occlum by reducing the communication and runtime overhead, respectively.",
            "keywords": [
                "SGX Enclaves",
                "Intra-Enclave Isolation",
                "Trusted Computing Base (TCB)",
                "Intel MPK",
                "Performance Overhead"
            ]
        },
        "url": "URL#1416824",
        "sema_paperId": "c59b057f4de112bc0a8ae548f3169b352d5b0ca2"
    },
    {
        "@score": "1",
        "@id": "1416825",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "238/0150-1",
                        "text": "Yiping Ma 0001"
                    },
                    {
                        "@pid": "40/4551",
                        "text": "Ke Zhong"
                    },
                    {
                        "@pid": "r/TalRabin",
                        "text": "Tal Rabin"
                    },
                    {
                        "@pid": "132/8480",
                        "text": "Sebastian Angel"
                    }
                ]
            },
            "title": "Incremental Offline/Online PIR.",
            "venue": "USENIX Security Symposium",
            "pages": "1741-1758",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0001ZRA22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/ma",
            "url": "https://dblp.org/rec/conf/uss/0001ZRA22",
            "abstract": ". Recent private information retrieval (PIR) schemes preprocess the database with a query-independent offline phase in order to achieve sublinear computation during a query-specific online phase. These offline/online protocols expand the set of applications that can profitably use PIR, but they make a critical assumption: that the database is immutable. In the presence of changes such as additions, deletions, or updates, existing schemes must preprocess the database from scratch, wasting prior effort. To address this, we introduce incremental preprocessing for offline/online PIR schemes, allowing the original preprocessing to continue to be used after database changes, while incurring an update cost proportional to the number of changes rather than the size of the database. We adapt two offline/online PIR schemes to use incremental preprocessing and show how it significantly improves the throughput and reduces the latency of applications where the database changes over time.",
            "keywords": [
                "Private Information Retrieval",
                "Incremental Preprocessing",
                "Database Updates",
                "Offline/Online Protocols",
                "Query Efficiency"
            ]
        },
        "url": "URL#1416825",
        "sema_paperId": "612e2fce0eff76da0d089d538f3059b556e024ef"
    },
    {
        "@score": "1",
        "@id": "1416826",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "43/8066-4",
                        "text": "Xiaojie Guo 0004"
                    },
                    {
                        "@pid": "70/961",
                        "text": "Ye Han"
                    },
                    {
                        "@pid": "22/8078",
                        "text": "Zheli Liu"
                    },
                    {
                        "@pid": "99/4292-2",
                        "text": "Ding Wang 0002"
                    },
                    {
                        "@pid": "230/3262",
                        "text": "Yan Jia"
                    },
                    {
                        "@pid": "48/1097-2",
                        "text": "Jin Li 0002"
                    }
                ]
            },
            "title": "Birds of a Feather Flock Together: How Set Bias Helps to Deanonymize You via Revealed Intersection Sizes.",
            "venue": "USENIX Security Symposium",
            "pages": "1487-1504",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0004HLWJ022",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/guo",
            "url": "https://dblp.org/rec/conf/uss/0004HLWJ022",
            "abstract": "Secure two-party protocols that compute intersection-related statistics have attracted much attention from the industry. These protocols enable two organizations to jointly compute a function (e.g., count and sum) over the intersection of their sets without explicitly revealing this intersection. However, most of such protocols will reveal the intersection size of the two sets in the end. In this work, we are interested in how well an attacker can leverage the revealed intersection sizes to infer some elements' membership of one organization's set. Even disclosing an element's membership of one organization's set to the other organization may violate privacy regulations (e.g., GDPR) since such an element is usually used to identify a person between two organizations. We are the first to study this set membership leakage in intersection-size-revealing protocols. We propose two attacks, namely, baseline attack and feature-aware attack, to evaluate this leakage in realistic scenarios. In particular, our feature-aware attack exploits the realistic set bias that elements with specific features are more likely to be the members of one organization's set. The results show that our two attacks can infer 2.0 similar to 72.7 set members on average in three realistic scenarios. If the set bias is not weak, the feature-aware attack will outperform the baseline one. For example, in COVID-19 contact tracing, the feature-aware attack can find 25.9 tokens of infected patients in 135 protocol invocations, 1.5 x more than the baseline attack. We discuss how such results may cause negative real-world impacts and propose possible defenses against our attacks.",
            "keywords": [
                "Set Membership Leakage",
                "Intersection Size Protocols",
                "Privacy Regulations",
                "Feature-Aware Attacks",
                "Set Bias"
            ]
        },
        "url": "URL#1416826",
        "sema_paperId": "23f9e96819985dec84c18117ad983172aa1b0bca"
    },
    {
        "@score": "1",
        "@id": "1416827",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "53/8484-4",
                        "text": "Daniel G\u00fcnther 0004"
                    },
                    {
                        "@pid": "296/2518",
                        "text": "Maurice Heymann"
                    },
                    {
                        "@pid": "31/1735",
                        "text": "Benny Pinkas"
                    },
                    {
                        "@pid": "06/3872-3",
                        "text": "Thomas Schneider 0003"
                    }
                ]
            },
            "title": "GPU-accelerated PIR with Client-Independent Preprocessing for Large-Scale Applications.",
            "venue": "USENIX Security Symposium",
            "pages": "1759-1776",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0004HP022",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/gunther",
            "url": "https://dblp.org/rec/conf/uss/0004HP022",
            "abstract": "Multi-Server Private Information Retrieval (PIR) is a cryptographic protocol that allows a client to securely query a database entry from n \u2265 2 servers of which less than t can collude, s.t. the servers learn no information about the query. Highly efficient PIR could be used for large-scale applications like Compromised Credential Checking (C3) (USENIX Security'19), which allows users to check whether their credentials have been leaked in a data breach. However, state-of-the art PIR schemes are not efficient enough for fast online responses at this scale.In this work, we introduce Client-Independent Preprocessing (CIP) PIR that moves (t \u22121)/n of the online computation to a local, client independent, preprocessing phase suitable for efficient batch precomputations. The online performance of CIP-PIR improves linearly with the number of servers n. We show that large-scale applications like C3 with PIR are practical by implementing our CIP-PIR scheme using a parallelized CPU implementation. To the best of our knowledge, this is the first multi-server PIR scheme whose preprocessing phase is completely independent of the client, and where online performance simultaneously improves with the number of servers n. In addition, we accelerate for the first time the huge amount of XOR operations in multi-server PIR with GPUs. Our GPUbased CIP-PIR achieves an improvement up to factor 2.1\u00d7 over our CPU-based implementation for n = 2 servers, and enables a client to query an entry in a 25 GB database within less than 1 second.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-gunther.pdf",
            "keywords": [
                "Private Information Retrieval",
                "Client-Independent Preprocessing",
                "Multi-Server Architecture",
                "Database Querying",
                "GPU Acceleration"
            ]
        },
        "url": "URL#1416827"
    },
    {
        "@score": "1",
        "@id": "1416828",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "82/6141-5",
                        "text": "Hongbin Liu 0005"
                    },
                    {
                        "@pid": "24/5124-1",
                        "text": "Jinyuan Jia 0001"
                    },
                    {
                        "@pid": "03/9437",
                        "text": "Neil Zhenqiang Gong"
                    }
                ]
            },
            "title": "PoisonedEncoder: Poisoning the Unlabeled Pre-training Data in Contrastive Learning.",
            "venue": "USENIX Security Symposium",
            "pages": "3629-3645",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0005JG22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/liu-hongbin",
            "url": "https://dblp.org/rec/conf/uss/0005JG22",
            "abstract": "Contrastive learning pre-trains an image encoder using a large amount of unlabeled data such that the image encoder can be used as a general-purpose feature extractor for various downstream tasks. In this work, we propose PoisonedEncoder, a data poisoning attack to contrastive learning. In particular, an attacker injects carefully crafted poisoning inputs into the unlabeled pre-training data, such that the downstream classifiers built based on the poisoned encoder for multiple target downstream tasks simultaneously classify attacker-chosen, arbitrary clean inputs as attacker-chosen, arbitrary classes. We formulate our data poisoning attack as a bilevel optimization problem, whose solution is the set of poisoning inputs; and we propose a contrastive-learning-tailored method to approximately solve it. Our evaluation on multiple datasets shows that PoisonedEncoder achieves high attack success rates while maintaining the testing accuracy of the downstream classifiers built upon the poisoned encoder for non-attacker-chosen inputs. We also evaluate five defenses against PoisonedEncoder, including one pre-processing, three in-processing, and one post-processing defenses. Our results show that these defenses can decrease the attack success rate of PoisonedEncoder, but they also sacrifice the utility of the encoder or require a large clean pre-training dataset.",
            "keywords": [
                "Contrastive Learning",
                "Data Poisoning",
                "Image Encoder",
                "Bilevel Optimization",
                "Downstream Classifiers"
            ]
        },
        "url": "URL#1416828",
        "sema_paperId": "5a123d014b77652aefff24e6e26c7f95d43f409a"
    },
    {
        "@score": "1",
        "@id": "1416829",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "64/5725-18",
                        "text": "Long Chen 0018"
                    },
                    {
                        "@pid": "61/7498-7",
                        "text": "Ya-Nan Li 0007"
                    },
                    {
                        "@pid": "17/2212-5",
                        "text": "Qiang Tang 0005"
                    },
                    {
                        "@pid": "y/MotiYung",
                        "text": "Moti Yung"
                    }
                ]
            },
            "title": "End-to-Same-End Encryption: Modularly Augmenting an App with an Efficient, Portable, and Blind Cloud Storage.",
            "venue": "USENIX Security Symposium",
            "pages": "2353-2370",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/001800Y22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/chen-long",
            "url": "https://dblp.org/rec/conf/uss/001800Y22",
            "abstract": "\n The cloud has become pervasive, and we ask: how can we protect cloud data against the cloud itself? For secure user-to-user communication via a cloud server, End-to-End encryption has been formally studied, building on existing TLS channels without requiring new primitives. However, enabling user-to-same-user secure outsourced data storage - solving the analogous problem of \u201cprivacy from the server\u201d while (1) relying on existing infrastructure and (2) supporting user mobility, remains open. Existing proposals, like password-protected secret sharing, target the same goal but are incompatible with existing cloud storage services. Specifically, they lack the simplicity needed to directly utilize existing cloud\n storage\n without requiring changes on the cloud side.\n \n \n Here, we propose a novel system for securely storing private data in existing cloud storage with the help of a key server (necessary given the requirements). In our system, user data is secure against threats from the cloud server, the key server, and illegitimate users. Only the legitimate user can access the data on any device using a correct passphrase. Most importantly, our system does not require the storage server to support any newly programmable operations. Moreover, leveraging the existing App login, our system requires only one passphrase, which never leaves the user\u2019s device and remains hidden from both servers. The security is proved under formal models, and its efficiency is demonstrated by experiments conducted on Amazon S3. Notably, a preliminary variant, based on our principles, was deployed by Snapchat in their\n My Eyes Only\n module, serving hundreds of millions of users!\n",
            "keywords": [
                "Cloud Storage Security",
                "End-to-End Encryption",
                "User Privacy",
                "Data Outsourcing",
                "Key Management"
            ]
        },
        "url": "URL#1416829",
        "sema_paperId": "a415ad2dc1cc00f3dd1f90fdf0f9de46c328e37d"
    },
    {
        "@score": "1",
        "@id": "1416830",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "52/3194-46",
                        "text": "Fei Wang 0046"
                    },
                    {
                        "@pid": "16/5608",
                        "text": "Jianliang Wu"
                    },
                    {
                        "@pid": "167/0416",
                        "text": "Yuhong Nan"
                    },
                    {
                        "@pid": "138/6356",
                        "text": "Yousra Aafer"
                    },
                    {
                        "@pid": "95/3760-1",
                        "text": "Xiangyu Zhang 0001"
                    },
                    {
                        "@pid": "59/5539",
                        "text": "Dongyan Xu"
                    },
                    {
                        "@pid": "31/1273",
                        "text": "Mathias Payer"
                    }
                ]
            },
            "title": "ProFactory: Improving IoT Security via Formalized Protocol Customization.",
            "venue": "USENIX Security Symposium",
            "pages": "3879-3896",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0046WNA0XP22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/wang-fei",
            "url": "https://dblp.org/rec/conf/uss/0046WNA0XP22",
            "abstract": "As IoT applications gain widespread adoption, it becomes important to design and implement IoT protocols with security. Existing research in protocol security reveals that the majority of disclosed protocol vulnerabilities are caused by incorrectly implemented message parsing and network state machines. Instead of testing and \ufb01xing those bugs after development, which is extremely expensive, we would like to avert them upfront. For this purpose, we propose P RO F AC - TORY which formally and unambiguously models a protocol, checks model correctness, and generates a secure protocol implementation. We leverage P RO F ACTORY to generate a group of IoT protocols in the Bluetooth and Zigbee families and the evaluation demonstrates that 82 known vulnerabilities are averted. P RO F ACTORY will be publicly available [1].",
            "keywords": [
                "IoT Protocol Security",
                "Formal Modeling",
                "Protocol Customization",
                "Vulnerability Prevention",
                "Message Parsing Errors"
            ]
        },
        "url": "URL#1416830",
        "sema_paperId": "7b4538ba65cf7940fd1f57afc43d9e97a6ea0bdd"
    },
    {
        "@score": "1",
        "@id": "1416831",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "97/8704-96",
                        "text": "Lei Zhang 0096"
                    },
                    {
                        "@pid": "191/1165",
                        "text": "Zhibo Zhang"
                    },
                    {
                        "@pid": "331/2675",
                        "text": "Ancong Liu"
                    },
                    {
                        "@pid": "28/8733",
                        "text": "Yinzhi Cao"
                    },
                    {
                        "@pid": "96/6053-1",
                        "text": "Xiaohan Zhang 0001"
                    },
                    {
                        "@pid": "28/3921",
                        "text": "Yanjun Chen"
                    },
                    {
                        "@pid": "48/2168-9",
                        "text": "Yuan Zhang 0009"
                    },
                    {
                        "@pid": "153/5855",
                        "text": "Guangliang Yang 0001"
                    },
                    {
                        "@pid": "02/1640-2",
                        "text": "Min Yang 0002"
                    }
                ]
            },
            "title": "Identity Confusion in WebView-based Mobile App-in-app Ecosystems.",
            "venue": "USENIX Security Symposium",
            "pages": "1597-1613",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0096ZLC0C0Y022",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/zhang-lei",
            "url": "https://dblp.org/rec/conf/uss/0096ZLC0C0Y022",
            "abstract": "Mobile applications (apps) often delegate their own functions to other parties, which makes them become a super ecosystem hosting these parties. Therefore, such mobile apps are being called super-apps, and the delegated parties are subsequently called sub-apps, behaving like \u201capp-in-app\u201d. Sub-apps not only load (third-party) resources like a normal app, but also have access to the privileged APIs provided by the super-app. This leads to an important research question\u2014determining who can access these privileged APIs. Real-world super-apps, according to our study, adopt three types of identities\u2014namely web domains, sub-app IDs, and capabilities\u2014to determine privileged API access. However, existing identity checks of these three types are often not well designed, leading to a disobey of the least privilege principle. That is, the granted recipient of a privileged API is broader than intended, thus defined as an \u201cidentity confusion\u201d in this paper. To the best of our knowledge, no prior works have studied this type of identity confusion vulnerability. In this paper, we perform the first systematic study of identity confusion in real-world app-in-app ecosystems. We find that confusions of the aforementioned three types of identities are widespread among all 47 studied super-apps. More impor-tantly, such confusions lead to severe consequences such as manipulating users\u2019 financial accounts and installing malware on a smartphone. We responsibly reported all of our findings to developers of affected super-apps, and helped them to fix their vulnerabilities.",
            "keywords": [
                "Mobile App Ecosystems",
                "Super-apps",
                "Identity Confusion",
                "Privileged API Access",
                "Sub-app Vulnerabilities"
            ]
        },
        "url": "URL#1416831",
        "sema_paperId": "29e6e2bb927fd0ecd418b63e783f086ac5375623"
    },
    {
        "@score": "1",
        "@id": "1416834",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "207/6255",
                        "text": "Shimaa Ahmed"
                    },
                    {
                        "@pid": "213/8587",
                        "text": "Ilia Shumailov"
                    },
                    {
                        "@pid": "162/1405",
                        "text": "Nicolas Papernot"
                    },
                    {
                        "@pid": "97/535",
                        "text": "Kassem Fawaz"
                    }
                ]
            },
            "title": "Towards More Robust Keyword Spotting for Voice Assistants.",
            "venue": "USENIX Security Symposium",
            "pages": "2655-2672",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AhmedSPF22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/ahmed",
            "url": "https://dblp.org/rec/conf/uss/AhmedSPF22",
            "abstract": "Voice assistants rely on keyword spotting (KWS) to process vocal commands issued by humans: commands are prepended with a keyword, such as \u201cAlexa\u201d or \u201cOk Google,\u201d which must be spotted to activate the voice assistant. Typically, keyword spotting is two-fold: an on-device model first identifies the keyword, then the resulting voice sample triggers a second on-cloud model which verifies and processes the activation. In this work, we explore the significant privacy and security concerns that this raises under two threat models. First, our experiments demonstrate that accidental activations result in up to a minute of speech recording being uploaded to the cloud. Second, we verify that adversaries can systematically trigger misactivations through adversarial examples, which exposes the integrity and availability of services connected to the voice assistant. We propose EKOS (Ensemble for KeywOrd Spotting) which leverages the semantics of the KWS task to defend against both accidental and adversarial activations. EKOS incorporates spatial redundancy from the acoustic environment at training and inference time to minimize distribution drifts responsible for accidental activations. It also exploits a physical property of speech\u2014its redundancy at different harmonics\u2014to deploy an ensemble of models trained on different harmonics and provably force the adversary to modify more of the frequency spectrum to obtain adversarial examples. Our evaluation shows that EKOS increases the cost of adversarial activations, while preserving the natural accuracy. We validate the performance of EKOS with over-the-air experiments on commodity devices and commercial voice assistants; we find that EKOS improves the precision of the KWS task in non-adversarial settings.",
            "keywords": [
                "Keyword Spotting",
                "Voice Assistants",
                "Accidental Activations",
                "Adversarial Examples",
                "EKOS"
            ]
        },
        "url": "URL#1416834",
        "sema_paperId": "fd778ae06dd66f080514a4374a4b3d38722e2c52"
    },
    {
        "@score": "1",
        "@id": "1416835",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "166/2137",
                        "text": "Bushra A. AlAhmadi"
                    },
                    {
                        "@pid": "193/3111",
                        "text": "Louise Axon"
                    },
                    {
                        "@pid": "87/2623",
                        "text": "Ivan Martinovic"
                    }
                ]
            },
            "title": "99% False Positives: A Qualitative Study of SOC Analysts&apos; Perspectives on Security Alarms.",
            "venue": "USENIX Security Symposium",
            "pages": "2783-2800",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AlAhmadiAM22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/alahmadi",
            "url": "https://dblp.org/rec/conf/uss/AlAhmadiAM22",
            "abstract": "In this work, we focus on the prevalence of False Positive (FP) alarms produced by security tools, and Security Operation Centers (SOCs) practitioners\u2019 perception of their quality . In an online survey we conducted with security practitioners ( n = 20) working in SOCs, practitioners con\ufb01rmed the high FP rates of the tools used, requiring manual validation. With these \ufb01ndings in mind, we conducted a broader, discovery-orientated, qualitative investigation with security practitioners ( n = 21) of the limitations of security tools, particularly their alarms\u2019 quality and validity. Our results highlight that, despite the perceived volume of FPs, most are attributed to benign triggers\u2014true alarms, explained by legitimate behavior in the organization\u2019s environment, which analysts may choose to ignore. To properly evaluate security tools\u2019 adequacy and performance, it is critical that vendors and researchers are able make such distinctions between types of FP. Alarm validation is a tedious task that can cause alarm burnout and eventually desensitization. Therefore, we investigated the process of alarm validation in SOCs, identifying factors that may in\ufb02uence the outcome of this process. To improve security alarm quality, we elicit \ufb01ve properties ( R eliable, E xplainable, A nalytical, C ontextual, T ransferable) required to foster effective and quick validation of alarms. Incorporating these requirements in future tools will not only reduce alarm burnout but improve SOC analysts\u2019 decision-making process by generating interpretable and meaningful alarms that enable prompt reaction.",
            "keywords": [
                "Security Operation Centers",
                "False Positives",
                "Alarm Validation",
                "Security Tool Limitations",
                "Analyst Decision-Making"
            ]
        },
        "url": "URL#1416835",
        "sema_paperId": "184783fb11908a6884afeef1d155314e3379dc98"
    },
    {
        "@score": "1",
        "@id": "1416836",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "207/2188",
                        "text": "Kinan Dak Albab"
                    },
                    {
                        "@pid": "211/5012",
                        "text": "Rawane Issa"
                    },
                    {
                        "@pid": "59/6288",
                        "text": "Mayank Varia"
                    },
                    {
                        "@pid": "61/5614",
                        "text": "Kalman Graffi"
                    }
                ]
            },
            "title": "Batched Differentially Private Information Retrieval.",
            "venue": "USENIX Security Symposium",
            "pages": "3327-3344",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AlbabIVG22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/albab",
            "url": "https://dblp.org/rec/conf/uss/AlbabIVG22",
            "abstract": "Private Information Retrieval (PIR) allows several clients to query a database held by one or more servers, such that the contents of their queries remain private. Prior PIR schemes have achieved sublinear communication and computation by leveraging computational assumptions, federating trust among many servers, relaxing security to permit differentially private leakage, refactoring effort into an offline stage to reduce online costs, or amortizing costs over a large batch of queries.In this work, we present an efficient PIR protocol that combines all of the above techniques to achieve constant amortized communication and computation complexity in the size of the database and constant client work. We leverage differentially private leakage in order to provide better trade-offs between privacy and efficiency. Our protocol achieves speed-ups up to and exceeding 10x in practical settings compared to state of the art PIR protocols, and can scale to batches with hundreds of millions of queries on cheap commodity AWS machines. Our protocol builds upon a new secret sharing scheme that is both incremental and non-malleable, which may be of interest to a wider audience. Our protocol provides security up to abort against malicious adversaries that can corrupt all but one party.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-albab.pdf",
            "keywords": [
                "Private Information Retrieval",
                "Differential Privacy",
                "Amortized Communication",
                "Secret Sharing",
                "Malicious Adversaries"
            ]
        },
        "url": "URL#1416836"
    },
    {
        "@score": "1",
        "@id": "1416837",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "150/9442",
                        "text": "Ange Albertini"
                    },
                    {
                        "@pid": "86/10074",
                        "text": "Thai Duong"
                    },
                    {
                        "@pid": "38/1135",
                        "text": "Shay Gueron"
                    },
                    {
                        "@pid": "72/4913",
                        "text": "Stefan K\u00f6lbl"
                    },
                    {
                        "@pid": "54/10551",
                        "text": "Atul Luykx"
                    },
                    {
                        "@pid": "279/6099",
                        "text": "Sophie Schmieg"
                    }
                ]
            },
            "title": "How to Abuse and Fix Authenticated Encryption Without Key Commitment.",
            "venue": "USENIX Security Symposium",
            "pages": "3291-3308",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AlbertiniDGKLS22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/albertini",
            "url": "https://dblp.org/rec/conf/uss/AlbertiniDGKLS22",
            "abstract": "Authenticated encryption (AE) is used in a wide variety of applications, potentially in settings for which it was not originally designed. Recent research tries to understand what happens when AE is not used as prescribed by its designers. A question given relatively little attention is whether an AE scheme guarantees \"key commitment\": ciphertext should only decrypt to a valid plaintext under the key used to generate the ciphertext. Generally, AE schemes do not guarantee key commitment as it is not part of AE's design goal. Nevertheless, one would not expect this seemingly obscure property to have much impact on the security of actual products. In reality, however, products do rely on key commitment. We discuss three recent applications where missing key commitment is exploitable in practice. We provide proof-of-concept attacks via a tool that constructs AES-GCM ciphertext which can be decrypted to two plaintexts valid under a wide variety of file formats, such as PDF, Windows executables, and DICOM. Finally we discuss two solutions to add key commitment to AE schemes which have not been analyzed in the literature: a generic approach that adds an explicit key commitment scheme to the AE scheme, and a simple fix which works for AE schemes like AES-GCM and ChaCha20Poly1305, but requires separate analysis for each scheme.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-albertini.pdf",
            "keywords": [
                "Authenticated Encryption",
                "Key Commitment",
                "Security Vulnerabilities",
                "AES-GCM",
                "Practical Exploits"
            ]
        },
        "url": "URL#1416837"
    },
    {
        "@score": "1",
        "@id": "1416838",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "92/7397",
                        "text": "Martin R. Albrecht"
                    },
                    {
                        "@pid": "331/2490",
                        "text": "Raphael Eikenberg"
                    },
                    {
                        "@pid": "39/780",
                        "text": "Kenneth G. Paterson"
                    }
                ]
            },
            "title": "Breaking Bridgefy, again: Adopting libsignal is not enough.",
            "venue": "USENIX Security Symposium",
            "pages": "269-286",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AlbrechtEP22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/albrecht",
            "url": "https://dblp.org/rec/conf/uss/AlbrechtEP22",
            "abstract": "Bridgefy is a messaging application that uses Bluetooth-based mesh networking. Its developers and others have advertised it for use in areas witnessing large-scale protests involving confrontations between protesters and state agents. In August 2020, a security analysis reported severe vulnerabilities that invalidated Bridgefy\u2019s claims of con\ufb01dentiality, authentication, and resilience. In response, the developers adopted the Signal protocol and then continued to advertise their application as being suitable for use by higher-risk users. In this work, we analyse the security of the revised Bridgefy messenger and SDK and invalidate its security claims. One attack (targeting the messenger) enables an adversary to com-promise the con\ufb01dentiality of private messages by exploiting a time-of-check to time-of-use (TOCTOU) issue, side-stepping Signal\u2019s guarantees. The other attack (targeting the SDK) allows an adversary to recover broadcast messages without knowing the network-wide shared encryption key. We also found that the changes deployed in response to the August 2020 analysis failed to remedy the previously reported vulnerabilities. In particular, we show that (i) the protocol persisted to be susceptible to an active attacker-in-the-middle, (ii) an adversary continued to be able to impersonate other users in the broadcast channel of the Bridgefy messenger, (iii) the DoS attack using a decompression bomb was still applicable, albeit in a limited form, and that (iv) the privacy issues of Bridgefy remained largely unresolved.",
            "keywords": [
                "Messaging Security",
                "Bluetooth Mesh Networking",
                "Signal Protocol",
                "Vulnerability Analysis",
                "Confidentiality Issues"
            ]
        },
        "url": "URL#1416838",
        "sema_paperId": "f25933a542667d49b242ffaaa0417db0da7f9df0"
    },
    {
        "@score": "1",
        "@id": "1416839",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "180/3056",
                        "text": "Alejandro Cabrera Aldaya"
                    },
                    {
                        "@pid": "25/1876",
                        "text": "Billy Bob Brumley"
                    }
                ]
            },
            "title": "HyperDegrade: From GHz to MHz Effective CPU Frequencies.",
            "venue": "USENIX Security Symposium",
            "pages": "2801-2818",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AldayaB22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/aldaya",
            "url": "https://dblp.org/rec/conf/uss/AldayaB22",
            "abstract": "Performance degradation techniques are an important complement to side-channel attacks. In this work, we propose HYPERDEGRADE\u2014a combination of previous approaches and the use of simultaneous multithreading (SMT) architectures. In addition to the new technique, we investigate the root causes of performance degradation using cache eviction, discovering a previously unknown slowdown origin. The slowdown produced is significantly higher than previous approaches, which translates into an increased time granularity for FLUSH+RELOAD attacks. We evaluate HYPERDEGRADE on different Intel microarchitectures, yielding significant slowdowns that achieve, in select microbenchmark cases, three orders of magnitude improvement over state-of-the-art. To evaluate the efficacy of performance degradation in side-channel amplification, we propose and evaluate leakage assessment metrics. The results evidence that HYPERDEGRADE increases time granularity without a meaningful impact on trace quality. Additionally, we designed a fair experiment that compares three performance degradation strategies when coupled with FLUSH+RELOAD from an attacker perspective. We developed an attack on an unexploited vulnerability in OpenSSL in which HYPERDEGRADE excels\u2014reducing by three times the number of required FLUSH+RELOAD traces to succeed. Regarding cryptography contributions, we revisit the recently proposed Raccoon attack on TLS-DH key exchanges, demonstrating its application to other protocols. Using HYPERDEGRADE, we developed an end-to-end attack that shows how a Raccoon-like attack can succeed with real data, filling a missing gap from previous research.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-aldaya.pdf",
            "keywords": [
                "Performance Degradation",
                "Side-Channel Attacks",
                "Simultaneous Multithreading (SMT)",
                "FLUSH+RELOAD",
                "Raccoon Attack"
            ]
        },
        "url": "URL#1416839"
    },
    {
        "@score": "1",
        "@id": "1416840",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "200/5775",
                        "text": "Nikolaos Alexopoulos"
                    },
                    {
                        "@pid": "326/8265",
                        "text": "Manuel Brack"
                    },
                    {
                        "@pid": "331/2622",
                        "text": "Jan Philipp Wagner"
                    },
                    {
                        "@pid": "150/8806",
                        "text": "Tim Grube"
                    },
                    {
                        "@pid": "m/MaxMuhlhauser",
                        "text": "Max M\u00fchlh\u00e4user"
                    }
                ]
            },
            "title": "How Long Do Vulnerabilities Live in the Code? A Large-Scale Empirical Measurement Study on FOSS Vulnerability Lifetimes.",
            "venue": "USENIX Security Symposium",
            "pages": "359-376",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AlexopoulosBWGM22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/alexopoulos",
            "url": "https://dblp.org/rec/conf/uss/AlexopoulosBWGM22",
            "abstract": "How long do vulnerabilities live in the repositories of large, evolving projects? Although the question has been identified as an interesting problem by the software community in online forums, it has not been investigated yet in adequate depth and scale, since the process of identifying the exact point in time when a vulnerability was introduced is particularly cum-bersome. In this paper, we provide an automatic approach for accurately estimating how long vulnerabilities remain in the code (their lifetimes ). Our method relies on the observation that while it is difficult to pinpoint the exact point of introduction for one vulnerability, it is possible to accurately estimate the average lifetime of a large enough sample of vulnerabilities, via a heuristic approach. With our approach, we perform the first large-scale measurement of Free and Open Source Software vulnerability lifetimes, going beyond approaches estimating lower bounds prevalent in previous research. We find that the average lifetime of a vulnerability is around 4 years, varying significantly between projects (~2 years for Chromium, ~7 years for OpenSSL). The distribution of lifetimes can be approximately described by an exponential distribution. There are no statistically significant differences between the lifetimes of different vulnerability types when considering specific projects. Vulnerabilities are getting older, as the average lifetime of fixed vulnerabilities in a given year increases over time, influenced by the overall increase of code age. However, they live less than non-vulnerable code, with an increasing spread over time for some projects, suggesting a notion of maturity that can be considered an indicator of quality. While the introduction of fuzzers does not significantly reduce the lifetimes of memory-related vulnerabilities, further research is needed to better understand and quantify the impact of fuzzers and other tools on vulnerability lifetimes and on the security of codebases.",
            "keywords": [
                "FOSS Vulnerability Lifetimes",
                "Vulnerability Analysis",
                "Code Evolution",
                "Vulnerability Introduction",
                "Fuzzer Impact on Vulnerabilities"
            ]
        },
        "url": "URL#1416840",
        "sema_paperId": "25276f0f8a04c8ca127a41e0766dc206195d28cb"
    },
    {
        "@score": "1",
        "@id": "1416841",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "227/8129",
                        "text": "Esmerald Aliaj"
                    },
                    {
                        "@pid": "173/5375",
                        "text": "Ivan De Oliveira Nunes"
                    },
                    {
                        "@pid": "08/1183",
                        "text": "Gene Tsudik"
                    }
                ]
            },
            "title": "GAROTA: Generalized Active Root-Of-Trust Architecture (for Tiny Embedded Devices).",
            "venue": "USENIX Security Symposium",
            "pages": "2243-2260",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AliajNT22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/aliaj",
            "url": "https://dblp.org/rec/conf/uss/AliajNT22",
            "abstract": "In this paper, we set out to systematically design a minimal active RoT for tiny low-end MCU-s. We begin with the following questions: (1) What functions and hardware support are required to guarantee actions in the presence of malware?, (2) How to implement this efficiently?, and (3) What security benefits stem from such an active RoT architecture? We then design, implement, formally verify, and evaluate GAROTA: Generalized Active Root-Of-Trust Architecture. We believe that GAROTA is the first clean-slate design of an active RoT for low-end MCU-s. We show how GAROTA guarantees that even a fully software-compromised low-end MCU performs a desired action. We demonstrate its practicality by implementing GAROTA in the context of three types of applications where actions are triggered by: sensing hardware, network events and timers. We also formally specify and verify GAROTA functionality and properties.",
            "keywords": [
                "Active Root-Of-Trust",
                "Low-End Microcontrollers",
                "Malware Resistance",
                "Formal Verification",
                "Embedded Security Architecture"
            ]
        },
        "url": "URL#1416841",
        "sema_paperId": "efe019f699a0c5f0c6e260d519606ac4a8b7a31e"
    },
    {
        "@score": "1",
        "@id": "1416842",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "132/8480",
                        "text": "Sebastian Angel"
                    },
                    {
                        "@pid": "93/1054",
                        "text": "Andrew J. Blumberg"
                    },
                    {
                        "@pid": "241/6379",
                        "text": "Eleftherios Ioannidis"
                    },
                    {
                        "@pid": "298/6428",
                        "text": "Jess Woods"
                    }
                ]
            },
            "title": "Efficient Representation of Numerical Optimization Problems for SNARKs.",
            "venue": "USENIX Security Symposium",
            "pages": "4273-4290",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AngelBIW22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/angel",
            "url": "https://dblp.org/rec/conf/uss/AngelBIW22",
            "abstract": "This paper introduces Otti, a general-purpose compiler for (zk)SNARKs that provides support for numerical optimization problems. Otti produces efficient arithmetizations of programs that contain optimization problems including linear programming (LP), semi-definite programming (SDP), and a broad class of stochastic gradient descent (SGD) instances. Numerical optimization is a fundamental algorithmic building block: applications include scheduling and resource allocation tasks, approximations to NP-hard problems, and training of neural networks. Otti takes as input arbitrary programs written in a subset of C that contain optimization problems specified via an easy-to-use API. Otti then automatically produces rank-1 constraint satisfiability (R1CS) instances that express a succinct transformation of those programs. Correct execution of the transformed program implies the optimality of the solution to the original optimization problem. Our evaluation on real benchmarks shows that Otti, instantiated with the Spartan proof system, can prove the optimality of solutions in zero-knowledge in as little as 100 ms\u2014over 4 orders of magnitude faster than existing approaches.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-angel.pdf",
            "keywords": [
                "Numerical Optimization",
                "Zero-Knowledge Proofs",
                "SNARKs",
                "Rank-1 Constraint Satisfiability (R1CS)",
                "Otti Compiler"
            ]
        },
        "url": "URL#1416842"
    },
    {
        "@score": "1",
        "@id": "1416844",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "119/8218",
                        "text": "Daniel Arp"
                    },
                    {
                        "@pid": "149/3695",
                        "text": "Erwin Quiring"
                    },
                    {
                        "@pid": "223/5655",
                        "text": "Feargus Pendlebury"
                    },
                    {
                        "@pid": "205/4365",
                        "text": "Alexander Warnecke"
                    },
                    {
                        "@pid": "149/1452",
                        "text": "Fabio Pierazzi"
                    },
                    {
                        "@pid": "136/8406",
                        "text": "Christian Wressnegger"
                    },
                    {
                        "@pid": "95/5162",
                        "text": "Lorenzo Cavallaro"
                    },
                    {
                        "@pid": "64/4020",
                        "text": "Konrad Rieck"
                    }
                ]
            },
            "title": "Dos and Don&apos;ts of Machine Learning in Computer Security.",
            "venue": "USENIX Security Symposium",
            "pages": "3971-3988",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ArpQPWPWCR22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/arp",
            "url": "https://dblp.org/rec/conf/uss/ArpQPWPWCR22",
            "abstract": "With the growing processing power of computing systems and the increasing availability of massive datasets, machine learning algorithms have led to major breakthroughs in many different areas. This development has influenced computer security, spawning a series of work on learning-based security systems, such as for malware detection, vulnerability discovery, and binary code analysis. Despite great potential, machine learning in security is prone to subtle pitfalls that undermine its performance and render learning-based systems potentially unsuitable for security tasks and practical deployment.In this paper, we look at this problem with critical eyes. First, we identify common pitfalls in the design, implementation, and evaluation of learning-based security systems. We conduct a study of 30 papers from top-tier security conferences within the past 10 years, confirming that these pitfalls are widespread in the current security literature. In an empirical analysis, we further demonstrate how individual pitfalls can lead to unrealistic performance and interpretations, obstructing the understanding of the security problem at hand. As a remedy, we propose actionable recommendations to support researchers in avoiding or mitigating the pitfalls where possible. Furthermore, we identify open problems when applying machine learning in security and provide directions for further research.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-arp.pdf",
            "keywords": [
                "Learning-based Security Systems",
                "Malware Detection",
                "Vulnerability Discovery",
                "Performance Pitfalls",
                "Empirical Analysis"
            ]
        },
        "url": "URL#1416844"
    },
    {
        "@score": "1",
        "@id": "1416845",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "318/0975",
                        "text": "Jinsheng Ba"
                    },
                    {
                        "@pid": "91/7541",
                        "text": "Marcel B\u00f6hme"
                    },
                    {
                        "@pid": "182/1403",
                        "text": "Zahra Mirzamomen"
                    },
                    {
                        "@pid": "04/5884",
                        "text": "Abhik Roychoudhury"
                    }
                ]
            },
            "title": "Stateful Greybox Fuzzing.",
            "venue": "USENIX Security Symposium",
            "pages": "3255-3272",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BaBMR22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/ba",
            "url": "https://dblp.org/rec/conf/uss/BaBMR22",
            "abstract": "Many protocol implementations are reactive systems, where the protocol process is in continuous interaction with other processes and the environment. If a bug can be exposed only in a certain state, a fuzzer needs to provide a specific sequence of events as inputs that would take protocol into this state before the bug is manifested. We call these bugs as\"stateful\"bugs. Usually, when we are testing a protocol implementation, we do not have a detailed formal specification of the protocol to rely upon. Without knowledge of the protocol, it is inherently difficult for a fuzzer to discover such stateful bugs. A key challenge then is to cover the state space without an explicit specification of the protocol. In this work, we posit that manual annotations for state identification can be avoided for stateful protocol fuzzing. Specifically, we rely on a programmatic intuition that the state variables used in protocol implementations often appear in enum type variables whose values (the state names) come from named constants. In our analysis of the Top-50 most widely used open-source protocol implementations, we found that every implementation uses state variables that are assigned named constants (with easy to comprehend names such as INIT, READY) to represent the current state. In this work, we propose to automatically identify such state variables and track the sequence of values assigned to them during fuzzing to produce a\"map\"of the explored state space. Our experiments confirm that our stateful fuzzer discovers stateful bugs twice as fast as the baseline greybox fuzzer that we extended. Starting from the initial state, our fuzzer exercises one order of magnitude more state/transition sequences and covers code two times faster than the baseline fuzzer. Several zero-day bugs in prominent protocol implementations were found by our fuzzer, and 8 CVEs have been assigned.",
            "keywords": [
                "Stateful Fuzzing",
                "Protocol Testing",
                "State Variables",
                "Bug Discovery",
                "Greybox Fuzzing"
            ]
        },
        "url": "URL#1416845",
        "sema_paperId": "cf1b8907a854327babca7dfedcbade959ed5ec05"
    },
    {
        "@score": "1",
        "@id": "1416846",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "83/7954",
                        "text": "Sangwook Bae"
                    },
                    {
                        "@pid": "236/4147",
                        "text": "Mincheol Son"
                    },
                    {
                        "@pid": "62/10307-1",
                        "text": "Dongkwan Kim 0001"
                    },
                    {
                        "@pid": "283/0238",
                        "text": "CheolJun Park"
                    },
                    {
                        "@pid": "137/1560",
                        "text": "Jiho Lee"
                    },
                    {
                        "@pid": "09/3668",
                        "text": "Sooel Son"
                    },
                    {
                        "@pid": "20/6892",
                        "text": "Yongdae Kim"
                    }
                ]
            },
            "title": "Watching the Watchers: Practical Video Identification Attack in LTE Networks.",
            "venue": "USENIX Security Symposium",
            "pages": "1307-1324",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BaeSKPLSK22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/bae",
            "url": "https://dblp.org/rec/conf/uss/BaeSKPLSK22",
            "abstract": "A video identi\ufb01cation attack is a tangible privacy threat that can reveal videos that victims are watching. In this paper, we present the \ufb01rst study of a video identi\ufb01cation attack in Long Term Evolution (LTE) networks. We discovered that, by leveraging broadcast radio signals, an unprivileged adversary equipped with a software-de\ufb01ned radio can 1) identify mobile users who are watching target videos of the adversary\u2019s interest and then 2) infer the video title that each of these users is watching. Using 46,810 LTE traces of three video streaming services from three cellular operators, we demonstrate that our attack achieves an accuracy of up to 0.985. We empha-size that this high level of accuracy stems from overcoming the unique challenges related to the operational logic of LTE networks and video streaming systems. Finally, we present an end-to-end attack scenario leveraging the presented video identi\ufb01cation attack and propose countermeasures that are readily applicable to current LTE networks.",
            "keywords": [
                "LTE Networks",
                "Video Identification Attack",
                "Privacy Threats",
                "Video Streaming Services",
                "Software-Defined Radio"
            ]
        },
        "url": "URL#1416846",
        "sema_paperId": "54b86b551a84bcd5dd6817157414177f90c62a6a"
    },
    {
        "@score": "1",
        "@id": "1416847",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "294/0161",
                        "text": "David G. Balash"
                    },
                    {
                        "@pid": "01/3193",
                        "text": "Xiaoyuan Wu"
                    },
                    {
                        "@pid": "301/5815",
                        "text": "Miles Grant"
                    },
                    {
                        "@pid": "203/1639",
                        "text": "Irwin Reyes"
                    },
                    {
                        "@pid": "94/1554",
                        "text": "Adam J. Aviv"
                    }
                ]
            },
            "title": "Security and Privacy Perceptions of Third-Party Application Access for Google Accounts.",
            "venue": "USENIX Security Symposium",
            "pages": "3397-3414",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BalashWGRA22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/balash",
            "url": "https://dblp.org/rec/conf/uss/BalashWGRA22",
            "abstract": "In our paper we explore how users consider security and privacy in light of third-party API access to their Google accounts given the disclosure and control mechanisms currently available. First, we surveyed n = 432 participants to recall the last times they used Google SSO or authorized a third-party app access to their Google account data. We then invited n = 214 participants from the first survey to return for a follow-up survey. As part of this second survey, participants installed a browser extension that parsed entries in their Google account\u2019s \"Apps with access to your account\" dash-board. In our archive we make available functional artifacts that can be used to reproduce our qualitative and quantitative study results. The artifact includes the custom survey and browser extension software we developed for this study along with detailed instructions on how to deploy this software. A single PC, Mac, or Linux machine should be sufficient hardware. Software requirements include Docker, RStudio, and a Chrome or Firefox web browser. The artifact can be evaluated by running the survey software in a docker container, loading the browser extension in a web browser, running the R-programming files, and evaluating the qualitative coding results.",
            "keywords": [
                "Third-Party Application Access",
                "Google Account Security",
                "User Privacy Perceptions",
                "API Authorization",
                "Survey-Based Study"
            ]
        },
        "url": "URL#1416847",
        "sema_paperId": "6afb314666b85dd56c5838bfcac3e5a2d11efe3d"
    },
    {
        "@score": "1",
        "@id": "1416849",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "247/4778",
                        "text": "Enrico Barberis"
                    },
                    {
                        "@pid": "224/2335",
                        "text": "Pietro Frigo"
                    },
                    {
                        "@pid": "185/2352",
                        "text": "Marius Muench"
                    },
                    {
                        "@pid": "91/800",
                        "text": "Herbert Bos"
                    },
                    {
                        "@pid": "75/8194",
                        "text": "Cristiano Giuffrida"
                    }
                ]
            },
            "title": "Branch History Injection: On the Effectiveness of Hardware Mitigations Against Cross-Privilege Spectre-v2 Attacks.",
            "venue": "USENIX Security Symposium",
            "pages": "971-988",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BarberisFMBG22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/barberis",
            "url": "https://dblp.org/rec/conf/uss/BarberisFMBG22",
            "abstract": "Branch Target Injection (BTI or Spectre v2) is one of the most dangerous transient execution vulnerabilities, as it allows an attacker to abuse indirect branch mispredictions to leak sensitive information. Unfortunately, it also has proven difficult to mitigate, with vendors originally resorting to inefficient software mitigations like retpoline. Recently, efficient hardware mitigations such as Intel eIBRS and Arm CSV2 have been deployed as a replacement in production, isolating the branch target state across privilege domains. The assumption is that this is sufficient to deter practical BTI exploitation. In this paper, we challenge this belief and disclose fundamental design flaws in both Intel and Arm solutions. We introduce Branch History Injection (BHI or Spectre-BHB), a new primitive to build cross-privilege BTI attacks on systems deploying isolation-based hardware defenses. BHI builds on the observation that, while the branch target state is now isolated across privilege domains, such isolation is not extended to other branch predictor elements tracking the branch history state\u2014ultimately re-enabling cross-privilege attacks. We further analyze the guarantees of a hypothetical isolation-based mitigation which also isolates the branch history and show that, barring a collision-free design, practical same-predictor-mode attacks are still possible. To instantiate our approach, we present end-to-end exploits leaking kernel memory from userland on Intel systems at 160 bytes/s, in spite of existing or hypothetical isolation-based mitigations. We conclude software defenses such as retpoline remain the only practical BTI mitigations in the foreseeable future and the pursuit for efficient hardware mitigations must continue.",
            "keywords": [
                "Transient Execution Vulnerabilities",
                "Branch Target Injection",
                "Cross-Privilege Attacks",
                "Hardware Mitigations",
                "Branch History Injection"
            ]
        },
        "url": "URL#1416849",
        "sema_paperId": "24dcf00311771edb3cc1f15bdfdc70ac23b0600c"
    },
    {
        "@score": "1",
        "@id": "1416850",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "b/DanielJBernstein",
                        "text": "Daniel J. Bernstein"
                    },
                    {
                        "@pid": "25/1876",
                        "text": "Billy Bob Brumley"
                    },
                    {
                        "@pid": "00/7017",
                        "text": "Ming-Shing Chen"
                    },
                    {
                        "@pid": "54/10083",
                        "text": "Nicola Tuveri"
                    }
                ]
            },
            "title": "OpenSSLNTRU: Faster post-quantum TLS key exchange.",
            "venue": "USENIX Security Symposium",
            "pages": "845-862",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BernsteinBCT22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/bernstein",
            "url": "https://dblp.org/rec/conf/uss/BernsteinBCT22",
            "abstract": "Google's CECPQ1 experiment in 2016 integrated a post-quantum key-exchange algorithm, newhope1024, into TLS 1.2. The Google-Cloudflare CECPQ2 experiment in 2019 integrated a more efficient key-exchange algorithm, ntruhrss701, into TLS 1.3.This paper revisits the choices made in CECPQ2, and shows how to achieve higher performance for post-quantum key exchange in TLS 1.3 using a higher-security algorithm, sntrup761. Previous work had indicated that ntruhrss701 key generation was much faster than sntrup761 key generation, but this paper makes sntrup761 key generation much faster by generating a batch of keys at once.Batch key generation is invisible at the TLS protocol layer, but raises software-engineering questions regarding the difficulty of integrating batch key exchange into existing TLS libraries and applications. This paper shows that careful choices of software layers make it easy to integrate fast post-quantum software, including batch key exchange, into TLS with minor changes to TLS libraries and no changes to applications.As a demonstration of feasibility, this paper reports successful integration of its fast sntrup761 library, via a lightly patched OpenSSL, into an unmodified web browser and an unmodified TLS terminator. This paper also reports TLS 1.3 handshake benchmarks, achieving more TLS 1.3 handshakes per second than any software included in OpenSSL.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-bernstein.pdf",
            "keywords": [
                "Post-Quantum Cryptography",
                "TLS Key Exchange",
                "sntrup761",
                "Batch Key Generation",
                "Performance Optimization"
            ]
        },
        "url": "URL#1416850"
    },
    {
        "@score": "1",
        "@id": "1416851",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "331/2323",
                        "text": "Abhishek Bhaskar"
                    },
                    {
                        "@pid": "61/1749",
                        "text": "Paul Pearce"
                    }
                ]
            },
            "title": "Many Roads Lead To Rome: How Packet Headers Influence DNS Censorship Measurement.",
            "venue": "USENIX Security Symposium",
            "pages": "449-464",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BhaskarP22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/bhaskar",
            "url": "https://dblp.org/rec/conf/uss/BhaskarP22",
            "abstract": "Internet censorship is widespread, impacting citizens of hundreds of countries around the world. Recent work has devel-oped techniques that can perform widespread, longitudinal measurements of global Internet manipulation remotely and have focused largely on the scale of censorship measurements with minimal focus on reproducibility and consistency. In this work we explore the role packet headers (e.g., source IP address and source port) have on DNS censorship. By performing a large-scale measurement study building on the techniques deployed by previous and current censorship measurement platforms, we \ufb01nd that choice of ephemeral source port and local source IP address (e.g., x.x.x.7 vs x.x.x.8) in\ufb02uence routing, which in turn in\ufb02uences DNS censorship. We show that 37% of IPs across 56% ASes measured show some change in censorship behavior depending on source port and local source IP. This behavior is frequently all-or-nothing , where choice of header can result in no observable censorship. Such behavior mimics and could be misattributed to geolocation error, packet loss, or network outages. The scale of censorship differences can more than double depending on the lowest 3 bits of the source IP address, consistent with known router load balancing techniques. We also observe smaller-scale censorship variation where only a few domains experience censorship differences based on packet parameters. We lastly \ufb01nd that these variations are persistent; packet retries do not control for observed variation. Our results point to the need for methodological changes in future DNS censorship measurement, which we discuss.",
            "keywords": [
                "DNS Censorship",
                "Internet Manipulation",
                "Packet Headers",
                "Censorship Measurement",
                "Routing Influence"
            ]
        },
        "url": "URL#1416851",
        "sema_paperId": "d4ddda209dbfba3636a5b9c0b78e54f3ab985ee4"
    },
    {
        "@score": "1",
        "@id": "1416852",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "237/9617",
                        "text": "Atri Bhattacharyya"
                    },
                    {
                        "@pid": "331/2576",
                        "text": "Uros Tesic"
                    },
                    {
                        "@pid": "31/1273",
                        "text": "Mathias Payer"
                    }
                ]
            },
            "title": "Midas: Systematic Kernel TOCTTOU Protection.",
            "venue": "USENIX Security Symposium",
            "pages": "107-124",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BhattacharyyaTP22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/bhattacharyya",
            "url": "https://dblp.org/rec/conf/uss/BhattacharyyaTP22",
            "abstract": "Double-fetch bugs are a plague across all major operating sys-tem kernels. They occur when data is fetched twice across the user/kernel trust boundary while allowing concurrent mod-i\ufb01cation. Such bugs enable an attacker to illegally access memory, cause denial of service, or to escalate privileges. So far, the only protection against double-fetch bugs is to detect and \ufb01x them. However, they remain incredibly hard to \ufb01nd. Similarly, they fundamentally prohibit ef\ufb01cient, kernel-based stateful system call \ufb01ltering. Thus, we propose Midas to mitigate double-fetch bugs. Midas creates on-demand snapshots and copies of accessed data, enforcing our key invariant that throughout a system call\u2019s lifetime, every read to a userspace object will return the same value. Midas shows no noticeable drop in performance when evaluated on compute-bound workloads. On system call heavy workloads, Midas incurs 0.2\u201314% performance overhead, while protecting the kernel against any TOCTTOU attacks. On average, Midas shows a 3 . 4% overhead on diverse work-loads across two benchmark suites.",
            "keywords": [
                "Kernel Security",
                "Double-Fetch Bugs",
                "TOCTTOU Attacks",
                "System Call Protection",
                "Data Consistency"
            ]
        },
        "url": "URL#1416852",
        "sema_paperId": "8d358e9ac87a30db00bac66b3569b6d3de77c43e"
    },
    {
        "@score": "1",
        "@id": "1416853",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "331/2792",
                        "text": "Veroniek Binkhorst"
                    },
                    {
                        "@pid": "150/5174",
                        "text": "Tobias Fiebig"
                    },
                    {
                        "@pid": "128/4803",
                        "text": "Katharina Krombholz"
                    },
                    {
                        "@pid": "24/3988",
                        "text": "Wolter Pieters"
                    },
                    {
                        "@pid": "139/6939",
                        "text": "Katsiaryna Labunets"
                    }
                ]
            },
            "title": "Security at the End of the Tunnel: The Anatomy of VPN Mental Models Among Experts and Non-Experts in a Corporate Context.",
            "venue": "USENIX Security Symposium",
            "pages": "3433-3450",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BinkhorstFKPL22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/binkhorst",
            "url": "https://dblp.org/rec/conf/uss/BinkhorstFKPL22",
            "abstract": "With the worldwide COVID-19 pandemic in 2020 and 2021 necessitating working from home, corporate Virtual Private Networks (VPNs) have become an important item securing the continued operation of companies around the globe. However, due to their different use case, corporate VPNs and how users interact with them differ from public VPNs, which are now commonly used by end-users. In this paper, we present a first explorative study of eleven experts' and seven non-experts' mental models in the context of corporate VPNs. We find a partial alignment of these models in the high-level technical understanding while diverging in important parameters of how, when, and why VPNs are being used. While, in general, experts have a deeper technical understanding of VPN technology, we also observe that even they sometimes hold false beliefs on security aspects of VPNs. In summary, we show that the mental models of corporate VPNs differ from those for related security technology, e.g., HTTPS. Our findings allow us to draft recommendations for practitioners to encourage a secure use of VPN technology (through training interventions, better communication, and system design changes in terms of device management). Furthermore, we identify avenues for future research, e.g., into experts' knowledge and balancing privacy and security between system operators and users.",
            "keywords": [
                "Corporate VPNs",
                "Mental Models",
                "User Interaction",
                "Security Misconceptions",
                "Training Interventions"
            ]
        },
        "url": "URL#1416853",
        "sema_paperId": "e1689eaa6b5b6b530356138a44e35a5ea4c44124"
    },
    {
        "@score": "1",
        "@id": "1416854",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "224/9340",
                        "text": "Henry Birge-Lee"
                    },
                    {
                        "@pid": "274/7250",
                        "text": "Joel Wanner"
                    },
                    {
                        "@pid": "282/8466",
                        "text": "Grace H. Cimaszewski"
                    },
                    {
                        "@pid": "46/4109",
                        "text": "Jonghoon Kwon"
                    },
                    {
                        "@pid": "56/4499-54",
                        "text": "Liang Wang 0054"
                    },
                    {
                        "@pid": "279/2370",
                        "text": "Fran\u00e7ois Wirz"
                    },
                    {
                        "@pid": "39/6266",
                        "text": "Prateek Mittal"
                    },
                    {
                        "@pid": "16/6873",
                        "text": "Adrian Perrig"
                    },
                    {
                        "@pid": "139/9789",
                        "text": "Yixin Sun"
                    }
                ]
            },
            "title": "Creating a Secure Underlay for the Internet.",
            "venue": "USENIX Security Symposium",
            "pages": "2601-2618",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Birge-LeeWCK0WM22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/birge-lee",
            "url": "https://dblp.org/rec/conf/uss/Birge-LeeWCK0WM22",
            "abstract": "Adversaries can exploit inter-domain routing vulnerabilities to intercept communication and compromise the security of critical Internet applications. Meanwhile the deployment of secure routing solutions such as Border Gateway Protocol Security (BGPsec) and Scalability, Control and Isolation On Next-generation networks (SCION) are still limited. How can we leverage emerging secure routing backbones and extend their security properties to the broader Internet? We design and deploy an architecture to bootstrap secure routing. Our key insight is to abstract the secure routing backbone as a virtual Autonomous System (AS), called Secure Backbone AS (SBAS). While SBAS appears as one AS to the Internet, it is a federated network where routes are exchanged between participants using a secure backbone. SBAS makes BGP announcements for its customers' IP prefixes at multiple locations (referred to as Points of Presence or PoPs) allowing traffic from non-participating hosts to be routed to a nearby SBAS PoP (where it is then routed over the secure backbone to the true prefix owner). In this manner, we are the first to integrate a federated secure non-BGP routing backbone with the BGP-speaking Internet. We present a real-world deployment of our architecture that uses SCIONLab to emulate the secure backbone and the PEERING framework to make BGP announcements to the Internet. A combination of real-world attacks and Internet-scale simulations shows that SBAS substantially reduces the threat of routing attacks. Finally, we survey network operators to better understand optimal governance and incentive models.",
            "keywords": [
                "Secure Routing",
                "Inter-domain Routing",
                "BGPsec",
                "SCION",
                "Routing Attacks"
            ]
        },
        "url": "URL#1416854",
        "sema_paperId": "a78a9d6b91a815ca8b00ce72786bb2d0fa15e452"
    },
    {
        "@score": "1",
        "@id": "1416855",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "183/1275",
                        "text": "Logan Blue"
                    },
                    {
                        "@pid": "250/9724",
                        "text": "Kevin Warren"
                    },
                    {
                        "@pid": "205/2013",
                        "text": "Hadi Abdullah"
                    },
                    {
                        "@pid": "304/8162",
                        "text": "Cassidy Gibson"
                    },
                    {
                        "@pid": "68/5101",
                        "text": "Luis Vargas"
                    },
                    {
                        "@pid": "331/2213",
                        "text": "Jessica O&apos;Dell"
                    },
                    {
                        "@pid": "82/1935",
                        "text": "Kevin R. B. Butler"
                    },
                    {
                        "@pid": "14/3295",
                        "text": "Patrick Traynor"
                    }
                ]
            },
            "title": "Who Are You (I Really Wanna Know)? Detecting Audio DeepFakes Through Vocal Tract Reconstruction.",
            "venue": "USENIX Security Symposium",
            "pages": "2691-2708",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BlueWAGVOBT22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/blue",
            "url": "https://dblp.org/rec/conf/uss/BlueWAGVOBT22",
            "abstract": "Generative machine learning models have made convincing voice synthesis a reality. While such tools can be extremely useful in applications where people consent to their voices being cloned (e.g., patients losing the ability to speak, ac-tors not wanting to have to redo dialog, etc), they also allow for the creation of nonconsensual content known as deepfakes. This malicious audio is problematic not only because it can convincingly be used to impersonate arbitrary users, but because detecting deepfakes is challenging and generally requires knowledge of the speci\ufb01c deepfake generator. In this paper, we develop a new mechanism for detecting audio deepfakes using techniques from the \ufb01eld of articulatory phonetics. Speci\ufb01cally, we apply \ufb02uid dynamics to estimate the arrangement of the human vocal tract during speech generation and show that deepfakes often model impossible or highly-unlikely anatomical arrangements. When parameterized to achieve 99.9% precision, our detection mechanism achieves a recall of 99.5%, correctly identifying all but one deepfake sample in our dataset. We then discuss the limitations of this approach, and how deepfake models fail to reproduce all aspects of speech equally. In so doing, we demonstrate that subtle, but biologically constrained aspects of how humans generate speech are not captured by current models, and can therefore act as a powerful tool to detect audio deepfakes.",
            "keywords": [
                "Audio Deepfakes",
                "Vocal Tract Reconstruction",
                "Articulatory Phonetics",
                "Voice Synthesis Detection",
                "Nonconsensual Content"
            ]
        },
        "url": "URL#1416855",
        "sema_paperId": "7f1ca5f97c6b12f9d06e0e2f3150c366be0ffa4e"
    },
    {
        "@score": "1",
        "@id": "1416856",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "331/2515",
                        "text": "Marina Sanusi Bohuk"
                    },
                    {
                        "@pid": "208/1920-2",
                        "text": "Mazharul Islam 0002"
                    },
                    {
                        "@pid": "260/8995",
                        "text": "Suleman Ahmad"
                    },
                    {
                        "@pid": "s/MichaelMSwift",
                        "text": "Michael M. Swift"
                    },
                    {
                        "@pid": "26/3399",
                        "text": "Thomas Ristenpart"
                    },
                    {
                        "@pid": "03/9962",
                        "text": "Rahul Chatterjee 0001"
                    }
                ]
            },
            "title": "Gossamer: Securely Measuring Password-based Logins.",
            "venue": "USENIX Security Symposium",
            "pages": "1867-1884",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BohukIASR022",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/sanusi-bohuk",
            "url": "https://dblp.org/rec/conf/uss/BohukIASR022",
            "abstract": "Passwords remain the primary way to authenticate users on-line. Yet little is known about the characteristics of login requests submitted to login systems due to the sensitivity of monitoring submitted passwords. This means we don\u2019t have answers to basic questions, such as how often users submit a password similar to their actual password, whether users often resubmit the same incorrect password, how many users utilize passwords known to be in a public breach, and more. Whether we can build and deploy measurement infrastructure to safely answer such questions is, itself, an open question. We offer a system, called Gossamer , that enables securely logging information about login attempts, including carefully chosen statistics about submitted passwords. We provide a simulation-based approach for tuning the security-utility trade-offs for storing different password-derived statistics. This enables us to gather useful measurements while reducing risk even in the unlikely case of complete compromise of the measurement system. We worked closely with two large universities and deployed Gossamer to perform a measurement study that observed 34 million login requests over a seven month period. The measurements we gather provide insight into the use of breached credentials, password usability, and other characteristics of the submitted login requests.",
            "keywords": [
                "Password Authentication",
                "Login Request Measurement",
                "Breached Credentials",
                "Password Usability",
                "Secure Logging"
            ]
        },
        "url": "URL#1416856",
        "sema_paperId": "4e7fe9a29a110a6efc753c04be1f6c5a332cb869"
    },
    {
        "@score": "1",
        "@id": "1416857",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "331/2038",
                        "text": "Dino Bollinger"
                    },
                    {
                        "@pid": "233/8369-1",
                        "text": "Karel Kubicek 0001"
                    },
                    {
                        "@pid": "150/0652",
                        "text": "Carlos Cotrini"
                    },
                    {
                        "@pid": "b/DavidABasin",
                        "text": "David A. Basin"
                    }
                ]
            },
            "title": "Automating Cookie Consent and GDPR Violation Detection.",
            "venue": "USENIX Security Symposium",
            "pages": "2893-2910",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BollingerKCB22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/bollinger",
            "url": "https://dblp.org/rec/conf/uss/BollingerKCB22",
            "abstract": "The European Union\u2019s General Data Protection Regulation ( GDPR ) requires websites to inform users about personal data collection and request consent for cookies. Yet the majority of websites do not give users any choices, and others attempt to deceive them into accepting all cookies. We document the severity of this situation through an analysis of potential GDPR violations in cookie banners in almost 30k websites. We identify six novel violation types, such as incorrect category assignments and misleading expiration times, and we \ufb01nd at least one potential violation in a surprising 94.7% of the analyzed websites. We address this issue by giving users the power to protect their privacy. We develop a browser extension, called CookieBlock, that uses machine learning to enforce GDPR cookie consent at the client. It automatically categorizes cookies by usage purpose using only the information provided in the cookie itself. At a mean validation accuracy of 84.4%, our model attains a prediction quality competitive with expert knowledge in the \ufb01eld. Additionally, our approach differs from prior work by not relying on the cooperation of websites themselves. We empirically evaluate CookieBlock on a set of 100 randomly sampled websites, on which it \ufb01lters roughly 90% of the privacy-invasive cookies without signi\ufb01cantly impairing website functionality. Abstract Our work in this paper consists of four separate components which perform different functions but each others",
            "keywords": [
                "Cookie Consent",
                "GDPR Compliance",
                "Privacy Protection",
                "Cookie Categorization",
                "Privacy-Invasive Cookies"
            ]
        },
        "url": "URL#1416857",
        "sema_paperId": "687c0136bb54d5d9492e27298793e248d538ad19"
    },
    {
        "@score": "1",
        "@id": "1416858",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "239/8466",
                        "text": "Pietro Borrello"
                    },
                    {
                        "@pid": "280/4649",
                        "text": "Andreas Kogler"
                    },
                    {
                        "@pid": "223/9857",
                        "text": "Martin Schwarzl"
                    },
                    {
                        "@pid": "172/1127",
                        "text": "Moritz Lipp"
                    },
                    {
                        "@pid": "166/1494",
                        "text": "Daniel Gruss"
                    },
                    {
                        "@pid": "08/1117-1",
                        "text": "Michael Schwarz 0001"
                    }
                ]
            },
            "title": "\u00c6PIC Leak: Architecturally Leaking Uninitialized Data from the Microarchitecture.",
            "venue": "USENIX Security Symposium",
            "pages": "3917-3934",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BorrelloKSLG022",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/borrello",
            "url": "https://dblp.org/rec/conf/uss/BorrelloKSLG022",
            "abstract": "CPU vulnerabilities undermine the security guarantees provided by software-and hardware-security improvements. While the discovery of transient-execution attacks increased the interest in CPU vulnerabilities on a microarchitectural level, architectural CPU vulnerabilities are still understudied. In this paper, we systematically analyze existing CPU vulnerabilities showing that CPUs suffer from vulnerabilities whose root causes match with those in complex software. We show that transient-execution attacks and architectural vulnerabilities often arise from the same type of bug and identify the blank spots. Investigating the blank spots, we focus on architecturally improperly initialized data locations. We discover \u00c6PIC Leak, the first architectural CPU bug that leaks stale data from the microarchitecture without us-ing a side channel. \u00c6PIC Leak works on all recent Sunny-Cove-based Intel CPUs ( i.e. , Ice Lake and Alder Lake). It architecturally leaks stale data incorrectly returned by reading undefined APIC-register ranges. \u00c6PIC Leak samples data transferred between the L2 and last-level cache, including SGX enclave data, from the superqueue. We target data in use, e.g., register values and memory loads, as well as data at rest, e.g., SGX-enclave data pages. Our end-to-end attack extracts AES-NI, RSA, and even the Intel SGX attestation keys from enclaves within a few seconds. We discuss mitigations and conclude that the only short-term mitigations for \u00c6PIC Leak are to disable APIC MMIO or not rely on SGX.",
            "keywords": [
                "Microarchitectural Vulnerabilities",
                "Architectural CPU Bugs",
                "\u00c6PIC Leak",
                "Data Leakage",
                "Transient-Execution Attacks"
            ]
        },
        "url": "URL#1416858",
        "sema_paperId": "8cf01bf34605fdffd1a404db509fb8b1fde589d8"
    },
    {
        "@score": "1",
        "@id": "1416859",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "02/7441",
                        "text": "Joppe W. Bos"
                    },
                    {
                        "@pid": "170/3652",
                        "text": "Joost Renes"
                    },
                    {
                        "@pid": "150/0066",
                        "text": "Christine van Vredendaal"
                    }
                ]
            },
            "title": "Post-Quantum Cryptography with Contemporary Co-Processors: Beyond Kronecker, Sch\u00f6nhage-Strassen &amp; Nussbaumer.",
            "venue": "USENIX Security Symposium",
            "pages": "3683-3697",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BosRV22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/bos",
            "url": "https://dblp.org/rec/conf/uss/BosRV22",
            "abstract": "There are currently over 30 billion IoT (Internet of Things) devices installed worldwide. To secure these devices from various threats one often relies on public-key cryptographic primitives whose operations can be costly to compute on resource-constrained IoT devices. To support such operations these devices often include a dedicated co-processor for cryptographic procedures, typically in the form of a big integer arithmetic unit. Such existing arithmetic co-processors do not offer the functionality that is expected by upcoming post-quantum cryptographic primitives. Regardless, contemporary systems may exist in the \ufb01eld for many years to come. In this paper we propose the Kronecker + algorithm for polynomial multiplication in rings of the form Z [ X ] / ( X n + 1 ) : the arithmetic foundation of many lattice-based cryptographic schemes. We discuss how Kronecker + allows for re-use of existing co-processors for post-quantum cryptography, and in particular directly applies to the various \ufb01nalists in the post-quantum standardization effort led by NIST. We demonstrate the effectiveness of our algorithm in practice by in-tegrating Kronecker + into Saber: one of the \ufb01nalists in the ongoing NIST standardization effort. On our target platform, a RV32IMC with access to a dedicated arithmetic co-processor designed to accelerate RSA and ECC, Kronecker + performs the matrix multiplication 2.8 times faster than regular Kronecker substitution and 1.7 times faster than Harvey\u2019s negated-evaluation-points method.",
            "keywords": [
                "Post-Quantum Cryptography",
                "Cryptographic Co-Processors",
                "Polynomial Multiplication",
                "Lattice-Based Schemes",
                "Kronecker + Algorithm"
            ]
        },
        "url": "URL#1416859",
        "sema_paperId": "e5ae15e4fec86b3becea10995ce1adcad3fc58b6"
    },
    {
        "@score": "1",
        "@id": "1416860",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "181/4477",
                        "text": "Jay Bosamiya"
                    },
                    {
                        "@pid": "290/4168",
                        "text": "Wen Shih Lim"
                    },
                    {
                        "@pid": "49/6324",
                        "text": "Bryan Parno"
                    }
                ]
            },
            "title": "Provably-Safe Multilingual Software Sandboxing using WebAssembly.",
            "venue": "USENIX Security Symposium",
            "pages": "1975-1992",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BosamiyaLP22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/bosamiya",
            "url": "https://dblp.org/rec/conf/uss/BosamiyaLP22",
            "abstract": "Many applications, from the Web to smart contracts, need to safely execute untrusted code. We observe that WebAssembly (Wasm) is ideally positioned to support such applications, since it promises safety and performance, while serving as a compiler target for many high-level languages. However, Wasm\u2019s safety guarantees are only as strong as the implementation that enforces them. Hence, we explore two distinct approaches to producing provably sandboxed Wasm code. One draws on traditional formal methods to produce mathematical, machine-checked proofs of safety. The second carefully embeds Wasm semantics in safe Rust code such that the Rust compiler can emit safe executable code with good performance. Our implementation and evaluation of these two techniques indicate that leveraging Wasm gives us provably-safe multilingual sandboxing with performance comparable to standard, unsafe approaches.",
            "keywords": [
                "WebAssembly",
                "Sandboxing",
                "Formal Methods",
                "Provably-Safe Code",
                "Multilingual Execution"
            ]
        },
        "url": "URL#1416860",
        "sema_paperId": "0bfa7803aa3086b5a6fd7f679f80d95627710986"
    },
    {
        "@score": "1",
        "@id": "1416861",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "272/7083",
                        "text": "Xander Bouwman"
                    },
                    {
                        "@pid": "221/3626",
                        "text": "Victor Le Pochat"
                    },
                    {
                        "@pid": "36/9959",
                        "text": "Pawel Foremski"
                    },
                    {
                        "@pid": "147/2244",
                        "text": "Tom van Goethem"
                    },
                    {
                        "@pid": "22/7256",
                        "text": "Carlos Hernandez Ga\u00f1\u00e1n"
                    },
                    {
                        "@pid": "76/5048",
                        "text": "Giovane C. M. Moura"
                    },
                    {
                        "@pid": "182/6692",
                        "text": "Samaneh Tajalizadehkhoob"
                    },
                    {
                        "@pid": "13/86",
                        "text": "Wouter Joosen"
                    },
                    {
                        "@pid": "17/7444",
                        "text": "Michel van Eeten"
                    }
                ]
            },
            "title": "Helping hands: Measuring the impact of a large threat intelligence sharing community.",
            "venue": "USENIX Security Symposium",
            "pages": "1149-1165",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BouwmanPFGGMTJE22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/bouwman",
            "url": "https://dblp.org/rec/conf/uss/BouwmanPFGGMTJE22",
            "abstract": "We tracked the largest volunteer security information sharing community known to date: the COVID-19 Cyber Threat Coalition, with over 4,000 members. This enabled us to address long-standing questions on threat information sharing. First, does collaboration at scale lead to better coverage? And second, does making threat data freely available improve the ability of defenders to act? We found that the CTC mostly aggregated existing industry sources of threat information. User-submitted domains often did not make it to the CTC's blocklist as a result of the high threshold posed by its automated quality assurance using VirusTotal. Although this ensured a low false positive rate, it also caused the focus of the blocklist to drift away from domains related to COVID-19 (1.4%-3.6%) to more generic abuse, such as phishing, for which established mitigation mechanisms already exist. However, in the slice of data that was related to COVID-19, we found promising evidence of the added value of a community like the CTC: just 25.1% of these domains were known to existing abuse detection infrastructures at time of listing, as compared to 58.4% of domains on the overall blocklist. From the unique experiment that the CTC represented, we draw three lessons for future threat data sharing initiatives.",
            "keywords": [
                "Threat Intelligence Sharing",
                "Cyber Threat Coalition",
                "COVID-19 Cyber Threats",
                "Blocklist Effectiveness",
                "Community Collaboration in Security"
            ]
        },
        "url": "URL#1416861",
        "sema_paperId": "cf2dc729a4206def18a3580f84a0273963cc52c3"
    },
    {
        "@score": "1",
        "@id": "1416862",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "294/4488",
                        "text": "Alexander Bulekov"
                    },
                    {
                        "@pid": "331/2331",
                        "text": "Bandan Das"
                    },
                    {
                        "@pid": "136/6169",
                        "text": "Stefan Hajnoczi"
                    },
                    {
                        "@pid": "27/3108",
                        "text": "Manuel Egele"
                    }
                ]
            },
            "title": "Morphuzz: Bending (Input) Space to Fuzz Virtual Devices.",
            "venue": "USENIX Security Symposium",
            "pages": "1221-1238",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BulekovDHE22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/bulekov",
            "url": "https://dblp.org/rec/conf/uss/BulekovDHE22",
            "abstract": "The security of the entire cloud ecosystem crucially de-pends on the isolation guarantees that hypervisors provide between guest VMs and the host system. To allow VMs to communicate with their environment, hypervisors provide a slew of virtual-devices including network interface cards and performance-optimized VIRTIO-based SCSI adapters. As these devices sit directly on the hypervisor\u2019s isolation boundary and accept potentially attacker controlled input (e.g., from a malicious cloud tenant), bugs and vulnerabilities in the devices\u2019 implementations have the potential to render the hypervisor\u2019s isolation guarantees moot. Prior works applied fuzzing to simple virtual-devices, focusing on a narrow subset of the vast input-space and the state-of-the-art virtual-device fuzzer, Nyx, requires precise, manually-written, speci\ufb01cations to exercise complex devices. In this paper we present M ORPHUZZ , a generic approach that leverages insights about hypervisor design combined with coverage-guided fuzzing to \ufb01nd bugs in virtual device implementations. Crucially M ORPHUZZ does not rely on expert knowledge speci\ufb01c to each device. M ORPHUZZ is the \ufb01rst approach that automatically elicits the complex I/O behaviors of the real-world virtual devices found in modern clouds. To demonstrate this capability, we implemented M ORPHUZZ in QEMU and bhyve and fuzzed 33 different virtual devices (a superset of the 16 devices analyzed by prior work). Additionally, we show that M ORPHUZZ is not tied to a speci\ufb01c CPU architecture, by fuzzing 3 additional ARM devices. M OR PHUZZ matches or exceeds coverage obtained by Nyx, for 13/16 virtual devices, and identi\ufb01ed a superset",
            "keywords": [
                "Virtual Device Fuzzing",
                "Hypervisor Isolation",
                "Input Space Exploration",
                "Bug Detection",
                "Coverage-Guided Fuzzing"
            ]
        },
        "url": "URL#1416862",
        "sema_paperId": "ccbf122bf7c6ebd64a2705bf2aeedad976e72964"
    },
    {
        "@score": "1",
        "@id": "1416863",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "168/2351",
                        "text": "Ben Burgess"
                    },
                    {
                        "@pid": "238/4577",
                        "text": "Avi Ginsberg"
                    },
                    {
                        "@pid": "f/EdwardWFelten",
                        "text": "Edward W. Felten"
                    },
                    {
                        "@pid": "170/3520",
                        "text": "Shaanan Cohney"
                    }
                ]
            },
            "title": "Watching the watchers: bias and vulnerability in remote proctoring software.",
            "venue": "USENIX Security Symposium",
            "pages": "571-588",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BurgessGFC22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/burgess",
            "url": "https://dblp.org/rec/conf/uss/BurgessGFC22",
            "abstract": "Educators are rapidly switching to remote proctoring and examination software for their testing needs, both due to the COVID-19 pandemic and the expanding virtualization of the education sector. State boards are increasingly utilizing these software for high stakes legal and medical licensing exams. Three key concerns arise with the use of these complex software: exam integrity, exam procedural fairness, and exam-taker security and privacy. We conduct the first technical analysis of each of these concerns through a case study of four primary proctoring suites used in U.S. law school and state attorney licensing exams. We reverse engineer these proctoring suites and find that despite promises of high-security, all their anti-cheating measures can be trivially bypassed and can pose significant user security risks. We evaluate current facial recognition classifiers alongside the classifier used by Examplify, the legal exam proctoring suite with the largest market share, to ascertain their accuracy and determine whether faces with certain skin tones are more readily flagged for cheating. Finally, we offer recommendations to improve the integrity and fairness of the remotely proctored exam experience.",
            "keywords": [
                "Remote Proctoring",
                "Exam Integrity",
                "Facial Recognition Bias",
                "User Privacy",
                "Exam Procedural Fairness"
            ]
        },
        "url": "URL#1416863",
        "sema_paperId": "393bdb64d4b7c54a1d2a5dbab2c53a99c8a2c5da"
    },
    {
        "@score": "1",
        "@id": "1416864",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "331/2570",
                        "text": "Kevin Burk"
                    },
                    {
                        "@pid": "123/3252",
                        "text": "Fabio Pagani"
                    },
                    {
                        "@pid": "k/ChristopherKruegel",
                        "text": "Christopher Kruegel"
                    },
                    {
                        "@pid": "v/GiovanniVigna",
                        "text": "Giovanni Vigna"
                    }
                ]
            },
            "title": "Decomperson: How Humans Decompile and What We Can Learn From It.",
            "venue": "USENIX Security Symposium",
            "pages": "2765-2782",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BurkPKV22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/burk",
            "url": "https://dblp.org/rec/conf/uss/BurkPKV22",
            "abstract": "Human analysts must reverse engineer binary programs as a prerequisite for a number of security tasks, such as vulnerability analysis, malware detection, and \ufb01rmware re-hosting. Existing studies of human reversers and the processes they follow are limited in size and often use qualitative metrics that require subjective evaluation. In this paper, we reframe the problem of reverse engineering binaries as the problem of perfect decompilation , which is the process of recovering, from a binary program, source code that, when compiled, produces binary code that is identical to the original binary. This gives us a quantitative measure of understanding, and lets us examine the reversing process programmatically.Wedevelopedatool, called D ECOMPERSON , that supported a group of reverse engineers during a large-scale security competition designed to collect information about the participants\u2019 reverse engineering process, with the well-de\ufb01ned goal of achieving perfect decompilation. Over 150 people par-ticipated,andwe collectedmore than 35,000 code submissions, the largest manual reverse engineering dataset to date. This includes snapshots of over 300 successful perfect decompilation attempts. In this paper, we show how perfect decompilation allows programmatic analysis of such large datasets, providing new insights into the reverse engineering process.",
            "keywords": [
                "Reverse Engineering",
                "Binary Analysis",
                "Perfect Decompilation",
                "Human Analysts",
                "Security Competition"
            ]
        },
        "url": "URL#1416864",
        "sema_paperId": "e04986e352bc5861ddd8ff47ed491199e5e02e3f"
    },
    {
        "@score": "1",
        "@id": "1416865",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "205/3630",
                        "text": "Matteo Cardaioli"
                    },
                    {
                        "@pid": "202/9073",
                        "text": "Stefano Cecconello"
                    },
                    {
                        "@pid": "82/4386",
                        "text": "Mauro Conti"
                    },
                    {
                        "@pid": "10/4730",
                        "text": "Simone Milani"
                    },
                    {
                        "@pid": "50/10230",
                        "text": "Stjepan Picek"
                    },
                    {
                        "@pid": "224/4536",
                        "text": "Eugen Saraci"
                    }
                ]
            },
            "title": "Hand Me Your PIN! Inferring ATM PINs of Users Typing with a Covered Hand.",
            "venue": "USENIX Security Symposium",
            "pages": "1687-1704",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CardaioliCCMPS22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/cardaioli",
            "url": "https://dblp.org/rec/conf/uss/CardaioliCCMPS22",
            "abstract": "Automated Teller Machines (ATMs) represent the most used system for withdrawing cash. The European Central Bank reported more than 11 billion cash withdrawals and loading/unloading transactions on the European ATMs in 2019. Although ATMs have undergone various technological evolutions, Personal Identification Numbers (PINs) are still the most common authentication method for these devices. Unfortunately, the PIN mechanism is vulnerable to shoulder-surfing attacks performed via hidden cameras installed near the ATM to catch the PIN pad. To overcome this problem, people get used to covering the typing hand with the other hand. While such users probably believe this behavior is safe enough to protect against mentioned attacks, there is no clear assessment of this countermeasure in the scientific literature.This paper proposes a novel attack to reconstruct PINs entered by victims covering the typing hand with the other hand. We consider the setting where the attacker can access an ATM PIN pad of the same brand/model as the target one. Afterward, the attacker uses that model to infer the digits pressed by the victim while entering the PIN. Our attack owes its success to a carefully selected deep learning architecture that can infer the PIN from the typing hand position and movements. We run a detailed experimental analysis including 58 users. With our approach, we can guess 30% of the 5-digit PINs within three attempts \u2013 the ones usually allowed by ATM before blocking the card. We also conducted a survey with 78 users that managed to reach an accuracy of only 7.92% on average for the same setting. Finally, we evaluate a shielding countermeasure that proved to be rather inefficient unless the whole keypad is shielded.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-cardaioli.pdf",
            "keywords": [
                "ATM Security",
                "Shoulder Surfing",
                "PIN Inference",
                "User Behavior",
                "Countermeasures"
            ]
        },
        "url": "URL#1416865"
    },
    {
        "@score": "1",
        "@id": "1416866",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "255/2388",
                        "text": "David Cerdeira"
                    },
                    {
                        "@pid": "97/5724",
                        "text": "Jos\u00e9 Martins"
                    },
                    {
                        "@pid": "07/967-1",
                        "text": "Nuno Santos 0001"
                    },
                    {
                        "@pid": "170/0331",
                        "text": "Sandro Pinto 0001"
                    }
                ]
            },
            "title": "ReZone: Disarming TrustZone with TEE Privilege Reduction.",
            "venue": "USENIX Security Symposium",
            "pages": "2261-2279",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CerdeiraM0022",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/cerdeira",
            "url": "https://dblp.org/rec/conf/uss/CerdeiraM0022",
            "abstract": "In TrustZone-assisted TEEs, the trusted OS has unrestricted access to both secure and normal world memory. Unfortunately, this architectural limitation has opened an aisle of exploration for attackers, which have demonstrated how to leverage a chain of exploits to hijack the trusted OS and gain full control of the system, targeting (i) the rich execution environment (REE), (ii) all trusted applications (TAs), and (iii) the secure monitor. In this paper, we propose ReZone. The main novelty behind ReZone design relies on leveraging TrustZone-agnostic hardware primitives available on commercially off-the-shelf (COTS) platforms to restrict the privileges of the trusted OS. With ReZone, a monolithic TEE is restructured and partitioned into multiple sandboxed domains named zones, which have only access to private resources. We have fully implemented ReZone for the i.MX 8MQuad EVK and integrated it with Android OS and OP-TEE. We extensively evaluated ReZone using microbenchmarks and real-world applications. ReZone can sustain popular applications like DRM-protected video encoding with acceptable performance overheads. We have surveyed 80 CVE vulnerability reports and estimate that ReZone could mitigate 86.84% of them.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-cerdeira.pdf",
            "keywords": [
                "Trusted Execution Environments",
                "TrustZone",
                "Privilege Reduction",
                "Sandboxing",
                "Vulnerability Mitigation"
            ]
        },
        "url": "URL#1416866"
    },
    {
        "@score": "1",
        "@id": "1416867",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "227/9110",
                        "text": "Javad Ghareh Chamani"
                    },
                    {
                        "@pid": "18/9002",
                        "text": "Dimitrios Papadopoulos 0001"
                    },
                    {
                        "@pid": "322/3466",
                        "text": "Mohammadamin Karbasforushan"
                    },
                    {
                        "@pid": "181/5758",
                        "text": "Ioannis Demertzis"
                    }
                ]
            },
            "title": "Dynamic Searchable Encryption with Optimal Search in the Presence of Deletions.",
            "venue": "USENIX Security Symposium",
            "pages": "2425-2442",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Chamani0KD22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/chamani",
            "url": "https://dblp.org/rec/conf/uss/Chamani0KD22",
            "abstract": "We focus on the problem of Dynamic Searchable Encryption (DSE) with efficient (optimal/quasi-optimal) search in the presence of deletions. Towards that end, we first propose OSSE, the first DSE scheme that can achieve asymptotically optimal search time, linear to the result size and independent of any prior deletions, improving the previous state of the art by a multiplicative logarithmic factor. We then propose our second scheme LLSE, that achieves a sublogarithmic search overhead (loglogi_w, where i_w is the number or prior insertions for a keyword) compared to the optimal achieved by OSSE. While this is slightly worse than our first scheme, it still outperforms prior works, while also achieving faster deletions and asymptotically smaller server storage. Both schemes have standard leakage profiles and are forward-and-backward private. Our experimental evaluation is very encouraging as it shows our schemes consistently outperform the prior state-of-the-art DSE by 1.2-6.6x in search computation time, while also requiring just a single roundtrip to receive the search result. Even compared with prior simpler and very efficient constructions in which all deleted records are returned as part of the result, our OSSE achieves better performance for deletion rates ranging from 45-55%, while the previous state-of-the-art quasi-optimal scheme achieves this for 65-75% deletion rates.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-chamani.pdf",
            "keywords": [
                "Dynamic Searchable Encryption",
                "Optimal Search",
                "Data Deletions",
                "Asymptotic Performance",
                "Server Storage Efficiency"
            ]
        },
        "url": "URL#1416867"
    },
    {
        "@score": "1",
        "@id": "1416868",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "77/5616",
                        "text": "Nishanth Chandran"
                    },
                    {
                        "@pid": "66/11477-1",
                        "text": "Divya Gupta 0001"
                    },
                    {
                        "@pid": "208/0827",
                        "text": "Sai Lakshmi Bhavana Obbattu"
                    },
                    {
                        "@pid": "179/9900",
                        "text": "Akash Shah"
                    }
                ]
            },
            "title": "SIMC: ML Inference Secure Against Malicious Clients at Semi-Honest Cost.",
            "venue": "USENIX Security Symposium",
            "pages": "1361-1378",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Chandran0OS22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/chandran",
            "url": "https://dblp.org/rec/conf/uss/Chandran0OS22",
            "abstract": "Secure inference allows a model owner (or, the server) and the input owner (or, the client) to perform inference on machine learning model without revealing their private information to each other. A large body of work has shown efficient cryptographic solutions to this problem through secure 2- party computation. However, they assume that both parties are semi-honest, i.e., follow the protocol specification. Recently, Lehmkuhl et al. showed that malicious clients can extract the whole model of the server using novel model-extraction attacks. To remedy the situation, they introduced the client-malicious threat model and built a secure inference system, MUSE, that provides security guarantees, even when the client is malicious.In this work, we design and build SIMC, a new cryptographic system for secure inference in the client malicious threat model. On secure inference benchmarks considered by MUSE, SIMC has 23 \u2212 29\u00d7 lesser communication and is up to 11.4\u00d7 faster than MUSE. SIMC obtains these improvements using a novel protocol for non-linear activation functions (such as ReLU) that has > 28\u00d7 lesser communication and is up to 43\u00d7 more performant than MUSE. In fact, SIMC's performance beats the state-of-the-art semi-honest secure inference system!Finally, similar to MUSE, we show how to push the majority of the cryptographic cost of SIMC to an input independent preprocessing phase. While the cost of the online phase of this protocol, SIMC++, is same as that of MUSE, the overall improvements of SIMC translate to similar improvements to the preprocessing phase of MUSE.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-chandran.pdf",
            "keywords": [
                "Secure Inference",
                "Client-Malicious Threat Model",
                "Cryptographic Protocols",
                "Model Extraction Attacks",
                "Non-linear Activation Functions"
            ]
        },
        "url": "URL#1416868"
    },
    {
        "@score": "1",
        "@id": "1416869",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "281/6881",
                        "text": "Yunang Chen"
                    },
                    {
                        "@pid": "33/3099-11",
                        "text": "Yue Gao 0011"
                    },
                    {
                        "@pid": "304/6781",
                        "text": "Nick Ceccio"
                    },
                    {
                        "@pid": "03/9962",
                        "text": "Rahul Chatterjee 0001"
                    },
                    {
                        "@pid": "97/535",
                        "text": "Kassem Fawaz"
                    },
                    {
                        "@pid": "16/10817",
                        "text": "Earlence Fernandes"
                    }
                ]
            },
            "title": "Experimental Security Analysis of the App Model in Business Collaboration Platforms.",
            "venue": "USENIX Security Symposium",
            "pages": "2011-2028",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Chen0C0FF22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/chen-yunang-experimental",
            "url": "https://dblp.org/rec/conf/uss/Chen0C0FF22",
            "abstract": "Business Collaboration Platforms like Microsoft Teams and Slack enable teamwork by supporting text chatting and third-party resource integration. A user can access online file storage, make video calls, and manage a code repository, all from within the platform, thus making them a hub for sensitive communication and resources. The key enabler for these productivity features is a third-party application model. We contribute an experimental security analysis of this model and the third-party apps. Performing this analysis is challenging because commercial platforms and their apps are closed-source systems. Our analysis methodology is to systematically investigate different types of interactions possible between apps and users. We discover that the access control model in these systems violates two fundamental security principles: least privilege and complete mediation. These violations enable a malicious app to exploit the confidentiality and integrity of user messages and third-party resources connected to the platform. We construct proof-of-concept attacks that can: (1) eavesdrop on user messages without having permission to read those messages; (2) launch fake video calls; (3) automatically merge code into repositories without user approval or involvement. Finally, we provide an analysis of countermeasures that systems like Slack and Microsoft Teams can adopt today.",
            "keywords": [
                "Business Collaboration Platforms",
                "Third-Party Application Model",
                "Access Control Violations",
                "Confidentiality Exploitation",
                "Integrity Attacks"
            ]
        },
        "url": "URL#1416869",
        "sema_paperId": "4a1589f26787ef3cb300f34daae85ee1030cf682"
    },
    {
        "@score": "1",
        "@id": "1416870",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "281/6881",
                        "text": "Yunang Chen"
                    },
                    {
                        "@pid": "222/8115",
                        "text": "Mohannad Alhanahnah"
                    },
                    {
                        "@pid": "s/AndreiSabelfeld",
                        "text": "Andrei Sabelfeld"
                    },
                    {
                        "@pid": "03/9962",
                        "text": "Rahul Chatterjee 0001"
                    },
                    {
                        "@pid": "16/10817",
                        "text": "Earlence Fernandes"
                    }
                ]
            },
            "title": "Practical Data Access Minimization in Trigger-Action Platforms.",
            "venue": "USENIX Security Symposium",
            "pages": "2929-2945",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChenAS0F22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/chen-yunang-practical",
            "url": "https://dblp.org/rec/conf/uss/ChenAS0F22",
            "abstract": "Trigger-Action Platforms (TAPs) connect disparate online services and enable users to create automation rules in diverse domains such as smart homes and business productivity. Unfortunately, the current design of TAPs is flawed from a privacy perspective, allowing unfettered access to sensitive user data. We point out that it suffers from two types of overprivilege: (1) attribute-level, where it has access to more data attributes than it needs for running user-created rules; and (2) token-level, where it has access to more APIs than it needs. To mitigate overprivilege and subsequent privacy concerns we design and implement minTAP, a practical approach to data access minimization in TAPs. Our key insight is that the semantics of a user-created automation rule implicitly specifies the minimal amount of data it needs. This allows minTAP to leverage language-based data minimization to apply the principle of least-privilege by releasing only the necessary attributes of user data to TAPs and fending off unrelated API access. Using real user-created rules on the popular IFTTT TAP, we demonstrate that minTAP sanitizes a median of 4 sensitive data attributes per rule, with modest performance overhead and without modifying IFTTT.",
            "keywords": [
                "Trigger-Action Platforms",
                "Data Access Minimization",
                "Privacy Concerns",
                "Overprivilege",
                "User Data Sanitization"
            ]
        },
        "url": "URL#1416870",
        "sema_paperId": "d5c2a461adfd78b315238fe95925d4a2b2b5ae53"
    },
    {
        "@score": "1",
        "@id": "1416871",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "164/3860",
                        "text": "Ju Chen"
                    },
                    {
                        "@pid": "57/10300",
                        "text": "Wookhyun Han"
                    },
                    {
                        "@pid": "248/4507",
                        "text": "Mingjun Yin"
                    },
                    {
                        "@pid": "331/2642",
                        "text": "Haochen Zeng"
                    },
                    {
                        "@pid": "69/6818",
                        "text": "Chengyu Song"
                    },
                    {
                        "@pid": "45/7986",
                        "text": "Byoungyoung Lee"
                    },
                    {
                        "@pid": "77/6178-1",
                        "text": "Heng Yin 0001"
                    },
                    {
                        "@pid": "45/4154",
                        "text": "Insik Shin"
                    }
                ]
            },
            "title": "SYMSAN: Time and Space Efficient Concolic Execution via Dynamic Data-flow Analysis.",
            "venue": "USENIX Security Symposium",
            "pages": "2531-2548",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChenHYZSLYS22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/chen-ju",
            "url": "https://dblp.org/rec/conf/uss/ChenHYZSLYS22",
            "abstract": "Concolic execution is a powerful program analysis technique for systematically exploring execution paths. Compared to random-mutation-based fuzzing, concolic execution is especially good at exploring paths that are guarded by complex and tight branch predicates. The drawback, however, is that concolic execution engines are much slower than native execution. While recent advances in concolic execution have significantly reduced its performance overhead, our analysis shows that state-of-the-art concolic executors overlook the overhead for managing symbolic expressions. Based on the observation that concolic execution can be modeled as a special form of dynamic data-flow analysis, we propose to leverage existing highly-optimized data-flow analysis frameworks to implement concolic executors. To validate this idea, we implemented a prototype S YM S AN based on the data-flow sanitizer of LLVM and evaluated it against the state-of-the-art concolic executors SymCC and SymQEMU with three sets of programs: nbench, the DARPA Cyber Grand Challenge dataset, and real-world applications from Google\u2019s Fuzzbench and binutils. The results showed that S YM S AN has a much lower overhead for managing symbolic expressions. The reduced overhead can also lead to faster concolic execution and improved code coverage.",
            "keywords": [
                "Concolic Execution",
                "Dynamic Data-flow Analysis",
                "Symbolic Expressions",
                "Performance Overhead",
                "Code Coverage"
            ]
        },
        "url": "URL#1416871",
        "sema_paperId": "243e68e8214c7a9babfb67d7a66d8b8f39f54f9f"
    },
    {
        "@score": "1",
        "@id": "1416872",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "238/0932",
                        "text": "Qibin Chen"
                    },
                    {
                        "@pid": "223/2758",
                        "text": "Jeremy Lacomis"
                    },
                    {
                        "@pid": "21/8302",
                        "text": "Edward J. Schwartz"
                    },
                    {
                        "@pid": "93/4573",
                        "text": "Claire Le Goues"
                    },
                    {
                        "@pid": "03/8155",
                        "text": "Graham Neubig"
                    },
                    {
                        "@pid": "43/10504",
                        "text": "Bogdan Vasilescu"
                    }
                ]
            },
            "title": "Augmenting Decompiler Output with Learned Variable Names and Types.",
            "venue": "USENIX Security Symposium",
            "pages": "4327-4343",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChenLSGNV22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/chen-qibin",
            "url": "https://dblp.org/rec/conf/uss/ChenLSGNV22",
            "abstract": "A common tool used by security professionals for reverse-engineering binaries found in the wild is the decompiler. A decompiler attempts to reverse compilation, transforming a binary to a higher-level language such as C. High-level languages ease reasoning about programs by providing useful abstractions such as loops, typed variables, and comments, but these abstractions are lost during compilation. Decompilers are able to deterministically reconstruct structural properties of code, but comments, variable names, and custom variable types are technically impossible to recover. In this paper we present DIRTY (DecompIled variable ReTYper), a novel technique for improving the quality of decompiler output that automatically generates meaningful variable names and types. Empirical evaluation on a novel dataset of C code mined from GitHub shows that DIRTY outperforms prior work approaches by a sizable margin, recovering the original names written by developers 66.4% of the time and the original types 75.8% of the time.",
            "keywords": [
                "Decompiler",
                "Variable Naming",
                "Type Recovery",
                "Reverse Engineering",
                "DIRTY"
            ]
        },
        "url": "URL#1416872",
        "sema_paperId": "06e36261b21af2943e464a562c92c09dac292a82"
    },
    {
        "@score": "1",
        "@id": "1416873",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "55/6958",
                        "text": "Yuan Chen"
                    },
                    {
                        "@pid": "118/4502",
                        "text": "Jiaqi Li"
                    },
                    {
                        "@pid": "189/5198",
                        "text": "Guorui Xu"
                    },
                    {
                        "@pid": "15/7381",
                        "text": "Yajin Zhou"
                    },
                    {
                        "@pid": "95/6543-4",
                        "text": "Zhi Wang 0004"
                    },
                    {
                        "@pid": "18/2771-1",
                        "text": "Cong Wang 0001"
                    },
                    {
                        "@pid": "20/6179-1",
                        "text": "Kui Ren 0001"
                    }
                ]
            },
            "title": "SGXLock: Towards Efficiently Establishing Mutual Distrust Between Host Application and Enclave for SGX.",
            "venue": "USENIX Security Symposium",
            "pages": "4129-4146",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChenLXZ00022",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/chen-yuan",
            "url": "https://dblp.org/rec/conf/uss/ChenLXZ00022",
            "abstract": "Since its debut, SGX has been used to secure various types of applications. However, existing systems usually assume a trusted enclave and ignore the security issues caused by an untrusted enclave. For instance, a vulnerable (or even malicious) third-party enclave can be exploited to attack the host application and the rest of the system. In this paper, we propose an ef\ufb01cient mechanism to con\ufb01ne an untrusted enclave\u2019s behaviors. In particular, the threats of an untrusted enclave come from the enclave-host asymmetries, which can be abused to access arbitrary memory regions of its host application, jump to any code location after leaving the enclave and forge the stack register to manipulate the saved context. Our solution breaks such asymmetries and establishes mutual distrust between the host application and the enclave. Speci\ufb01cally, it leverages Intel MPK for ef\ufb01cient memory isolation and the x86 single-step debugging mechanism to capture the exiting event of the enclave. Then it performs the integrity check of the jump target and the stack pointer. We have implemented a prototype system and solved two practical challenges. The evaluation with multiple micro-benchmarks and representative real-world applications demonstrated the effectiveness and the ef\ufb01ciency of our system, with less than 4% performance overhead.",
            "keywords": [
                "SGX",
                "Enclave Security",
                "Mutual Distrust",
                "Memory Isolation",
                "Integrity Check"
            ]
        },
        "url": "URL#1416873",
        "sema_paperId": "e06afd48afbd8417e7c4da09db8dbf73ee08112f"
    },
    {
        "@score": "1",
        "@id": "1416874",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "49/6574",
                        "text": "Yi Chen"
                    },
                    {
                        "@pid": "77/1147-1",
                        "text": "Di Tang 0001"
                    },
                    {
                        "@pid": "226/0656",
                        "text": "Yepeng Yao"
                    },
                    {
                        "@pid": "205/3769",
                        "text": "Mingming Zha"
                    },
                    {
                        "@pid": "06/6268",
                        "text": "XiaoFeng Wang 0001"
                    },
                    {
                        "@pid": "11/6389",
                        "text": "Xiaozhong Liu"
                    },
                    {
                        "@pid": "90/3951",
                        "text": "Haixu Tang"
                    },
                    {
                        "@pid": "272/7105",
                        "text": "Dongfang Zhao 0010"
                    }
                ]
            },
            "title": "Seeing the Forest for the Trees: Understanding Security Hazards in the 3GPP Ecosystem through Intelligent Analysis on Change Requests.",
            "venue": "USENIX Security Symposium",
            "pages": "17-34",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChenTYZ0LT022",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/chen-yi",
            "url": "https://dblp.org/rec/conf/uss/ChenTYZ0LT022",
            "abstract": "With the recent report of erroneous content in 3GPP specifications leading to real-world vulnerabilities, attention has been drawn to not only the specifications but also the way they are maintained and adopted by manufacturers and carriers. In this paper, we report the first study on this 3GPP ecosystem, for the purpose of understanding its security hazards. Our research leverages 414,488 Change Requests (CRs) that document the problems discovered from specifications and proposed changes, which provides valuable information about the security assurance of the 3GPP ecosystem. Analyzing these CRs is impeded by the challenge in finding security-relevant CRs (SR-CRs), whose security connections cannot be easily established by even human experts. To identify them, we developed a novel NLP/ML pipeline that utilizes a small set of positively labeled CRs to recover 1,270 high-confidence SR-CRs. Our measurement on them reveals serious consequences of specification errors and their causes, including design errors and presentation issues, particularly the pervasiveness of inconsistent descriptions ( misalignment ) in security-relevant content. Also important is the discovery of a security weakness inherent to the 3GPP ecosystem, which publishes an SR-CR long before the specification has been fixed and related systems have been patched. This opens an \u201cattack window\u201d, which can be as long as 11 years! Interest-ingly, we found that some recently reported vulnerabilities",
            "keywords": [
                "3GPP Ecosystem",
                "Change Requests",
                "Security Hazards",
                "Specification Errors",
                "Attack Window"
            ]
        },
        "url": "URL#1416874",
        "sema_paperId": "f86acf7e93339b4f369b9c83e68ce792de81d3ce"
    },
    {
        "@score": "1",
        "@id": "1416875",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "05/1884",
                        "text": "Guoxing Chen"
                    },
                    {
                        "@pid": "77/3503",
                        "text": "Yinqian Zhang"
                    }
                ]
            },
            "title": "MAGE: Mutual Attestation for a Group of Enclaves without Trusted Third Parties.",
            "venue": "USENIX Security Symposium",
            "pages": "4095-4110",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChenZ22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/chen-guoxing",
            "url": "https://dblp.org/rec/conf/uss/ChenZ22",
            "abstract": "Remote attestation mechanism enables an enclave to attest its identity (which is usually represented by the enclave's initial code and data) to another enclave. To verify that the attested identity is trusted, one enclave usually includes the identity of the enclave it trusts into its initial data in advance assuming no trusted third parties are available during runtime to provide this piece of information. However, when mutual trust between these two enclaves is required, it is infeasible to simultaneously include into their own initial data the other's identities respectively as any change to the initial data will change their identities, making the previously included identities invalid. In this paper, we propose MAGE, a framework enabling a group of enclaves to mutually attest each other without trusted third parties. Particularly, we introduce a technique to instrument these enclaves so that each of them could derive the others' identities using information solely from its own initial data. We also provide an open-sourced prototype implementation based on Intel SGX SDK, to facilitate enclave developers to adopt this technique.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-chen-guoxing.pdf",
            "keywords": [
                "Enclave Attestation",
                "Mutual Trust",
                "Remote Attestation",
                "Trusted Execution Environments",
                "Intel SGX"
            ]
        },
        "url": "URL#1416875"
    },
    {
        "@score": "1",
        "@id": "1416876",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "160/9382",
                        "text": "Giovanni Cherubin"
                    },
                    {
                        "@pid": "14/7561",
                        "text": "Rob Jansen"
                    },
                    {
                        "@pid": "01/4825",
                        "text": "Carmela Troncoso"
                    }
                ]
            },
            "title": "Online Website Fingerprinting: Evaluating Website Fingerprinting Attacks on Tor in the Real World.",
            "venue": "USENIX Security Symposium",
            "pages": "753-770",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CherubinJT22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/cherubin",
            "url": "https://dblp.org/rec/conf/uss/CherubinJT22",
            "abstract": "Website \ufb01ngerprinting (WF) attacks on Tor allow an adversary who can observe the traf\ufb01c patterns between a victim and the Tor network to predict the website visited by the victim. Existing WF attacks yield extremely high accuracy. However, the conditions under which these attacks are evaluated raises ques-tions about their effectiveness in the real world. We conduct the \ufb01rst evaluation of website \ufb01ngerprinting using genuine Tor traf\ufb01c as ground truth and evaluated under a true open world . We achieve this by adapting the state-of-the-art Triplet Fingerprinting attack to an online setting and training the WF models on data safely collected on a Tor exit relay\u2014a setup an adversary can easily deploy in practice. By studying WF under realistic conditions, we demonstrate that an adversary can achieve a WF classi\ufb01cation accuracy of above 95% when monitoring a small set of 5 popular websites, but that accuracy quickly degrades to less than 80% when monitoring as few as 25 websites. We conclude that, although WF attacks may be possible, it is likely infeasible to carry them out in the real world while monitoring more than a small set of websites.",
            "keywords": [
                "Website Fingerprinting",
                "Tor Network",
                "Traffic Analysis",
                "Adversarial Attacks",
                "Real-World Evaluation"
            ]
        },
        "url": "URL#1416876",
        "sema_paperId": "a2b2c2a3d421930688669e0b6cf528f8c1125bcc"
    },
    {
        "@score": "1",
        "@id": "1416877",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "62/8336",
                        "text": "Vincent Cheval"
                    },
                    {
                        "@pid": "195/3195",
                        "text": "Charlie Jacomme"
                    },
                    {
                        "@pid": "k/SteveKremer",
                        "text": "Steve Kremer"
                    },
                    {
                        "@pid": "89/11274",
                        "text": "Robert K\u00fcnnemann"
                    }
                ]
            },
            "title": "SAPIC+: protocol verifiers of the world, unite!",
            "venue": "USENIX Security Symposium",
            "pages": "3935-3952",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChevalJKK22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/cheval",
            "url": "https://dblp.org/rec/conf/uss/ChevalJKK22",
            "abstract": "Symbolic security protocol verifiers have reached a high degree of automation and maturity. Today, experts can model real-world protocols, but this often requires model-specific encodings and deep insight into the strengths and weaknesses of each of those tools. With SAPIC+, we introduce a protocol verification platform that lifts this burden and permits choosing the right tool for the job, at any development stage. We build on the existing compiler from SAPIC to TAMARIN, and extend it with automated translations from SAPIC+ to PROVERIF and DEEPSEC, as well as powerful, protocol-independent optimizations of the existing translation. We prove each part of these translations sound. A user can thus, with a single SAPIC+ file, verify reachability and equivalence properties on the specified protocol, either using PROVERIF, TAMARIN or DEEPSEC. Moreover, the soundness of the translation allows to directly assume results proven by another tool which allows to exploit the respective strengths of each tool. We demonstrate our approach by analyzing various existing models. This includes a large case study of the 5G authentication protocols, previously analyzed in TAMARIN. Encoding this model in SAPIC+ we demonstrate the effectiveness of our approach. Moreover, we study four new case studies: the LAKE-EDHOC and the Privacy-Pass protocols, both under standardization, the SSH protocol with the agent-forwarding feature, and the recent KEMTLS protocol, a post-quantum version of the main TLS key exchange.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-cheval.pdf",
            "keywords": [
                "Protocol Verification",
                "SAPIC+",
                "TAMARIN",
                "5G Authentication",
                "Post-Quantum Cryptography"
            ]
        },
        "url": "URL#1416877"
    },
    {
        "@score": "1",
        "@id": "1416878",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "183/4920",
                        "text": "Phakpoom Chinprutthiwong"
                    },
                    {
                        "@pid": "312/6561",
                        "text": "Jianwei Huang"
                    },
                    {
                        "@pid": "64/1147",
                        "text": "Guofei Gu"
                    }
                ]
            },
            "title": "SWAPP: A New Programmable Playground for Web Application Security.",
            "venue": "USENIX Security Symposium",
            "pages": "2029-2046",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Chinprutthiwong22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/chinprutthiwong",
            "url": "https://dblp.org/rec/conf/uss/Chinprutthiwong22",
            "abstract": "Client-side web attacks are one of the major battle\ufb01elds for cybercriminals today. To mitigate such attacks, researchers have proposed numerous defenses that can be deployed on a server or client. Server-side defenses can be easily deployed and modi\ufb01ed by web developers, but it lacks the context of client-side attacks such as DOM-XSS attacks. On the other hand, client-side defenses, especially in the form of modi-\ufb01ed browsers or browser extensions, require constant vendor support or user involvement to be up to date. In this work, we explore the feasibility of using a new execution context, the service worker context, as a platform for web security defense development that is programmable, browser agnostic, and runs at the client side without user involvement. To this end, we propose and develop SWAPP (Service Worker APplication Platform), a framework for implementing security mechanisms inside a service worker. As the service worker is supported by most browsers, our framework is compatible with most clients. Furthermore, SWAPP is designed to enable the extensibility and programmability of the apps. We demonstrate the versatility of SWAPP by implementing various apps that can mitigate web attacks including a recent side-channel attack targeting websites that deploy a service worker. SWAPP allows websites to of\ufb02oad a part of the security tasks from the server to the client and also enables the possibility to deploy or retro\ufb01t emerging security features/prototypes before they are of\ufb01cially supported by browsers. Finally, we evaluate the performance overhead of our framework and show that deploying defenses on a service worker is a feasible option.",
            "keywords": [
                "Web Application Security",
                "Service Worker",
                "Client-side Attacks",
                "DOM-XSS",
                "Security Mechanisms"
            ]
        },
        "url": "URL#1416878",
        "sema_paperId": "b494c1a8cf0e229b7fc5340faaa179b0cb4ee1df"
    },
    {
        "@score": "1",
        "@id": "1416880",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "25/3543",
                        "text": "Andrew Chu"
                    },
                    {
                        "@pid": "331/2639",
                        "text": "Arjun Arunasalam"
                    },
                    {
                        "@pid": "202/6743",
                        "text": "Muslum Ozgur Ozmen"
                    },
                    {
                        "@pid": "143/2298",
                        "text": "Z. Berkay Celik"
                    }
                ]
            },
            "title": "Behind the Tube: Exploitative Monetization of Content on YouTube.",
            "venue": "USENIX Security Symposium",
            "pages": "2171-2188",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChuAOC22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/chu",
            "url": "https://dblp.org/rec/conf/uss/ChuAOC22",
            "abstract": "The YouTube video sharing platform is a prominent online presence that delivers various genres of content to society today. As the viewership and userbase of the platform grow, both individual users and larger companies have recognized the potential for monetizing this content. While content monetization is a native capability of the YouTube service, a number of requirements are enforced on the platform to prevent its abuse. Yet, methods to circumvent these requirements exist; many of which are potentially harmful to viewers and other users. In this paper, we present the \ufb01rst comprehensive study on exploitative monetization of content on YouTube . To do this, we \ufb01rst create two datasets; one using thousands of user posts from eleven forums whose users discuss monetization on YouTube , and one using listing data from \ufb01ve active sites that facilitate the purchase and sale of YouTube accounts. We then perform both manual and automated analysis to develop a view of illicit monetization exploits used on YouTube by both individual users and larger channel collectives. We discover six distinct exploits used to execute illicit content monetization on YouTube ; four used by individual users, and two used by channel collectives. Further, we identify real-world evidence of each exploit on YouTube message board communities and provide insight into how each is executed. Through this, we present a comprehensive view of illicit monetization exploits on the YouTube platform that can motivate future investigation into mitigating these harmful endeavors.",
            "keywords": [
                "YouTube Monetization",
                "Content Exploitation",
                "Illicit Monetization",
                "User-generated Content",
                "Monetization Exploits"
            ]
        },
        "url": "URL#1416880",
        "sema_paperId": "119452d3e90b119808a1f9dde7f7978f02f8c4d1"
    },
    {
        "@score": "1",
        "@id": "1416881",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "232/1974",
                        "text": "Kaleigh Clary"
                    },
                    {
                        "@pid": "20/9799",
                        "text": "Emma Tosch"
                    },
                    {
                        "@pid": "178/1987",
                        "text": "Jeremiah Onaolapo"
                    },
                    {
                        "@pid": "38/828",
                        "text": "David D. Jensen"
                    }
                ]
            },
            "title": "Stick It to The Man: Correcting for Non-Cooperative Behavior of Subjects in Experiments on Social Networks.",
            "venue": "USENIX Security Symposium",
            "pages": "3771-3788",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ClaryTOJ22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/clary",
            "url": "https://dblp.org/rec/conf/uss/ClaryTOJ22",
            "abstract": "A large body of research in network and social sciences studies the effects of interventions in network systems. Nearly all of this work assumes that network participants will respond to interventions in similar ways. However, in real-world systems, a subset of participants may respond in ways purposefully different than their true outcome. We characterize the in\ufb02uence of non-cooperative nodes and the bias these nodes introduce in estimates of average treatment effect (ATE). In addition to theoretical bounds, we empirically demonstrate estimation bias through experiments on synthetically generated graphs and a real-world network. We demonstrate that causal estimates in networks can be sensitive to the actions of non-cooperative members, and we identify network structures that are particularly vulnerable to non-cooperative responses. Our work demonstrates a vulnerability in cluster-randomized network A/B testing to manipulation under non-cooperative behavior, particularly for networks with long-tailed degree distributions. We have shown that networks with strong peer effects are susceptible to ATE bias from non-cooperative behavior and identi\ufb01ed forest-\ufb01re models and SBMs as network structures vulnerable to non-cooperative spillover effects. Our experiments using a real-world network show results consistent with our \ufb01ndings in synthetic networks.",
            "keywords": [
                "Social Network Analysis",
                "Non-Cooperative Behavior",
                "Average Treatment Effect",
                "Network Interventions",
                "Causal Estimation Bias"
            ]
        },
        "url": "URL#1416881",
        "sema_paperId": "0dd9cf12fa8e245efa520e1ecd892cec6fac31f6"
    },
    {
        "@score": "1",
        "@id": "1416882",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "270/1642",
                        "text": "Tobias Cloosters"
                    },
                    {
                        "@pid": "331/2527",
                        "text": "Johannes Willbold"
                    },
                    {
                        "@pid": "h/ThorstenHolz",
                        "text": "Thorsten Holz"
                    },
                    {
                        "@pid": "73/7564",
                        "text": "Lucas Davi"
                    }
                ]
            },
            "title": "SGXFuzz: Efficiently Synthesizing Nested Structures for SGX Enclave Fuzzing.",
            "venue": "USENIX Security Symposium",
            "pages": "3147-3164",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CloostersWHD22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/cloosters",
            "url": "https://dblp.org/rec/conf/uss/CloostersWHD22",
            "abstract": "Intel\u2019s Software Guard Extensions (SGX) provide a non-introspectable trusted execution environment (TEE) to protect security-critical code from a potentially malicious OS. This protection can onlybeeffectiveiftheindividualenclavesarese-cure, which is already challenging in regular software, and this becomes even more difficult for enclaves as the entire environment is potentially malicious. As such, many enclaves expose common vulnerabilities, e.g., memory corruption and SGX-specific vulnerabilities like null-pointer dereferences. While fuzzing is a populartechnique to assess the securityofsoftware, dynamically analyzing enclaves is challenging as enclaves are meant to be non-introspectable. Further, they expect an allocated multi-pointer structure as input instead of a plain buffer. In this paper, we present SGXF UZZ , a coverage-guided fuzzer that introduces a novel binary input structure synthesis method to expose enclave vulnerabilities even without source-code access. To obtain code coverage feedback from enclaves, we show how to extract enclave code from distribution formats. We also present an enclave runner that allows execution of the extracted enclave code as a user-space application at native speed, while emulating all relevant environment interactions of the enclave. We use this setup to fuzz enclaves using a state-of-the-artsnapshotfuzzing engine thatdeploys ournovelstructure synthesis stage. This stage synthesizes multi-layer pointer structures and size fields incrementally on-the-fly based on faultsignals. Furthermore,itmatches the expectedinputformat",
            "keywords": [
                "SGX Enclaves",
                "Fuzzing",
                "Vulnerability Detection",
                "Binary Input Structure Synthesis",
                "Memory Corruption"
            ]
        },
        "url": "URL#1416882",
        "sema_paperId": "6cafd9eb8f1fa677c7c3ed65da8c010cfefe87e2"
    },
    {
        "@score": "1",
        "@id": "1416883",
        "info": {
            "authors": {
                "author": {
                    "@pid": "157/0152",
                    "text": "Aloni Cohen"
                }
            },
            "title": "Attacks on Deidentification&apos;s Defenses.",
            "venue": "USENIX Security Symposium",
            "pages": "1469-1486",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Cohen22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/cohen",
            "url": "https://dblp.org/rec/conf/uss/Cohen22",
            "abstract": "Quasi-identifier-based deidentification techniques (QI-deidentification) are widely used in practice, including $k$-anonymity, $\\ell$-diversity, and $t$-closeness. We present three new attacks on QI-deidentification: two theoretical attacks and one practical attack on a real dataset. In contrast to prior work, our theoretical attacks work even if every attribute is a quasi-identifier. Hence, they apply to $k$-anonymity, $\\ell$-diversity, $t$-closeness, and most other QI-deidentification techniques. First, we introduce a new class of privacy attacks called downcoding attacks, and prove that every QI-deidentification scheme is vulnerable to downcoding attacks if it is minimal and hierarchical. Second, we convert the downcoding attacks into powerful predicate singling-out (PSO) attacks, which were recently proposed as a way to demonstrate that a privacy mechanism fails to legally anonymize under Europe's General Data Protection Regulation. Third, we use LinkedIn.com to reidentify 3 students in a $k$-anonymized dataset published by EdX (and show thousands are potentially vulnerable), undermining EdX's claimed compliance with the Family Educational Rights and Privacy Act. The significance of this work is both scientific and political. Our theoretical attacks demonstrate that QI-deidentification may offer no protection even if every attribute is treated as a quasi-identifier. Our practical attack demonstrates that even deidentification experts acting in accordance with strict privacy regulations fail to prevent real-world reidentification. Together, they rebut a foundational tenet of QI-deidentification and challenge the actual arguments made to justify the continued use of $k$-anonymity and other QI-deidentification techniques.",
            "keywords": [
                "Deidentification Techniques",
                "Quasi-Identifiers",
                "Privacy Attacks",
                "Reidentification",
                "k-Anonymity"
            ]
        },
        "url": "URL#1416883",
        "sema_paperId": "784de911b3cc582776a0dc26501a0e440ba11851"
    },
    {
        "@score": "1",
        "@id": "1416884",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "146/6045",
                        "text": "Kovila P. L. Coopamootoo"
                    },
                    {
                        "@pid": "162/1901",
                        "text": "Maryam Mehrnezhad"
                    },
                    {
                        "@pid": "127/2330",
                        "text": "Ehsan Toreini"
                    }
                ]
            },
            "title": "&quot;I feel invaded, annoyed, anxious and I may protect myself&quot;: Individuals&apos; Feelings about Online Tracking and their Protective Behaviour across Gender and Country.",
            "venue": "USENIX Security Symposium",
            "pages": "287-304",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CoopamootooMT22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/coopamootoo",
            "url": "https://dblp.org/rec/conf/uss/CoopamootooMT22",
            "abstract": "Online tracking is a primary concern for Internet users, yet previous research has not found a clear link between the cognitive understanding of tracking and protective actions. We postulate that protective behaviour follows affective evaluation of tracking. We conducted an online study, with N=614 participants, across the UK, Germany and France, to investigate how users feel about third-party tracking and what protective actions they take. We found that most participants' feelings about tracking were negative, described as deeply intrusive - beyond the informational sphere, including feelings of annoyance and anxiety, that predict protective actions. We also observed indications of a `privacy gender gap', where women feel more negatively about tracking, yet are less likely to take protective actions, compared to men. And less UK individuals report negative feelings and protective actions, compared to those from Germany and France. This paper contributes insights into the affective evaluation of privacy threats and how it predicts protective behaviour. It also provides a discussion on the implications of these findings for various stakeholders, make recommendations and outline avenues for future work.",
            "keywords": [
                "Online Tracking",
                "Privacy Concerns",
                "Protective Behavior",
                "Gender Differences",
                "Affective Evaluation"
            ]
        },
        "url": "URL#1416884",
        "sema_paperId": "bf1e0c1593528467d0d59a354d1e0486c9c6d856"
    },
    {
        "@score": "1",
        "@id": "1416885",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "88/8709",
                        "text": "Alejandro Cuevas"
                    },
                    {
                        "@pid": "264/2681",
                        "text": "Fieke Miedema"
                    },
                    {
                        "@pid": "133/3572",
                        "text": "Kyle Soska"
                    },
                    {
                        "@pid": "c/NicolasChristin",
                        "text": "Nicolas Christin"
                    },
                    {
                        "@pid": "224/9337",
                        "text": "Rolf van Wegberg"
                    }
                ]
            },
            "title": "Measurement by Proxy: On the Accuracy of Online Marketplace Measurements.",
            "venue": "USENIX Security Symposium",
            "pages": "2153-2170",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CuevasMSCW22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/cuevas",
            "url": "https://dblp.org/rec/conf/uss/CuevasMSCW22",
            "abstract": "A number of recent studies have investigated online anonymous (\u201cdark web\u201d) marketplaces. Almost all leverage a \u201cmeasurement-by-proxy\u201d design, in which researchers scrape market public pages, and take buyer reviews as a proxy for actual transactions, to gain insights into market size and revenue. Yet, we do not know if and how this method biases results. We build a framework to reason about marketplace measurement accuracy, and use it to contrast estimates projected from scrapes of Hansa Market with data from a back-end database seized by the police. We further investigate, by simulation, the impact of scraping frequency, consistency and rate-limits. We \ufb01nd that, even with a decent scraping regimen, one might miss approximately 46% of objects \u2013 with scraped listings differing signi\ufb01cantly from not-scraped listings on price, views and product categories. This bias also impacts revenue calculations. We \ufb01nd Hansa\u2019s total market revenue to be US $50M, which projections based on our scrapes un-derestimate by a factor of four. Simulations further show that studies based on one or two scrapes are likely to suffer from a very poor coverage (on average, 14% to 30%, respectively).",
            "keywords": [
                "Online Marketplaces",
                "Measurement Accuracy",
                "Data Scraping",
                "Revenue Estimation",
                "Market Size Bias"
            ]
        },
        "url": "URL#1416885",
        "sema_paperId": "70e164807dfa0460c88d6ea3e2b6cdc31ae240ce"
    },
    {
        "@score": "1",
        "@id": "1416886",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "215/3493",
                        "text": "Miles Dai"
                    },
                    {
                        "@pid": "224/9301",
                        "text": "Riccardo Paccagnella"
                    },
                    {
                        "@pid": "331/2499",
                        "text": "Miguel Gomez-Garcia"
                    },
                    {
                        "@pid": "80/1983",
                        "text": "John D. McCalpin"
                    },
                    {
                        "@pid": "137/0590",
                        "text": "Mengjia Yan 0001"
                    }
                ]
            },
            "title": "Don&apos;t Mesh Around: Side-Channel Attacks and Mitigations on Mesh Interconnects.",
            "venue": "USENIX Security Symposium",
            "pages": "2857-2874",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DaiPGMY22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/dai",
            "url": "https://dblp.org/rec/conf/uss/DaiPGMY22",
            "abstract": "This paper studies microarchitectural side-channel attacks and mitigations on the on-chip mesh interconnect used in modern, server-class Intel processors. We \ufb01nd that, though dif\ufb01cult to exploit, the mesh interconnect can be abused by an adversary even when known attack vectors inside the cores and caches are closed . We then present novel, non-invasive mitigation mechanisms to interconnect side-channel attacks and offer insights to guide the design of future defenses. Our analysis starts by thoroughly reverse engineering the mesh interconnect to reveal, for the \ufb01rst time, the precise conditions under which it is susceptible to contention. We show that an attacker can use these conditions to build a cross-core covert channel with a capacity of over 1.5 Mbps. We then demonstrate the feasibility of side-channel attacks that leak keys from vulnerable cryptographic implementations by monitoring mesh interconnect contention. Finally, we present an analytical model to quantify the vulnerability levels of different victim and attacker placements on the chip and use the results to design a software-only mitigation mechanism.",
            "keywords": [
                "Mesh Interconnect Security",
                "Side-Channel Attacks",
                "Microarchitectural Vulnerabilities",
                "Covert Channels",
                "Mitigation Mechanisms"
            ]
        },
        "url": "URL#1416886",
        "sema_paperId": "e876cd58c4fc0a7b1a5c96bb0e3bebc2e8339bcb"
    },
    {
        "@score": "1",
        "@id": "1416887",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "219/7484",
                        "text": "Savino Dambra"
                    },
                    {
                        "@pid": "165/2039",
                        "text": "Iskander S\u00e1nchez-Rola"
                    },
                    {
                        "@pid": "15/6037",
                        "text": "Leyla Bilge"
                    },
                    {
                        "@pid": "56/490",
                        "text": "Davide Balzarotti"
                    }
                ]
            },
            "title": "When Sally Met Trackers: Web Tracking From the Users&apos; Perspective.",
            "venue": "USENIX Security Symposium",
            "pages": "2189-2206",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DambraSBB22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/dambra",
            "url": "https://dblp.org/rec/conf/uss/DambraSBB22",
            "abstract": "Web tracking has evolved to become a norm on the Internet. As a matter of fact, the web tracking market has grown to raise billions of dollars. Privacy cautious web practitioners and researchers extensively studied the phenomenon proving how widespread this practice is, and providing effective solutions to give users the option of feeling private while freely sur\ufb01ng the web. However, because all those studies looked at this trend only from the trackers\u2019 perspective, still there are a lot of unknowns regarding what the real impact of tracking is on real users. Our goal with this paper is to \ufb01ll this gap in the web tracking topic. Thanks to logs of web browsing telemetry, we were able to look at this trend from the users\u2019 eyes. Precisely, we measure how fast a user encounters trackers and research on options to reduce her privacy risk. Moreover, we also estimate the fraction of browsing histories that are known by trackers and discuss two tracking strategies to increase the existing knowledge about users.",
            "keywords": [
                "Web Tracking",
                "User Privacy",
                "Telemetry Analysis",
                "Tracking Strategies",
                "User Encounter with Trackers"
            ]
        },
        "url": "URL#1416887",
        "sema_paperId": "39cc21bc9fb455b7cea8dd2f16bee0100c17fba0"
    },
    {
        "@score": "1",
        "@id": "1416888",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "154/4512",
                        "text": "Pubali Datta"
                    },
                    {
                        "@pid": "251/3349",
                        "text": "Isaac Polinsky"
                    },
                    {
                        "@pid": "331/2710",
                        "text": "Muhammad Adil Inam"
                    },
                    {
                        "@pid": "126/3601",
                        "text": "Adam Bates 0001"
                    },
                    {
                        "@pid": "22/4463",
                        "text": "William Enck"
                    }
                ]
            },
            "title": "ALASTOR: Reconstructing the Provenance of Serverless Intrusions.",
            "venue": "USENIX Security Symposium",
            "pages": "2443-2460",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DattaPI0E22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/datta",
            "url": "https://dblp.org/rec/conf/uss/DattaPI0E22",
            "abstract": "Serverless computing has freed developers from the burden of managing their own platform and infrastructure, allowing them to rapidly prototype and deploy applications. Despite its surging popularity, however, serverless raises a number of concerning security implications. Among them is the dif\ufb01-culty of investigating intrusions \u2013 by decomposing traditional applications into ephemeral re-entrant functions, serverless has enabled attackers to conceal their activities within legitimate work\ufb02ows, and even prevent root cause analysis by abusing warm container reuse policies to break causal paths. Unfortunately, neither traditional approaches to system auditing nor commercial serverless security products provide the transparency needed to accurately track these novel threats. In this work, we propose A LASTOR , a provenance-based auditing framework that enables precise tracing of suspicious events in serverless applications. A LASTOR records function activity at both system and application layers to capture a holistic picture of each function instances\u2019 behavior. It then aggregates provenance from different functions at a central repository within the serverless platform, stitching it together to produce a global data provenance graph of complex function work\ufb02ows. A LASTOR is both function and language-agnostic, and can easily be integrated into existing serverless platforms with minimal modi\ufb01cation. We implement A LAS TOR for the OpenFaaS platform and evaluate its performance using the well-established Nordstrom Hello,Retail! application, discovering in the process that A LASTOR imposes man-ageable overheads (13.74%), in exchange for signi\ufb01cantly improved forensic capabilities as compared to commercially-available monitoring tools. To our knowledge, A LASTOR is the \ufb01rst auditing framework speci\ufb01cally designed to satisfy the operational requirements of serverless platforms.",
            "keywords": [
                "Serverless Computing",
                "Intrusion Detection",
                "Provenance Tracking",
                "Auditing Framework",
                "Function Workflows"
            ]
        },
        "url": "URL#1416888",
        "sema_paperId": "019763af2d67a89ffe15b6e2024a865d2371ff87"
    },
    {
        "@score": "1",
        "@id": "1416889",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "220/2573",
                        "text": "G\u00f6k\u00e7en Yilmaz Dayanikli"
                    },
                    {
                        "@pid": "141/0814",
                        "text": "Sourav Sinha"
                    },
                    {
                        "@pid": "202/5665",
                        "text": "Devaprakash Muniraj"
                    },
                    {
                        "@pid": "73/1832",
                        "text": "Ryan M. Gerdes"
                    },
                    {
                        "@pid": "26/6376",
                        "text": "Mazen Farhood"
                    },
                    {
                        "@pid": "13/2750",
                        "text": "Mani Mina"
                    }
                ]
            },
            "title": "Physical-Layer Attacks Against Pulse Width Modulation-Controlled Actuators.",
            "venue": "USENIX Security Symposium",
            "pages": "953-970",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DayanikliSMGFM22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/dayanikli",
            "url": "https://dblp.org/rec/conf/uss/DayanikliSMGFM22",
            "abstract": "Cyber-physical systems (CPS) consist of integrated compu-tational and physical components. The dynamics of physical components (e.g., a robot arm) are controlled by actuators via actuation signals. In this work, we analyze the extent to which intentional electromagnetic interference (IEMI) allows an attacker to alter the actuation signal to jam or control a class of widely used actuators: those that use pulse width modulation (PWM) to encode actuation data (e.g., rotation angle or speed). A theory of False Actuation Injection (FAI) is developed and experimentally validated with IEMI waveforms of certain frequencies and modulations. Speci\ufb01cally, three attack waveforms, denoted as Block , Block & Rotate , and Full Control , are described that can be utilized by an attacker to block (denial of service) or alter the actuation data encoded in the PWM signal sent by an actuator\u2019s legitimate controller. The ef\ufb01cacy of the attack waveforms is evaluated against several PWM-controlled actuators, and it is observed that an attacker can implement denial-of-service attacks on all the tested actuators with Block waveform. Additionally, attackers can take control of servo motors from speci\ufb01c manufacturers (Futaba and HiTec) with reported Block & Rotate , and Full Control waveforms. A coupling model between the attack apparatus and victim PWM-based control system is presented to show that the attacker can utilize magnetic, resonant coupling to mount attacks at an appreciable distance. Indoor and in-\ufb02ight attacks are demonstrated on the actuators of an unmanned aerial vehicle (UAV), the effects of which are shown to seriously impact the safe operation of said UAV, e.g., change in the \ufb02ight trajectory.",
            "keywords": [
                "Cyber-Physical Systems",
                "Pulse Width Modulation",
                "Intentional Electromagnetic Interference",
                "False Actuation Injection",
                "Denial of Service Attacks"
            ]
        },
        "url": "URL#1416889",
        "sema_paperId": "6f32c08cebe96521e803656625e8ec5a97ff3d76"
    },
    {
        "@score": "1",
        "@id": "1416892",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "268/8322",
                        "text": "Maya Dotan"
                    },
                    {
                        "@pid": "228/7799",
                        "text": "Saar Tochner"
                    },
                    {
                        "@pid": "92/4269",
                        "text": "Aviv Zohar"
                    },
                    {
                        "@pid": "84/7357",
                        "text": "Yossi Gilad"
                    }
                ]
            },
            "title": "Twilight: A Differentially Private Payment Channel Network.",
            "venue": "USENIX Security Symposium",
            "pages": "555-570",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DotanTZG22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/dotan",
            "url": "https://dblp.org/rec/conf/uss/DotanTZG22",
            "abstract": "Payment channel networks (PCNs) provide a faster and cheaper alternative to transactions recorded on the blockchain. Clients can trustlessly establish payment channels with relays by locking coins and then send signed payments that shift coin balances over the network's channels. Although payments are never published, anyone can track a client's payment by monitoring changes in coin balances over the network's channels. We present Twilight, the first PCN that provides a rigorous differential privacy guarantee to its users. Relays in Twilight run a noisy payment processing mechanism that hides the payments they carry. This mechanism increases the relay's cost, so Twilight combats selfish relays that wish to avoid it, using a trusted execution environment (TEE) that ensures they follow its protocol. The TEE does not store the channel's state, which minimizes the trusted computing base. Crucially, Twilight ensures that even if a relay breaks the TEE's security, it cannot break the integrity of the PCN. We analyze Twilight in terms of privacy and cost and study the trade-off between them. We implement Twilight using Intel's SGX framework and evaluate its performance using relays deployed on two continents. We show that a route consisting of 4 relays handles 820 payments/sec.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-dotan.pdf",
            "keywords": [
                "Payment Channel Networks",
                "Differential Privacy",
                "Trusted Execution Environment",
                "Payment Processing",
                "Relay Cost"
            ]
        },
        "url": "URL#1416892"
    },
    {
        "@score": "1",
        "@id": "1416893",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "126/6581",
                        "text": "Yufei Du"
                    },
                    {
                        "@pid": "219/9076",
                        "text": "Zhuojia Shen"
                    },
                    {
                        "@pid": "208/7376",
                        "text": "Komail Dharsee"
                    },
                    {
                        "@pid": "00/5012-22",
                        "text": "Jie Zhou 0022"
                    },
                    {
                        "@pid": "17/9458",
                        "text": "Robert J. Walls"
                    },
                    {
                        "@pid": "03/2122",
                        "text": "John Criswell"
                    }
                ]
            },
            "title": "Holistic Control-Flow Protection on Real-Time Embedded Systems with Kage.",
            "venue": "USENIX Security Symposium",
            "pages": "2281-2298",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DuSD0WC22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/du",
            "url": "https://dblp.org/rec/conf/uss/DuSD0WC22",
            "abstract": "This paper presents Kage : a system that protects the control data of both application and kernel code on microcontroller-based embedded systems. Kage consists of a Kage-compliant embedded OS that stores all control data in separate memory regions from untrusted data, a compiler that transforms code to protect these memory regions ef\ufb01ciently and to add forward-edge control-\ufb02ow integrity checks, and a secure API that allows safe updates to the protected data. We implemented Kage as an extension to FreeRTOS, an embedded real-time operating system. We evaluated Kage\u2019s performance using the CoreMark benchmark. Kage incurred a 5.2% average runtime overhead and 49.8% code size overhead. Furthermore, the code size overhead was only 14.2% when compared to baseline FreeRTOS with the MPU enabled. We also evaluated Kage\u2019s security guarantees by measuring and analyzing reachable code-reuse gadgets. Compared to FreeRTOS, Kage reduces the number of reachable gadgets from 2,276 to 27, and the remaining 27 gadgets cannot be stitched together to launch a practical attack.",
            "keywords": [
                "Embedded Systems Security",
                "Control-Flow Integrity",
                "Microcontroller Protection",
                "Kage System",
                "Real-Time Operating System"
            ]
        },
        "url": "URL#1416893",
        "sema_paperId": "c65f3b0e900cfd25169bbc7b8afd7bb10c7b5519"
    },
    {
        "@score": "1",
        "@id": "1416894",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "224/2019",
                        "text": "Agnieszka Dutkowska-Zuk"
                    },
                    {
                        "@pid": "222/1799",
                        "text": "Austin Hounsel"
                    },
                    {
                        "@pid": "331/2830",
                        "text": "Amy Morrill"
                    },
                    {
                        "@pid": "259/2395",
                        "text": "Andre Xiong"
                    },
                    {
                        "@pid": "c/MarshiniChetty",
                        "text": "Marshini Chetty"
                    },
                    {
                        "@pid": "87/840",
                        "text": "Nick Feamster"
                    }
                ]
            },
            "title": "How and Why People Use Virtual Private Networks.",
            "venue": "USENIX Security Symposium",
            "pages": "3451-3465",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Dutkowska-ZukHM22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/dutkowska-zuk",
            "url": "https://dblp.org/rec/conf/uss/Dutkowska-ZukHM22",
            "abstract": "Virtual Private Networks (VPNs) are often used to protect online users\u2019 privacy, but many VPNs do not guarantee privacy and may even compromise user privacy through leakage of traf\ufb01c \ufb02ows, data collection and sharing, and so forth. In this paper, we aim to understand the extent to which people are aware of privacy and security risks when using VPNs, as well as how they use and adopt VPNs in the \ufb01rst place. To do so, we conducted a study of 729 VPN users in the United States about their VPN usage habits and preferences. Our study comprised 32 in-person interviews with university students, a survey of 349 university students and a survey of 348 general VPN users on Proli\ufb01c. We present three \ufb01ndings. First, although a general population of VPN users primarily use VPNs to improve privacy and security, students are addi-tionally concerned with access to content (e.g., circumvention of geographic restrictions). Second, both groups concluded that VPNs collect data about them, exposing gaps in both mental models about how VPNs work and awareness of the risks of data collection. Finally, most users learned about VPNs in high school or college and use free VPNs but feel safer using VPNs provided by their institutions. These results could form the basis of future research, awareness campaigns, and regulatory activity.",
            "keywords": [
                "Virtual Private Networks",
                "User Privacy",
                "Data Collection",
                "VPN Awareness",
                "Content Access"
            ]
        },
        "url": "URL#1416894",
        "sema_paperId": "c05673a10838f2163dd9b118d7f8fa902680be75"
    },
    {
        "@score": "1",
        "@id": "1416895",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "303/6604",
                        "text": "Catherine Easdon"
                    },
                    {
                        "@pid": "08/1117-1",
                        "text": "Michael Schwarz 0001"
                    },
                    {
                        "@pid": "223/9857",
                        "text": "Martin Schwarzl"
                    },
                    {
                        "@pid": "166/1494",
                        "text": "Daniel Gruss"
                    }
                ]
            },
            "title": "Rapid Prototyping for Microarchitectural Attacks.",
            "venue": "USENIX Security Symposium",
            "pages": "3861-3877",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Easdon0SG22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/easdon",
            "url": "https://dblp.org/rec/conf/uss/Easdon0SG22",
            "abstract": "In recent years, microarchitectural attacks have been demonstrated to be a powerful attack class. However, as our em-pirical analysis shows, there are numerous implementation challenges that hinder discovery and subsequent mitigation of these vulnerabilities. In this paper, we examine the attack development process, the features and usability of existing tools, and the real-world challenges faced by practitioners. We propose a novel approach to microarchitectural attack development, based on rapid prototyping , and present two open-source software frameworks, libtea and SCFirefox , that improve upon state-of-the-art tooling to facilitate rapid prototyping of attacks. libtea demonstrates that native code attacks can be abstracted suf\ufb01ciently to permit cross-platform implementations while retaining \ufb01ne-grained control of microarchitectural behavior. We evaluate its effectiveness by developing proof-of-concept Foreshadow and LVI attacks. Our LVI prototype runs on x86-64 and ARMv8-A, and is the \ufb01rst public demonstration of LVI on ARM. SCFirefox is the \ufb01rst tool for browser-based microarchitectural attack development, providing the functionality of libtea in JavaScript. This functionality can then be used to iteratively port a prototype to unmodi\ufb01ed browsers. We demonstrate this process by prototyping the \ufb01rst browser-based ZombieLoad attack and deriving a vanilla JavaScript and WebAssembly PoC running in an unmodi\ufb01ed recent version of Firefox. We discuss how libtea and SCFirefox contribute to the security landscape by providing attack researchers and defenders with frameworks to prototype attacks and assess their feasibility.",
            "keywords": [
                "Microarchitectural Attacks",
                "Rapid Prototyping",
                "Attack Development",
                "libtea",
                "SCFirefox"
            ]
        },
        "url": "URL#1416895",
        "sema_paperId": "1a0b3258f669d0682e26b7af8a74ba9052dd9b17"
    },
    {
        "@score": "1",
        "@id": "1416896",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "296/2087",
                        "text": "Pengcheng Fang"
                    },
                    {
                        "@pid": "29/5999-8",
                        "text": "Peng Gao 0008"
                    },
                    {
                        "@pid": "186/0772",
                        "text": "Changlin Liu"
                    },
                    {
                        "@pid": "44/2529",
                        "text": "Erman Ayday"
                    },
                    {
                        "@pid": "36/10085",
                        "text": "Kangkook Jee"
                    },
                    {
                        "@pid": "12/2633-6",
                        "text": "Ting Wang 0006"
                    },
                    {
                        "@pid": "07/4509",
                        "text": "Yanfang (Fanny) Ye"
                    },
                    {
                        "@pid": "69/11514",
                        "text": "Zhuotao Liu"
                    },
                    {
                        "@pid": "13/9656",
                        "text": "Xusheng Xiao"
                    }
                ]
            },
            "title": "Back-Propagating System Dependency Impact for Attack Investigation.",
            "venue": "USENIX Security Symposium",
            "pages": "2461-2478",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Fang0LAJ0YLX22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/fang",
            "url": "https://dblp.org/rec/conf/uss/Fang0LAJ0YLX22",
            "abstract": "Causality analysis on system auditing data has emerged as an important solution for attack investigation. Given a POI (Point-Of-Interest) event (e.g., an alert fired on a suspicious file creation), causality analysis constructs a dependency graph, in which nodes represent system entities (e.g., processes and files) and edges represent dependencies among entities, to reveal the attack sequence. However, causality analysis often produces a huge graph (> 100,000 edges) that is hard for security analysts to inspect. From the dependency graphs of various attacks, we observe that (1) dependencies that are highly related to the POI event often exhibit a different set of properties (e.g., data flow and time) from the less-relevant dependencies; (2) the POI event is often related to a few attack entries (e.g., downloading a file). Based on these insights, we propose DEPIMPACT, a framework that identifies the critical component of a dependency graph (i.e., a subgraph) by (1) assigning discriminative dependency weights to edges to distinguish critical edges that represent the attack sequence from less-important dependencies, (2) propagating dependency impacts backward from the POI event to entry points, and (3) performing forward causality analysis from the top-ranked entry nodes based on their dependency impacts to filter out edges that are not found in the forward causality analysis. Our evaluations on the 150 million real system auditing events of real attacks and the DARPA TC dataset show that DEPIMPACT can significantly reduce the large dependency graphs (\u223c 1,000,000 edges) to a small graph (\u223c 234 edges), which is 4611\u00d7 smaller. The comparison with the other state-of-the-art causality analysis techniques shows that DEPIMPACT is 106\u00d7 more effective in reducing the dependency graphs while preserving the attack sequences.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-fang.pdf",
            "keywords": [
                "Causality Analysis",
                "Dependency Graphs",
                "Attack Investigation",
                "Dependency Impact",
                "Security Auditing"
            ]
        },
        "url": "URL#1416896"
    },
    {
        "@score": "1",
        "@id": "1416898",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "53/8376",
                        "text": "Xuewei Feng"
                    },
                    {
                        "@pid": "181/2688-2",
                        "text": "Qi Li 0002"
                    },
                    {
                        "@pid": "30/3530-1",
                        "text": "Kun Sun 0001"
                    },
                    {
                        "@pid": "31/8302",
                        "text": "Zhiyun Qian"
                    },
                    {
                        "@pid": "73/860",
                        "text": "Gang Zhao"
                    },
                    {
                        "@pid": "18/1267",
                        "text": "Xiaohui Kuang"
                    },
                    {
                        "@pid": "274/0756",
                        "text": "Chuanpu Fu"
                    },
                    {
                        "@pid": "181/2626-2",
                        "text": "Ke Xu 0002"
                    }
                ]
            },
            "title": "Off-Path Network Traffic Manipulation via Revitalized ICMP Redirect Attacks.",
            "venue": "USENIX Security Symposium",
            "pages": "2619-2636",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Feng00QZKF022",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/feng",
            "url": "https://dblp.org/rec/conf/uss/Feng00QZKF022",
            "abstract": "ICMP redirect is a mechanism that allows an end host to dynamically update its routing decisions for particular destinations. Previous studies show that ICMP redirect may be exploited by attackers to manipulate the routing of victim traffic. However, it is widely believed that ICMP redirect attacks are not a real-world threat since they can only occur under specific network topologies (e.g., LAN). In this paper, we conduct a systematic study on the legitimacy check mechanism of ICMP and uncover a fundamental gap between the check mechanism and stateless protocols, resulting in a wide range of vulnerabilities. In particular, we find that off-path attackers can utilize a suite of stateless protocols (e.g., UDP, ICMP, GRE, IPIP and SIT) to easily craft evasive ICMP error messages, thus revitalizing ICMP redirect attacks to cause serious damage in the real world, particularly, on the wide-area network. First, we show that off-path attackers can conduct a stealthy DoS attack by tricking various public servers on the Internet into mis-redirecting their traffic into black holes with a single forged ICMP redirect message. For example, we reveal that more than 43K popular websites on the Internet are vulnerable to this DoS attack. In addition, we identify 54.47K open DNS resolvers and 186 Tor nodes on the Internet are vulnerable as well. Second, we show that, by leveraging ICMP redirect attacks against NATed networks, off-path attackers in the same NATed network can perform a man-in-the-middle",
            "keywords": [
                "ICMP Redirect Attacks",
                "Off-Path Attacks",
                "Network Traffic Manipulation",
                "Denial of Service (DoS)",
                "Man-in-the-Middle (MitM)"
            ]
        },
        "url": "URL#1416898",
        "sema_paperId": "2e7e58ac5fedacd53dd400f9392b1ad707554fd8"
    },
    {
        "@score": "1",
        "@id": "1416899",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "30/6251",
                        "text": "Chong Fu"
                    },
                    {
                        "@pid": "139/6932-2",
                        "text": "Xuhong Zhang 0002"
                    },
                    {
                        "@pid": "07/8388",
                        "text": "Shouling Ji"
                    },
                    {
                        "@pid": "50/415",
                        "text": "Jinyin Chen"
                    },
                    {
                        "@pid": "96/10278",
                        "text": "Jingzheng Wu"
                    },
                    {
                        "@pid": "47/401",
                        "text": "Shanqing Guo"
                    },
                    {
                        "@pid": "99/3847-11",
                        "text": "Jun Zhou 0011"
                    },
                    {
                        "@pid": "l/AlexXLiu",
                        "text": "Alex X. Liu"
                    },
                    {
                        "@pid": "12/2633-6",
                        "text": "Ting Wang 0006"
                    }
                ]
            },
            "title": "Label Inference Attacks Against Vertical Federated Learning.",
            "venue": "USENIX Security Symposium",
            "pages": "1397-1414",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Fu0JCWG0L022",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/fu-chong",
            "url": "https://dblp.org/rec/conf/uss/Fu0JCWG0L022",
            "abstract": "As the initial variant of federated learning (FL), horizontal federated learning (HFL) applies to the situations where datasets share the same feature space but differ in the sample space, e.g., the collaboration between two regional banks, while trending vertical federated learning (VFL) deals with the cases where datasets share the same sample space but differ in the feature space, e.g., the collaboration between a bank and an e-commerce platform.Although various attacks have been proposed to evaluate the privacy risks of HFL, yet, few studies, if not none, have explored that for VFL. Considering that the typical application scenario of VFL is that a few participants (usually two) collaboratively train a machine learning (ML) model with features distributed among them but labels owned by only one of them, protecting the privacy of the labels owned by one participant should be a fundamental guarantee provided by VFL, as the labels might be highly sensitive, e.g., whether a person has a certain kind of disease. However, we discover that the bottom model structure and the gradient update mechanism of VFL can be exploited by a malicious participant to gain the power to infer the privately owned labels. Worse still, by abusing the bottom model, he/she can even infer labels beyond the training dataset. Based on our findings, we propose a set of novel label inference attacks against VFL. Our experiments show that the proposed attacks achieve an outstanding performance. We further share our insights and discuss possible defenses. Our research can shed light on the hidden privacy risks of VFL and pave the way for new research directions towards more secure VFL.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-fu-chong.pdf",
            "keywords": [
                "Vertical Federated Learning",
                "Label Inference Attacks",
                "Privacy Risks",
                "Collaborative Machine Learning",
                "Sensitive Data Protection"
            ]
        },
        "url": "URL#1416899"
    },
    {
        "@score": "1",
        "@id": "1416900",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "238/1872",
                        "text": "Qi-An Fu"
                    },
                    {
                        "@pid": "183/0980",
                        "text": "Yinpeng Dong"
                    },
                    {
                        "@pid": "26/5371-6",
                        "text": "Hang Su 0006"
                    },
                    {
                        "@pid": "50/2644-1",
                        "text": "Jun Zhu 0001"
                    },
                    {
                        "@pid": "94/3019-8",
                        "text": "Chao Zhang 0008"
                    }
                ]
            },
            "title": "AutoDA: Automated Decision-based Iterative Adversarial Attacks.",
            "venue": "USENIX Security Symposium",
            "pages": "3557-3574",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/FuD00022",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/fu-qi",
            "url": "https://dblp.org/rec/conf/uss/FuD00022",
            "abstract": "Adversarial attacks can fool deep learning models by imposing imperceptible perturbations onto natural examples, which have provoked concerns in various security-sensitive applications. Among them, decision-based black-box attacks are practical yet more challenging, where the adversary can only acquire the final classification labels by querying the target model without access to the model's details. Under this setting, existing works usually rely on heuristics and exhibit unsatisfactory performance in terms of query efficiency and attack success rate. To better understand the rationality of these heuristics and further improve over existing methods, we propose AutoDA to automatically discover decision-based iterative adversarial attack algorithms. In our approach, we construct a generic search space of attack algorithms and develop an efficient search algorithm to explore this space. Although we adopt a small and fast model to efficiently evaluate and discover qualified attack algorithms during the search, extensive experiments demonstrate that the discovered algorithms are simple yet query-efficient when attacking larger models on the CIFAR-10 and ImageNet datasets. They achieve comparable performance with the human-designed state-of-the-art decision-based iterative attack methods consistently.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-fu-qi.pdf",
            "keywords": [
                "Adversarial Attacks",
                "Decision-based Attacks",
                "Black-box Attacks",
                "Query Efficiency",
                "Iterative Adversarial Algorithms"
            ]
        },
        "url": "URL#1416900",
        "sema_paperId": "ea30b28ed0e5fe5b6cda29590a45d7125242f0a2"
    },
    {
        "@score": "1",
        "@id": "1416901",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "218/6805",
                        "text": "Andrea Gadotti"
                    },
                    {
                        "@pid": "217/2259",
                        "text": "Florimond Houssiau"
                    },
                    {
                        "@pid": "303/3273",
                        "text": "Meenatchi Sundaram Muthu Selva Annamalai"
                    },
                    {
                        "@pid": "75/7560",
                        "text": "Yves-Alexandre de Montjoye"
                    }
                ]
            },
            "title": "Pool Inference Attacks on Local Differential Privacy: Quantifying the Privacy Guarantees of Apple&apos;s Count Mean Sketch in Practice.",
            "venue": "USENIX Security Symposium",
            "pages": "501-518",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GadottiHAM22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/gadotti",
            "url": "https://dblp.org/rec/conf/uss/GadottiHAM22",
            "abstract": "Behavioral data generated by users' devices, ranging from emoji use to pages visited, are collected at scale to improve apps and services. These data, however, contain fine-grained records and can reveal sensitive information about individual users. Local differential privacy has been used by companies as a solution to collect data from users while preserving privacy. We here first introduce pool inference attacks, where an adversary has access to a user's obfuscated data, defines pools of objects, and exploits the user's polarized behavior in multiple data collections to infer the user's preferred pool. Second, we instantiate this attack against Count Mean Sketch, a local differential privacy mechanism proposed by Apple and deployed in iOS and Mac OS devices, using a Bayesian model. Using Apple's parameters for the privacy loss $\\varepsilon$, we then consider two specific attacks: one in the emojis setting -- where an adversary aims at inferring a user's preferred skin tone for emojis -- and one against visited websites -- where an adversary wants to learn the political orientation of a user from the news websites they visit. In both cases, we show the attack to be much more effective than a random guess when the adversary collects enough data. We find that users with high polarization and relevant interest are significantly more vulnerable, and we show that our attack is well-calibrated, allowing the adversary to target such vulnerable users. We finally validate our results for the emojis setting using user data from Twitter. Taken together, our results show that pool inference attacks are a concern for data protected by local differential privacy mechanisms with a large $\\varepsilon$, emphasizing the need for additional technical safeguards and the need for more research on how to apply local differential privacy for multiple collections.",
            "keywords": [
                "Local Differential Privacy",
                "Pool Inference Attacks",
                "Count Mean Sketch",
                "User Behavior Analysis",
                "Privacy Vulnerabilities"
            ]
        },
        "url": "URL#1416901",
        "sema_paperId": "14d369add9986cef6ea93dbea1540dabd67a2ad8"
    },
    {
        "@score": "1",
        "@id": "1416902",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "270/8889",
                        "text": "Matheus E. Garbelini"
                    },
                    {
                        "@pid": "274/4313",
                        "text": "Vaibhav Bedi"
                    },
                    {
                        "@pid": "21/7660-1",
                        "text": "Sudipta Chattopadhyay 0001"
                    },
                    {
                        "@pid": "46/3348",
                        "text": "Sumei Sun"
                    },
                    {
                        "@pid": "23/1245",
                        "text": "Ernest Kurniawan"
                    }
                ]
            },
            "title": "BrakTooth: Causing Havoc on Bluetooth Link Manager via Directed Fuzzing.",
            "venue": "USENIX Security Symposium",
            "pages": "1025-1042",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GarbeliniB0SK22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/garbelini",
            "url": "https://dblp.org/rec/conf/uss/GarbeliniB0SK22",
            "abstract": "In this paper we propose, design and evaluate a systematic directed fuzzing framework to automatically discover implementation bugs in arbitrary Bluetooth Classic (BT) devices. The core of our fuzzer is the first over-the-air approach that takes full control of the BT controller baseband from the host. This enables us to intercept and modify arbitrary packets, as well as to inject packets out-of-order in lower layers of closed-source BT stack, i.e., Link Manager Protocol (LMP) and Baseband . To systematically guide our fuzzing process, we propose an extensible and novel rule-based approach to automatically construct the protocol state machine during normal over-the-air communication. In particular, by writing a simple set of rules to identify protocol messages, we can dynamically construct an abstracted protocol state machine, fuzz packets resulting from a state and validate responses from target devices. As of today, we have fuzzed 13 BT devices from 11 vendors and we have discovered a total of 18 unknown implementation flaws, with 24 common vulnerability exposures (CVEs) assigned. Furthermore, our discoveries were awarded with six bug bounties from certain vendors. Finally, to show the broader applicability of our framework beyond BT, we have extended our approach to fuzz other wireless protocols, which additionally revealed 6 unknown bugs in certain Wi-Fi and BLE Host stacks.",
            "keywords": [
                "Bluetooth Security",
                "Directed Fuzzing",
                "Implementation Bugs",
                "Bluetooth Classic Protocol",
                "Link Manager Protocol (LMP)"
            ]
        },
        "url": "URL#1416902",
        "sema_paperId": "428bcaeb7c8ed32b30fcec0604a50aa8828d8f26"
    },
    {
        "@score": "1",
        "@id": "1416903",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "239/7899",
                        "text": "Christine Geeng"
                    },
                    {
                        "@pid": "89/8318",
                        "text": "Mike Harris"
                    },
                    {
                        "@pid": "141/9244",
                        "text": "Elissa M. Redmiles"
                    },
                    {
                        "@pid": "23/2758",
                        "text": "Franziska Roesner"
                    }
                ]
            },
            "title": "&quot;Like Lesbians Walking the Perimeter&quot;: Experiences of U.S. LGBTQ+ Folks With Online Security, Safety, and Privacy Advice.",
            "venue": "USENIX Security Symposium",
            "pages": "305-322",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GeengHRR22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/geeng",
            "url": "https://dblp.org/rec/conf/uss/GeengHRR22",
            "abstract": "Given stigma and threats surrounding being gay or transgender, LGBTQ+ folks often seek support and information on navigating identity and personal (digital and physical) safety. While prior research on digital security advice focused on a general population and general advice, our work focuses on queer security, safety, and privacy advice-seeking to determine population-speci\ufb01c needs and takeaways for broader advice research. We conducted qualitative semi-structured interviews with 14 queer participants diverse across race, age, gender, sexuality, and socioeconomic status. We \ufb01nd that participants turn to their trusted queer support groups for advice, since they often experienced similar threats. We also document reasons that participants sometimes reject advice, including that it would interfere with their material livelihood and their potential to connect with others. Given our results, we recommend that queer-speci\ufb01c and general security and safety advice focus on speci\ufb01city\u2014 why and how\u2014over consistency, because advice cannot be one-size-\ufb01ts-all. We also discuss the value of intersectionality as a framework for understanding vulnerability to harms in security research, since our participants\u2019 overlapping identities affected their threat models and advice perception.",
            "keywords": [
                "LGBTQ+ Digital Safety",
                "Queer Security Advice",
                "Online Privacy",
                "Intersectionality in Security",
                "Advice Rejection in LGBTQ+ Communities"
            ]
        },
        "url": "URL#1416903",
        "sema_paperId": "b50c6a31b7bd9ff1cbfdefacc591c6024899f94e"
    },
    {
        "@score": "1",
        "@id": "1416904",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "98/8283",
                        "text": "Daniel Genkin"
                    },
                    {
                        "@pid": "331/2343",
                        "text": "Noam Nissan"
                    },
                    {
                        "@pid": "180/8190",
                        "text": "Roei Schuster"
                    },
                    {
                        "@pid": "t/EranTromer",
                        "text": "Eran Tromer"
                    }
                ]
            },
            "title": "Lend Me Your Ear: Passive Remote Physical Side Channels on PCs.",
            "venue": "USENIX Security Symposium",
            "pages": "4437-4454",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GenkinNST22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/genkin",
            "url": "https://dblp.org/rec/conf/uss/GenkinNST22",
            "abstract": "We show that built-in sensors in commodity PCs, such as microphones, inadvertently capture electromagnetic side-channel leakage from ongoing computation. Moreover, this information is often conveyed by supposedly-benign channels such as audio recordings and common Voice-over-IP applications, even after lossy compression. Thus, we show, it is possible to conduct physical side-channel attacks on computation by remote and purely passive analysis of commonly-shared channels. These attacks require neither physical proximity (which could be mitigated by distance and shielding), nor the ability to run code on the target or con\ufb01gure its hardware. Consequently, we argue, physical side channels on PCs can no longer be excluded from remote-attack threat models. We analyze the computation-dependent leakage captured by internal microphones, and empirically demonstrate its ef\ufb01-cacy for attacks. In one scenario, an attacker steals the secret ECDSA signing keys of the counterparty in a voice call. In another, the attacker detects what web page their counterparty is loading. In the third scenario, a player in the Counter-Strike online multiplayer game can detect a hidden opponent waiting in ambush, by analyzing how the 3D rendering done by the opponent\u2019s computer induces faint but detectable signals into the opponent\u2019s audio feed.",
            "keywords": [
                "Physical Side Channels",
                "Remote Attacks",
                "Electromagnetic Leakage",
                "Microphone Exploitation",
                "ECDSA Key Theft"
            ]
        },
        "url": "URL#1416904",
        "sema_paperId": "908f02a27703af6c717a55dbfe0884945dae8b5c"
    },
    {
        "@score": "1",
        "@id": "1416905",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "212/6725",
                        "text": "Lukas Giner"
                    },
                    {
                        "@pid": "280/4649",
                        "text": "Andreas Kogler"
                    },
                    {
                        "@pid": "230/4065",
                        "text": "Claudio Canella"
                    },
                    {
                        "@pid": "08/1117-1",
                        "text": "Michael Schwarz 0001"
                    },
                    {
                        "@pid": "166/1494",
                        "text": "Daniel Gruss"
                    }
                ]
            },
            "title": "Repurposing Segmentation as a Practical LVI-NULL Mitigation in SGX.",
            "venue": "USENIX Security Symposium",
            "pages": "3111-3127",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GinerKC0G22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/giner",
            "url": "https://dblp.org/rec/conf/uss/GinerKC0G22",
            "abstract": "Load Value Injection (LVI) uses Meltdown-type data \ufb02ows in Spectre-like confused-deputy attacks. LVI has been demon-strated in practical attacks on Intel SGX enclaves, and con-sequently, mitigations were deployed that incur tremendous overheads of factor 2 to 19. However, as we discover, on \ufb01xed hardware LVI-NULL leakage is still present. Hence, to mitigate LVI-NULL in SGX enclaves on LVI-\ufb01xed CPUs, the expensive mitigations would still be necessary. In this paper, we propose a lightweight mitigation focused on LVI-NULL in SGX, LVI-NULLify. We systematically analyze and categorize LVI-NULL variants. Our analysis reveals that previously proposed mitigations targeting LVI-NULL are not effective. Our novel mitigation addresses this problem by repurposing segmentation, a fast legacy hardware mechanism that x86 already uses for every memory operation. LVI-NULLify consists of a modi\ufb01ed SGX-SDK and a compiler extension which put the enclave in control of LVI-NULL-exploitable memory locations. We evaluate LVI-NULLify on the LVI-\ufb01xed Comet Lake CPU and observe a performance overhead below 10% for the worst case, which is substantially lower than previous defenses with a prohibitive overhead of 1220% in the worst case. We conclude that LVI-NULLify is a practical solution to protect SGX enclaves against LVI-NULL today.",
            "keywords": [
                "Intel SGX",
                "Load Value Injection (LVI)",
                "LVI-NULL Mitigation",
                "Segmentation",
                "Performance Overhead"
            ]
        },
        "url": "URL#1416905",
        "sema_paperId": "00e4e7fd9c1bb2a7a00412571ba09da2d964a91e"
    },
    {
        "@score": "1",
        "@id": "1416906",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "131/7172",
                        "text": "Olga Gkountouna"
                    },
                    {
                        "@pid": "63/4123",
                        "text": "Katerina Doka"
                    },
                    {
                        "@pid": "59/4372",
                        "text": "Mingqiang Xue"
                    },
                    {
                        "@pid": "13/2139",
                        "text": "Jianneng Cao"
                    },
                    {
                        "@pid": "08/5342",
                        "text": "Panagiotis Karras"
                    }
                ]
            },
            "title": "One-off Disclosure Control by Heterogeneous Generalization.",
            "venue": "USENIX Security Symposium",
            "pages": "3363-3377",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GkountounaDXCK22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/gkountouna",
            "url": "https://dblp.org/rec/conf/uss/GkountounaDXCK22",
            "abstract": "How can we orchestrate an one-off sharing of informative data about individuals, while bounding the risk of disclosing sensitive information to an adversary who has access to the global distribution of such information and to personal identifiers? Despite intensive efforts, current privacy protection techniques fall short of this objective. Differential privacy provides strong guarantees regarding the privacy risk incurred by one's participation in the data at the cost of high information loss and is vulnerable to learning-based attacks exploiting correlations among data. Syntactic anonymization bounds the risk on specific sensitive information incurred by data publication, yet typically resorts to a superfluous clustering of individuals into groups that forfeits data utility.In this paper, we develop algorithms for disclosure control that abide to sensitive-information-oriented syntactic privacy guarantees and gain up to 77% in utility against current methods. We achieve this feat by recasting data heterogeneously, via bipartite matching, rather than homogeneously via clustering. We show that our methods resist adversaries who know the employed algorithm and its parameters. Our experimental study featuring synthetic and real data, as well as real learning and data analysis tasks, shows that these methods enhance data utility with a runtime overhead that is small and reducible by data partitioning, while the \u03b2-likeness guarantee with heterogeneous generalization staunchly resists machine-learning-based attacks, hence offers practical value.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-gkountouna.pdf",
            "keywords": [
                "Disclosure Control",
                "Heterogeneous Generalization",
                "Syntactic Privacy",
                "Data Utility",
                "\u03b2-likeness Guarantee"
            ]
        },
        "url": "URL#1416906",
        "sema_paperId": "571328812e53fb4a9ad6ae66c782a028c1a191e7"
    },
    {
        "@score": "1",
        "@id": "1416907",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "192/6848",
                        "text": "Sigmund Albert Gorski III"
                    },
                    {
                        "@pid": "218/1644",
                        "text": "Seaver Thorn"
                    },
                    {
                        "@pid": "22/4463",
                        "text": "William Enck"
                    },
                    {
                        "@pid": "91/8378",
                        "text": "Haining Chen"
                    }
                ]
            },
            "title": "FReD: Identifying File Re-Delegation in Android System Services.",
            "venue": "USENIX Security Symposium",
            "pages": "1525-1542",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GorskiTEC22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/gorski",
            "url": "https://dblp.org/rec/conf/uss/GorskiTEC22",
            "abstract": "The security of the Android platform bene\ufb01ts greatly from a privileged middleware that provides indirect access to protected resources. This architecture is further enhanced by privilege separating functionality into many different services and carefully tuning \ufb01le access control policy to mitigate the impact of software vulnerabilities. However, these services can become confused deputies if they improperly re-delegate \ufb01le access to third-party applications through remote procedure call (RPC) interfaces. In this paper, we propose a static program analysis tool called FR E D, which identi\ufb01es a mapping between Java-based system service RPC interfaces and the \ufb01le paths opened within the Java and C/C++ portions of the service. It then combines the Linux-layer \ufb01le access control policy with the Android-layer permission policy to identify potential \ufb01le re-delegation. We use FR E D to analyze three devices running Android 10 and identify 12 confused deputies that are accessible from third-party applications. These vulnerabilities include \ufb01ve CVEs with moderate severity, demonstrating the utility of semi-automated approaches to discover subtle \ufb02aws in access control enforcement.",
            "keywords": [
                "Android System Services",
                "File Access Control",
                "Confused Deputy Problem",
                "Static Program Analysis",
                "File Re-Delegation Vulnerabilities"
            ]
        },
        "url": "URL#1416907",
        "sema_paperId": "22f8945010b773cd2fc739efae45d22c83129744"
    },
    {
        "@score": "1",
        "@id": "1416908",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "326/7403",
                        "text": "Michele Grisafi"
                    },
                    {
                        "@pid": "02/5804",
                        "text": "Mahmoud Ammar"
                    },
                    {
                        "@pid": "83/563",
                        "text": "Marco Roveri"
                    },
                    {
                        "@pid": "c/BrunoCrispo",
                        "text": "Bruno Crispo"
                    }
                ]
            },
            "title": "PISTIS: Trusted Computing Architecture for Low-end Embedded Systems.",
            "venue": "USENIX Security Symposium",
            "pages": "3843-3860",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GrisafiARC22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/grisafi",
            "url": "https://dblp.org/rec/conf/uss/GrisafiARC22",
            "abstract": "Recently, several hardware-assisted security architectures have been proposed to mitigate the ever-growing cyber-attacks on Internet-connected devices. However, such proposals are not compatible with a large portion of the already deployed resource-constrained embedded devices due to hardware limitations. To \ufb01ll this gap, we propose PISTIS, a pure-software trusted computing architecture for bare-metal low-end embedded devices. PISTIS enables several security services, such as memory isolation, remote attestation and secure code update, while fully supporting critical features such as Direct Memory Access (DMA) and interrupts. PISTIS targets a wide range of embedded devices including those that lack any hardware protection mechanisms, while only requiring a few kilobytes of Flash memory to store its root of trust (RoT) software. The entire architecture of PISTIS is built from the ground up by leveraging memory protection-enabling techniques such as assembly-level code veri\ufb01cation and selective software virtualisation. Most importantly, PISTIS achieves strong security guarantees supported by a formally veri\ufb01ed design. We implement and evaluate PISTIS on MSP430 architecture, showing a reasonable overhead in terms of runtime, memory footprint, and power consumption.",
            "keywords": [
                "Trusted Computing",
                "Embedded Systems",
                "Software Security Architecture",
                "Memory Isolation",
                "Remote Attestation"
            ]
        },
        "url": "URL#1416908",
        "sema_paperId": "305293ec62c93c1411bd789d3bcf182b3a1fe967"
    },
    {
        "@score": "1",
        "@id": "1416909",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "139/2372",
                        "text": "Paul Grubbs"
                    },
                    {
                        "@pid": "256/9241",
                        "text": "Arasu Arun"
                    },
                    {
                        "@pid": "147/0497",
                        "text": "Ye Zhang"
                    },
                    {
                        "@pid": "27/3087",
                        "text": "Joseph Bonneau"
                    },
                    {
                        "@pid": "00/2879",
                        "text": "Michael Walfish"
                    }
                ]
            },
            "title": "Zero-Knowledge Middleboxes.",
            "venue": "USENIX Security Symposium",
            "pages": "4255-4272",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GrubbsAZBW22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/grubbs",
            "url": "https://dblp.org/rec/conf/uss/GrubbsAZBW22",
            "abstract": "This paper initiates research on zero-knowledge middleboxes (ZKMBs). A ZKMB is a network middlebox that enforces network usage policies on encrypted traffic. Clients send the middlebox zero-knowledge proofs that their traffic is policy-compliant; these proofs reveal nothing about the client's communication except that it complies with the policy. We show how to make ZKMBs work with unmodified encrypted-communication protocols (specifically TLS 1.3), making ZKMBs invisible to servers. As a contribution of independent interest, we design optimized zero-knowledge proofs for TLS 1.3 session keys. We apply the ZKMB paradigm to several case studies. Experimental results suggest that in certain settings, performance is in striking distance of practicality; an example is a middlebox that filters domain queries (each query requiring a separate proof) when the client has a long-lived TLS connection with a DNS resolver. In such configurations, the middlebox's overhead is 2\u20135 ms of running time per proof, and client latency to create a proof is several seconds. On the other hand, clients may have to store hundreds of MBs depending on the underlying zero-knowledge proof machinery, and for some applications, latency is tens of seconds.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-grubbs.pdf",
            "keywords": [
                "Zero-Knowledge Proofs",
                "Network Middleboxes",
                "Encrypted Traffic",
                "Policy Compliance",
                "TLS 1.3"
            ]
        },
        "url": "URL#1416909"
    },
    {
        "@score": "1",
        "@id": "1416910",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "06/6808",
                        "text": "Fangming Gu"
                    },
                    {
                        "@pid": "157/1827",
                        "text": "Qingli Guo"
                    },
                    {
                        "@pid": "57/1586",
                        "text": "Lian Li"
                    },
                    {
                        "@pid": "140/5462",
                        "text": "Zhiniang Peng"
                    },
                    {
                        "@pid": "99/2649",
                        "text": "Wei Lin"
                    },
                    {
                        "@pid": "92/1807",
                        "text": "Xiaobo Yang"
                    },
                    {
                        "@pid": "33/10782",
                        "text": "Xiaorui Gong"
                    }
                ]
            },
            "title": "COMRace: Detecting Data Race Vulnerabilities in COM Objects.",
            "venue": "USENIX Security Symposium",
            "pages": "3019-3036",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GuGLPLYG22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/gu-fangming",
            "url": "https://dblp.org/rec/conf/uss/GuGLPLYG22",
            "abstract": "The Microsoft Component Object Model (COM) is the foundation for many key Microsoft technologies and we develop COMRace, the first data race vulnerability detection tool for commercial off-the-shelf COM objects. COMRace targets a severe but previously overlooked flaw in the COM threading model, which makes COM objects prone to data race attacks. In COMRace, we apply static binary analyses to identify thread-unsafe interface methods in off-the-shelf COM binaries, then further verify binary analyses results with automatically synthesized proof-of-concept exploits (PoC). We have applied COMRace to 10,420 registered COM objects on the windows platform and the tool reports 186 vulnerable interface methods. COMRace automatically synthesizes 234 PoCs for 256 selected method pairs (82 unsafe methods) with conflict accesses, and there are 194 PoCs triggering race conditions. Furthermore, 145 PoCs lead to critical memory corruptions, exposing 26 vulnerabilities confirmed by the Common Vulnerabilities and Exposures (CVE) database.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-gu-fangming.pdf",
            "keywords": [
                "COM Object Model",
                "Data Race Vulnerabilities",
                "Thread Safety",
                "Static Binary Analysis",
                "Memory Corruption"
            ]
        },
        "url": "URL#1416910",
        "sema_paperId": "9cde92c1ee8fb6c5bb76f19a528f3a84d7f74a20"
    },
    {
        "@score": "1",
        "@id": "1416911",
        "info": {
            "authors": {
                "author": {
                    "@pid": "h/JAlexHalderman",
                    "text": "J. Alex Halderman"
                }
            },
            "title": "The Antrim County 2020 Election Incident: An Independent Forensic Investigation.",
            "venue": "USENIX Security Symposium",
            "pages": "589-605",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Halderman22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/halderman",
            "url": "https://dblp.org/rec/conf/uss/Halderman22",
            "abstract": "In November 2020, Antrim County, Michigan published unofficial election results that misstated totals in the presidential race and other contests by up to several thousand votes. Antrim subsequently issued a series of corrections, and the certified presidential results were confirmed by a hand count. Nevertheless, Antrim was cited by the President of the United States as evidence of widespread fraud, and it remains a cen-terpiece of conspiracy theories about the 2020 election. At the request of the Michigan Secretary of State and Attorney General, I performed a forensic investigation of the incident. Using data from the election system, I precisely reproduce the major anomalies, explain their cause, and verify that they have been corrected. I also uncover other errors affecting specific down-ballot contests that have not been corrected, despite the unusual attention focused on the results, one of which may have changed the outcome of a local contest. Based on this analysis, I refute misinformation about the incident, concluding that it was not the result of a security breach but rather a series of operator errors compounded by inadequate procedures and insufficiently defensive software design. These events offer lessons for improving election administration and highlight the value of rigorously investigating election technology incidents for enhancing accuracy and public trust.",
            "keywords": [
                "Election Integrity",
                "Forensic Investigation",
                "Antrim County",
                "Voting Errors",
                "Election Administration"
            ]
        },
        "url": "URL#1416911",
        "sema_paperId": "0dcdd3ba951442360af81c03a73a58d3b29a200c"
    },
    {
        "@score": "1",
        "@id": "1416912",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "199/2049",
                        "text": "R. Spencer Hallyburton"
                    },
                    {
                        "@pid": "204/1178",
                        "text": "Yupei Liu"
                    },
                    {
                        "@pid": "207/6576",
                        "text": "Yulong Cao"
                    },
                    {
                        "@pid": "91/584",
                        "text": "Z. Morley Mao"
                    },
                    {
                        "@pid": "74/7446",
                        "text": "Miroslav Pajic"
                    }
                ]
            },
            "title": "Security Analysis of Camera-LiDAR Fusion Against Black-Box Attacks on Autonomous Vehicles.",
            "venue": "USENIX Security Symposium",
            "pages": "1903-1920",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HallyburtonLCMP22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/hallyburton",
            "url": "https://dblp.org/rec/conf/uss/HallyburtonLCMP22",
            "abstract": "To enable safe and reliable decision-making, autonomous vehicles (AVs) feed sensor data to perception algorithms to understand the environment. Sensor fusion with multi-frame tracking is becoming increasingly popular for detecting 3D objects. Thus, in this work, we perform an analysis of camera-LiDAR fusion, in the AV context, under LiDAR spoofing attacks. Recently, LiDAR-only perception was shown vulnerable to LiDAR spoofing attacks; however, we demonstrate these attacks are not capable of disrupting camera-LiDAR fusion. We then define a novel, context-aware attack: frustum attack, and show that out of 8 widely used perception algorithms - across 3 architectures of LiDAR-only and 3 architectures of camera-LiDAR fusion - all are significantly vulnerable to the frustum attack. In addition, we demonstrate that the frustum attack is stealthy to existing defenses against LiDAR spoofing as it preserves consistencies between camera and LiDAR semantics. Finally, we show that the frustum attack can be exercised consistently over time to form stealthy longitudinal attack sequences, compromising the tracking module and creating adverse outcomes on end-to-end AV control.",
            "keywords": [
                "Camera-LiDAR Fusion",
                "Autonomous Vehicles",
                "LiDAR Spoofing Attacks",
                "Frustum Attack",
                "Perception Algorithm Vulnerabilities"
            ]
        },
        "url": "URL#1416912",
        "sema_paperId": "89f623903b3862cacbbd50ef1c8923e482d2a047"
    },
    {
        "@score": "1",
        "@id": "1416913",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "27/4390",
                        "text": "Yi Han"
                    },
                    {
                        "@pid": "51/9597",
                        "text": "Matthew Chan"
                    },
                    {
                        "@pid": "231/1408",
                        "text": "Zahra Aref"
                    },
                    {
                        "@pid": "32/7125",
                        "text": "Nils Ole Tippenhauer"
                    },
                    {
                        "@pid": "89/4316",
                        "text": "Saman A. Zonouz"
                    }
                ]
            },
            "title": "Hiding in Plain Sight? On the Efficacy of Power Side Channel-Based Control Flow Monitoring.",
            "venue": "USENIX Security Symposium",
            "pages": "661-678",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HanCATZ22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/han",
            "url": "https://dblp.org/rec/conf/uss/HanCATZ22",
            "abstract": "Physical side-channel monitoring leverages the physical phenomena produced by a microcontroller (e.g. power consumption or electromagnetic radiation) to monitor program execution for malicious behavior. As such, it offers a promising intrusion detection solution for resource-constrained embedded systems, which are incompatible with conventional security measures. This method is especially relevant in safety and security-critical embedded systems such as in industrial control systems. Side-channel monitoring poses unique challenges for would-be attackers, such as: (1) limiting attack vectors by being physically isolated from the monitored system, (2) monitoring immutable physical side channels with uninterpretable data-driven models, and (3) being speci\ufb01cally trained for the architectures and programs on which they are applied to. As a result, physical side-channel monitors are conventionally believed to provide a high level of security. In this paper, we propose a novel attack to illustrate that, despite the many barriers to attack that side-channel monitoring systems create, they are still vulnerable to adversarial attacks. We present a method for crafting functional malware such that, when injected into a side-channel-monitored system, the detector is not triggered. Our experiments reveal that this attack is robust across detector models and hardware im-plementations. We evaluate our attack on the popular ARM microcontroller platform on several representative programs, demonstrating the feasibility of such an attack and highlighting the need for further research into side-channel monitors.",
            "keywords": [
                "Side-Channel Monitoring",
                "Embedded Systems",
                "Adversarial Attacks",
                "Malware Injection",
                "Control Flow Monitoring"
            ]
        },
        "url": "URL#1416913",
        "sema_paperId": "8a96489b40c8c99a5e15bb33300bf852c7c658e2"
    },
    {
        "@score": "1",
        "@id": "1416914",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "331/2352",
                        "text": "Michael Harrity"
                    },
                    {
                        "@pid": "186/5066",
                        "text": "Kevin Bock 0001"
                    },
                    {
                        "@pid": "331/2449",
                        "text": "Frederick Sell"
                    },
                    {
                        "@pid": "03/6428",
                        "text": "Dave Levin"
                    }
                ]
            },
            "title": "GET /out: Automated Discovery of Application-Layer Censorship Evasion Strategies.",
            "venue": "USENIX Security Symposium",
            "pages": "465-483",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Harrity0SL22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/harrity",
            "url": "https://dblp.org/rec/conf/uss/Harrity0SL22",
            "abstract": "The censorship arms race has recently gone through a transformation, thanks to recent efforts showing that new ways to evade censorship can be discovered in an automated fashion. However, all of these prior automated efforts operate by manipulating TCP/IP headers; while impressive, deploying these have proven challenging, as header modi\ufb01cations often require greater privileges than are available to censorship cir-cumvention apps. In that line of work, the application layer has gone largely unexplored. This is not without reason: the space of application messages is much larger and far less structured than TCP/IP headers. In this paper, we present the \ufb01rst techniques to automate the discovery of new censorship evasion techniques purely in the application layer. We present a general solution and apply it speci\ufb01cally to HTTP and DNS censorship in China, India, and Kazakhstan. Our automated techniques discovered a total of 77 unique evasion strategies for HTTP and 9 for DNS, all of which require only application-layer modi\ufb01cations, making them easier to incorporate into apps and deploy. We analyze these strategies and shed new light into the inner workings of the censors. We \ufb01nd that the success of application-layer strategies can depend heavily on the type and version of the destination server. Surprisingly, a large class of our evasion strategies exploit instances in which censors are more RFC-compliant than popular application servers. We have made our code publicly available.",
            "keywords": [
                "Censorship Evasion",
                "Application Layer",
                "Automated Discovery",
                "HTTP and DNS Censorship",
                "RFC Compliance"
            ]
        },
        "url": "URL#1416914",
        "sema_paperId": "03592c4dc87c063fb0b0252c1ee6eb75da1d2b73"
    },
    {
        "@score": "1",
        "@id": "1416915",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "218/2644",
                        "text": "Ruiwen He"
                    },
                    {
                        "@pid": "39/1697-1",
                        "text": "Xiaoyu Ji 0001"
                    },
                    {
                        "@pid": "04/8388",
                        "text": "Xinfeng Li"
                    },
                    {
                        "@pid": "63/4074",
                        "text": "Yushi Cheng"
                    },
                    {
                        "@pid": "10/3878-1",
                        "text": "Wenyuan Xu 0001"
                    }
                ]
            },
            "title": "&quot;OK, Siri&quot; or &quot;Hey, Google&quot;: Evaluating Voiceprint Distinctiveness via Content-based PROLE Score.",
            "venue": "USENIX Security Symposium",
            "pages": "1131-1148",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/He0LCX22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/he-ruiwen",
            "url": "https://dblp.org/rec/conf/uss/He0LCX22",
            "abstract": "A voiceprint is the distinctive pattern of human voices that is spectrographically produced and has been widely used for authentication in the voice assistants. This paper investigates the impact of speech contents on the distinctiveness of voiceprint, and has obtained answers to three questions by studying 2457 speakers and 14,600,000 test samples: 1) What are the influential factors that determine the distinctiveness of voiceprints? 2) How to quantify the distinctiveness of voiceprints for given words, e.g., wake-up words in commercial voice assistants? 3) How to construct wake-up words whose voiceprints have high distinctiveness levels. To answer those questions, we break down voiceprint into phones, and experimentally obtain the correlation between the false recognition rates and the richness of the phone types, the order, the length, and the elements of the phones. Then, we define PROLE Score that can be easily calculated based on speech content yet can reflect the voice distinctiveness. Under the guidance of PROLE Score, we tested 30 wake-up words of 19 commercial voice assistant products, e.g., \u201cHey, Siri\u201d, \u201cOK, Google\u201d and \u201cNihao, Xiaona\u201d in both English and Chinese. Finally, we provide recommendations for both users and manufacturers, on selecting secure voiceprint words.",
            "keywords": [
                "Voiceprint Distinctiveness",
                "Speech Content Analysis",
                "Wake-up Words",
                "PROLE Score",
                "Voice Assistant Authentication"
            ]
        },
        "url": "URL#1416915",
        "sema_paperId": "5713d218e22a0901d50e4f30c4d187e1430d38fd"
    },
    {
        "@score": "1",
        "@id": "1416916",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "42/963-11",
                        "text": "Liang He 0011"
                    },
                    {
                        "@pid": "70/2543-4",
                        "text": "Hong Hu 0004"
                    },
                    {
                        "@pid": "46/3714",
                        "text": "Purui Su"
                    },
                    {
                        "@pid": "60/3060-1",
                        "text": "Yan Cai 0001"
                    },
                    {
                        "@pid": "99/4951",
                        "text": "Zhenkai Liang"
                    }
                ]
            },
            "title": "FreeWill: Automatically Diagnosing Use-after-free Bugs via Reference Miscounting Detection on Binaries.",
            "venue": "USENIX Security Symposium",
            "pages": "2497-2512",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/He0S0L22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/he-liang",
            "url": "https://dblp.org/rec/conf/uss/He0S0L22",
            "abstract": "Memory-safety issues in operating systems and popular applications are still top security threats. As one widely exploited vulnerability, Use After Free (UAF) resulted in hundreds of new incidents every year. Existing bug diagnosis techniques report the locations that allocate or deallocate the vulnerable object, but cannot provide suf\ufb01cient information for developers to reason about a bug or synthesize a correct patch. In this work, we identi\ufb01ed incorrect reference counting as one common root cause of UAF bugs: if the developer forgets to increase the counter for a newly created reference, the program may prematurely free the actively used object, rendering other references dangling pointers. We call this problem reference miscounting . By proposing an omission-aware counting model, we developed an automatic method, F REE W ILL , to diagnose UAF bugs. F REE W ILL \ufb01rst reproduces a UAF bug and collects related execution trace. Then, it identi\ufb01es the UAF object and related references. Finally, F REE W ILL compares reference operations with our model to detect reference miscounting. We evaluated F REE W ILL on 76 real-world UAF bugs and it successfully con\ufb01rmed reference miscounting as root causes for 48 bugs and dangling usage for 18 bugs. F REE W ILL also identi\ufb01ed \ufb01ve null-pointer deref-erence bugs and failed to analyze \ufb01ve bugs. F REE W ILL can complete its analysis within 15 minutes on average, showing its practicality for diagnosing UAF bugs.",
            "keywords": [
                "Memory Safety",
                "Use After Free (UAF)",
                "Reference Counting",
                "Bug Diagnosis",
                "Reference Miscounting"
            ]
        },
        "url": "URL#1416916",
        "sema_paperId": "12906c0c3a3a5b7c2b7e55051f8a5cd5af022755"
    },
    {
        "@score": "1",
        "@id": "1416917",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "65/425",
                        "text": "Yi He"
                    },
                    {
                        "@pid": "88/8969",
                        "text": "Zhenhua Zou"
                    },
                    {
                        "@pid": "30/3530-1",
                        "text": "Kun Sun 0001"
                    },
                    {
                        "@pid": "69/11514",
                        "text": "Zhuotao Liu"
                    },
                    {
                        "@pid": "181/2626-2",
                        "text": "Ke Xu 0002"
                    },
                    {
                        "@pid": "75/5723-2",
                        "text": "Qian Wang 0002"
                    },
                    {
                        "@pid": "48/4825-1",
                        "text": "Chao Shen 0001"
                    },
                    {
                        "@pid": "95/6543-4",
                        "text": "Zhi Wang 0004"
                    },
                    {
                        "@pid": "181/2688-2",
                        "text": "Qi Li 0002"
                    }
                ]
            },
            "title": "RapidPatch: Firmware Hotpatching for Real-Time Embedded Devices.",
            "venue": "USENIX Security Symposium",
            "pages": "2225-2242",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HeZ0L0000022",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/he-yi",
            "url": "https://dblp.org/rec/conf/uss/HeZ0L0000022",
            "abstract": "Nowadays real-time embedded devices are becoming one main target of cyber attacks. A huge number of embedded devices equipped with outdated \ufb01rmware are subject to various vulnerabilities, but they cannot be timely patched due to two main reasons. First, it is dif\ufb01cult for vendors who have various types of fragmented devices to generate patches for each type of device. Second, it is challenging to deploy patches on many embedded devices without restarting or halting real-time tasks, hindering the patch installation on devices (e.g., industrial control devices) that have high availability requirements. In this paper, we present RapidPatch , a new hotpatching framework to facilitate patch propagation by installing generic patches without disrupting other tasks running on heterogeneous embedded devices. RapidPatch allows RTOS developers to directly release common patches for all downstream devices so that device maintainers can easily generate device-speci\ufb01c patches for different \ufb01rmware. We utilize eBPF virtual machines to execute patches on resource-constrained embedded devices and develop three hotpatching strategies to support hotpatching for all major microcontroller (MCU) architectures. In particular, we propose two types of eBPF patches for different types of vulnerabilities and develop an eBPF patch veri\ufb01er to ensure patch safety. We evaluate RapidPatch with major CVEs on four major RTOSes running on different embedded devices. We \ufb01nd that over 90% vulnerabilities can be hotpatched via RapidPatch . Our system can work on devices with 64 KB or more memory and 64 MHz MCU frequency. The average patch delay is less than 8 \u00b5 s and the overall latency overhead is less than 0.6%.",
            "keywords": [
                "Real-Time Embedded Systems",
                "Firmware Hotpatching",
                "Cybersecurity Vulnerabilities",
                "Patch Propagation",
                "eBPF Virtual Machines"
            ]
        },
        "url": "URL#1416917",
        "sema_paperId": "6b8d68be32cb72e820b3f3011b2f1f4d86d2e6f3"
    },
    {
        "@score": "1",
        "@id": "1416918",
        "info": {
            "authors": {
                "author": {
                    "@pid": "45/1437",
                    "text": "Cormac Herley"
                }
            },
            "title": "Automated Detection of Automated Traffic.",
            "venue": "USENIX Security Symposium",
            "pages": "1615-1632",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Herley22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/herley",
            "url": "https://dblp.org/rec/conf/uss/Herley22",
            "abstract": "We describe a method to separate abuse from legitimate traf\ufb01c when we have categorical features and no labels are available. Our approach hinges on the observation that, if we could locate them, unattacked bins of a categorical feature x would allow us to estimate the benign distribution of any feature that is independent of x . We give an algorithm that \ufb01nds these unattacked bins (if they exist) and show how to build an overall classi\ufb01er that is suitable for very large data volumes and high levels of abuse. The approach is one-sided: our only signi\ufb01cant assumptions about abuse are the existence of unattacked bins, and that distributions of abuse traf\ufb01c do not precisely match those of benign. We evaluate on two datasets: 3 million requests from a web-server dataset and a collection of 5.1 million Twitter accounts crawled using the public API. The results con\ufb01rm that the approach is successful at identifying clusters of automated behaviors. On both problems we easily outperform unsupervised methods such as Isolation Forests, and have comparable performance to Botometer on the Twitter dataset.",
            "keywords": [
                "Automated Traffic Detection",
                "Abuse Detection",
                "Categorical Features",
                "Unattacked Bins",
                "Automated Behaviors"
            ]
        },
        "url": "URL#1416918",
        "sema_paperId": "8ac985d50d33d9d326c2b784316c86290b68c2f9"
    },
    {
        "@score": "1",
        "@id": "1416919",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "144/4431",
                        "text": "Raphael Hiesgen"
                    },
                    {
                        "@pid": "185/0838",
                        "text": "Marcin Nawrocki"
                    },
                    {
                        "@pid": "121/4962",
                        "text": "Alistair King"
                    },
                    {
                        "@pid": "28/5074",
                        "text": "Alberto Dainotti"
                    },
                    {
                        "@pid": "s/TCSchmidt",
                        "text": "Thomas C. Schmidt"
                    },
                    {
                        "@pid": "91/5978",
                        "text": "Matthias W\u00e4hlisch"
                    }
                ]
            },
            "title": "Spoki: Unveiling a New Wave of Scanners through a Reactive Network Telescope.",
            "venue": "USENIX Security Symposium",
            "pages": "431-448",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HiesgenNKDSW22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/hiesgen",
            "url": "https://dblp.org/rec/conf/uss/HiesgenNKDSW22",
            "abstract": "Large-scale Internet scans are a common method to identify victims of a specific attack. Stateless scanning like in ZMap has been established as an efficient approach to probing at Internet scale. Stateless scans, however, need a second phase to perform the attack, which remains invisible to network telescopes that only capture the first incoming packet and is not observed as a related event by honeypots. In this work, we examine Internet-wide scan traffic through Spoki, a reactive network telescope operating in real-time that we design and implement. Spoki responds to asynchronous TCP SYN packets and engages in TCP handshakes initiated in the second phase of two-phase scans. Because it is extremely lightweight it scales to large prefixes where it has the unique opportunity to record the first data sequence submitted within the TCP handshake ACK. We analyze two-phase scanners during a three months period using globally deployed Spoki reactive telescopes as well as flow data sets from IXPs and ISPs. We find that a predominant fraction of TCP SYNs on the Internet has irregular characteristics. Our findings also provide a clear signature of today's scans as: (i) highly targeted, (ii) scanning activities notably vary between regional vantage points, and (iii) a significant share originates from malicious sources.",
            "keywords": [
                "Internet Scanning",
                "Reactive Network Telescope",
                "TCP Handshake Analysis",
                "Two-Phase Scans",
                "Malicious Traffic Identification"
            ]
        },
        "url": "URL#1416919",
        "sema_paperId": "c82accb353686950f05edcbb4bea80143f37f945"
    },
    {
        "@score": "1",
        "@id": "1416920",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "223/6748",
                        "text": "Tomas Hlavacek"
                    },
                    {
                        "@pid": "271/6045",
                        "text": "Philipp Jeitner"
                    },
                    {
                        "@pid": "248/0549",
                        "text": "Donika Mirdita"
                    },
                    {
                        "@pid": "94/7397",
                        "text": "Haya Schulmann"
                    },
                    {
                        "@pid": "90/308",
                        "text": "Michael Waidner"
                    }
                ]
            },
            "title": "Stalloris: RPKI Downgrade Attack.",
            "venue": "USENIX Security Symposium",
            "pages": "4455-4471",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HlavacekJMSW22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/hlavacek",
            "url": "https://dblp.org/rec/conf/uss/HlavacekJMSW22",
            "abstract": "We demonstrate the first downgrade attacks against RPKI. The key design property in RPKI that allows our attacks is the tradeoff between connectivity and security: when networks cannot retrieve RPKI information from publication points, they make routing decisions in BGP without validating RPKI. We exploit this tradeoff to develop attacks that prevent the retrieval of the RPKI objects from the public repositories, thereby disabling RPKI validation and exposing the RPKI-protected networks to prefix hijack attacks.We demonstrate experimentally that at least 47% of the public repositories are vulnerable against a specific version of our attacks, a rate-limiting off-path downgrade attack. We also show that all the current RPKI relying party implementations are vulnerable to attacks by a malicious publication point. This translates to 20.4% of the IPv4 address space.We provide recommendations for preventing our downgrade attacks. However, resolving the fundamental problem is not straightforward: if the relying parties prefer security over connectivity and insist on RPKI validation when ROAs cannot be retrieved, the victim AS may become disconnected from many more networks than just the one that the adversary wishes to hijack. Our work shows that the publication points are a critical infrastructure for Internet connectivity and security. Our main recommendation is therefore that the publication points should be hosted on robust platforms guaranteeing a high degree of connectivity.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-hlavacek.pdf",
            "keywords": [
                "RPKI",
                "Downgrade Attack",
                "BGP Routing",
                "Prefix Hijacking",
                "Publication Points Vulnerability"
            ]
        },
        "url": "URL#1416920"
    },
    {
        "@score": "1",
        "@id": "1416921",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "12/1662",
                        "text": "Viet Tung Hoang"
                    },
                    {
                        "@pid": "30/10768",
                        "text": "Cong Wu"
                    },
                    {
                        "@pid": "78/713-1",
                        "text": "Xin Yuan 0001"
                    }
                ]
            },
            "title": "Faster Yet Safer: Logging System Via Fixed-Key Blockcipher.",
            "venue": "USENIX Security Symposium",
            "pages": "2389-2406",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HoangW022",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/hoang",
            "url": "https://dblp.org/rec/conf/uss/HoangW022",
            "abstract": "System logs are crucial for forensic analysis, but to be useful, they need to be tamper-proof. To protect the logs, a number of secure logging systems have been proposed from both academia and the industry. Unfortunately, except for the recent KennyLoggings construction, all other logging systems are broken by an attack of Paccagnella et al. (CCS 2020). In this work, we build a secure logging system that improves KennyLoggings in several fronts: adoptability, security, and performance. Our key insight for performance gain is to use AES on a fixed, known key. While this trick is widely used in secure distributed computing, this is the first time it has found an application in the area of symmetric-key cryptography.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-hoang.pdf",
            "keywords": [
                "Secure Logging Systems",
                "Tamper-Proof Logs",
                "Forensic Analysis",
                "AES Fixed-Key Blockcipher",
                "KennyLoggings Improvement"
            ]
        },
        "url": "URL#1416921"
    },
    {
        "@score": "1",
        "@id": "1416922",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "163/3603",
                        "text": "Yiqing Hua"
                    },
                    {
                        "@pid": "301/5856",
                        "text": "Armin Namavari"
                    },
                    {
                        "@pid": "290/2358",
                        "text": "Kaishuo Cheng"
                    },
                    {
                        "@pid": "42/241",
                        "text": "Mor Naaman"
                    },
                    {
                        "@pid": "26/3399",
                        "text": "Thomas Ristenpart"
                    }
                ]
            },
            "title": "Increasing Adversarial Uncertainty to Scale Private Similarity Testing.",
            "venue": "USENIX Security Symposium",
            "pages": "1777-1794",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HuaNCNR22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/hua",
            "url": "https://dblp.org/rec/conf/uss/HuaNCNR22",
            "abstract": "Social media and other platforms rely on automated detection of abusive content to help combat disinformation, harassment, and abuse. One common approach is to check user content for similarity against a server-side database of problematic items. However, this method fundamentally endangers user privacy. Instead, we target client-side detection, notifying only the users when such matches occur to warn them against abusive content. Our solution is based on privacy-preserving similarity testing. Existing approaches rely on expensive cryptographic protocols that do not scale well to large databases and may sacrifice the correctness of the matching. To contend with this challenge, we propose and formalize the concept of similarity-based bucketization~(SBB). With SBB, a client reveals a small amount of information to a database-holding server so that it can generate a bucket of potentially similar items. The bucket is small enough for efficient application of privacy-preserving protocols for similarity. To analyze the privacy risk of the revealed information, we introduce a framework for measuring an adversary's confidence in inferring a predicate about the client input correctly. We develop a practical SBB protocol for image content, and evaluate its client privacy guarantee with real-world social media data. We then combine SBB with various similarity protocols, showing that the combination with SBB provides a speedup of at least 29x on large-scale databases compared to that without, while retaining correctness of over 95%.",
            "keywords": [
                "Privacy-Preserving Similarity Testing",
                "Client-Side Detection",
                "Adversarial Uncertainty",
                "Similarity-Based Bucketization",
                "Content Moderation"
            ]
        },
        "url": "URL#1416922",
        "sema_paperId": "01b5855bcd91511abf4db74c4d305ff20bb66913"
    },
    {
        "@score": "1",
        "@id": "1416923",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "128/9270",
                        "text": "Zhicong Huang"
                    },
                    {
                        "@pid": "231/4234",
                        "text": "Wen-jie Lu"
                    },
                    {
                        "@pid": "78/10002",
                        "text": "Cheng Hong"
                    },
                    {
                        "@pid": "316/4311",
                        "text": "Jiansheng Ding"
                    }
                ]
            },
            "title": "Cheetah: Lean and Fast Secure Two-Party Deep Neural Network Inference.",
            "venue": "USENIX Security Symposium",
            "pages": "809-826",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HuangLHD22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/huang-zhicong",
            "url": "https://dblp.org/rec/conf/uss/HuangLHD22",
            "abstract": "Secure two-party neural network inference (2PC-NN) can offer privacy protection for both the client and the server and is a promising technique in the machine-learning-as-a-service setting. However, the large overhead of the current 2PC-NN inference systems is still being a headache, especially when applied to deep neural networks such as ResNet50. In this work, we present Cheetah, a new 2PC-NN inference system that is faster and more communication-efficient than state-of-the-arts. The main contributions of Cheetah are two-fold: the first part includes carefully designed homomorphic encryption-based protocols that can evaluate the linear layers (namely convolution, batch normalization, and fully-connection) without any expensive rotation operation. The second part includes several lean and communication-efficient primitives for the non-linear functions (e.g., ReLU and truncation). Using Cheetah, we present intensive benchmarks over several large-scale deep neural networks. Take ResNet50 for an example, an end-to-end execution of Cheetah under a WAN setting costs less than 2.5 minutes and 2.3 gigabytes of communication, which outperforms CrypTFlow2 (ACM CCS 2020) by about 5.6\u00d7 and 12.9\u00d7, respectively.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-huang-zhicong.pdf",
            "keywords": [
                "Secure Two-Party Computation",
                "Homomorphic Encryption",
                "Neural Network Inference",
                "Communication Efficiency",
                "Deep Neural Network Performance"
            ]
        },
        "url": "URL#1416923"
    },
    {
        "@score": "1",
        "@id": "1416924",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "244/2598",
                        "text": "Jacob Imola"
                    },
                    {
                        "@pid": "37/9269",
                        "text": "Takao Murakami"
                    },
                    {
                        "@pid": "56/6435",
                        "text": "Kamalika Chaudhuri"
                    }
                ]
            },
            "title": "Communication-Efficient Triangle Counting under Local Differential Privacy.",
            "venue": "USENIX Security Symposium",
            "pages": "537-554",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ImolaMC22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/imola",
            "url": "https://dblp.org/rec/conf/uss/ImolaMC22",
            "abstract": "Triangle counting in networks under LDP (Local Differential Privacy) is a fundamental task for analyzing connection patterns or calculating a clustering coefficient while strongly protecting sensitive friendships from a central server. In particular, a recent study proposes an algorithm for this task that uses two rounds of interaction between users and the server to significantly reduce estimation error. However, this algorithm suffers from a prohibitively high communication cost due to a large noisy graph each user needs to download. In this work, we propose triangle counting algorithms under LDP with a small estimation error and communication cost. We first propose two-rounds algorithms consisting of edge sampling and carefully selecting edges each user downloads so that the estimation error is small. Then we propose a double clipping technique, which clips the number of edges and then the number of noisy triangles, to significantly reduce the sensitivity of each user's query. Through comprehensive evaluation, we show that our algorithms dramatically reduce the communication cost of the existing algorithm, e.g., from 6 hours to 8 seconds or less at a 20 Mbps download rate, while keeping a small estimation error.",
            "keywords": [
                "Local Differential Privacy",
                "Triangle Counting",
                "Communication Efficiency",
                "Edge Sampling",
                "Estimation Error"
            ]
        },
        "url": "URL#1416924",
        "sema_paperId": "573cb04e946265a6d768dbe4292c29704c2baa6c"
    },
    {
        "@score": "1",
        "@id": "1416925",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "295/6488",
                        "text": "Abdullah Imran"
                    },
                    {
                        "@pid": "222/5923",
                        "text": "Habiba Farrukh"
                    },
                    {
                        "@pid": "83/5186",
                        "text": "Muhammad Ibrahim"
                    },
                    {
                        "@pid": "143/2298",
                        "text": "Z. Berkay Celik"
                    },
                    {
                        "@pid": "99/3883",
                        "text": "Antonio Bianchi"
                    }
                ]
            },
            "title": "SARA: Secure Android Remote Authorization.",
            "venue": "USENIX Security Symposium",
            "pages": "1561-1578",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ImranFICB22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/imran",
            "url": "https://dblp.org/rec/conf/uss/ImranFICB22",
            "abstract": "Modern smartphones are equipped with Trusted Execution Environments (TEEs), offering security features resilient even against attackers able to fully compromise the normal operating system (e.g., Linux in Android devices). The academic community, as well as the smartphone manufacturers, have proposed to use TEEs to strengthen the security of authorization protocols. However, the usage of these protocols has been hampered by both practicality issues and lack of completeness in terms of security. To address these issues, in this paper, we design, implement, and evaluate SARA (Secure Android Remote Authorization), an Android library that uses the existing TEE-powered Android APIs to implement secure, end-to-end remote authorization for Android apps. SARA is practical in its design, as it makes use of Android APIs and TEE features that are already present in modern Android devices to implement a novel secure authorization protocol. In fact, SARA does not require any modifications to the Android operating system nor to the code running in TrustZone (the TEE powering existing Android devices). For this reason, it can be readily used in existing apps running on existing smartphones. Moreover, SARA is designed to ensure that even developers that have no experience in implementing security protocols can make use of it within their apps. At the same time, SARA is secure , since it allows implementing authorization protocols that are resilient even against attackers able to achieve root privileges on a compromised Android device. We first evaluate SARA by conducting a user study to ascertain its usability. Then, we prove SARA \u2019s security features by formally verifying its security protocol using ProVerif.",
            "keywords": [
                "Trusted Execution Environments",
                "Android Security",
                "Remote Authorization",
                "End-to-End Security",
                "Usability in Security Protocols"
            ]
        },
        "url": "URL#1416925",
        "sema_paperId": "788e34ead9b4d1305f342bdfde52195c14f32cd1"
    },
    {
        "@score": "1",
        "@id": "1416926",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "08/8604-2",
                        "text": "Umar Iqbal 0002"
                    },
                    {
                        "@pid": "331/2829",
                        "text": "Charlie Wolfe"
                    },
                    {
                        "@pid": "37/3513",
                        "text": "Charles Nguyen"
                    },
                    {
                        "@pid": "137/7764",
                        "text": "Steven Englehardt"
                    },
                    {
                        "@pid": "83/9528",
                        "text": "Zubair Shafiq"
                    }
                ]
            },
            "title": "Khaleesi: Breaker of Advertising and Tracking Request Chains.",
            "venue": "USENIX Security Symposium",
            "pages": "2911-2928",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/IqbalWNES22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/iqbal",
            "url": "https://dblp.org/rec/conf/uss/IqbalWNES22",
            "abstract": "Request chains are being used by advertisers and trackers for information sharing and circumventing recently introduced privacy protections in web browsers. There is little prior work on mitigating the increasing exploitation of request chains by advertisers and trackers. The state-of-the-art ad and tracker blocking approaches lack the necessary context to effectively detect advertising and tracking request chains. We propose K HALEESI , a machine learning approach that captures the essential sequential context needed to effectively detect advertising and tracking request chains. We show that K HALEESI achieves high accuracy, that holds well over time, is generally robust against evasion attempts, and outperforms existing approaches. We also show that K HALEESI is suitable for online deployment and it improves page load performance. Abstract We propose K HALEESI , a machine learning (ML) approach that captures the essential sequential context needed to effectively detect advertising and tracking request chains. We release K HALEESI \u2019s classi\ufb01cation code, ML model, browser extension, and data sets. Classi\ufb01cation code is written in Python 3.6, the ML model is trained using Scikit, the browser extension is written in JavaScript/HTML, and the data is crawled using OpenWPM.",
            "keywords": [
                "Advertising Tracking",
                "Request Chains",
                "Privacy Protections",
                "Machine Learning Detection",
                "K HALEESI"
            ]
        },
        "url": "URL#1416926",
        "sema_paperId": "3eacafe3a5460c5fbab44e65dfa4b5680527f356"
    },
    {
        "@score": "1",
        "@id": "1416927",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "280/7922",
                        "text": "Mohannad Ismail"
                    },
                    {
                        "@pid": "317/5288",
                        "text": "Andrew Quach"
                    },
                    {
                        "@pid": "161/0183",
                        "text": "Christopher Jelesnianski"
                    },
                    {
                        "@pid": "150/5222",
                        "text": "Yeongjin Jang"
                    },
                    {
                        "@pid": "19/10203",
                        "text": "Changwoo Min"
                    }
                ]
            },
            "title": "Tightly Seal Your Sensitive Pointers with PACTight.",
            "venue": "USENIX Security Symposium",
            "pages": "3717-3734",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/IsmailQJJM22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/ismail",
            "url": "https://dblp.org/rec/conf/uss/IsmailQJJM22",
            "abstract": "ARM is becoming more popular in desktops and data centers, opening a new realm in terms of security attacks against ARM. ARM has released Pointer Authentication, a new hardware security feature that is intended to ensure pointer integrity with cryptographic primitives.In this paper, we utilize Pointer Authentication (PA) to build a novel scheme to completely prevent any misuse of security-sensitive pointers. We propose PACTIGHT to tightly seal these pointers. PACTIGHT utilizes a strong and unique modifier that addresses the current issues with the state-of-the-art PA defense mechanisms. We implement four defenses based on the PACTIGHT mechanism. Our security and performance evaluation results show that PACTIGHT defenses are more efficient and secure. Using real PA instructions, we evaluated PACTIGHT on 30 different applications, including NGINX web server, with an average performance overhead of 4.07% even when enforcing our strongest defense. PACTIGHT demonstrates its effectiveness and efficiency with real PA instructions on real hardware.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-ismail.pdf",
            "keywords": [
                "Pointer Authentication",
                "ARM Security",
                "Pointer Integrity",
                "PACTIGHT",
                "Security-Sensitive Pointers"
            ]
        },
        "url": "URL#1416927"
    },
    {
        "@score": "1",
        "@id": "1416928",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "211/5012",
                        "text": "Rawane Issa"
                    },
                    {
                        "@pid": "286/6462",
                        "text": "Nicolas Alhaddad"
                    },
                    {
                        "@pid": "59/6288",
                        "text": "Mayank Varia"
                    }
                ]
            },
            "title": "Hecate: Abuse Reporting in Secure Messengers with Sealed Sender.",
            "venue": "USENIX Security Symposium",
            "pages": "2335-2352",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/IssaAV22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/issa",
            "url": "https://dblp.org/rec/conf/uss/IssaAV22",
            "abstract": "End-to-end encryption provides strong privacy protections to billions of people, but it also complicates efforts to moderate content that can seriously harm people. To address this concern, Tyagi et al. [CRYPTO 2019] introduced the concept of asymmetric message franking (AMF) so that people can report abusive content to a moderator, while otherwise retaining end-to-end privacy by default and compatibility with anonymous communication systems like Signal's sealed sender.\nIn this work, we provide a new construction for asymmetric message franking called Hecate that is faster, more secure, and introduces additional functionality compared to Tyagi et al. First, our construction uses fewer invocations of standardized crypto primitives and operates in the plain model. Second, on top of AMF's accountability and deniability requirements, we also add forward and backward secrecy. Third, we combine AMF with source tracing, another approach to content moderation that has previously been considered only in the setting of non-anonymous networks. Source tracing allows for messages to be forwarded, and a report only identifies the original source who created a message. To provide anonymity for senders and forwarders, we introduce a model of AMF with preprocessing whereby every client authenticates with the moderator out-of-band to receive a token that they later consume when sending a message anonymously.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-issa.pdf",
            "keywords": [
                "End-to-End Encryption",
                "Asymmetric Message Franking",
                "Content Moderation",
                "Abuse Reporting",
                "Source Tracing"
            ]
        },
        "url": "URL#1416928"
    },
    {
        "@score": "1",
        "@id": "1416929",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "291/2820",
                        "text": "Bahruz Jabiyev"
                    },
                    {
                        "@pid": "270/2324",
                        "text": "Steven Sprecher"
                    },
                    {
                        "@pid": "331/2536",
                        "text": "Anthony Gavazzi"
                    },
                    {
                        "@pid": "296/7414",
                        "text": "Tommaso Innocenti"
                    },
                    {
                        "@pid": "77/8031",
                        "text": "Kaan Onarlioglu"
                    },
                    {
                        "@pid": "k/EnginKirda",
                        "text": "Engin Kirda"
                    }
                ]
            },
            "title": "FRAMESHIFTER: Security Implications of HTTP/2-to-HTTP/1 Conversion Anomalies.",
            "venue": "USENIX Security Symposium",
            "pages": "1061-1075",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/JabiyevSGIOK22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/jabiyev",
            "url": "https://dblp.org/rec/conf/uss/JabiyevSGIOK22",
            "abstract": "HTTP/2 adoption is rapidly climbing. However, in practice, Internet communications still rarely happen over end-to-end HTTP/2 channels. This is due to Content Delivery Networks and other reverse proxies, ubiquitous and necessary components of the Internet ecosystem, which only support HTTP/2 on the client\u2019s end, but not the forward connection to the origin server. Instead, proxy technologies predominantly rely on HTTP/2-to-HTTP/1 protocol conversion between the two legs of the connection. We present the \ufb01rst systematic exploration of HTTP/2-to-HTTP/1 protocol conversion anomalies and their security implications. We develop a novel grammar-based fuzzer for HTTP/2, experiment with 12 popular reverse proxy technologies & CDNs through HTTP/2 frame sequence and content manipulation, and discover a plethora of novel web application attack vectors that lead to Request Blackholing, Denial-of-Service, Query-of-Death, and Request Smuggling attacks.",
            "keywords": [
                "HTTP/2 Security",
                "Protocol Conversion",
                "Reverse Proxies",
                "Web Application Attacks",
                "Request Smuggling"
            ]
        },
        "url": "URL#1416929",
        "sema_paperId": "4316d64762302677c48496431a9ca9ed5273402c"
    },
    {
        "@score": "1",
        "@id": "1416930",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "132/6759",
                        "text": "Shubham Jain"
                    },
                    {
                        "@pid": "31/2956-2",
                        "text": "Ana-Maria Cretu 0002"
                    },
                    {
                        "@pid": "75/7560",
                        "text": "Yves-Alexandre de Montjoye"
                    }
                ]
            },
            "title": "Adversarial Detection Avoidance Attacks: Evaluating the robustness of perceptual hashing-based client-side scanning.",
            "venue": "USENIX Security Symposium",
            "pages": "2317-2334",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Jain0M22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/jain",
            "url": "https://dblp.org/rec/conf/uss/Jain0M22",
            "abstract": "End-to-end encryption (E2EE) by messaging platforms en-able people to securely and privately communicate with one another. Its widespread adoption however raised concerns that illegal content might now be shared undetected. Following the global pushback against key escrow systems, client-side scanning based on perceptual hashing has been recently proposed by tech companies, governments and researchers to detect illegal content in E2EE communications. We here propose the \ufb01rst framework to evaluate the robustness of perceptual hashing-based client-side scanning to detection avoidance attacks and show current systems to not be robust. More speci\ufb01cally, we propose three adversarial attacks\u2013a general black-box attack and two white-box attacks for discrete cosine transform-based algorithms\u2013against perceptual hashing algorithms. In a large-scale evaluation, we show perceptual hashing-based client-side scanning mechanisms to be highly vulnerable to detection avoidance attacks in a black-box setting, with more than 99.9% of images successfully attacked while preserving the content of the image. We furthermore show our attack to generate diverse perturbations, strongly suggesting that straightforward mitigation strategies would be ineffective. Finally, we show that the larger thresholds necessary to make the attack harder would probably require more than one billion images to be \ufb02agged and decrypted daily, raising strong privacy concerns. Taken together, our results shed serious doubts on the robustness of perceptual hashing-based client-side scanning mechanisms currently proposed by governments, organizations, and researchers around the world. 1",
            "keywords": [
                "End-to-End Encryption",
                "Client-Side Scanning",
                "Perceptual Hashing",
                "Detection Avoidance Attacks",
                "Robustness Evaluation"
            ]
        },
        "url": "URL#1416930",
        "sema_paperId": "25a97dc25bfe80a465ef6a4f4bbbe42401f777b2"
    },
    {
        "@score": "1",
        "@id": "1416931",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "271/6045",
                        "text": "Philipp Jeitner"
                    },
                    {
                        "@pid": "94/7397",
                        "text": "Haya Schulmann"
                    },
                    {
                        "@pid": "327/7606",
                        "text": "Lucas Teichmann"
                    },
                    {
                        "@pid": "90/308",
                        "text": "Michael Waidner"
                    }
                ]
            },
            "title": "XDRI Attacks - and - How to Enhance Resilience of Residential Routers.",
            "venue": "USENIX Security Symposium",
            "pages": "4473-4490",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/JeitnerSTW22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/jeitner",
            "url": "https://dblp.org/rec/conf/uss/JeitnerSTW22",
            "abstract": "We explore the security of residential routers and find a range of critical vulnerabilities. Our evaluations show that 10 out of 36 popular routers are vulnerable to injections of fake records via misinterpretation of special characters. We also find that in 15 of the 36 routers the mechanisms, that are meant to prevent cache poisoning attacks, can be circumvented.In our Internet-wide study with an advertisement network, we identified and analyzed 976 residential routers used by web clients, out of which more than 95% were found vulnerable to our attacks. Overall, vulnerable routers are prevalent and are distributed among 177 countries and 4830 networks.To understand the core factors causing the vulnerabilities we perform black- and white-box analyses of the routers. We find that many problems can be attributed to incorrect assumptions on the protocols' behaviour and the Internet, misunderstanding of the standard recommendations, bugs, and simplified DNS software implementations.We provide recommendations to mitigate our attacks. We also set up a tool to enable everyone to evaluate the security of their routers at https://xdi-attack.net/.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-jeitner.pdf",
            "keywords": [
                "Residential Router Security",
                "Cache Poisoning",
                "Vulnerability Assessment",
                "DNS Software Implementation",
                "XDRI Attacks"
            ]
        },
        "url": "URL#1416931"
    },
    {
        "@score": "1",
        "@id": "1416932",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "295/0886",
                        "text": "Kaihang Ji"
                    },
                    {
                        "@pid": "04/1346",
                        "text": "Jun Zeng"
                    },
                    {
                        "@pid": "320/8787",
                        "text": "Yuancheng Jiang"
                    },
                    {
                        "@pid": "99/4951",
                        "text": "Zhenkai Liang"
                    },
                    {
                        "@pid": "150/5333",
                        "text": "Zheng Leong Chua"
                    },
                    {
                        "@pid": "90/105",
                        "text": "Prateek Saxena"
                    },
                    {
                        "@pid": "04/5884",
                        "text": "Abhik Roychoudhury"
                    }
                ]
            },
            "title": "FlowMatrix: GPU-Assisted Information-Flow Analysis through Matrix-Based Representation.",
            "venue": "USENIX Security Symposium",
            "pages": "2567-2584",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/JiZJLCSR22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/ji",
            "url": "https://dblp.org/rec/conf/uss/JiZJLCSR22",
            "abstract": "Dynamic Information Flow Tracking (DIFT) forms the foundation of a wide range of security and privacy analysis. The main challenges faced by DIFT techniques are performance and scalability. Due to the large number of states in a program, the number of data flows can be prohibitively large and efficiently performing interactive data flow analysis queries using existing approaches is challenging. In this paper, we identify that DIFT under dependency-based information flow rules can be cast as linear transformations over taint states. This enables a novel matrix-based representation, which we call F LOW M ATRIX , to represent DIFT operations concisely and makes it practical to adopt GPUs as co-processors for DIFT analysis. F LOW M ATRIX provides efficient support for interactive DIFT query operations. We design a DIFT query system and prototype it on commodity GPUs. Our evaluation shows that our prototype outperforms CPU-based baseline by 5.6 times and enables rapid response to DIFT queries. It has two to three orders of magnitude higher throughput compared to typical DIFT analysis solutions. We also demonstrate the efficiency and efficacy of new DIFT query operations.",
            "keywords": [
                "Dynamic Information Flow Tracking",
                "Dependency-Based Information Flow",
                "GPU-Assisted Analysis",
                "Matrix-Based Representation",
                "Interactive Data Flow Queries"
            ]
        },
        "url": "URL#1416932",
        "sema_paperId": "3ba64205dfc2c1963f7060c2855429470eb6ff8d"
    },
    {
        "@score": "1",
        "@id": "1416933",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "231/8643",
                        "text": "Yanxue Jia"
                    },
                    {
                        "@pid": "117/3128-1",
                        "text": "Shifeng Sun 0001"
                    },
                    {
                        "@pid": "23/6726",
                        "text": "Hong-Sheng Zhou"
                    },
                    {
                        "@pid": "232/2136",
                        "text": "Jiajun Du"
                    },
                    {
                        "@pid": "72/1963",
                        "text": "Dawu Gu"
                    }
                ]
            },
            "title": "Shuffle-based Private Set Union: Faster and More Secure.",
            "venue": "USENIX Security Symposium",
            "pages": "2947-2964",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/JiaSZDG22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/jia",
            "url": "https://dblp.org/rec/conf/uss/JiaSZDG22",
            "abstract": "Private Set Union (PSU) allows two players, the sender and the receiver, to compute the union of their input datasets without revealing any more information than the result. While it has found numerous applications in practice, not much research has been carried out so far, especially for large datasets.In this work, we take shuffling technique as a key to design PSU protocols for the first time. By shuffling receiver's set, we put forward the first protocol, denoted as \u03a0R PSU, that eliminates the expensive operations in previous works, such as additive homomorphic encryption and repeated operations on the receiver's set. It outperforms the state-of-the-art design by Kolesnikov et al. (ASIACRYPT 2019) in both efficiency and security; the unnecessary leakage in Kolesnikov et al.'s design, can be avoided in our design.We further extend our investigation to the application scenarios in which both players may hold unbalanced input datasets. We propose our second protocol \u03a0S PSU, by shuffling the sender's dataset. This design can be viewed as a dual version of our first protocol, and it is suitable in the cases where the sender's input size is much smaller than the receiver's.Finally, we implement our protocols \u03a0R PSU and \u03a0S PSU in C++ on big datasets, and perform a comprehensive evaluation in terms of both scalability and parallelizability. The results demonstrate that our design can obtain a 4-5\u00d7 improvement over the state-of-the-art by Kolesnikov et al. with a single thread in WAN/LAN settings.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-jia.pdf",
            "keywords": [
                "Private Set Union",
                "Shuffling Technique",
                "Data Privacy",
                "Protocol Design",
                "Efficiency and Security"
            ]
        },
        "url": "URL#1416933"
    },
    {
        "@score": "1",
        "@id": "1416934",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "205/0183",
                        "text": "Bailey Kacsmar"
                    },
                    {
                        "@pid": "258/4835",
                        "text": "Kyle Tilbury"
                    },
                    {
                        "@pid": "275/2619",
                        "text": "Miti Mazmudar"
                    },
                    {
                        "@pid": "26/5304",
                        "text": "Florian Kerschbaum"
                    }
                ]
            },
            "title": "Caring about Sharing: User Perceptions of Multiparty Data Sharing.",
            "venue": "USENIX Security Symposium",
            "pages": "899-916",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KacsmarTMK22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/kacsmar",
            "url": "https://dblp.org/rec/conf/uss/KacsmarTMK22",
            "abstract": "Data sharing between companies is typically regarded as one-size-\ufb01ts-all in practice and in research. For instance, the main source of information available to users about how a company shares their data is privacy policies. Privacy policies use ambiguous terms such as \u2018third-parties\u2019 and \u2018partners\u2019 with regard to who data is shared with. In the real-world, data sharing has more nuance than is captured by these over-arching terms. We investigate whether users perceive different data sharing scenarios differently through an online survey with scenarios that describe speci\ufb01c types of multiparty data sharing practices. We determine users\u2019 perceptions when explicitly presented with how their data is shared, who it is shared with, and why. We show that users have preferences and that variations in acceptability exist which depend on the nature of the data sharing collaboration. Users caring about sharing, necessitates more transparent sharing practices and regulations.",
            "keywords": [
                "Data Sharing",
                "User Perceptions",
                "Privacy Policies",
                "Multiparty Data Sharing",
                "Transparency in Data Practices"
            ]
        },
        "url": "URL#1416934",
        "sema_paperId": "838c6205566f825fa23382ee505a05b6aa6b2eea"
    },
    {
        "@score": "1",
        "@id": "1416935",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "295/3339",
                        "text": "Rahul Kande"
                    },
                    {
                        "@pid": "309/4549",
                        "text": "Addison Crump"
                    },
                    {
                        "@pid": "232/2300",
                        "text": "Garrett Persyn"
                    },
                    {
                        "@pid": "224/9363",
                        "text": "Patrick Jauernig"
                    },
                    {
                        "@pid": "s/AhmadRezaSadeghi",
                        "text": "Ahmad-Reza Sadeghi"
                    },
                    {
                        "@pid": "255/3072",
                        "text": "Aakash Tyagi"
                    },
                    {
                        "@pid": "79/9006",
                        "text": "Jeyavijayan Rajendran"
                    }
                ]
            },
            "title": "TheHuzz: Instruction Fuzzing of Processors Using Golden-Reference Models for Finding Software-Exploitable Vulnerabilities.",
            "venue": "USENIX Security Symposium",
            "pages": "3219-3236",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KandeCPJSTR22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/kande",
            "url": "https://dblp.org/rec/conf/uss/KandeCPJSTR22",
            "abstract": "The increasing complexity of modern processors poses many challenges to existing hardware verification tools and methodologies for detecting security-critical bugs. Recent attacks on processors have shown the fatal consequences of uncovering and exploiting hardware vulnerabilities. Fuzzing has emerged as a promising technique for detecting software vulnerabilities. Recently, a few hardware fuzzing techniques have been proposed. However, they suffer from several limitations, including non-applicability to commonly used Hardware Description Languages (HDLs) like Verilog and VHDL, the need for significant human intervention, and inability to capture many intrinsic hardware behaviors, such as signal transitions and floating wires. In this paper, we present the design and implementation of a novel hardware fuzzer, TheHuzz, that overcomes the aforementioned limitations and significantly improves the state of the art. We analyze the intrinsic behaviors of hardware designs in HDLs and then measure the coverage metrics that model such behaviors. TheHuzz generates assembly-level instructions to increase the desired coverage values, thereby finding many hardware bugs that are exploitable from software. We evaluate TheHuzz on four popular open-source processors and achieve 1.98x and 3.33x the speed compared to the industry-standard random regression approach and the state-of-the-art hardware fuzzer, DiffuzRTL, respectively. Using TheHuzz, we detected 11 bugs in these processors, including 8 new vulnerabilities, and we demonstrate exploits using the detected bugs. We also show that TheHuzz overcomes the limitations of formal verification tools from the semiconductor industry by comparing its findings to those discovered by the Cadence JasperGold tool.",
            "keywords": [
                "Hardware Fuzzing",
                "Processor Verification",
                "Software-Exploitable Vulnerabilities",
                "Golden-Reference Models",
                "Intrinsic Hardware Behaviors"
            ]
        },
        "url": "URL#1416935",
        "sema_paperId": "9e2300fc8f40b33e11bd2a56da42114e26e0ce3e"
    },
    {
        "@score": "1",
        "@id": "1416936",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "19/10126",
                        "text": "George Kappos"
                    },
                    {
                        "@pid": "220/3348",
                        "text": "Haaroon Yousaf"
                    },
                    {
                        "@pid": "256/5148",
                        "text": "Rainer St\u00fctz"
                    },
                    {
                        "@pid": "321/1763",
                        "text": "Sofia Rollet"
                    },
                    {
                        "@pid": "85/3208",
                        "text": "Bernhard Haslhofer"
                    },
                    {
                        "@pid": "94/8813",
                        "text": "Sarah Meiklejohn"
                    }
                ]
            },
            "title": "How to Peel a Million: Validating and Expanding Bitcoin Clusters.",
            "venue": "USENIX Security Symposium",
            "pages": "2207-2223",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KapposYSRHM22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/kappos",
            "url": "https://dblp.org/rec/conf/uss/KapposYSRHM22",
            "abstract": "One of the defining features of Bitcoin and the thousands of cryptocurrencies that have been derived from it is a globally visible transaction ledger. While Bitcoin uses pseudonyms as a way to hide the identity of its participants, a long line of research has demonstrated that Bitcoin is not anonymous. This has been perhaps best exemplified by the development of clustering heuristics, which have in turn given rise to the ability to track the flow of bitcoins as they are sent from one entity to another. In this paper, we design a new heuristic that is designed to track a certain type of flow, called a peel chain, that represents many transactions performed by the same entity; in doing this, we implicitly cluster these transactions and their associated pseudonyms together. We then use this heuristic to both validate and expand the results of existing clustering heuristics. We also develop a machine learning-based validation method and, using a ground-truth dataset, evaluate all our approaches and compare them with the state of the art. Ultimately, our goal is to not only enable more powerful tracking techniques but also call attention to the limits of anonymity in these systems.",
            "keywords": [
                "Bitcoin Clustering",
                "Transaction Flow Analysis",
                "Peel Chains",
                "Anonymity Limits",
                "Clustering Heuristics"
            ]
        },
        "url": "URL#1416936",
        "sema_paperId": "a758862cfaa09d82c9d6467a0d8608be7a6ac794"
    },
    {
        "@score": "1",
        "@id": "1416937",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "270/2346",
                        "text": "Soroush Karami"
                    },
                    {
                        "@pid": "205/2187",
                        "text": "Faezeh Kalantari"
                    },
                    {
                        "@pid": "287/5804",
                        "text": "Mehrnoosh Zaeifi"
                    },
                    {
                        "@pid": "331/2225",
                        "text": "Xavier J. Maso"
                    },
                    {
                        "@pid": "196/8835",
                        "text": "Erik Trickel"
                    },
                    {
                        "@pid": "129/9582",
                        "text": "Panagiotis Ilia"
                    },
                    {
                        "@pid": "119/7712",
                        "text": "Yan Shoshitaishvili"
                    },
                    {
                        "@pid": "28/8280",
                        "text": "Adam Doup\u00e9"
                    },
                    {
                        "@pid": "47/8412",
                        "text": "Jason Polakis"
                    }
                ]
            },
            "title": "Unleash the Simulacrum: Shifting Browser Realities for Robust Extension-Fingerprinting Prevention.",
            "venue": "USENIX Security Symposium",
            "pages": "735-752",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KaramiKZMTISDP22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/karami",
            "url": "https://dblp.org/rec/conf/uss/KaramiKZMTISDP22",
            "abstract": "Online tracking has garnered signi\ufb01cant attention due to the privacy risk it poses to users. Among the various approaches, techniques that identify which extensions are installed in a browser can be used for \ufb01ngerprinting browsers and tracking users, but also for inferring personal and sensitive user data. While preventing certain \ufb01ngerprinting techniques is relatively simple, mitigating behavior-based extension-\ufb01ngerprinting poses a signi\ufb01cant challenge as it relies on hiding actions that stem from an extension\u2019s functionality. To that end, we introduce the conceptof DOM RealityShifting ,wherebywe splitthe reality users experience while browsing from the reality that webpages can observe. To demonstrate our approach we de-velop Simulacrum, a prototype extension that implements our defense through a targeted instrumentation of core Web API interfaces. Despite being conceptually straightforward, our implementation highlights the technical challenges posed by the complex and often idiosyncratic nature and behavior of web applications, modern browsers, and the JavaScript language. We experimentally evaluate our system against a state-of-the-art DOM-based extension \ufb01ngerprinting system and \ufb01nd that Simulacrum readily protects 95.37% of susceptible extensions. We then identify trivial modi\ufb01cations to extensions that enable our defense for the majority of the remaining extensions. To facilitate additional research and protect users from privacy-invasive behaviors we will open-source our system.",
            "keywords": [
                "Browser Privacy",
                "Extension Fingerprinting",
                "DOM Reality Shifting",
                "User Tracking Prevention",
                "Simulacrum"
            ]
        },
        "url": "URL#1416937",
        "sema_paperId": "07a9fff080a6e7eed0b6c8778517777702e53725"
    },
    {
        "@score": "1",
        "@id": "1416939",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "248/1646",
                        "text": "Ranjita Pai Kasturi"
                    },
                    {
                        "@pid": "151/1951",
                        "text": "Jonathan Fuller"
                    },
                    {
                        "@pid": "15/8685",
                        "text": "Yiting Sun"
                    },
                    {
                        "@pid": "331/2662",
                        "text": "Omar Chabklo"
                    },
                    {
                        "@pid": "331/2512",
                        "text": "Andres Rodriguez 0005"
                    },
                    {
                        "@pid": "163/7414",
                        "text": "Jeman Park 0001"
                    },
                    {
                        "@pid": "150/5240",
                        "text": "Brendan Saltaformaggio"
                    }
                ]
            },
            "title": "Mistrust Plugins You Must: A Large-Scale Study Of Malicious Plugins In WordPress Marketplaces.",
            "venue": "USENIX Security Symposium",
            "pages": "161-178",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KasturiFSCR0S22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/kasturi",
            "url": "https://dblp.org/rec/conf/uss/KasturiFSCR0S22",
            "abstract": "Modern websites owe most of their aesthetics and functionalities to Content Management Systems (CMS) plugins, which are bought and sold on widely popular marketplaces. Driven by economic incentives, attackers abuse the trust in this economy: selling malware on legitimate marketplaces, pirating popular plugins, and infecting plugins post-deployment. This research studied the evolution of CMS plugins in over 400K production webservers dating back to 2012. We developed YODA , an automated framework to detect malicious plugins and track down their origin. YODA uncovered 47,337 malicious plugins on 24,931 unique websites. Among these, $41.5K had been spent on 3,685 malicious plugins sold on legitimate plugin marketplaces. Pirated plugins cheated developers out of $228K in revenues. Post-deployment attacks infected $834K worth of previously benign plugins with malware. Lastly, YODA informs our remediation e\ufb00orts, as over 94% of these malicious plugins are still active today .",
            "keywords": [
                "CMS Plugins",
                "Malicious Software",
                "WordPress Marketplaces",
                "Plugin Security",
                "Post-Deployment Attacks"
            ]
        },
        "url": "URL#1416939",
        "sema_paperId": "433109a78073c48b4f61e1f06829a869a9c58b13"
    },
    {
        "@score": "1",
        "@id": "1416940",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "139/0822",
                        "text": "Harjot Kaur"
                    },
                    {
                        "@pid": "251/3013",
                        "text": "Sabrina Amft"
                    },
                    {
                        "@pid": "61/11094",
                        "text": "Daniel Votipka"
                    },
                    {
                        "@pid": "132/9687",
                        "text": "Yasemin Acar"
                    },
                    {
                        "@pid": "38/9378",
                        "text": "Sascha Fahl"
                    }
                ]
            },
            "title": "Where to Recruit for Security Development Studies: Comparing Six Software Developer Samples.",
            "venue": "USENIX Security Symposium",
            "pages": "4041-4058",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KaurAVAF22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/kaur",
            "url": "https://dblp.org/rec/conf/uss/KaurAVAF22",
            "abstract": "Studying developers is an important aspect of usable security and privacy research. In particular, studying security development challenges such as the usability of security APIs, the secure use of information sources during development or the effectiveness of IDE security plugins raised interest in recent years. However, recruiting skilled participants with software development experience is particularly challenging, and it is often not clear what security researchers can expect from certain participant samples, which can make research results hard to compare and interpret. Hence, in this work, we study for the first time opportunities and challenges of different platforms to recruit participants with software development experience for security development studies. First, we identify popular recruitment platforms in 59 papers. Then, we conduct a comparative online study with 706 participants based on self-reported software development experience across six recruitment platforms. Using an online questionnaire, we investigate participants' programming and security experiences, skills and knowledge. We find that participants across all samples report rich general software development and security experience, skills, and knowledge. Based on our results, we recommend developer recruitment from Upwork for practical coding studies and Amazon MTurk along with a pre-screening survey to reduce additional noise for larger studies. Both of these, along with Freelancer, are also recommended for security studies. We conclude the paper by discussing the impact of our results on future security development studies.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-kaur.pdf",
            "keywords": [
                "Usable Security",
                "Software Development",
                "Participant Recruitment",
                "Security Development Studies",
                "Recruitment Platforms"
            ]
        },
        "url": "URL#1416940",
        "sema_paperId": "63597b40893fe6c8201e78a16b9a2198515d3453"
    },
    {
        "@score": "1",
        "@id": "1416941",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "218/7156",
                        "text": "Mahimna Kelkar"
                    },
                    {
                        "@pid": "252/4143",
                        "text": "Phi Hung Le"
                    },
                    {
                        "@pid": "07/5590-1",
                        "text": "Mariana Raykova 0001"
                    },
                    {
                        "@pid": "125/0309",
                        "text": "Karn Seth"
                    }
                ]
            },
            "title": "Secure Poisson Regression.",
            "venue": "USENIX Security Symposium",
            "pages": "791-808",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KelkarL0S22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/kelkar",
            "url": "https://dblp.org/rec/conf/uss/KelkarL0S22",
            "abstract": "We introduce the first construction for secure two-party computation of Poisson regression, which enables two parties who hold shares of the input samples to learn only the resulting Poisson model while protecting the privacy of the inputs.Our construction relies on new protocols for secure fixed-point exponentiation and correlated matrix multiplications. Our secure exponentiation construction avoids expensive bit decomposition and achieves orders of magnitude improvement in both online and offline costs over state of the art works. As a result, the dominant cost for our secure Poisson regression are matrix multiplications with one fixed matrix. We introduce a new technique, called correlated Beaver triples, which enables many such multiplications at the cost of roughly one matrix multiplication. This further brings down the cost of secure Poisson regression.We implement our constructions and show their extreme efficiency. In a LAN setting, our secure exponentiation for 20-bit fractional precision takes less than 0.07ms with a batch-size of 100,000. One iteration of secure Poisson regression on a dataset with 10,000 samples with 1000 binary features needs about 65.82s in the offline phase, 55.14s in the online phase and 17MB total communication. For several real datasets this translates into training that takes seconds and only a couple of MB communication.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-kelkar.pdf",
            "keywords": [
                "Secure Two-Party Computation",
                "Poisson Regression",
                "Privacy-Preserving Machine Learning",
                "Correlated Matrix Multiplications",
                "Fixed-Point Exponentiation"
            ]
        },
        "url": "URL#1416941"
    },
    {
        "@score": "1",
        "@id": "1416942",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "16/5689",
                        "text": "Sunwoo Kim"
                    },
                    {
                        "@pid": "61/9605",
                        "text": "Young Min Kim"
                    },
                    {
                        "@pid": "263/9985",
                        "text": "Jaewon Hur"
                    },
                    {
                        "@pid": "278/0329",
                        "text": "Suhwan Song"
                    },
                    {
                        "@pid": "173/9806",
                        "text": "Gwangmu Lee"
                    },
                    {
                        "@pid": "45/7986",
                        "text": "Byoungyoung Lee"
                    }
                ]
            },
            "title": "FuzzOrigin: Detecting UXSS vulnerabilities in Browsers through Origin Fuzzing.",
            "venue": "USENIX Security Symposium",
            "pages": "1008-1023",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KimKHSLL22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/kim",
            "url": "https://dblp.org/rec/conf/uss/KimKHSLL22",
            "abstract": "Universal cross-site scripting (UXSS) is a browser vulnerability, making a vulnerable browser execute an attacker's script on any web pages loaded by the browser. UXSS is considered a far more severe vulnerability than well-studied cross-site scripting (XSS). This is because the impact of UXSS is not limited to a web application, but it impacts each and every web application as long as a victim user runs a vulnerable browser. We find that UXSS vulnerabilities are difficult to find, especially through fuzzing, for the following two reasons. First, it is challenging to detect UXSS because it is a semantic vulnerability. In order to detect UXSS, one needs to understand the complex interaction semantics between web pages. Second, it is difficult to generate HTML inputs that trigger UXSS since one needs to drive the browser to perform complex interactions and navigations.This paper proposes FuzzOrigin, a browser fuzzer designed to detect UXSS vulnerabilities. FuzzOrigin addresses the above two challenges by (i) designing an origin sanitizer with a static origin tagging mechanism and (ii) prioritizing origin-update operations through generating chained-navigation operations handling dedicated events. We implemented FuzzOrigin, which works with most modern browsers, including Chrome, Firefox, Edge, and Safari. During the evaluation, FuzzOrigin discovered four previously unknown UXSS vulnerabilities, one in Chrome and three in Firefox, all of which have been confirmed by the vendors. FuzzOrigin is responsible for finding one out of two UXSS vulnerabilities in Chrome reported in 2021 and all three in Firefox, highlighting its strong effectiveness in finding new UXSS vulnerabilities.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-kim.pdf",
            "keywords": [
                "Browser Security",
                "Universal Cross-Site Scripting",
                "Fuzzing",
                "Vulnerability Detection",
                "Origin Fuzzing"
            ]
        },
        "url": "URL#1416942",
        "sema_paperId": "bce412847e2a7f0b74e42998e3d2acad2d2709e2"
    },
    {
        "@score": "1",
        "@id": "1416944",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "280/4649",
                        "text": "Andreas Kogler"
                    },
                    {
                        "@pid": "166/1494",
                        "text": "Daniel Gruss"
                    },
                    {
                        "@pid": "08/1117-1",
                        "text": "Michael Schwarz 0001"
                    }
                ]
            },
            "title": "Minefield: A Software-only Protection for SGX Enclaves against DVFS Attacks.",
            "venue": "USENIX Security Symposium",
            "pages": "4147-4164",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KoglerG022",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/kogler-minefield",
            "url": "https://dblp.org/rec/conf/uss/KoglerG022",
            "abstract": "Modern CPUs adapt clock frequencies and voltage levels to workloads to reduce energy consumption and heat dissipa-tion. This mechanism, dynamic voltage and frequency scaling (DVFS), is controlled from privileged software but affects all execution modes, including SGX. Prior work showed that manipulating voltage or frequency can fault instructions and thereby subvert SGX enclaves. Consequently, Intel disabled the overclocking mailbox (OCM) required for software undervolting, also preventing benign use for energy saving. In this paper, we propose Mine\ufb01eld, the \ufb01rst software-level defense against DVFS attacks. The idea of Mine\ufb01eld is not to prevent DVFS faults but to de\ufb02ect faults to trap instructions and handle them before they lead to harmful behavior. As groundwork for Mine\ufb01eld, we systematically analyze DVFS attacks and observe a timing gap of at least 57 . 8 \u00b5s between every OCM transition, leading to random faults over at least 57 000 cycles. Mine\ufb01eld places highly fault-susceptible trap instructions in the victim code during compilation. Like redundancy countermeasures, Mine\ufb01eld is scalable and enables enclave developers to choose a security parameter between 0 % and almost 100 %, yielding a \ufb01ne-grained security-performance trade-off. Our evaluation shows a density of 0 . 75, i.e. , one trap after every 1-2 instruction, mitigates all known DVFS attacks in 99 % on Intel SGX, incurring an overhead of 148 . 4 % on protected enclaves. However, Mine\ufb01eld has no performance effect on the remaining system. Thus, Mine\ufb01eld is a better solution than hardware- or microcode-based patches disabling the OCM interface.",
            "keywords": [
                "SGX Enclaves",
                "DVFS Attacks",
                "Fault Tolerance",
                "Minefield Defense",
                "Security-Performance Trade-off"
            ]
        },
        "url": "URL#1416944",
        "sema_paperId": "291322e7d3e24536cb0e85872fcd0cda2d25297e"
    },
    {
        "@score": "1",
        "@id": "1416945",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "280/4649",
                        "text": "Andreas Kogler"
                    },
                    {
                        "@pid": "207/7615",
                        "text": "Jonas Juffinger"
                    },
                    {
                        "@pid": "305/3800",
                        "text": "Salman Qazi"
                    },
                    {
                        "@pid": "70/4287",
                        "text": "Yoongu Kim"
                    },
                    {
                        "@pid": "172/1127",
                        "text": "Moritz Lipp"
                    },
                    {
                        "@pid": "06/7654",
                        "text": "Nicolas Boichat"
                    },
                    {
                        "@pid": "73/1243",
                        "text": "Eric Shiu"
                    },
                    {
                        "@pid": "54/7509",
                        "text": "Mattias Nissler"
                    },
                    {
                        "@pid": "166/1494",
                        "text": "Daniel Gruss"
                    }
                ]
            },
            "title": "Half-Double: Hammering From the Next Row Over.",
            "venue": "USENIX Security Symposium",
            "pages": "3807-3824",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KoglerJQKLBSNG22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/kogler-half-double",
            "url": "https://dblp.org/rec/conf/uss/KoglerJQKLBSNG22",
            "abstract": "Rowhammer is a vulnerability in modern DRAM where repeated accesses to one row (the aggressor) give off electrical disturbance whose cumulative effect flips the bits in an adjacent row (the victim). Consequently, Rowhammer defenses presuppose the adjacency of aggressor-victim pairs, including those in LPDDR4 and DDR4, most notably TRR. In this paper, we present Half-Double 1 , an escalation of Rowhammer to rows beyond immediate neighbors. Using Half-Double, we induce errors in a victim by combining many accesses to a distance-2 row with just a few to a distance-1 row. Our experiments show that the cumulative effect of these leads to a sufficient electrical disturbance in the victim row, inducing bit flips. We demonstrate the practical relevance of Half-Double in a proof-of-concept attack on a fully up-to-date system. We use side channels, a new technique called Blind-Hammering , a new spraying technique, and a Spectre attack in our end-to-end Half-Double Attack. On recent Chromebooks with ECC-and TRR-protected LPDDR4x memory, the attack takes less than 45 minutes on average.",
            "keywords": [
                "Rowhammer Vulnerability",
                "DRAM Memory",
                "Bit Flips",
                "Half-Double Attack",
                "Electrical Disturbance"
            ]
        },
        "url": "URL#1416945",
        "sema_paperId": "ec2be980333c82b6bf97c8f84e747560fe919828"
    },
    {
        "@score": "1",
        "@id": "1416946",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "155/5132",
                        "text": "Katharina Kohls"
                    },
                    {
                        "@pid": "d/ClaudiaDiaz",
                        "text": "Claudia D\u00edaz"
                    }
                ]
            },
            "title": "VerLoc: Verifiable Localization in Decentralized Systems.",
            "venue": "USENIX Security Symposium",
            "pages": "2637-2654",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KohlsD22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/kohls",
            "url": "https://dblp.org/rec/conf/uss/KohlsD22",
            "abstract": "We tackle the challenge of reliably determining the geo-location of nodes in decentralized networks, considering adversarial settings and without depending on any trusted landmarks. In particular, we consider active adversaries that control a subset of nodes, announce false locations and strategically manipulate measurements. To address this problem we propose, implement and evaluate VerLoc, a system that allows verifying the claimed geo-locations of network nodes in a fully decentralized manner. VerLoc securely schedules roundtrip time (RTT) measurements between randomly chosen pairs of nodes. Trilateration is then applied to the set of measurements to verify claimed geo-locations. We evaluate VerLoc both with simulations and in the wild using a prototype implementation integrated in the Nym network (currently run by thousands of nodes). We find that VerLoc can localize nodes in the wild with a median error of 60 km, and that in attack simulations it is capable of detecting and filtering out adversarial timing manipulations for network setups with up to 20 % malicious nodes.",
            "keywords": [
                "Decentralized Localization",
                "Geo-Location Verification",
                "Adversarial Networks",
                "Roundtrip Time Measurements",
                "Trilateration"
            ]
        },
        "url": "URL#1416946",
        "sema_paperId": "a2a3d250cd09b85cf2d6a03a329d09b86b075e2e"
    },
    {
        "@score": "1",
        "@id": "1416947",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "295/1145",
                        "text": "Igibek Koishybayev"
                    },
                    {
                        "@pid": "331/2482",
                        "text": "Aleksandr Nahapetyan"
                    },
                    {
                        "@pid": "232/7579",
                        "text": "Raima Zachariah"
                    },
                    {
                        "@pid": "331/2359",
                        "text": "Siddharth Muralee"
                    },
                    {
                        "@pid": "117/3983",
                        "text": "Bradley Reaves"
                    },
                    {
                        "@pid": "22/1459",
                        "text": "Alexandros Kapravelos"
                    },
                    {
                        "@pid": "133/8188",
                        "text": "Aravind Machiry"
                    }
                ]
            },
            "title": "Characterizing the Security of Github CI Workflows.",
            "venue": "USENIX Security Symposium",
            "pages": "2747-2763",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KoishybayevNZMR22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/koishybayev",
            "url": "https://dblp.org/rec/conf/uss/KoishybayevNZMR22",
            "abstract": "Continuous integration and deployment (CI/CD) has revolutionized software development and maintenance. Commercial CI/CD platforms provide services for specifying and running CI/CD actions. However, they present a security risk in their own right, given their privileged access to secrets, infrastructure, and ability to fetch and execute arbitrary code.\nIn this paper, we study the security of the newly popular GitHub CI platform. We first identify four fundamental security properties that must hold for any CI/CD system: Admittance Control, Execution Control, Code Control, and Access to Secrets. We then examine if GitHub CI enforces these properties in comparison with the other five popular CI/CD platforms. We perform a comprehensive analysis of 447,238 workflows spanning 213,854 GitHub repositories. We made several disturbing observations. Our analysis shows that 99.8% of workflows are overprivileged and have read-write access (instead of read-only) to the repository. In addition, 23.7% of workflows are triggerable by a pull_request and use code from the underlying repository. An attacker can exploit these workflows and execute arbitrary code as part of the workflow. Due to the modular nature of workflows, we find that 99.7% of repositories in our dataset execute some externally developed plugin, called \"Actions\" , for various purposes. We found that 97% of repositories execute at least one Action that does not originate with a verified creator, and 18% of repositories in our dataset execute at least one Action with missing security updates. These represent potential attack vectors that can be used to compromise the execution of workflows, consequently leading to supply chain attacks. This work highlights the systemic risks inherent in CI/CD platforms like GitHub CI; we also present our own Github action, GWChecker, which functions as an early warning system for bad practices that violate the identified security properties.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-koishybayev.pdf",
            "keywords": [
                "GitHub CI/CD",
                "Workflow Security",
                "Access Control",
                "Supply Chain Attacks",
                "Security Properties"
            ]
        },
        "url": "URL#1416947",
        "sema_paperId": "9e2aeb6f5d82bde4365a9d99e6f330ab1e92fbbe"
    },
    {
        "@score": "1",
        "@id": "1416948",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "250/9440",
                        "text": "David Koisser"
                    },
                    {
                        "@pid": "224/9363",
                        "text": "Patrick Jauernig"
                    },
                    {
                        "@pid": "08/1183",
                        "text": "Gene Tsudik"
                    },
                    {
                        "@pid": "s/AhmadRezaSadeghi",
                        "text": "Ahmad-Reza Sadeghi"
                    }
                ]
            },
            "title": "V&apos;CER: Efficient Certificate Validation in Constrained Networks.",
            "venue": "USENIX Security Symposium",
            "pages": "4491-4508",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KoisserJTS22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/koisser",
            "url": "https://dblp.org/rec/conf/uss/KoisserJTS22",
            "abstract": "We address the challenging problem of efficient trust establishment in constrained networks, i.e., networks that are composed of a large and dynamic set of (possibly heterogeneous) devices with limited bandwidth, connectivity, storage, and computational capabilities. Constrained networks are an integral part of many emerging application domains, from IoT meshes to satellite networks. A particularly difficult challenge is how to enforce timely revocation of compromised or faulty devices. Unfortunately, current solutions and techniques cannot cope with idiosyncrasies of constrained networks, since they mandate frequent real-time communication with centralized entities, storage and maintenance of large amounts of revocation information, and incur considerable bandwidth overhead.\nTo address the shortcomings of existing solutions, we design V'CER, a secure and efficient scheme for certificate validation that augments and benefits a PKI for constrained networks. V'CER utilizes unique features of Sparse Merkle Trees (SMTs) to perform lightweight revocation checks, while enabling collaborative operations among devices to keep them up-to-date when connectivity to external authorities is limited. V'CER can complement any PKI scheme to increase its flexibility and applicability, while ensuring fast dissemination of validation information independent of the network routing or topology. V'CER requires under 3KB storage per node covering 106 certificates. We developed and deployed a prototype of V'CER on an in-orbit satellite and our large-scale simulations demonstrate that V'CER decreases the number of requests for updates from external authorities by over 93%, when nodes are intermittently connected.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-koisser.pdf",
            "keywords": [
                "Constrained Networks",
                "Certificate Validation",
                "Trust Establishment",
                "Revocation Mechanism",
                "Sparse Merkle Trees"
            ]
        },
        "url": "URL#1416948"
    },
    {
        "@score": "1",
        "@id": "1416949",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "272/8278",
                        "text": "Brian Kondracki"
                    },
                    {
                        "@pid": "294/4100",
                        "text": "Johnny So"
                    },
                    {
                        "@pid": "04/8280",
                        "text": "Nick Nikiforakis"
                    }
                ]
            },
            "title": "Uninvited Guests: Analyzing the Identity and Behavior of Certificate Transparency Bots.",
            "venue": "USENIX Security Symposium",
            "pages": "53-70",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KondrackiSN22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/kondracki",
            "url": "https://dblp.org/rec/conf/uss/KondrackiSN22",
            "abstract": "Since its creation, Certi\ufb01cate Transparency (CT) has served as a vital component of the secure web. However, with the increase in TLS adoption, CT has essentially become a defacto log for all newly-created websites, announcing to the public the existence of web endpoints, including those that could have otherwise remained hidden. As a result, web bots can use CT to probe websites in real time, as they are created. Little is known about these bots, their behaviors, and their intentions. In this paper we present C T P OT , a distributed honeypot system which creates new TLS certi\ufb01cates for the purpose of advertising previously non-existent domains, and records the activity generated towards them from a number of network vantage points. Using C T P OT ,we create 4,657 TLS certi\ufb01cates over a period of ten weeks, attracting 1.5 million web requests from31,898uniqueIPaddresses. We\ufb01ndthatCTbotsoccupya distinct subset of the overall web bot population, with less than 2% overlap between IP addresses of CT bots and traditional host-scanning web bots. By creating certi\ufb01cates with varying content types, we are able to further sub-divide the CT bot population into subsets of varying intentions, revealing a stark contrast in malicious behavior among these groups. Finally, we correlate observed bot IP addresses into campaigns using the \ufb01le paths requested by each bot, and \ufb01nd 105 malicious campaigns targeting the domains we advertise. Our \ufb01ndings shed light onto the CT bot ecosystem, revealing that it is not only distinct to that of traditional IP-based bots, but is composed of numerous entities with varying targets and behaviors. Abstract In our paper, \u201cUninvited Guests: Analyzing the Identity and Behavior of Certi\ufb01cate Transparency Bots\u201d, we curated an extensive dataset of web requests originating from bots monitoring Certi\ufb01cate Transparency (CT) logs. In total, we recorded over 1.5 million requests from CT bots, originating from 31,898 unique IP addresses. To assist in the understanding and further exploration of this previously-unexplored population of bots, we are releasing our dataset and domain generation script to researchers. We observed that CT bots can be subdivided into distinct groups based on the types of hosts they target, each with varying behaviors. Using our provided dataset,one can analyze these subsets of CT bots, including the populations of each group and characteristics of the web requests they transmit.",
            "keywords": [
                "Certificate Transparency",
                "Web Bots",
                "Honeypot System",
                "Malicious Campaigns",
                "Bot Behavior Analysis"
            ]
        },
        "url": "URL#1416949",
        "sema_paperId": "995d165ad2c459fe7821b2d4f87d34659511d191"
    },
    {
        "@score": "1",
        "@id": "1416950",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "265/6132",
                        "text": "Martin Kotuliak"
                    },
                    {
                        "@pid": "294/8778",
                        "text": "Simon Erni"
                    },
                    {
                        "@pid": "183/1273",
                        "text": "Patrick Leu"
                    },
                    {
                        "@pid": "121/9557",
                        "text": "Marc R\u00f6schlin"
                    },
                    {
                        "@pid": "51/1639",
                        "text": "Srdjan Capkun"
                    }
                ]
            },
            "title": "LTrack: Stealthy Tracking of Mobile Phones in LTE.",
            "venue": "USENIX Security Symposium",
            "pages": "1291-1306",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KotuliakELRC22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/kotuliak",
            "url": "https://dblp.org/rec/conf/uss/KotuliakELRC22",
            "abstract": "We introduce LTrack, a new tracking attack on LTE that allows an attacker to stealthily extract user devices' locations and permanent identifiers (IMSI). To remain stealthy, the localization of devices in LTrack is fully passive, relying on our new uplink/downlink sniffer. Our sniffer records both the times of arrival of LTE messages and the contents of the Timing Advance Commands, based on which LTrack calculates locations. LTrack is the first to show the feasibility of a passive localization in LTE through implementation on software-defined radio. Passive localization attacks reveal a user's location traces but can at best link these traces to a device's pseudonymous temporary identifier (TMSI), making tracking in dense areas or over a long time-period challenging. LTrack overcomes this challenge by introducing and implementing a new type of IMSI Catcher named IMSI Extractor. It extracts a device's IMSI and binds it to its current TMSI. Instead of relying on fake base stations like existing IMSI Catchers, which are detectable due to their continuous transmission, IMSI Extractor relies on our uplink/downlink sniffer enhanced with surgical message overshadowing. This makes our IMSI Extractor the stealthiest IMSI Catcher to date. We evaluate LTrack through a series of experiments and show that in line-of-sight conditions, the attacker can estimate the location of a phone with less than 6m error in 90% of the cases. We successfully tested our IMSI Extractor against a set of 17 modern smartphones connected to our industry-grade LTE testbed. We further validated our uplink/downlink sniffer and IMSI Extractor in a test facility of an operator.",
            "keywords": [
                "LTE Tracking",
                "Passive Localization",
                "IMSI Extraction",
                "Mobile Device Privacy",
                "Stealthy Attacks"
            ]
        },
        "url": "URL#1416950",
        "sema_paperId": "71d37becb2570105b1dc076d2caa35d0631918fc"
    },
    {
        "@score": "1",
        "@id": "1416951",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "222/5402",
                        "text": "Masoud Mehrabi Koushki"
                    },
                    {
                        "@pid": "48/2209",
                        "text": "Yue Huang"
                    },
                    {
                        "@pid": "26/4417",
                        "text": "Julia Rubin"
                    },
                    {
                        "@pid": "47/6517",
                        "text": "Konstantin Beznosov"
                    }
                ]
            },
            "title": "Neither Access nor Control: A Longitudinal Investigation of the Efficacy of User Access-Control Solutions on Smartphones.",
            "venue": "USENIX Security Symposium",
            "pages": "917-935",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KoushkiHRB22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/koushki",
            "url": "https://dblp.org/rec/conf/uss/KoushkiHRB22",
            "abstract": "The incumbent all-or-nothing model of access control on smartphones has been known to dissatisfy users, due to high overhead (both cognitive and physical) and lack of device-sharing support. Several alternative models have been proposed. However, their ef\ufb01cacy has not been evaluated and compared empirically, due to a lack of detailed quantitative data on users\u2019 authorization needs. This paper bridges this gap with a 30-day diary study. We probed a near-representative sample ( N = 55) of US smartphone users to gather a compre-hensive list of tasks they perform on their phones and their authorization needs for each task. Using this data, we quan-tify, for the \ufb01rst time, the ef\ufb01cacy of the all-or-nothing model, demonstrating frequent unnecessary or missed interventions (false positive rate (FPR) = 90%, false negative rate (FNR) = 21%). In comparison, we show that app- or task-level models can improve the FPR up to 88% and the FNR up to 20%, albeit with a modest (up to 15%) increase in required upfront con\ufb01guration. We also demonstrate that the context in which phone sharing happens is consistent up to 75% of the time, showing promise for context-based solutions.",
            "keywords": [
                "Smartphone Access Control",
                "User Authorization Needs",
                "Task-Level Models",
                "Context-Based Solutions",
                "Diary Study"
            ]
        },
        "url": "URL#1416951",
        "sema_paperId": "b6c6526bdf8926a82482508d98e7defa1e7b7773"
    },
    {
        "@score": "1",
        "@id": "1416952",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "153/5752",
                        "text": "Johannes Krupp"
                    },
                    {
                        "@pid": "180/7263",
                        "text": "Ilya Grishchenko"
                    },
                    {
                        "@pid": "08/6024",
                        "text": "Christian Rossow"
                    }
                ]
            },
            "title": "AmpFuzz: Fuzzing for Amplification DDoS Vulnerabilities.",
            "venue": "USENIX Security Symposium",
            "pages": "1043-1060",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KruppGR22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/krupp",
            "url": "https://dblp.org/rec/conf/uss/KruppGR22",
            "abstract": "Amplification DDoS attacks remain a prevalent and severe threat to the Internet, with recent attacks reaching the Tbps range. However, all amplification attack vectors known to date were either found by researchers through laborious manual analysis or could only be identified postmortem following large attacks. Ideally, though, an attack vector is discovered and mitigated before the first attack can occur. To this end, we present A MP F UZZ , the first systematic approach to finding amplification vectors in UDP services in a protocol-agnostic way. A MP F UZZ is based on the state-of-the-art greybox fuzzing boosted by a novel technique to make fuzzing UDP-aware, which significantly increases performance. We evaluate A MP F UZZ on 28 Debian network services, where we (re-)discover 7 known and 6 previously unreported amplification vulnerabilities. \u229b The author contributed while being employed at CISPA.",
            "keywords": [
                "Amplification DDoS Attacks",
                "Fuzzing",
                "UDP Services",
                "Vulnerability Discovery",
                "Protocol-Agnostic Testing"
            ]
        },
        "url": "URL#1416952",
        "sema_paperId": "9c85a617d46d595697282c6616990089b4ffd3f8"
    },
    {
        "@score": "1",
        "@id": "1416953",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "02/11141",
                        "text": "Anunay Kulshrestha"
                    },
                    {
                        "@pid": "116/8542",
                        "text": "Jonathan R. Mayer"
                    }
                ]
            },
            "title": "Estimating Incidental Collection in Foreign Intelligence Surveillance: Large-Scale Multiparty Private Set Intersection with Union and Sum.",
            "venue": "USENIX Security Symposium",
            "pages": "1705-1722",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KulshresthaM22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/kulshrestha",
            "url": "https://dblp.org/rec/conf/uss/KulshresthaM22",
            "abstract": "Multiparty Private Set Operations is a software program that implements the protocols that we present in the main publication. The program enables multiple parties to privately compute the intersection of sets that they hold (MPSI) or the intersection of one set with the union of all other sets (MPSIU). If set elements have associated values, the library supports privately aggregating those values (MPSI-Sum or MPSIU-Sum). A delegated party learns the result of the set operation, and the parties learn no other information. The library implementation is in Go and supports execution in a Docker container.",
            "keywords": [
                "Multiparty Private Set Operations",
                "Private Set Intersection",
                "Incidental Collection",
                "Data Privacy",
                "Value Aggregation"
            ]
        },
        "url": "URL#1416953",
        "sema_paperId": "0668eb96e2d8e179a7e11910085b52ebc54aeb9c"
    },
    {
        "@score": "1",
        "@id": "1416954",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "227/2162",
                        "text": "Renuka Kumar"
                    },
                    {
                        "@pid": "331/2188",
                        "text": "Apurva Virkud"
                    },
                    {
                        "@pid": "270/2488",
                        "text": "Ram Sundara Raman"
                    },
                    {
                        "@pid": "p/AtulPrakash",
                        "text": "Atul Prakash 0001"
                    },
                    {
                        "@pid": "24/973",
                        "text": "Roya Ensafi"
                    }
                ]
            },
            "title": "A Large-scale Investigation into Geodifferences in Mobile Apps.",
            "venue": "USENIX Security Symposium",
            "pages": "1203-1220",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KumarVR0E22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/kumar",
            "url": "https://dblp.org/rec/conf/uss/KumarVR0E22",
            "abstract": "Recent studies on the web ecosystem have been raising alarms on the increasing geodifferences in access to Internet content and services due to Internet censorship and geoblocking. However, geodifferences in the mobile app ecosystem have received limited attention, even though apps are central to how mobile users communicate and consume Internet content. We present the \ufb01rst large-scale measurement study of geodifferences in the mobile app ecosystem. We design a semi-automatic, parallel measurement testbed that we use to collect 5,684 popular apps from Google Play in 26 countries. In all, we collected 117,233 apk \ufb01les and 112,607 privacy policies for those apps. Our results show high amounts of geoblocking with 3,672 apps geoblocked in at least one of our countries. While our data corroborates anecdotal evidence of takedowns due to government requests, unlike common perception, we \ufb01nd that blocking by developers is signi\ufb01cantly higher than takedowns in all our countries, and has the most in\ufb02uence on geoblocking in the mobile app ecosystem. We also \ufb01nd instances of developers releasing different app versions to different countries, some with weaker security settings or privacy disclosures that expose users to higher security and privacy risks. We provide recommendations for app market proprietors to address the issues discovered.",
            "keywords": [
                "Mobile App Ecosystem",
                "Geodifferences",
                "Geoblocking",
                "App Takedowns",
                "Privacy Risks"
            ]
        },
        "url": "URL#1416954",
        "sema_paperId": "bdbbe9cebd381195ec1f7e9348b1431874d27836"
    },
    {
        "@score": "1",
        "@id": "1416956",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "267/1560",
                        "text": "Hyeonmin Lee"
                    },
                    {
                        "@pid": "260/9262",
                        "text": "Md. Ishtiaq Ashiq"
                    },
                    {
                        "@pid": "12/303",
                        "text": "Moritz M\u00fcller"
                    },
                    {
                        "@pid": "155/5773",
                        "text": "Roland van Rijswijk-Deij"
                    },
                    {
                        "@pid": "14/2293-1",
                        "text": "Ted Taekyoung Kwon"
                    },
                    {
                        "@pid": "90/8396",
                        "text": "Taejoong Chung"
                    }
                ]
            },
            "title": "Under the Hood of DANE Mismanagement in SMTP.",
            "venue": "USENIX Security Symposium",
            "pages": "1-16",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LeeAMRKC22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/lee",
            "url": "https://dblp.org/rec/conf/uss/LeeAMRKC22",
            "abstract": "The DNS-based Authentication of Named Entities (DANE) is an Internet security protocol that enables a TLS connection without relying on trusted third parties like CAs by introducing a new DNS record type, TLSA . DANE leverages DNSSEC PKI to provide the integrity and authenticity of TLSA records. As DANE can solve security challenges in SMTP, such as STARTTLS downgrade attacks and receiver authentication, it has been increasingly deployed surpassing more than 1 M domains with SMTP servers that have TLSA records. A recent study, however, reported that there are prevalent misconfigurations on DANE SMTP servers, which hinders DANE from being proliferated. In this paper, we investigate the reasons why it is hard to deploy and manage DANE correctly. Our study uses large-scale, longitudinal measurements to study DANE adoption and management, coupled with a survey of DANE operators, some of which serve more than 100 K domains. Overall, we find that keeping the TLSA records from a name server and certificates from an SMTP server synchronized is not straightforward even when the same entity manages the two servers. Furthermore, many of the certificates are configured to be reissued automatically, which may result in invalid TLSA records. From surveying 39 mail server operators, we also learn that the majority keeps using CA-issued certificates, despite this no longer being required with DANE, since they are worried about their certificates not being trusted by clients that have not deployed DANE. Having identified several operational challenges for correct DANE management, we release automated tools and shed light on unsolved challenges.",
            "keywords": [
                "DANE",
                "SMTP Security",
                "TLSA Records",
                "Misconfiguration",
                "Certificate Management"
            ]
        },
        "url": "URL#1416956",
        "sema_paperId": "dd5e3c323de0d352886786d26b68639d0a550afb"
    },
    {
        "@score": "1",
        "@id": "1416957",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "183/1273",
                        "text": "Patrick Leu"
                    },
                    {
                        "@pid": "224/9311",
                        "text": "Giovanni Camurati"
                    },
                    {
                        "@pid": "248/1693",
                        "text": "Alexander Heinrich"
                    },
                    {
                        "@pid": "121/9557",
                        "text": "Marc Roeschlin"
                    },
                    {
                        "@pid": "195/0397",
                        "text": "Claudio Anliker"
                    },
                    {
                        "@pid": "95/1816",
                        "text": "Matthias Hollick"
                    },
                    {
                        "@pid": "51/1639",
                        "text": "Srdjan Capkun"
                    },
                    {
                        "@pid": "155/8567",
                        "text": "Jiska Classen"
                    }
                ]
            },
            "title": "Ghost Peak: Practical Distance Reduction Attacks Against HRP UWB Ranging.",
            "venue": "USENIX Security Symposium",
            "pages": "1343-1359",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LeuCHRAHCC22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/leu",
            "url": "https://dblp.org/rec/conf/uss/LeuCHRAHCC22",
            "abstract": "We present the first over-the-air attack on IEEE 802.15.4z High-Rate Pulse Repetition Frequency (HRP) Ultra-Wide Band (UWB) distance measurement systems. Specifically, we demonstrate a practical distance reduction attack against pairs of Apple U1 chips (embedded in iPhones and AirTags), as well as against U1 chips inter-operating with NXP and Qorvo UWB chips. These chips have been deployed in a wide range of phones and cars to secure car entry and start and are projected for secure contactless payments, home locks, and contact tracing systems. Our attack operates without any knowledge of cryptographic material, results in distance reductions from 12m (actual distance) to 0m (spoofed distance) with attack success probabilities of up to 4%, and requires only an inexpensive (USD 65) off-the-shelf device. Access control can only tolerate sub-second latencies to not inconvenience the user, leaving little margin to perform time-consuming verifications. These distance reductions bring into question the use of UWB HRP in security-critical applications.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-leu.pdf",
            "keywords": [
                "Ultra-Wide Band (UWB)",
                "Distance Measurement",
                "Distance Reduction Attack",
                "Apple U1 Chip",
                "Security-Critical Applications"
            ]
        },
        "url": "URL#1416957"
    },
    {
        "@score": "1",
        "@id": "1416958",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "20/6946",
                        "text": "Derek Leung"
                    },
                    {
                        "@pid": "84/7357",
                        "text": "Yossi Gilad"
                    },
                    {
                        "@pid": "117/3299-1",
                        "text": "Sergey Gorbunov 0001"
                    },
                    {
                        "@pid": "r/LeonidReyzin",
                        "text": "Leonid Reyzin"
                    },
                    {
                        "@pid": "99/5780",
                        "text": "Nickolai Zeldovich"
                    }
                ]
            },
            "title": "Aardvark: An Asynchronous Authenticated Dictionary with Applications to Account-based Cryptocurrencies.",
            "venue": "USENIX Security Symposium",
            "pages": "4237-4254",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LeungG0RZ22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/leung",
            "url": "https://dblp.org/rec/conf/uss/LeungG0RZ22",
            "abstract": "We design Aardvark, a novel authenticated dictionary with short proofs of correctness for lookups and modifications. Our design reduces storage requirements for transaction validation in cryptocurrencies by outsourcing data from validators to untrusted servers, which supply proofs of correctness of this data as needed. In this setting, short proofs are particularly important because proofs are distributed to many validators, and the transmission of long proofs can easily dominate costs. A proof for a piece of data in an authenticated dictionary may change whenever any (even unrelated) data changes. This presents a problem for concurrent issuance of cryptocurrency transactions, as proofs become stale. To solve this problem, Aardvark employs a versioning mechanism to safely accept stale proofs for a limited time. On a dictionary with 100 million keys, operation proof sizes are about 1KB in a Merkle Tree versus 100\u2013200B in Aardvark. Our evaluation shows that a 32-core validator processes 1492\u2013 2941 operations per second, saving about 800 \u00d7 in storage costs relative to maintaining the entire state.",
            "keywords": [
                "Authenticated Dictionary",
                "Cryptocurrency Transactions",
                "Storage Optimization",
                "Proofs of Correctness",
                "Versioning Mechanism"
            ]
        },
        "url": "URL#1416958",
        "sema_paperId": "814da058488a74d1aadf32fd42170c6e4a9eae33"
    },
    {
        "@score": "1",
        "@id": "1416959",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "06/721-7",
                        "text": "Wen Li 0007"
                    },
                    {
                        "@pid": "09/6585-2",
                        "text": "Jiang Ming 0002"
                    },
                    {
                        "@pid": "53/1565",
                        "text": "Xiapu Luo"
                    },
                    {
                        "@pid": "117/7062",
                        "text": "Haipeng Cai"
                    }
                ]
            },
            "title": "PolyCruise: A Cross-Language Dynamic Information Flow Analysis.",
            "venue": "USENIX Security Symposium",
            "pages": "2513-2530",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Li0LC22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/li-wen",
            "url": "https://dblp.org/rec/conf/uss/Li0LC22",
            "abstract": "Despite the fact that most real-world software systems today are written in multiple programming languages, existing program analysis based security techniques are still limited to single-language code. In consequence, security \ufb02aws (e.g., code vulnerabilities) at and across language boundaries are largely left out as blind spots. We present P OLY C RUISE , a technique that enables holistic dynamic information \ufb02ow analysis (DIFA) across heterogeneous languages hence security applications empowered by DIFA (e.g., vulnerability discovery) for multilingual software. P OLY C RUISE combines a light language-speci\ufb01c analysis that computes symbolic dependencies in each language unit with a language-agnostic online data \ufb02ow analysis guided by those dependencies, in a way that overcomes language heterogeneity. Extensive evaluation of its implementation for Python-C programs against micro, medium-sized, and large-scale benchmarks demonstrated P OLY C RUISE \u2019s practical scalability and promising capabilities. It has enabled the discovery of 14 unknown cross-language security vulnerabilities in real-world multilingual systems such as NumPy, with 11 con\ufb01rmed, 8 CVEs assigned, and 8 \ufb01xed so far. We also contributed the \ufb01rst benchmark suite for systematically assessing multilingual DIFA.",
            "keywords": [
                "Dynamic Information Flow Analysis",
                "Cross-Language Security",
                "Multilingual Software Vulnerabilities",
                "Symbolic Dependency Analysis",
                "Vulnerability Discovery"
            ]
        },
        "url": "URL#1416959",
        "sema_paperId": "4511acdf1e7cf798fad081b691b7c9b7b3bc4186"
    },
    {
        "@score": "1",
        "@id": "1416960",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "67/2580-6",
                        "text": "Song Li 0006"
                    },
                    {
                        "@pid": "288/6749",
                        "text": "Mingqing Kang"
                    },
                    {
                        "@pid": "49/8706",
                        "text": "Jianwei Hou"
                    },
                    {
                        "@pid": "28/8733",
                        "text": "Yinzhi Cao"
                    }
                ]
            },
            "title": "Mining Node.js Vulnerabilities via Object Dependence Graph and Query.",
            "venue": "USENIX Security Symposium",
            "pages": "143-160",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiKHC22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/li-song",
            "url": "https://dblp.org/rec/conf/uss/LiKHC22",
            "abstract": "Node.js is a popular non-browser JavaScript platform that provides useful but sometimes also vulnerable packages. On one hand, prior works have proposed many program analysis-based approaches to detect Node.js vulnerabilities, such as command injection and prototype pollution, but they are spe-ci\ufb01c to individual vulnerability and do not generalize to a wide range of vulnerabilities on Node.js. On the other hand, prior works on C/C++ and PHP have proposed graph query-based approaches, such as Code Property Graph (CPG), to ef\ufb01ciently mine vulnerabilities, but they are not directly applicable to JavaScript due to the language\u2019s extensive use of dynamic features. In the paper, we propose \ufb02ow-and context-sensitive static analysis with hybrid branch-sensitivity and points-to information to generate a novel graph structure, called Object De-pendence Graph (ODG), using abstract interpretation. ODG represents JavaScript objects as nodes and their relations with Abstract Syntax Tree (AST) as edges, and accepts graph queries\u2014especially on object lookups and de\ufb01nitions\u2014for detecting Node.js vulnerabilities. We implemented an open-source prototype system, called ODG EN , to generate ODG for Node.js programs via abstract interpretation and detect vulnerabilities. Our evaluation of recent Node.js vulnerabilities shows that ODG together with AST and Control Flow Graph (CFG) is capable of modeling 13 out of 16 vulnerability types. We applied ODG EN to detect six types of vulnerabilities using graph queries: ODG EN correctly reported 180 zero-day vulnerabilities, among which we have received 70 Common Vulnerabilities and Exposures (CVE) identi\ufb01ers so far.",
            "keywords": [
                "Node.js Vulnerabilities",
                "Object Dependence Graph",
                "Static Analysis",
                "Graph Query",
                "Vulnerability Detection"
            ]
        },
        "url": "URL#1416960",
        "sema_paperId": "039088293737bd3f1afaaa6cde3a63cb90a5c598"
    },
    {
        "@score": "1",
        "@id": "1416961",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "185/7953",
                        "text": "Yeting Li"
                    },
                    {
                        "@pid": "226/7694",
                        "text": "Yecheng Sun"
                    },
                    {
                        "@pid": "25/9771",
                        "text": "Zhiwu Xu 0001"
                    },
                    {
                        "@pid": "224/1601",
                        "text": "Jialun Cao"
                    },
                    {
                        "@pid": "204/3729",
                        "text": "Yuekang Li"
                    },
                    {
                        "@pid": "331/2626",
                        "text": "Rongchen Li"
                    },
                    {
                        "@pid": "75/248",
                        "text": "Haiming Chen"
                    },
                    {
                        "@pid": "c/SCCheung",
                        "text": "Shing-Chi Cheung"
                    },
                    {
                        "@pid": "51/3710-3",
                        "text": "Yang Liu 0003"
                    },
                    {
                        "@pid": "181/1848-11",
                        "text": "Yang Xiao 0011"
                    }
                ]
            },
            "title": "RegexScalpel: Regular Expression Denial of Service (ReDoS) Defense by Localize-and-Fix.",
            "venue": "USENIX Security Symposium",
            "pages": "4183-4200",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiS0CLLCC0X22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/li-yeting",
            "url": "https://dblp.org/rec/conf/uss/LiS0CLLCC0X22",
            "abstract": "The Regular expression Denial of Service (ReDoS) is a class of denial of service attacks that exploit vulnerable regular expressions (regexes) whose execution time can be super-linearly related to input sizes. A common approach of defending ReDoS attacks is to repair the vulnerable regexes. Techniques have been recently proposed to synthesize repaired regexes using program-by-example (PBE) techniques. However, these existing techniques may generate regexes, which are not semantically equivalent or similar to the original ones, or are still vulnerable to ReDoS attacks. To address the challenges, we propose RegexScalpel, an automatic regex repair framework that adopts a localize-and-fix strategy. RegexScalpel first localizes the vulnerabilities by leveraging fine-grained vulnerability patterns proposed by us to analyze their vulnerable patterns, the source (i.e., the pathological sub-regexes), and the root causes (e.g., the over-lapping sub-regexes). Then, RegexScalpel targets to fix the pathological sub-regexes according to our predefined repair patterns and the localized vulnerability information. Furthermore, our repair patterns ensure that the repair regexes are semantically either equivalent to or similar to the original ones. Our iterative repair method also keeps out vulnerabilities of the repaired",
            "keywords": [
                "Regular Expressions",
                "Denial of Service",
                "ReDoS",
                "Vulnerability Repair",
                "Localize-and-Fix Strategy"
            ]
        },
        "url": "URL#1416961",
        "sema_paperId": "54f9fa1bb86edeb16b1a3b9a0e3f80cc46be4261"
    },
    {
        "@score": "1",
        "@id": "1416962",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "23/4315",
                        "text": "Huiying Li"
                    },
                    {
                        "@pid": "217/9308",
                        "text": "Shawn Shan"
                    },
                    {
                        "@pid": "259/1518",
                        "text": "Emily Wenger"
                    },
                    {
                        "@pid": "189/5595",
                        "text": "Jiayun Zhang"
                    },
                    {
                        "@pid": "43/4261",
                        "text": "Haitao Zheng 0001"
                    },
                    {
                        "@pid": "z/BenYZhao",
                        "text": "Ben Y. Zhao"
                    }
                ]
            },
            "title": "Blacklight: Scalable Defense for Neural Networks against Query-Based Black-Box Attacks.",
            "venue": "USENIX Security Symposium",
            "pages": "2117-2134",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiSWZ0Z22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/li-huiying",
            "url": "https://dblp.org/rec/conf/uss/LiSWZ0Z22",
            "abstract": "Deep learning systems are known to be vulnerable to adversarial examples. In particular, query-based black-box attacks do not require knowledge of the deep learning model, but can compute adversarial examples over the network by submitting queries and inspecting returns. Recent work largely improves the efficiency of those attacks, demonstrating their practicality on today's ML-as-a-service platforms. We propose Blacklight, a new defense against query-based black-box adversarial attacks. The fundamental insight driving our design is that, to compute adversarial examples, these attacks perform iterative optimization over the network, producing image queries highly similar in the input space. Blacklight detects query-based black-box attacks by detecting highly similar queries, using an efficient similarity engine operating on probabilistic content fingerprints. We evaluate Blacklight against eight state-of-the-art attacks, across a variety of models and image classification tasks. Blacklight identifies them all, often after only a handful of queries. By rejecting all detected queries, Blacklight prevents any attack to complete, even when attackers persist to submit queries after account ban or query rejection. Blacklight is also robust against several powerful countermeasures, including an optimal black-box attack that approximates white-box attacks in efficiency. Finally, we illustrate how Blacklight generalizes to other domains like text classification.",
            "keywords": [
                "Adversarial Attacks",
                "Black-Box Attacks",
                "Query-Based Attacks",
                "Image Classification Defense",
                "Similarity Detection"
            ]
        },
        "url": "URL#1416962",
        "sema_paperId": "862b76d28870ed8a1378e5e91ab315ff27852181"
    },
    {
        "@score": "1",
        "@id": "1416963",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "216/3218",
                        "text": "Changjiang Li"
                    },
                    {
                        "@pid": "58/6810",
                        "text": "Li Wang"
                    },
                    {
                        "@pid": "07/8388",
                        "text": "Shouling Ji"
                    },
                    {
                        "@pid": "139/6932-2",
                        "text": "Xuhong Zhang 0002"
                    },
                    {
                        "@pid": "224/9296",
                        "text": "Zhaohan Xi"
                    },
                    {
                        "@pid": "47/401",
                        "text": "Shanqing Guo"
                    },
                    {
                        "@pid": "12/2633-6",
                        "text": "Ting Wang 0006"
                    }
                ]
            },
            "title": "Seeing is Living? Rethinking the Security of Facial Liveness Verification in the Deepfake Era.",
            "venue": "USENIX Security Symposium",
            "pages": "2673-2690",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiWJ0XG022",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/li-changjiang",
            "url": "https://dblp.org/rec/conf/uss/LiWJ0XG022",
            "abstract": "Facial Liveness Verification (FLV) is widely used for identity authentication in many security-sensitive domains and offered as Platform-as-a-Service (PaaS) by leading cloud vendors. Yet, with the rapid advances in synthetic media techniques (e.g., deepfake), the security of FLV is facing unprecedented challenges, about which little is known thus far. \nTo bridge this gap, in this paper, we conduct the first systematic study on the security of FLV in real-world settings. Specifically, we present LiveBugger, a new deepfake-powered attack framework that enables customizable, automated security evaluation of FLV.  Leveraging LiveBugger, we perform a comprehensive empirical assessment of representative FLV platforms, leading to a set of interesting findings. For instance, most FLV APIs do not use anti-deepfake detection; even for those with such defenses, their effectiveness is concerning (e.g., it may detect high-quality synthesized videos but fail to detect low-quality ones). We then conduct an in-depth analysis of the factors impacting the attack performance of LiveBugger:  a) the bias (e.g., gender or race) in FLV can be exploited to select victims; b) adversarial training makes deepfake more effective to bypass FLV; c) the input quality has a varying influence on different deepfake techniques to bypass FLV. Based on these findings, we propose a customized, two-stage approach that can boost the attack success rate by up to 70%. Further, we run proof-of-concept attacks on several representative applications of FLV (i.e., the clients of FLV APIs) to illustrate the practical implications: due to the vulnerability of the APIs, many downstream applications are vulnerable to deepfake. Finally, we discuss potential countermeasures to improve the security of FLV. Our findings have been confirmed by the corresponding vendors.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-li-changjiang.pdf",
            "keywords": [
                "Facial Liveness Verification",
                "Deepfake Attacks",
                "Security Evaluation",
                "Synthetic Media",
                "Automated Vulnerability Assessment"
            ]
        },
        "url": "URL#1416963"
    },
    {
        "@score": "1",
        "@id": "1416964",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "10/3844-6",
                        "text": "Jianfeng Li 0006"
                    },
                    {
                        "@pid": "63/778-9",
                        "text": "Hao Zhou 0009"
                    },
                    {
                        "@pid": "311/8828",
                        "text": "Shuohan Wu"
                    },
                    {
                        "@pid": "53/1565",
                        "text": "Xiapu Luo"
                    },
                    {
                        "@pid": "12/2633-6",
                        "text": "Ting Wang 0006"
                    },
                    {
                        "@pid": "154/0904",
                        "text": "Xian Zhan"
                    },
                    {
                        "@pid": "18/10062",
                        "text": "Xiaobo Ma"
                    }
                ]
            },
            "title": "FOAP: Fine-Grained Open-World Android App Fingerprinting.",
            "venue": "USENIX Security Symposium",
            "pages": "1579-1596",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiZWL0ZM22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/li-jianfeng",
            "url": "https://dblp.org/rec/conf/uss/LiZWL0ZM22",
            "abstract": "Despite the widespread adoption of encrypted communication for mobile apps, adversaries can still identify apps or infer selected user activities of interest from encrypted mobile traf\ufb01c via app \ufb01ngerprinting (AF) attacks. However, most existing AF techniques only work under the closed-world as-sumption, thereby suffering potential precision decline when faced with apps unseen during model training. Moreover, serious privacy leakage often occurs when users conduct some sensitive operations, which are closely associated with speci\ufb01c UI components. Unfortunately, existing AF techniques are too coarse-grained to acquire such \ufb01ne-grained sensitive information. In this paper, we take the \ufb01rst step to identify method-level \ufb01ne-grained user action of Android apps in the open-world setting and present a systematic solution, dubbed FOAP, to address the above limitations. First, to effectively reduce false positive risks in the open-world setting, we propose a novel metric, named structural similarity, to adaptively \ufb01lter out traf\ufb01c segments irrelevant to the app of interest. Second, FOAP achieves \ufb01ne-grained user action identi\ufb01cation via synthesizing traf\ufb01c and binary analysis. Speci\ufb01cally, FOAP identi\ufb01es user actions on speci\ufb01c UI components through inferring entry point methods correlated with them. Extensive evaluations and case studies demonstrate that FOAP is not only reasonably accurate but also practical in \ufb01ne-grained user activity inference and user privacy analysis.",
            "keywords": [
                "Android App Fingerprinting",
                "Open-World Setting",
                "User Action Identification",
                "Privacy Leakage",
                "Fine-Grained Analysis"
            ]
        },
        "url": "URL#1416964",
        "sema_paperId": "6bbf975e102e8caaff262649004c59a0b5b9ac79"
    },
    {
        "@score": "1",
        "@id": "1416965",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "65/1700-2",
                        "text": "Yu Liang 0002"
                    },
                    {
                        "@pid": "80/1141",
                        "text": "Song Liu"
                    },
                    {
                        "@pid": "70/2543-4",
                        "text": "Hong Hu 0004"
                    }
                ]
            },
            "title": "Detecting Logical Bugs of DBMS with Coverage-based Guidance.",
            "venue": "USENIX Security Symposium",
            "pages": "4309-4326",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiangL022",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/liang",
            "url": "https://dblp.org/rec/conf/uss/LiangL022",
            "abstract": "Database management systems (DBMSs) are critical components of modern data-intensive applications. Developers have adopted many testing techniques to detect DBMS bugs such as crashes and assertion failures. However, most previous efforts cannot detect logical bugs that make the DBMS return incorrect results. Recent work proposed several oracles to identify incorrect results, but they rely on rule-based expression generation to synthesize queries without any guidance. In this paper, we propose to combine coverage-based guidance, validity-oriented mutations and oracles to detect logical bugs in DBMS systems. Specifically, we first design a set of general APIs to decouple the logic of fuzzers and oracles, so that developers can easily port fuzzing tools to test DBMSs and write new oracles for existing fuzzers. Then, we provide validity-oriented mutations to generate high-quality query statements in order to find more logical bugs. Our prototype, SQLRight , outperforms existing tools that only rely on oracles or code coverage. In total, SQLRight detects 18 logical bugs from two well-tested DBMSs, SQLite and MySQL . All bugs have been confirmed and 14 of them have been fixed. Abstract This artifact is to help users reproduce the results we reported in our USENIX Security 2022 paper submission. We recom-mend to run the artifact on a x86-64 computer with \u2265 20 CPU cores, \u2265 600 GB of memory and \u2265 1 . 5 TB hard drive storage, and with an Ubuntu 20.04 LTS operating system. The artifact should reproduce all the Figures and Tables we reported in the paper, and thus can validate the main claims of the paper. Detailed execution steps are elaborated in the artifact README.md \ufb01le.",
            "keywords": [
                "Database Management Systems",
                "Logical Bugs",
                "Fuzzing Tools",
                "Coverage-based Guidance",
                "Validity-oriented Mutations"
            ]
        },
        "url": "URL#1416965",
        "sema_paperId": "77faa12e3aa52f3cb41009e9e8f65c79c9ef9f42"
    },
    {
        "@score": "1",
        "@id": "1416966",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "33/3328-3",
                        "text": "Xu Lin 0003"
                    },
                    {
                        "@pid": "129/9582",
                        "text": "Panagiotis Ilia"
                    },
                    {
                        "@pid": "198/1782",
                        "text": "Saumya Solanki"
                    },
                    {
                        "@pid": "47/8412",
                        "text": "Jason Polakis"
                    }
                ]
            },
            "title": "Phish in Sheep&apos;s Clothing: Exploring the Authentication Pitfalls of Browser Fingerprinting.",
            "venue": "USENIX Security Symposium",
            "pages": "1651-1668",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LinISP22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/lin-xu",
            "url": "https://dblp.org/rec/conf/uss/LinISP22",
            "abstract": "As users navigate the web they face a multitude of threats; among them, attacks that result in account compromise can be particularly devastating. In a world fraught with data breaches and sophisticated phishing attacks, web services strive to fortify user accounts by adopting new mechanisms that identify and prevent suspicious login attempts. More recently, browser \ufb01ngerprinting techniques have been incorporated into the authentication work\ufb02ow of major services as part of their decision-making process for triggering additional security mechanisms (e.g., two-factor authentication). In this paperwe present the \ufb01rst comprehensive and in-depth exploration of the security implications of real-world systems relying on browser \ufb01ngerprints for authentication. Guided by ourinvestigation,we developa toolforautomaticallyconstruct-ing \ufb01ngerprinting vectors that replicate the process of target websites, enabling the extraction of \ufb01ngerprints from users\u2019 devices that exactly match those generated by target websites. Subsequently, we demonstrate how phishing attackers can replicate users\u2019 \ufb01ngerprints on different devices to deceive the risk-based authentication systems of high-value web services (e.g., cryptocurrency trading) to completely bypass two-factor authentication . To gain a better understanding of whether attackers can carry out such attacks, we study the evolution of browser\ufb01ngerprinting practices in phishing websites overtime. While attackers do not generally collect all the necessary \ufb01ngerprinting attributes, unfortunately that is not the case for attackers targeting certain \ufb01nancial institutions where we observe an increasing number of phishing sites capable of pulling off our attacks. To address the signi\ufb01cant threat posed by our attack, we have disclosed our \ufb01ndings to the vulnerable vendors.",
            "keywords": [
                "Browser Fingerprinting",
                "Authentication Mechanisms",
                "Phishing Attacks",
                "Risk-based Authentication",
                "Two-Factor Authentication Bypass"
            ]
        },
        "url": "URL#1416966",
        "sema_paperId": "e620619b918ad2a4aef481619fc1ae41ffaa30fe"
    },
    {
        "@score": "1",
        "@id": "1416967",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "172/1127",
                        "text": "Moritz Lipp"
                    },
                    {
                        "@pid": "166/1494",
                        "text": "Daniel Gruss"
                    },
                    {
                        "@pid": "08/1117-1",
                        "text": "Michael Schwarz 0001"
                    }
                ]
            },
            "title": "AMD Prefetch Attacks through Power and Time.",
            "venue": "USENIX Security Symposium",
            "pages": "643-660",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LippG022",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/lipp",
            "url": "https://dblp.org/rec/conf/uss/LippG022",
            "abstract": "Modern operating systems fundamentally rely on the strict isolation of user applications from the kernel. This isolation is enforced by the hardware. On Intel CPUs, this isolation has been shown to be imperfect, for instance, with the prefetch side-channel. With Meltdown, it was even completely circum-vented. Both the prefetch side channel and Meltdown have been mitigated with the same software patch on Intel. As AMD is believed to be not vulnerable to these attacks, this software patch is not active by default on AMD CPUs. In this paper, we show that the isolation on AMD CPUs suffers from the same type of side-channel leakage. We discover timing and power variations of the prefetch instruction that can be observed from unprivileged user space. In contrast to previous work on prefetch attacks on Intel, we show that the prefetch instruction on AMD leaks even more information. We demonstrate the signi\ufb01cance of this side channel with multiple case studies in real-world scenarios. We demonstrate the \ufb01rst microarchitectural break of (\ufb01ne-grained) KASLR on AMD CPUs. We monitor kernel activity, e.g., if audio is played over Bluetooth, and establish a covert channel. Finally, we even leak kernel memory with 52 . 85 B / s with simple Spectre gadgets in the Linux kernel. We show that stronger page table isolation should be activated on AMD CPUs by default to mitigate our presented attacks successfully.",
            "keywords": [
                "Microarchitectural Attacks",
                "Prefetch Side-Channel",
                "AMD CPUs",
                "Kernel Memory Leakage",
                "KASLR Break"
            ]
        },
        "url": "URL#1416967",
        "sema_paperId": "d656a81d382c62eee6f926f20f96d4cf10711598"
    },
    {
        "@score": "1",
        "@id": "1416968",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "02/8772",
                        "text": "Guannan Liu"
                    },
                    {
                        "@pid": "87/4866-1",
                        "text": "Xing Gao 0001"
                    },
                    {
                        "@pid": "81/4036-1",
                        "text": "Haining Wang 0001"
                    },
                    {
                        "@pid": "30/3530-1",
                        "text": "Kun Sun 0001"
                    }
                ]
            },
            "title": "Exploring the Unchartered Space of Container Registry Typosquatting.",
            "venue": "USENIX Security Symposium",
            "pages": "35-51",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Liu0W022",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/liu-guannan",
            "url": "https://dblp.org/rec/conf/uss/Liu0W022",
            "abstract": "With the increasing popularity of containerized applications, container registries have hosted millions of repositories that allow developers to store, manage, and share their software. Unfortunately, they have also become a hotbed for adversaries to spread malicious images to the public. In this paper, we present the \ufb01rst in-depth study on the vulnerability of container registries to typosquatting attacks, in which adversaries intentionally upload malicious images with an identi\ufb01cation similar to that of a benign image so that users may accidentally download malicious images due to typos. We demonstrate that such typosquatting attacks could pose a serious security threat in both public and private registries as well as across multiple platforms. To shed light on the container registry typosquatting threat, we \ufb01rst conduct a measurement study and a 210-day proof-of-concept exploitation on public container registries, revealing that human users indeed make random typos and download unwanted container images. We also systematically investigate attack vectors on private registries and reveal that its naming space is open and could be easily exploited for launching a typosquatting attack. In addition, for a typosquatting attack across multiple platforms, we demonstrate that adversaries can easily self-host malicious registries or exploit existing container registries to manipulate repositories with similar identi\ufb01cations. Finally, we propose CRYSTAL, a lightweight extension to existing image management, which effectively defends against typosquatting attacks from both container users and registries.",
            "keywords": [
                "Container Registries",
                "Typosquatting",
                "Malicious Images",
                "Security Threats",
                "CRYSTAL"
            ]
        },
        "url": "URL#1416968",
        "sema_paperId": "a7673525db463da8794854e906eb2e86d391b883"
    },
    {
        "@score": "1",
        "@id": "1416969",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "301/5834",
                        "text": "Ruofan Liu"
                    },
                    {
                        "@pid": "77/1513-1",
                        "text": "Yun Lin 0001"
                    },
                    {
                        "@pid": "01/2410",
                        "text": "Xianglin Yang"
                    },
                    {
                        "@pid": "303/0429",
                        "text": "Siang Hwee Ng"
                    },
                    {
                        "@pid": "87/2495",
                        "text": "Dinil Mon Divakaran"
                    },
                    {
                        "@pid": "33/6517",
                        "text": "Jin Song Dong"
                    }
                ]
            },
            "title": "Inferring Phishing Intention via Webpage Appearance and Dynamics: A Deep Vision Based Approach.",
            "venue": "USENIX Security Symposium",
            "pages": "1633-1650",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Liu0YNDD22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/liu-ruofan",
            "url": "https://dblp.org/rec/conf/uss/Liu0YNDD22",
            "abstract": "Explainable phishing detection approaches are usually based on references, i.e., they compare a suspicious webpage against a reference list of commonly targeted legitimate brands\u2019 webpages. If a webpage is detected as similar to any referenced website but their domains are not aligned, a phishing alert is raised with an explanation comprising its targeted brand. In comparison to other techniques, such explainable reference-based solutions are more robust to ever-changing phishing webpages. However, the webpage similarity is still measured by representations conveying only partial intentions (e.g., screenshot and logo), which (i) incurs considerable false positives and (ii) gives an adversary opportunities to compromise user con\ufb01dence in the approaches. In this work, we propose, PhishIntention, to extract precise phishing intention of a webpage by visually (i) extracting its brand intention and credential-taking intention, and (ii) interacting with the webpage to con\ufb01rm the credential-taking intention. We design PhishIntention as a heterogeneous system of deep learning vision models, overcoming various technical challenges. The models \u201clook at\u201d and \u201cinteract with\u201d the webpage for its intention, which are robust to potential HTML obfuscation. We compare PhishIntention with four state-of-the-art reference-based approaches on the largest phishing identi\ufb01cation dataset consisting of 50K phishing and benign webpages. For similar level of recall, PhishIntention achieves signi\ufb01cantly higher precision than the baselines. Moreover, we conduct a continuous \ufb01eld study on the Internet for two months to discover emerging phishing webpages. PhishIntention detects 1,942 new phishing webpages (1,368 not reported by VirusTotal). Comparing to the best baseline, PhishIntention generates 86.5% less false alerts (139 vs. 1,033 false positives) while detecting similar number of real phishing webpages. Our models and code are available at https: //github.com/lindsey98/PhishIntention.git .",
            "keywords": [
                "Phishing Detection",
                "Webpage Intention",
                "Visual Analysis",
                "Credential Theft",
                "False Positives Reduction"
            ]
        },
        "url": "URL#1416969",
        "sema_paperId": "b84d3dd9fc5995ec3d5b5970e593cb821072318b"
    },
    {
        "@score": "1",
        "@id": "1416970",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "55/6956",
                        "text": "Yijing Liu"
                    },
                    {
                        "@pid": "230/3262",
                        "text": "Yan Jia"
                    },
                    {
                        "@pid": "331/2193",
                        "text": "Qingyin Tan"
                    },
                    {
                        "@pid": "22/8078",
                        "text": "Zheli Liu"
                    },
                    {
                        "@pid": "34/8412",
                        "text": "Luyi Xing"
                    }
                ]
            },
            "title": "How Are Your Zombie Accounts? Understanding Users&apos; Practices and Expectations on Mobile App Account Deletion.",
            "venue": "USENIX Security Symposium",
            "pages": "863-880",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiuJTLX22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/liu-yijing",
            "url": "https://dblp.org/rec/conf/uss/LiuJTLX22",
            "abstract": "Account deletion is an important way for users to exercise their right to delete. However, little work has been done to evaluate the usability of account deletion in mobile apps. In this paper, we conducted a 647-participants online survey covering two countries along with an additional 20-participants on-site interview to explore users\u2019 awareness, practices, and expectations for mobile app account deletion. The studies were based on the account deletion model we proposed, which was summarized from an empirical measurement covering 60 mobile apps. The results reveal that although account deletion is highly demanded, users commonly keep zombie app accounts in practice due to the lack of awareness. Moreover, users\u2019 understandings and expectations of account deletion are different from the current design of apps in many aspects. Our \ufb01ndings indicate that current ruleless implementations made consumers feel inconvenienced during the deletion process, especially the hidden entry and complex operation steps, which even blocked a non-negligible number of users exercising account deletion. Finally, we provide some design recommendations for making mobile app account deletion more usable for consumers.",
            "keywords": [
                "Mobile App Usability",
                "Account Deletion",
                "User Awareness",
                "Zombie Accounts",
                "User Expectations"
            ]
        },
        "url": "URL#1416970",
        "sema_paperId": "ac6887f85a8a690126da215bc71589aa3d52ac4b"
    },
    {
        "@score": "1",
        "@id": "1416971",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "227/9104",
                        "text": "Yugeng Liu"
                    },
                    {
                        "@pid": "63/10765-2",
                        "text": "Rui Wen 0002"
                    },
                    {
                        "@pid": "227/7262-1",
                        "text": "Xinlei He 0001"
                    },
                    {
                        "@pid": "41/506-1",
                        "text": "Ahmed Salem 0001"
                    },
                    {
                        "@pid": "90/545-1",
                        "text": "Zhikun Zhang 0001"
                    },
                    {
                        "@pid": "b/MichaelBackes1",
                        "text": "Michael Backes 0001"
                    },
                    {
                        "@pid": "36/6225",
                        "text": "Emiliano De Cristofaro"
                    },
                    {
                        "@pid": "07/5701",
                        "text": "Mario Fritz"
                    },
                    {
                        "@pid": "06/6785-16",
                        "text": "Yang Zhang 0016"
                    }
                ]
            },
            "title": "ML-Doctor: Holistic Risk Assessment of Inference Attacks Against Machine Learning Models.",
            "venue": "USENIX Security Symposium",
            "pages": "4525-4542",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiuWH000CF022",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/liu-yugeng",
            "url": "https://dblp.org/rec/conf/uss/LiuWH000CF022",
            "abstract": "Inference attacks against Machine Learning (ML) models allow adversaries to learn sensitive information about training data, model parameters, etc. While researchers have studied, in depth, several kinds of attacks, they have done so in isolation. As a result, we lack a comprehensive picture of the risks caused by the attacks, e.g., the different scenarios they can be applied to, the common factors that influence their performance, the relationship among them, or the effectiveness of possible defenses. In this paper, we fill this gap by presenting a first-of-its-kind holistic risk assessment of different inference attacks against machine learning models. We concentrate on four attacks -- namely, membership inference, model inversion, attribute inference, and model stealing -- and establish a threat model taxonomy.Our extensive experimental evaluation, run on five model architectures and four image datasets, shows that the complexity of the training dataset plays an important role with respect to the attack's performance, while the effectiveness of model stealing and membership inference attacks are negatively correlated. We also show that defenses like DP-SGD and Knowledge Distillation can only mitigate some of the inference attacks. Our analysis relies on a modular re-usable software, ML-Doctor, which enables ML model owners to assess the risks of deploying their models, and equally serves as a benchmark tool for researchers and practitioners.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-liu-yugeng.pdf",
            "keywords": [
                "Inference Attacks",
                "Risk Assessment",
                "Membership Inference",
                "Model Inversion",
                "Defensive Mechanisms"
            ]
        },
        "url": "URL#1416971"
    },
    {
        "@score": "1",
        "@id": "1416972",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "35/295-8",
                        "text": "Jian Liu 0008"
                    },
                    {
                        "@pid": "97/8166",
                        "text": "Lin Yi"
                    },
                    {
                        "@pid": "224/9379",
                        "text": "Weiteng Chen"
                    },
                    {
                        "@pid": "69/6818",
                        "text": "Chengyu Song"
                    },
                    {
                        "@pid": "31/8302",
                        "text": "Zhiyun Qian"
                    },
                    {
                        "@pid": "68/10566",
                        "text": "Qiuping Yi"
                    }
                ]
            },
            "title": "LinKRID: Vetting Imbalance Reference Counting in Linux kernel with Symbolic Execution.",
            "venue": "USENIX Security Symposium",
            "pages": "125-142",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiuYCSQY22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/liu-jian",
            "url": "https://dblp.org/rec/conf/uss/LiuYCSQY22",
            "abstract": "Linux kernel employs reference counters, which record the number of references to a shared kernel object, to track its lifecycle and prevent memory errors like use-after-free. However, the usage of reference counters can be tricky and often error-prone, especially considering unique kernel conventions of managing reference counters (e.g., external vs. internal reference counters). In this paper, we aim to automatically discover incorrect usage of reference counters, overcoming two key challenges: (1) scalability and (2) the aforementioned unique kernel conventions. Specifically, we develop a tiered program analysis based solution to efficiently and precisely check the imbalances between the change in the actual number of references and the corresponding reference counter. We apply our tool to the 4.14.0 kernel (with allyesconfig) and find 118 bugs, out of which 87 are new. The result shows our tool is scalable and effective.",
            "keywords": [
                "Linux Kernel",
                "Reference Counting",
                "Memory Management",
                "Symbolic Execution",
                "Bug Detection"
            ]
        },
        "url": "URL#1416972",
        "sema_paperId": "e7d77e6cb7d55e0811ae62f8cb82dbfff5105f9f"
    },
    {
        "@score": "1",
        "@id": "1416973",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "26/848",
                        "text": "Ning Luo"
                    },
                    {
                        "@pid": "281/0124",
                        "text": "Samuel Judson"
                    },
                    {
                        "@pid": "62/6761",
                        "text": "Timos Antonopoulos"
                    },
                    {
                        "@pid": "p/RuzicaPiskac",
                        "text": "Ruzica Piskac"
                    },
                    {
                        "@pid": "150/9413",
                        "text": "Xiao Wang 0012"
                    }
                ]
            },
            "title": "ppSAT: Towards Two-Party Private SAT Solving.",
            "venue": "USENIX Security Symposium",
            "pages": "2983-3000",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LuoJAPW22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/luo",
            "url": "https://dblp.org/rec/conf/uss/LuoJAPW22",
            "abstract": "We design and implement a privacy-preserving Boolean satisfiability (ppSAT) solver, which allows mutually distrustful parties to evaluate the conjunction of their input formulas while maintaining privacy. We first define a family of security guarantees reconcilable with the (known) exponential complexity of SAT solving, and then construct an oblivious variant of the classic DPLL algorithm which can be integrated with existing secure two-party computation (2PC) techniques. We further observe that most known SAT solving heuristics are unsuitable for 2PC, as they are highly data-dependent in order to minimize the number of exploration steps. Faced with how best to trade off between the number of steps and the cost of obliviously executing each one, we design three efficient oblivious heuristics, one deterministic and two randomized. As a result of this effort we are able to evaluate our ppSAT solver on small but practical instances arising from the haplotype inference problem in bioinformatics. We conclude by looking towards future directions for making ppSAT solving more practical, most especially the integration of conflict-driven clause learning (CDCL).",
            "pdf_url": "https://www.usenix.org/system/files/sec22-luo.pdf",
            "keywords": [
                "Privacy-Preserving Computation",
                "Boolean Satisfiability",
                "Two-Party Computation",
                "Haplotype Inference",
                "Oblivious Heuristics"
            ]
        },
        "url": "URL#1416973"
    },
    {
        "@score": "1",
        "@id": "1416974",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "265/8774",
                        "text": "Varun Madathil"
                    },
                    {
                        "@pid": "72/7642",
                        "text": "Alessandra Scafuro"
                    },
                    {
                        "@pid": "234/7668",
                        "text": "Istv\u00e1n Andr\u00e1s Seres"
                    },
                    {
                        "@pid": "242/3072",
                        "text": "Omer Shlomovits"
                    },
                    {
                        "@pid": "283/4483",
                        "text": "Denis Varlakov"
                    }
                ]
            },
            "title": "Private Signaling.",
            "venue": "USENIX Security Symposium",
            "pages": "3309-3326",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MadathilSSSV22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/madathil",
            "url": "https://dblp.org/rec/conf/uss/MadathilSSSV22",
            "abstract": "We introduce the problem of private signaling. In this problem, a sender posts a message on a certain location of a public bulletin board, and then posts a signal that allows only the intended recipient (and no one else) to learn that it is the recipient of the message posted at that location. Besides privacy, two efficiency requirements must be met. First, the sender and recipient do not participate in any out-of-band communication. Second, the overhead of the recipient must be (much) better than scanning the entire board.Existing techniques, such as server-aided fuzzy message detection (Beck et al., CCS'21), could be employed to solve the private signaling problem. However, this solution leads to a trade-off between privacy and efficiency, where the complexity of the recipient grows with the required privacy. Specifically, this would require a scan of the entire board to obtain full privacy for the recipient.In this work, we present a server-aided solution to the private signaling problem that guarantees full privacy for all recipients while requiring only constant amount of work for both the recipient and the sender.Specifically, we provide three contributions: First, we provide a formal definition of private signaling in the Universal Composability (UC) framework and show that it captures several real-world settings where recipient anonymity is desired. Second, we present two server-aided protocols that UC-realize our definitions: one using a single server equipped with a trusted execution environment, and one based on two servers that employ garbled circuits. Third, we provide an open-source implementation of both of our protocols, evaluate their performance, and identify for which sets of parameters they can be practical.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-madathil.pdf",
            "keywords": [
                "Private Signaling",
                "Recipient Anonymity",
                "Server-Aided Protocols",
                "Universal Composability",
                "Trusted Execution Environment"
            ]
        },
        "url": "URL#1416974"
    },
    {
        "@score": "1",
        "@id": "1416975",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "331/2735",
                        "text": "Marcel Maehren"
                    },
                    {
                        "@pid": "331/2817",
                        "text": "Philipp Nieting"
                    },
                    {
                        "@pid": "331/2250",
                        "text": "Sven Hebrok"
                    },
                    {
                        "@pid": "248/1716",
                        "text": "Robert Merget"
                    },
                    {
                        "@pid": "27/8331",
                        "text": "Juraj Somorovsky"
                    },
                    {
                        "@pid": "58/5730",
                        "text": "J\u00f6rg Schwenk"
                    }
                ]
            },
            "title": "TLS-Anvil: Adapting Combinatorial Testing for TLS Libraries.",
            "venue": "USENIX Security Symposium",
            "pages": "215-232",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MaehrenNHMSS22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/maehren",
            "url": "https://dblp.org/rec/conf/uss/MaehrenNHMSS22",
            "abstract": "Although the newest versions of TLS are considered secure, \ufb02awed implementations may undermine the promised security properties. Such implementation \ufb02aws result from the TLS speci\ufb01cations\u2019 complexity, with exponentially many possible parameter combinations. Combinatorial Testing (CT) is a technique to tame this complexity, but it is hard to apply to TLS due to semantic dependencies between the parameters and thus leaves the developers with a major challenge referred to as the test oracle problem : Determining if the observed behavior of software is correct for a given test input. In this work, we present TLS-Anvil, a test suite based on CT that can ef\ufb01ciently and systematically test parameter value combinations and overcome the oracle problem by dynamically extracting an implementation-speci\ufb01c input parameter model (IPM) that we constrained based on TLS speci\ufb01c parameter value interactions. Our approach thus carefully restricts the available input space, which in return allows us to reliably solve the oracle problem for any combination of values generated by the CT algorithm. We evaluated TLS-Anvil with 13 well known TLS implementations, including OpenSSL, BoringSSL, and NSS. Our evaluation revealed two new exploits in MatrixSSL, \ufb01ve issues directly in\ufb02uencing the cryptographic operations of a session, as well as 15 interoperability issues, 116 problems related to incorrect alert handling, and 100 other issues across all tested libraries.",
            "keywords": [
                "TLS Libraries",
                "Combinatorial Testing",
                "Implementation Flaws",
                "Test Oracle Problem",
                "Input Parameter Model (IPM)"
            ]
        },
        "url": "URL#1416975",
        "sema_paperId": "a01083ac0c707b18e35e76eca1a46da6499a49f5"
    },
    {
        "@score": "1",
        "@id": "1416976",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "280/8174",
                        "text": "Rasoul Akhavan Mahdavi"
                    },
                    {
                        "@pid": "26/5304",
                        "text": "Florian Kerschbaum"
                    }
                ]
            },
            "title": "Constant-weight PIR: Single-round Keyword PIR via Constant-weight Equality Operators.",
            "venue": "USENIX Security Symposium",
            "pages": "1723-1740",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MahdaviK22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/mahdavi",
            "url": "https://dblp.org/rec/conf/uss/MahdaviK22",
            "abstract": "Equality operators are an essential building block in tasks over secure computation such as private information retrieval. In private information retrieval (PIR), a user queries a database such that the server does not learn which element is queried. In this work, we propose \\emph{equality operators for constant-weight codewords}. A constant-weight code is a collection of codewords that share the same Hamming weight. Constant-weight equality operators have a multiplicative depth that depends only on the Hamming weight of the code, not the bit-length of the elements. In our experiments, we show how these equality operators are up to 10 times faster than existing equality operators. Furthermore, we propose PIR using the constant-weight equality operator or \\emph{constant-weight PIR}, which is a PIR protocol using an approach previously deemed impractical. We show that for private retrieval of large, streaming data, constant-weight PIR has a smaller communication complexity and lower runtime compared to SEALPIR and MulPIR, respectively, which are two state-of-the-art solutions for PIR. Moreover, we show how constant-weight PIR can be extended to keyword PIR. In keyword PIR, the desired element is retrieved by a unique identifier pertaining to the sought item, e.g., the name of a file. Previous solutions to keyword PIR require one or multiple rounds of communication to reduce the problem to normal PIR. We show that constant-weight PIR is the first practical single-round solution to single-server keyword PIR.",
            "keywords": [
                "Private Information Retrieval",
                "Constant-weight Codes",
                "Equality Operators",
                "Single-round Keyword PIR",
                "Communication Complexity"
            ]
        },
        "url": "URL#1416976",
        "sema_paperId": "ba9b1091845724e4245ff57d596a4d4c8254da43"
    },
    {
        "@score": "1",
        "@id": "1416977",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "204/0061",
                        "text": "Henrique Teles Maia"
                    },
                    {
                        "@pid": "66/10110",
                        "text": "Chang Xiao"
                    },
                    {
                        "@pid": "117/4807",
                        "text": "Dingzeyu Li"
                    },
                    {
                        "@pid": "25/5353",
                        "text": "Eitan Grinspun"
                    },
                    {
                        "@pid": "92/5285",
                        "text": "Changxi Zheng"
                    }
                ]
            },
            "title": "Can one hear the shape of a neural network?: Snooping the GPU via Magnetic Side Channel.",
            "venue": "USENIX Security Symposium",
            "pages": "4383-4400",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MaiaXLGZ22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/maia",
            "url": "https://dblp.org/rec/conf/uss/MaiaXLGZ22",
            "abstract": "Neural network applications have become popular in both enterprise and personal settings. Network solutions are tuned meticulously for each task, and designs that can robustly resolve queries end up in high demand. As the commercial value of accurate and performant machine learning models increases, so too does the demand to protect neural architectures as confidential investments. We explore the vulnerability of neural networks deployed as black boxes across accelerated hardware through electromagnetic side channels.\nWe examine the magnetic flux emanating from a graphics processing unit's power cable, as acquired by a cheap $3 induction sensor, and find that this signal betrays the detailed topology and hyperparameters of a black-box neural network model. The attack acquires the magnetic signal for one query with unknown input values, but known input dimension and batch size. The network reconstruction is possible due to the modular layer sequence in which deep neural networks are evaluated. We find that each layer component's evaluation produces an identifiable magnetic signal signature, from which layer topology, width, function type, and sequence order can be inferred using a suitably trained classifier and a joint consistency optimization based on integer programming.\nWe study the extent to which network specifications can be recovered, and consider metrics for comparing network similarity. We demonstrate the potential accuracy of this side channel attack in recovering the details for a broad range of network architectures, including random designs. We consider applications that may exploit this novel side channel exposure, such as adversarial transfer attacks. In response, we discuss countermeasures to protect against our method and other similar snooping techniques.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-maia.pdf",
            "keywords": [
                "Electromagnetic Side Channels",
                "Neural Network Topology",
                "Magnetic Signal Reconstruction",
                "Classifier Training",
                "Adversarial Transfer Attacks"
            ]
        },
        "url": "URL#1416977"
    },
    {
        "@score": "1",
        "@id": "1416978",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "224/6467",
                        "text": "Sujaya Maiyya"
                    },
                    {
                        "@pid": "306/1516",
                        "text": "Seif Ibrahim"
                    },
                    {
                        "@pid": "322/3512",
                        "text": "Caitlin Scarberry"
                    },
                    {
                        "@pid": "a/DivyakantAgrawal",
                        "text": "Divyakant Agrawal"
                    },
                    {
                        "@pid": "a/AmrElAbbadi",
                        "text": "Amr El Abbadi"
                    },
                    {
                        "@pid": "37/778",
                        "text": "Huijia Lin"
                    },
                    {
                        "@pid": "38/937",
                        "text": "Stefano Tessaro"
                    },
                    {
                        "@pid": "151/5215",
                        "text": "Victor Zakhary"
                    }
                ]
            },
            "title": "QuORAM: A Quorum-Replicated Fault Tolerant ORAM Datastore.",
            "venue": "USENIX Security Symposium",
            "pages": "3665-3682",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MaiyyaISAALTZ22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/maiyya",
            "url": "https://dblp.org/rec/conf/uss/MaiyyaISAALTZ22",
            "abstract": "Privacy and security challenges due to the outsourcing of data storage and processing to third-party cloud providers are well known. With regard to data privacy, Oblivious RAM (ORAM) schemes provide strong privacy guarantees by not only hiding the contents of the data (by encryption) but also obfuscating the access patterns of the outsourced data. But most existing ORAM datastores are not fault tolerant in that if the external storage server (which stores encrypted data) or the trusted proxy (which stores the encryption key and other metadata) crashes, an application loses all of its data. To achieve fault tolerance, we propose QuORAM, the first ORAM datastore to replicate data with a quorum-based replication protocol. QuORAM's contributions are three-fold: (i) it obfuscates access patterns to provide obliviousness guarantees, (ii) it replicates data using a novel lock-free and decentralized replication protocol to achieve fault tolerance, and (iii) it guarantees linearizable semantics. Experimentally evaluating QuORAM highlights counter-intuitive results: QuORAM incurs negligible cost to achieve obliviousness when compared to an insecure fault-tolerant replicated system; QuORAM's peak throughput is 2.4x of its non-replicated baseline; and QuORAM performs 33.2x better in terms of throughput than an ORAM datastore that relies on CockroachDB, an open-source geo-replicated database, for fault tolerance.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-maiyya.pdf",
            "keywords": [
                "Oblivious RAM",
                "Fault Tolerance",
                "Data Replication",
                "Quorum-Based Protocol",
                "Access Pattern Obfuscation"
            ]
        },
        "url": "URL#1416978"
    },
    {
        "@score": "1",
        "@id": "1416979",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "232/2235",
                        "text": "Sunil Manandhar"
                    },
                    {
                        "@pid": "222/2853",
                        "text": "Kaushal Kafle"
                    },
                    {
                        "@pid": "167/0165",
                        "text": "Benjamin Andow"
                    },
                    {
                        "@pid": "87/6804",
                        "text": "Kapil Singh"
                    },
                    {
                        "@pid": "136/8334",
                        "text": "Adwait Nadkarni"
                    }
                ]
            },
            "title": "Smart Home Privacy Policies Demystified: A Study of Availability, Content, and Coverage.",
            "venue": "USENIX Security Symposium",
            "pages": "3521-3538",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ManandharKASN22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/manandhar",
            "url": "https://dblp.org/rec/conf/uss/ManandharKASN22",
            "abstract": "Smart home devices transmit highly sensitive usage information to servers owned by vendors or third-parties as part of their core functionality. Hence, it is necessary to provide users with the context in which their device data is collected and shared, to enable them to weigh the bene\ufb01ts of deploying smart home technology against the resulting loss of privacy. As privacy policies are generally expected to precisely convey this information, we perform a systematic and data-driven analysis of the current state of smart home privacy policies, with a particular focus on three key questions: (1) how hard privacy policies are for consumers to obtain, (2) how existing policies describe the collection and sharing of device data, and (3) how accurate these descriptions are when compared to information derived from alternate sources. Our analysis of 596 smart home vendors, affecting 2 , 442 smart home devices yields 17 \ufb01ndings that impact millions of users, demonstrate gaps in existing smart home privacy policies, as well as challenges and opportunities for automated analysis.",
            "keywords": [
                "Smart Home Privacy",
                "Privacy Policies",
                "Data Collection",
                "User Privacy",
                "Automated Analysis"
            ]
        },
        "url": "URL#1416979",
        "sema_paperId": "63ffac0c9e21eca5e28b7ddacf7abacb940254b2"
    },
    {
        "@score": "1",
        "@id": "1416980",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "270/2295",
                        "text": "Alessandro Mantovani"
                    },
                    {
                        "@pid": "204/5152",
                        "text": "Simone Aonzo"
                    },
                    {
                        "@pid": "11/10929",
                        "text": "Yanick Fratantonio"
                    },
                    {
                        "@pid": "56/490",
                        "text": "Davide Balzarotti"
                    }
                ]
            },
            "title": "RE-Mind: a First Look Inside the Mind of a Reverse Engineer.",
            "venue": "USENIX Security Symposium",
            "pages": "2727-2745",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MantovaniAFB22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/mantovani",
            "url": "https://dblp.org/rec/conf/uss/MantovaniAFB22",
            "abstract": "When a human activity requires a lot of expertise and very specialized cognitive skills that are poorly understood by the general population, it is often considered \u2018an art.\u2019 Different activities in the security domain have fallen in this category, such as exploitation, hacking, and the main focus of this paper: binary reverse engineering (RE). However, while experts in many areas (ranging from chess players to computer programmers) have been studied by scientists to understand their mental models and capture what is special about their behavior, the \u2018art\u2019 of understanding binary code and solving reverse engineering puzzles remains to date a black box. In this paper, we present a measurement of the different strategies adopted by expert and beginner reverse engineers while approaching the analysis of x86 (dis)assembly code, a typical static RE task. We do that by performing an exploratory analysis of data collected over 16,325 minutes of RE activity of two unknown binaries from 72 participants with different experience levels: 39 novices and 33 experts.",
            "keywords": [
                "Binary Reverse Engineering",
                "x86 Assembly Analysis",
                "Expert vs. Novice Strategies",
                "Reverse Engineering Techniques",
                "Cognitive Skills in RE"
            ]
        },
        "url": "URL#1416980",
        "sema_paperId": "30c0d8a15d53e6272870c501fb19277808b24bf3"
    },
    {
        "@score": "1",
        "@id": "1416981",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "165/0174",
                        "text": "Andrea Marcelli"
                    },
                    {
                        "@pid": "123/3219",
                        "text": "Mariano Graziano"
                    },
                    {
                        "@pid": "86/9728",
                        "text": "Xabier Ugarte-Pedrero"
                    },
                    {
                        "@pid": "11/10929",
                        "text": "Yanick Fratantonio"
                    },
                    {
                        "@pid": "262/9484",
                        "text": "Mohamad Mansouri"
                    },
                    {
                        "@pid": "56/490",
                        "text": "Davide Balzarotti"
                    }
                ]
            },
            "title": "How Machine Learning Is Solving the Binary Function Similarity Problem.",
            "venue": "USENIX Security Symposium",
            "pages": "2099-2116",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MarcelliGUFMB22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/marcelli",
            "url": "https://dblp.org/rec/conf/uss/MarcelliGUFMB22",
            "abstract": "The ability to accurately compute the similarity between two pieces of binary code plays an important role in a wide range of different problems. Several research communities such as security, programming language analysis, and machine learning, have been working on this topic for more than \ufb01ve years, with hundreds of papers published on the subject. One would expect that, by now, it would be possible to answer a number of research questions that go beyond very speci\ufb01c techniques presented in papers, but that generalize to the entire research \ufb01eld. Unfortunately, this topic is affected by a number of challenges, ranging from reproducibility issues to opaqueness of research results, which hinders meaningful and effective progress. In this paper, we set out to perform the \ufb01rst measurement study on the state of the art of this research area. We begin by systematizing the existing body of research. We then identify a number of relevant approaches, which are representative of a wide range of solutions recently proposed by three different research communities. We re-implemented these approaches and created a new dataset (with binaries compiled with different compilers, optimizations settings, and for three different architectures), which enabled us to perform a fair and meaningful comparison. This effort allowed us to answer a number of research questions that go beyond what could be inferred by reading the individual research papers. By releasing our entire modular framework and our datasets (with associated documentation), we also hope to inspire future work in this interesting research area.",
            "keywords": [
                "Binary Code Similarity",
                "Reproducibility Issues",
                "Measurement Study",
                "Research Framework",
                "Dataset Creation"
            ]
        },
        "url": "URL#1416981",
        "sema_paperId": "c58c20e1f2de8ad32c4f2ef7816f24a69a1c1d7e"
    },
    {
        "@score": "1",
        "@id": "1416982",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "179/7489",
                        "text": "Karola Marky"
                    },
                    {
                        "@pid": "121/9504",
                        "text": "Paul Gerber"
                    },
                    {
                        "@pid": "67/6306-1",
                        "text": "Sebastian G\u00fcnther 0001"
                    },
                    {
                        "@pid": "129/9490",
                        "text": "Mohamed Khamis"
                    },
                    {
                        "@pid": "294/5026",
                        "text": "Maximilian Fries"
                    },
                    {
                        "@pid": "m/MaxMuhlhauser",
                        "text": "Max M\u00fchlh\u00e4user"
                    }
                ]
            },
            "title": "Investigating State-of-the-Art Practices for Fostering Subjective Trust in Online Voting through Interviews.",
            "venue": "USENIX Security Symposium",
            "pages": "4059-4076",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MarkyG0KFM22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/marky",
            "url": "https://dblp.org/rec/conf/uss/MarkyG0KFM22",
            "abstract": "Ensuring voters\u2019 subjective trust is key to adopting any voting system. Consequently, researchers, experts, and policymakers have proposed and implemented practices to foster the trust of voters in online voting. State-of-the-art practices include security features, public information, or evaluations. How-ever, it remains unclear how these practices affect the voters\u2019 subjective trust. Through interviews with 26 participants, this work presents the \ufb01rst analysis of voters\u2019 perceptions considering state-of-the-art practices that help voters determine their trust in Internet voting. Among our results, we show practices, such as expert evaluations, that we identi\ufb01ed as mandatory. Further, we found practices, such as individual veri\ufb01ability, that facilitate trust. Others, such as vote updating, have a negative impact due to unfamiliarity. We, furthermore, report misconceptions, discuss ways to address them through different information interfaces or as part of the voting software. Finally, we list recommendations for the speci\ufb01c realization of expedient practices to inform developers and policymakers.",
            "keywords": [
                "Online Voting",
                "Subjective Trust",
                "Voter Perception",
                "Trust Practices",
                "Expert Evaluations"
            ]
        },
        "url": "URL#1416982",
        "sema_paperId": "993580c8558206e83181cf69fa0955380e96ccbb"
    },
    {
        "@score": "1",
        "@id": "1416983",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "36/111-1",
                        "text": "Peter Mayer 0001"
                    },
                    {
                        "@pid": "293/9864",
                        "text": "Collins W. Munyendo"
                    },
                    {
                        "@pid": "20/7983",
                        "text": "Michelle L. Mazurek"
                    },
                    {
                        "@pid": "94/1554",
                        "text": "Adam J. Aviv"
                    }
                ]
            },
            "title": "Why Users (Don&apos;t) Use Password Managers at a Large Educational Institution.",
            "venue": "USENIX Security Symposium",
            "pages": "1849-1866",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MayerMMA22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/mayer",
            "url": "https://dblp.org/rec/conf/uss/MayerMMA22",
            "abstract": "We quantitatively investigated the current state of Password Manager (PM) usage and general password habits at a large, private university in the United States. Building on prior qualitative findings from SOUPS 2019, we survey n =277 faculty, staff, and students, finding that 77% of our participants already use PMs, but users of third-party PMs, as opposed to browser-based PMs, were significantly less likely to reuse their passwords across accounts. The largest factor encouraging PM adoption is perceived ease-of-use, indicating that communication and institutional campaigns should focus more on usability factors. Additionally, our work indicates the need for design improvements for browser-based PMs to encourage less password reuse as they are more widely adopted.",
            "keywords": [
                "Password Managers",
                "Usability",
                "Password Reuse",
                "User Adoption",
                "Educational Institution"
            ]
        },
        "url": "URL#1416983",
        "sema_paperId": "350fc2b0600b449564143076d1ffc6a096208b92"
    },
    {
        "@score": "1",
        "@id": "1416984",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "10/6810",
                        "text": "Robert McLaughlin"
                    },
                    {
                        "@pid": "123/3252",
                        "text": "Fabio Pagani"
                    },
                    {
                        "@pid": "303/5956",
                        "text": "Noah Spahn"
                    },
                    {
                        "@pid": "k/ChristopherKruegel",
                        "text": "Christopher Kruegel"
                    },
                    {
                        "@pid": "v/GiovanniVigna",
                        "text": "Giovanni Vigna"
                    }
                ]
            },
            "title": "Regulator: Dynamic Analysis to Detect ReDoS.",
            "venue": "USENIX Security Symposium",
            "pages": "4219-4235",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/McLaughlinPSKV22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/mclaughlin",
            "url": "https://dblp.org/rec/conf/uss/McLaughlinPSKV22",
            "abstract": "Regular expressions (regexps) are a convenient way for programmers to express complex string searching logic. Several popular programming languages expose an interface to a regexp matching subsystem, either by language-level primi-tives or through standard libraries. The implementations behind these matching systems vary greatly in their capabilities and running-time characteristics. In particular, backtracking matchers may exhibit worst-case running-time that is either linear, polynomial, or exponential in the length of the string being searched. Such super-linear worst-case regexps expose applications to Regular Expression Denial-of-Service (Re-DoS) when inputs can be controlled by an adversarial attacker. In this work, we investigate the impact of ReDoS in backtracking engines, a popular type of engine used by most programming languages. We evaluate several existing tools against a dataset of broadly collected regexps, and \ufb01nd that despite extensive theoretical work in this \ufb01eld, none are able to achieve both high precision and high recall. To address this gap in existing work, we develop R EGULATOR , a novel dynamic, fuzzer-based analysis system for identifying regexps vulnerable to ReDoS. We implement this system by directly instrumenting a popular backtracking regexp engine, which increases the scope of supported regexp syntax and features over prior work. Finally, we evaluate this system against three common regexp datasets, and demonstrate a seven-fold increase in true positives discovered when comparing against existing tools.",
            "keywords": [
                "Regular Expressions",
                "ReDoS",
                "Backtracking Engines",
                "Dynamic Analysis",
                "Fuzzer-based Analysis"
            ]
        },
        "url": "URL#1416984",
        "sema_paperId": "905a24eb915688eb5b0b6b872d3edec812f9536a"
    },
    {
        "@score": "1",
        "@id": "1416985",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "196/8838",
                        "text": "Shagufta Mehnaz"
                    },
                    {
                        "@pid": "184/4250",
                        "text": "Sayanton V. Dibbo"
                    },
                    {
                        "@pid": "312/5588",
                        "text": "Ehsanul Kabir"
                    },
                    {
                        "@pid": "l/NinghuiLi",
                        "text": "Ninghui Li"
                    },
                    {
                        "@pid": "b/ElisaBertino",
                        "text": "Elisa Bertino"
                    }
                ]
            },
            "title": "Are Your Sensitive Attributes Private? Novel Model Inversion Attribute Inference Attacks on Classification Models.",
            "venue": "USENIX Security Symposium",
            "pages": "4579-4596",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MehnazDKLB22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/mehnaz",
            "url": "https://dblp.org/rec/conf/uss/MehnazDKLB22",
            "abstract": "Increasing use of machine learning (ML) technologies in privacy-sensitive domains such as medical diagnoses, lifestyle predictions, and business decisions highlights the need to better understand if these ML technologies are introducing leakage of sensitive and proprietary training data. In this paper, we focus on model inversion attacks where the adversary knows non-sensitive attributes about records in the training data and aims to infer the value of a sensitive attribute unknown to the adversary, using only black-box access to the target classification model. We first devise a novel confidence score-based model inversion attribute inference attack that significantly outperforms the state-of-the-art. We then introduce a label-only model inversion attack that relies only on the model's predicted labels but still matches our confidence score-based attack in terms of attack effectiveness. We also extend our attacks to the scenario where some of the other (non-sensitive) attributes of a target record are unknown to the adversary. We evaluate our attacks on two types of machine learning models, decision tree and deep neural network, trained on three real datasets. Moreover, we empirically demonstrate the disparate vulnerability of model inversion attacks, i.e., specific groups in the training dataset (grouped by gender, race, etc.) could be more vulnerable to model inversion attacks.",
            "keywords": [
                "Model Inversion Attacks",
                "Attribute Inference",
                "Privacy Leakage",
                "Sensitive Attributes",
                "Disparate Vulnerability"
            ]
        },
        "url": "URL#1416985",
        "sema_paperId": "1c5508302ae71d7b591acceec645ed64ef22efe6"
    },
    {
        "@score": "1",
        "@id": "1416986",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "161/0164",
                        "text": "Aastha Mehta"
                    },
                    {
                        "@pid": "248/2254",
                        "text": "Mohamed Alzayat"
                    },
                    {
                        "@pid": "243/0062",
                        "text": "Roberta De Viti"
                    },
                    {
                        "@pid": "19/2942",
                        "text": "Bj\u00f6rn B. Brandenburg"
                    },
                    {
                        "@pid": "d/PDruschel",
                        "text": "Peter Druschel"
                    },
                    {
                        "@pid": "45/6786-1",
                        "text": "Deepak Garg 0001"
                    }
                ]
            },
            "title": "Pacer: Comprehensive Network Side-Channel Mitigation in the Cloud.",
            "venue": "USENIX Security Symposium",
            "pages": "2819-2838",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MehtaAVBD022",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/mehta",
            "url": "https://dblp.org/rec/conf/uss/MehtaAVBD022",
            "abstract": "Network side channels (NSCs) leak secrets through packet timing and packet sizes. They are of particular concern in public IaaS Clouds, where any tenant may be able to colocate and indirectly observe a victim's traffic shape. We present Pacer, the first system that eliminates NSC leaks in public IaaS Clouds end-to-end. It builds on the principled technique of shaping guest traffic outside the guest to make the traffic shape independent of secrets by design. However, Pacer also addresses important concerns that have not been considered in prior work -- it prevents internal side-channel leaks from affecting reshaped traffic, and it respects network flow control, congestion control and loss recovery signals. Pacer is implemented as a paravirtualizing extension to the host hypervisor, requiring modest changes to the hypervisor and the guest kernel, and only optional, minimal changes to applications. We present Pacer's key abstraction of a cloaked tunnel, describe its design and implementation, prove the security of important design aspects through a formal model, and show through an experimental evaluation that Pacer imposes moderate overheads on bandwidth, client latency, and server throughput, while thwarting attacks based on state-of-the-art CNN classifiers.",
            "keywords": [
                "Network Side Channels",
                "Cloud Security",
                "Traffic Shaping",
                "Paravirtualization",
                "Cloaked Tunnel"
            ]
        },
        "url": "URL#1416986",
        "sema_paperId": "f0f5925f9d2ff996f4762321e16110b751a46160"
    },
    {
        "@score": "1",
        "@id": "1416987",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "43/1032-1",
                        "text": "Yan Meng 0001"
                    },
                    {
                        "@pid": "09/7698",
                        "text": "Jiachun Li"
                    },
                    {
                        "@pid": "331/2035",
                        "text": "Matthew Pillari"
                    },
                    {
                        "@pid": "331/2803",
                        "text": "Arjun Deopujari"
                    },
                    {
                        "@pid": "331/2518",
                        "text": "Liam Brennan"
                    },
                    {
                        "@pid": "331/2814",
                        "text": "Hafsah Shamsie"
                    },
                    {
                        "@pid": "22/5702",
                        "text": "Haojin Zhu"
                    },
                    {
                        "@pid": "39/5423-1",
                        "text": "Yuan Tian 0001"
                    }
                ]
            },
            "title": "Your Microphone Array Retains Your Identity: A Robust Voice Liveness Detection System for Smart Speakers.",
            "venue": "USENIX Security Symposium",
            "pages": "1077-1094",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MengLPDBSZ022",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/meng",
            "url": "https://dblp.org/rec/conf/uss/MengLPDBSZ022",
            "abstract": "Though playing an essential role in smart home systems, smart speakers are vulnerable to voice spoo\ufb01ng attacks. Passive liveness detection, which utilizes only the collected audio rather than the deployed sensors to distinguish between live-human and replayed voices, has drawn increasing attention. However, it faces the challenge of performance degradation under the different environmental factors as well as the strict requirement of the \ufb01xed user gestures. In this study, we propose a novel liveness feature, array \ufb01ngerprint , which utilizes the microphone array inherently adopted by the smart speaker to determine the identity of collected audios. Our theoretical analysis demonstrates that by leveraging the circular layout of microphones, compared with existing schemes, array \ufb01ngerprint achieves a more robust performance under the environmental change and user\u2019s movement. Then, to leverage such a \ufb01ngerprint, we propose A RRAY ID, a lightweight passive detection scheme, and elaborate a series of features working together with array \ufb01n-gerprint. Our evaluation on the dataset containing 32,780 audio samples and 14 spoo\ufb01ng devices shows that A RRAY ID achieves an accuracy of 99.84%, which is superior to existing passive liveness detection schemes.",
            "keywords": [
                "Voice Liveness Detection",
                "Smart Speakers",
                "Voice Spoofing Attacks",
                "Microphone Array",
                "Array Fingerprint"
            ]
        },
        "url": "URL#1416987",
        "sema_paperId": "c64e49d387752d9aa4d0a5d57ab524ed20aa20e3"
    },
    {
        "@score": "1",
        "@id": "1416988",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "139/2505",
                        "text": "Mohsen Minaei"
                    },
                    {
                        "@pid": "87/8324",
                        "text": "Mainack Mondal"
                    },
                    {
                        "@pid": "12/3394",
                        "text": "Aniket Kate"
                    }
                ]
            },
            "title": "Empirical Understanding of Deletion Privacy: Experiences, Expectations, and Measures.",
            "venue": "USENIX Security Symposium",
            "pages": "3415-3432",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MinaeiMK22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/minaei",
            "url": "https://dblp.org/rec/conf/uss/MinaeiMK22",
            "abstract": "Social platforms are heavily used by individuals to share their thoughts and personal information. However, due to regret over time about posting inappropriate social content, embarrassment, or even life or relationship changes, some past posts might also pose serious privacy concerns for them. To cope with these privacy concerns, social platforms offer deletion mechanisms that allow users to remove their contents. Quite naturally, these deletion mechanisms are really useful for removing past posts as and when needed. However, these same mechanisms also leave the users potentially vulnerable to attacks by adversaries who specifically seek the users' damaging content and exploit the act of deletion as a strong signal for identifying such content. Unfortunately, today user experiences and contextual expectations regarding such attacks on deletion privacy and deletion privacy in general are not well understood. To that end, in this paper, we conduct a user survey-based exploration involving 191 participants to unpack their prior deletion experiences, their expectations of deletion privacy, and how effective they find the current deletion mechanisms. We find that more than 80% of the users have deleted at least a social media post, and users self-reported that, on average, around 35% of their deletions happened after a week of posting. While the participants identified the irrelevancy (due to time passing) as the main reason for content removal, most of them believed that deletions indicate that the deleted content includes some damaging information to the owner. Importantly, the participants are significantly more concerned about their deletions being noticed by large-scale data collectors (e.g., the government) than individuals from their social circle. Finally, the participants felt that popular deletion mechanisms are not very effective in protecting the privacy of those deletions.",
            "keywords": [
                "Deletion Privacy",
                "Social Media",
                "User Experience",
                "Privacy Concerns",
                "Data Deletion Mechanisms"
            ]
        },
        "url": "URL#1416988",
        "sema_paperId": "5625b117911c3c69f1b553a4918f9b36335ec5ca"
    },
    {
        "@score": "1",
        "@id": "1416989",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "280/8210",
                        "text": "Jaron Mink"
                    },
                    {
                        "@pid": "286/6495",
                        "text": "Licheng Luo"
                    },
                    {
                        "@pid": "162/9876",
                        "text": "Nat\u00e3 M. Barbosa"
                    },
                    {
                        "@pid": "307/9855",
                        "text": "Olivia Figueira"
                    },
                    {
                        "@pid": "w/YangWang5",
                        "text": "Yang Wang 0005"
                    },
                    {
                        "@pid": "71/4292-11",
                        "text": "Gang Wang 0011"
                    }
                ]
            },
            "title": "DeepPhish: Understanding User Trust Towards Artificially Generated Profiles in Online Social Networks.",
            "venue": "USENIX Security Symposium",
            "pages": "1669-1686",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MinkLBF0022",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/mink",
            "url": "https://dblp.org/rec/conf/uss/MinkLBF0022",
            "abstract": "Fabricated media from deep learning models, or deepfakes , have been recently applied to facilitate social engineering efforts by constructing a trusted social persona. While existing works are primarily focused on deepfake detection, little is done to understand how users perceive and interact with deep-fake persona (e.g., pro\ufb01les) in a social engineering context. In this paper, we conduct a user study ( n = 286) to quantitatively evaluate how deepfake artifacts affect the perceived trustworthiness of a social media pro\ufb01le and the pro\ufb01le\u2019s likelihood to connect with users. Our study investigates artifacts isolated within a single media \ufb01eld (images or text) as well as mismatched relations between multiple \ufb01elds. We also evaluate whether user prompting (or training) bene\ufb01ts users in this process. We \ufb01nd that artifacts and prompting significantly decrease the trustworthiness and request acceptance of deepfake pro\ufb01les. Even so, users still appear vulnerable with 43% of them connecting to a deepfake pro\ufb01le under the best-case conditions. Through qualitative data, we \ufb01nd numerous reasons why this task is challenging for users, such as the dif\ufb01culty of distinguishing text artifacts from honest mistakes and the social pressures entailed in the connection decisions. We conclude by discussing the implications of our results for content moderators, social media platforms, and future defenses.",
            "keywords": [
                "Deepfake Profiles",
                "User Trust",
                "Social Engineering",
                "Trustworthiness Assessment",
                "User Vulnerability"
            ]
        },
        "url": "URL#1416989",
        "sema_paperId": "63c78b6fe1aaa68a8807c9da8af513dfe5406bd4"
    },
    {
        "@score": "1",
        "@id": "1416990",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "119/3501",
                        "text": "Seyed Ali Mirheidari"
                    },
                    {
                        "@pid": "331/2805",
                        "text": "Matteo Golinelli"
                    },
                    {
                        "@pid": "77/8031",
                        "text": "Kaan Onarlioglu"
                    },
                    {
                        "@pid": "k/EnginKirda",
                        "text": "Engin Kirda"
                    },
                    {
                        "@pid": "c/BrunoCrispo",
                        "text": "Bruno Crispo"
                    }
                ]
            },
            "title": "Web Cache Deception Escalates!",
            "venue": "USENIX Security Symposium",
            "pages": "179-196",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MirheidariGOKC22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/mirheidari",
            "url": "https://dblp.org/rec/conf/uss/MirheidariGOKC22",
            "abstract": "Web Cache Deception (WCD) tricks a web cache into erroneously storing sensitive content, thereby making it widely accessible on the Internet. In a USENIX Security 2020 paper titled \u201cCached and Confused: Web Cache Deception in the Wild \u201d, researchers presented the first systematic exploration of the attack over 340 websites. This state-of-the-art approach for WCD detection injects markers into websites and checks for leaks into caches. However, this scheme has two fundamental limitations: 1) It cannot probe websites that do not present avenues for marker injection or reflection. 2) Marker setup is a burdensome process, making large-scale measurements infeasible. More generally, all previous literature on WCD focuses solely on personal information leaks on websites protected behind authentication gates, leaving important gaps in our understanding of the full ramifications of WCD. We expand our knowledge of WCD attacks, their spread, and implications. We propose a novel WCD detection methodology that forgoes testing prerequisites, and utilizes page identicality checks and cache header heuristics to test any website. We conduct a comparative experiment on 404 websites, and show that our scheme identifies over 100 vulnerabilities while \u201cCached and Confused\u201d is capped at 18. Equipped with a technique unhindered by the limitations of the previous work, we conduct the largest WCD experiment to date on the Alexa Top 10K, and detect 1188 vulnerable websites. We present case studies showing that WCD has consequences well beyond personal information leaks, and that attacks targeting non-authenticated pages are highly damaging.",
            "keywords": [
                "Web Cache Deception",
                "Cache Vulnerabilities",
                "Web Security",
                "Sensitive Content Exposure",
                "Cache Header Heuristics"
            ]
        },
        "url": "URL#1416990",
        "sema_paperId": "c3f8b7cf48203ea8b8398bcb7dab1ed8e49c56d4"
    },
    {
        "@score": "1",
        "@id": "1416991",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "264/7260",
                        "text": "Eyitemi Moju-Igbene"
                    },
                    {
                        "@pid": "331/2302",
                        "text": "Hanan Abdi"
                    },
                    {
                        "@pid": "130/0449",
                        "text": "Alan Lu"
                    },
                    {
                        "@pid": "83/8570",
                        "text": "Sauvik Das"
                    }
                ]
            },
            "title": "&quot;How Do You Not Lose Friends?&quot;: Synthesizing a Design Space of Social Controls for Securing Shared Digital Resources Via Participatory Design Jams.",
            "venue": "USENIX Security Symposium",
            "pages": "881-898",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Moju-IgbeneALD22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/moju-igbene",
            "url": "https://dblp.org/rec/conf/uss/Moju-IgbeneALD22",
            "abstract": "Digital resources (streaming services, banking accounts, collaborative documents, etc.) are commonly shared among small, social groups. Yet, the security and privacy (S&P) controls for these resources map poorly onto the reality of shared access and ownership (e.g., one shared Net\ufb02ix password for roommates). One challenge is that the design space for social S&P controls remains unclear. We bridged this gap by engaging end-users in participatory design workshops to envision social solutions to S&P challenges common to their groups. In analyzing the generated ideas and group discussions, we identi\ufb01ed four design considerations salient to social S&P controls: social transparency; structures of governance; stakes and responsibility; and, promoting pro-group S&P behaviors. Additionally, we discovered trade-offs and challenges that arise when designing social S&P controls: balancing group security versus individual privacy; combating social friction; mitigating social herding behaviors; and, minimizing coordination costs.",
            "keywords": [
                "Social Security Controls",
                "Participatory Design",
                "Digital Resource Sharing",
                "Group Privacy Challenges",
                "Social Governance Structures"
            ]
        },
        "url": "URL#1416991",
        "sema_paperId": "15692f618fd52fd33c5dd93573d979047ab778f6"
    },
    {
        "@score": "1",
        "@id": "1416992",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "293/9864",
                        "text": "Collins W. Munyendo"
                    },
                    {
                        "@pid": "260/6737",
                        "text": "Philipp Markert"
                    },
                    {
                        "@pid": "326/5249",
                        "text": "Alexandra Nisenoff"
                    },
                    {
                        "@pid": "301/5815",
                        "text": "Miles Grant"
                    },
                    {
                        "@pid": "331/2266",
                        "text": "Elena Korkes"
                    },
                    {
                        "@pid": "66/9786",
                        "text": "Blase Ur"
                    },
                    {
                        "@pid": "94/1554",
                        "text": "Adam J. Aviv"
                    }
                ]
            },
            "title": "&quot;The Same PIN, Just Longer&quot;: On the (In)Security of Upgrading PINs from 4 to 6 Digits.",
            "venue": "USENIX Security Symposium",
            "pages": "4023-4040",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MunyendoMNGKUA22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/munyendo",
            "url": "https://dblp.org/rec/conf/uss/MunyendoMNGKUA22",
            "abstract": "With the goal of improving security, companies like Apple have moved from requiring 4-digit PINs to 6-digit PINs in contexts like smartphone unlocking. Users with a 4-digit PIN thus must \u201cupgrade\u201d to a 6-digit PIN for the same device or account. In an online user study ( n = 1010), we explore the security of such upgrades. Participants used their own smart-phone to \ufb01rst select a 4-digit PIN. They were then directed to select a 6-digit PIN with one of \ufb01ve randomly assigned justi\ufb01cations. In an online attack that guesses a small number of common PINs (10\u201330), we observe that 6-digit PINs are, at best, marginally more secure than 4-digit PINs. To understand the relationship between 4-and 6-digit PINs, we then model targeted attacks for PIN upgrades. We \ufb01nd that attackers who know a user\u2019s previous 4-digit PIN perform signi\ufb01cantly better than those who do not at guessing their 6-digit PIN in only a few guesses using basic heuristics (e.g., appending digits to the 4-digit PIN). Participants who selected a 6-digit PIN when given a \u201cdevice upgrade\u201d justi\ufb01cation selected 6-digit PINs that were the easiest to guess in a targeted attack, with the attacker successfully guessing over 25% of the PINs in just 10 attempts, and more than 30% in 30 attempts. Our re-sults indicate that forcing users to upgrade to 6-digit PINs offers limited security improvements despite adding usability burdens. System designers should thus carefully consider this tradeoff before requiring upgrades.",
            "keywords": [
                "PIN Security",
                "User Authentication",
                "PIN Upgrade",
                "Targeted Attacks",
                "Usability Burden"
            ]
        },
        "url": "URL#1416992",
        "sema_paperId": "84127bb19486a7394d1cb504d499242a75b5457b"
    },
    {
        "@score": "1",
        "@id": "1416993",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "331/2591",
                        "text": "Cheolwoo Myung"
                    },
                    {
                        "@pid": "173/9806",
                        "text": "Gwangmu Lee"
                    },
                    {
                        "@pid": "45/7986",
                        "text": "Byoungyoung Lee"
                    }
                ]
            },
            "title": "MundoFuzz: Hypervisor Fuzzing with Statistical Coverage Testing and Grammar Inference.",
            "venue": "USENIX Security Symposium",
            "pages": "1257-1274",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MyungLL22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/myung",
            "url": "https://dblp.org/rec/conf/uss/MyungLL22",
            "abstract": "A hypervisor is system software, managing and running virtual machines. Since the hypervisor is placed at the lowest-level in the typical systems software stack, it has critical security implications. Once compromised, the entire software components running on top of the hypervisor (including all guest virtual machines and applications running within each guest virtual machine) are compromised as well, as the hypervisor has all the privileges to access those. This paper proposes M UNDO F UZZ , a hypervisor fuzzer to enable both coverage-guided and grammar-aware fuzzing. We find that the coverage measurement in hypervisors suffers from noises due to the hypervisor\u2019s asynchronous system event handling. In order to filter out such noises, M UNDO F UZZ develops a statistical differential coverage measurement methods, allowing M UNDO F UZZ to capture the clean coverage information for hypervisor inputs. Moreover, we observe that hypervisor inputs have complex input grammars because it supports many different devices and each device has its own input format. Thus, M UNDO F UZZ learns the input grammar through inspecting the coverage characteristics of the given hypervisor input, which is based on the idea that the hypervisor behaves in a different way if the grammatically correct (or incorrect) input is given. We evaluated M UNDO F UZZ with popular hypervisors, QEMU and Bhyve, and M UNDO F UZZ outperformed other state-of-the-art hypervisor fuzzers ranging from 4.91% to 6.60% in terms of coverage. More importantly, M UNDO F UZZ identified 40 pre-viously unknown bugs (including 9 CVEs), demonstrating its strong practical effectiveness in finding real-world hypervisor",
            "keywords": [
                "Hypervisor Fuzzing",
                "Statistical Coverage Testing",
                "Grammar Inference",
                "Virtual Machine Security",
                "Bug Detection"
            ]
        },
        "url": "URL#1416993",
        "sema_paperId": "9bb85fbfc2e626e2164257c0caa6232c6f4ce162"
    },
    {
        "@score": "1",
        "@id": "1416994",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "192/2096",
                        "text": "Ben Nassi"
                    },
                    {
                        "@pid": "268/5147",
                        "text": "Yaron Pirutin"
                    },
                    {
                        "@pid": "331/2608",
                        "text": "Raz Swisa"
                    },
                    {
                        "@pid": "s/AdiShamir",
                        "text": "Adi Shamir"
                    },
                    {
                        "@pid": "38/4086",
                        "text": "Yuval Elovici"
                    },
                    {
                        "@pid": "14/10501",
                        "text": "Boris Zadov"
                    }
                ]
            },
            "title": "Lamphone: Passive Sound Recovery from a Desk Lamp&apos;s Light Bulb Vibrations.",
            "venue": "USENIX Security Symposium",
            "pages": "4401-4417",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/NassiPSSEZ22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/nassi",
            "url": "https://dblp.org/rec/conf/uss/NassiPSSEZ22",
            "abstract": "\"In this paper, we introduce \"\"Lamphone,\"\" an optical side-channel attack used to recover sound from desk lamp light bulbs;such lamps are commonly used in home offices, which became a primary work setting during the COVID-19 pandemic. We show how fluctuations in the air pressure on the surface of a light bulb, which occur in response to sound and cause the bulb to vibrate very slightly (a millidegree vibration), can be exploited by eavesdroppers to recover speech passively, externally, and using equipment that provides no indication regarding its application. We analyze a light bulb's response to sound via an electro-optical sensor and learn how to isolate the audio signal from the optical signal. We compare Lamphone to related methods presented in other studies and show that Lamphone can recover sound at high quality and lower volume levels that those methods. Finally, we show that eavesdroppers can apply Lamphone in order to recover speech at the sound level of a virtual meeting with fair intelligibility when the victim is sitting/working at a desk that contains a desk lamp with a light bulb from a distance of 35 meters.\"",
            "keywords": [
                "Optical Side-Channel Attack",
                "Sound Recovery",
                "Desk Lamp Vibrations",
                "Eavesdropping",
                "Speech Intelligibility"
            ]
        },
        "url": "URL#1416994",
        "sema_paperId": "940b8ec549272a68aa9633bf196e901743458aa9"
    },
    {
        "@score": "1",
        "@id": "1416995",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "153/5738",
                        "text": "Thien Duc Nguyen"
                    },
                    {
                        "@pid": "283/4641",
                        "text": "Phillip Rieger"
                    },
                    {
                        "@pid": "122/1230",
                        "text": "Huili Chen"
                    },
                    {
                        "@pid": "268/5150",
                        "text": "Hossein Yalame"
                    },
                    {
                        "@pid": "277/9396",
                        "text": "Helen M\u00f6llering"
                    },
                    {
                        "@pid": "151/8708",
                        "text": "Hossein Fereidooni"
                    },
                    {
                        "@pid": "79/11359",
                        "text": "Samuel Marchal"
                    },
                    {
                        "@pid": "05/617",
                        "text": "Markus Miettinen"
                    },
                    {
                        "@pid": "18/8314",
                        "text": "Azalia Mirhoseini"
                    },
                    {
                        "@pid": "137/9430",
                        "text": "Shaza Zeitouni"
                    },
                    {
                        "@pid": "k/FarinazKoushanfar",
                        "text": "Farinaz Koushanfar"
                    },
                    {
                        "@pid": "s/AhmadRezaSadeghi",
                        "text": "Ahmad-Reza Sadeghi"
                    },
                    {
                        "@pid": "06/3872-3",
                        "text": "Thomas Schneider 0003"
                    }
                ]
            },
            "title": "FLAME: Taming Backdoors in Federated Learning.",
            "venue": "USENIX Security Symposium",
            "pages": "1415-1432",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/NguyenRCYMFMMMZ22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/nguyen",
            "url": "https://dblp.org/rec/conf/uss/NguyenRCYMFMMMZ22",
            "abstract": ",",
            "keywords": [
                "Federated Learning",
                "Backdoor Attacks",
                "Model Integrity",
                "Privacy Preservation",
                "Attack Mitigation"
            ]
        },
        "url": "URL#1416995",
        "sema_paperId": "4089197a8fef8935bab8b879adc08dc5fdf53c6d"
    },
    {
        "@score": "1",
        "@id": "1416996",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "292/5885",
                        "text": "Kentrell Owens"
                    },
                    {
                        "@pid": "331/2252",
                        "text": "Anita Alem"
                    },
                    {
                        "@pid": "23/2758",
                        "text": "Franziska Roesner"
                    },
                    {
                        "@pid": "k/TadayoshiKohno",
                        "text": "Tadayoshi Kohno"
                    }
                ]
            },
            "title": "Electronic Monitoring Smartphone Apps: An Analysis of Risks from Technical, Human-Centered, and Legal Perspectives.",
            "venue": "USENIX Security Symposium",
            "pages": "4077-4094",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/OwensARK22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/owens",
            "url": "https://dblp.org/rec/conf/uss/OwensARK22",
            "abstract": "Electronic monitoring is the use of technology to track individuals accused or convicted of a crime (or civil violation) as an \u201calternative to incarceration.\u201d Traditionally, this technology has been in the form of ankle monitors, but recently federal, state, and local entities around the U.S. are shifting to using smartphone applications for electronic monitoring. These applications (apps) purport to make the monitoring simpler and more convenient for both the community supervisor and the person being monitored. However, due to the multipurpose nature of smartphones in people\u2019s lives and the amount of sensitive information (e.g., sensor data) smartphones make available, this introduces new risks to people coerced to use these apps. To understand what type of privacy-related and other risks might be introduced to people who use these applications, we conducted a privacy-oriented analysis of 16 Android apps used for electronic monitoring. We analyzed the apps \ufb01rst technically, with static and (limited) dynamic analysis tech-niques. We also analyzed user reviews in the Google Play Store to understand the experiences of the people using these apps, and also the privacy policies. We found that apps contain numerous trackers, the permissions requested by them vary widely (with the most common one being location), and the reviews indicate that people \ufb01nd the apps invasive and frequently dysfunctional. We end the paper by encouraging mobile app marketplaces to reconsider their role in the future of electronic monitoring apps, and computer security and privacy researchers to consider their potential role in auditing carceral technologies. We hope that this work will lead to more transparency in this obfuscated ecosystem.",
            "keywords": [
                "Electronic Monitoring",
                "Smartphone Applications",
                "Privacy Risks",
                "User Experience",
                "Data Tracking"
            ]
        },
        "url": "URL#1416996",
        "sema_paperId": "6d2dcf9e82befc0580f6fac177c799de8d54c77c"
    },
    {
        "@score": "1",
        "@id": "1416997",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "147/1534",
                        "text": "Simon Oya"
                    },
                    {
                        "@pid": "26/5304",
                        "text": "Florian Kerschbaum"
                    }
                ]
            },
            "title": "IHOP: Improved Statistical Query Recovery against Searchable Symmetric Encryption through Quadratic Optimization.",
            "venue": "USENIX Security Symposium",
            "pages": "2407-2424",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/OyaK22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/oya",
            "url": "https://dblp.org/rec/conf/uss/OyaK22",
            "abstract": "Effective query recovery attacks against Searchable Symmetric Encryption (SSE) schemes typically rely on auxiliary ground-truth information about the queries or dataset. Query recovery is also possible under the weaker statistical auxiliary information assumption, although statistical-based attacks achieve lower accuracy and are not considered a serious threat. In this work we present IHOP, a statistical-based query recovery attack that formulates query recovery as a quadratic optimization problem and reaches a solution by iterating over linear assignment problems. We perform an extensive evaluation with five real datasets, and show that IHOP outperforms all other statistical-based query recovery attacks under different parameter and leakage configurations, including the case where the client uses some access-pattern obfuscation defenses. In some cases, our attack achieves almost perfect query recovery accuracy. Finally, we use IHOP in a frequency-only leakage setting where the client's queries are correlated, and show that our attack can exploit query dependencies even when PANCAKE, a recent frequency-hiding defense by Grubbs et al., is applied. Our findings indicate that statistical query recovery attacks pose a severe threat to privacy-preserving SSE schemes.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-oya.pdf",
            "keywords": [
                "Searchable Symmetric Encryption",
                "Query Recovery Attacks",
                "Statistical-based Attacks",
                "Quadratic Optimization",
                "Access-pattern Obfuscation"
            ]
        },
        "url": "URL#1416997"
    },
    {
        "@score": "1",
        "@id": "1416998",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "200/3122",
                        "text": "Alex Ozdemir"
                    },
                    {
                        "@pid": "b/DanBoneh",
                        "text": "Dan Boneh"
                    }
                ]
            },
            "title": "Experimenting with Collaborative zk-SNARKs: Zero-Knowledge Proofs for Distributed Secrets.",
            "venue": "USENIX Security Symposium",
            "pages": "4291-4308",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/OzdemirB22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/ozdemir",
            "url": "https://dblp.org/rec/conf/uss/OzdemirB22",
            "abstract": "A zk-SNARK is a powerful cryptographic primitive that provides a succinct and efficiently checkable argument that the prover has a witness to a public NP statement, without revealing the witness. However, in their native form, zk-SNARKs only apply to a secret witness held by a single party. In practice, a collection of parties often need to prove a statement where the secret witness is distributed or shared among them.We implement and experiment with collaborative zkSNARKs: proofs over the secrets of multiple, mutually distrusting parties. We construct these by lifting conventional zk-SNARKs into secure protocols among N provers to jointly produce a single proof over the distributed witness. We optimize the proof generation algorithm in pairing-based zkSNARKs so that algebraic techniques for multiparty computation (MPC) yield efficient proof generation protocols. For some zk-SNARKs, optimization is more challenging. This suggests MPC \"friendliness\" as an additional criterion for evaluating zk-SNARKs.We implement three collaborative proofs and evaluate the concrete cost of proof generation. We find that over a 3Gb/s link, security against a malicious minority of provers can be achieved with approximately the same runtime as a single prover. Security against N \u22121 malicious provers requires only a 2\u00d7 slowdown. This efficiency is unusual since most computations slow down by orders of magnitude when securely distributed. This efficiency means that most applications that can tolerate the cost of a single-prover proof should also be able to tolerate the cost of a collaborative proof.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-ozdemir.pdf",
            "keywords": [
                "zk-SNARKs",
                "Collaborative Proofs",
                "Multiparty Computation",
                "Distributed Secrets",
                "Proof Generation Efficiency"
            ]
        },
        "url": "URL#1416998"
    },
    {
        "@score": "1",
        "@id": "1416999",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "241/9681",
                        "text": "Bijeeta Pal"
                    },
                    {
                        "@pid": "208/1920-2",
                        "text": "Mazharul Islam 0002"
                    },
                    {
                        "@pid": "331/2515",
                        "text": "Marina Sanusi Bohuk"
                    },
                    {
                        "@pid": "172/5512",
                        "text": "Nick Sullivan"
                    },
                    {
                        "@pid": "166/6979",
                        "text": "Luke Valenta"
                    },
                    {
                        "@pid": "18/300",
                        "text": "Tara Whalen"
                    },
                    {
                        "@pid": "163/1886",
                        "text": "Christopher A. Wood"
                    },
                    {
                        "@pid": "26/3399",
                        "text": "Thomas Ristenpart"
                    },
                    {
                        "@pid": "03/9962",
                        "text": "Rahul Chatterjee 0001"
                    }
                ]
            },
            "title": "Might I Get Pwned: A Second Generation Compromised Credential Checking Service.",
            "venue": "USENIX Security Symposium",
            "pages": "1831-1848",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PalIBSVWWR022",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/pal",
            "url": "https://dblp.org/rec/conf/uss/PalIBSVWWR022",
            "abstract": "Credential stuffing attacks use stolen passwords to log into victim accounts. To defend against these attacks, recently deployed compromised credential checking (C3) services provide APIs that help users and companies check whether a username, password pair is exposed. These services however only check if the exact password is leaked, and therefore do not mitigate credential tweaking attacks - attempts to compromise a user account with variants of a user's leaked passwords. Recent work has shown credential tweaking attacks can compromise accounts quite effectively even when the credential stuffing countermeasures are in place. We initiate work on C3 services that protect users from credential tweaking attacks. The core underlying challenge is how to identify passwords that are similar to their leaked passwords while preserving honest clients' privacy and also preventing malicious clients from extracting breach data from the service. We formalize the problem and explore ways to measure password similarity that balance efficacy, performance, and security. Based on this study, we design\"Might I Get Pwned\"(MIGP), a new kind of breach alerting service. Our simulations show that MIGP reduces the efficacy of state-of-the-art 1000-guess credential tweaking attacks by 94%. MIGP preserves user privacy and limits potential exposure of sensitive breach entries. We show that the protocol is fast, with response time close to existing C3 services. We worked with Cloudflare to deploy MIGP in practice.",
            "keywords": [
                "Compromised Credential Checking",
                "Credential Stuffing",
                "Credential Tweaking Attacks",
                "Password Similarity",
                "Breach Alerting Service"
            ]
        },
        "url": "URL#1416999",
        "sema_paperId": "19c49cc9b937102934d21b25a89f331270b1b320"
    },
    {
        "@score": "1",
        "@id": "1417000",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "71/7816",
                        "text": "Xudong Pan"
                    },
                    {
                        "@pid": "84/2519-1",
                        "text": "Mi Zhang 0001"
                    },
                    {
                        "@pid": "247/1066",
                        "text": "Beina Sheng"
                    },
                    {
                        "@pid": "179/0957",
                        "text": "Jiaming Zhu"
                    },
                    {
                        "@pid": "02/1640-2",
                        "text": "Min Yang 0002"
                    }
                ]
            },
            "title": "Hidden Trigger Backdoor Attack on NLP Models via Linguistic Style Manipulation.",
            "venue": "USENIX Security Symposium",
            "pages": "3611-3628",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PanZSZ022",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/pan-hidden",
            "url": "https://dblp.org/rec/conf/uss/PanZSZ022",
            "abstract": "The vulnerability of deep neural networks (DNN) to backdoor (trojan) attacks is extensively studied for the image domain. In a backdoor attack, a DNN is modified to exhibit expected behaviors under attacker-specified inputs (i.e., triggers). Exploring the backdoor vulnerability of DNN in natural language processing (NLP), recent studies are limited to using specially added words/phrases as the trigger pattern (i.e., word-based triggers), which distorts the semantics of the base sentence, causes perceivable abnormality in linguistic features and can be eliminated by potential defensive techniques.\nIn this paper, we present LiMnguistic Style-Motivated backdoor attack (LISM), the first hidden trigger backdoor attack which exploits implicit linguistic styles for backdooring NLP models. Besides the basic requirements on attack success rate and normal model performance, LISM realizes the following advanced design goals compared with previous word-based backdoor: (a) LISM weaponizes text style transfer models to learn to generate sentences with an attacker-specified linguistic style (i.e., trigger style), which largely preserves the malicious semantics of the base sentence and reveals almost no abnormality exploitable by detection algorithms. (b) Each base sentence is dynamically paraphrased to hold the trigger style, which has almost no dependence on common words or phrases and therefore evades existing defenses which exploit the strong correlation between trigger words and misclassification. Extensive evaluation on 5 popular model architectures, 3 real-world security-critical tasks, 3 trigger styles and 3 potential countermeasures strongly validates the effectiveness and the stealthiness of LISM.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-pan-hidden.pdf",
            "keywords": [
                "Natural Language Processing",
                "Backdoor Attack",
                "Linguistic Style Manipulation",
                "Stealthy Trigger",
                "Text Style Transfer"
            ]
        },
        "url": "URL#1417000",
        "sema_paperId": "84a33d6966cbb2cf8f5192087b286122e806a242"
    },
    {
        "@score": "1",
        "@id": "1417001",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "71/7816",
                        "text": "Xudong Pan"
                    },
                    {
                        "@pid": "84/2519-1",
                        "text": "Mi Zhang 0001"
                    },
                    {
                        "@pid": "209/7183",
                        "text": "Yifan Yan"
                    },
                    {
                        "@pid": "179/0957",
                        "text": "Jiaming Zhu"
                    },
                    {
                        "@pid": "55/11040",
                        "text": "Zhemin Yang"
                    }
                ]
            },
            "title": "Exploring the Security Boundary of Data Reconstruction via Neuron Exclusivity Analysis.",
            "venue": "USENIX Security Symposium",
            "pages": "3989-4006",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PanZYZY22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/pan-exploring",
            "url": "https://dblp.org/rec/conf/uss/PanZYZY22",
            "abstract": "Among existing privacy attacks on the gradient of neural networks, \\emph{data reconstruction attack}, which reverse engineers the training batch from the gradient, poses a severe threat on the private training data. Despite its empirical success on large architectures and small training batches, unstable reconstruction accuracy is also observed when a smaller architecture or a larger batch is under attack. Due to the weak interpretability of existing learning-based attacks, there is little known on why, when and how data reconstruction attack is feasible. In our work, we perform the first analytic study on the security boundary of data reconstruction from gradient via a microcosmic view on neural networks with rectified linear units (ReLUs), the most popular activation function in practice. For the first time, we characterize the insecure/secure boundary of data reconstruction attack in terms of the \\emph{neuron exclusivity state} of a training batch, indexed by the number of \\emph{\\textbf{Ex}clusively \\textbf{A}ctivated \\textbf{N}eurons} (ExANs, i.e., a ReLU activated by only one sample in a batch). Intuitively, we show a training batch with more ExANs are more vulnerable to data reconstruction attack and vice versa. On the one hand, we construct a novel deterministic attack algorithm which substantially outperforms previous attacks for reconstructing training batches lying in the insecure boundary of a neural network. Meanwhile, for training batches lying in the secure boundary, we prove the impossibility of unique reconstruction, based on which an exclusivity reduction strategy is devised to enlarge the secure boundary for mitigation purposes.",
            "keywords": [
                "Data Reconstruction Attack",
                "Neuron Exclusivity",
                "Gradient Privacy",
                "Exclusively Activated Neurons (ExANs)",
                "Secure Boundary Analysis"
            ]
        },
        "url": "URL#1417001",
        "sema_paperId": "8dd6595d38a1aee0e4117f93f4d8ac1d173b3cfb"
    },
    {
        "@score": "1",
        "@id": "1417002",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "252/5223",
                        "text": "Ren Pang"
                    },
                    {
                        "@pid": "224/9296",
                        "text": "Zhaohan Xi"
                    },
                    {
                        "@pid": "07/8388",
                        "text": "Shouling Ji"
                    },
                    {
                        "@pid": "53/1565",
                        "text": "Xiapu Luo"
                    },
                    {
                        "@pid": "12/2633-6",
                        "text": "Ting Wang 0006"
                    }
                ]
            },
            "title": "On the Security Risks of AutoML.",
            "venue": "USENIX Security Symposium",
            "pages": "3953-3970",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PangXJL022",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/pang-ren",
            "url": "https://dblp.org/rec/conf/uss/PangXJL022",
            "abstract": "Neural architecture search (NAS) represents an emerging machine learning (ML) paradigm that automatically searches for model architectures tailored to given tasks, which significantly simplifies the development of ML systems and propels the trend of ML democratization. Yet, thus far little is known about the potential security risks incurred by NAS, which is concerning given the increasing use of NAS-generated models in critical domains. This work represents a solid initial step towards bridging the gap. First, through an extensive empirical study of 10 popular NAS methods, we show that compared with their manually designed counterparts, NAS-generated models tend to suffer greater vulnerabilities to various malicious manipulations (e.g., adversarial evasion, model poisoning, functionality stealing). Further, with both empirical and analytical evidence, we provide possible explanations for such phenomena: given the prohibitive search space and training cost, most NAS methods favor models that converge fast at early training stages; this preference results in architectural properties associated with attack vulnerabilities (e.g., high loss smoothness, low gradient variance). Our findings not only reveal the relationships between model characteristics and attack vulnerabilities but also suggest the inherent connections underlying different attacks. Finally, we discuss potential remedies to mitigate such drawbacks, including increasing cell depth and suppressing skip connects, which lead to several promising research directions.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-pang-ren.pdf",
            "keywords": [
                "Neural Architecture Search",
                "Model Vulnerabilities",
                "Adversarial Manipulations",
                "Model Poisoning",
                "Functionality Stealing"
            ]
        },
        "url": "URL#1417002"
    },
    {
        "@score": "1",
        "@id": "1417003",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "223/6697",
                        "text": "Chengbin Pang"
                    },
                    {
                        "@pid": "09/25",
                        "text": "Tiantai Zhang"
                    },
                    {
                        "@pid": "257/3247",
                        "text": "Ruotong Yu"
                    },
                    {
                        "@pid": "98/5039-1",
                        "text": "Bing Mao 0001"
                    },
                    {
                        "@pid": "90/514-24",
                        "text": "Jun Xu 0024"
                    }
                ]
            },
            "title": "Ground Truth for Binary Disassembly is Not Easy.",
            "venue": "USENIX Security Symposium",
            "pages": "2479-2495",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PangZYM022",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/pang-chengbin",
            "url": "https://dblp.org/rec/conf/uss/PangZYM022",
            "abstract": "Modern disassembly tools often rely on empirical evaluations to validate their performance and discover their limitations, thus promoting long-term evolvement. To support the empirical evaluation, a foundation is the right approach to collect the ground truth knowledge. However, there has been no unani-mous agreement on the approach we should use. Most users pick an approach based on their experience or will, regardless of the properties that the approach presents. In this paper, we perform a study on the approaches to building the ground truth for binary disassembly, aiming to shed light on the right way for the future. We \ufb01rst provide a taxonomy of the approaches used by past research, which unveils \ufb01ve major mechanisms behind those approaches. Following the taxonomy, we summarize the properties of the \ufb01ve mechanisms from two perspectives: (i) the coverage and precision of the ground truth produced by the mechanisms and (ii) the applicable scope of the mechanisms (e.g., what disassembly tasks and what types of binaries are supported). The summarization, accompanied by quantitative evaluations, illustrates that many mechanisms are ill-suited to support the generation of disassembly ground truth. The mechanism best serving today\u2019s need is to trace the compiling process of the target binaries to collect the ground truth information. Observing that the existing tool to trace the compiling process can still miss ground truth results and can only handle x86/x64 binaries, we extend the tool to avoid overlooking those results and support ARM32/AArch64/MIPS32/MIPS64 binaries. We envision that our extension will make the tool a better foundation to enable universal, standard ground truth for binary disassembly.",
            "keywords": [
                "Binary Disassembly",
                "Ground Truth",
                "Disassembly Evaluation",
                "Compiling Process",
                "Disassembly Mechanisms"
            ]
        },
        "url": "URL#1417003",
        "sema_paperId": "6d99eeb78cf85ef05de8c838644e8b5c104e9de7"
    },
    {
        "@score": "1",
        "@id": "1417004",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "283/0238",
                        "text": "CheolJun Park"
                    },
                    {
                        "@pid": "83/7954",
                        "text": "Sangwook Bae"
                    },
                    {
                        "@pid": "263/5973",
                        "text": "Beomseok Oh"
                    },
                    {
                        "@pid": "137/1560",
                        "text": "Jiho Lee"
                    },
                    {
                        "@pid": "51/6686",
                        "text": "Eunkyu Lee"
                    },
                    {
                        "@pid": "119/7670",
                        "text": "Insu Yun"
                    },
                    {
                        "@pid": "20/6892",
                        "text": "Yongdae Kim"
                    }
                ]
            },
            "title": "DoLTEst: In-depth Downlink Negative Testing Framework for LTE Devices.",
            "venue": "USENIX Security Symposium",
            "pages": "1325-1342",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ParkBOLLYK22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/park-cheoljun",
            "url": "https://dblp.org/rec/conf/uss/ParkBOLLYK22",
            "abstract": "An implementation \ufb02aw in LTE control plane protocols at end-user devices directly leads to severe security threats. In order to uncover these \ufb02aws, conducting negative testing is a promising approach, whose test case only contains invalid or prohibited messages. Despite its importance, the cellular standard mostly focuses on positive test cases, producing many implementation vulnerabilities unchecked, as evidenced by many existing vulnerabilities. To \ufb01ll this gap, we present D O LTE ST , a negative testing framework, which can comprehensively test an end-user device. Enumerable test cases with a deterministic oracle produced from detailed speci\ufb01cation analysis make it suitable to be used as a standard to \ufb01nd implementation vulnerabilities. We uncovered 26 implementation \ufb02aws from 43 devices from 5 different baseband manufacturers by using D O LTE ST , demonstrating its effectiveness.",
            "keywords": [
                "LTE Security",
                "Negative Testing",
                "Implementation Vulnerabilities",
                "Control Plane Protocols",
                "End-User Devices"
            ]
        },
        "url": "URL#1417004",
        "sema_paperId": "914a6d2b808830a1200ab2ef3d5a0f18bffa76a6"
    },
    {
        "@score": "1",
        "@id": "1417005",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "222/8260",
                        "text": "Sunnyeo Park"
                    },
                    {
                        "@pid": "248/1658",
                        "text": "Daejun Kim"
                    },
                    {
                        "@pid": "74/28",
                        "text": "Suman Jana"
                    },
                    {
                        "@pid": "09/3668",
                        "text": "Sooel Son"
                    }
                ]
            },
            "title": "FUGIO: Automatic Exploit Generation for PHP Object Injection Vulnerabilities.",
            "venue": "USENIX Security Symposium",
            "pages": "197-214",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ParkKJS22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/park-sunnyeo",
            "url": "https://dblp.org/rec/conf/uss/ParkKJS22",
            "abstract": "A PHP object injection (POI) vulnerability is a security-critical bug that allows the remote code execution of class methods existing in a vulnerable PHP application. Exploiting this vulnerability often requires sophisticated property-oriented programming to shape an injection object. Existing off-the-shelf tools focus only on identifying potential POI vulnerabilities without confirming the presence of any exploit objects. To this end, we propose FUGIO, the first automatic exploit generation (AEG) tool for POI vulnerabilities. FUGIO conducts coarse-grained static and dynamic program analyses to generate a list of gadget chains that serve as blueprints for exploit objects. FUGIO then runs fuzzing campaigns using these identified chains and produces exploit objects. FUGIO generated 68 exploit objects from 30 applications containing known POI vulnerabilities with zero false positives. FUGIO also found two previously unreported POI vulnerabilities with five exploits, demonstrating its efficacy in generating functional exploits.",
            "keywords": [
                "PHP Object Injection",
                "Automatic Exploit Generation",
                "Exploit Objects",
                "Vulnerability Detection",
                "Fuzzing Campaigns"
            ]
        },
        "url": "URL#1417005",
        "sema_paperId": "be7fb9376867a2981ae51291321086a24855ec54"
    },
    {
        "@score": "1",
        "@id": "1417006",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "124/5787",
                        "text": "Yuvraj Patel"
                    },
                    {
                        "@pid": "304/2139",
                        "text": "Chenhao Ye"
                    },
                    {
                        "@pid": "192/2771",
                        "text": "Akshat Sinha"
                    },
                    {
                        "@pid": "244/5051",
                        "text": "Abigail Matthews"
                    },
                    {
                        "@pid": "a/AndreaCArpaciDusseau",
                        "text": "Andrea C. Arpaci-Dusseau"
                    },
                    {
                        "@pid": "s/MichaelMSwift",
                        "text": "Michael M. Swift"
                    }
                ]
            },
            "title": "Using Tr\u0101t\u1e5b to tame Adversarial Synchronization.",
            "venue": "USENIX Security Symposium",
            "pages": "3897-3916",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PatelYSMAS22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/patel",
            "url": "https://dblp.org/rec/conf/uss/PatelYSMAS22",
            "abstract": "We show that Linux containers are vulnerable to a new class of attacks \u2013 synchronization attacks \u2013 that exploit kernel synchronization to harm application performance, where an unprivileged attacker can control the duration of kernel critical sections to stall victims running in other containers on the same operating system. Furthermore, a subset of these attacks \u2013 framing attacks \u2013 persistently harm performance by expanding data structures even after the attacker quiesces. We demonstrate three such attacks on the Linux kernel involving the inode cache, the directory cache, and the futex table.We design Tr\u0101t\u1e5b, a Linux kernel extension, to detect and mitigate synchronization and framing attacks with low overhead, prevent attacks from worsening, and recover by repairing data structures to their pre-attack state. Using microbenchmarks and real-world workloads, we show that Tr\u0101t\u1e5b can detect an attack within seconds and recover instantaneously, guaranteeing similar performance to baseline. Our experiments show that Tr\u0101t\u1e5b can detect simultaneous attacks and mitigate them with minimal overhead.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-patel.pdf",
            "keywords": [
                "Linux Containers",
                "Synchronization Attacks",
                "Kernel Performance",
                "Tr\u0101t\u1e5b",
                "Framing Attacks"
            ]
        },
        "url": "URL#1417006",
        "sema_paperId": "7abdfdc90da67eba76cb8b0ca0a9d80e13f3f09e"
    },
    {
        "@score": "1",
        "@id": "1417008",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "331/2025",
                        "text": "Lukas Petzi"
                    },
                    {
                        "@pid": "327/9300",
                        "text": "Ala Eddine Ben Yahya"
                    },
                    {
                        "@pid": "67/8264",
                        "text": "Alexandra Dmitrienko"
                    },
                    {
                        "@pid": "08/1183",
                        "text": "Gene Tsudik"
                    },
                    {
                        "@pid": "251/5431",
                        "text": "Thomas Prantl"
                    },
                    {
                        "@pid": "k/SamuelKounev",
                        "text": "Samuel Kounev"
                    }
                ]
            },
            "title": "SCRAPS: Scalable Collective Remote Attestation for Pub-Sub IoT Networks with Untrusted Proxy Verifier.",
            "venue": "USENIX Security Symposium",
            "pages": "3485-3501",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PetziYDTPK22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/petzi",
            "url": "https://dblp.org/rec/conf/uss/PetziYDTPK22",
            "abstract": "Remote Attestation ( RA ) is a basic security mechanism that detects malicious presence on various types of computing components, e.g., IoT devices. In a typical IoT setting, RA involves a trusted Veri\ufb01er that sends a challenge to an untrusted remote Prover , which must in turn reply with a fresh and authentic evidence of being in a trustworthy state. However, most current RA schemes assume a central Veri\ufb01er , which represents a single point of failure. This feature is problematic when mutually suspicious stakeholders are involved. Furthermore, scalability issues arise as the number of IoT devices ( Provers ) grows. Although some RA schemes allow peer Provers to act as Veri\ufb01ers , they involve unrealistic (for IoT devices) requirements, such as time synchronization and synchronous communication. Moreover, they incur heavy memory, computation, and communication burdens, while not considering sleeping or otherwise disconnected devices. Motivated by the need to address these limitations, we construct S calable C ollective R emote A ttestation for P ub-S ub ( SCRAPS ), a novel collective RA scheme. It achieves scalability by outsourcing Ver-i\ufb01er duties to a smart contract and mitigates DoS attacks against both Provers and Veri\ufb01ers . It also removes the need for synchronous communication. Furthermore, RA evidence in SCRAPS is publicly veri\ufb01able, which signi\ufb01cantly reduces the number of attestation evidence computations, thus lowering Prover burden. We report on SCRAPS prototype implemented over Hyperledger Sawtooth (a blockchain geared for IoT use-cases) and evaluate its performance, scalability, and security aspects.",
            "keywords": [
                "Remote Attestation",
                "IoT Security",
                "Scalable Verification",
                "Untrusted Proxy",
                "Blockchain for IoT"
            ]
        },
        "url": "URL#1417008",
        "sema_paperId": "6eead8e6b01f7571336785fa218fa90364446264"
    },
    {
        "@score": "1",
        "@id": "1417009",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "221/3626",
                        "text": "Victor Le Pochat"
                    },
                    {
                        "@pid": "236/5179",
                        "text": "Laura Edelson"
                    },
                    {
                        "@pid": "147/2244",
                        "text": "Tom van Goethem"
                    },
                    {
                        "@pid": "13/86",
                        "text": "Wouter Joosen"
                    },
                    {
                        "@pid": "58/4016",
                        "text": "Damon McCoy"
                    },
                    {
                        "@pid": "00/3175",
                        "text": "Tobias Lauinger"
                    }
                ]
            },
            "title": "An Audit of Facebook&apos;s Political Ad Policy Enforcement.",
            "venue": "USENIX Security Symposium",
            "pages": "607-624",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PochatEGJML22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/lepochat",
            "url": "https://dblp.org/rec/conf/uss/PochatEGJML22",
            "abstract": "Major technology companies strive to protect the integrity of political advertising on their platforms by implementing and enforcing self-regulatory policies that impose transparency requirements on political ads. In this paper, we quantify whether Facebook\u2019s current enforcement correctly identi\ufb01es political ads and ensures compliance by advertisers. In a comprehensive, large-scale analysis of 4.2 million political and 29.6 million non-political ads from 215,030 advertisers, we identify ads correctly detected as political ( true positives ), ads incorrectly detected ( false positives ), and ads missed by detection ( false negatives ). Facebook\u2019s current enforcement appears imprecise: 61% more ads are missed than are detected worldwide, and 55% of U.S. detected ads are in fact non-political. Detection performance is uneven across countries, with some having up to 53 times higher false negative rates among clearly political pages than in the U.S. Moreover, enforcement appears inadequate for preventing systematic violations of political advertising policies: for example, advertisers were able to continue running political ads without disclosing them while they were temporarily prohibited in the U.S. We attribute these \ufb02aws to \ufb01ve gaps in Facebook\u2019s current enforcement and transparency implementation, and close with recommendations to improve the security of the online political ad ecosystem.",
            "keywords": [
                "Political Advertising",
                "Ad Policy Enforcement",
                "Transparency Requirements",
                "False Positives",
                "False Negatives"
            ]
        },
        "url": "URL#1417009",
        "sema_paperId": "0d5ebff6e81bbbf9b801dfdf4dd32048050aa901"
    },
    {
        "@score": "1",
        "@id": "1417010",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "168/2691",
                        "text": "Bernd Pr\u00fcnster"
                    },
                    {
                        "@pid": "79/11260",
                        "text": "Alexander Marsalek"
                    },
                    {
                        "@pid": "30/5214",
                        "text": "Thomas Zefferer"
                    }
                ]
            },
            "title": "Total Eclipse of the Heart - Disrupting the InterPlanetary File System.",
            "venue": "USENIX Security Symposium",
            "pages": "3735-3752",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PrunsterMZ22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/prunster",
            "url": "https://dblp.org/rec/conf/uss/PrunsterMZ22",
            "abstract": "Peer-to-peer networks are an attractive alternative to classical client-server architectures in several fields of application such as voice-over-IP telephony and file sharing. Recently, a new peer-to-peer solution called the InterPlanetary File System (IPFS) has attracted attention, which promises to re-decentralise the Web. Being increasingly used as a stand-alone application, IPFS has also emerged as the technical backbone of various other decentralised solutions and was even used to evade censorship. Decentralised applications serving millions of users rely on IPFS as one of their crucial building blocks. This popularity makes IPFS attractive for large-scale attacks. We have identified a conceptual issue in one of IPFS's core libraries and demonstrate their exploitation by means of a successful end-to-end attack. We evaluated this attack against the IPFS reference implementation on the public IPFS network, which is used by the average user to share and consume IPFS content. Results obtained from mounting this attack on live IPFS nodes show that arbitrary IPFS nodes can be eclipsed, i.e. isolated from the network, with moderate effort and limited resources. Compared to similar works, we show that our attack scales linearly even beyond current network sizes and can disrupt the entire public IPFS network with alarmingly low effort. The vulnerability set described in this paper has been assigned CVE-2020-10937. Responsible disclosure procedures are currently being carried out and have led to mitigations being deployed, with additional fixes to be rolled out in future releases.",
            "keywords": [
                "InterPlanetary File System (IPFS)",
                "Peer-to-Peer Networks",
                "Decentralization",
                "Network Vulnerability",
                "Eclipse Attack"
            ]
        },
        "url": "URL#1417010",
        "sema_paperId": "cc48b0ba231e5991ebf6e7fd07646f03493ba1e7"
    },
    {
        "@score": "1",
        "@id": "1417011",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "237/4710",
                        "text": "Antoon Purnal"
                    },
                    {
                        "@pid": "186/8758",
                        "text": "Furkan Turan"
                    },
                    {
                        "@pid": "92/16",
                        "text": "Ingrid Verbauwhede"
                    }
                ]
            },
            "title": "Double Trouble: Combined Heterogeneous Attacks on Non-Inclusive Cache Hierarchies.",
            "venue": "USENIX Security Symposium",
            "pages": "3647-3664",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PurnalTV22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/purnal",
            "url": "https://dblp.org/rec/conf/uss/PurnalTV22",
            "abstract": "As the performance of general-purpose processors faces di-minishing improvements, computing systems are increasingly equipped with domain-speci\ufb01c accelerators. Today\u2019s high-end servers tightly integrate such accelerators with the CPU, e.g., giving them direct access to the CPU\u2019s last-level cache ( LLC ). Caches are an important source of information leakage across security domains. This work explores combined cache attacks, complementing traditional co-tenancy with control over one or more accelerators. The constraints imposed on these accelerators, originally perceived as limitations, turn out to be advantageous to an attacker. We develop a novel approach for accelerators to \ufb01nd eviction sets, and leverage precise double-sided control over cache lines to expose undocumented behavior in non-inclusive Intel cache hierarchies. We develop a compact and extensible FPGA hardware accelerator to demonstrate our \ufb01ndings. It constructs eviction sets at unprecedented speeds ( < 200\u00b5s), outperforming existing techniques with one to three orders of magnitude. It maintains excellent performance, even under high noise pres-sure. We also use the accelerator to set up a covert channel with \ufb01ne spatial granularity, encoding more than 3 bits per cache set. Furthermore, it can ef\ufb01ciently evict shared targets with tiny eviction sets, refuting the common assumption that eviction sets must be as large as the cache associativity.",
            "keywords": [
                "Cache Attacks",
                "Non-Inclusive Cache Hierarchies",
                "Eviction Sets",
                "FPGA Hardware Accelerator",
                "Covert Channel"
            ]
        },
        "url": "URL#1417011",
        "sema_paperId": "290a896e5d12f997ebabfca64ab52b9674bb1aaa"
    },
    {
        "@score": "1",
        "@id": "1417013",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "331/2299",
                        "text": "Lancheng Qin"
                    },
                    {
                        "@pid": "48/4185",
                        "text": "Dan Li"
                    },
                    {
                        "@pid": "38/6776",
                        "text": "Ruifeng Li"
                    },
                    {
                        "@pid": "30/6102",
                        "text": "Kang Wang"
                    }
                ]
            },
            "title": "Themis: Accelerating the Detection of Route Origin Hijacking by Distinguishing Legitimate and Illegitimate MOAS.",
            "venue": "USENIX Security Symposium",
            "pages": "4509-4524",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/QinLLW22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/qin",
            "url": "https://dblp.org/rec/conf/uss/QinLLW22",
            "abstract": "Route hijacking is one of the most severe security problems in today\u2019s Internet, and route origin hijacking is the most common. While origin hijacking detection systems are already available, they suffer from tremendous pressures brought by frequent legitimate Multiple origin ASes (MOAS) con\ufb02icts. They detect MOAS con\ufb02icts on the control plane and then identify origin hijackings by data-plane probing or even manual veri\ufb01cation. However, legitimate changes in pre\ufb01x ownership can also cause MOAS con\ufb02icts, which are the majority of MOAS con\ufb02icts daily. Massive legitimate MOAS con\ufb02icts consume many resources for probing and identi\ufb01cation, resulting in high veri\ufb01cation costs and high veri\ufb01cation latency in practice. In this paper, we propose a new origin hijacking system Themis to accelerate the detection of origin hijacking. Based on the ground truth dataset we built, we analyze the characteristics of different MOAS con\ufb02icts and train a clas-si\ufb01er to \ufb01lter out legitimate MOAS con\ufb02icts on the control plane. The accuracy and recall of the MOAS classi\ufb01er are 95.49% and 99.20%, respectively. Using the MOAS classi-\ufb01er, Themis reduces 56.69% of veri\ufb01cation costs than Argus, the state-of-the-art, and signi\ufb01cantly accelerates the detection when many concurrent MOAS con\ufb02icts occur. The overall accuracy of Themis is almost the same as Argus.",
            "keywords": [
                "Route Origin Hijacking",
                "Multiple Origin ASes (MOAS)",
                "Origin Hijacking Detection",
                "Verification Costs",
                "Themis System"
            ]
        },
        "url": "URL#1417013",
        "sema_paperId": "d16205d657ffe3072fd24c0d3c81a74fc89d976e"
    },
    {
        "@score": "1",
        "@id": "1417014",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "144/5265",
                        "text": "A. S. M. Rizvi"
                    },
                    {
                        "@pid": "45/2226",
                        "text": "Leandro M. Bertholdo"
                    },
                    {
                        "@pid": "03/9064",
                        "text": "Jo\u00e3o M. Ceron"
                    },
                    {
                        "@pid": "h/JohnSHeidemann",
                        "text": "John S. Heidemann"
                    }
                ]
            },
            "title": "Anycast Agility: Network Playbooks to Fight DDoS.",
            "venue": "USENIX Security Symposium",
            "pages": "4201-4218",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RizviBCH22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/rizvi",
            "url": "https://dblp.org/rec/conf/uss/RizviBCH22",
            "abstract": "IP anycast is used for services such as DNS and Content Delivery Networks (CDN) to provide the capacity to handle Distributed Denial-of-Service (DDoS) attacks. During a DDoS attack service operators redistribute traffic between anycast sites to take advantage of sites with unused or greater capacity. Depending on site traffic and attack size, operators may instead concentrate attackers in a few sites to preserve operation in others. Operators use these actions during attacks, but how to do so has not been described systematically or publicly. This paper describes several methods to use BGP to shift traffic when under DDoS, and shows that a response playbook can provide a menu of responses that are options during an attack. To choose an appropriate response from this playbook, we also describe a new method to estimate true attack size, even though the operator's view during the attack is incomplete. Finally, operator choices are constrained by distributed routing policies, and not all are helpful. We explore how specific anycast deployment can constrain options in this playbook, and are the first to measure how generally applicable they are across multiple anycast networks.",
            "keywords": [
                "IP Anycast",
                "DDoS Mitigation",
                "Traffic Redistribution",
                "BGP Routing",
                "Attack Size Estimation"
            ]
        },
        "url": "URL#1417014",
        "sema_paperId": "fe9c3a563af3b82db261dfed4568cd4a273d4518"
    },
    {
        "@score": "1",
        "@id": "1417015",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "295/1057",
                        "text": "Simon Rohlmann"
                    },
                    {
                        "@pid": "57/11338",
                        "text": "Christian Mainka"
                    },
                    {
                        "@pid": "138/0964",
                        "text": "Vladislav Mladenov"
                    },
                    {
                        "@pid": "58/5730",
                        "text": "J\u00f6rg Schwenk"
                    }
                ]
            },
            "title": "Oops... Code Execution and Content Spoofing: The First Comprehensive Analysis of OpenDocument Signatures.",
            "venue": "USENIX Security Symposium",
            "pages": "3075-3092",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RohlmannMMS22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/rohlmann",
            "url": "https://dblp.org/rec/conf/uss/RohlmannMMS22",
            "abstract": "OpenDocument is one of the major standards for inter-operable office documents. Supported by office suites like Apache OpenOffice, LibreOffice, and Microsoft Office, the OpenDocument Format (ODF) is available for text processing, spreadsheets, and presentations on all major desktop and mobile operating systems. When it comes to governmental and business use cases, OpenDocument signatures can protect the integrity of a doc-ument\u2019s content, for example, for contracts, amendments, or bills. Moreover OpenDocument signatures also protect document\u2019s macros. Since the risks of using macros in documents is well-known, modern office applications only enable their execution if a trusted entity signs the macro code. Thus, the security of ODF documents often depends on the correct signature verification. In this paper, we conduct the first comprehensive analysis of OpenDocument signatures and reveal numerous severe threats. We identified five new attacks and evaluated them against 16 office applications on Windows, macOS, Linux, iOS, Android, and two online services. Our investigation revealed 12 out of 18 applications to be vulnerable for macro code execution, although the application only executes macros signed by trusted entities. For 17 of 18 applications, we could spoof the content in a signed ODF document while keeping the signature valid and trusted. Finally, we showed that at-tackers possessing a signed ODF could alter and forge the signature creation time in 16 of 18 applications. Our research was acknowledged by Microsoft, Apache OpenOffice, and LibreOffice during the coordinated disclosure.",
            "keywords": [
                "OpenDocument Format",
                "Document Signatures",
                "Macro Code Execution",
                "Content Spoofing",
                "Signature Verification Vulnerabilities"
            ]
        },
        "url": "URL#1417015",
        "sema_paperId": "b1454282146a07a9ef188ae09d0f9f64f135acd5"
    },
    {
        "@score": "1",
        "@id": "1417016",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "244/5274",
                        "text": "Sebastian Roth"
                    },
                    {
                        "@pid": "89/9526",
                        "text": "Stefano Calzavara"
                    },
                    {
                        "@pid": "331/2052",
                        "text": "Moritz Wilhelm"
                    },
                    {
                        "@pid": "159/0703",
                        "text": "Alvise Rabitti"
                    },
                    {
                        "@pid": "136/8343",
                        "text": "Ben Stock"
                    }
                ]
            },
            "title": "The Security Lottery: Measuring Client-Side Web Security Inconsistencies.",
            "venue": "USENIX Security Symposium",
            "pages": "2047-2064",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RothCWRS22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/roth",
            "url": "https://dblp.org/rec/conf/uss/RothCWRS22",
            "abstract": "To mitigate a myriad of Web attacks, modern browsers support client-side security policies shipped through HTTP response headers. To enforce these defenses, the server needs to communicate them to the client, a seemingly straightforward process. However, users may access the same site in variegate ways, e.g., using different User-Agents, network access meth-ods, or language settings. All these usage scenarios should enforce the same security policies, otherwise a security lottery would take place: depending on specific client characteristics, different levels of Web application security would be provided to users ( inconsistencies ). We formalize security guarantees provided through four popular mechanisms and apply this to measure the prevalence of inconsistencies in the security policies of top sites across different client characteristics. Based on our insights, we investigate the security implications of both deterministic and non-deterministic inconsistencies, and show how even prominent services are affected by them.",
            "keywords": [
                "Client-Side Security",
                "Web Security Policies",
                "Security Inconsistencies",
                "HTTP Response Headers",
                "User-Agent Variability"
            ]
        },
        "url": "URL#1417016",
        "sema_paperId": "5e19389db83c335ed6e973b042703f7e4966645a"
    },
    {
        "@score": "1",
        "@id": "1417017",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "195/7997",
                        "text": "Lawrence Roy"
                    },
                    {
                        "@pid": "322/3442",
                        "text": "Stanislav Lyakhov"
                    },
                    {
                        "@pid": "150/5222",
                        "text": "Yeongjin Jang"
                    },
                    {
                        "@pid": "r/MikeRosulek",
                        "text": "Mike Rosulek"
                    }
                ]
            },
            "title": "Practical Privacy-Preserving Authentication for SSH.",
            "venue": "USENIX Security Symposium",
            "pages": "3345-3362",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RoyLJR22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/roy",
            "url": "https://dblp.org/rec/conf/uss/RoyLJR22",
            "abstract": "Public-key authentication in SSH reveals more information about the participants' keys than is necessary. (1) The server can learn a client's entire set of public keys, even keys generated for other servers. (2) The server learns exactly which key the client uses to authenticate, and can further prove this fact to a third party. (3) A client can learn whether the server recognizes public keys belonging to other users. Each of these problems lead to tangible privacy violations for SSH users.\nIn this work we introduce a new public-key authentication method for SSH that reveals essentially the minimum possible amount of information. With our new method, the server learns only whether the client knows the private key for some authorized public key. If multiple keys are authorized, the server does not learn which one the client used. The client cannot learn whether the server recognizes public keys belonging to other users. Unlike traditional SSH authentication, our method is fully deniable.\nOur method supports existing SSH keypairs of all standard flavors\u2014RSA, ECDSA, EdDSA. It does not require users to generate new key material. As in traditional SSH authentication, clients and servers can use a mixture of different key flavors in a single authentication session.\nWe integrated our new authentication method into OpenSSH, and found it to be practical and scalable. For a typical client and server with at most 10 ECDSA/EdDSA keys each, our protocol requires 9 kB of communication and 12.4 ms of latency. Even for a client with 20 keys and server with 100 keys, our protocol requires only 12 kB of communication and 26.7 ms of latency.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-roy.pdf",
            "keywords": [
                "SSH Authentication",
                "Privacy-Preserving",
                "Public-Key Cryptography",
                "Deniable Authentication",
                "Key Recognition Privacy"
            ]
        },
        "url": "URL#1417017"
    },
    {
        "@score": "1",
        "@id": "1417018",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "241/1422",
                        "text": "Harshad Sathaye"
                    },
                    {
                        "@pid": "117/8959",
                        "text": "Martin Strohmeier"
                    },
                    {
                        "@pid": "75/5939",
                        "text": "Vincent Lenders"
                    },
                    {
                        "@pid": "23/11190",
                        "text": "Aanjhan Ranganathan"
                    }
                ]
            },
            "title": "An Experimental Study of GPS Spoofing and Takeover Attacks on UAVs.",
            "venue": "USENIX Security Symposium",
            "pages": "3503-3520",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SathayeSLR22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/sathaye",
            "url": "https://dblp.org/rec/conf/uss/SathayeSLR22",
            "abstract": "Today, there is limited knowledge about the behavior of UAVs under GPS spoofing attacks in a real-world environment, in particular considering the interplay between the UAV\u2019s software as well as other equipped navigation aids and vision sensors. This work aims to understand the feasibility and requirements of fully controlling a UAV\u2019s movements by spoofing GPS signals alone. We enumerate the challenges in accomplishing a complete UAV takeover through GPS spoofing and controlling it without crashing. We design and implement a Real-time GPS Signal Generator (RtGSG) that can be configured to generate any arbitrary trajectory and is capable of making changes to GPS signals in real-time through user input, e.g., using a keyboard or joystick. We evaluate RtGSG on popular commercial UAVs from DJI and Autel through over-the-air spoofing experiments in a controlled chamber. We explore generic and UAV-specific GPS spoofing strategies in order to best achieve complete maneuvering control (e.g., velocity and direction). This work highlights that, although COTS UAVs remain vulnerable to GPS spoofing attacks, a complete takeover and control of the UAV requires careful manipulation of the spoofing signals in real-time. Finally, we release our implementation to the scientific community for further research.",
            "keywords": [
                "UAV Control",
                "GPS Spoofing",
                "Real-time Signal Manipulation",
                "Takeover Attacks",
                "Navigation Vulnerabilities"
            ]
        },
        "url": "URL#1417018",
        "sema_paperId": "35d25d2507c87cfa25a668376e48e488e434e54f"
    },
    {
        "@score": "1",
        "@id": "1417019",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "272/7190",
                        "text": "Tobias Scharnowski"
                    },
                    {
                        "@pid": "331/2788",
                        "text": "Nils Bars"
                    },
                    {
                        "@pid": "207/4015",
                        "text": "Moritz Schloegel"
                    },
                    {
                        "@pid": "121/1138",
                        "text": "Eric Gustafson"
                    },
                    {
                        "@pid": "185/2352",
                        "text": "Marius Muench"
                    },
                    {
                        "@pid": "v/GiovanniVigna",
                        "text": "Giovanni Vigna"
                    },
                    {
                        "@pid": "k/ChristopherKruegel",
                        "text": "Christopher Kruegel"
                    },
                    {
                        "@pid": "h/ThorstenHolz",
                        "text": "Thorsten Holz"
                    },
                    {
                        "@pid": "73/2297-2",
                        "text": "Ali Abbasi 0002"
                    }
                ]
            },
            "title": "Fuzzware: Using Precise MMIO Modeling for Effective Firmware Fuzzing.",
            "venue": "USENIX Security Symposium",
            "pages": "1239-1256",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ScharnowskiBSGM22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/scharnowski",
            "url": "https://dblp.org/rec/conf/uss/ScharnowskiBSGM22",
            "abstract": "As embedded devices are becoming more pervasive in our everyday lives, they turn into an attractive target for adver-saries. Despite their high value and large attack surface, ap-plying automated testing techniques such as fuzzing is not straightforward for such devices. As fuzz testing \ufb01rmware on constrained embedded devices is inef\ufb01cient, state-of-the-art approaches instead opt to run the \ufb01rmware in an emulator (through a process called re-hosting ). However, existing approaches either use coarse-grained static models of hardware behavior or require manual effort to re-host the \ufb01rmware. We propose a novel combination of lightweight program analysis, re-hosting, and fuzz testing to tackle these challenges. We present the design and implementation of F UZZWARE , a software-only system to fuzz test unmodi\ufb01ed monolithic \ufb01rmware in a scalable way. By determining how hardware-generated values are actually used by the \ufb01rmware logic, F UZZWARE can automatically generate models that help fo-cusing the fuzzing process on mutating the inputs that matter, which drastically improves its effectiveness. We evaluate our approach on synthetic and real-world targets comprising a total of 19 hardware platforms and 77 \ufb01rmware images. Compared to state-of-the-art work, F UZZ WARE achieves up to 3.25 times the code coverage and our modeling approach reduces the size of the input space by up to 95.5%. The synthetic samples contain 66 unit tests for various hardware interactions, and we \ufb01nd that our approach is the \ufb01rst generic re-hosting solution to automatically pass all of them. F UZZWARE discovered 15 completely new bugs including bugs in targets which were previously analyzed by other works;",
            "keywords": [
                "Firmware Fuzzing",
                "Embedded Systems",
                "MMIO Modeling",
                "Re-hosting",
                "Automated Testing"
            ]
        },
        "url": "URL#1417019",
        "sema_paperId": "17b0422509e7a7cc1de5a9614c82f4a4adc43ad3"
    },
    {
        "@score": "1",
        "@id": "1417020",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "207/4015",
                        "text": "Moritz Schloegel"
                    },
                    {
                        "@pid": "205/2079",
                        "text": "Tim Blazytko"
                    },
                    {
                        "@pid": "150/7970",
                        "text": "Moritz Contag"
                    },
                    {
                        "@pid": "160/7844",
                        "text": "Cornelius Aschermann"
                    },
                    {
                        "@pid": "295/8565",
                        "text": "Julius Basler"
                    },
                    {
                        "@pid": "h/ThorstenHolz",
                        "text": "Thorsten Holz"
                    },
                    {
                        "@pid": "73/2297-2",
                        "text": "Ali Abbasi 0002"
                    }
                ]
            },
            "title": "Loki: Hardening Code Obfuscation Against Automated Attacks.",
            "venue": "USENIX Security Symposium",
            "pages": "3055-3073",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SchlogelBCABH022",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/schloegel",
            "url": "https://dblp.org/rec/conf/uss/SchlogelBCABH022",
            "abstract": "Software obfuscation is a crucial technology to protect intellectual property. Despite its importance, commercial and academic state-of-the-art obfuscation approaches are vulnerable to a plethora of automated deobfuscation attacks, such as symbolic execution, taint analysis, or program synthesis. While several enhanced techniques were proposed to thwart taint analysis or symbolic execution, they either impose a prohibitive runtime overhead or can be removed by compiler optimizations. In general, they suffer from focusing on a single attack vector, allowing an attacker to switch to other more effective techniques, such as program synthesis. In this work, we present L OKI , an approach for code obfuscation that is resilient against all known automated deob-fuscation attacks. To this end, we deploy multiple techniques, including a generic approach to synthesize formally veri\ufb01ed expressions of arbitrary complexity. Contrary to state-of-the-art approaches that rely on a few hardcoded generation rules, our expressions are more diverse and harder to pattern match against. Moreover, L OKI protects against previously unac-counted attack vectors such as program synthesis, for which it reduces the success rate to merely 19%. Overall, our design incurs signi\ufb01cantly less overhead while providing a much stronger protection level.",
            "keywords": [
                "Code Obfuscation",
                "Automated Deobfuscation Attacks",
                "Program Synthesis",
                "Intellectual Property Protection",
                "Taint Analysis"
            ]
        },
        "url": "URL#1417020",
        "sema_paperId": "ebf34582711e15504ec76742e04164110dcee03b"
    },
    {
        "@score": "1",
        "@id": "1417021",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "272/7215",
                        "text": "David Schrammel"
                    },
                    {
                        "@pid": "145/2706",
                        "text": "Samuel Weiser"
                    },
                    {
                        "@pid": "331/2191",
                        "text": "Richard Sadek"
                    },
                    {
                        "@pid": "91/4831",
                        "text": "Stefan Mangard"
                    }
                ]
            },
            "title": "Jenny: Securing Syscalls for PKU-based Memory Isolation Systems.",
            "venue": "USENIX Security Symposium",
            "pages": "936-952",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SchrammelWSM22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/schrammel",
            "url": "https://dblp.org/rec/conf/uss/SchrammelWSM22",
            "abstract": "Effective syscall \ufb01ltering is a key component for withstanding the numerous exploitation techniques and privilege escalation attacks we face today. For example, modern browsers use sandboxing techniques with syscall \ufb01ltering in order to isolate critical code. Cloud computing heavily uses containers, which virtualize the syscall interface. Recently, cloud providers are switching to in-process containers for performance reasons, calling for better isolation primitives. A new isolation primi-tive that has the potential to \ufb01ll this gap is called Protection Keys for Userspace (PKU). Unfortunately, prior research high-lights severe de\ufb01ciencies in how PKU-based systems manage syscalls, questioning their security and practicability. In this work, we comprehensively investigate syscall \ufb01ltering for PKU-based memory isolation systems. First, we identify new syscall-based attacks that can break a PKU sandbox. Second, we derive syscall \ufb01lter rules necessary for protecting PKU domains and show ef\ufb01cient ways of enforcing them. Third, we do a comparative study on different syscall interposition techniques with respect to their suitability for PKU, which allows us to design a secure syscall interposition technique that is both fast and \ufb02exible. We design and prototype Jenny\u2013 a PKU-based memory isolation system that provides powerful syscall \ufb01ltering capabilities in userspace. Jenny supports various interposition techniques (e.g., seccomp and ptrace), and allows for domain-speci\ufb01c syscall \ufb01ltering in a nested way. Furthermore, it handles asynchronous signals securely. Our evaluation shows a minor performance impact of 0\u20135% for nginx.",
            "keywords": [
                "Syscall Filtering",
                "PKU-based Memory Isolation",
                "Sandboxing Techniques",
                "Syscall Interposition",
                "Asynchronous Signal Handling"
            ]
        },
        "url": "URL#1417021",
        "sema_paperId": "8bc0d149658d77d95c8698db25a0e60ac17a645c"
    },
    {
        "@score": "1",
        "@id": "1417023",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "196/0697",
                        "text": "Asuman Senol"
                    },
                    {
                        "@pid": "136/8452",
                        "text": "Gunes Acar"
                    },
                    {
                        "@pid": "83/8816",
                        "text": "Mathias Humbert"
                    },
                    {
                        "@pid": "126/2663",
                        "text": "Frederik J. Zuiderveen Borgesius"
                    }
                ]
            },
            "title": "Leaky Forms: A Study of Email and Password Exfiltration Before Form Submission.",
            "venue": "USENIX Security Symposium",
            "pages": "1813-1830",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SenolAHB22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/senol",
            "url": "https://dblp.org/rec/conf/uss/SenolAHB22",
            "abstract": "Web users enter their email addresses into online forms for a variety of reasons, including signing in or signing up for a service or subscribing to a newsletter. While enabling such functionality, email addresses typed into forms can also be collected by third-party scripts even when users change their minds and leave the site without submitting the form. Email addresses\u2014or identi\ufb01ers derived from them\u2014are known to be used by data brokers and advertisers for cross-site, cross-platform, and persistent identi\ufb01cation of potentially unsuspect-ing individuals. In order to \ufb01nd out whether access to online forms is misused by online trackers, we present a measurement of email and password collection that occurs before the form submission on the top 100 , 000 websites. We evaluate the effect of user location, browser con\ufb01guration, and interaction with consent dialogs by comparing results across two vantage points (EU/US), two browser con\ufb01gurations (desk-top/mobile), and three consent modes. Our crawler \ufb01nds and \ufb01lls email and password \ufb01elds, monitors the network traf\ufb01c for leaks, and intercepts script access to \ufb01lled input \ufb01elds. Our analyses show that users\u2019 email addresses are ex\ufb01ltrated to tracking, marketing and analytics domains before form submission and without giving consent on 1 , 844 websites in the EU crawl and 2 , 950 websites in the US crawl. While the majority of email addresses are sent to known tracking domains, we further identify 41 tracker domains that are not listed by any of the popular blocklists. Furthermore, we \ufb01nd incidental password collection on 52 websites by third-party session replay scripts.",
            "keywords": [
                "Email Exfiltration",
                "Web Tracking",
                "Form Submission",
                "Data Privacy",
                "Third-Party Scripts"
            ]
        },
        "url": "URL#1417023",
        "sema_paperId": "44500d56b47e128c0d1f983e789acbf65c2db788"
    },
    {
        "@score": "1",
        "@id": "1417024",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "316/4141",
                        "text": "Alon Shakevsky"
                    },
                    {
                        "@pid": "180/7297",
                        "text": "Eyal Ronen"
                    },
                    {
                        "@pid": "w/AvishaiWool",
                        "text": "Avishai Wool"
                    }
                ]
            },
            "title": "Trust Dies in Darkness: Shedding Light on Samsung&apos;s TrustZone Keymaster Design.",
            "venue": "USENIX Security Symposium",
            "pages": "251-268",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ShakevskyRW22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/shakevsky",
            "url": "https://dblp.org/rec/conf/uss/ShakevskyRW22",
            "abstract": "ARM-based Android smartphones rely on the TrustZone hardware support for a Trusted Execution Environment (TEE) to implement security-sensitive functions. The TEE runs a separate, isolated, TrustZone Operating System (TZOS), in parallel to Android. The implementation of the cryptographic functions within the TZOS is left to the device vendors, who create proprietary undocumented designs. In this work, we expose the cryptographic design and implementation of Android's Hardware-Backed Keystore in Samsung's Galaxy S8, S9, S10, S20, and S21 flagship devices. We reversed-engineered and provide a detailed description of the cryptographic design and code structure, and we unveil severe design flaws. We present an IV reuse attack on AES-GCM that allows an attacker to extract hardware-protected key material, and a downgrade attack that makes even the latest Samsung devices vulnerable to the IV reuse attack. We demonstrate working key extraction attacks on the latest devices. We also show the implications of our attacks on two higher-level cryptographic protocols between the TrustZone and a remote server: we demonstrate a  working FIDO2 WebAuthn login bypass and a compromise of Google's Secure Key Import. We discuss multiple flaws in the design flow of TrustZone based protocols. Although our specific attacks only apply to the \u2248100 million devices made by Samsung, it raises the much more general requirement for open and proven standards for critical cryptographic and security designs.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-shakevsky.pdf",
            "keywords": [
                "Trusted Execution Environment",
                "TrustZone",
                "Cryptographic Design",
                "Key Extraction Attacks",
                "IV Reuse Attack"
            ]
        },
        "url": "URL#1417024"
    },
    {
        "@score": "1",
        "@id": "1417025",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "217/9308",
                        "text": "Shawn Shan"
                    },
                    {
                        "@pid": "199/2164",
                        "text": "Arjun Nitin Bhagoji"
                    },
                    {
                        "@pid": "43/4261",
                        "text": "Haitao Zheng 0001"
                    },
                    {
                        "@pid": "z/BenYZhao",
                        "text": "Ben Y. Zhao"
                    }
                ]
            },
            "title": "Poison Forensics: Traceback of Data Poisoning Attacks in Neural Networks.",
            "venue": "USENIX Security Symposium",
            "pages": "3575-3592",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ShanB0Z22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/shan",
            "url": "https://dblp.org/rec/conf/uss/ShanB0Z22",
            "abstract": "In adversarial machine learning, new defenses against attacks on deep learning systems are routinely broken soon after their release by more powerful attacks. In this context, forensic tools can offer a valuable complement to existing defenses, by tracing back a successful attack to its root cause, and offering a path forward for mitigation to prevent similar attacks in the future. In this paper, we describe our efforts in developing a forensic traceback tool for poison attacks on deep neural networks. We propose a novel iterative clustering and pruning solution that trims\"innocent\"training samples, until all that remains is the set of poisoned data responsible for the attack. Our method clusters training samples based on their impact on model parameters, then uses an efficient data unlearning method to prune innocent clusters. We empirically demonstrate the efficacy of our system on three types of dirty-label (backdoor) poison attacks and three types of clean-label poison attacks, across domains of computer vision and malware classification. Our system achieves over 98.4% precision and 96.8% recall across all attacks. We also show that our system is robust against four anti-forensics measures specifically designed to attack it.",
            "keywords": [
                "Data Poisoning",
                "Forensic Analysis",
                "Backdoor Attacks",
                "Clean-label Poisoning",
                "Model Parameter Impact"
            ]
        },
        "url": "URL#1417025",
        "sema_paperId": "59a41d9178dd7e6187a1db7d1a5bf89372f4189c"
    },
    {
        "@score": "1",
        "@id": "1417026",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "304/2671",
                        "text": "Vandit Sharma"
                    },
                    {
                        "@pid": "87/8324",
                        "text": "Mainack Mondal"
                    }
                ]
            },
            "title": "Understanding and Improving Usability of Data Dashboards for Simplified Privacy Control of Voice Assistant Data.",
            "venue": "USENIX Security Symposium",
            "pages": "3379-3395",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SharmaM22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/sharma-vandit",
            "url": "https://dblp.org/rec/conf/uss/SharmaM22",
            "abstract": "Today, intelligent voice assistant (VA) software like Amazon's Alexa, Google's Voice Assistant (GVA) and Apple's Siri have millions of users. These VAs often collect and analyze huge user data for improving their functionality. However, this collected data may contain sensitive information (e.g., personal voice recordings) that users might not feel comfortable sharing with others and might cause significant privacy concerns. To counter such concerns, service providers like Google present their users with a personal data dashboard (called 'My Activity Dashboard'), allowing them to manage all voice assistant collected data. However, a real-world GVA-data driven understanding of user perceptions and preferences regarding this data (and data dashboards) remained relatively unexplored in prior research.To that end, in this work we focused on Google Voice Assistant (GVA) users and investigated the perceptions and preferences of GVA users regarding data and dashboard while grounding them in real GVA-collected user data. Specifically, we conducted an 80-participant survey-based user study to collect both generic perceptions regarding GVA usage as well as desired privacy preferences for a stratified sample of their GVA data. We show that most participants had superficial knowledge about the type of data collected by GVA. Worryingly, we found that participants felt uncomfortable sharing a non-trivial 17.7% of GVA-collected data elements with Google. The current My Activity dashboard, although useful, did not help long-time GVA users effectively manage their data privacy. Our real-data-driven study found that showing users even one sensitive data element can significantly improve the usability of data dashboards. To that end, we built a classifier that can detect sensitive data for data dashboard recommendations with a 95% F1-score and shows 76% improvement over baseline models.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-sharma-vandit.pdf",
            "keywords": [
                "Voice Assistant Privacy",
                "Data Dashboard Usability",
                "User Perceptions",
                "Sensitive Data Management",
                "Privacy Control Preferences"
            ]
        },
        "url": "URL#1417026"
    },
    {
        "@score": "1",
        "@id": "1417027",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "172/1323",
                        "text": "Rahul Anand Sharma"
                    },
                    {
                        "@pid": "180/7169",
                        "text": "Elahe Soltanaghaei"
                    },
                    {
                        "@pid": "02/630",
                        "text": "Anthony Rowe 0001"
                    },
                    {
                        "@pid": "45/4044",
                        "text": "Vyas Sekar"
                    }
                ]
            },
            "title": "Lumos: Identifying and Localizing Diverse Hidden IoT Devices in an Unfamiliar Environment.",
            "venue": "USENIX Security Symposium",
            "pages": "1095-1112",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SharmaSRS22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/sharma-rahul",
            "url": "https://dblp.org/rec/conf/uss/SharmaSRS22",
            "abstract": "Hidden IoT devices are increasingly being used to snoop on users in hotel rooms or AirBnBs. We envision empowering users entering such unfamiliar environments to identify and locate (e.g., hidden camera behind plants) diverse hidden devices (e.g., cameras, microphones, speakers) using only their personal handhelds. What makes this challenging is the limited network visibility and physical access that a user has in such unfamiliar environments, coupled with the lack of specialized equipment. This paper presents Lumos, a system that runs on commodity user devices (e.g., phone, laptop) and enables users to identify and locate WiFi-connected hidden IoT devices and visualize their presence using an augmented reality interface. Lumos addresses key challenges in: (1) identifying diverse devices using only coarse-grained wireless layer features, without IP/DNS layer information and without knowledge of the WiFi channel assignments of the hidden devices; and (2) locating the identi\ufb01ed IoT devices with respect to the user using only phone sensors and wireless signal strength measurements. We evaluated Lumos across 44 different IoT devices spanning various types, models, and brands across six different environments. Our results show that Lumos can identify hidden devices with 95% accuracy and locate them with a median error of 1.5m within 30 minutes in a two-bedroom, 1000 sq. ft. apartment.",
            "keywords": [
                "IoT Device Identification",
                "Augmented Reality",
                "Hidden Device Localization",
                "Wireless Signal Analysis",
                "User Empowerment in Unfamiliar Environments"
            ]
        },
        "url": "URL#1417027",
        "sema_paperId": "2ba767160b70c7488e11ffc50531c0bf41a39431"
    },
    {
        "@score": "1",
        "@id": "1417028",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "187/9868",
                        "text": "Tohid Shekari"
                    },
                    {
                        "@pid": "48/6119",
                        "text": "Alvaro A. C\u00e1rdenas"
                    },
                    {
                        "@pid": "12/6354",
                        "text": "Raheem Beyah"
                    }
                ]
            },
            "title": "MaDIoT 2.0: Modern High-Wattage IoT Botnet Attacks and Defenses.",
            "venue": "USENIX Security Symposium",
            "pages": "3539-3556",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ShekariCB22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/shekari",
            "url": "https://dblp.org/rec/conf/uss/ShekariCB22",
            "abstract": "The widespread availability of vulnerable IoT devices has resulted in IoT botnets. A particularly concerning IoT botnet can be built around high-wattage IoT devices such as EV chargers because, in large numbers, they can abruptly change the electricity consumption in the power grid. These attacks are called Manipulation of Demand via IoT (MaDIoT) attacks. Previous research has shown that the existing power grid protection mechanisms prevent any large-scale negative consequences to the grid from MaDIoT attacks. In this paper, we analyze this assumption and show that an intelligent attacker with extra knowledge about the power grid and its state, can launch more sophisticated attacks. Rather than at-tacking all locations at random times, our adversary uses an instability metric that lets the attacker know the speci\ufb01c time and geographical location to activate the high-wattage bots. We call these new attacks MaDIoT 2.0.",
            "keywords": [
                "IoT Botnets",
                "High-Wattage Devices",
                "Power Grid Attacks",
                "MaDIoT Attacks",
                "Demand Manipulation"
            ]
        },
        "url": "URL#1417028",
        "sema_paperId": "049ccca54acb5a9f2f18f3764827e432bbbde83f"
    },
    {
        "@score": "1",
        "@id": "1417029",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "280/7865",
                        "text": "Zekun Shen"
                    },
                    {
                        "@pid": "331/2514",
                        "text": "Ritik Roongta"
                    },
                    {
                        "@pid": "94/7563",
                        "text": "Brendan Dolan-Gavitt"
                    }
                ]
            },
            "title": "Drifuzz: Harvesting Bugs in Device Drivers from Golden Seeds.",
            "venue": "USENIX Security Symposium",
            "pages": "1275-1290",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ShenRD22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/shen-zekun",
            "url": "https://dblp.org/rec/conf/uss/ShenRD22",
            "abstract": "Peripheral hardware in modern computers is typically assumed to be secure and not malicious, and device drivers are implemented in a way that trusts inputs from hardware. However, recent vulnerabilities such as Broadpwn have demonstrated that attackers can exploit hosts through vulnerable peripherals, highlighting the importance of securing the OS-peripheral boundary. In this paper, we propose a hardware-free concolic-augmented fuzzer targeting WiFi and Ethernet drivers, and a technique for generating high-quality initial seeds, which we call golden seeds , that allow fuzzing to bypass difficult code constructs during driver initialization. Compared to prior work using symbolic execution or greybox fuzzing, Drifuzz is more successful at automatically finding inputs that allow network interfaces to be fully initialized, and improves fuzzing coverage by 214% (3.1\u00d7) in WiFi drivers and 60% (1.6\u00d7) for Ethernet drivers. During our experiments with fourteen PCI and USB network drivers, we find eleven previously unknown bugs, two of which were assigned CVEs.",
            "keywords": [
                "Device Driver Security",
                "Fuzzing",
                "Concolic Execution",
                "Network Driver Vulnerabilities",
                "Golden Seeds"
            ]
        },
        "url": "URL#1417029",
        "sema_paperId": "eaae6d0ca013954fa026b76d65d5710479f5d393"
    },
    {
        "@score": "1",
        "@id": "1417030",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "14/4412",
                        "text": "Yun Shen"
                    },
                    {
                        "@pid": "122/8629",
                        "text": "Pierre-Antoine Vervier"
                    },
                    {
                        "@pid": "86/8823",
                        "text": "Gianluca Stringhini"
                    }
                ]
            },
            "title": "A Large-scale Temporal Measurement of Android Malicious Apps: Persistence, Migration, and Lessons Learned.",
            "venue": "USENIX Security Symposium",
            "pages": "1167-1184",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ShenVS22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/shen-yun",
            "url": "https://dblp.org/rec/conf/uss/ShenVS22",
            "abstract": "We study the temporal dynamics of potentially harmful apps (PHAs) on Android by leveraging 8.8M daily on-device detections collected among 11.7M customers of a popular mobile security product between 2019 and 2020. We show that the current security model of Android, which limits security products to run as regular apps and prevents them from automatically removing malicious apps opens a significant window of opportunity for attackers. Such apps warn users about the newly discovered threats, but users do not promptly act on this information, allowing PHAs to persist on their device for an average of 24 days after they are detected. We also find that while app markets remove PHAs after these become known, there is a significant delay between when PHAs are identified and when they are removed: PHAs persist on Google Play for 77 days on average and 34 days on third party marketplaces. Finally, we find evidence of PHAs migrating to other marketplaces after being removed on the original one. This paper provides an unprecedented view of the Android PHA landscape, showing that current defenses against PHAs on Android are not as effective as commonly thought, and identifying multiple research directions that the security community should pursue, from orchestrating more effective PHA takedowns to devising better alerts for mobile security products.",
            "keywords": [
                "Android Malicious Apps",
                "Potentially Harmful Apps (PHAs)",
                "App Market Dynamics",
                "Malware Persistence",
                "Malicious App Migration"
            ]
        },
        "url": "URL#1417030",
        "sema_paperId": "63ff1eaf67e3ce76824932c19fb5ccb4bf4b69bd"
    },
    {
        "@score": "1",
        "@id": "1417031",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "331/2215",
                        "text": "Youkun Shi"
                    },
                    {
                        "@pid": "48/2168-9",
                        "text": "Yuan Zhang 0009"
                    },
                    {
                        "@pid": "331/2055",
                        "text": "Tianhan Luo"
                    },
                    {
                        "@pid": "138/3444",
                        "text": "Xiangyu Mao"
                    },
                    {
                        "@pid": "28/8733",
                        "text": "Yinzhi Cao"
                    },
                    {
                        "@pid": "05/8765",
                        "text": "Ziwen Wang"
                    },
                    {
                        "@pid": "44/2817",
                        "text": "Yudi Zhao"
                    },
                    {
                        "@pid": "331/2409",
                        "text": "Zongan Huang"
                    },
                    {
                        "@pid": "02/1640-2",
                        "text": "Min Yang 0002"
                    }
                ]
            },
            "title": "Backporting Security Patches of Web Applications: A Prototype Design and Implementation on Injection Vulnerability Patches.",
            "venue": "USENIX Security Symposium",
            "pages": "1993-2010",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Shi0LMCWZH022",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/shi",
            "url": "https://dblp.org/rec/conf/uss/Shi0LMCWZH022",
            "abstract": "Web vulnerabilities, especially injection-related ones, are popular among web application frameworks (such as Word-Press and Piwigo), which can lead to severe consequences like user information leak and server-side malware execution. One major practice of \ufb01xing web vulnerabilities on real-world websites is to apply security patches from the of\ufb01cial developers of web frameworks. However, such a practice is challenging because security patches are developed for the latest version of a web framework, but real-world websites often run an old version due to legacy reasons. A direct application of security patches on the old version often fails because web frameworks, especially the code around the vulnerable location, may change between versions. In this paper, we design a security patch backporting framework and implement a prototype on injection vulnerability patches, called S KY P ORT . S KY P ORT \ufb01rst identi\ufb01es safely-backportable patches of injection vulnerabilities and web framework versions in theory and then backports patches to corresponding old versions. In the evaluation, S KY P ORT iden-ti\ufb01es 98 out of 155 security patches targeting legacy injection vulnerabilities, which can be backported to 750 old versions of web application frameworks. Then, S KY P ORT successfully backported all of the aforementioned backportable patches to corresponding old versions to correctly \ufb01x vulnerabilities. We believe that this is a \ufb01rst-step towards this important research problem and hope our research can draw further attention from the research community in backporting security patches to \ufb01x unpatched vulnerabilities in general beyond injection-related ones.",
            "keywords": [
                "Web Application Security",
                "Injection Vulnerabilities",
                "Security Patch Backporting",
                "Legacy Versions",
                "SKYPORT"
            ]
        },
        "url": "URL#1417031",
        "sema_paperId": "d21fe3b76761dcb3cb27901b4788091965ae6e25"
    },
    {
        "@score": "1",
        "@id": "1417032",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "156/5453",
                        "text": "Sandra Siby"
                    },
                    {
                        "@pid": "08/8604-2",
                        "text": "Umar Iqbal 0002"
                    },
                    {
                        "@pid": "137/7764",
                        "text": "Steven Englehardt"
                    },
                    {
                        "@pid": "83/9528",
                        "text": "Zubair Shafiq"
                    },
                    {
                        "@pid": "01/4825",
                        "text": "Carmela Troncoso"
                    }
                ]
            },
            "title": "WebGraph: Capturing Advertising and Tracking Information Flows for Robust Blocking.",
            "venue": "USENIX Security Symposium",
            "pages": "2875-2892",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SibyIEST22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/siby",
            "url": "https://dblp.org/rec/conf/uss/SibyIEST22",
            "abstract": "Millions of web users directly depend on ad and tracker blocking tools to protect their privacy. However, existing ad and tracker blockers fall short because of their reliance on trivially susceptible advertising and tracking content. In this paper, we first demonstrate that the state-of-the-art machine learning based ad and tracker blockers, such as AdGraph, are susceptible to adversarial evasions deployed in real-world. Second, we introduce WebGraph, the first graph-based machine learning blocker that detects ads and trackers based on their action rather than their content. By building features around the actions that are fundamental to advertising and tracking - storing an identifier in the browser, or sharing an identifier with another tracker - WebGraph performs nearly as well as prior approaches, but is significantly more robust to adversarial evasions. In particular, we show that WebGraph achieves comparable accuracy to AdGraph, while significantly decreasing the success rate of an adversary from near-perfect under AdGraph to around 8% under WebGraph. Finally, we show that WebGraph remains robust to a more sophisticated adversary that uses evasion techniques beyond those currently deployed on the web.",
            "keywords": [
                "Ad and Tracker Blocking",
                "Privacy Protection",
                "Graph-Based Detection",
                "Adversarial Evasion",
                "WebGraph"
            ]
        },
        "url": "URL#1417032",
        "sema_paperId": "0ecab43a57d05d54a5fbcb01ba0416f1514729d1"
    },
    {
        "@score": "1",
        "@id": "1417033",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "292/8996",
                        "text": "Julia Slupska"
                    },
                    {
                        "@pid": "253/0712",
                        "text": "Selina Y. Cho"
                    },
                    {
                        "@pid": "331/2231",
                        "text": "Marissa Begonia"
                    },
                    {
                        "@pid": "163/8698",
                        "text": "Ruba Abu-Salma"
                    },
                    {
                        "@pid": "331/2491",
                        "text": "Nayanatara Prakash"
                    },
                    {
                        "@pid": "331/2190",
                        "text": "Mallika Balakrishnan"
                    }
                ]
            },
            "title": "&quot;They Look at Vulnerability and Use That to Abuse You&quot;: Participatory Threat Modelling with Migrant Domestic Workers.",
            "venue": "USENIX Security Symposium",
            "pages": "323-340",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SlupskaCBAPB22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/slupska-vulnerability",
            "url": "https://dblp.org/rec/conf/uss/SlupskaCBAPB22",
            "abstract": "The needs of marginalised groups like migrant domestic workers (MDWs) are often ignored in digital privacy and security research. If considered, MDWs are treated as 'bystanders' or even as threats rather than as targets of surveillance and legitimate security subjects in their own right. Using participatory threat modelling (PTM) as a method of incorporating marginalised populations' experiences, we designed and conducted five workshops with MDWs (n=32) in the UK to identify threats to their privacy and security. We found that MDWs named government surveillance, scams and harassment, and employer monitoring (in this order) as the primary threats to their privacy and security. We also examined the methods MDWs used to stay safe online, such as configuring the privacy settings of their online accounts and creating on- and offline community support networks. Based on our findings, we developed and disseminated a digital privacy and security guide with links to further resources that MDWs can refer to. We conclude by arguing that security research must consider broader social structures like gendered work and racialised border policy that foster insecurity in the lives of MDWs. We also present the key lessons of our work, including considering data sharing from the perspective of stakeholders who do not own technology devices but are affected by them, and reflecting on how security research can stop enabling harmful forms of surveillance.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-slupska-vulnerability.pdf",
            "keywords": [
                "Participatory Threat Modelling",
                "Migrant Domestic Workers",
                "Digital Privacy",
                "Surveillance",
                "Security Insecurity"
            ]
        },
        "url": "URL#1417033",
        "sema_paperId": "d497dc77a150afd3d7def3ab7746b88866be826d"
    },
    {
        "@score": "1",
        "@id": "1417034",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "292/8996",
                        "text": "Julia Slupska"
                    },
                    {
                        "@pid": "161/3360",
                        "text": "Angelika Strohmayer"
                    }
                ]
            },
            "title": "Networks of Care: Tech Abuse Advocates&apos; Digital Security Practices.",
            "venue": "USENIX Security Symposium",
            "pages": "341-358",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SlupskaS22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/slupska-networks",
            "url": "https://dblp.org/rec/conf/uss/SlupskaS22",
            "abstract": "As technology becomes an enabler of relationship abuse and coercive control, advocates who support survivors develop digital security practices to counter this. Existing research on technology-related abuse has primarily focused on describing the dynamics of abuse and developing solutions for this problem; we extend this literature by focusing on the security practices of advocates working \u201con the ground\u201d, i.e. in domestic violence shelters and other support services. We present \ufb01ndings from 26 semi-structured interviews and a data walkthrough workshop in which advocates described how they support survivors. We identi\ufb01ed a variety of intertwined emotional and technical support practices, including establishing trust, safety planning, empowerment, demysti\ufb01cation, supporting evidence collection and making referrals. By building relationships with other services and stakeholders, advocates also develop networks of care throughout society to create more supportive environments for survivors. Using critical and feminist theories, we see advocates as sources of crucial technical expertise to reduce this kind of violence in the future. Security and privacy researchers can build on and develop these networks of care by employing participatory methods and expanding threat modelling to account for interpersonal harms like coercive control and structural forms of discrimination such as misogyny and racism.",
            "keywords": [
                "Digital Security Practices",
                "Tech Abuse",
                "Survivor Support",
                "Coercive Control",
                "Networks of Care"
            ]
        },
        "url": "URL#1417034",
        "sema_paperId": "8944308f5a5e883666fa4e4a20e32dc16d184259"
    },
    {
        "@score": "1",
        "@id": "1417035",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "218/3823",
                        "text": "Jean-Pierre Smith"
                    },
                    {
                        "@pid": "331/2772",
                        "text": "Luca Dolfi"
                    },
                    {
                        "@pid": "39/6266",
                        "text": "Prateek Mittal"
                    },
                    {
                        "@pid": "16/6873",
                        "text": "Adrian Perrig"
                    }
                ]
            },
            "title": "QCSD: A QUIC Client-Side Website-Fingerprinting Defence Framework.",
            "venue": "USENIX Security Symposium",
            "pages": "771-789",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SmithDMP22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/smith",
            "url": "https://dblp.org/rec/conf/uss/SmithDMP22",
            "abstract": "Website \ufb01ngerprinting attacks, which analyse the metadata of encrypted network communication to identify visited web-sites, have been shown to be effective on privacy-enhancing technologies including virtual private networks (VPNs) and encrypted proxies. Despite this, VPNs are still undefended against these attacks, leaving millions of users vulnerable. Proposed defences against website \ufb01ngerprinting require co-operation between the client and a remote endpoint to reshape the network traf\ufb01c, thereby hindering deployment. We observe that the rapid and wide-spread deployment of QUIC and HTTP/3 creates an exciting opportunity to build website-\ufb01ngerprinting defences directly into client applications, such as browsers, without requiring any changes to web servers, VPNs, or the deployment of new network services. We therefore design and implement the QCSD framework, which leverages QUIC and HTTP/3 to emulate existing website-\ufb01ngerprinting defences by bidirectionally adding cover traf\ufb01c and reshaping connections solely from the client. As case studies, we emulate both the FRONT and Tama-raw defences solely from the client and collected several datasets of live-defended traf\ufb01c on which we evaluated modern machine-learning based attacks. Our results demonstrate the promise of this approach in shaping connections towards client-orchestrated defences, thereby removing a primary barrier to the deployment of website-\ufb01ngerprinting defences.",
            "keywords": [
                "Website Fingerprinting",
                "QUIC",
                "Client-Side Defence",
                "Cover Traffic",
                "Privacy Protection"
            ]
        },
        "url": "URL#1417035",
        "sema_paperId": "98835de5b9c347dafc6347a5eecff95498db21c0"
    },
    {
        "@score": "1",
        "@id": "1417036",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "232/2988",
                        "text": "Konstantinos Solomos"
                    },
                    {
                        "@pid": "129/9582",
                        "text": "Panagiotis Ilia"
                    },
                    {
                        "@pid": "270/2346",
                        "text": "Soroush Karami"
                    },
                    {
                        "@pid": "04/8280",
                        "text": "Nick Nikiforakis"
                    },
                    {
                        "@pid": "47/8412",
                        "text": "Jason Polakis"
                    }
                ]
            },
            "title": "The Dangers of Human Touch: Fingerprinting Browser Extensions through User Actions.",
            "venue": "USENIX Security Symposium",
            "pages": "717-733",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SolomosIKNP22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/solomos",
            "url": "https://dblp.org/rec/conf/uss/SolomosIKNP22",
            "abstract": "Browser extension \ufb01ngerprinting has garnered considerable attention recently due to the twofold privacy loss that it incurs. Apart from facilitating tracking by augmenting browser \ufb01ngerprints, the list of installed extensions can be directly used to infer sensitive user characteristics. However, prior research was performed in a vacuum , overlooking a core dimension of extensions\u2019 functionality: how they react to user actions. In this paper, we present the \ufb01rst exploration of user-triggered extension \ufb01ngerprinting. Guided by our \ufb01ndings from a large-scale static analysis of browser extensions we devise a series of user action templates that enable dynamic extension-exercising frameworks to comprehensively uncover hidden extension functionality that can only be triggered through user interactions. Our experimental evaluation demonstrates the effectiveness of our proposed technique, as we are able to \ufb01ngerprint 4,971 unique extensions, 36% of which are not detectable by state-of-the-art techniques. To make matters worse, we \ufb01nd that \u2248 67% of the extensions that require mouse or keyboard interactions lack appropriate safeguards, rendering them vulnerable to pages that simulate user actions through JavaScript. To assist extension developers in protecting users from this privacy threat, we build a tool that automatically includes origin checks for fortifying extensions against invasive sites.",
            "keywords": [
                "Browser Extension Fingerprinting",
                "User Interaction Tracking",
                "Privacy Vulnerabilities",
                "Dynamic Extension Analysis",
                "Origin Checks for Extensions"
            ]
        },
        "url": "URL#1417036",
        "sema_paperId": "cf406190c98935cc605adb2e2e9045be974202a5"
    },
    {
        "@score": "1",
        "@id": "1417037",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "264/9973",
                        "text": "Flavien Solt"
                    },
                    {
                        "@pid": "68/86",
                        "text": "Ben Gras"
                    },
                    {
                        "@pid": "121/2685",
                        "text": "Kaveh Razavi"
                    }
                ]
            },
            "title": "CellIFT: Leveraging Cells for Scalable and Precise Dynamic Information Flow Tracking in RTL.",
            "venue": "USENIX Security Symposium",
            "pages": "2549-2566",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SoltGR22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/solt",
            "url": "https://dblp.org/rec/conf/uss/SoltGR22",
            "abstract": "Dynamic Information Flow Tracking (dynamic IFT) is a well-known technique with many security applications such as analyzing the behavior of a system given an input and detecting security violations. While there are many widely used open dynamic IFT solutions that scale to large software, the same level of support is unfortunately lacking for hardware. This gap is becoming more pronounced with the increasing complexity of open-source hardware and the plethora of recent hardware attacks. We introduce C ELL IFT, a new design point in the space of dynamic IFT for hardware. C ELL IFT leverages the logical macrocell abstraction (e.g., an adder) to achieve scalability, precision and completeness when instrumenting a given Register Transfer Level (RTL) hardware design. Cell-level dynamic IFT does not suffer from the scalability problems that are inherent to lower levels of abstraction such as gates, yet it achieves completeness given the limited number of cell types. We show the versatility of C ELL IFT by instrumenting \ufb01ve distinct RISC-V designs, one of which is a complete SoC. The only existing complete solution already fails to instrument two of these designs. Our extensive evaluation using microbenchmarks and standard RISC-V benchmarks on the instrumented designs shows that C ELL IFT is 21 \u00d7 to 61 \u00d7 faster than the state of the art in terms of simulation runtime without losing precision. We further show-case concrete applications of C ELL IFT in four scenarios by detecting: 1) sources of microarchitectural information leakage, 2) microarchitectural bugs such as Meltdown, 3) speculative vulnerabilities such as Spectre-BCB, and 4) SoC-wide architectural design \ufb02aws. We release C ELL IFT as open source to enable RTL-level security research for the wider community.",
            "keywords": [
                "Dynamic Information Flow Tracking",
                "Hardware Security",
                "Register Transfer Level (RTL)",
                "Microarchitectural Vulnerabilities",
                "Open Source Hardware"
            ]
        },
        "url": "URL#1417037",
        "sema_paperId": "c3140fe74c3b210398d3b077d0a9edc3697ea5eb"
    },
    {
        "@score": "1",
        "@id": "1417038",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "165/9469",
                        "text": "Shravan Srinivasan"
                    },
                    {
                        "@pid": "175/1587",
                        "text": "Alexander Chepurnoy"
                    },
                    {
                        "@pid": "p/CharalamposPapamanthou",
                        "text": "Charalampos Papamanthou"
                    },
                    {
                        "@pid": "119/7737",
                        "text": "Alin Tomescu"
                    },
                    {
                        "@pid": "82/4816-1",
                        "text": "Yupeng Zhang 0001"
                    }
                ]
            },
            "title": "Hyperproofs: Aggregating and Maintaining Proofs in Vector Commitments.",
            "venue": "USENIX Security Symposium",
            "pages": "3001-3018",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SrinivasanCPT022",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/srinivasan",
            "url": "https://dblp.org/rec/conf/uss/SrinivasanCPT022",
            "abstract": "We present Hyperproofs, the first vector commitment (VC) scheme that is efficiently maintainable and aggregatable. Similar to Merkle proofs, our proofs form a tree that can be efficiently maintained: updating all n proofs in the tree after a single leaf change only requires O(logn) time. Importantly, unlike Merkle proofs, Hyperproofs are efficiently aggregatable, anywhere from 10\u00d7 to 41\u00d7 faster than SNARK-based aggregation of Merkle proofs. At the same time, an individual Hyperproof consists of only logn algebraic hashes (e.g., 32-byte elliptic curve points) and an aggregation of b such proofs is only O(log(blogn))-sized. Hyperproofs are also reasonably fast to update when compared to Merkle trees with SNARK-friendly hash functions.As another benefit over Merkle trees, Hyperproofs are homomorphic: digests (and proofs) for two vectors can be homomorphically combined into a digest (and proofs) for their sum. Homomorphism is very useful in emerging applications such as stateless cryptocurrencies. First, it enables unstealability, a novel property that incentivizes proof computation. Second, it makes digests and proofs much more convenient to update.Finally, Hyperproofs have certain limitations: they are not transparent, have linear-sized public parameters, are slower to verify, and have larger aggregated proofs and slower verification than SNARK-based approaches. Nonetheless, end-to-end, aggregation and verification in Hyperproofs is 10\u00d7 to 41\u00d7 faster than in SNARK-based Merkle trees.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-srinivasan.pdf",
            "keywords": [
                "Vector Commitments",
                "Hyperproofs",
                "Proof Aggregation",
                "Homomorphic Properties",
                "Efficient Maintenance"
            ]
        },
        "url": "URL#1417038"
    },
    {
        "@score": "1",
        "@id": "1417039",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "266/1311",
                        "text": "Theresa Stadler"
                    },
                    {
                        "@pid": "222/4910",
                        "text": "Bristena Oprisanu"
                    },
                    {
                        "@pid": "01/4825",
                        "text": "Carmela Troncoso"
                    }
                ]
            },
            "title": "Synthetic Data - Anonymisation Groundhog Day.",
            "venue": "USENIX Security Symposium",
            "pages": "1451-1468",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/StadlerOT22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/stadler",
            "url": "https://dblp.org/rec/conf/uss/StadlerOT22",
            "abstract": "Synthetic data has been advertised as a silver-bullet solution to privacy-preserving data publishing that addresses the shortcomings of traditional anonymisation techniques. The promise is that synthetic data drawn from generative models preserves the statistical properties of the original dataset but, at the same time, provides perfect protection against privacy attacks. In this work, we present the first quantitative evaluation of the privacy gain of synthetic data publishing and compare it to that of previous anonymisation techniques. Our evaluation of a wide range of state-of-the-art generative models demonstrates that synthetic data either does not prevent inference attacks or does not retain data utility. In other words, we empirically show that synthetic data does not provide a better tradeoff between privacy and utility than traditional anonymisation techniques. Furthermore, in contrast to traditional anonymisation, the privacy-utility tradeoff of synthetic data publishing is hard to predict. Because it is impossible to predict what signals a synthetic dataset will preserve and what information will be lost, synthetic data leads to a highly variable privacy gain and unpredictable utility loss. In summary, we find that synthetic data is far from the holy grail of privacy-preserving data publishing.",
            "keywords": [
                "Synthetic Data",
                "Privacy-Preserving Publishing",
                "Anonymisation Techniques",
                "Privacy-Utility Tradeoff",
                "Inference Attacks"
            ]
        },
        "url": "URL#1417039",
        "sema_paperId": "1e248bee6268a14c254b3a9f48fa1bae72a092b3"
    },
    {
        "@score": "1",
        "@id": "1417040",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "135/8303",
                        "text": "Timothy Stevens"
                    },
                    {
                        "@pid": "07/3882",
                        "text": "Christian Skalka"
                    },
                    {
                        "@pid": "178/5254",
                        "text": "Christelle Vincent"
                    },
                    {
                        "@pid": "252/3936",
                        "text": "John H. Ring"
                    },
                    {
                        "@pid": "175/9593",
                        "text": "Samuel Clark"
                    },
                    {
                        "@pid": "39/5361",
                        "text": "Joseph P. Near"
                    }
                ]
            },
            "title": "Efficient Differentially Private Secure Aggregation for Federated Learning via Hardness of Learning with Errors.",
            "venue": "USENIX Security Symposium",
            "pages": "1379-1395",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/StevensSVRCN22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/stevens",
            "url": "https://dblp.org/rec/conf/uss/StevensSVRCN22",
            "abstract": "Federated machine learning leverages edge computing to develop models from network user data, but privacy in federated learning remains a major challenge. Techniques using differential privacy have been proposed to address this, but bring their own challenges -- many require a trusted third party or else add too much noise to produce useful models. Recent advances in \\emph{secure aggregation} using multiparty computation eliminate the need for a third party, but are computationally expensive especially at scale. We present a new federated learning protocol that leverages a novel differentially private, malicious secure aggregation protocol based on techniques from Learning With Errors. Our protocol outperforms current state-of-the art techniques, and empirical results show that it scales to a large number of parties, with optimal accuracy for any differentially private federated learning scheme.",
            "keywords": [
                "Federated Learning",
                "Differential Privacy",
                "Secure Aggregation",
                "Learning With Errors",
                "Malicious Secure Aggregation"
            ]
        },
        "url": "URL#1417040",
        "sema_paperId": "8efd8297a75cacaa524d0993e51fcad26a125425"
    },
    {
        "@score": "1",
        "@id": "1417042",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "167/0439",
                        "text": "Octavian Suciu"
                    },
                    {
                        "@pid": "285/5518",
                        "text": "Connor Nelson"
                    },
                    {
                        "@pid": "285/4821",
                        "text": "Zhuoer Lyu"
                    },
                    {
                        "@pid": "150/5198",
                        "text": "Tiffany Bao"
                    },
                    {
                        "@pid": "01/4921",
                        "text": "Tudor Dumitras"
                    }
                ]
            },
            "title": "Expected Exploitability: Predicting the Development of Functional Vulnerability Exploits.",
            "venue": "USENIX Security Symposium",
            "pages": "377-394",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SuciuNLBD22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/suciu",
            "url": "https://dblp.org/rec/conf/uss/SuciuNLBD22",
            "abstract": "Assessing the exploitability of software vulnerabilities at the time of disclosure is difficult and error-prone, as features extracted via technical analysis by existing metrics are poor predictors for exploit development. Moreover, exploitability assessments suffer from a class bias because\"not exploitable\"labels could be inaccurate. To overcome these challenges, we propose a new metric, called Expected Exploitability (EE), which reflects, over time, the likelihood that functional exploits will be developed. Key to our solution is a time-varying view of exploitability, a departure from existing metrics. This allows us to learn EE using data-driven techniques from artifacts published after disclosure, such as technical write-ups and proof-of-concept exploits, for which we design novel feature sets. This view also allows us to investigate the effect of the label biases on the classifiers. We characterize the noise-generating process for exploit prediction, showing that our problem is subject to the most challenging type of label noise, and propose techniques to learn EE in the presence of noise. On a dataset of 103,137 vulnerabilities, we show that EE increases precision from 49% to 86% over existing metrics, including two state-of-the-art exploit classifiers, while its precision substantially improves over time. We also highlight the practical utility of EE for predicting imminent exploits and prioritizing critical vulnerabilities. We develop EE into an online platform which is publicly available at https://exploitability.app/.",
            "keywords": [
                "Exploitability Assessment",
                "Vulnerability Prediction",
                "Functional Exploits",
                "Label Noise",
                "Expected Exploitability (EE)"
            ]
        },
        "url": "URL#1417042",
        "sema_paperId": "1bbe3bca30768ef1fdb0573e8eb0b4174794f4df"
    },
    {
        "@score": "1",
        "@id": "1417043",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "182/4673",
                        "text": "Avinash Sudhodanan"
                    },
                    {
                        "@pid": "30/9784",
                        "text": "Andrew Paverd"
                    }
                ]
            },
            "title": "Pre-hijacked accounts: An Empirical Study of Security Failures in User Account Creation on the Web.",
            "venue": "USENIX Security Symposium",
            "pages": "1795-1812",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SudhodananP22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/sudhodanan",
            "url": "https://dblp.org/rec/conf/uss/SudhodananP22",
            "abstract": "The ubiquity of user accounts in websites and online services makes account hijacking a serious security concern. Although previous research has studied various techniques through which an attacker can gain access to a victim's account, relatively little attention has been directed towards the process of account creation. The current trend towards federated authentication (e.g., Single Sign-On) adds an additional layer of complexity because many services now support both the classic approach in which the user directly sets a password, and the federated approach in which the user authenticates via an identity provider. Inspired by previous work on preemptive account hijacking [Ghasemisharif et al., USENIX SEC 2018], we show that there exists a whole class of account pre-hijacking attacks. The distinctive feature of these attacks is that the attacker performs some action before the victim creates an account, which makes it trivial for the attacker to gain access after the victim has created/recovered the account. Assuming a realistic attacker who knows only the victim's email address, we identify and discuss five different types of account pre-hijacking attacks. To ascertain the prevalence of such vulnerabilities in the wild, we analyzed 75 popular services and found that at least 35 of these were vulnerable to one or more account pre-hijacking attacks. Whilst some of these may be noticed by attentive users, others were completely undetectable from the victim's perspective. Finally, we investigated the root cause of these vulnerabilities and present a set of security requirements to prevent such vulnerabilities arising in future.",
            "keywords": [
                "Account Security",
                "Account Hijacking",
                "User Account Creation",
                "Pre-hijacking Attacks",
                "Federated Authentication"
            ]
        },
        "url": "URL#1417043",
        "sema_paperId": "d3cef489fa601529cf94cfbcc5aafe64b5aee54a"
    },
    {
        "@score": "1",
        "@id": "1417044",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "331/2217",
                        "text": "George Arnold Sullivan"
                    },
                    {
                        "@pid": "327/9719",
                        "text": "Jackson Sippe"
                    },
                    {
                        "@pid": "12/3207",
                        "text": "Nadia Heninger"
                    },
                    {
                        "@pid": "60/8733",
                        "text": "Eric Wustrow"
                    }
                ]
            },
            "title": "Open to a fault: On the passive compromise of TLS keys via transient errors.",
            "venue": "USENIX Security Symposium",
            "pages": "233-250",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SullivanSHW22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/sullivan",
            "url": "https://dblp.org/rec/conf/uss/SullivanSHW22",
            "abstract": "It is well known in the cryptographic literature that the most common digital signature schemes used in practice can fail catastrophically in the presence of faults during computation. We use passive and active network measurements to analyze organically-occuring faults in billions of digital signatures generated by tens of millions of hosts. We \ufb01nd that a persistent rate of apparent hardware faults in unprotected implementations has resulted in compromised certi\ufb01cate RSA private keys for years. The faulty signatures we observed allowed us to compute private RSA keys associated with a top-10 Alexa site, several browser-trusted wildcard certi\ufb01cates for organiza-tions that used a popular VPN product, and a small sporadic population of other web sites and network devices. These measurements illustrate the fragility of RSA PKCS#1v1.5 signature padding and provide insight on the risks faced by unprotected implementations on hardware at Internet scale.",
            "keywords": [
                "TLS Security",
                "Digital Signatures",
                "RSA Key Compromise",
                "Transient Errors",
                "Faulty Signature Analysis"
            ]
        },
        "url": "URL#1417044",
        "sema_paperId": "6a4e97496ef42bcfd7eb930ef3b2a17aa739c07f"
    },
    {
        "@score": "1",
        "@id": "1417045",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "65/5518",
                        "text": "Xinyu Tang"
                    },
                    {
                        "@pid": "208/0825",
                        "text": "Saeed Mahloujifar"
                    },
                    {
                        "@pid": "150/3945",
                        "text": "Liwei Song"
                    },
                    {
                        "@pid": "243/3113",
                        "text": "Virat Shejwalkar"
                    },
                    {
                        "@pid": "187/8997",
                        "text": "Milad Nasr"
                    },
                    {
                        "@pid": "22/1797",
                        "text": "Amir Houmansadr"
                    },
                    {
                        "@pid": "39/6266",
                        "text": "Prateek Mittal"
                    }
                ]
            },
            "title": "Mitigating Membership Inference Attacks by Self-Distillation Through a Novel Ensemble Architecture.",
            "venue": "USENIX Security Symposium",
            "pages": "1433-1450",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/TangMSSNHM22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/tang",
            "url": "https://dblp.org/rec/conf/uss/TangMSSNHM22",
            "abstract": "Membership inference attacks are a key measure to evaluate privacy leakage in machine learning (ML) models. It is important to train ML models that have high membership privacy while largely preserving their utility. In this work, we propose a new framework to train privacy-preserving models that induce similar behavior on member and non-member inputs to mitigate membership inference attacks. Our framework, called SELENA, has two major components. The first component and the core of our defense is a novel ensemble architecture for training. This architecture, which we call Split-AI, splits the training data into random subsets, and trains a model on each subset of the data. We use an adaptive inference strategy at test time: our ensemble architecture aggregates the outputs of only those models that did not contain the input sample in their training data. Our second component, Self-Distillation, (self-)distills the training dataset through our Split-AI ensemble, without using any external public datasets. We prove that our Split-AI architecture defends against a family of membership inference attacks, however, our defense does not provide provable guarantees against all possible attackers as opposed to differential privacy. This enables us to improve the utility of models compared to DP. Through extensive experiments on major benchmark datasets we show that SELENA presents a superior trade-off between (empirical) membership privacy and utility compared to the state of the art empirical privacy defenses. In particular, SELENA incurs no more than 3.9% drop in classification accuracy compared to the undefended model while reducing the membership inference attack advantage by a factor of up to 3.7 compared to MemGuard and a factor of up to 2.1 compared to adversarial regularization.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-tang.pdf",
            "keywords": [
                "Membership Inference Attacks",
                "Privacy Preservation",
                "Ensemble Architecture",
                "Self-Distillation",
                "Model Utility"
            ]
        },
        "url": "URL#1417045"
    },
    {
        "@score": "1",
        "@id": "1417046",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "174/8281",
                        "text": "Mohammadkazem Taram"
                    },
                    {
                        "@pid": "298/8714",
                        "text": "Xida Ren"
                    },
                    {
                        "@pid": "76/11029",
                        "text": "Ashish Venkat"
                    },
                    {
                        "@pid": "t/DeanMTullsen",
                        "text": "Dean M. Tullsen"
                    }
                ]
            },
            "title": "SecSMT: Securing SMT Processors against Contention-Based Covert Channels.",
            "venue": "USENIX Security Symposium",
            "pages": "3165-3182",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/TaramRVT22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/taram",
            "url": "https://dblp.org/rec/conf/uss/TaramRVT22",
            "abstract": "This paper presents the first comprehensive analysis of contention-based security vulnerabilities in a high-performance simultaneous mulithreaded (SMT) processor. It features a characterization of contention throughout the shared pipeline, and potential resulting leakage channels for each resource. Further, it presents a set of unified mitiga-tion/isolation strategies that dramatically cut that leakage while preserving most of the performance of a full, insecure SMT implementation. These results lay the groundwork for considering SMT execution, with its performance benefits, a reasonable choice even for security-sensitive applications.",
            "keywords": [
                "Simultaneous Multithreading (SMT)",
                "Contention-Based Vulnerabilities",
                "Covert Channels",
                "Performance Isolation",
                "Security Mitigation Strategies"
            ]
        },
        "url": "URL#1417046",
        "sema_paperId": "e9b4d590a06636734a913bad0ff794b0591c629b"
    },
    {
        "@score": "1",
        "@id": "1417047",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "223/0853",
                        "text": "Andrei Tatar"
                    },
                    {
                        "@pid": "331/2106",
                        "text": "Dani\u00ebl Trujillo"
                    },
                    {
                        "@pid": "75/8194",
                        "text": "Cristiano Giuffrida"
                    },
                    {
                        "@pid": "91/800",
                        "text": "Herbert Bos"
                    }
                ]
            },
            "title": "TLB;DR: Enhancing TLB-based Attacks with TLB Desynchronized Reverse Engineering.",
            "venue": "USENIX Security Symposium",
            "pages": "989-1007",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/TatarTGB22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/tatar",
            "url": "https://dblp.org/rec/conf/uss/TatarTGB22",
            "abstract": "Translation Lookaside Buffers, or TLBs, play a vital role in recent microarchitectural attacks. However, unlike CPU caches, we know very little about the exact operation of these essential microarchitectural components. In this paper, we introduce TLB desynchronization as a novel technique for reverse engineering TLB behavior from software. Unlike previous efforts that rely on timing or performance counters, our technique relies on fundamental properties of TLBs, enabling precise and \ufb01ne-grained experiments. We use desynchronization to shed new light on TLB behavior, examining previously undoc-umented features such as replacement policies and handling of PCIDs on commodity Intel processors. We also show that such knowledge allows for more and better attacks. Our results reveal a novel replacement policy on the L2 TLB of modern Intel CPUs as well as behavior indicative of a PCID cache. We use our new insights to design adversarial access patterns that massage the TLB state into evicting a target entry in the minimum number of steps, then examine their impact on several classes of prior TLB-based attacks. Our \ufb01ndings enable practical side channels \u00e0 la TLBleed over L2, with much \ufb01ner spatial discrimination and at a sampling rate comparable to L1, as well as an even \ufb01ner-grained variant that targets both levels. We also show substantial speed gains for other classes of attacks that rely on TLB eviction.",
            "keywords": [
                "TLB Desynchronization",
                "Microarchitectural Attacks",
                "Translation Lookaside Buffer",
                "Replacement Policies",
                "PCID Cache Behavior"
            ]
        },
        "url": "URL#1417047",
        "sema_paperId": "fbb5ab7032d6c9887026e235962cab1554dab03b"
    },
    {
        "@score": "1",
        "@id": "1417049",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "287/4822",
                        "text": "Anvith Thudi"
                    },
                    {
                        "@pid": "255/4934",
                        "text": "Hengrui Jia"
                    },
                    {
                        "@pid": "213/8587",
                        "text": "Ilia Shumailov"
                    },
                    {
                        "@pid": "162/1405",
                        "text": "Nicolas Papernot"
                    }
                ]
            },
            "title": "On the Necessity of Auditable Algorithmic Definitions for Machine Unlearning.",
            "venue": "USENIX Security Symposium",
            "pages": "4007-4022",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ThudiJSP22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/thudi",
            "url": "https://dblp.org/rec/conf/uss/ThudiJSP22",
            "abstract": "Machine unlearning, i.e. having a model forget about some of its training data, has become increasingly more important as privacy legislation promotes variants of the right-to-be-forgotten. In the context of deep learning, approaches for machine unlearning are broadly categorized into two classes: exact unlearning methods, where an entity has formally removed the data point's impact on the model by retraining the model from scratch, and approximate unlearning, where an entity approximates the model parameters one would obtain by exact unlearning to save on compute costs. In this paper, we first show that the definition that underlies approximate unlearning, which seeks to prove the approximately unlearned model is close to an exactly retrained model, is incorrect because one can obtain the same model using different datasets. Thus one could unlearn without modifying the model at all. We then turn to exact unlearning approaches and ask how to verify their claims of unlearning. Our results show that even for a given training trajectory one cannot formally prove the absence of certain data points used during training. We thus conclude that unlearning is only well-defined at the algorithmic level, where an entity's only possible auditable claim to unlearning is that they used a particular algorithm designed to allow for external scrutiny during an audit.",
            "keywords": [
                "Machine Unlearning",
                "Right-to-be-Forgotten",
                "Exact Unlearning",
                "Approximate Unlearning",
                "Auditable Algorithmic Definitions"
            ]
        },
        "url": "URL#1417049",
        "sema_paperId": "cc0296fec3b2525f698df498253dff607f92264c"
    },
    {
        "@score": "1",
        "@id": "1417050",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "250/5797",
                        "text": "Daniel Townley"
                    },
                    {
                        "@pid": "323/4231",
                        "text": "Kerem Arikan"
                    },
                    {
                        "@pid": "30/3456",
                        "text": "Yu David Liu"
                    },
                    {
                        "@pid": "p/DmitryVPonomarev",
                        "text": "Dmitry Ponomarev 0001"
                    },
                    {
                        "@pid": "48/389",
                        "text": "Oguz Ergin"
                    }
                ]
            },
            "title": "Composable Cachelets: Protecting Enclaves from Cache Side-Channel Attacks.",
            "venue": "USENIX Security Symposium",
            "pages": "2839-2856",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/TownleyAL0E22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/townley",
            "url": "https://dblp.org/rec/conf/uss/TownleyAL0E22",
            "abstract": "The security of isolated execution architectures such as Intel SGX has been signi\ufb01cantly threatened by the recent emer-gence of side-channel attacks. Cache side-channel attacks allow adversaries to leak secrets stored inside isolated enclaves without having direct access to the enclave memory. In some cases, secrets can be leaked even without having the knowledge of the victim application code or having OS-level privileges. We propose the concept of Composable Cachelets (CC), a new scalable strategy to dynamically partition the last-level cache (LLC) for completely isolating enclaves from other applications and from each other. CC supports enclave isolation in caches with the capability to dynamically readjust the cache capacity as enclaves are created and destroyed. We present a cache-aware and enclave-aware operational semantics to help rigorously establish security properties of CC, and we experimentally demonstrate that CC thwarts side-channel attacks on caches with modest performance and complexity impact.",
            "keywords": [
                "Cache Side-Channel Attacks",
                "Enclave Isolation",
                "Last-Level Cache (LLC)",
                "Composable Cachelets",
                "Dynamic Cache Partitioning"
            ]
        },
        "url": "URL#1417050",
        "sema_paperId": "419eb719a23070a2eaad7ab6a38595487de6a909"
    },
    {
        "@score": "1",
        "@id": "1417051",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "117/6580",
                        "text": "Rahmadi Trimananda"
                    },
                    {
                        "@pid": "123/2117-3",
                        "text": "Hieu Le 0003"
                    },
                    {
                        "@pid": "98/75",
                        "text": "Hao Cui"
                    },
                    {
                        "@pid": "294/8429",
                        "text": "Janice Tran Ho"
                    },
                    {
                        "@pid": "167/5922",
                        "text": "Anastasia Shuba"
                    },
                    {
                        "@pid": "82/5866",
                        "text": "Athina Markopoulou"
                    }
                ]
            },
            "title": "OVRseen: Auditing Network Traffic and Privacy Policies in Oculus VR.",
            "venue": "USENIX Security Symposium",
            "pages": "3789-3806",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/TrimanandaLCHSM22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/trimananda",
            "url": "https://dblp.org/rec/conf/uss/TrimanandaLCHSM22",
            "abstract": "Virtual reality (VR) is an emerging technology that enables new applications but also introduces privacy risks. In this paper, we focus on Oculus VR (OVR), the leading platform in the VR space and we provide the first comprehensive analysis of personal data exposed by OVR apps and the platform itself, from a combined networking and privacy policy perspective. We experimented with the Quest 2 headset and tested the most popular VR apps available on the official Oculus and the SideQuest app stores. We developed OVRseen, a methodology and system for collecting, analyzing, and comparing network traffic and privacy policies on OVR. On the networking side, we captured and decrypted network traffic of VR apps, which was previously not possible on OVR, and we extracted data flows, defined as\u3008app, data type, destination\u3009. Compared to the mobile and other app ecosystems, we found OVR to be more centralized and driven by tracking and analytics, rather than by third-party advertising. We show that the data types exposed by VR apps include personally identifiable information (PII), device information that can be used for fingerprinting, and VR-specific data types. By comparing the data flows found in the network traffic with statements made in the apps' privacy policies, we found that approximately 70% of OVR data flows were not properly disclosed. Furthermore, we extracted additional context from the privacy policies, and we observed that 69% of the data flows were used for purposes unrelated to the core functionality of apps.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-trimananda.pdf",
            "keywords": [
                "Virtual Reality Privacy",
                "Oculus VR",
                "Network Traffic Analysis",
                "Data Exposure",
                "Privacy Policy Compliance"
            ]
        },
        "url": "URL#1417051"
    },
    {
        "@score": "1",
        "@id": "1417052",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "202/7675",
                        "text": "Timothy Trippel"
                    },
                    {
                        "@pid": "s/KangGShin",
                        "text": "Kang G. Shin"
                    },
                    {
                        "@pid": "284/8063",
                        "text": "Alex Chernyakhovsky"
                    },
                    {
                        "@pid": "284/8404",
                        "text": "Garret Kelly"
                    },
                    {
                        "@pid": "09/5053",
                        "text": "Dominic Rizzo"
                    },
                    {
                        "@pid": "09/2334",
                        "text": "Matthew Hicks"
                    }
                ]
            },
            "title": "Fuzzing Hardware Like Software.",
            "venue": "USENIX Security Symposium",
            "pages": "3237-3254",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/TrippelSCKRH22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/trippel",
            "url": "https://dblp.org/rec/conf/uss/TrippelSCKRH22",
            "abstract": "Hardware flaws are permanent and potent: hardware cannot be patched once fabricated, and any flaws may undermine any software executing on top. Consequently, verification time dominates implementation time. The gold standard in hardware Design Verification (DV) is concentrated at two extremes: random dynamic verification and formal verification. Both struggle to root out the subtle flaws in complex hardware that often manifest as security vulnerabilities. The root problem with random verification is its undirected nature, making it inefficient, while formal verification is constrained by the state-space explosion problem, making it infeasible against complex designs. What is needed is a solution that is directed, yet under-constrained. Instead of making incremental improvements to existing DV approaches, we leverage the observation that existing software fuzzers already provide such a solution, and adapt them for hardware DV. Specifically, we translate RTL hardware to a software model and fuzz that model. The central challenge we address is how best to mitigate the differences between the hardware execution model and software execution model. This includes: 1) how to represent test cases, 2) what is the hardware equivalent of a crash, 3) what is an appropriate coverage metric, and 4) how to create a general-purpose fuzzing harness for hardware. To evaluate our approach, we fuzz four IP blocks from Google's OpenTitan SoC. Our experiments reveal a two orders-of-magnitude reduction in run time to achieve Finite State Machine (FSM) coverage over traditional dynamic verification schemes. Moreover, with our design-agnostic harness, we achieve over 88% HDL line coverage in three out of four of our designs -- even without any initial seeds.",
            "keywords": [
                "Hardware Design Verification",
                "Fuzzing",
                "RTL Hardware",
                "Dynamic Verification",
                "Finite State Machine Coverage"
            ]
        },
        "url": "URL#1417052",
        "sema_paperId": "de7eff32b91ab9c2a73077e5e7258a3877ffcb94"
    },
    {
        "@score": "1",
        "@id": "1417053",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "213/3696",
                        "text": "Lenka Turonov\u00e1"
                    },
                    {
                        "@pid": "64/6177",
                        "text": "Luk\u00e1s Hol\u00edk"
                    },
                    {
                        "@pid": "171/6536",
                        "text": "Ivan Homoliak"
                    },
                    {
                        "@pid": "47/7646",
                        "text": "Ondrej Leng\u00e1l"
                    },
                    {
                        "@pid": "42/6841",
                        "text": "Margus Veanes"
                    },
                    {
                        "@pid": "51/533",
                        "text": "Tom\u00e1s Vojnar"
                    }
                ]
            },
            "title": "Counting in Regexes Considered Harmful: Exposing ReDoS Vulnerability of Nonbacktracking Matchers.",
            "venue": "USENIX Security Symposium",
            "pages": "4165-4182",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/TuronovaHHLVV22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/turonova",
            "url": "https://dblp.org/rec/conf/uss/TuronovaHHLVV22",
            "abstract": "In this paper, we study the performance characteristics of nonbacktracking regex matchers and their vulnerability against ReDoS ( regular expression denial of service ) attacks. We focus on their known Achilles heel, which are extended regexes that use bounded quanti\ufb01ers (e.g., \u2018 (ab){100} \u2019). We propose a method for generating input texts that can cause ReDoS attacks on these matchers. The method exploits the bounded repetition and uses it to force expensive simulations of the deterministic automaton for the regex. We perform an extensive experimental evaluation of our and other state-of-the-art ReDoS generators on a large set of practical regexes with a comprehensive set of backtracking and nonbacktracking matchers, as well as experiments where we demonstrate ReDoS attacks on state-of-the-art real-world security applications containing S NORT with Hyperscan and the HW-accelerated regex matching engine on the NVIDIA BlueField-2 card. Our experiments show that bounded repetition is indeed a notable weakness of nonbacktracking matchers, with our generator being the only one capable of signi\ufb01cantly increasing their running time.",
            "keywords": [
                "Regular Expression Denial of Service (ReDoS)",
                "Nonbacktracking Regex Matchers",
                "Bounded Quantifiers",
                "Regex Performance Vulnerability",
                "Deterministic Automaton Simulation"
            ]
        },
        "url": "URL#1417053",
        "sema_paperId": "b0313f5bd7af7819095cc19403688c18be90de2a"
    },
    {
        "@score": "1",
        "@id": "1417054",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "174/4813",
                        "text": "Nirvan Tyagi"
                    },
                    {
                        "@pid": "207/6590",
                        "text": "Julia Len"
                    },
                    {
                        "@pid": "129/9500",
                        "text": "Ian Miers"
                    },
                    {
                        "@pid": "26/3399",
                        "text": "Thomas Ristenpart"
                    }
                ]
            },
            "title": "Orca: Blocklisting in Sender-Anonymous Messaging.",
            "venue": "USENIX Security Symposium",
            "pages": "2299-2316",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/TyagiLMR22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/tyagi",
            "url": "https://dblp.org/rec/conf/uss/TyagiLMR22",
            "abstract": "Sender-anonymous end-to-end encrypted messaging allows sending messages to a recipient without revealing the sender's identity to the messaging platform. Signal recently introduced a sender anonymity feature that includes an abuse mitigation mechanism meant to allow the platform to block malicious senders on behalf of a recipient.We explore the tension between sender anonymity and abuse mitigation. We start by showing limitations of Signal's deployed mechanism, observing that it results in relatively weak anonymity properties and showing a new griefing attack that allows a malicious sender to drain a victim's battery. We therefore design a new protocol, called Orca, that allows recipients to register a privacy-preserving blocklist with the platform. Without learning the sender's identity, the platform can check that the sender is not on the blocklist and that the sender can be identified by the recipient. We construct Orca using a new type of group signature scheme, for which we give formal security notions. Our prototype implementation showcases Orca's practicality.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-tyagi.pdf",
            "keywords": [
                "Sender-Anonymity",
                "End-to-End Encryption",
                "Abuse Mitigation",
                "Blocklisting",
                "Group Signature Scheme"
            ]
        },
        "url": "URL#1417054"
    },
    {
        "@score": "1",
        "@id": "1417055",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "224/1548",
                        "text": "Jayakrishna Vadayath"
                    },
                    {
                        "@pid": "200/3271",
                        "text": "Moritz Eckert"
                    },
                    {
                        "@pid": "270/2413",
                        "text": "Kyle Zeng"
                    },
                    {
                        "@pid": "182/6157",
                        "text": "Nicolaas Weideman"
                    },
                    {
                        "@pid": "331/2470",
                        "text": "Gokulkrishna Praveen Menon"
                    },
                    {
                        "@pid": "11/10929",
                        "text": "Yanick Fratantonio"
                    },
                    {
                        "@pid": "56/490",
                        "text": "Davide Balzarotti"
                    },
                    {
                        "@pid": "28/8280",
                        "text": "Adam Doup\u00e9"
                    },
                    {
                        "@pid": "150/5198",
                        "text": "Tiffany Bao"
                    },
                    {
                        "@pid": "127/9829",
                        "text": "Ruoyu Wang 0001"
                    },
                    {
                        "@pid": "28/10586",
                        "text": "Christophe Hauser"
                    },
                    {
                        "@pid": "119/7712",
                        "text": "Yan Shoshitaishvili"
                    }
                ]
            },
            "title": "Arbiter: Bridging the Static and Dynamic Divide in Vulnerability Discovery on Binary Programs.",
            "venue": "USENIX Security Symposium",
            "pages": "413-430",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/VadayathEZWMFBD22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/vadayath",
            "url": "https://dblp.org/rec/conf/uss/VadayathEZWMFBD22",
            "abstract": "In spite of their effectiveness in the context of vulnerability discovery, current state-of-the-art binary program analysis approaches are limited by inherent trade-offs between accuracy and scalability. In this paper, we identify a set of vulnerability properties that can aid both static and dynamic vulnerability detection techniques, improving the precision of the former and the scalability of the latter. By carefully integrating static and dynamic techniques, we detect vulnerabilities that exhibit these properties in real-world programs at a large scale. We implemented our technique, making several advancements in the analysis of binary code, and created a prototype called A RBITER . We demonstrate the effectiveness of our approach with a large-scale evaluation on four common vulnerability classes: CWE-131 (Incorrect Calculation of Buffer Size), CWE-252 (Unchecked Return Value), CWE-134 (Un-controlled Format String), and CWE-337 (Predictable Seed in Pseudo-Random Number Generator). We evaluated our approach on more than 76,516 x86-64 binaries in the Ubuntu repositories and discovered new vulnerabilities, including a flaw inserted into programs during compilation.",
            "keywords": [
                "Binary Program Analysis",
                "Vulnerability Detection",
                "Static and Dynamic Techniques",
                "CWE Vulnerabilities",
                "Large-Scale Evaluation"
            ]
        },
        "url": "URL#1417055",
        "sema_paperId": "9a07224bd074371b5defc937f12e5cfa9309919f"
    },
    {
        "@score": "1",
        "@id": "1417056",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "187/7077",
                        "text": "Pratik Vaishnavi"
                    },
                    {
                        "@pid": "157/9161",
                        "text": "Kevin Eykholt"
                    },
                    {
                        "@pid": "125/0358",
                        "text": "Amir Rahmati"
                    }
                ]
            },
            "title": "Transferring Adversarial Robustness Through Robust Representation Matching.",
            "venue": "USENIX Security Symposium",
            "pages": "2083-2098",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/VaishnaviER22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/vaishnavi",
            "url": "https://dblp.org/rec/conf/uss/VaishnaviER22",
            "abstract": "With the widespread use of machine learning, concerns over its security and reliability have become prevalent. As such, many have developed defenses to harden neural networks against adversarial examples, imperceptibly perturbed inputs that are reliably misclassified. Adversarial training in which adversarial examples are generated and used during training is one of the few known defenses able to reliably withstand such attacks against neural networks. However, adversarial training imposes a significant training overhead and scales poorly with model complexity and input dimension. In this paper, we propose Robust Representation Matching (RRM), a low-cost method to transfer the robustness of an adversarially trained model to a new model being trained for the same task irrespective of architectural differences. Inspired by student-teacher learning, our method introduces a novel training loss that encourages the student to learn the teacher's robust representations. Compared to prior works, RRM is superior with respect to both model performance and adversarial training time. On CIFAR-10, RRM trains a robust model $\\sim 1.8\\times$ faster than the state-of-the-art. Furthermore, RRM remains effective on higher-dimensional datasets. On Restricted-ImageNet, RRM trains a ResNet50 model $\\sim 18\\times$ faster than standard adversarial training.",
            "keywords": [
                "Adversarial Robustness",
                "Robust Representation Matching",
                "Adversarial Training",
                "Model Transfer",
                "Representation Learning"
            ]
        },
        "url": "URL#1417056",
        "sema_paperId": "88399dde6052de10a23fe43cc7d6d659493b0c7e"
    },
    {
        "@score": "1",
        "@id": "1417057",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "130/1339-1",
                        "text": "Lun Wang 0001"
                    },
                    {
                        "@pid": "281/7021",
                        "text": "Usmann Khan"
                    },
                    {
                        "@pid": "39/5361",
                        "text": "Joseph P. Near"
                    },
                    {
                        "@pid": "44/8421",
                        "text": "Qi Pang"
                    },
                    {
                        "@pid": "281/6755",
                        "text": "Jithendaraa Subramanian"
                    },
                    {
                        "@pid": "248/7712",
                        "text": "Neel Somani"
                    },
                    {
                        "@pid": "29/5999-8",
                        "text": "Peng Gao 0008"
                    },
                    {
                        "@pid": "174/9529",
                        "text": "Andrew Low"
                    },
                    {
                        "@pid": "s/DXSong",
                        "text": "Dawn Song"
                    }
                ]
            },
            "title": "PrivGuard: Privacy Regulation Compliance Made Easier.",
            "venue": "USENIX Security Symposium",
            "pages": "3753-3770",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WangKNPSS0LS22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/wang-lun",
            "url": "https://dblp.org/rec/conf/uss/WangKNPSS0LS22",
            "abstract": "Continuous compliance with privacy regulations, such as GDPR and CCPA, has become a costly burden for companies from small-sized start-ups to business giants. The culprit is the heavy reliance on human auditing in today\u2019s compliance process, which is expensive, slow, and error-prone. To address the issue, we propose P RIV G UARD , a novel system design that reduces human participation required and improves the productivity of the compliance process. P RIV G UARD is mainly comprised of two components: (1) P RIV A NALYZER , a static analyzer based on abstract interpretation for partly enforcing privacy regulations, and (2) a set of components providing strong security protection on the data throughout its life cycle. To validate the effectiveness of this approach, we prototype P RIV G UARD and integrate it into an industrial-level data governance platform. Our case studies and evaluation show that P RIV G UARD can correctly enforce the encoded privacy policies on real-world programs with reasonable performance overhead.",
            "keywords": [
                "Privacy Regulation Compliance",
                "GDPR",
                "CCPA",
                "Automated Compliance",
                "Data Governance"
            ]
        },
        "url": "URL#1417057",
        "sema_paperId": "c8217dce520d243b1643be8b0a56df764616154d"
    },
    {
        "@score": "1",
        "@id": "1417058",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "78/2022",
                        "text": "Kai Wang"
                    },
                    {
                        "@pid": "244/4957",
                        "text": "Richard Mitev"
                    },
                    {
                        "@pid": "46/1162-1",
                        "text": "Chen Yan 0001"
                    },
                    {
                        "@pid": "39/1697-1",
                        "text": "Xiaoyu Ji 0001"
                    },
                    {
                        "@pid": "s/AhmadRezaSadeghi",
                        "text": "Ahmad-Reza Sadeghi"
                    },
                    {
                        "@pid": "10/3878-1",
                        "text": "Wenyuan Xu 0001"
                    }
                ]
            },
            "title": "GhostTouch: Targeted Attacks on Touchscreens without Physical Touch.",
            "venue": "USENIX Security Symposium",
            "pages": "1543-1559",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WangMY0SX22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/wang-kai",
            "url": "https://dblp.org/rec/conf/uss/WangMY0SX22",
            "abstract": "Capacitive touchscreens have become the primary human-machine interface for personal devices such as smartphones and tablets. In this paper, we present GhostTouch , the \ufb01rst active contactless attack against capacitive touchscreens. GhostTouch uses electromagnetic interference (EMI) to inject fake touch points into a touchscreen without the need to physically touch it. By tuning the parameters of the electromagnetic signal and adjusting the antenna, we can inject two types of basic touch events, taps and swipes, into targeted locations of the touchscreen and control them to manipulate the underlying device. We successfully launch the GhostTouch attacks on nine smartphone models. We can inject targeted taps continuously with a standard deviation of as low as 14 . 6 \u00d7 19 . 2 pixels from the target area, a delay of less than 0 . 5 s and a distance of up to 40 mm . We show the real-world impact of the GhostTouch attacks in a few proof-of-concept scenarios, including answering an eavesdropping phone call, pressing the button, swiping up to unlock, and entering a password. Finally, we discuss potential hardware and software countermeasures to mitigate the attack.",
            "keywords": [
                "Touchscreen Security",
                "Electromagnetic Interference",
                "Contactless Attack",
                "Fake Touch Injection",
                "GhostTouch"
            ]
        },
        "url": "URL#1417058",
        "sema_paperId": "cc671f2b7167eb2d69c8c292a855be5e3d1fc451"
    },
    {
        "@score": "1",
        "@id": "1417059",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "216/4663",
                        "text": "Yingchen Wang"
                    },
                    {
                        "@pid": "224/9301",
                        "text": "Riccardo Paccagnella"
                    },
                    {
                        "@pid": "331/2739",
                        "text": "Elizabeth Tang He"
                    },
                    {
                        "@pid": "35/1061",
                        "text": "Hovav Shacham"
                    },
                    {
                        "@pid": "25/8166",
                        "text": "Christopher W. Fletcher"
                    },
                    {
                        "@pid": "131/5093",
                        "text": "David Kohlbrenner"
                    }
                ]
            },
            "title": "Hertzbleed: Turning Power Side-Channel Attacks Into Remote Timing Attacks on x86.",
            "venue": "USENIX Security Symposium",
            "pages": "679-697",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WangPHSFK22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/wang-yingchen",
            "url": "https://dblp.org/rec/conf/uss/WangPHSFK22",
            "abstract": "Power side-channel attacks exploit data-dependent variations in a CPU's power consumption to leak secrets. In this paper, we show that on modern Intel (and AMD) x86 CPUs, power side-channel attacks can be turned into timing attacks that can be mounted without access to any power measurement interface. Our discovery is enabled by dynamic voltage and frequency scaling (DVFS). We find that, under certain circumstances, DVFS-induced variations in CPU frequency depend on the current power consumption (and hence, data) at the granularity of milliseconds. Making matters worse, these variations can be observed by a remote attacker, since frequency differences translate to wall time differences!The frequency side channel is theoretically more powerful than the software side channels considered in cryptographic engineering practice today, but it is difficult to exploit because it has a coarse granularity. Yet, we show that this new channel is a real threat to the security of cryptographic software. First, we reverse engineer the dependency between data, power, and frequency on a modern x86 CPU\u2014finding, among other things, that differences as seemingly minute as a set bit's position in a word can be distinguished through frequency changes. Second, we describe a novel chosen-ciphertext attack against (constant-time implementations of) SIKE, a post-quantum key encapsulation mechanism, that amplifies a single key-bit guess into many thousands of high- or low-power operations, allowing full key extraction via remote timing.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-wang-yingchen.pdf",
            "keywords": [
                "Power Side-Channel Attacks",
                "Dynamic Voltage and Frequency Scaling (DVFS)",
                "Remote Timing Attacks",
                "Cryptographic Software Vulnerabilities",
                "Chosen-Ciphertext Attack"
            ]
        },
        "url": "URL#1417059"
    },
    {
        "@score": "1",
        "@id": "1417060",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "210/1379",
                        "text": "Chuhan Wang"
                    },
                    {
                        "@pid": "245/2568",
                        "text": "Kaiwen Shen"
                    },
                    {
                        "@pid": "278/8551",
                        "text": "Minglei Guo"
                    },
                    {
                        "@pid": "173/0246",
                        "text": "Yuxuan Zhao"
                    },
                    {
                        "@pid": "29/3959",
                        "text": "Mingming Zhang"
                    },
                    {
                        "@pid": "20/1036-5",
                        "text": "Jianjun Chen 0005"
                    },
                    {
                        "@pid": "89/10754",
                        "text": "Baojun Liu"
                    },
                    {
                        "@pid": "11/11005",
                        "text": "Xiaofeng Zheng"
                    },
                    {
                        "@pid": "36/5143",
                        "text": "Haixin Duan"
                    },
                    {
                        "@pid": "331/2560",
                        "text": "Yanzhong Lin"
                    },
                    {
                        "@pid": "245/2668",
                        "text": "Qingfeng Pan"
                    }
                ]
            },
            "title": "A Large-scale and Longitudinal Measurement Study of DKIM Deployment.",
            "venue": "USENIX Security Symposium",
            "pages": "1185-1201",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WangSGZZ0LZDLP22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/wang-chuhan",
            "url": "https://dblp.org/rec/conf/uss/WangSGZZ0LZDLP22",
            "abstract": "DomainKeys Identi\ufb01ed Mail (DKIM) is an email authentication protocol to protect the integrity of email contents. It has been proposed and standardized for over a decade and adopted by Yahoo!, Google, and other leading email service providers. However, little has been done to understand the adoption rate and potential security issues of DKIM due to the challenges of measuring DKIM deployment at scale. In this paper, we provide a large-scale and longitudinal measurement study on how well DKIM is deployed and managed. Our study was made possible by a broad collection of datasets, including 9.5 million DKIM records from passive DNS datasets over \ufb01ve years and 460 million DKIM signatures from real-world email headers. Moreover, we conduct an active measurement on Alexa Top 1 million domains. Our measurement results show that 28.1% of Alexa Top 1 million domains have enabled DKIM, of which 2.9% are mis-con\ufb01gured. We demonstrate that the issues of DKIM key management and DKIM signatures are prevalent in the real world, even for well-known email providers (e.g., Gmail and Mail.ru). We recommend the security community should pay more attention to the systemic problems of DKIM deployment and mitigate these issues from the perspective of protocol de-sign.",
            "keywords": [
                "Email Authentication",
                "DKIM Deployment",
                "Email Security",
                "Key Management Issues",
                "Misconfiguration"
            ]
        },
        "url": "URL#1417060",
        "sema_paperId": "b35588871e0d8428eaf3907dcbdb8bca7b779987"
    },
    {
        "@score": "1",
        "@id": "1417061",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "10/293",
                        "text": "Zhiwei Wang"
                    },
                    {
                        "@pid": "118/0321",
                        "text": "Yihui Yan"
                    },
                    {
                        "@pid": "331/2308",
                        "text": "Yueli Yan"
                    },
                    {
                        "@pid": "202/8474",
                        "text": "Huangxun Chen"
                    },
                    {
                        "@pid": "162/5529",
                        "text": "Zhice Yang"
                    }
                ]
            },
            "title": "CamShield: Securing Smart Cameras through Physical Replication and Isolation.",
            "venue": "USENIX Security Symposium",
            "pages": "3467-3484",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WangYYCY22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/wang-zhiwei",
            "url": "https://dblp.org/rec/conf/uss/WangYYCY22",
            "abstract": "Smart home devices, such as security cameras, are equipped with visual sensors, either for monitoring or improving user experience. Due to the sensitivity of the home environment, their visual sensing capabilities cause privacy and security concerns. In this paper, we design and implement the CamShield, a companion device to guarantee the privacy of smart security cameras, even if the whole camera system is fully compromised. At a high level, the CamShield is a shielding case that works by attaching it to the front of the security camera to blind it. Then, it uses its own camera for visual recording. The videos are \ufb01rst protected according to user-speci\ufb01ed policies, and then transmitted to the security camera and hence to the Internet through a Visible Light Communication (VLC) channel. It ensures that only the authorized entities have full access to the protected videos. Since the CamShield is physically isolated from the shielded security camera and the Internet, it naturally resists many known attacks and can operate as it is expected to.",
            "keywords": [
                "Smart Home Security",
                "Privacy Protection",
                "Visual Sensors",
                "Companion Device",
                "Visible Light Communication (VLC)"
            ]
        },
        "url": "URL#1417061",
        "sema_paperId": "2039996d7d91334bb98ac6e2a0cbb67282a7c41c"
    },
    {
        "@score": "1",
        "@id": "1417062",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "317/1692",
                        "text": "Jean-Luc Watson"
                    },
                    {
                        "@pid": "175/1766",
                        "text": "Sameer Wagh"
                    },
                    {
                        "@pid": "91/275",
                        "text": "Raluca Ada Popa"
                    }
                ]
            },
            "title": "Piranha: A GPU Platform for Secure Computation.",
            "venue": "USENIX Security Symposium",
            "pages": "827-844",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WatsonWP22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/watson",
            "url": "https://dblp.org/rec/conf/uss/WatsonWP22",
            "abstract": "Secure multi-party computation (MPC) is an essential tool for privacy-preserving machine learning (ML). However, secure training of large-scale ML models currently requires a prohibitively long time to complete. Given that large ML inference and training tasks in the plaintext setting are significantly accelerated by Graphical Processing Units (GPUs), this raises the natural question: can secure MPC leverage GPU acceleration? A few recent works have studied this question in the context of accelerating specific components or protocols, but do not provide a general-purpose solution. Consequently, MPC developers must be both experts in cryptographic protocol design and proficient at low-level GPU kernel development to achieve good performance on any new protocol implementation.\nWe present Piranha, a general-purpose, modular platform for accelerating secret sharing-based MPC protocols using GPUs. Piranha allows the MPC community to easily leverage the benefits of a GPU without requiring GPU expertise. Piranha contributes a three-layer architecture: (1) a device layer that can independently accelerate secret-sharing protocols by providing integer-based kernels absent in current general-purpose GPU libraries, (2) a modular protocol layer that allows developers to maximize utility of limited GPU memory with in-place computation and iterator-based support for non-standard memory access patterns, and (3) an application layer that allows applications to remain completely agnostic to the underlying protocols they use.\nTo demonstrate the benefits of Piranha, we implement 3 state-of-the-art linear secret sharing MPC protocols for secure NN training: 2-party SecureML (IEEE S&P '17), 3-party Falcon (PETS '21), and 4-party FantasticFour (USENIX Security '21). Compared to their CPU-based implementations, the same protocols implemented on top of Piranha's protocol-agnostic acceleration exhibit a 16-48x decrease in training time. For the first time, Piranha demonstrates the feasibility of training a realistic neural network (e.g. VGG), end-to-end, using MPC in a little over one day. Piranha is open source and available at https://github.com/ucbrise/piranha.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-watson.pdf",
            "keywords": [
                "Secure Multi-Party Computation",
                "GPU Acceleration",
                "Secret Sharing",
                "Protocol Implementation",
                "Training Time Reduction"
            ]
        },
        "url": "URL#1417062"
    },
    {
        "@score": "1",
        "@id": "1417064",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "331/2554",
                        "text": "Johannes Wikner"
                    },
                    {
                        "@pid": "121/2685",
                        "text": "Kaveh Razavi"
                    }
                ]
            },
            "title": "RETBLEED: Arbitrary Speculative Code Execution with Return Instructions.",
            "venue": "USENIX Security Symposium",
            "pages": "3825-3842",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WiknerR22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/wikner",
            "url": "https://dblp.org/rec/conf/uss/WiknerR22",
            "abstract": "Modern operating systems rely on software defenses against hardware attacks. These defenses are, however, as good as the assumptions they make on the underlying hardware. In this paper, we invalidate some of the key assumptions behind retpoline , a widely deployed mitigation against Spectre Branch Target Injection (BTI) that converts vulnerable indirect branches to protected returns. We present R ETBLEED , a new Spectre-BTI attack that leaks arbitrary kernel memory on fully patched Intel and AMD systems. Two insights make R ETBLEED possible: \ufb01rst, we show that return instructions behave like indirect branches under certain microarchitecture-dependent conditions, which we reverse engineer. Our dynamic analysis framework discovers many exploitable return instructions inside the Linux kernel, reach-able through unprivileged system calls. Second, we show how an unprivileged attacker can arbitrarily control the predicted target of such return instructions by branching into kernel memory. R ETBLEED leaks privileged memory at the rate of 219 bytes/s on Intel Coffee Lake and 3.9 kB/s on AMD Zen 2. Abstract Speculative execution attacks that exploit branch target injection (Spectre-BTI) have so far been limited to indirect branch instructions. R ETBLEED extends Spectre-BTI to return instructions. During our research into R ETBLEED , we discovered that certain AMD CPUs are also vulnerable to a new class of speculative execution attacks that we refer to as P HANTOM JMP S \u2014 incorrect branch target prediction in the absence of a corresponding branch instruction. Our investiga-tion so far shows that P HANTOM JMP S signi\ufb01cantly increases the attack surface of Spectre-BTI, but it is more dif\ufb01cult to exploit under real-world conditions. This addendum brie\ufb02y discusses our \ufb01ndings and directions for future research.",
            "keywords": [
                "Speculative Execution Attacks",
                "Branch Target Injection",
                "Return Instructions",
                "Kernel Memory Leakage",
                "RETBLEED"
            ]
        },
        "url": "URL#1417064",
        "sema_paperId": "8d83482799bab6f973a7e530533e071870e4e3f3"
    },
    {
        "@score": "1",
        "@id": "1417065",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "201/9210",
                        "text": "Seunghoon Woo"
                    },
                    {
                        "@pid": "308/2183",
                        "text": "Hyunji Hong"
                    },
                    {
                        "@pid": "196/5004",
                        "text": "Eunjin Choi"
                    },
                    {
                        "@pid": "75/4485",
                        "text": "Heejo Lee"
                    }
                ]
            },
            "title": "MOVERY: A Precise Approach for Modified Vulnerable Code Clone Discovery from Modified Open-Source Software Components.",
            "venue": "USENIX Security Symposium",
            "pages": "3037-3053",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WooHCL22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/woo",
            "url": "https://dblp.org/rec/conf/uss/WooHCL22",
            "abstract": "Vulnerabilities inherited from third-party open-source software (OSS) components can compromise the entire software security. However, discovering propagated vulnerable code is challenging as it proliferates with various code syntaxes owing to the OSS modifications, more specifically, internal ( e . g ., OSS updates) and external modifications of OSS ( e . g ., code changes that occur during the OSS reuse). In this paper, we present M OVERY , a precise approach for discovering vulnerable code clones (VCCs) from modified OSS components. By considering the oldest vulnerable function and extracting only core vulnerable and patch lines from security patches, M OVERY generates vulnerability and patch signatures that effectively address OSS modifications. For scalability, M OVERY reduces the search space of the target software by focusing only on the codes borrowed from other OSS projects. Finally, M OVERY determines that the function is VCC when it matches the vulnerability signature and is distinctive from the patch signature. When",
            "keywords": [
                "Open-Source Software Security",
                "Vulnerable Code Clones",
                "Vulnerability Discovery",
                "Code Modifications",
                "Vulnerability Signatures"
            ]
        },
        "url": "URL#1417065",
        "sema_paperId": "6a721b2e1f31cdfc67d20211c3113258465e7cca"
    },
    {
        "@score": "1",
        "@id": "1417066",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "179/3242",
                        "text": "Yongji Wu"
                    },
                    {
                        "@pid": "146/9100",
                        "text": "Xiaoyu Cao"
                    },
                    {
                        "@pid": "24/5124-1",
                        "text": "Jinyuan Jia 0001"
                    },
                    {
                        "@pid": "03/9437",
                        "text": "Neil Zhenqiang Gong"
                    }
                ]
            },
            "title": "Poisoning Attacks to Local Differential Privacy Protocols for Key-Value Data.",
            "venue": "USENIX Security Symposium",
            "pages": "519-536",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WuCJG22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/wu-yongji",
            "url": "https://dblp.org/rec/conf/uss/WuCJG22",
            "abstract": "Local Differential Privacy (LDP) protocols enable an untrusted server to perform privacy-preserving, federated data analytics. Various LDP protocols have been developed for different types of data such as categorical data, numerical data, and key-value data. Due to their distributed settings, LDP protocols are fundamentally vulnerable to poisoning attacks, in which fake users manipulate the server's analytics results via sending carefully crafted data to the server. However, existing poisoning attacks focused on LDP protocols for simple data types such as categorical and numerical data, leaving the security of LDP protocols for more advanced data types such as key-value data unexplored. In this work, we aim to bridge the gap by introducing novel poisoning attacks to LDP protocols for key-value data. In such a LDP protocol, a server aims to simultaneously estimate the frequency and mean value of each key among some users, each of whom possesses a set of key-value pairs. Our poisoning attacks aim to simultaneously maximize the frequencies and mean values of some attacker-chosen target keys via sending carefully crafted data from some fake users to the sever. Specifically, since our attacks have two objectives, we formulate them as a two-objective optimization problem. Moreover, we propose a method to approximately solve the two-objective optimization problem, from which we obtain the optimal crafted data the fake users should send to the server. We demonstrate the effectiveness of our attacks to three LDP protocols for key-value data both theoretically and empirically. We also explore two defenses against our attacks, which are effective in some scenarios but have limited effectiveness in other scenarios. Our results highlight the needs for new defenses against our poisoning attacks.",
            "keywords": [
                "Local Differential Privacy",
                "Poisoning Attacks",
                "Key-Value Data",
                "Data Manipulation",
                "Two-Objective Optimization"
            ]
        },
        "url": "URL#1417066",
        "sema_paperId": "2f41590e197f3831a06087d3673e187e191c21bb"
    },
    {
        "@score": "1",
        "@id": "1417067",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "40/5102",
                        "text": "Ruoyu Wu"
                    },
                    {
                        "@pid": "157/5259",
                        "text": "Taegyu Kim"
                    },
                    {
                        "@pid": "159/0537",
                        "text": "Dave (Jing) Tian"
                    },
                    {
                        "@pid": "99/3883",
                        "text": "Antonio Bianchi"
                    },
                    {
                        "@pid": "59/5539",
                        "text": "Dongyan Xu"
                    }
                ]
            },
            "title": "DnD: A Cross-Architecture Deep Neural Network Decompiler.",
            "venue": "USENIX Security Symposium",
            "pages": "2135-2152",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WuKTBX22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/wu-ruoyu",
            "url": "https://dblp.org/rec/conf/uss/WuKTBX22",
            "abstract": "The usage of Deep Neural Networks (DNNs) has steadily increased in recent years. Especially when used in edge devices, dedicated DNN compilers are used to compile DNNs into binaries. Many security applications (such as DNN model extraction, white-box adversarial sample generation, and DNN model patching and hardening) are possible when a DNN model is accessible. However, these techniques cannot be applied to compiled DNNs. Unfortunately, no dedicated decompiler exists that is able to recover a high-level representation of a DNN starting from its compiled binary code.To address this issue, we propose DnD, the first compiler- and ISA-agnostic DNN decompiler. DnD uses symbolic execution, in conjunction with a dedicated loop analysis, to lift the analyzed binary code into a novel intermediate representation, able to express the high-level mathematical DNN operations in a compiler- and ISA-agnostic way. Then, DnD matches the extracted mathematical DNN operations with template mathematical DNN operations, and it recovers hyper-parameters and parameters of all the identified DNN operators, as well as the overall DNN topology. Our evaluation shows that DnD can perfectly recover different DNN models, extracting them from binaries compiled by two different compilers (Glow and TVM) for three different ISAs (Thumb, AArch64, and x86-64). Moreover, DnD enables extracting the DNN models used by real-world micro-controllers and attacking them using white-box adversarial machine learning techniques.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-wu-ruoyu.pdf",
            "keywords": [
                "DNN Decompilation",
                "Symbolic Execution",
                "Intermediate Representation",
                "Compiler-Agnostic",
                "Model Extraction"
            ]
        },
        "url": "URL#1417067",
        "sema_paperId": "a793ffb0de38f621d5ba7c798c194235a8501846"
    },
    {
        "@score": "1",
        "@id": "1417068",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "248/1662",
                        "text": "Qiushi Wu"
                    },
                    {
                        "@pid": "80/6791-7",
                        "text": "Yue Xiao 0007"
                    },
                    {
                        "@pid": "129/1113",
                        "text": "Xiaojing Liao"
                    },
                    {
                        "@pid": "67/10639",
                        "text": "Kangjie Lu"
                    }
                ]
            },
            "title": "OS-Aware Vulnerability Prioritization via Differential Severity Analysis.",
            "venue": "USENIX Security Symposium",
            "pages": "395-412",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WuXLL22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/wu-qiushi",
            "url": "https://dblp.org/rec/conf/uss/WuXLL22",
            "abstract": "The Linux kernel is quickly evolving and extensively customized. This results in thousands of versions and derivatives. Unfortunately, the Linux kernel is quite vulnerable. Each year, thousands of bugs are reported, and hundreds of them are security-related bugs. Given the limited resources, the kernel maintainers have to prioritize patching the more severe vulnerabilities. In practice, Common Vulnerability Scoring System (CVSS) [1] has become the standard for characterizing vulnerability severity. However, a fundamental problem exists when CVSS meets Linux\u2014it is used in a \u201cone for all\u201d manner. The severity of a Linux vulnerability is assessed for only the mainstream Linux, and all affected versions and derivatives will simply honor and reuse the CVSS score. Such an undistinguished CVSS usage results in underestimation or overestimation of severity, which further results in delayed and ignored patching or wastes of the precious resources. In this paper, we propose OS-aware vulnerability prioritization (namely D IFF CVSS), which employs differential severity analysis for vulnerabilities. Specifically, given a severity-assessed vulnerability, as well as the mainstream version and a target version of Linux, D IFF CVSS employs multiple new techniques based on static program analysis and natural language processing to differentially identify whether the vulnerability manifests a higher or lower severity in the target version. A unique strength of this approach is that it transforms the challenging and laborious CVSS calculation into automatable differential analysis. We implement D IFF CVSS and apply it to the mainstream Linux and downstream Android systems. The evaluation and user-study results show that D IFF CVSS is able to precisely perform the differential severity analysis, and offers a precise and effective way to identify vulnerabilities that deserve a severity reevaluation.",
            "keywords": [
                "Linux Kernel Vulnerabilities",
                "Vulnerability Prioritization",
                "Differential Severity Analysis",
                "Common Vulnerability Scoring System (CVSS)",
                "OS-aware Vulnerability Assessment"
            ]
        },
        "url": "URL#1417068",
        "sema_paperId": "01ab986d2aa0f6547251debd0b6a8d4e22ddc14d"
    },
    {
        "@score": "1",
        "@id": "1417069",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "205/3035",
                        "text": "Shujiang Wu"
                    },
                    {
                        "@pid": "251/3631",
                        "text": "Jianjia Yu"
                    },
                    {
                        "@pid": "02/1640-2",
                        "text": "Min Yang 0002"
                    },
                    {
                        "@pid": "28/8733",
                        "text": "Yinzhi Cao"
                    }
                ]
            },
            "title": "Rendering Contention Channel Made Practical in Web Browsers.",
            "venue": "USENIX Security Symposium",
            "pages": "3183-3199",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WuY0C22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/wu-shujiang",
            "url": "https://dblp.org/rec/conf/uss/WuY0C22",
            "abstract": "Browser rendering utilizes hardware resources shared within and across browsers to display web contents, thus inevitably being vulnerable to side channel attacks. Prior works have studied rendering side channels that are caused by rendering time differences of one frame, such as URL color change. However, it still remains unclear how rendering contentions play a role in side-channel attacks and covert communications. In this paper, we design a novel rendering contention channel. Speci\ufb01cally, we stress the browser\u2019s rendering resource with stable, self-adjustable pressure and measure the time taken to render a sequence of frames. The measured time sequence is further used to infer any co-rendering event of the browser. To better understand the channel, we study its cause via a method called single variable testing. That is, we keep all variables the same but only change one to test whether the changed variable contributes to the contention. Our results show that CPU, GPU and screen buffer are all part of the contention. To demonstrate the channel\u2019s feasibility, we design and implement a prototype, open-source framework, called S IDE R, to launch four attacks using the rendering contention channel, which are (i) cross-browser, cross-mode cookie synchronization, (ii) history snif\ufb01ng, (iii) website \ufb01ngerprinting, and (iv) keystroke logging. Our evaluation shows the effectiveness and feasibility of all four attacks.",
            "keywords": [
                "Browser Rendering",
                "Side Channel Attacks",
                "Rendering Contention",
                "Covert Communications",
                "S IDE R Framework"
            ]
        },
        "url": "URL#1417069",
        "sema_paperId": "2d7eafba365ca9c0ca5e1def51fffaac1a8a94ba"
    },
    {
        "@score": "1",
        "@id": "1417070",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "205/5853",
                        "text": "Qinge Xie"
                    },
                    {
                        "@pid": "329/5533",
                        "text": "Shujun Tang"
                    },
                    {
                        "@pid": "11/11005",
                        "text": "Xiaofeng Zheng"
                    },
                    {
                        "@pid": "257/1214",
                        "text": "Qingran Lin"
                    },
                    {
                        "@pid": "89/10754",
                        "text": "Baojun Liu"
                    },
                    {
                        "@pid": "36/5143",
                        "text": "Haixin Duan"
                    },
                    {
                        "@pid": "53/10825",
                        "text": "Frank Li 0001"
                    }
                ]
            },
            "title": "Building an Open, Robust, and Stable Voting-Based Domain Top List.",
            "venue": "USENIX Security Symposium",
            "pages": "625-642",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/XieTZLLD022",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/xie",
            "url": "https://dblp.org/rec/conf/uss/XieTZLLD022",
            "abstract": "Domain top lists serve as critical resources for the Internet measurement, security, and privacy research communities. Hundreds of prior research studies have used these lists as a set of supposedly popular domains to investigate. However, existing top lists exhibit numerous issues, including a lack of transparency into the list data sources and construction methods, high volatility, and easy ranking manipulation. Despite these \ufb02aws, these top lists remain widely used today due to a lack of suitable alternatives. In this paper, we systematically explore the construction of a domain top list from scratch. Using an extensive passive DNS dataset, we investigate different top list design considerations. As a product of our exploration, we produce a voting-based domain ranking method where we quantify the domain preferences of individual IP addresses, and then determine a global ranking across addresses through a voting mechanism. We empirically evaluate our top list design, demonstrating that it achieves better stability and manipulation resistance than existing top lists, while serving as an open and transparent ranking method that other researchers can use or adapt.",
            "keywords": [
                "Domain Top Lists",
                "Internet Measurement",
                "Voting-Based Ranking",
                "Domain Manipulation Resistance",
                "Transparency in Data Sources"
            ]
        },
        "url": "URL#1417070",
        "sema_paperId": "4d4e42b91a756c58a79c1cb20d134c7c2e359c5c"
    },
    {
        "@score": "1",
        "@id": "1417071",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "217/0857",
                        "text": "Jiarong Xing"
                    },
                    {
                        "@pid": "36/10257",
                        "text": "Kuo-Feng Hsu"
                    },
                    {
                        "@pid": "25/9687",
                        "text": "Yiming Qiu"
                    },
                    {
                        "@pid": "331/2526",
                        "text": "Ziyang Yang"
                    },
                    {
                        "@pid": "45/4076",
                        "text": "Hongyi Liu"
                    },
                    {
                        "@pid": "59/146-1",
                        "text": "Ang Chen 0001"
                    }
                ]
            },
            "title": "Bedrock: Programmable Network Support for Secure RDMA Systems.",
            "venue": "USENIX Security Symposium",
            "pages": "2585-2600",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/XingHQYLC22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/xing",
            "url": "https://dblp.org/rec/conf/uss/XingHQYLC22",
            "abstract": "Remote direct memory access (RDMA) has gained popularity in cloud datacenters. In RDMA, clients bypass server CPUs and directly read/write remote memory. Recent \ufb01ndings have highlighted a host of vulnerabilities with RDMA, which give rise to attacks such as packet injection, denial of service, and side channel leakage, but RDMA defenses are still lagging behind. As the RDMA datapath bypasses CPU-based software processing, traditional defenses cannot be easily inserted without incurring performance penalty. Bedrock develops a security foundation for RDMA inside the network, leverag-ing programmable data planes in modern network hardware. It designs a range of defense primitives, including source authentication, access control, as well as monitoring and logging, to address RDMA-based attacks. Bedrock does not incur software overhead to the critical datapath, and delivers native RDMA performance in data transfers. Moreover, Bedrock operates transparently to legacy RDMA systems, without requiring RNIC, OS, or RDMA library changes. We present a comprehensive set of experiments on Bedrock and demonstrate its effectiveness.",
            "keywords": [
                "RDMA Security",
                "Programmable Data Planes",
                "Network Attacks",
                "Source Authentication",
                "Access Control"
            ]
        },
        "url": "URL#1417071",
        "sema_paperId": "3febb525fde42ace2942d5ab1f50fcfd0abae2d1"
    },
    {
        "@score": "1",
        "@id": "1417072",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "259/6190",
                        "text": "Diwen Xue"
                    },
                    {
                        "@pid": "270/2465",
                        "text": "Reethika Ramesh"
                    },
                    {
                        "@pid": "305/3463",
                        "text": "Arham Jain"
                    },
                    {
                        "@pid": "68/4656",
                        "text": "Michalis Kallitsis 0001"
                    },
                    {
                        "@pid": "h/JAlexHalderman",
                        "text": "J. Alex Halderman"
                    },
                    {
                        "@pid": "c/JRCrandall",
                        "text": "Jedidiah R. Crandall"
                    },
                    {
                        "@pid": "24/973",
                        "text": "Roya Ensafi"
                    }
                ]
            },
            "title": "OpenVPN is Open to VPN Fingerprinting.",
            "venue": "USENIX Security Symposium",
            "pages": "483-500",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/XueRJ0HCE22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/xue-diwen",
            "url": "https://dblp.org/rec/conf/uss/XueRJ0HCE22",
            "abstract": "VPN adoption has seen steady growth over the past decade due to increased public awareness of privacy and surveillance threats. In response, certain governments are attempting to restrict VPN access by identifying connections using \"dual use\" DPI technology. To investigate the potential for VPN blocking, we develop mechanisms for accurately fingerprinting connections using OpenVPN, the most popular protocol for commercial VPN services. We identify three fingerprints based on protocol features such as byte pattern, packet size, and server response. Playing the role of an attacker who controls the network, we design a two-phase framework that performs passive fingerprinting and active probing in sequence. We evaluate our framework in partnership with a million-user ISP and find that we identify over 85% of OpenVPN flows with only negligible false positives, suggesting that OpenVPN-based services can be effectively blocked with little collateral damage. Although some commercial VPNs implement countermeasures to avoid detection, our framework successfully identified connections to 34 out of 41 \"obfuscated\" VPN configurations. We discuss the implications of the VPN fingerprintability for different threat models and propose short-term defenses. In the longer term, we urge commercial VPN providers to be more transparent about their obfuscation approaches and to adopt more principled detection countermeasures, such as those developed in censorship circumvention research.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-xue-diwen.pdf",
            "keywords": [
                "VPN Fingerprinting",
                "OpenVPN",
                "DPI Technology",
                "Traffic Analysis",
                "Obfuscation Techniques"
            ]
        },
        "url": "URL#1417072"
    },
    {
        "@score": "1",
        "@id": "1417073",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "46/1162-1",
                        "text": "Chen Yan 0001"
                    },
                    {
                        "@pid": "72/8350",
                        "text": "Zhijian Xu"
                    },
                    {
                        "@pid": "289/3025",
                        "text": "Zhanyuan Yin"
                    },
                    {
                        "@pid": "39/1697-1",
                        "text": "Xiaoyu Ji 0001"
                    },
                    {
                        "@pid": "10/3878-1",
                        "text": "Wenyuan Xu 0001"
                    }
                ]
            },
            "title": "Rolling Colors: Adversarial Laser Exploits against Traffic Light Recognition.",
            "venue": "USENIX Security Symposium",
            "pages": "1957-1974",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YanXY0X22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/yan",
            "url": "https://dblp.org/rec/conf/uss/YanXY0X22",
            "abstract": "Traffic light recognition is essential for fully autonomous driving in urban areas. In this paper, we investigate the feasibility of fooling traffic light recognition mechanisms by shedding laser interference on the camera. By exploiting the rolling shutter of CMOS sensors, we manage to inject a color stripe overlapped on the traffic light in the image, which can cause a red light to be recognized as a green light or vice versa. To increase the success rate, we design an optimization method to search for effective laser parameters based on empirical models of laser interference. Our evaluation in emulated and real-world setups on 2 state-of-the-art recognition systems and 5 cameras reports a maximum success rate of 30% and 86.25% for Red-to-Green and Green-to-Red attacks. We observe that the attack is effective in continuous frames from more than 40 meters away against a moving vehicle, which may cause end-to-end impacts on self-driving such as running a red light or emergency stop. To mitigate the threat, we propose redesigning the rolling shutter mechanism.",
            "keywords": [
                "Traffic Light Recognition",
                "Adversarial Attacks",
                "Laser Interference",
                "Rolling Shutter Exploitation",
                "Autonomous Driving Safety"
            ]
        },
        "url": "URL#1417073",
        "sema_paperId": "b55986258a10114d3c5b0c1541942e5c6778a176"
    },
    {
        "@score": "1",
        "@id": "1417074",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "309/6323",
                        "text": "Sungbae Yoo"
                    },
                    {
                        "@pid": "231/1918",
                        "text": "Jinbum Park"
                    },
                    {
                        "@pid": "309/5909",
                        "text": "Seolheui Kim"
                    },
                    {
                        "@pid": "183/9947",
                        "text": "Yeji Kim"
                    },
                    {
                        "@pid": "38/8882",
                        "text": "Taesoo Kim"
                    }
                ]
            },
            "title": "In-Kernel Control-Flow Integrity on Commodity OSes using ARM Pointer Authentication.",
            "venue": "USENIX Security Symposium",
            "pages": "89-106",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YooPKKK22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/yoo",
            "url": "https://dblp.org/rec/conf/uss/YooPKKK22",
            "abstract": "This paper presents an in-kernel, hardware-based control-flow\nintegrity (CFI) protection, called PAL, that utilizes ARM's\nPointer Authentication (PA). It provides three important benefits\nover commercial, state-of-the-art PA-based CFIs like\niOS's: 1) enhancing CFI precision via automated refinement\ntechniques, 2) addressing hindsight problems of PA for inkernel\nuses such as preemptive hijacking and brute-forcing\nattacks, and 3) assuring the algorithmic or implementation\ncorrectness via post validation.\nPAL achieves these goals in an OS-agnostic manner, so\ncould be applied to commodity OSes like Linux and FreeBSD.\nThe precision of the CFI protection can be adjusted for better\nperformance or improved for better security with minimal engineering\nefforts. Our evaluation shows that PAL incurs negligible\nperformance overhead: e.g., <1% overhead for Apache\nbenchmark and 3\u20135% overhead for Linux perf benchmark on\nthe latest Mac mini (M1). Our post-validation approach helps\nus ensure the security invariant required for the safe uses of\nPA inside the kernel, which also reveals new attack vectors\non the iOS kernel. PAL as well as the CFI-protected kernels\nwill be open sourced.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-yoo.pdf",
            "keywords": [
                "Control-Flow Integrity",
                "Pointer Authentication",
                "In-Kernel Security",
                "Performance Overhead",
                "Post-Validation"
            ]
        },
        "url": "URL#1417074"
    },
    {
        "@score": "1",
        "@id": "1417075",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "69/5196",
                        "text": "Jeffrey Young"
                    },
                    {
                        "@pid": "271/4608",
                        "text": "Song Liao"
                    },
                    {
                        "@pid": "49/225-5",
                        "text": "Long Cheng 0005"
                    },
                    {
                        "@pid": "02/2870",
                        "text": "Hongxin Hu"
                    },
                    {
                        "@pid": "271/4533",
                        "text": "Huixing Deng"
                    }
                ]
            },
            "title": "SkillDetective: Automated Policy-Violation Detection of Voice Assistant Applications in the Wild.",
            "venue": "USENIX Security Symposium",
            "pages": "1113-1130",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YoungL0HD22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/young",
            "url": "https://dblp.org/rec/conf/uss/YoungL0HD22",
            "abstract": "Today\u2019s voice personal assistant (VPA) services have been largely expanded by allowing third-party developers to build voice-apps and publish them to marketplaces ( e.g. , the Amazon Alexa and Google Assistant platforms). In an effort to thwart unscrupulous developers, VPA platform providers have specifed a set of policy requirements to be adhered to by third-party developers, e.g. , personal data collection is not allowed for kid-directed voice-apps. In this work, we aim to identify policy-violating voice-apps in current VPA platforms through a comprehensive dynamic analysis of voice-apps. To this end, we design and develop S KILL D ETECTIVE , an interactive testing tool capable of exploring voice-apps\u2019 behaviors and identifying policy violations in an automated manner. Distinc-tive from prior works, S KILL D ETECTIVE evaluates voice-apps\u2019 conformity to 52 different policy requirements in a broader context from multiple sources including textual, image and audio fles. With S KILL D ETECTIVE , we tested 54,055 Amazon Alexa skills and 5,583 Google Assistant actions, and collected 518,385 textual outputs, approximately 2,070 unique audio fles and 31,100 unique images from voice-app interactions. We identifed 6,079 skills and 175 actions violating at least one policy requirement. We have reported our fndings to both VPA vendors, and received their acknowledgments.",
            "keywords": [
                "Voice Assistant Applications",
                "Policy Violation Detection",
                "Automated Testing",
                "Dynamic Analysis",
                "Third-Party Developer Compliance"
            ]
        },
        "url": "URL#1417075",
        "sema_paperId": "29f37586c1bdc4b976af2735811c244ab15a122f"
    },
    {
        "@score": "1",
        "@id": "1417076",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "23/7122-2",
                        "text": "Le Yu 0002"
                    },
                    {
                        "@pid": "14/3968",
                        "text": "Yangyang Liu"
                    },
                    {
                        "@pid": "226/7196",
                        "text": "Pengfei Jing"
                    },
                    {
                        "@pid": "53/1565",
                        "text": "Xiapu Luo"
                    },
                    {
                        "@pid": "68/2052-1",
                        "text": "Lei Xue 0001"
                    },
                    {
                        "@pid": "201/9069",
                        "text": "Kaifa Zhao"
                    },
                    {
                        "@pid": "15/7381",
                        "text": "Yajin Zhou"
                    },
                    {
                        "@pid": "12/2633-6",
                        "text": "Ting Wang 0006"
                    },
                    {
                        "@pid": "64/1147",
                        "text": "Guofei Gu"
                    },
                    {
                        "@pid": "50/8847",
                        "text": "Sen Nie"
                    },
                    {
                        "@pid": "49/10149",
                        "text": "Shi Wu"
                    }
                ]
            },
            "title": "Towards Automatically Reverse Engineering Vehicle Diagnostic Protocols.",
            "venue": "USENIX Security Symposium",
            "pages": "1939-1956",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YuLJL0ZZ0GNW22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/yu-le",
            "url": "https://dblp.org/rec/conf/uss/YuLJL0ZZ0GNW22",
            "abstract": "In-vehicle protocols are very important to the security assessment and protection of modern vehicles since they are used in communicating with, accessing, and even manipulating ECUs (Electronic Control Units) that control various vehicle components. Unfortunately, the majority of in-vehicle protocols are proprietary without publicly available documents. Although recent studies proposed methods to reverse engineer the CAN protocol used in the communication among ECUs, they cannot be applied to vehicle diagnostics protocols, which have been widely exploited by attackers to launch remote attacks. In this paper, we propose a novel framework for automatically reverse engineering the diagnostic protocols of vehicles by leveraging professional diagnostic tools. Speci\ufb01cally, we design and develop a new cyber-physical system that uses a set of algorithms to control a programmable robotics arm with the aid of cameras to automatically trigger and capture the messages of diagnostics protocols as well as reverse engineer their formats, semantic meanings, and proprietary formulas required for processing the response messages. We perform a large-scale experiment to evaluate our prototype using 18 real vehicles. It successfully reverse engineers 570 messages (446 for reading sensor values and 124 for controlling components). The experimental results show that our framework achieves high precision in reverse engineering proprietary formulas and obtains much more messages than the prior approach based on app analysis.",
            "keywords": [
                "Vehicle Diagnostic Protocols",
                "Reverse Engineering",
                "Cyber-Physical Systems",
                "Electronic Control Units (ECUs)",
                "Automated Message Capture"
            ]
        },
        "url": "URL#1417076",
        "sema_paperId": "5f94c6398201aedcc61c40727cca34f21f78d919"
    },
    {
        "@score": "1",
        "@id": "1417077",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "181/2830",
                        "text": "Sheng Yu"
                    },
                    {
                        "@pid": "70/7820",
                        "text": "Yu Qu"
                    },
                    {
                        "@pid": "148/1333",
                        "text": "Xunchao Hu"
                    },
                    {
                        "@pid": "77/6178-1",
                        "text": "Heng Yin 0001"
                    }
                ]
            },
            "title": "DeepDi: Learning a Relational Graph Convolutional Network Model on Instructions for Fast and Accurate Disassembly.",
            "venue": "USENIX Security Symposium",
            "pages": "2709-2725",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YuQHY22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/yu-sheng",
            "url": "https://dblp.org/rec/conf/uss/YuQHY22",
            "abstract": "Disassembly is the cornerstone of many binary analysis tasks. Traditional disassembly approaches (e.g., linear and recursive) are not accurate enough, while more sophisticated approaches (e.g., Probabilistic Disassembly, Datalog Disassembly, and XDA) have high overhead, which hinders them from being widely used in time-critical security practices. In this paper, we propose D EEP D I , a novel approach that achieves both accuracy and ef\ufb01ciency. The key idea of D EEP D I is to use a graph neural network model to capture and propagate instruction relations. Speci\ufb01cally, D EEP D I \ufb01rstly uses superset disassembly to get a superset of instructions. Then we construct a graph model called Instruction Flow Graph to capture different instruction relations. Then a Relational Graph Convolutional Network is used to propagate instruction embeddings for accurate instruction classi\ufb01cation. D EEP D I also provides heuristics to recover function entrypoints. We evaluate D EEP D I on several large-scale datasets containing real-world and obfuscated binaries. We show that D EEP D I is comparable or superior to the state-of-the-art disassemblers in terms of accuracy, and is robust against unseen binaries, compilers, platforms, obfuscated binaries, and adversarial attacks. Its CPU version is two times faster than IDA Pro, and its GPU version is 350 times faster.",
            "keywords": [
                "Binary Analysis",
                "Disassembly",
                "Graph Neural Networks",
                "Instruction Classification",
                "Instruction Flow Graph"
            ]
        },
        "url": "URL#1417077",
        "sema_paperId": "2ee09367fb6d2a81f69eab968d12e66df23319f3"
    },
    {
        "@score": "1",
        "@id": "1417078",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "276/6842",
                        "text": "Jason Zhijingcheng Yu"
                    },
                    {
                        "@pid": "136/8404",
                        "text": "Shweta Shinde"
                    },
                    {
                        "@pid": "37/10441",
                        "text": "Trevor E. Carlson"
                    },
                    {
                        "@pid": "90/105",
                        "text": "Prateek Saxena"
                    }
                ]
            },
            "title": "Elasticlave: An Efficient Memory Model for Enclaves.",
            "venue": "USENIX Security Symposium",
            "pages": "4111-4128",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YuSCS22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/yu-jason",
            "url": "https://dblp.org/rec/conf/uss/YuSCS22",
            "abstract": "Trusted execution environments (TEEs) isolate user-space applications into secure enclaves without trusting the OS. Existing TEE memory models are rigid &mdash; they do not allow an enclave to share memory with other enclaves. This lack of essential functionality breaks compatibility with several constructs such as shared memory, pipes, and fast mutexes that are frequently required in data intensive use-cases. In this work, we present Elasticlave, a new TEE memory model which allows sharing. Elasticlave strikes a balance between security and flexibility in managing access permissions. Our implementation of Elasticlave on RISC-V achieves performance overheads of about 10% compared to native (non-TEE) execution for data sharing workloads. In contrast, a similarly secure implementation on a rigid TEE design incurs 1-2 orders of magnitude overheads for these workloads. Thus, Elasticlave enables cross-enclave data sharing with much better performance.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-yu-jason.pdf",
            "keywords": [
                "Trusted Execution Environments",
                "Memory Model",
                "Cross-Enclave Communication",
                "Data Sharing",
                "Performance Overheads"
            ]
        },
        "url": "URL#1417078"
    },
    {
        "@score": "1",
        "@id": "1417079",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "150/3870",
                        "text": "Xiaoyong Yuan"
                    },
                    {
                        "@pid": "54/2752-5",
                        "text": "Lan Zhang 0005"
                    }
                ]
            },
            "title": "Membership Inference Attacks and Defenses in Neural Network Pruning.",
            "venue": "USENIX Security Symposium",
            "pages": "4561-4578",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Yuan022",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/yuan-xiaoyong",
            "url": "https://dblp.org/rec/conf/uss/Yuan022",
            "abstract": "Neural network pruning has been an essential technique to reduce the computation and memory requirements for using deep neural networks for resource-constrained devices. Most existing research focuses primarily on balancing the sparsity and accuracy of a pruned neural network by strategically removing insignificant parameters and retraining the pruned model. Such efforts on reusing training samples pose serious privacy risks due to increased memorization, which, however, has not been investigated yet. In this paper, we conduct the first analysis of privacy risks in neural network pruning. Specifically, we investigate the impacts of neural network pruning on training data privacy, i.e., membership inference attacks. We first explore the impact of neural network pruning on prediction divergence, where the pruning process disproportionately affects the pruned model's behavior for members and non-members. Meanwhile, the influence of divergence even varies among different classes in a fine-grained manner. Enlighten by such divergence, we proposed a self-attention membership inference attack against the pruned neural networks. Extensive experiments are conducted to rigorously evaluate the privacy impacts of different pruning approaches, sparsity levels, and adversary knowledge. The proposed attack shows the higher attack performance on the pruned models when compared with eight existing membership inference attacks. In addition, we propose a new defense mechanism to protect the pruning process by mitigating the prediction divergence based on KL-divergence distance, whose effectiveness has been experimentally demonstrated to effectively mitigate the privacy risks while maintaining the sparsity and accuracy of the pruned models.",
            "keywords": [
                "Neural Network Pruning",
                "Privacy Risks",
                "Membership Inference Attacks",
                "Prediction Divergence",
                "Defense Mechanism"
            ]
        },
        "url": "URL#1417079",
        "sema_paperId": "633b3435b4ddd48bf8430a0d9e4872572f6a18f2"
    },
    {
        "@score": "1",
        "@id": "1417080",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "295/5277",
                        "text": "Yuanyuan Yuan"
                    },
                    {
                        "@pid": "44/8421",
                        "text": "Qi Pang"
                    },
                    {
                        "@pid": "42/1503-11",
                        "text": "Shuai Wang 0011"
                    }
                ]
            },
            "title": "Automated Side Channel Analysis of Media Software with Manifold Learning.",
            "venue": "USENIX Security Symposium",
            "pages": "4419-4436",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YuanP022",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/yuan-yuanyuan",
            "url": "https://dblp.org/rec/conf/uss/YuanP022",
            "abstract": "The prosperous development of cloud computing and machine learning as a service has led to the widespread use of media software to process confidential media data. This paper explores an adversary's ability to launch side channel analyses (SCA) against media software to reconstruct confidential media inputs. Recent advances in representation learning and perceptual learning inspired us to consider the reconstruction of media inputs from side channel traces as a cross-modality manifold learning task that can be addressed in a unified manner with an autoencoder framework trained to learn the mapping between media inputs and side channel observations. We further enhance the autoencoder with attention to localize the program points that make the primary contribution to SCA, thus automatically pinpointing information-leakage points in media software. We also propose a novel and highly effective defensive technique called perception blinding that can perturb media inputs with perception masks and mitigate manifold learning-based SCA. Our evaluation exploits three popular media software to reconstruct inputs in image, audio, and text formats. We analyze three common side channels - cache bank, cache line, and page tables - and userspace-only cache set accesses logged by standard Prime+Probe. Our framework successfully reconstructs high-quality confidential inputs from the assessed media software and automatically pinpoint their vulnerable program points, many of which are unknown to the public. We further show that perception blinding can mitigate manifold learning-based SCA with negligible extra cost.",
            "keywords": [
                "Side Channel Analysis",
                "Media Software",
                "Manifold Learning",
                "Information Leakage",
                "Perception Blinding"
            ]
        },
        "url": "URL#1417080",
        "sema_paperId": "68302f06fc4f8f328b6c6b12b6328086eab4b7c4"
    },
    {
        "@score": "1",
        "@id": "1417081",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "216/6671",
                        "text": "Mojtaba Zaheri"
                    },
                    {
                        "@pid": "69/39",
                        "text": "Yossi Oren"
                    },
                    {
                        "@pid": "c/RezaCurtmola",
                        "text": "Reza Curtmola"
                    }
                ]
            },
            "title": "Targeted Deanonymization via the Cache Side Channel: Attacks and Defenses.",
            "venue": "USENIX Security Symposium",
            "pages": "1505-1523",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZaheriOC22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/zaheri",
            "url": "https://dblp.org/rec/conf/uss/ZaheriOC22",
            "abstract": "Targeted deanonymization attacks let a malicious website discover whether a website visitor bears a certain public identi\ufb01er, such as an email address or a Twitter handle. These attacks were previously considered to rely on several assumptions, limiting their practical impact. In this work, we challenge these assumptions and show the attack surface for deanonymization attacks is drastically larger than previously considered. We achieve this by using the cache side channel for our attack, instead of relying on cross-site leaks. This makes our attack oblivious to recently proposed software-based isolation mechanisms, including cross-origin resource policies (CORP), cross-origin opener policies (COOP) and SameSite cookie attribute. We evaluate our attacks on multiple hardware microarchitectures, multiple operating systems and multiple browser versions, including the highly-secure Tor Browser, and demonstrate practical targeted deanonymization attacks on major sites, including Google, Twitter, LinkedIn, TikTok, Facebook, Instagram and Reddit. Our attack runs in less than 3 seconds in most cases, and can be scaled to target an exponentially large amount of users. To stop these attacks, we present a full-featured defense deployed as a browser extension. To minimize the risk to vulnerable individuals, our defense is already available on the Chrome and Firefox app stores. We have also responsibly disclosed our \ufb01ndings to multiple tech vendors, as well as to the Electronic Frontier Foundation. Finally, we provide guidance to websites and browser vendors, as well as to users who cannot install the extension.",
            "keywords": [
                "Deanonymization Attacks",
                "Cache Side Channel",
                "Privacy Vulnerabilities",
                "Web Tracking",
                "Browser Defense Mechanisms"
            ]
        },
        "url": "URL#1417081",
        "sema_paperId": "fb5467f727d447d2a2dc66dc746b93b0c831ea4a"
    },
    {
        "@score": "1",
        "@id": "1417083",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "270/2413",
                        "text": "Kyle Zeng"
                    },
                    {
                        "@pid": "16/6884-1",
                        "text": "Yueqi Chen 0001"
                    },
                    {
                        "@pid": "164/2543",
                        "text": "Haehyun Cho"
                    },
                    {
                        "@pid": "40/6431",
                        "text": "Xinyu Xing"
                    },
                    {
                        "@pid": "28/8280",
                        "text": "Adam Doup\u00e9"
                    },
                    {
                        "@pid": "119/7712",
                        "text": "Yan Shoshitaishvili"
                    },
                    {
                        "@pid": "150/5198",
                        "text": "Tiffany Bao"
                    }
                ]
            },
            "title": "Playing for K(H)eaps: Understanding and Improving Linux Kernel Exploit Reliability.",
            "venue": "USENIX Security Symposium",
            "pages": "71-88",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZengCCXDSB22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/zeng",
            "url": "https://dblp.org/rec/conf/uss/ZengCCXDSB22",
            "abstract": "The dynamic of the Linux kernel heap layout signi\ufb01cantly impacts the reliability of kernel heap exploits, making ex-ploitability assessment challenging. Though techniques have been proposed to stabilize exploits in the past, little scienti\ufb01c research has been conducted to evaluate their effectiveness and explore their working conditions. In this paper, we present a systematic study of the kernel heap exploit reliability problem. We \ufb01rst interview kernel security experts, gathering commonly adopted exploitation stabilization techniques and expert opinions about these techniques. We then evaluate these stabilization techniques on 17 real-world kernel heap exploits. The results indicate that many kernel security experts have incorrect opinions on exploitation stabilization techniques. To help the security community better understand exploitation stabilization, we inspect our experiment results and design a generic kernel heap exploit model. We use the proposed exploit model to interpret the exploitation unreliability issue and analyze why stabilization techniques succeed or fail. We also leverage the model to propose a new exploitation technique. Our experiment indicates that the new stabilization technique improves Linux kernel exploit reliability by 14.87% on average. Combining this newly proposed technique with existing stabilization approaches produces a composite stabilization method that achieves a 135.53% exploitation reliability improvement on average, outperforming exploit stabilization by professional security researchers by 36.07%.",
            "keywords": [
                "Linux Kernel Exploits",
                "Heap Exploit Reliability",
                "Exploitation Stabilization Techniques",
                "Kernel Security Assessment",
                "Exploit Model"
            ]
        },
        "url": "URL#1417083",
        "sema_paperId": "738d9bccf9f8418fba591e68301f960cc658de0b"
    },
    {
        "@score": "1",
        "@id": "1417084",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "297/3112",
                        "text": "Zenong Zhang"
                    },
                    {
                        "@pid": "318/5093",
                        "text": "Zach Patterson"
                    },
                    {
                        "@pid": "h/MichaelWHicks",
                        "text": "Michael Hicks 0001"
                    },
                    {
                        "@pid": "120/0117",
                        "text": "Shiyi Wei"
                    }
                ]
            },
            "title": "FIXREVERTER: A Realistic Bug Injection Methodology for Benchmarking Fuzz Testing.",
            "venue": "USENIX Security Symposium",
            "pages": "3699-3715",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhangP0W22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/zhang-zenong",
            "url": "https://dblp.org/rec/conf/uss/ZhangP0W22",
            "abstract": "Fuzz testing is an active area of research with proposed improvements published at a rapid pace. Such proposals are assessed empirically : Can they be shown to perform better than the status quo? Such an assessment requires a benchmark of target programs with well-identi\ufb01ed, realistic bugs. To ease the construction of such a benchmark, this paper presents F IX R EVERTER , a tool that automatically injects realistic bugs in a program. F IX R EVERTER takes as input a bug\ufb01x pattern which contains both code syntax and semantic conditions. Any code site that matches the speci\ufb01ed syntax is undone if the semantic conditions are satis\ufb01ed, as checked by static analysis, thus (re)introducing a likely bug. This paper focuses on three bug\ufb01x patterns, which we call conditional-abort , conditional-execute , and conditional-assign , based on a study of \ufb01xes in a corpus of Common Vulnerabilities and Exposures (CVEs). Using F IX R EVERTER we have built R EV B UG B ENCH , which consists of 10 programs into which we have injected nearly 8,000 bugs; the programs are taken from FuzzBench and Binutils, and represent common targets of fuzzing evaluations. We have integrated R EV B UG B ENCH into the FuzzBench service, and used it to evaluate \ufb01ve fuzzers. Fuzzing performance varies by fuzzer and program, as de-sired/expected. Overall, 219 unique bugs were reported, 19% of which were detected by just one fuzzer.",
            "keywords": [
                "Fuzz Testing",
                "Bug Injection",
                "Benchmarking",
                "Realistic Bugs",
                "FuzzBench"
            ]
        },
        "url": "URL#1417084",
        "sema_paperId": "a2b87179dcea5dad26e6e3d17640c689eabc2940"
    },
    {
        "@score": "1",
        "@id": "1417085",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "09/5661-6",
                        "text": "Yuchen Zhang 0006"
                    },
                    {
                        "@pid": "223/6697",
                        "text": "Chengbin Pang"
                    },
                    {
                        "@pid": "44/3319",
                        "text": "Georgios Portokalidis"
                    },
                    {
                        "@pid": "29/4200",
                        "text": "Nikos Triandopoulos"
                    },
                    {
                        "@pid": "90/514-24",
                        "text": "Jun Xu 0024"
                    }
                ]
            },
            "title": "Debloating Address Sanitizer.",
            "venue": "USENIX Security Symposium",
            "pages": "4345-4363",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhangPPT022",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/zhang-yuchen",
            "url": "https://dblp.org/rec/conf/uss/ZhangPPT022",
            "abstract": "Address Sanitizer (ASan) is a powerful memory error detector. It can detect various errors ranging from spatial issues like out-of-bound accesses to temporal issues like use-after-free. However, ASan has the major drawback of high runtime overhead. With every functionality enabled, ASan incurs an overhead of more than 1x.This paper first presents a study to dissect the operations of ASan and inspects the primary sources of its runtime overhead. The study unveils (or confirms) that the high overhead is mainly caused by the extensive sanitizer checks on memory accesses. Inspired by the study, the paper proposes ASan--, a tool assembling a group of optimizations to reduce (or \"debloat\") sanitizer checks and improve ASan's efficiency. Unlike existing tools that remove sanitizer checks with harm to the capability, scalability, or usability of ASan, ASan-- fully maintains those decent properties of ASan.Our evaluation shows that ASan-- presents high promise. It reduces the overhead of ASan by 41.7% on SPEC CPU2006 and by 35.7% on Chromium. If only considering the overhead incurred by sanitizer checks, the reduction rates increase to 51.6% on SPEC CPU2006 and 69.6% on Chromium. In the context of fuzzing, ASan-- increases the execution speed of AFL by over 40% and the branch coverage by 5%. Combined with orthogonal, fuzzing-tailored optimizations, ASan-- can speed up AFL by 60% and increase the branch coverage by 9%. Running in Chromium to support our daily work for four weeks, ASan-- did not present major usability issues or significant slowdown and it detected all the bugs we reproduced from previous reports.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-zhang-yuchen.pdf",
            "keywords": [
                "Memory Error Detection",
                "Address Sanitizer",
                "Runtime Overhead",
                "Sanitizer Checks",
                "Debloating"
            ]
        },
        "url": "URL#1417085"
    },
    {
        "@score": "1",
        "@id": "1417086",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "203/8611",
                        "text": "Jiaheng Zhang"
                    },
                    {
                        "@pid": "216/6422",
                        "text": "Tiancheng Xie"
                    },
                    {
                        "@pid": "132/2690",
                        "text": "Thang Hoang"
                    },
                    {
                        "@pid": "80/4580",
                        "text": "Elaine Shi"
                    },
                    {
                        "@pid": "82/4816-1",
                        "text": "Yupeng Zhang 0001"
                    }
                ]
            },
            "title": "Polynomial Commitment with a One-to-Many Prover and Applications.",
            "venue": "USENIX Security Symposium",
            "pages": "2965-2982",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhangXHSZ22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/zhang-jiaheng",
            "url": "https://dblp.org/rec/conf/uss/ZhangXHSZ22",
            "abstract": "Veri\ufb01able Secret Sharing (VSS) is a foundational cryptographic primitive that serves as an essential building block in multi-party computation and decentralized blockchain applications. One of the most practical ways to construct VSS is through a polynomial commitment, where the dealer commits to a random polynomial whose 0-th coef\ufb01cient encodes the secret to be shared, and proves the evaluation of the committed polynomial at a different point to each of N veri\ufb01ers, i.e., the polynomial commitment is used in a \u201cone-to-many\u201d fashion. The recent work of Tomescu et al. (IEEE S&P 2020) was the \ufb01rst to consider polynomial commitment with \u201cone-to-many prover batching\u201d, such that the prover can prove evaluations at N different points at the cost of (cid:101) O ( 1 ) proofs. However, their scheme is not optimal and requires a trusted setup. In this paper, we asymptotically improve polynomial commitment with one-to-many prover batching. We propose two novel schemes. First, we propose a scheme with optimal asymptotics in all dimensions in the trusted setup setting. Second, we are the \ufb01rst to consider one-to-many prover batching for transparent polynomial commitments, and we propose a transparent scheme whose performance approximately matches the best-known scheme in the trusted setup setting. We implement our schemes and evaluate their performance. Our scheme in the trusted setup setting improves the proof size by 20 \u00d7 and the veri\ufb01er time by 7 . 8 \u00d7 for 2 21 parties, with a small overhead on the prover time. Our transparent polynomial commitment removes the trusted setup and further improves the prover time by 2 . 3 \u00d7 .",
            "keywords": [
                "Polynomial Commitment",
                "Verifiable Secret Sharing",
                "One-to-Many Prover",
                "Trusted Setup",
                "Transparent Scheme"
            ]
        },
        "url": "URL#1417086",
        "sema_paperId": "0313e5467d03c77df53fc7ea82b749a084333eee"
    },
    {
        "@score": "1",
        "@id": "1417087",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "278/7106",
                        "text": "Zirui Neil Zhao"
                    },
                    {
                        "@pid": "40/944",
                        "text": "Adam Morrison 0001"
                    },
                    {
                        "@pid": "25/8166",
                        "text": "Christopher W. Fletcher"
                    },
                    {
                        "@pid": "t/JosepTorrellas",
                        "text": "Josep Torrellas"
                    }
                ]
            },
            "title": "Binoculars: Contention-Based Side-Channel Attacks Exploiting the Page Walker.",
            "venue": "USENIX Security Symposium",
            "pages": "699-716",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Zhao0FT22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/zhao-zirui",
            "url": "https://dblp.org/rec/conf/uss/Zhao0FT22",
            "abstract": "Microarchitectural side channels are a pressing security threat. These channels are created when programs modulate hardware resources in a secret data-dependent fashion. They are broadly classified as being either stateful or stateless (also known as contention-based), depending on whether they leave behind a trace for attackers to later observe. Common wisdom suggests that stateful channels are significantly easier to monitor than stateless ones, and hence have received the most attention. In this paper, we present a novel stateless attack that shows this common wisdom is not always true. Our attack, called Binoculars , exploits unexplored interactions between in-flight page walk operations and other memory operations. Unlike other stateless channels, Binoculars creates significant timing perturbations\u2014up to 20,000 cycles stemming from a single dynamic instruction\u2014making it easy to monitor. We show how these perturbations are address dependent, enabling Binoculars to leak more virtual address bits in victim memory operations than any prior channel. Binoculars needs no shared memory between the attacker and the victim. Using Binoculars, we design both covert-and side-channel attacks. Our covert channel achieves a high capacity of 1116 KB/s on a Cascade Lake-X machine. We then design a side-channel attack that steals keys from OpenSSL\u2019s side-channel resistant ECDSA by learning the ECDSA nonce k . Binoculars\u2019 ability to significantly amplify subtle behaviors, e.g., orderings of stores, is crucial for this attack to succeed because the nonce changes after each run. Finally, we fully break kernel ASLR.",
            "keywords": [
                "Microarchitectural Side Channels",
                "Contention-Based Attacks",
                "Page Walk Exploitation",
                "Covert Channels",
                "Side-Channel Attacks"
            ]
        },
        "url": "URL#1417087",
        "sema_paperId": "f2e659860930d57b0424f18835fa8df92fe5921c"
    },
    {
        "@score": "1",
        "@id": "1417088",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "237/1416",
                        "text": "Bodong Zhao"
                    },
                    {
                        "@pid": "62/7776",
                        "text": "Zheming Li"
                    },
                    {
                        "@pid": "297/2374",
                        "text": "Shisong Qin"
                    },
                    {
                        "@pid": "249/4978",
                        "text": "Zheyu Ma"
                    },
                    {
                        "@pid": "37/449-3",
                        "text": "Ming Yuan 0003"
                    },
                    {
                        "@pid": "57/1228",
                        "text": "Wenyu Zhu"
                    },
                    {
                        "@pid": "73/5444",
                        "text": "Zhihong Tian"
                    },
                    {
                        "@pid": "94/3019-8",
                        "text": "Chao Zhang 0008"
                    }
                ]
            },
            "title": "StateFuzz: System Call-Based State-Aware Linux Driver Fuzzing.",
            "venue": "USENIX Security Symposium",
            "pages": "3273-3289",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhaoLQMYZT022",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/zhao-bodong",
            "url": "https://dblp.org/rec/conf/uss/ZhaoLQMYZT022",
            "abstract": "Coverage-guided fuzzing has achieved great success in finding software vulnerabilities. Existing coverage-guided fuzzers generally favor test cases that hit new code, and discard ones that exercise the same code. However, such a strategy is not optimum. A new test case exercising the same code could be better than a previous test case, as it may trigger new program states useful for code exploration and bug discovery.In this paper, we assessed the limitation of coverage-guided fuzzing solutions and proposed a state-aware fuzzing solution StateFuzz to address this issue. First, we model program states with values of state-variables and utilize static analysis to recognize such variables. Then, we instrument target programs to track such variables' values and infer program state transition at runtime. Lastly, we utilize state information to prioritize test cases that can trigger new states, and apply a three-dimension feedback mechanism to fine-tune the evolutionary direction of coverage-guided fuzzers. We have implemented a prototype of StateFuzz, and evaluated it on Linux upstream drivers and Android drivers. Evaluation results show that StateFuzz is effective at discovering both new code and vulnerabilities. It finds 18 unknown vulnerabilities and 2 known but unpatched vulnerabilities, and reaches 19% higher code coverage and 32% higher state coverage than the state-of-the-art fuzzer Syzkaller.",
            "pdf_url": "https://www.usenix.org/system/files/sec22-zhao-bodong.pdf",
            "keywords": [
                "Linux Driver Fuzzing",
                "Coverage-Guided Fuzzing",
                "State-Aware Fuzzing",
                "Program State Transition",
                "Vulnerability Discovery"
            ]
        },
        "url": "URL#1417088",
        "sema_paperId": "aaeb7c50cf1e34eb92c3271234574e4f0ef3db00"
    },
    {
        "@score": "1",
        "@id": "1417089",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "167/0431",
                        "text": "Shunfan Zhou"
                    },
                    {
                        "@pid": "55/11040",
                        "text": "Zhemin Yang"
                    },
                    {
                        "@pid": "152/4915",
                        "text": "Dan Qiao"
                    },
                    {
                        "@pid": "21/6121-5",
                        "text": "Peng Liu 0005"
                    },
                    {
                        "@pid": "02/1640-2",
                        "text": "Min Yang 0002"
                    },
                    {
                        "@pid": "75/3158-17",
                        "text": "Zhe Wang 0017"
                    },
                    {
                        "@pid": "51/3529-2",
                        "text": "Chenggang Wu 0002"
                    }
                ]
            },
            "title": "Ferry: State-Aware Symbolic Execution for Exploring State-Dependent Program Paths.",
            "venue": "USENIX Security Symposium",
            "pages": "4365-4382",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhouYQ000022",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/zhou-shunfan",
            "url": "https://dblp.org/rec/conf/uss/ZhouYQ000022",
            "abstract": "Symbolic execution and fuzz testing are effective approaches for program analysis, thanks to their evolving path exploration approaches. The state-of-the-art symbolic execution and fuzzing techniques are able to generate valid program inputs to satisfy the conditional statements. However, they have very limited ability to explore the finite-state-machine models implemented by real-world programs. This is because such state machines contain program-state-dependent branches ( state-dependent branches in this paper) which depend on earlier program execution instead of the current program inputs. explore state-dependent branches. state-dependent in their arbitrary state-dependent branches a of dependency between current program and inputs in class of important programs. Ferry , symbolic execution engine by recognizing program exploring state-dependent different programs the comprehensive dataset Google higher and branch",
            "keywords": [
                "Symbolic Execution",
                "Fuzz Testing",
                "State-Dependent Branches",
                "Program Analysis",
                "Finite-State Machines"
            ]
        },
        "url": "URL#1417089",
        "sema_paperId": "1fc3df1a05e5794f07a3611e9d769d5def5f9781"
    },
    {
        "@score": "1",
        "@id": "1417090",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "184/9445",
                        "text": "Ce Zhou"
                    },
                    {
                        "@pid": "86/10809",
                        "text": "Qiben Yan"
                    },
                    {
                        "@pid": "67/2601",
                        "text": "Yan Shi"
                    },
                    {
                        "@pid": "121/0780-1",
                        "text": "Lichao Sun 0001"
                    }
                ]
            },
            "title": "DoubleStar: Long-Range Attack Towards Depth Estimation based Obstacle Avoidance in Autonomous Systems.",
            "venue": "USENIX Security Symposium",
            "pages": "1885-1902",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhouYSS22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/zhou-ce",
            "url": "https://dblp.org/rec/conf/uss/ZhouYSS22",
            "abstract": "Depth estimation-based obstacle avoidance has been widely adopted by autonomous systems (drones and vehicles) for safety purpose. It normally relies on a stereo camera to automatically detect obstacles and make flying/driving decisions, e.g., stopping several meters ahead of the obstacle in the path or moving away from the detected obstacle. In this paper, we explore new security risks associated with the stereo vision-based depth estimation algorithms used for obstacle avoidance. By exploiting the weaknesses of the stereo matching in depth estimation algorithms and the lens flare effect in optical imaging, we propose DoubleStar, a long-range attack that injects fake obstacle depth by projecting pure light from two complementary light sources. DoubleStar includes two distinctive attack formats: beams attack and orbs attack, which leverage projected light beams and lens flare orbs respectively to cause false depth perception. We successfully attack two commercial stereo cameras designed for autonomous systems (ZED and Intel RealSense). The visualization of fake depth perceived by the stereo cameras illustrates the false stereo matching induced by DoubleStar. We further use Ardupilot to simulate the attack and demonstrate its impact on drones. To validate the attack on real systems, we perform a real-world attack towards a commercial drone equipped with state-of-the-art obstacle avoidance algorithms. Our attack can continuously bring a flying drone to a sudden stop or drift it away across a long distance under various lighting conditions, even bypassing sensor fusion mechanisms. Specifically, our experimental results show that DoubleStar creates fake depth up to 15 meters in distance at night and up to 8 meters during the daytime. To mitigate this newly discovered threat, we provide discussions on potential countermeasures to defend against DoubleStar.",
            "keywords": [
                "Depth Estimation",
                "Obstacle Avoidance",
                "Stereo Vision",
                "Long-Range Attack",
                "Fake Depth Perception"
            ]
        },
        "url": "URL#1417090",
        "sema_paperId": "76f759c5fb7c9b5cb0e34b319f53d5f9b9a94d3f"
    },
    {
        "@score": "1",
        "@id": "1417091",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "210/0533",
                        "text": "Xiaochen Zou"
                    },
                    {
                        "@pid": "272/7041",
                        "text": "Guoren Li"
                    },
                    {
                        "@pid": "224/9379",
                        "text": "Weiteng Chen"
                    },
                    {
                        "@pid": "49/6156-12",
                        "text": "Hang Zhang 0012"
                    },
                    {
                        "@pid": "31/8302",
                        "text": "Zhiyun Qian"
                    }
                ]
            },
            "title": "SyzScope: Revealing High-Risk Security Impacts of Fuzzer-Exposed Bugs in Linux kernel.",
            "venue": "USENIX Security Symposium",
            "pages": "3201-3217",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZouLCZQ22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/zou",
            "url": "https://dblp.org/rec/conf/uss/ZouLCZQ22",
            "abstract": "Fuzzing has become one of the most effective bug finding approach for software. In recent years, 24*7 continuous fuzzing platforms have emerged to test critical pieces of software, e.g., Linux kernel. Though capable of discovering many bugs and providing reproducers (e.g., proof-of-concepts), a major problem is that they neglect a critical function that should have been built-in, i.e., evaluation of a bug's security impact. It is well-known that the lack of understanding of security impact can lead to delayed bug fixes as well as patch propagation. In this paper, we develop SyzScope, a system that can automatically uncover new\"high-risk\"impacts given a bug with seemingly\"low-risk\"impacts. From analyzing over a thousand low-risk bugs on syzbot, SyzScope successfully determined that 183 low-risk bugs (more than 15%) in fact contain high-risk impacts, e.g., control flow hijack and arbitrary memory write, some of which still do not have patches available yet.",
            "keywords": [
                "Linux Kernel Security",
                "Fuzzing",
                "Bug Impact Evaluation",
                "High-Risk Vulnerabilities",
                "SyzScope"
            ]
        },
        "url": "URL#1417091",
        "sema_paperId": "c057a7dde1d3956491123c443ad7f90f9ee2a5b7"
    },
    {
        "@score": "1",
        "@id": "1417092",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "149/8302",
                        "text": "Chaoshun Zuo"
                    },
                    {
                        "@pid": "49/4102-1",
                        "text": "Zhiqiang Lin 0001"
                    }
                ]
            },
            "title": "Playing Without Paying: Detecting Vulnerable Payment Verification in Native Binaries of Unity Mobile Games.",
            "venue": "USENIX Security Symposium",
            "pages": "3093-3110",
            "year": "2022",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZuoL22",
            "ee": "https://www.usenix.org/conference/usenixsecurity22/presentation/zuo",
            "url": "https://dblp.org/rec/conf/uss/ZuoL22",
            "abstract": "Modern mobile games often contain in-app purchasing (IAP) for players to purchase digital items such as virtual currency, equipment, or extra moves. In theory, IAP should have been implemented securely; but in practice, we have found that many game developers have failed to do so, particularly by misplacing the trust of payment veri\ufb01cation, e.g. , by either locally verifying the payment transactions or without using any veri\ufb01cation at all, leading to playing without paying vulnerabilities. This paper presents P AYMENT S COPE , a static binary analysis tool to automatically identify vulnerable IAP implementations in mobile games. Through modeling of its IAP protocols with the SDK provided APIs using a payment-aware data \ufb02ow analysis, P AYMENT S COPE directly pinpoints untrusted payment veri\ufb01cation vulnerabilities in game native binaries. We have implemented P AYMENT S COPE on top of binary analysis framework Ghidra, and tested with 39 , 121 Unity (the most popular game engine) mobile games, with which P AYMENT S COPE has identi\ufb01ed 8 , 954 (22 . 89%) vulnerable games. Among them, 8 , 233 games do not verify the validity of payment transactions and 721 games simply verify the transactions locally. We have disclosed the identi\ufb01ed vulnerabilities to developers of vulnerable games, and many of them have acknowledged our \ufb01ndings.",
            "keywords": [
                "Mobile Game Security",
                "In-App Purchasing (IAP)",
                "Payment Verification",
                "Vulnerabilities Detection",
                "Static Binary Analysis"
            ]
        },
        "url": "URL#1417092",
        "sema_paperId": "c48603847f82f394ed51ff938b8680f3dc8b6c3a"
    },
    {
        "@score": "1",
        "@id": "1430062",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "82/1935",
                        "text": "Kevin R. B. Butler"
                    },
                    {
                        "@pid": "68/8283",
                        "text": "Kurt Thomas"
                    }
                ]
            },
            "title": "31st USENIX Security Symposium, USENIX Security 2022, Boston, MA, USA, August 10-12, 2022",
            "venue": "USENIX Security Symposium",
            "publisher": "USENIX Association",
            "year": "2022",
            "type": "Editorship",
            "access": "open",
            "key": "conf/uss/2022",
            "ee": "https://www.usenix.org/conference/usenixsecurity22",
            "url": "https://dblp.org/rec/conf/uss/2022",
            "abstract": null
        },
        "url": "URL#1430062",
        "sema_paperId": "1e648c7ab0911fe9f2fbf137a08b9dded5e9773b"
    }
]