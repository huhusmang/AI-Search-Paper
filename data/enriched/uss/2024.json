[
    {
        "@score": "1",
        "@id": "379371",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "81/8013-1",
                        "text": "Penghui Li 0001"
                    },
                    {
                        "@pid": "05/3920-1",
                        "text": "Wei Meng 0001"
                    },
                    {
                        "@pid": "94/3019-8",
                        "text": "Chao Zhang 0008"
                    }
                ]
            },
            "title": "SDFuzz: Target States Driven Directed Fuzzing.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/00010024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/li-penghui",
            "url": "https://dblp.org/rec/conf/uss/00010024",
            "abstract": "Directed fuzzers often unnecessarily explore program code and paths that cannot trigger the target vulnerabilities. We observe that the major application scenarios of directed fuzzing provide detailed vulnerability descriptions, from which highly-valuable program states ( i.e. , target states) can be derived, e.g. , call traces when a vulnerability gets triggered. By driving to expose such target states, directed fuzzers can exclude massive unnecessary exploration. Inspired by the observation, we present SDF UZZ , an efficient directed fuzzing tool driven by target states. SDF UZZ first automatically extracts target states in vulnerability reports and static analysis results. SDF UZZ employs a selective instrumentation technique to reduce the fuzzing scope to the required code for reaching target states. SDF UZZ then early terminates the execution of a test case once SDF UZZ probes that the remaining execution cannot reach the target states. It further uses a new target state feedback and refines prior imprecise distance metric into a two-dimensional feedback mechanism to proactively drive the exploration towards the target states. We thoroughly evaluated SDF UZZ on known vulnerabilities and compared it to related works. The results show that SDF UZZ could improve vulnerability exposure capability with more vulnerability triggered and less time used, outper-forming the state-of-the-art solutions. SDF UZZ could significantly improve the fuzzing throughput. Our application of SDF UZZ to automatically validate the static analysis results successfully discovered four new vulnerabilities in well-tested applications. Three of them have been acknowledged by developers.",
            "keywords": [
                "Directed Fuzzing",
                "Vulnerability Detection",
                "Target States",
                "Selective Instrumentation",
                "Fuzzing Throughput"
            ]
        },
        "url": "URL#379371",
        "sema_paperId": "3054cdb3746029f3e41d17e30b3dc6133238dcf8"
    },
    {
        "@score": "1",
        "@id": "379372",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "301/5809",
                        "text": "Eric Olsson 0001"
                    },
                    {
                        "@pid": "242/3200",
                        "text": "Benjamin Eriksson"
                    },
                    {
                        "@pid": "28/8280",
                        "text": "Adam Doup\u00e9"
                    },
                    {
                        "@pid": "s/AndreiSabelfeld",
                        "text": "Andrei Sabelfeld"
                    }
                ]
            },
            "title": "Spider-Scents: Grey-box Database-aware Web Scanning for Stored XSS.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0001EDS24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/olsson",
            "url": "https://dblp.org/rec/conf/uss/0001EDS24",
            "abstract": "As web applications play an ever more important role in society, so does ensuring their security. A large threat to web application security is XSS vulnerabilities, and in particular, stored XSS. Due to the complexity of web applications and the dif\ufb01culty of properly injecting XSS payloads into a web application, many of these vulnerabilities still evade current state-of-the-art scanners. We approach this problem from a new direction\u2014by injecting XSS payloads directly into the database we can completely bypass the dif\ufb01culty of injecting XSS payloads into a web application. We thus propose Spider-Scents, a novel method for grey-box database-aware scanning for stored XSS, that maps database values to the web application and automatically \ufb01nds unprotected outputs. Spider-Scents reveals code smells that expose stored XSS vulnerabilities. We evaluate our approach on a set of 12 web applications and compare with three state-of-the-art black-box scanners. We demonstrate improvement of database coverage, ranging from 79% to 100% database coverage across the applications compared to the range of 2% to 60% for the other scanners. We systematize the relationship between unprotected outputs, vulnerabilities, and exploits in the context of stored XSS. We manually analyze unprotected outputs reported by Spider-Scents to determine their vulnerability and exploitability. In total, this method \ufb01nds 85 stored XSS vulnerabilities, outperforming the union of state-of-the-art\u2019s 32.",
            "keywords": [
                "Stored XSS",
                "Web Application Vulnerabilities",
                "Database-aware Scanning",
                "Grey-box Testing",
                "Unprotected Outputs"
            ]
        },
        "url": "URL#379372",
        "sema_paperId": "f802abc0d1fd813d8d465c9ebf109b2cc1b99eda"
    },
    {
        "@score": "1",
        "@id": "379373",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "75/5483-1",
                        "text": "Yibin Yang 0001"
                    },
                    {
                        "@pid": "19/72",
                        "text": "David Heath"
                    }
                ]
            },
            "title": "Two Shuffles Make a RAM: Improved Constant Overhead Zero Knowledge RAM.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0001H24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/yang-yibin",
            "url": "https://dblp.org/rec/conf/uss/0001H24",
            "abstract": "We optimize Zero Knowledge (ZK) proofs of statements expressed as RAM programs over arithmetic values. Our arithmetic-circuit-based read/write memory uses only 4 input gates and 6 multiplication gates per memory access. This is an almost 3\u00d7 total gate improvement over prior state of the art (Delpech de Saint Guilhem et al., SCN'22).We implemented our memory in the context of ZK proofs based on vector oblivious linear evaluation (VOLE), and we further optimized based on techniques available in the VOLE setting. Our experiments show that (1) our total runtime improves over that of the prior best VOLE-ZK RAM (Franzese et al., CCS'21) by 2-20\u00d7 and (2) on a typical hardware setup, we can achieve \u2248 600K RAM accesses per second.We also develop improved read-only memory and set ZK data structures. These are used internally in our read/write memory and improve over prior work.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-yang-yibin.pdf",
            "keywords": [
                "Zero Knowledge Proofs",
                "RAM Programs",
                "Arithmetic Circuits",
                "Memory Access Optimization",
                "Vector Oblivious Linear Evaluation (VOLE)"
            ]
        },
        "url": "URL#379373"
    },
    {
        "@score": "1",
        "@id": "379374",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "44/5966-1",
                        "text": "Daniel Collins 0001"
                    },
                    {
                        "@pid": "227/7908",
                        "text": "Lo\u00efs Huguenin-Dumittan"
                    },
                    {
                        "@pid": "75/9806-1",
                        "text": "Ngoc Khanh Nguyen 0001"
                    },
                    {
                        "@pid": "117/9391",
                        "text": "Nicolas Rolin"
                    },
                    {
                        "@pid": "v/SergeVaudenay",
                        "text": "Serge Vaudenay"
                    }
                ]
            },
            "title": "K-Waay: Fast and Deniable Post-Quantum X3DH without Ring Signatures.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0001HNRV24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/collins",
            "url": "https://dblp.org/rec/conf/uss/0001HNRV24",
            "abstract": "The Signal protocol and its X3DH key exchange core are regularly used by billions of people in applications like WhatsApp but are unfortunately not quantum-secure. Thus, designing an efficient and post-quantum secure X3DH alternative is paramount. Notably, X3DH supports asynchronicity, as parties can immediately derive keys after uploading them to a central server, and deniability, allowing parties to plausibly deny having completed key exchange. To satisfy these constraints, existing post-quantum X3DH proposals use ring signatures (or equivalently a form of designated-verifier signatures) to provide authentication without compromising deniability as regular signatures would. Existing ring signature schemes, however, have some drawbacks. Notably, they are not generally proven secure in the quantum random oracle model (QROM) and so the quantum security of parameters that are proposed is unclear and likely weaker than claimed. In addition, they are generally slower than standard primitives like KEMs.\nIn this work, we propose an efficient, deniable and post-quantum X3DH-like protocol that we call K-Waay, that does not rely on ring signatures. At its core, K-Waay uses a split-KEM, a primitive introduced by Brendel et al. [SAC 2020], to provide Diffie-Hellman-like implicit authentication and secrecy guarantees. Along the way, we revisit the formalism of Brendel et al. and identify that additional security properties are required to prove a split-KEM-based protocol secure. We instantiate split-KEM by building a protocol based on the Frodo key exchange protocol relying on the plain LWE assumption: our proofs might be of independent interest as we show it satisfies our novel unforgeability and deniability security notions. Finally, we complement our theoretical results by thoroughly benchmarking both K-Waay and existing X3DH protocols. Our results show even when using plain LWE and a conservative choice of parameters that K-Waay is significantly faster than previous work.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-collins.pdf",
            "keywords": [
                "Post-Quantum Cryptography",
                "Key Exchange Protocols",
                "Deniable Authentication",
                "Split-KEM",
                "X3DH Alternative"
            ]
        },
        "url": "URL#379374"
    },
    {
        "@score": "1",
        "@id": "379375",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "03/8774-1",
                        "text": "Meng Shen 0001"
                    },
                    {
                        "@pid": "338/0957",
                        "text": "Changyue Li"
                    },
                    {
                        "@pid": "181/2688-2",
                        "text": "Qi Li 0002"
                    },
                    {
                        "@pid": "72/5422",
                        "text": "Hao Lu"
                    },
                    {
                        "@pid": "26/2546",
                        "text": "Liehuang Zhu"
                    },
                    {
                        "@pid": "181/2626-2",
                        "text": "Ke Xu 0002"
                    }
                ]
            },
            "title": "Transferability of White-box Perturbations: Query-Efficient Adversarial Attacks against Commercial DNN Services.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0001L0LZ024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/shen-meng",
            "url": "https://dblp.org/rec/conf/uss/0001L0LZ024",
            "abstract": "Deep Neural Networks (DNNs) have been proven to be vulnerable to adversarial attacks. Existing decision-based adversarial attacks require large numbers of queries to find an effective adversarial example, resulting in a heavy query cost and also performance degradation under defenses. In this paper, we propose the Dispersed Sampling Attack (DSA), which is a query-efficient decision-based adversarial attack by exploiting the transferability of white-box perturbations. DSA can generate diverse examples with different locations in the embedding space, which provides more information about the adversarial region of substitute models and allows us to search for transferable perturbations. Specifically, DSA samples in a hypersphere centered on an original image, and progressively constrains the perturbation. Extensive experiments are conducted on public datasets to evaluate the performance of DSA in closed-set and open-set scenarios. DSA outperforms the state-of-the-art attacks in terms of both attack success rate (ASR) and average number of queries (AvgQ). Specifically, DSA achieves an ASR of about 90% with an AvgQ of 200 on 4 well-known commercial DNN services.",
            "keywords": [
                "Adversarial Attacks",
                "Decision-based Attacks",
                "Transferability",
                "Query Efficiency",
                "Dispersed Sampling Attack (DSA)"
            ]
        },
        "url": "URL#379375",
        "sema_paperId": "596cf45d4a22456d39748318c70dff2af56cbcd1"
    },
    {
        "@score": "1",
        "@id": "379376",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "238/6241-1",
                        "text": "Jiahao Yu 0001"
                    },
                    {
                        "@pid": "227/9139",
                        "text": "Xingwei Lin"
                    },
                    {
                        "@pid": "28/4466",
                        "text": "Zheng Yu"
                    },
                    {
                        "@pid": "40/6431",
                        "text": "Xinyu Xing"
                    }
                ]
            },
            "title": "LLM-Fuzzer: Scaling Assessment of Large Language Model Jailbreaks.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0001LYX24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/yu-jiahao",
            "url": "https://dblp.org/rec/conf/uss/0001LYX24",
            "abstract": "Warning: This paper contains unfiltered content generated by LLMs that may be offensive to readers. The jailbreak threat poses a significant concern for Large Language Models (LLMs), primarily due to their potential to generate content at scale. If not properly controlled, LLMs can be exploited to produce undesirable outcomes, including the dissemination of misinformation, offensive content, and other forms of harmful or unethical behavior. To tackle this pressing issue, researchers and developers often rely on red-team efforts to manually create adversarial inputs and prompts designed to push LLMs into generating harmful, biased, or inappropriate content. However, this approach encounters serious scalability challenges. To address these scalability issues, we introduce an automated solution for large-scale LLM jailbreak susceptibility assessment called LLM-F UZZER . Inspired by fuzz testing, LLM-F UZZER uses human-crafted jailbreak prompts as starting points. By employing carefully customized seed selection strategies and mutation mechanisms, LLM-F UZZER generates additional jailbreak prompts tailored to specific LLMs. Our experiments show that LLM-F UZZER -generated jailbreak prompts demonstrate significantly increased effectiveness and transferability. This highlights that many open-source and commercial LLMs suffer from severe jailbreak issues, even after safety fine-tuning.",
            "keywords": [
                "Large Language Models",
                "Jailbreak Vulnerabilities",
                "Fuzz Testing",
                "Adversarial Prompts",
                "Safety Fine-tuning"
            ]
        },
        "url": "URL#379376",
        "sema_paperId": "78a83b6e2e470f9c20ceebb4cddae137ab863af4"
    },
    {
        "@score": "1",
        "@id": "379377",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "22/2222-1",
                        "text": "Qian Guo 0001"
                    },
                    {
                        "@pid": "292/4213",
                        "text": "Denis Nabokov"
                    },
                    {
                        "@pid": "368/7367",
                        "text": "Elias Suvanto"
                    },
                    {
                        "@pid": "30/3785-1",
                        "text": "Thomas Johansson 0001"
                    }
                ]
            },
            "title": "Key Recovery Attacks on Approximate Homomorphic Encryption with Non-Worst-Case Noise Flooding Countermeasures.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0001NS024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/guo-qian",
            "url": "https://dblp.org/rec/conf/uss/0001NS024",
            "abstract": "In this paper, we present novel key-recovery attacks on Ap-proximate Homomorphic Encryption schemes, such as CKKS, when employing noise-flooding countermeasures based on non-worst-case noise estimation. Our attacks build upon and enhance the seminal work by Li and Micciancio at EURO-CRYPT 2021. We demonstrate that relying on average-case noise estimation undermines noise-flooding countermeasures, even if the secure noise bounds derived from differential privacy as published by Li et al. at CRYPTO 2022 are implemented. This study emphasizes the necessity of adopting worst-case noise estimation in Approximate Homomorphic Encryption when sharing decryption results. We perform the proposed attacks on OpenFHE, an emerging open-source FHE library garnering increased attention. We experimentally demonstrate the ability to recover the secret key using just one shared decryption output. Furthermore, we investigate the implications of our findings for other libraries, such as IBM\u2019s HElib library, which allows experimental estimation of the noise bounds. Finally, we reveal that deterministic noise generation utilizing a pseudorandom generator fails to provide supplementary protection.",
            "keywords": [
                "Approximate Homomorphic Encryption",
                "Key Recovery Attacks",
                "Noise Flooding Countermeasures",
                "Non-Worst-Case Noise Estimation",
                "Secret Key Recovery"
            ]
        },
        "url": "URL#379377",
        "sema_paperId": "58c35eab6deb0ae9895ce329b639e79eef7c0f19"
    },
    {
        "@score": "1",
        "@id": "379378",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "31/10505-1",
                        "text": "Hanjun Li 0001"
                    },
                    {
                        "@pid": "370/6574",
                        "text": "Sela Navot"
                    },
                    {
                        "@pid": "38/937",
                        "text": "Stefano Tessaro"
                    }
                ]
            },
            "title": "POPSTAR: Lightweight Threshold Reporting with Reduced Leakage.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0001NT24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/li-hanjun",
            "url": "https://dblp.org/rec/conf/uss/0001NT24",
            "abstract": "This paper proposes POPSTAR, a new lightweight protocol for the private computation of heavy hitters, also known as a private threshold reporting system. In such a protocol, the users provide input measurements, and a report server learns which measurements appear more than a pre-specified threshold. POPSTAR follows the same architecture as STAR (Davidson et al., CCS 2022) by relying on a helper randomness server in addition to a main server computing the aggregate heavy hitter statistics. While STAR is extremely lightweight, it leaks a substantial amount of information, consisting of an entire histogram of the provided measurements (but only reveals the actual measurements that appear beyond the threshold). POPSTAR shows that this leakage can be reduced at a modest cost (\u223c7\u00d7 longer aggregation time). Our leakage is closer to that of Poplar (Boneh et al., S&P 2021), which relies however on distributed point functions and a different model which requires interactions of two non-colluding servers to compute the heavy hitters.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-li-hanjun.pdf",
            "keywords": [
                "Private Computation",
                "Threshold Reporting",
                "Heavy Hitters",
                "Information Leakage",
                "Lightweight Protocol"
            ]
        },
        "url": "URL#379378"
    },
    {
        "@score": "1",
        "@id": "379379",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "14/10073",
                        "text": "Benjamin Fuller 0001"
                    },
                    {
                        "@pid": "368/6655",
                        "text": "Rashmi Pai"
                    },
                    {
                        "@pid": "r/AlexanderRussell",
                        "text": "Alexander Russell"
                    }
                ]
            },
            "title": "The Decisive Power of Indecision: Low-Variance Risk-Limiting Audits and Election Contestation via Marginal Mark Recording.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0001PR24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/fuller",
            "url": "https://dblp.org/rec/conf/uss/0001PR24",
            "abstract": "Risk-limiting audits (RLAs) are techniques for verifying the outcomes of large elections. While they provide rigorous guarantees of correctness, widespread adoption has been impeded by both efficiency concerns and the fact they offer statistical, rather than absolute, conclusions. We attend to both of these difficulties, defining new families of audits that improve efficiency and offer qualitative advances in statistical power. Our new audits are enabled by revisiting the standard notion of a cast-vote record so that it can declare multiple possible mark interpretations rather than a single decision; this can reflect the presence of marginal marks, which appear regularly on hand-marked ballots. We show that this simple expedient can offer significant efficiency improvements with only minor changes to existing auditing infrastructure. We consider two ways of representing these marks, both yield risk-limiting comparison audits in the formal sense of Fuller, Harrison, and Russell (IEEE Security&Privacy 2023). We then define a new type of post-election audit we call a contested audit. These permit each candidate to provide a cast-vote record table advancing their own claim to victory. We prove that these audits offer remarkable sample efficiency, yielding control of risk with a constant number of samples (that is independent of margin). This is a first for an audit with provable soundness. These results are formulated in a game-based security model that specify quantitative soundness and completeness guarantees. These audits provide a means to handle contestation of election results affirmed by conventional RLAs.",
            "keywords": [
                "Risk-Limiting Audits",
                "Election Verification",
                "Cast-Vote Record",
                "Marginal Marks",
                "Contested Audit"
            ]
        },
        "url": "URL#379379",
        "sema_paperId": "5f5028dd55e411a448d45fee659a71eb48f02eb5"
    },
    {
        "@score": "1",
        "@id": "379380",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "26/5329-1",
                        "text": "Xiang Ling 0001"
                    },
                    {
                        "@pid": "144/9815",
                        "text": "Zhiyu Wu"
                    },
                    {
                        "@pid": "13/1898-62",
                        "text": "Bin Wang 0062"
                    },
                    {
                        "@pid": "69/508",
                        "text": "Wei Deng"
                    },
                    {
                        "@pid": "96/10278",
                        "text": "Jingzheng Wu"
                    },
                    {
                        "@pid": "07/8388",
                        "text": "Shouling Ji"
                    },
                    {
                        "@pid": "168/9558",
                        "text": "Tianyue Luo"
                    },
                    {
                        "@pid": "01/3269",
                        "text": "Yanjun Wu"
                    }
                ]
            },
            "title": "A Wolf in Sheep&apos;s Clothing: Practical Black-box Adversarial Attacks for Evading Learning-based Windows Malware Detection in the Wild.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0001W0DWJLW24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/ling",
            "url": "https://dblp.org/rec/conf/uss/0001W0DWJLW24",
            "abstract": "Given the remarkable achievements of existing learning-based malware detection in both academia and industry, this paper presents MalGuise, a practical black-box adversarial attack framework that evaluates the security risks of existing learning-based Windows malware detection systems under the black-box setting. MalGuise first employs a novel semantics-preserving transformation of call-based redividing to concurrently manipulate both nodes and edges of malware's control-flow graph, making it less noticeable. By employing a Monte-Carlo-tree-search-based optimization, MalGuise then searches for an optimized sequence of call-based redividing transformations to apply to the input Windows malware for evasions. Finally, it reconstructs the adversarial malware file based on the optimized transformation sequence while adhering to Windows executable format constraints, thereby maintaining the same semantics as the original. MalGuise is systematically evaluated against three state-of-the-art learning-based Windows malware detection systems under the black-box setting. Evaluation results demonstrate that MalGuise achieves a remarkably high attack success rate, mostly exceeding 95%, with over 91% of the generated adversarial malware files maintaining the same semantics. Furthermore, MalGuise achieves up to a 74.97% attack success rate against five anti-virus products, highlighting potential tangible security concerns to real-world users.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-ling.pdf",
            "keywords": [
                "Malware Detection",
                "Adversarial Attacks",
                "Black-box Attacks",
                "Control-flow Graph Manipulation",
                "MalGuise Framework"
            ]
        },
        "url": "URL#379380"
    },
    {
        "@score": "1",
        "@id": "379381",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "133/5336-1",
                        "text": "Chong Xiang 0001"
                    },
                    {
                        "@pid": "75/5056",
                        "text": "Tong Wu"
                    },
                    {
                        "@pid": "244/9642",
                        "text": "Sihui Dai"
                    },
                    {
                        "@pid": "33/7861",
                        "text": "Jonathan Petit"
                    },
                    {
                        "@pid": "74/28",
                        "text": "Suman Jana"
                    },
                    {
                        "@pid": "39/6266",
                        "text": "Prateek Mittal"
                    }
                ]
            },
            "title": "PatchCURE: Improving Certifiable Robustness, Model Utility, and Computation Efficiency of Adversarial Patch Defenses.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0001WDPJM24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/xiang-chong",
            "url": "https://dblp.org/rec/conf/uss/0001WDPJM24",
            "abstract": "State-of-the-art defenses against adversarial patch attacks can now achieve strong certifiable robustness with a marginal drop in model utility. However, this impressive performance typically comes at the cost of 10-100x more inference-time computation compared to undefended models -- the research community has witnessed an intense three-way trade-off between certifiable robustness, model utility, and computation efficiency. In this paper, we propose a defense framework named PatchCURE to approach this trade-off problem. PatchCURE provides sufficient\"knobs\"for tuning defense performance and allows us to build a family of defenses: the most robust PatchCURE instance can match the performance of any existing state-of-the-art defense (without efficiency considerations); the most efficient PatchCURE instance has similar inference efficiency as undefended models. Notably, PatchCURE achieves state-of-the-art robustness and utility performance across all different efficiency levels, e.g., 16-23% absolute clean accuracy and certified robust accuracy advantages over prior defenses when requiring computation efficiency to be close to undefended models. The family of PatchCURE defenses enables us to flexibly choose appropriate defenses to satisfy given computation and/or utility constraints in practice.",
            "keywords": [
                "Adversarial Patch Defenses",
                "Certifiable Robustness",
                "Model Utility",
                "Computation Efficiency",
                "PatchCURE Framework"
            ]
        },
        "url": "URL#379381",
        "sema_paperId": "126c18df57c6bd0aa206add24e7ebec8032ba3bb"
    },
    {
        "@score": "1",
        "@id": "379382",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "85/7672-2",
                        "text": "Tiantian Liu 0002"
                    },
                    {
                        "@pid": "75/2611-4",
                        "text": "Feng Lin 0004"
                    },
                    {
                        "@pid": "139/5759",
                        "text": "Zhongjie Ba"
                    },
                    {
                        "@pid": "49/2793-8",
                        "text": "Li Lu 0008"
                    },
                    {
                        "@pid": "148/4477",
                        "text": "Zhan Qin"
                    },
                    {
                        "@pid": "20/6179-1",
                        "text": "Kui Ren 0001"
                    }
                ]
            },
            "title": "MicGuard: A Comprehensive Detection System against Out-of-band Injection Attacks for Different Level Microphone-based Devices.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/00020B0Q024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/liu-tiantian",
            "url": "https://dblp.org/rec/conf/uss/00020B0Q024",
            "abstract": "The integration of microphones into sensors and systems, serving as input interfaces to intelligent applications and industrial manufacture, has raised public concerns regarding their input perception. Studies have uncovered the potential dangers posed by out-of-band injection attacks on micro-phones, encompassing ultrasound, laser, and electromagnetic attacks, injecting commands or interferences for malicious purposes. Despite existing efforts on defense against ultrasound injections, there is a critical gap in addressing the risks posed by other out-of-band injections. To bridge this gap, this paper proposes MicGuard, a comprehensive passive detection system against out-of-band attacks. Without relying on prior information from attacking and victim devices, MicGuard leverages carrier traces and spectral chaos observed by injection phenomena across different levels of devices. The carrier traces are used in a prejudgment to fast reject partial injected signals, and the following memory-based detection model to distinguish anomaly based on the quantified chaotic entropy extracted from publicly available audio datasets. Mic-Guard is evaluated on a wide range of microphone-based devices including sensors, recorders, smartphones, and tablets, achieving an average AUC of 98% with high robustness and universality.",
            "keywords": [
                "Microphone Security",
                "Out-of-band Injection Attacks",
                "Passive Detection System",
                "Chaotic Entropy",
                "MicGuard"
            ]
        },
        "url": "URL#379382",
        "sema_paperId": "f03a738908ee59ec2ae3ac4d073d3c32f092dbc5"
    },
    {
        "@score": "1",
        "@id": "379383",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "120/5486-2",
                        "text": "Yanan Guo 0002"
                    },
                    {
                        "@pid": "117/0017",
                        "text": "Zhenkai Zhang"
                    },
                    {
                        "@pid": "y/JunYang2",
                        "text": "Jun Yang 0002"
                    }
                ]
            },
            "title": "GPU Memory Exploitation for Fun and Profit.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0002Z024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/guo-yanan",
            "url": "https://dblp.org/rec/conf/uss/0002Z024",
            "abstract": "As modern applications increasingly rely on GPUs to accelerate the computation, it has become very critical to study and understand the security implications of GPUs. In this work, we conduct a thorough examination of buffer overflows on modern GPUs. Specifically, we demonstrate that, due to GPU's unique memory system, GPU programs suffer from different and more complex buffer overflow vulnerabilities compared to CPU programs, contradicting the conclusions of prior studies. In addition, despite the critical role GPUs play in modern computing, GPU systems are missing essential memory protection mechanisms. Consequently, when buffer overflow vulnerabilities are exploited by an attacker, they can lead to both code injection attacks and code reuse attacks, including return-oriented programming (ROP). Our results show that these attacks pose a significant security risk to modern GPU applications.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-guo-yanan.pdf",
            "keywords": [
                "GPU Security",
                "Buffer Overflow",
                "Memory Protection",
                "Code Injection",
                "Return-Oriented Programming (ROP)"
            ]
        },
        "url": "URL#379383",
        "sema_paperId": "a1e2a2115c6d8f59ebcc564adefcd4d252d113b7"
    },
    {
        "@score": "1",
        "@id": "379384",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "85/670-3",
                        "text": "Peiyu Liu 0003"
                    },
                    {
                        "@pid": "88/9541",
                        "text": "Junming Liu"
                    },
                    {
                        "@pid": "246/8180",
                        "text": "Lirong Fu"
                    },
                    {
                        "@pid": "67/10639",
                        "text": "Kangjie Lu"
                    },
                    {
                        "@pid": "03/1418",
                        "text": "Yifan Xia"
                    },
                    {
                        "@pid": "139/6932-2",
                        "text": "Xuhong Zhang 0002"
                    },
                    {
                        "@pid": "70/2079",
                        "text": "Wenzhi Chen"
                    },
                    {
                        "@pid": "169/7167",
                        "text": "Haiqin Weng"
                    },
                    {
                        "@pid": "07/8388",
                        "text": "Shouling Ji"
                    },
                    {
                        "@pid": "122/3593",
                        "text": "Wenhai Wang"
                    }
                ]
            },
            "title": "Exploring ChatGPT&apos;s Capabilities on Vulnerability Management.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0003LFLX0CWJW24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/liu-peiyu",
            "url": "https://dblp.org/rec/conf/uss/0003LFLX0CWJW24",
            "abstract": "Recently, ChatGPT has attracted great attention from the code analysis domain. Prior works show that ChatGPT has the capabilities of processing foundational code analysis tasks, such as abstract syntax tree generation, which indicates the potential of using ChatGPT to comprehend code syntax and static behaviors. However, it is unclear whether ChatGPT can complete more complicated real-world vulnerability management tasks, such as the prediction of security relevance and patch correctness, which require an all-encompassing understanding of various aspects, including code syntax, program semantics, and related manual comments. In this paper, we explore ChatGPT's capabilities on 6 tasks involving the complete vulnerability management process with a large-scale dataset containing 70,346 samples. For each task, we compare ChatGPT against SOTA approaches, investigate the impact of different prompts, and explore the difficulties. The results suggest promising potential in leveraging ChatGPT to assist vulnerability management. One notable example is ChatGPT's proficiency in tasks like generating titles for software bug reports. Furthermore, our findings reveal the difficulties encountered by ChatGPT and shed light on promising future directions. For instance, directly providing random demonstration examples in the prompt cannot consistently guarantee good performance in vulnerability management. By contrast, leveraging ChatGPT in a self-heuristic way -- extracting expertise from demonstration examples itself and integrating the extracted expertise in the prompt is a promising research direction. Besides, ChatGPT may misunderstand and misuse the information in the prompt. Consequently, effectively guiding ChatGPT to focus on helpful information rather than the irrelevant content is still an open problem.",
            "keywords": [
                "Vulnerability Management",
                "Code Analysis",
                "Security Relevance Prediction",
                "Patch Correctness",
                "ChatGPT in Security"
            ]
        },
        "url": "URL#379384",
        "sema_paperId": "7d19fc3de6e3365993fc8ba4351511fe2c07e80d"
    },
    {
        "@score": "1",
        "@id": "379385",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "73/2286-3",
                        "text": "Anirban Chakraborty 0003"
                    },
                    {
                        "@pid": "254/3236",
                        "text": "Nimish Mishra"
                    },
                    {
                        "@pid": "85/3079",
                        "text": "Debdeep Mukhopadhyay"
                    }
                ]
            },
            "title": "Shesha : Multi-head Microarchitectural Leakage Discovery in new-generation Intel Processors.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0003MM24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/chakraborty",
            "url": "https://dblp.org/rec/conf/uss/0003MM24",
            "abstract": "Transient execution attacks have been one of the widely explored microarchitectural side channels since the discovery of Spectre and Meltdown. However, much of the research has been driven by manual discovery of new transient paths through well-known speculative events. Although a few attempts exist in literature on automating transient leakage discovery, such tools focus on finding variants of known transient attacks and explore a small subset of instruction set. Further, they take a random fuzzing approach that does not scale as the complexity of search space increases. In this work, we identify that the search space of bad speculation is disjointedly fragmented into equivalence classes and then use this observation to develop a framework named Shesha, inspired by Particle Swarm Optimization, which exhibits faster convergence rates than state-of-the-art fuzzing techniques for automatic discovery of transient execution attacks. We then use Shesha to explore the vast search space of extensions to the x86 Instruction Set Architecture (ISAs), thereby focusing on previously unexplored avenues of bad speculation. As such, we report five previously unreported transient execution paths in Instruction Set Extensions (ISEs) on new generation of Intel processors. We then perform extensive reverse engineering of each of the transient execution paths and provide root-cause analysis. Using the discovered transient execution paths, we develop attack building blocks to exhibit exploitable transient windows. Finally, we demonstrate data leakage from Fused Multiply-Add instructions through SIMD buffer and extract victim data from various cryptographic implementations.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-chakraborty.pdf",
            "keywords": [
                "Microarchitectural Attacks",
                "Transient Execution",
                "Speculative Execution",
                "Instruction Set Architecture",
                "Data Leakage"
            ]
        },
        "url": "URL#379385"
    },
    {
        "@score": "1",
        "@id": "379386",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "27/586-3",
                        "text": "Yan Lin 0003"
                    },
                    {
                        "@pid": "92/6076",
                        "text": "Joshua Wong"
                    },
                    {
                        "@pid": "40/1491",
                        "text": "Xiang Li"
                    },
                    {
                        "@pid": "144/1634",
                        "text": "Haoyu Ma"
                    },
                    {
                        "@pid": "60/206",
                        "text": "Debin Gao"
                    }
                ]
            },
            "title": "Peep With A Mirror: Breaking The Integrity of Android App Sandboxing via Unprivileged Cache Side Channel.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0003WLMG24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/lin-yan",
            "url": "https://dblp.org/rec/conf/uss/0003WLMG24",
            "abstract": "Application sandboxing is a well-established security principle employed in the Android platform to safeguard sensitive information. However, hardware resources, specifically the CPU caches, are beyond the protection of this software-based mechanism, leaving room for potential side-channel attacks. Existing attacks against this particular weakness of app sand-boxing mainly target shared components among apps, hence can only observe system-level program dynamics (such as UI tracing). In this work, we advance cache side-channel attacks by demonstrating the viability of non-intrusive and fine-grained probing across different app sandboxes, which have the potential to uncover app-specific and private program behaviors, thereby highlighting the importance of further research in this area. In contrast to conventional attack schemes, our proposal leverages a user-level attack surface within the Android platform, namely the dynamic inter-app component sharing with package context (also known as DICI), to fully map the code of targeted victim apps into the memory space of the at-tacker\u2019s sandbox. Building upon this concept, we have developed a proof-of-concept attack demo called A NDRO S COPE and demonstrated its effectiveness with empirical evaluations where the attack app was shown to be able to successfully infer private information pertaining to individual apps, such as driving routes and keystroke dynamics with considerable accuracy.",
            "keywords": [
                "Android App Sandboxing",
                "Cache Side-Channel Attacks",
                "Inter-App Component Sharing",
                "Private Information Leakage",
                "Non-Intrusive Probing"
            ]
        },
        "url": "URL#379386",
        "sema_paperId": "4db2cca740a42f38fd2daaaf850fea79e05c5916"
    },
    {
        "@score": "1",
        "@id": "379387",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "83/5898-3",
                        "text": "Cheng Huang 0003"
                    },
                    {
                        "@pid": "10/8359",
                        "text": "Nannan Wang"
                    },
                    {
                        "@pid": "61/2757",
                        "text": "Ziyan Wang"
                    },
                    {
                        "@pid": "120/1735",
                        "text": "Siqi Sun"
                    },
                    {
                        "@pid": "118/5889",
                        "text": "Lingzi Li"
                    },
                    {
                        "@pid": "126/8104",
                        "text": "Junren Chen"
                    },
                    {
                        "@pid": "338/5002",
                        "text": "Qianchong Zhao"
                    },
                    {
                        "@pid": "250/2542",
                        "text": "Jiaxuan Han"
                    },
                    {
                        "@pid": "70/2539",
                        "text": "Zhen Yang"
                    },
                    {
                        "@pid": "29/563",
                        "text": "Lei Shi"
                    }
                ]
            },
            "title": "DONAPI: Malicious NPM Packages Detector using Behavior Sequence Knowledge Mapping.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0003WWSLCZHYS24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/huang-cheng",
            "url": "https://dblp.org/rec/conf/uss/0003WWSLCZHYS24",
            "abstract": "With the growing popularity of modularity in software development comes the rise of package managers and language ecosystems. Among them, npm stands out as the most extensive package manager, hosting more than 2 million third-party open-source packages that greatly simplify the process of building code. However, this openness also brings security risks, as evidenced by numerous package poisoning incidents.\nIn this paper, we synchronize a local package cache containing more than 3.4 million packages in near real-time to give us access to more package code details. Further, we perform manual inspection and API call sequence analysis on packages collected from public datasets and security reports to build a hierarchical classification framework and behavioral knowledge base covering different sensitive behaviors. In addition, we propose the DONAPI, an automatic malicious npm packages detector that combines static and dynamic analysis. It makes preliminary judgments on the degree of maliciousness of packages by code reconstruction techniques and static analysis, extracts dynamic API call sequences to confirm and identify obfuscated content that static analysis can not handle alone, and finally tags malicious software packages based on the constructed behavior knowledge base. To date, we have identified and manually confirmed 325 malicious samples and discovered 2 unusual API calls and 246 API call sequences that have not appeared in known samples.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-huang-cheng.pdf",
            "keywords": [
                "Malicious Package Detection",
                "NPM Ecosystem",
                "Behavioral Analysis",
                "API Call Sequences",
                "Package Poisoning"
            ]
        },
        "url": "URL#379387"
    },
    {
        "@score": "1",
        "@id": "379388",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "158/9223-3",
                        "text": "Reham Mohamed 0003"
                    },
                    {
                        "@pid": "331/2639",
                        "text": "Arjun Arunasalam"
                    },
                    {
                        "@pid": "222/5923",
                        "text": "Habiba Farrukh"
                    },
                    {
                        "@pid": "381/1628",
                        "text": "Jason Tong"
                    },
                    {
                        "@pid": "99/3883",
                        "text": "Antonio Bianchi"
                    },
                    {
                        "@pid": "143/2298",
                        "text": "Z. Berkay Celik"
                    }
                ]
            },
            "title": "ATTention Please! An Investigation of the App Tracking Transparency Permission.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0004AFTBC24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/mohamed",
            "url": "https://dblp.org/rec/conf/uss/0004AFTBC24",
            "abstract": "Apple introduced the App Tracking Transparency (ATT) framework in iOS 14.5. The goal of this framework is to mitigate user concerns about how their privacy-sensitive data is used for targeted advertising. Through this framework, the OS generates an ATT alert to request user permission for tracking. While this alert includes developer-controlled alert text, Apple mandates this text adheres to specific guidelines to prevent users from being coerced into unwillingly granting the ATT permission for tracking. However, to improve apps' monetization, developers may incorporate dark patterns in the ATT alerts to deceive users into granting the permission.To understand the prevalence and characteristics of such dark patterns, we first study Apple's alert guidelines and identify four patterns that violate standards. We then develop ATTCLS, an ATT alert classification framework that combines contrastive learning for language modeling with a fully connected neural network for multi-label alert pattern classification. Finally, by applying ATTCLS to 4,000 iOS apps, we reveal that 59% of the alerts use four dark patterns that either mislead users, incentivize tracking, include confusing terms, or omit the purpose of the ATT permission.We then conduct a user study with 114 participants to examine users' understanding of ATT and how different alert patterns can influence their perception. This study reveals that ATT alerts used by current apps often deceive or confuse users. For instance, users can be misled into believing that granting the ATT permission guarantees better app features or that denying it protects all of their sensitive data. We envision that our developed tools and empirical results will aid mobile platforms to refine guidelines, introduce a strict vetting process, and better design privacy-related prompts for users.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-mohamed.pdf",
            "keywords": [
                "App Tracking Transparency",
                "User Privacy",
                "Dark Patterns",
                "Mobile Advertising",
                "User Consent Misleading"
            ]
        },
        "url": "URL#379388",
        "sema_paperId": "680124c972588d80d89496de38d7d4e704127c31"
    },
    {
        "@score": "1",
        "@id": "379389",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "116/0645-4",
                        "text": "Zeyu Liu 0004"
                    },
                    {
                        "@pid": "t/EranTromer",
                        "text": "Eran Tromer"
                    },
                    {
                        "@pid": "119/0981",
                        "text": "Yunhao Wang"
                    }
                ]
            },
            "title": "PerfOMR: Oblivious Message Retrieval with Reduced Communication and Computation.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0004TW24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/liu-zeyu",
            "url": "https://dblp.org/rec/conf/uss/0004TW24",
            "abstract": "Anonymous message delivery, as in privacy-preserving blockchain and private messaging applications, needs to protect recipient metadata: eavesdroppers should not be able to link messages to their recipients. This raises the question: how can untrusted servers assist in delivering the pertinent messages to each recipient, without learning which messages are addressed to whom?\nRecent work constructed Oblivious Message Retrieval (OMR) protocols that outsource the message detection and retrieval in a privacy-preserving way, using homomorphic encryption. Their construction exhibits significant costs in computation per message scanned (\u223c0.1 second), as well as in the size of the associated messages (\u223c1kB overhead) and public keys (\u223c132kB).\nThis work constructs more efficient OMR schemes, by replacing the LWE-based clue encryption of prior works with a Ring-LWE variant, and utilizing the resulting flexibility to improve several components of the scheme. We thus devise, analyze, and benchmark two protocols:\nThe first protocol focuses on improving the detector runtime, using a new retrieval circuit that can be homomorphically evaluated 15x faster than the prior work.\nThe second protocol focuses on reducing the communication costs, by designing a different homomorphic decryption circuit that allows the parameter of the Ring-LWE encryption to be set such that the public key size is about 235x smaller than the prior work, and the message size is roughly 1.6x smaller. The runtime of this second construction is \u223c40.0ms per message, still more than 2.5x faster than prior works.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-liu-zeyu.pdf",
            "keywords": [
                "Oblivious Message Retrieval",
                "Privacy-Preserving Communication",
                "Homomorphic Encryption",
                "Ring-LWE Encryption",
                "Metadata Protection"
            ]
        },
        "url": "URL#379389"
    },
    {
        "@score": "1",
        "@id": "379390",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "82/6141-5",
                        "text": "Hongbin Liu 0005"
                    },
                    {
                        "@pid": "r/MichaelKReiter",
                        "text": "Michael K. Reiter"
                    },
                    {
                        "@pid": "03/9437",
                        "text": "Neil Zhenqiang Gong"
                    }
                ]
            },
            "title": "Mudjacking: Patching Backdoor Vulnerabilities in Foundation Models.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0005RG24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/liu-hongbin",
            "url": "https://dblp.org/rec/conf/uss/0005RG24",
            "abstract": "Foundation model has become the backbone of the AI ecosystem. In particular, a foundation model can be used as a general-purpose feature extractor to build various downstream classifiers. However, foundation models are vulnerable to backdoor attacks and a backdoored foundation model is a single-point-of-failure of the AI ecosystem, e.g., multiple downstream classifiers inherit the backdoor vulnerabilities simultaneously. In this work, we propose Mudjacking, the first method to patch foundation models to remove backdoors. Specifically, given a misclassified trigger-embedded input detected after a backdoored foundation model is deployed, Mudjacking adjusts the parameters of the foundation model to remove the backdoor. We formulate patching a foundation model as an optimization problem and propose a gradient descent based method to solve it. We evaluate Mudjacking on both vision and language foundation models, eleven benchmark datasets, five existing backdoor attacks, and thirteen adaptive backdoor attacks. Our results show that Mudjacking can remove backdoor from a foundation model while maintaining its utility.",
            "keywords": [
                "Foundation Models",
                "Backdoor Attacks",
                "Vulnerability Patching",
                "Mudjacking",
                "Trigger-Embedded Inputs"
            ]
        },
        "url": "URL#379390",
        "sema_paperId": "faa1ff3982d4022c461cb4ec69ddc23325c129db"
    },
    {
        "@score": "1",
        "@id": "379391",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "05/1958-5",
                        "text": "Kun Wang 0005"
                    },
                    {
                        "@pid": "172/1282-1",
                        "text": "Xiangyu Xu 0001"
                    },
                    {
                        "@pid": "49/2793-8",
                        "text": "Li Lu 0008"
                    },
                    {
                        "@pid": "139/5759",
                        "text": "Zhongjie Ba"
                    },
                    {
                        "@pid": "75/2611-4",
                        "text": "Feng Lin 0004"
                    },
                    {
                        "@pid": "20/6179-1",
                        "text": "Kui Ren 0001"
                    }
                ]
            },
            "title": "FraudWhistler: A Resilient, Robust and Plug-and-play Adversarial Example Detection Method for Speaker Recognition.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0005X0B0024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/wang-kun",
            "url": "https://dblp.org/rec/conf/uss/0005X0B0024",
            "abstract": "With the in-depth integration of deep learning, state-of-the-art speaker recognition systems have achieved breakthrough progress. However, the intrinsic vulnerability of deep learning to Adversarial Example (AE) attacks has brought new severe threats to real-world speaker recognition systems. In this paper, we propose FraudWhistler , a practical AE detection system, which is resilient to various AE attacks, robust in complex physical environments, and plug-and-play for deployed systems. Its basic idea is to make use of an intrinsic characteristic of AE, i.e., the instability of model prediction for AE, which is totally different from benign samples. FraudWhistler generates several audio variants for the original audio sample with some distortion techniques, obtains multiple outputs of the speaker recognition system for these audio variants, and based on that FraudWhistler extracts some statistics representing the instability of the original audio sample and further trains a one-class SVM classi\ufb01er to detect adversarial example. Extensive experimental results show that FraudWhistler achieves 98.7% accuracy on AE detection outperforming SOTA works by 13%, and 84% accuracy in the worst case against an adaptive adversary.",
            "keywords": [
                "Speaker Recognition",
                "Adversarial Examples",
                "AE Detection",
                "Robustness",
                "One-Class SVM"
            ]
        },
        "url": "URL#379391",
        "sema_paperId": "77065e665037f1e14659c05ebd14f52f4ee8e59a"
    },
    {
        "@score": "1",
        "@id": "379392",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "42/6896-9",
                        "text": "Ting Su 0009"
                    },
                    {
                        "@pid": "46/8559",
                        "text": "Yaohua Wang"
                    },
                    {
                        "@pid": "25/356",
                        "text": "Shi Xu"
                    },
                    {
                        "@pid": "381/1680",
                        "text": "Lusi Zhang"
                    },
                    {
                        "@pid": "381/1635",
                        "text": "Simin Feng"
                    },
                    {
                        "@pid": "381/1591",
                        "text": "Jialong Song"
                    },
                    {
                        "@pid": "66/2967",
                        "text": "Yiming Liu"
                    },
                    {
                        "@pid": "77/8569",
                        "text": "Yongkang Tang"
                    },
                    {
                        "@pid": "06/6785",
                        "text": "Yang Zhang"
                    },
                    {
                        "@pid": "38/9639",
                        "text": "Shaoqing Li"
                    },
                    {
                        "@pid": "73/1810-3",
                        "text": "Yang Guo 0003"
                    },
                    {
                        "@pid": "00/5381",
                        "text": "Hengzhu Liu"
                    }
                ]
            },
            "title": "Improving the Ability of Thermal Radiation Based Hardware Trojan Detection.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0009WXZFSLTZL0L24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/su-ting",
            "url": "https://dblp.org/rec/conf/uss/0009WXZFSLTZL0L24",
            "abstract": "Hardware Trojans (HTs) pose a significant and growing threat to the field of hardware security. Several side-channel techniques, including power and electromagnetic radiation (EMR), have been proposed for HT detection, constrained by reliance on the golden chip or test vectors. In response, researchers advocate for the use of thermal radiation (TR) to identify HTs. However, existing TR-based methods are designed for the ideal HT that can fully occupy at least one pixel on the thermal radiation map (TRM). In reality, HTs may occupy multiple pixels, substantially diminishing occupancy in each pixel, thereby reducing the accuracy of existing detection methods. This challenge is exacerbated by the noise caused by the thermal camera. To this end, this paper introduces a countermeasure named noise based pixel occupation enhancement (NICE), aiming to improve the ability of TR-based HT detection. The key insight of NICE is that noise can vary the pixel occupation of HTs while disrupting HT detection. Consequently, the noise can be exploited to statistically find out the largest pixel occupation among the variations, thereby enhancing HT detection accuracy. Experimental results on a 0.13 \u03bcm Digital Signal Processing (DSP) show that the detection rate of NICE exceeds the existing TR-based method by more than 47%, reaching 91.81%, while maintaining a false alarm rate of less than 9%. Both metrics of NICE are comparable to the existing power-based and EMR-based methods, eliminating the need for the golden chip and test vectors.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-su-ting.pdf",
            "keywords": [
                "Hardware Trojan Detection",
                "Thermal Radiation",
                "Noise-Based Enhancement",
                "Pixel Occupation",
                "Detection Accuracy"
            ]
        },
        "url": "URL#379392",
        "sema_paperId": "1505c2338d66bf79c0148a6b4ad3e753383e00bc"
    },
    {
        "@score": "1",
        "@id": "379393",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "57/4707-10",
                        "text": "Yifan Zhang 0010"
                    },
                    {
                        "@pid": "381/1595",
                        "text": "Zhaojie Hu"
                    },
                    {
                        "@pid": "60/8494",
                        "text": "Xueqiang Wang"
                    },
                    {
                        "@pid": "305/0218",
                        "text": "Yuhui Hong"
                    },
                    {
                        "@pid": "167/0416",
                        "text": "Yuhong Nan"
                    },
                    {
                        "@pid": "06/6268",
                        "text": "XiaoFeng Wang 0001"
                    },
                    {
                        "@pid": "381/1599",
                        "text": "Jiatao Cheng"
                    },
                    {
                        "@pid": "34/8412",
                        "text": "Luyi Xing"
                    }
                ]
            },
            "title": "Navigating the Privacy Compliance Maze: Understanding Risks with Privacy-Configurable Mobile SDKs.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0010HWHN0CX24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/zhang-yifan",
            "url": "https://dblp.org/rec/conf/uss/0010HWHN0CX24",
            "abstract": "The rise of privacy laws like GDPR and CCPA has made privacy compliance a requirement for mobile apps. Yet, achieving it is difficult due to the apps' use of third-party SDKs with opaque data practices. Recently, to assist apps in complying with privacy laws, many leading third-party SDKs have started providing privacy APIs for configuring the SDK's data practices. Nevertheless, the extent to which such a paradigm, referred to as privacy-configurable SDKs (or PICO SDKs), truly enhances app privacy compliance remains unclear to the community.\nThis question can only be answered through a systematic measurement study, which is nontrivial and requires in-depth analysis of the implementation of privacy APIs in PICO SDKs, as well as the way they are utilized, sometimes through a \"wrapper\" SDK that encapsulates other SDKs. To address this challenge, we developed PICOSCAN, a privacy risk analysis framework targeting Android, one of the most common mobile platforms. PICOSCAN automatically analyzes the code of both apps and SDKs to detect practices that potentially invade user privacy. Applying PICOSCAN to 65 most popular PICO SDKs and over 48,000 Google Play apps, we uncovered significant privacy risks in today's Android ecosystem. A large number of them fail to correctly utilize privacy APIs as prescribed, and even when these APIs are used, they often do not align with user privacy preferences. Moreover, our study reveals that many wrapper SDKs do not accurately convey privacy configurations to the SDKs they encapsulate, resulting in compliance risks. Our findings expose systematic failures in the design, implementation, and usage of PICO SDKs, highlighting the urgent need for more effective solutions to enhance the privacy assurance of Android apps. We will open-source the framework and make the data produced by this study publicly available.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-zhang-yifan.pdf",
            "keywords": [
                "Privacy Compliance",
                "Mobile SDKs",
                "Privacy-Configurable SDKs",
                "User Privacy Risks",
                "PICOSCAN Framework"
            ]
        },
        "url": "URL#379393",
        "sema_paperId": "d3c30514e4d2ac912772ab3f14886d659a979428"
    },
    {
        "@score": "1",
        "@id": "379394",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "188/7759-97",
                        "text": "Chao Wang 0097"
                    },
                    {
                        "@pid": "75/2611-4",
                        "text": "Feng Lin 0004"
                    },
                    {
                        "@pid": "77/6310",
                        "text": "Hao Yan"
                    },
                    {
                        "@pid": "75/5056",
                        "text": "Tong Wu"
                    },
                    {
                        "@pid": "11/6689",
                        "text": "Wenyao Xu"
                    },
                    {
                        "@pid": "20/6179-1",
                        "text": "Kui Ren 0001"
                    }
                ]
            },
            "title": "VibSpeech: Exploring Practical Wideband Eavesdropping via Bandlimited Signal of Vibration-based Side Channel.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/00970YWX024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/wang-chao",
            "url": "https://dblp.org/rec/conf/uss/00970YWX024",
            "abstract": "Vibration-based side channel is an ever-present threat to speech privacy. However, due to the target\u2019s frequency response with a rapid decay or limited sampling rate of malicious sensors, the acquired vibration signals are often distorted and narrowband, which fails an intelligible speech recovery. This paper tries to answer that when the side-channel data has only a very limited bandwidth (<500Hz), is it feasible to achieve a wideband eavesdropping based on a practical assumption? Our answer is YES based on the assumption that a short utterance (2s-4s) of the victim is exposed to the attacker. What is most surprising is that the attack can recover speech with a bandwidth of up to 8kHz. This covers almost all phonemes (voiced and unvoiced) in human speech and causes practical threat. The core idea of the attack is using vocal-tract features extracted from the victim\u2019s utterance to compensate for the side-channel data. To demonstrate the threat, we proposed a vocal-guided attack scheme called VibSpeech and built a prototype based on a mmWave sensor to penetrate soundproof walls for vibration sensing. We solved challenges of vibration artifact suppression and a generalized scheme free of any target\u2019s training data. We evaluated VibSpeech with extensive experiments and validated it on the IMU-based method. The results indicated that VibSpeech can recover intelligible speech with an average MCD/SNR of 3.9/5.4dB.",
            "keywords": [
                "Vibration-based Eavesdropping",
                "Speech Privacy",
                "Wideband Signal Recovery",
                "Vocal-Tract Features",
                "VibSpeech"
            ]
        },
        "url": "URL#379394",
        "sema_paperId": "479618f051fe8e5f6b38792ed184b7fcf62aaef6"
    },
    {
        "@score": "1",
        "@id": "379395",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "262/3575",
                        "text": "Syed Ghazanfar Abbas"
                    },
                    {
                        "@pid": "202/6743",
                        "text": "Muslum Ozgur Ozmen"
                    },
                    {
                        "@pid": "301/5823",
                        "text": "Abdulellah Alsaheel"
                    },
                    {
                        "@pid": "271/4490",
                        "text": "Arslan Khan"
                    },
                    {
                        "@pid": "143/2298",
                        "text": "Z. Berkay Celik"
                    },
                    {
                        "@pid": "59/5539",
                        "text": "Dongyan Xu"
                    }
                ]
            },
            "title": "SAIN: Improving ICS Attack Detection Sensitivity via State-Aware Invariants.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AbbasOAKCX24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/abbas",
            "url": "https://dblp.org/rec/conf/uss/AbbasOAKCX24",
            "abstract": "Industrial Control Systems (ICSs) rely on Programmable Logic Controllers (PLCs) to operate within a set of states. The states are composed of variables that determine how sensor data is interpreted, configuration parameters are applied, and actuator commands are issued. Recent works have shown that attackers can manipulate these variables to compromise ICS safety and security. To detect such attacks, previous approaches have leveraged invariants\u2014a set of rules defining the correct behavior of an ICS. However, these invariants suffer from a critical limitation: they are state-agnostic . This means they define variable ranges across all possible ICS states, leading to loosely bounded detection thresholds. Unfortunately, attackers can exploit these loose bounds and launch stealthy attacks that evade detection without violating such invariants. In this paper, we introduce SAIN , an automated method to derive state-aware ICS invariants with tighter bounds and enforce them through a PLC-based monitor. SAIN first generates invariant templates by identifying the PLC program states, state transitions, and the inter-dependencies among sensing, actuation, and configuration variables within each state through program analysis. It then partitions the ICS data traces into state-specific sub-traces and quantifies the invariant templates with concrete, tighter bounds, as system-specific knowledge about the subject ICS. Lastly, it enforces the state-aware invariants through a run-time monitor. We evaluate SAIN on a Fischertechnik manufacturing plant and a chemical plant simulator against 17 attacks. SAIN protects the plants, on average, with a false positive rate of 2% and a run-time overhead of 3%.",
            "keywords": [
                "Industrial Control Systems",
                "Programmable Logic Controllers",
                "State-Aware Invariants",
                "Attack Detection",
                "Stealthy Attacks"
            ]
        },
        "url": "URL#379395",
        "sema_paperId": "1c324e5ab4d2d264065770c4e1f87a2a2d91e07c"
    },
    {
        "@score": "1",
        "@id": "379396",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "331/5842",
                        "text": "Anna Ablove"
                    },
                    {
                        "@pid": "371/4243",
                        "text": "Shreyas Chandrashekaran"
                    },
                    {
                        "@pid": "123/2117",
                        "text": "Hieu Le"
                    },
                    {
                        "@pid": "270/2488",
                        "text": "Ram Sundara Raman"
                    },
                    {
                        "@pid": "270/2465",
                        "text": "Reethika Ramesh"
                    },
                    {
                        "@pid": "381/1638",
                        "text": "Harry Oppenheimer"
                    },
                    {
                        "@pid": "24/973",
                        "text": "Roya Ensafi"
                    }
                ]
            },
            "title": "Digital Discrimination of Users in Sanctioned States: The Case of the Cuba Embargo.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AbloveCLRROE24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/ablove",
            "url": "https://dblp.org/rec/conf/uss/AbloveCLRROE24",
            "abstract": "We present one of the first in-depth and systematic end-user centered investigations into the effects of sanctions on geoblocking, specifically in the case of Cuba. We conduct network measurements on the Tranco Top 10K domains and complement our findings with a small-scale user study with a questionnaire. We identify 546 domains subject to geoblock-ing across all layers of the network stack, ranging from DNS failures to HTTP(S) response pages with a variety of status codes. Through this work, we discover a lack of user-facing transparency; we find 88% of geoblocked domains do not serve informative notice of why they are blocked. Further, we highlight a lack of measurement-level transparency, even among HTTP(S) blockpage responses. Notably, we identify 32 instances of blockpage responses served with 200 OK status codes, despite not returning the requested content. Finally, we note the inefficacy of current improvement strategies and make recommendations to both service providers and policy-makers to reduce Internet fragmentation.",
            "keywords": [
                "Geoblocking",
                "Sanctions",
                "Cuba",
                "Internet Fragmentation",
                "User Transparency"
            ]
        },
        "url": "URL#379396",
        "sema_paperId": "383516231809b25a72cf0dafd0540d5475ece04d"
    },
    {
        "@score": "1",
        "@id": "379397",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "301/5830",
                        "text": "Bhupendra Acharya"
                    },
                    {
                        "@pid": "351/0931",
                        "text": "Dario Lazzaro"
                    },
                    {
                        "@pid": "277/7996",
                        "text": "Efr\u00e9n L\u00f3pez-Morales"
                    },
                    {
                        "@pid": "72/10989",
                        "text": "Adam Oest"
                    },
                    {
                        "@pid": "181/5807-1",
                        "text": "Muhammad Saad 0001"
                    },
                    {
                        "@pid": "274/2233",
                        "text": "Antonio Emanuele Cin\u00e0"
                    },
                    {
                        "@pid": "195/0263",
                        "text": "Lea Sch\u00f6nherr"
                    },
                    {
                        "@pid": "h/ThorstenHolz",
                        "text": "Thorsten Holz"
                    }
                ]
            },
            "title": "The Imitation Game: Exploring Brand Impersonation Attacks on Social Media Platforms.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AcharyaLLO0CSH24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/acharya",
            "url": "https://dblp.org/rec/conf/uss/AcharyaLLO0CSH24",
            "abstract": "The rise of social media users has led to an increase in customer support services offered by brands on various platforms. Unfortunately, attackers also use this as an opportunity to trick victims through fake profiles that imitate official brand accounts. In this work, we provide a comprehensive overview of such brand impersonation attacks on social media. We analyze the fake profile creation and user engagement processes on X, Instagram, Telegram, and YouTube and quantify their impact. Between May and October 2023, we collected 1.3 million user profiles, 33 million posts, and publicly available profile metadata, wherein we found 349,411 squat-ted accounts targeting 2,625 of 2,847 major international brands. Analyzing profile engagement and user creation techniques, we show that squatting profiles persistently perform various novel attacks in addition to classic abuse such as social engineering, phishing, and copyright infringement. By sharing our findings with the top 100 brands and collaborating with one of them, we further validate the real-world implications of such abuse. Our research highlights a weakness in the ability of social media platforms to protect brands and users from attacks based on username squatting. Alongside strategies such as customer education and clear indicators of trust, our detection model can be used by platforms as a countermeasure to proactively detect abusive accounts.",
            "keywords": [
                "Brand Impersonation",
                "Social Media Security",
                "User Engagement",
                "Fake Profiles",
                "Username Squatting"
            ]
        },
        "url": "URL#379397",
        "sema_paperId": "8f1af22103efae3722b86edfac04e648c9586f42"
    },
    {
        "@score": "1",
        "@id": "379398",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "a/YAfek",
                        "text": "Yehuda Afek"
                    },
                    {
                        "@pid": "b/ABremlerBarr",
                        "text": "Anat Bremler-Barr"
                    },
                    {
                        "@pid": "335/1981",
                        "text": "Shoham Danino"
                    },
                    {
                        "@pid": "83/1922",
                        "text": "Yuval Shavitt"
                    }
                ]
            },
            "title": "A Flushing Attack on the DNS Cache.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AfekBDS24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/afek",
            "url": "https://dblp.org/rec/conf/uss/AfekBDS24",
            "abstract": "To fully understand the root cause of the CacheFlushAt-tack and to analyze its effective flush rate, we developed a mini-lab setup, disconnected from the Internet, that contains all the components of the DNS system, clients, resolvers",
            "keywords": [
                "DNS Cache",
                "Cache Flush Attack",
                "DNS System",
                "Resolver",
                "Effective Flush Rate"
            ]
        },
        "url": "URL#379398",
        "sema_paperId": "552137ce62a0ff408ce69328e4154c7d3843069c"
    },
    {
        "@score": "1",
        "@id": "379399",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "32/2676",
                        "text": "Junho Ahn"
                    },
                    {
                        "@pid": "304/2237",
                        "text": "Jaehyeon Lee"
                    },
                    {
                        "@pid": "81/11176",
                        "text": "Kanghyuk Lee"
                    },
                    {
                        "@pid": "381/1632",
                        "text": "Wooseok Gwak"
                    },
                    {
                        "@pid": "381/1658",
                        "text": "Minseong Hwang"
                    },
                    {
                        "@pid": "94/8239",
                        "text": "Youngjin Kwon"
                    }
                ]
            },
            "title": "BUDAlloc: Defeating Use-After-Free Bugs by Decoupling Virtual Address Management from Kernel.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AhnLLGHK24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/ahn",
            "url": "https://dblp.org/rec/conf/uss/AhnLLGHK24",
            "abstract": "Use-after-free bugs are an important class of vulnerabilities that often pose serious security threats. To prevent or detect use-after-free bugs, one-time allocators have recently gained attention for their better performance scalability and immediate detection of use-after-free bugs compared to garbage collection approaches. This paper introduces BUDAlloc, a one-time-allocator for detecting and protecting use-after-free bugs in unmodified binaries. The core idea is co-designing a user-level allocator and kernel by separating virtual and physical address management. The user-level allocator manages virtual address layout, eliminating the need for system calls when creating virtual alias, which is essential for reducing internal fragmentation caused by the one-time-allocator. BU-DAlloc customizes the kernel page fault handler with eBPF for batching unmap requests when freeing objects. In SPEC CPU 2017, BUDAlloc achieves a 15% performance improvement over DangZero and reduces memory overhead by 61% compared to FFmalloc.",
            "keywords": [
                "Use-After-Free Bugs",
                "One-Time Allocators",
                "Virtual Address Management",
                "Kernel Customization",
                "Memory Overhead Reduction"
            ]
        },
        "url": "URL#379399",
        "sema_paperId": "225c24a7509e2894953c202caee22fa6f52d4c45"
    },
    {
        "@score": "1",
        "@id": "379400",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "198/9755",
                        "text": "Omer Akgul"
                    },
                    {
                        "@pid": "91/8283",
                        "text": "Sai Teja Peddinti"
                    },
                    {
                        "@pid": "t/NinaTaft",
                        "text": "Nina Taft"
                    },
                    {
                        "@pid": "20/7983",
                        "text": "Michelle L. Mazurek"
                    },
                    {
                        "@pid": "17/9886",
                        "text": "Hamza Harkous"
                    },
                    {
                        "@pid": "123/8658",
                        "text": "Animesh Srivastava"
                    },
                    {
                        "@pid": "185/7910",
                        "text": "Benoit Seguin"
                    }
                ]
            },
            "title": "A Decade of Privacy-Relevant Android App Reviews: Large Scale Trends.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AkgulPTMHSS24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/akgul",
            "url": "https://dblp.org/rec/conf/uss/AkgulPTMHSS24",
            "abstract": "We present an analysis of 12 million instances of privacy-relevant reviews publicly visible on the Google Play Store that span a 10 year period. By leveraging state of the art NLP techniques, we examine what users have been writing about privacy along multiple dimensions: time, countries, app types, diverse privacy topics, and even across a spectrum of emotions. We find consistent growth of privacy-relevant reviews, and explore topics that are trending (such as Data Deletion and Data Theft), as well as those on the decline (such as privacy-relevant reviews on sensitive permissions). We find that although privacy reviews come from more than 200 countries, 33 countries provide 90% of privacy reviews. We conduct a comparison across countries by examining the distribution of privacy topics a country's users write about, and find that geographic proximity is not a reliable indicator that nearby countries have similar privacy perspectives. We uncover some countries with unique patterns and explore those herein. Surprisingly, we uncover that it is not uncommon for reviews that discuss privacy to be positive (32%); many users express pleasure about privacy features within apps or privacy-focused apps. We also uncover some unexpected behaviors, such as the use of reviews to deliver privacy disclaimers to developers. Finally, we demonstrate the value of analyzing app reviews with our approach as a complement to existing methods for understanding users' perspectives about privacy.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-akgul.pdf",
            "keywords": [
                "Privacy in Mobile Apps",
                "User Reviews Analysis",
                "Privacy Trends",
                "Geographic Privacy Perspectives",
                "Privacy Features Feedback"
            ]
        },
        "url": "URL#379400"
    },
    {
        "@score": "1",
        "@id": "379401",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "319/3364",
                        "text": "Wael S. Albayaydh"
                    },
                    {
                        "@pid": "57/3469",
                        "text": "Ivan Flechais"
                    }
                ]
            },
            "title": "Co-Designing a Mobile App for Bystander Privacy Protection in Jordanian Smart Homes: A Step Towards Addressing a Complex Privacy Landscape.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AlbayaydhF24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/albayaydh",
            "url": "https://dblp.org/rec/conf/uss/AlbayaydhF24",
            "abstract": "The proliferation of smart devices fuels privacy concerns, particularly for bystanders\u2014individuals impacted by smart devices beyond their control. Existing research primarily addresses these concerns in Western contexts, with limited focus on Muslim Arab Middle-Eastern (MAME) regions like Jordan. Additionally, there is a scarcity of proposed interventions or assessments for effectively addressing, communicating, ne-gotiating, and remediating privacy issues in these contexts. This study aims to bridge this gap by investigating how a technology probe in the form of a privacy-focused mobile application can serve as an auxiliary tool to support the privacy protection of smart home bystanders in Jordan. We initiated our research by collaboratively designing the app through four focus groups involving 24 stakeholders. Sub-sequently, we present and qualitatively evaluate the app\u2019s potential for privacy protection with a diverse group of 26 representative stakeholders. While the app is generally well-received, it encounters challenges rooted in broader contextual norms and practices. Our discussion delves into these challenges, offering recommendations to enhance bystander privacy protection in Jordanian smart homes.",
            "keywords": [
                "Smart Home Privacy",
                "Bystander Privacy",
                "Mobile Application Design",
                "Privacy Protection",
                "Jordanian Context"
            ]
        },
        "url": "URL#379401",
        "sema_paperId": "108717f488e908e1fa324fe80b85aac9650992a9"
    },
    {
        "@score": "1",
        "@id": "379402",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "322/1111",
                        "text": "Mir Masood Ali"
                    },
                    {
                        "@pid": "184/3044",
                        "text": "Mohammad Ghasemisharif"
                    },
                    {
                        "@pid": "20/4340",
                        "text": "Chris Kanich"
                    },
                    {
                        "@pid": "47/8412",
                        "text": "Jason Polakis"
                    }
                ]
            },
            "title": "Rise of Inspectron: Automated Black-box Auditing of Cross-platform Electron Apps.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AliGKP24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/ali",
            "url": "https://dblp.org/rec/conf/uss/AliGKP24",
            "abstract": "Browser-based cross-platform applications have become increasingly popular as they allow software vendors to sidestep two major issues in the app ecosystem. First, web apps can be impacted by the performance deterioration affecting browsers, as the continuous adoption of diverse and complex features has led to bloating. Second, re-developing or porting apps to different operating systems and execution environments is a costly, error-prone process. Instead, frameworks like Electron allow the creation of standalone apps for different platforms using JavaScript code (e.g., reused from an existing web app) and by incorporating a stripped down and configurable browser engine. Despite the aforementioned advantages, these apps face significant security and privacy threats that are either non-applicable to traditional web apps (due to the lack of access to certain system-facing APIs) or ineffective against them (due to countermeasures already baked into browsers). In this paper we present Inspectron, an automated dynamic analysis framework that audits packaged Electron apps for potential security vulnerabilities stemming from de-velopers\u2019 deviation from recommended security practices. Our study reveals a multitude of insecure practices and problematic trends in the Electron app ecosystem, highlighting the gap filled by Inspectron as it provides extensive and comprehensive auditing capabilities for developers and researchers.",
            "keywords": [
                "Electron Apps",
                "Dynamic Analysis",
                "Security Vulnerabilities",
                "Automated Auditing",
                "Inspectron Framework"
            ]
        },
        "url": "URL#379402",
        "sema_paperId": "73bf769e9ad7a7e6ab685293511a0f45419aa312"
    },
    {
        "@score": "1",
        "@id": "379403",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "224/9407",
                        "text": "Joey Allen"
                    },
                    {
                        "@pid": "59/5806",
                        "text": "Zheng Yang"
                    },
                    {
                        "@pid": "71/1116",
                        "text": "Feng Xiao"
                    },
                    {
                        "@pid": "231/1936",
                        "text": "Matthew Landen"
                    },
                    {
                        "@pid": "60/6768",
                        "text": "Roberto Perdisci"
                    },
                    {
                        "@pid": "29/5976",
                        "text": "Wenke Lee"
                    }
                ]
            },
            "title": "WEBRR: A Forensic System for Replaying and Investigating Web-Based Attacks in The Modern Web.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AllenYXLPL24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/allen",
            "url": "https://dblp.org/rec/conf/uss/AllenYXLPL24",
            "abstract": "After a sophisticated attack or data breach occurs at an organization, a postmortem forensic analysis must be conducted to reconstruct and understand the root causes of the attack. Unfortunately, the majority of proposed forensic analysis systems rely on system-level auditing, making it difficult to reconstruct and investigate web-based attacks, due to the semantic-gap be-tween system-and web-level semantics. This limited visibility into web-based attacks has recently become increasingly concerning because web-based attacks are commonly employed by nation-state adversaries to penetrate and achieve the initial compromise of an enterprise network. To enable forensic analysts to replay and investigate web-based attacks, we propose W EB RR, a novel OS-and device-independent record-and-replay (RR) forensic auditing system for Chromium-based web browsers. While there exist prior works that focus on web-based auditing, current systems are either record-only or suffer from critical limitations that prevent them from deterministi-cally replaying attacks. W EB RR addresses these limitation by introducing a novel design that allows it to record and de-terministically replay modern web applications by leveraging JavaScript Execution Unit Partitioning . Our evaluation demonstrates that W EB RR is capable of re-playing web-based attacks that fail to replay on prior state-of-the-art systems. Furthermore, we demonstrate that W EB RR can replay highly-dynamic modern websites in a deterministic fashion with an average runtime overhead of only 3.44%.",
            "keywords": [
                "Web Forensics",
                "Record-and-Replay Systems",
                "Web-Based Attacks",
                "JavaScript Execution",
                "Deterministic Replay"
            ]
        },
        "url": "URL#379403",
        "sema_paperId": "433ea3e8cb581346c7817d4ca5bb1421f1cb00cb"
    },
    {
        "@score": "1",
        "@id": "379404",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "02/5804",
                        "text": "Mahmoud Ammar"
                    },
                    {
                        "@pid": "262/0740",
                        "text": "Ahmed Abdelraoof"
                    },
                    {
                        "@pid": "381/1678",
                        "text": "Silviu Vlasceanu"
                    }
                ]
            },
            "title": "On Bridging the Gap between Control Flow Integrity and Attestation Schemes.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AmmarAV24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/ammar",
            "url": "https://dblp.org/rec/conf/uss/AmmarAV24",
            "abstract": "Control-flow hijacking attacks remain a significant challenge in software security. Several means of protection and detection have been proposed but gaps still exist. To address such gaps, leading processor manufacturers have introduced new extensions in their latest-generation architectures, such as Pointer Authentication ( PA ) and Branch Target Identification ( BTI ) technologies in the ARMv8.5-A processor architecture. However, simply enabling these technologies would offer only limited security guarantees without trustworthy evidence of runtime integrity. To bridge this gap, we propose CFA +, a practical hardware-assisted control flow attestation mechanism with prevention capabilities. CFA + leverages ARMv8.5-A\u2019s BTI security extension in combination with selective software instrumentation to enable lightweight always-on monitoring of the execution state without the need for maintaining in-memory control flow logs. The hybrid policy of CFA + enables immediate prevention or quick detection of control-flow violations while providing trustworthy evidence of runtime integrity. CFA + offers strong security guarantees for complex software stacks while maintaining high efficiency and scalability. Evaluation results demonstrate that CFA + incurs an average runtime overhead of less than 3% when applied to various benchmark applications, including the SPEC CPU2006 suite and nginx.",
            "keywords": [
                "Control Flow Integrity",
                "Runtime Integrity",
                "Control-Flow Hijacking",
                "Hardware-Assisted Attestation",
                "CFA+"
            ]
        },
        "url": "URL#379404",
        "sema_paperId": "19e3e76cd52f5a069c2c521cfea3450778e45f75"
    },
    {
        "@score": "1",
        "@id": "379405",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "168/9413",
                        "text": "Shengwei An"
                    },
                    {
                        "@pid": "y/LuYan",
                        "text": "Lu Yan"
                    },
                    {
                        "@pid": "263/7049",
                        "text": "Siyuan Cheng 0005"
                    },
                    {
                        "@pid": "216/6403",
                        "text": "Guangyu Shen"
                    },
                    {
                        "@pid": "147/6644-2",
                        "text": "Kaiyuan Zhang 0002"
                    },
                    {
                        "@pid": "263/6785",
                        "text": "Qiuling Xu"
                    },
                    {
                        "@pid": "88/10370-1",
                        "text": "Guanhong Tao 0001"
                    },
                    {
                        "@pid": "95/3760-1",
                        "text": "Xiangyu Zhang 0001"
                    }
                ]
            },
            "title": "Rethinking the Invisible Protection against Unauthorized Image Usage in Stable Diffusion.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AnY0S0X0024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/an",
            "url": "https://dblp.org/rec/conf/uss/AnY0S0X0024",
            "abstract": "Advancements in generative AI models like Stable Diffusion, DALL\u00b7E 2, and Midjourney have revolutionized digital creativity, enabling the generation of authentic-looking images from text and altering existing images with ease. Yet, their capacity poses significant ethical challenges, including replicating an artist\u2019s style without consent, the creation of counterfeit images, and potential reputational damage through manipulated content. Protection techniques have emerged to combat misuse by injecting imperceptible noises into images. This paper introduces I NSIGHT , a novel approach that challenges the robustness of these protections by aligning protected image features with human visual perception. By using a photo as a reference, approximating the human eye\u2019s perspective, I NSIGHT effectively neutralizes protective perturbations, enabling the generative model to recapture authentic features. Our extensive evaluation across 3 datasets and 10 protection techniques demonstrates its superiority over existing methods in overcoming protective measures, emphasizing the need for stronger safeguards in digital content generation.",
            "keywords": [
                "Generative AI",
                "Image Protection",
                "Unauthorized Usage",
                "Visual Perception",
                "Robustness of Protections"
            ]
        },
        "url": "URL#379405",
        "sema_paperId": "b47c07932fe2b6ba74b35f4ee8cef39dfd00279c"
    },
    {
        "@score": "1",
        "@id": "379406",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "132/8480",
                        "text": "Sebastian Angel"
                    },
                    {
                        "@pid": "241/6379",
                        "text": "Eleftherios Ioannidis"
                    },
                    {
                        "@pid": "358/2337",
                        "text": "Elizabeth Margolin"
                    },
                    {
                        "@pid": "68/8463",
                        "text": "Srinath T. V. Setty"
                    },
                    {
                        "@pid": "298/6428",
                        "text": "Jess Woods"
                    }
                ]
            },
            "title": "Reef: Fast Succinct Non-Interactive Zero-Knowledge Regex Proofs.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AngelIMSW24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/angel",
            "url": "https://dblp.org/rec/conf/uss/AngelIMSW24",
            "abstract": "This paper presents Reef, a system for generating publicly verifiable succinct non-interactive zero-knowledge proofs that a committed document matches or does not match a regular expression. We describe applications such as proving the strength of passwords, the provenance of email despite redactions, the validity of oblivious DNS queries, and the existence of mutations in DNA. Reef supports the Perl Compatible Regular Expression syntax, including wildcards, alternation, ranges, capture groups, Kleene star, negations, and lookarounds. Reef introduces a new type of automata, Skipping Alternating Finite Automata (SAFA), that skips irrelevant parts of a document when producing proofs without undermining soundness, and instantiates SAFA with a lookup argument. Our experimental evaluation confirms that Reef can generate proofs for documents with 32M characters; the proofs are small and cheap to verify (under a second).",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-angel.pdf",
            "keywords": [
                "Zero-Knowledge Proofs",
                "Regular Expressions",
                "Succinct Proofs",
                "Automata Theory",
                "Skipping Alternating Finite Automata (SAFA)"
            ]
        },
        "url": "URL#379406"
    },
    {
        "@score": "1",
        "@id": "379407",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "353/7664",
                        "text": "Ioannis Angelakopoulos"
                    },
                    {
                        "@pid": "86/8823",
                        "text": "Gianluca Stringhini"
                    },
                    {
                        "@pid": "27/3108",
                        "text": "Manuel Egele"
                    }
                ]
            },
            "title": "Pandawan: Quantifying Progress in Linux-based Firmware Rehosting.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AngelakopoulosS24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/angelakopoulos",
            "url": "https://dblp.org/rec/conf/uss/AngelakopoulosS24",
            "abstract": "The Internet of Things (IoT) is frequently the epicenter of cyberattacks due to its weak security. Prior works introduce various techniques for analyzing the firmware of IoT devices for bugs and vulnerabilities, especially through firmware re-hosting. However, comparing the emulation outcomes of different re-hosting approaches can be very challenging. In this paper, we present Firmware Initialization Completion Detection ( FICD ), a technique that enables the comparison of full-system re-hosting approaches across their re-hosting capabilities. In addition, prior works lack an important capability; they do not focus on both the user and privileged aspect of IoT firmware as a unit. Since prior work is not capable of holistically analyzing (both the user and privileged level) IoT firmware, we develop Pandawan , a framework that enables the holistic re-hosting and analysis of IoT firmware at scale. We use FICD to illustrate Pandawan \u2019s re-hosting improvements over the state-of-the-art, such as Firmadyne, FirmAE, and FirmSolo on a dataset of 1,520 firmware images. Our experiments show that Pandawan outperforms these systems, by executing up to 6% more user level programs and 21% more user code basic blocks, on average, than these systems. Furthermore, Pandawan loads 9% more IoT kernel modules and executes 26% more kernel module basic blocks on average than FirmSolo. We also use Pandawan to holistically analyze the firmware images by inspecting the interactions (through system calls) of user level code with kernel module code. Pandawan transforms the system call information into seeds for the TriforceAFL kernel fuzzer to analyze the kernel modules within the firmware images. The TriforceAFL experiment on 479 firmware images with seeds, discovered 16 bugs on 12 binary kernel modules, 6 of which are previously unknown bugs. The bugs affect 8 closed and 4 open source kernel modules.",
            "keywords": [
                "IoT Firmware Analysis",
                "Firmware Rehosting",
                "Holistic Analysis",
                "Firmware Vulnerabilities",
                "FICD Technique"
            ]
        },
        "url": "URL#379407",
        "sema_paperId": "1388bcd048bf8e58f2fcc144fd59cc68b657009c"
    },
    {
        "@score": "1",
        "@id": "379408",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "303/3273",
                        "text": "Meenatchi Sundaram Muthu Selva Annamalai"
                    },
                    {
                        "@pid": "284/8917",
                        "text": "Georgi Ganev"
                    },
                    {
                        "@pid": "36/6225",
                        "text": "Emiliano De Cristofaro"
                    }
                ]
            },
            "title": "&quot;What do you want from theory alone?&quot; Experimenting with Tight Auditing of Differentially Private Synthetic Data Generation.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AnnamalaiGC24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/annamalai-theory",
            "url": "https://dblp.org/rec/conf/uss/AnnamalaiGC24",
            "abstract": "Differentially private synthetic data generation (DP-SDG) algorithms are used to release datasets that are structurally and statistically similar to sensitive data while providing formal bounds on the information they leak. However, bugs in algorithms and implementations may cause the actual information leakage to be higher. This prompts the need to verify whether the theoretical guarantees of state-of-the-art DP-SDG implementations also hold in practice. We do so via a rigorous auditing process: we compute the information leakage via an adversary playing a distinguishing game and running membership inference attacks (MIAs). If the leakage observed empirically is higher than the theoretical bounds, we identify a DP violation; if it is non-negligibly lower, the audit is loose.\nWe audit six DP-SDG implementations using different datasets and threat models and find that black-box MIAs commonly used against DP-SDGs are severely limited in power, yielding remarkably loose empirical privacy estimates. We then consider MIAs in stronger threat models, i.e., passive and active white-box, using both existing and newly proposed attacks. Overall, we find that, currently, we do not only need white-box MIAs but also worst-case datasets to tightly estimate the privacy leakage from DP-SDGs. Finally, we show that our automated auditing procedure finds both known DP violations (in 4 out of the 6 implementations) as well as a new one in the DPWGAN implementation that was successfully submitted to the NIST DP Synthetic Data Challenge.\nThe source code needed to reproduce our experiments is available from https://github.com/spalabucr/synth-audit.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-annamalai-theory.pdf",
            "keywords": [
                "Differential Privacy",
                "Synthetic Data Generation",
                "Information Leakage",
                "Auditing",
                "Membership Inference Attacks"
            ]
        },
        "url": "URL#379408"
    },
    {
        "@score": "1",
        "@id": "379409",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "303/3273",
                        "text": "Meenatchi Sundaram Muthu Selva Annamalai"
                    },
                    {
                        "@pid": "218/6805",
                        "text": "Andrea Gadotti"
                    },
                    {
                        "@pid": "203/7256",
                        "text": "Luc Rocher"
                    }
                ]
            },
            "title": "A Linear Reconstruction Approach for Attribute Inference Attacks against Synthetic Data.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AnnamalaiGR24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/annamalai-linear",
            "url": "https://dblp.org/rec/conf/uss/AnnamalaiGR24",
            "abstract": "Recent advances in synthetic data generation (SDG) have been hailed as a solution to the difficult problem of sharing sensitive data while protecting privacy. SDG aims to learn statistical properties of real data in order to generate \"artificial\" data that are structurally and statistically similar to sensitive data. However, prior research suggests that inference attacks on synthetic data can undermine privacy, but only for specific outlier records.\nIn this work, we introduce a new attribute inference attack against synthetic data. The attack is based on linear reconstruction methods for aggregate statistics, which target all records in the dataset, not only outliers. We evaluate our attack on state-of-the-art SDG algorithms, including Probabilistic Graphical Models, Generative Adversarial Networks, and recent differentially private SDG mechanisms. By defining a formal privacy game, we show that our attack can be highly accurate even on arbitrary records, and that this is the result of individual information leakage (as opposed to population-level inference).\nWe then systematically evaluate the tradeoff between protecting privacy and preserving statistical utility. Our findings suggest that current SDG methods cannot consistently provide sufficient privacy protection against inference attacks while retaining reasonable utility. The best method evaluated, a differentially private SDG mechanism, can provide both protection against inference attacks and reasonable utility, but only in very specific settings. Lastly, we show that releasing a larger number of synthetic records can improve utility but at the cost of making attacks far more effective.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-annamalai-linear.pdf",
            "keywords": [
                "Synthetic Data Generation",
                "Attribute Inference Attack",
                "Privacy Leakage",
                "Statistical Utility",
                "Differential Privacy"
            ]
        },
        "url": "URL#379409"
    },
    {
        "@score": "1",
        "@id": "379410",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "351/9212",
                        "text": "Raja Hasnain Anwar"
                    },
                    {
                        "@pid": "83/7270",
                        "text": "Syed Rafiul Hussain"
                    },
                    {
                        "@pid": "12/7085",
                        "text": "Muhammad Taqi Raza"
                    }
                ]
            },
            "title": "In Wallet We Trust: Bypassing the Digital Wallets Payment Security for Free Shopping.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AnwarHR24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/anwar",
            "url": "https://dblp.org/rec/conf/uss/AnwarHR24",
            "abstract": "Digital wallets are a new form of payment technology that provides a secure and convenient way of making contactless payments through smart devices. In this paper, we study the security of financial transactions made through digital wal-lets, focusing on the authentication, authorization, and access control security functions. We find that the digital payment ecosystem supports the decentralized authority delegation which is susceptible to a number of attacks. First, an attacker adds the victim\u2019s bank card into their (attacker\u2019s) wallet by exploiting the authentication method agreement procedure between the wallet and the bank. Second, they exploit the unconditional trust between the wallet and the bank, and by-pass the payment authorization. Third, they create a trap door through different payment types and violate the access control policy for the payments. The implications of these attacks are of a serious nature where the attacker can make purchases of arbitrary amounts by using the victim\u2019s bank card, despite these cards being locked and reported to the bank as stolen by the victim. We validate these findings in practice over major US banks (notably Chase, AMEX, Bank of America, and others) and three digital wallet apps (ApplePay, GPay, and PayPal). We have disclosed our findings to all the concerned parties. Finally, we propose remedies for fixing the design flaws to avoid these and other similar attacks.",
            "keywords": [
                "Digital Wallet Security",
                "Payment Authentication",
                "Authorization Bypass",
                "Access Control Vulnerabilities",
                "Bank Card Exploitation"
            ]
        },
        "url": "URL#379410",
        "sema_paperId": "18351aeca913d50c84f66e7f51069d2c87fca516"
    },
    {
        "@score": "1",
        "@id": "379411",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "208/4906",
                        "text": "Wei Ao"
                    },
                    {
                        "@pid": "55/6988",
                        "text": "Vishnu Naresh Boddeti"
                    }
                ]
            },
            "title": "AutoFHE: Automated Adaption of CNNs for Efficient Evaluation over FHE.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AoB24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/ao",
            "url": "https://dblp.org/rec/conf/uss/AoB24",
            "abstract": "Secure inference of deep convolutional neural networks (CNNs) under RNS-CKKS involves polynomial approximation of unsupported non-linear activation functions. However, existing approaches have three main limitations: 1) Inflexibility: The polynomial approximation and associated homomorphic evaluation architecture are customized manually for each CNN architecture and do not generalize to other networks. 2) Suboptimal Approximation: Each activation function is approximated instead of the function represented by the CNN. 3) Restricted Design: Either high-degree or low-degree polynomial approximations are used. The former retains high accuracy but slows down inference due to bootstrapping operations, while the latter accelerates ciphertext inference but compromises accuracy. To address these limitations, we present AutoFHE, which automatically adapts standard CNNs for secure inference under RNS-CKKS. The key idea is to adopt layerwise mixed-degree polynomial activation functions, which are optimized jointly with the homomorphic evaluation architecture in terms of the placement of bootstrapping operations. The problem is modeled within a multi-objective optimization framework to maximize accuracy and minimize the number of bootstrapping operations. AutoFHE can be applied flexibly on any CNN architecture, and it provides diverse solutions that span the trade-off between accuracy and latency. Experimental evaluation over RNS-CKKS encrypted CIFAR datasets shows that AutoFHE accelerates secure inference by 1.32x to 1.8x compared to methods employing high-degree polynomials. It also improves accuracy by up to 2.56% compared to methods using low-degree polynomials. Lastly, AutoFHE accelerates inference and improves accuracy by 103x and 3.46%, respectively, compared to CNNs under TFHE.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-ao.pdf",
            "keywords": [
                "Homomorphic Encryption",
                "RNS-CKKS",
                "Convolutional Neural Networks",
                "Polynomial Approximation",
                "Secure Inference"
            ]
        },
        "url": "URL#379411"
    },
    {
        "@score": "1",
        "@id": "379412",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "381/1617",
                        "text": "Ioannis Arkalakis"
                    },
                    {
                        "@pid": "163/9888",
                        "text": "Michalis Diamantaris"
                    },
                    {
                        "@pid": "306/1268",
                        "text": "Serafeim Moustakas"
                    },
                    {
                        "@pid": "33/2939",
                        "text": "Sotiris Ioannidis"
                    },
                    {
                        "@pid": "47/8412",
                        "text": "Jason Polakis"
                    },
                    {
                        "@pid": "129/9582",
                        "text": "Panagiotis Ilia"
                    }
                ]
            },
            "title": "Abandon All Hope Ye Who Enter Here: A Dynamic, Longitudinal Investigation of Android&apos;s Data Safety Section.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ArkalakisDMIPI24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/arkalakis",
            "url": "https://dblp.org/rec/conf/uss/ArkalakisDMIPI24",
            "abstract": "Users\u2019 growing concerns about online privacy have led to increased platform support for transparency and consent in the web and mobile ecosystems. To that end, Android recently mandated that developers must disclose what user data their applications collect and share, and that information is made available in Google Play\u2019s Data Safety section. In this paper, we provide the \ufb01rst large-scale, in-depth investigation on the veracity of the Data Safety section and its use in the Android application ecosystem. We build an automated analysis framework that dynamically exercises and analyzes applications so as to uncover discrepancies be-tween the applications\u2019 behavior and the data practices that have been reported in their Data Safety section. Our study on almost 5K applications uncovers a pervasive trend of incomplete disclosure, as 81% misrepresent their data collection and sharing practices in the Data Safety section. At the same time, 79.4% of the applications with incomplete disclosures do not ask the user to provide consent for the data they collect and share, and 78.6% of those that ask for consent disregard the users\u2019 choice. Moreover, while embedded third-party libraries are the most common offender, Data Safety discrepancies can be traced back to the application\u2019s core code in 41% of the cases. Crucially, Google\u2019s documentation contains various \u201cloopholes\u201d that facilitate incomplete disclosure of data practices. Overall, we \ufb01nd that in its current form, Android\u2019s Data Safety section does not effectively achieve its goal of increasing",
            "keywords": [
                "Android Data Safety",
                "User Privacy",
                "Data Collection Disclosure",
                "Consent Mechanisms",
                "Third-Party Libraries"
            ]
        },
        "url": "URL#379412",
        "sema_paperId": "6bed11c04b87ce41fedae346f64df95d47833c21"
    },
    {
        "@score": "1",
        "@id": "379413",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "331/2639",
                        "text": "Arjun Arunasalam"
                    },
                    {
                        "@pid": "222/5923",
                        "text": "Habiba Farrukh"
                    },
                    {
                        "@pid": "381/1671",
                        "text": "Eliz Tekcan"
                    },
                    {
                        "@pid": "143/2298",
                        "text": "Z. Berkay Celik"
                    }
                ]
            },
            "title": "Understanding the Security and Privacy Implications of Online Toxic Content on Refugees.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ArunasalamFTC24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/arunasalam",
            "url": "https://dblp.org/rec/conf/uss/ArunasalamFTC24",
            "abstract": "Deteriorating conditions in regions facing social and political turmoil have resulted in the displacement of huge populations known as refugees. Technologies such as social media have helped refugees adapt to challenges in their new homes. While prior works have investigated refugees\u2019 computer security and privacy (S&P) concerns, refugees\u2019 increasing exposure to toxic content and its implications have remained largely unexplored. In this paper, we answer how toxic content can in\ufb02u-ence refugees\u2019 S&P actions, goals, and barriers, and how their experiences shape these factors. Through semi-structured interviews with refugee liaisons ( n =12), focus groups ( n =9, 27 participants), and an online survey ( n =29) with refugees, we discover unique attack contexts (e.g., participants are targeted after responding to posts directed against refugees) and how intersecting identities (e.g., LGBTQ+, women) exacerbate attacks. In response to attacks, refugees take immediate actions (e.g., selective blocking) or long-term behavioral shifts (e.g., ensuring uploaded photos are void of landmarks) These measures minimize vulnerability and discourage attacks, among other goals, while participants acknowledge barriers to measures (e.g., anonymity impedes family reuni-\ufb01cation). Our \ufb01ndings highlight lessons in better equipping refugees to manage toxic content attacks.",
            "keywords": [
                "Online Toxic Content",
                "Refugee Security",
                "Privacy Concerns",
                "Identity-Based Attacks",
                "Behavioral Responses"
            ]
        },
        "url": "URL#379413",
        "sema_paperId": "02cf3de0a65918bcdfab1b37e68ede4bc811dada"
    },
    {
        "@score": "1",
        "@id": "379414",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "260/9262",
                        "text": "Md. Ishtiaq Ashiq"
                    },
                    {
                        "@pid": "213/7358",
                        "text": "Weitong Li"
                    },
                    {
                        "@pid": "150/5174",
                        "text": "Tobias Fiebig"
                    },
                    {
                        "@pid": "90/8396",
                        "text": "Taejoong Chung"
                    }
                ]
            },
            "title": "SPF Beyond the Standard: Management and Operational Challenges in Practice and Practical Recommendations.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AshiqLFC24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/ashiq",
            "url": "https://dblp.org/rec/conf/uss/AshiqLFC24",
            "abstract": "Since its inception in the 1970s, email has emerged as an irreplaceable medium for global communication. Despite its ubiquity, the system is plagued by security vulnerabilities, such as email spoo\ufb01ng. Among the various countermeasures, the Sender Policy Framework (SPF) remains a seminal and commonly deployed solution, working by specifying a list of authorized IP addresses for sending email. While SPF might seem simple on the surface, the practical management of its records proves to be challenging; for example, although syntactical errors are uncommon (0.4%), evaluation-phase challenges are prevalent (7.7%), leading to potential disruptions in email delivery. In our paper, we conduct a comprehensive study on the SPF extension, drawing from 17 months of weekly data snapshots that span 176 million domains across four top-level domains; we delve into the reasons behind such prevalent evaluation errors. Simultaneously, we undertake an ethical methodology to explore how SMTP servers validate SPF records and evaluate the effectiveness of widely-used software implementations. Our study unveils potential attack vectors that could be exploited for DNS ampli\ufb01cation attacks or disrupt mail distribution; for instance, we demonstrate how an attacker could temporarily impede email reception by exploiting \ufb02aws in SPF validation mechanisms. We also conduct a qualitative study among email administrators to gain insights into the practical implementation and usage of SPF and SPF validators. Based on our \ufb01ndings, we provide recommendations designed to reconcile these discrepancies and bolster the SPF ecosystem\u2019s overall security.",
            "keywords": [
                "Email Security",
                "Sender Policy Framework (SPF)",
                "Email Spoofing",
                "SPF Evaluation Errors",
                "DNS Amplification Attacks"
            ]
        },
        "url": "URL#379414",
        "sema_paperId": "87babc7665e050cdadf94a6051e7710d001abc09"
    },
    {
        "@score": "1",
        "@id": "379415",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "364/7717",
                        "text": "Asmita"
                    },
                    {
                        "@pid": "371/9761",
                        "text": "Yaroslav Oliinyk"
                    },
                    {
                        "@pid": "s/MichaelScott",
                        "text": "Michael Scott"
                    },
                    {
                        "@pid": "335/5778",
                        "text": "Ryan Tsang"
                    },
                    {
                        "@pid": "232/9671",
                        "text": "Chongzhou Fang"
                    },
                    {
                        "@pid": "63/3012",
                        "text": "Houman Homayoun"
                    }
                ]
            },
            "title": "Fuzzing BusyBox: Leveraging LLM and Crash Reuse for Embedded Bug Unearthing.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AsmitaOSTFH24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/asmita",
            "url": "https://dblp.org/rec/conf/uss/AsmitaOSTFH24",
            "abstract": "BusyBox, an open-source software bundling over 300 essential Linux commands into a single executable, is ubiquitous in Linux-based embedded devices. Vulnerabilities in BusyBox can have far-reaching consequences, affecting a wide array of devices. This research, driven by the extensive use of BusyBox, delved into its analysis. The study revealed the prevalence of older BusyBox versions in real-world embedded products, prompting us to conduct fuzz testing on BusyBox. Fuzzing, a pivotal software testing method, aims to induce crashes that are subsequently scrutinized to uncover vulnerabilities. Within this study, we introduce two techniques to fortify software testing. The first technique enhances fuzzing by leveraging Large Language Models (LLM) to generate target-specific initial seeds. Our study showed a substantial increase in crashes when using LLM-generated initial seeds, highlighting the potential of LLM to efficiently tackle the typically labor-intensive task of generating target-specific initial seeds. The second technique involves repurposing previously acquired crash data from similar fuzzed targets before initiating fuzzing on a new target. This approach streamlines the time-consuming fuzz testing process by providing crash data directly to the new target before commencing fuzzing. We successfully identified crashes in the latest BusyBox target without conducting traditional fuzzing, emphasizing the effectiveness of LLM and crash reuse techniques in enhancing software testing and improving vulnerability detection in embedded systems. Additionally, manual triaging was performed to identify the nature of crashes in the latest BusyBox.",
            "keywords": [
                "Embedded Systems",
                "Fuzz Testing",
                "BusyBox",
                "Vulnerability Detection",
                "Crash Reuse"
            ]
        },
        "url": "URL#379415",
        "sema_paperId": "b160f353c65a25e7234d675ef91febcb26711ad8"
    },
    {
        "@score": "1",
        "@id": "379416",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "180/5458",
                        "text": "Erin Avllazagaj"
                    },
                    {
                        "@pid": "139/7034",
                        "text": "Yonghwi Kwon 0001"
                    },
                    {
                        "@pid": "01/4921",
                        "text": "Tudor Dumitras"
                    }
                ]
            },
            "title": "SCAVY: Automated Discovery of Memory Corruption Targets in Linux Kernel for Privilege Escalation.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Avllazagaj0D24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/avllazagaj",
            "url": "https://dblp.org/rec/conf/uss/Avllazagaj0D24",
            "abstract": "Kernel privilege-escalation exploits typically leverage memory-corruption vulnerabilities to overwrite particular target locations. These memory corruption targets play a critical role in the exploits, as they determine which privileged resources (e.g. files, memory, and operations) the adversary may access and what privileges (e.g. read, write, and unrestricted) they may gain. While prior research has made important advances in discovering vulnerabilities and achieving privilege escalation, in practice the exploits rely on the few memory corruption targets that have been discovered manually so far. We propose S CAVY , a framework that automatically discovers memory corruption targets for privilege escalation in the Linux kernel. S CAVY \u2019s key insight lies in broadening the search scope beyond the kernel data structures explored in prior work, which focused on function pointers or pointers to structures that include them, to encompass the remaining 90% of Linux kernel structures. Additionally, the search is bug-type agnostic, as it considers any memory corruption capability. To this end, we develop novel and scalable techniques that combine fuzzing and differential analysis to automatically explore and detect privilege escalation by comparing the accessibility of resources between executions with and without corruption. This allows S CAVY to determine that corrupting a certain field puts the system in an exploitable state, independently of the vulnerability exploited. S CAVY found 955 PoC, from which we identify 17 new fields in 12 structures that can enable privilege escalation. We utilize these targets to develop 6 exploits for 5 CVE vulnerabilities. Our findings show that new memory corruption targets can change the security implications of vulnerabilities, urging researchers to proactively discover memory corruption targets.",
            "keywords": [
                "Linux Kernel",
                "Memory Corruption",
                "Privilege Escalation",
                "Automated Discovery",
                "Exploitation Targets"
            ]
        },
        "url": "URL#379416",
        "sema_paperId": "fbec42385a1e66190c392beb0236d2b667e9ddfb"
    },
    {
        "@score": "1",
        "@id": "379417",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "372/1765",
                        "text": "Abhinaya S. B."
                    },
                    {
                        "@pid": "292/9805",
                        "text": "Aafaq Sabir"
                    },
                    {
                        "@pid": "84/5118-1",
                        "text": "Anupam Das 0001"
                    }
                ]
            },
            "title": "Enabling Developers, Protecting Users: Investigating Harassment and Safety in VR.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BS024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/sb",
            "url": "https://dblp.org/rec/conf/uss/BS024",
            "abstract": "Virtual Reality (VR) has witnessed a rising issue of harassment, prompting the integration of safety controls like muting and blocking in VR applications. However, the lack of standardized safety measures across VR applications hinders their universal effectiveness, especially across contexts like socializing, gaming, and streaming. While prior research has studied safety controls in social VR applications, our user study (n = 27) takes a multi-perspective approach, examining both users' perceptions of safety control usability and effectiveness as well as the challenges that developers face in designing and deploying VR safety controls. We identify challenges VR users face while employing safety controls, such as finding users in crowded virtual spaces to block them. VR users also find controls ineffective in addressing harassment; for instance, they fail to eliminate the harassers' presence from the environment. Further, VR users find the current methods of submitting evidence for reports time-consuming and cumbersome. Improvements desired by users include live moderation and behavior tracking across VR apps; however, developers cite technological, financial, and legal obstacles to implementing such solutions, often due to a lack of awareness and high development costs. We emphasize the importance of establishing technical and legal guidelines to enhance user safety in virtual environments.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-sb.pdf",
            "keywords": [
                "Virtual Reality Safety",
                "Harassment in VR",
                "User Safety Controls",
                "Developer Challenges",
                "Moderation Solutions"
            ]
        },
        "url": "URL#379417"
    },
    {
        "@score": "1",
        "@id": "379418",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "191/3210",
                        "text": "Priyanka Badva"
                    },
                    {
                        "@pid": "190/2066",
                        "text": "Kopo M. Ramokapane"
                    },
                    {
                        "@pid": "33/4652",
                        "text": "Eleonora Pantano"
                    },
                    {
                        "@pid": "26/3330",
                        "text": "Awais Rashid"
                    }
                ]
            },
            "title": "Unveiling the Hunter-Gatherers: Exploring Threat Hunting Practices and Challenges in Cyber Defense.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BadvaRPR24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/badva",
            "url": "https://dblp.org/rec/conf/uss/BadvaRPR24",
            "abstract": "The dynamic landscape of cyber threats constantly adapts its attack patterns, successfully evading traditional defense mechanisms and operating undetected until its objectives are fulfilled. In response to these elusive threats, threat hunting has become a crucial advanced defense technique against sophisticated and concealed cyber adversaries. However, despite its significance, there remains a lack of deep understanding of the best practices and challenges associated with effective threat hunting. To address this gap, we conducted semi-structured interviews with 22 experienced threat hunters to gain deeper insights into their daily practices, challenges, and strategies to overcome them. Our findings show that threat hunters deploy various approaches, often mixing them. They argue that flexibility in their approach helps them identify subtle threat indicators that might otherwise go undetected if using only one method. Their everyday challenges range from technical challenges to people and organizational culture challenges. Based on these findings, we provide empirical insights for improving threat-hunting best practices.",
            "keywords": [
                "Threat Hunting",
                "Cyber Defense",
                "Advanced Defense Techniques",
                "Threat Detection Challenges",
                "Hunter-Gatherer Practices"
            ]
        },
        "url": "URL#379418",
        "sema_paperId": "89c6c162c55e4f071044f969dd42150325b5085e"
    },
    {
        "@score": "1",
        "@id": "379419",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "228/8451",
                        "text": "Bolton Bailey"
                    },
                    {
                        "@pid": "39/1855",
                        "text": "Andrew Miller"
                    }
                ]
            },
            "title": "Formalizing Soundness Proofs of Linear PCP SNARKs.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BaileyM24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/bailey",
            "url": "https://dblp.org/rec/conf/uss/BaileyM24",
            "abstract": "Succinct Non-interactive Arguments of Knowledge (SNARKs) have seen interest and development from the cryptographic community over recent years, and there are now constructions with very small proof size designed to work well in practice. A SNARK protocol can only be widely accepted as secure, however, if a rigorous proof of its security properties has been vetted by the community. Even then, it is sometimes the case that these security proofs are \ufb02awed, and it is then necessary for further research to identify these \ufb02aws and correct the record [39,58]. To increase the rigor of these proofs, we create a formal framework in the Lean theorem prover for representing a widespread subclass of SNARKs based on linear PCPs. We then describe a decision procedure for checking the soundness of SNARKs in this class. We program this procedure and use it to formalize the soundness proof of several different SNARK constructions, including the well-known Groth \u201916.",
            "keywords": [
                "SNARKs",
                "Linear PCPs",
                "Soundness Proofs",
                "Formal Verification",
                "Lean Theorem Prover"
            ]
        },
        "url": "URL#379419",
        "sema_paperId": "f0891d02c48c957336c1e652769e05d62639bf04"
    },
    {
        "@score": "1",
        "@id": "379421",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "332/3154",
                        "text": "Zion Leonahenahe Basque"
                    },
                    {
                        "@pid": "364/0510",
                        "text": "Ati Priya Bajaj"
                    },
                    {
                        "@pid": "353/7674",
                        "text": "Wil Gibbs"
                    },
                    {
                        "@pid": "381/1596",
                        "text": "Jude O&apos;Kain"
                    },
                    {
                        "@pid": "381/1676",
                        "text": "Derron Miao"
                    },
                    {
                        "@pid": "150/5198",
                        "text": "Tiffany Bao"
                    },
                    {
                        "@pid": "28/8280",
                        "text": "Adam Doup\u00e9"
                    },
                    {
                        "@pid": "119/7712",
                        "text": "Yan Shoshitaishvili"
                    },
                    {
                        "@pid": "127/9829",
                        "text": "Ruoyu Wang 0001"
                    }
                ]
            },
            "title": "Ahoy SAILR! There is No Need to DREAM of C: A Compiler-Aware Structuring Algorithm for Binary Decompilation.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BasqueBGOMBDS024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/basque",
            "url": "https://dblp.org/rec/conf/uss/BasqueBGOMBDS024",
            "abstract": "Contrary to prevailing wisdom, we argue that the measure of binary decompiler success is not to eliminate all gotos or reduce the complexity of the decompiled code but to get as close as possible to the original source code. Many gotos exist in the original source code (the Linux kernel version 6.1 contains 3,754) and, therefore, should be preserved during decompilation, and only spurious gotos should be removed. Fundamentally, decompilers insert spurious gotos in de-compilation because structuring algorithms fail to recover C-style structures from binary code. Through a quantitative study, we find that the root cause of spurious gotos is compiler-induced optimizations that occur at all optimization levels (17% in non-optimized compilation). Therefore, we believe that to achieve high-quality decompilation, decom-pilers must be compiler-aware to mirror (and remove) the goto-inducing optimizations. In this paper, we present a novel structuring algorithm called SAILR that mirrors the compilation pipeline of GCC and precisely inverts goto-inducing transformations. We build an open-source decompiler on angr (the ANGR DE - COMPILER ) and implement SAILR as well as otherwise-unavailable prior work (Phoenix, DREAM, and rev.ng\u2019s Combing) and evaluate them, using a new metric of how close the decompiled code structure is to the original source code, showing that SAILR markedly improves on prior work. In addition, we find that SAILR performs well on binaries compiled with non-GCC compilers, which suggests that compilers similarly implement goto-inducing transformations",
            "keywords": [
                "Binary Decompilation",
                "Compiler-Aware Analysis",
                "Structuring Algorithm",
                "Spurious Gotos",
                "SAILR"
            ]
        },
        "url": "URL#379421",
        "sema_paperId": "8981db4fd42b3cc710fdf3416638b735832c45ee"
    },
    {
        "@score": "1",
        "@id": "379422",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "324/0631",
                        "text": "Fabian B\u00e4umer"
                    },
                    {
                        "@pid": "76/6564",
                        "text": "Marcus Brinkmann"
                    },
                    {
                        "@pid": "58/5730",
                        "text": "J\u00f6rg Schwenk"
                    }
                ]
            },
            "title": "Terrapin Attack: Breaking SSH Channel Integrity By Sequence Number Manipulation.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BaumerBS24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/b%C3%A4umer",
            "url": "https://dblp.org/rec/conf/uss/BaumerBS24",
            "abstract": "The SSH protocol provides secure access to network services, particularly remote terminal login and file transfer within organizational networks and to over 15 million servers on the open internet. SSH uses an authenticated key exchange to establish a secure channel between a client and a server, which protects the confidentiality and integrity of messages sent in either direction. The secure channel prevents message manipulation, replay, insertion, deletion, and reordering. At the network level, SSH uses the Binary Packet Protocol over TCP. In this paper, we show that the SSH Binary Packet Protocol is no longer a secure channel: SSH channel integrity (INT-PST, aINT-PTXT, and INT-sfCTF) is broken for three widely used encryption modes. This allows prefix truncation attacks where encrypted packets at the beginning of the SSH channel can be deleted without the client or server noticing it. We demonstrate several real-world applications of this attack. We show that we can fully break SSH extension negotiation (RFC 8308), such that an attacker can downgrade the public key algorithms for user authentication or turn off a new countermeasure against keystroke timing attacks introduced in OpenSSH 9.5. Further, we identify an implementation flaw in AsyncSSH that, together with prefix truncation, allows an attacker to redirect the victim's login into a shell controlled by the attacker. We also performed an internet-wide scan and found that 71.6% of SSH servers support a vulnerable encryption mode, while 63.2% even list it as their preferred choice. We identify two root causes that enable these attacks: First, the SSH handshake supports optional messages that are not authenticated. Second, SSH does not reset message sequence numbers when activating encryption keys. Based on this analysis, we propose effective and backward-compatible changes to SSH that mitigate our attacks.",
            "keywords": [
                "SSH Protocol",
                "Channel Integrity",
                "Prefix Truncation Attack",
                "Encryption Vulnerabilities",
                "Key Exchange Downgrade"
            ]
        },
        "url": "URL#379422",
        "sema_paperId": "7a6b31fe51cc87e47f6a4a79a8741dc131a429a2"
    },
    {
        "@score": "1",
        "@id": "379423",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "53/5909",
                        "text": "Josh Benaloh"
                    },
                    {
                        "@pid": "57/6968",
                        "text": "Michael Naehrig"
                    },
                    {
                        "@pid": "78/1061",
                        "text": "Olivier Pereira"
                    },
                    {
                        "@pid": "w/DanSWallach",
                        "text": "Dan S. Wallach"
                    }
                ]
            },
            "title": "ElectionGuard: a Cryptographic Toolkit to Enable Verifiable Elections.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BenalohNPW24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/benaloh",
            "url": "https://dblp.org/rec/conf/uss/BenalohNPW24",
            "abstract": "ElectionGuard is a flexible set of open-source tools that\u2014when used with traditional election systems\u2014can produce end-to-end verifiable elections whose integrity can be verified by observers, candidates, media, and even voters themselves. ElectionGuard has been integrated into a variety of systems and used in actual public U.S. elections in Wisconsin, California, Idaho, Utah, and Maryland as well as in caucus elections in the U.S. Congress. It has also been used for civic voting in the Paris suburb of Neuilly-sur-Seine and for an online election by a Switzerland/Denmark-based organization.\nThe principal innovation of ElectionGuard is the separation of the cryptographic tools from the core mechanics and user interfaces of voting systems. This separation allows the cryptography to be designed and built by security experts without having to re-invent and replace the existing infrastructure. Indeed, in its preferred deployment, ElectionGuard does not replace the existing vote counting infrastructure but instead runs alongside and produces its own independently-verifiable tallies.  Although much of the cryptography in ElectionGuard is, by design, not novel, some significant innovations are introduced which greatly simplify the process of verification.\nThis paper describes the design of ElectionGuard, its innovations, and many of the learnings from its implementation and growing number of real-world deployments.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-benaloh.pdf",
            "keywords": [
                "Election Security",
                "Cryptographic Tools",
                "End-to-End Verification",
                "Voting Integrity",
                "Real-World Deployments"
            ]
        },
        "url": "URL#379423"
    },
    {
        "@score": "1",
        "@id": "379424",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "76/8574",
                        "text": "Pedro Bernardo"
                    },
                    {
                        "@pid": "213/8814",
                        "text": "Lorenzo Veronese"
                    },
                    {
                        "@pid": "381/1621",
                        "text": "Valentino Dalla Valle"
                    },
                    {
                        "@pid": "89/9526",
                        "text": "Stefano Calzavara"
                    },
                    {
                        "@pid": "117/7980",
                        "text": "Marco Squarcina"
                    },
                    {
                        "@pid": "69/3516",
                        "text": "Pedro Ad\u00e3o"
                    },
                    {
                        "@pid": "25/3571",
                        "text": "Matteo Maffei"
                    }
                ]
            },
            "title": "Web Platform Threats: Automated Detection of Web Security Issues With WPT.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BernardoVVCSAM24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/bernardo",
            "url": "https://dblp.org/rec/conf/uss/BernardoVVCSAM24",
            "abstract": "We present a practical framework to formally and automatically detect security flaws in client-side security mechanisms. In particular, we leverage Web Platform Tests (WPT), a popular cross-browser test suite, to automatically collect browser execution traces and match them against Web invariants, i.e., intended security properties of Web mechanisms expressed in first-order logic. We demonstrate the effectiveness of our approach by validating 9 invariants against the WPT test suite, discovering violations with clear security implications in 104 tests for Firefox, Chromium and Safari. This artifact includes the source code of all the components of the trace verification pipeline and the execution traces and outputs for all experiments presented in the paper. In particular, all violations discovered in the WPT tests (Sec 5.1) and the new testing suite used to assess the impact of the comprehensiveness of tests on the pipeline results (Sec 5.3). To support the independent validation of the results, the artifact includes scripts to re-execute the pipeline on the violating tests.",
            "keywords": [
                "Web Platform Tests",
                "Client-side Security",
                "Security Flaws Detection",
                "Execution Traces",
                "Web Invariants"
            ]
        },
        "url": "URL#379424",
        "sema_paperId": "097e09790653ddcca9108d4288428712735e2d21"
    },
    {
        "@score": "1",
        "@id": "379426",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "340/9951",
                        "text": "Mazal Bethany"
                    },
                    {
                        "@pid": "367/1891",
                        "text": "Brandon Wherry"
                    },
                    {
                        "@pid": "367/0853",
                        "text": "Emet Bethany"
                    },
                    {
                        "@pid": "194/5621",
                        "text": "Nishant Vishwamitra"
                    },
                    {
                        "@pid": "133/1827",
                        "text": "Anthony Rios"
                    },
                    {
                        "@pid": "263/1357",
                        "text": "Peyman Najafirad"
                    }
                ]
            },
            "title": "Deciphering Textual Authenticity: A Generalized Strategy through the Lens of Large Language Semantics for Detecting Human vs. Machine-Generated Text.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BethanyWBVRN24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/bethany",
            "url": "https://dblp.org/rec/conf/uss/BethanyWBVRN24",
            "abstract": "With the recent proliferation of Large Language Models (LLMs), there has been an increasing demand for tools to detect machine-generated text. The effective detection of machine-generated text face two pertinent problems: First, they are severely limited in generalizing against real-world scenarios, where machine-generated text is produced by a variety of generators and spans diverse domains. Second, existing detection methodologies treat texts produced by LLMs through a restrictive binary classification lens, neglecting the nuanced diversity of artifacts generated by different LLMs, each of which exhibits distinctive stylistic and structural elements. In this work, we undertake a systematic study on the detection of machine-generated text in real-world scenarios. We first study the effectiveness of state-of-the-art approaches and find that they are severely limited against text produced by diverse generators and domains in the real world. Furthermore, t-SNE visualizations of the embeddings from a pretrained LLM's encoder show that they cannot reliably distinguish between human and machine-generated text. Based on our findings, we introduce a novel system, T5LLMCipher, for detecting machine-generated text using a pretrained T5 encoder combined with LLM embedding sub-clustering to address the text produced by diverse generators and domains in the real world. We evaluate our approach across 9 machine-generated text systems and 9 domains and find that our approach provides state-of-the-art generalization ability, with an average increase in F1 score on machine-generated text of 11.9% on unseen generators and domains compared to the top performing supervised learning approaches and correctly attributes the generator of text with an accuracy of 93.6%. We make the code for our proposed approach publicly available at https: //github.com/SecureAIAutonomyLab/LLM-Cipher",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-bethany.pdf",
            "keywords": [
                "Textual Authenticity",
                "Machine-Generated Text Detection",
                "Large Language Models",
                "Text Classification",
                "Generator Attribution"
            ]
        },
        "url": "URL#379426"
    },
    {
        "@score": "1",
        "@id": "379427",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "80/3503",
                        "text": "Karthikeyan Bhargavan"
                    },
                    {
                        "@pid": "195/3195",
                        "text": "Charlie Jacomme"
                    },
                    {
                        "@pid": "12/10661",
                        "text": "Franziskus Kiefer"
                    },
                    {
                        "@pid": "379/2047",
                        "text": "Rolfe Schmidt"
                    }
                ]
            },
            "title": "Formal verification of the PQXDH Post-Quantum key agreement protocol for end-to-end secure messaging.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BhargavanJKS24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/bhargavan",
            "url": "https://dblp.org/rec/conf/uss/BhargavanJKS24",
            "abstract": "The Signal Messenger recently introduced a new asynchronous key agreement protocol called PQXDH (Post-Quantum Extended Diffie-Hellman) that seeks to provide post-quantum forward secrecy, in addition to the authentication and confidentiality guarantees already provided by the previous X3DH (Extended Diffie-Hellman) protocol. More precisely, PQXDH seeks to protect the confidentiality of messages against harvest-now-decrypt-later attacks. In this work, we formally specify the PQXDH protocol and analyze its security using two formal verification tools, P ROVERIF and C RYPTO V ERIF . In particular, we ask whether PQXDH preserves the guarantees of X3DH, whether it provides post-quantum forward secrecy, and whether it can be securely deployed alongside X3DH. Our analysis identifies several flaws and potential vulnerabilities in the PQXDH specification, although these vulnerabilities are not exploitable in the Signal application, thanks to specific implementation choices which we describe in this paper. To prove the security of the current implementation, our analysis notably highlighted the need for an additional binding property of the KEM, which we formally define and prove for Kyber. We collaborated with the protocol designers to develop an updated protocol specification based on our findings, where each change was formally verified and validated with a security proof. This work identifies some pitfalls that the community should be aware of when upgrading protocols to be post-quantum secure. It also demonstrates the utility of using formal verification hand-in-hand with protocol design.",
            "keywords": [
                "Post-Quantum Cryptography",
                "Key Agreement Protocols",
                "Formal Verification",
                "PQXDH Protocol",
                "Forward Secrecy"
            ]
        },
        "url": "URL#379427",
        "sema_paperId": "9ba6436038321864f0f9f656fb23c67fb5b1acba"
    },
    {
        "@score": "1",
        "@id": "379428",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "85/150",
                        "text": "Nataliia Bielova"
                    },
                    {
                        "@pid": "381/1604",
                        "text": "Laura Litvine"
                    },
                    {
                        "@pid": "381/1660",
                        "text": "Anysia Nguyen"
                    },
                    {
                        "@pid": "381/1605",
                        "text": "Mariam Chammat"
                    },
                    {
                        "@pid": "94/1586",
                        "text": "Vincent Toubiana"
                    },
                    {
                        "@pid": "381/1629",
                        "text": "Estelle Hary"
                    }
                ]
            },
            "title": "The Effect of Design Patterns on (Present and Future) Cookie Consent Decisions.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BielovaLNCTH24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/bielova",
            "url": "https://dblp.org/rec/conf/uss/BielovaLNCTH24",
            "abstract": "Today most websites in the EU present users with a consent banner asking about the use of cookies or other tracking technologies. Data Protection Authorities (DPAs) need to ensure that users can express their true preferences when faced with these banners, while simultaneously satisfying the EU GDPR requirements. To address the needs of the French DPA, we conducted an online experiment among 3,947 participants in France exploring the impact of six different consent banner designs on the outcome of users\u2019 consent decision. We also assessed participants\u2019 knowledge and privacy preferences, as well as satisfaction with the banners. In contrast with previous results, we found that a \u201cbright pattern\u201d that highlights the decline option has a substantial effect on users\u2019 decisions. We also find that two new designs based on behavioral levers have the strongest effect on the outcome of the consent decision, and participants\u2019 satisfaction with the banners. Finally, our study provides novel evidence that the effect of design persists in a short time frame: designs can significantly affect users\u2019 future choices, even when faced with neutral banners.",
            "keywords": [
                "Cookie Consent",
                "User Preferences",
                "Consent Banner Design",
                "Data Protection",
                "GDPR Compliance"
            ]
        },
        "url": "URL#379428",
        "sema_paperId": "310aee576174e275c26aceef3e4207c7d96629f5"
    },
    {
        "@score": "1",
        "@id": "379429",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "275/2933",
                        "text": "Alexander Bienstock"
                    },
                    {
                        "@pid": "04/773",
                        "text": "Sarvar Patel"
                    },
                    {
                        "@pid": "175/1759",
                        "text": "Joon Young Seo"
                    },
                    {
                        "@pid": "176/7649",
                        "text": "Kevin Yeo"
                    }
                ]
            },
            "title": "Batch PIR and Labeled PSI with Oblivious Ciphertext Compression.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BienstockPSY24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/bienstock",
            "url": "https://dblp.org/rec/conf/uss/BienstockPSY24",
            "abstract": "In this paper, we study two problems: oblivious compression and decompression of ciphertexts. In oblivious compression, a server holds a set of ciphertexts with a subset of encryptions  of zeroes whose positions are only known to the client. The goal is for the server to effectively compress the ciphertexts  obliviously, while preserving the non-zero plaintexts and without learning the plaintext values. For oblivious decompression,  the client, instead, succinctly encodes a sequence of plaintexts such that the server may decode encryptions of all plaintexts value, but the zeroes may be replaced with arbitrary values. We present solutions to both problems that construct lossless compressions as small as only 5% more than the optimal  minimum using only additive homomorphism. The crux of both algorithms involve embedding ciphertexts as random linear systems that are efficiently solvable.\nUsing our compression schemes, we obtain state-of-the-art schemes for batch private information retrieval (PIR) where a client wishes to privately retrieve multiple entries from a server-held database in one query. We show that our compression  schemes may be used to reduce communication by up to 30% for batch PIR in both the single and two-server settings.Additionally, we study labeled private set intersection (PSI) in the unbalanced setting where one party's set is significantly smaller than the other party's set and each entry has associated  data. By utilizing our novel compression algorithm, we present a protocol with 65-88% reduction in communication with comparable computation compared to prior works.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-bienstock.pdf",
            "keywords": [
                "Oblivious Compression",
                "Ciphertext Decompression",
                "Batch Private Information Retrieval",
                "Labeled Private Set Intersection",
                "Homomorphic Encryption"
            ]
        },
        "url": "URL#379429"
    },
    {
        "@score": "1",
        "@id": "379430",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "375/5584",
                        "text": "Robin Bisping"
                    },
                    {
                        "@pid": "331/2527",
                        "text": "Johannes Willbold"
                    },
                    {
                        "@pid": "117/8959",
                        "text": "Martin Strohmeier"
                    },
                    {
                        "@pid": "75/5939",
                        "text": "Vincent Lenders"
                    }
                ]
            },
            "title": "Wireless Signal Injection Attacks on VSAT Satellite Modems.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BispingWSL24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/bisping",
            "url": "https://dblp.org/rec/conf/uss/BispingWSL24",
            "abstract": "This work considers the threat model of wireless signal injection attacks on Very Small Aperture Terminals (VSAT) satellite modems. In particular, we investigate the feasibility to inject malicious wireless signals from a transmitter on the ground in order to compromise and manipulate the control of close-by satellite terminals. Based on a case study with a widely used commercial modem device, we find that VSATs are not designed to withstand simple signal injection attacks. The modems assume that any received signal comes from a legitimate satellite. We show that an attacker equipped with a low-cost software-defined radio (SDR) can inject arbitrary IP traffic into the internal network of the terminal. We explore different attacks that aim to deny service, manipulate the modem\u2019s firmware, or gain a remote admin shell. Further, we quantify their probability of success depending on the wireless channel conditions and the placement of the attacker versus the angle of arrival of the signal at the antenna dish of the receiver.",
            "keywords": [
                "VSAT Security",
                "Signal Injection Attacks",
                "Satellite Modems",
                "Malicious Wireless Signals",
                "Firmware Manipulation"
            ]
        },
        "url": "URL#379430",
        "sema_paperId": "af2b0d7b77d0d1c1b4a23c96249affbfc1b3293e"
    },
    {
        "@score": "1",
        "@id": "379431",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "144/6602",
                        "text": "Cecylia Bocovich"
                    },
                    {
                        "@pid": "131/6501",
                        "text": "Arlo Breault"
                    },
                    {
                        "@pid": "116/4822",
                        "text": "David Fifield"
                    },
                    {
                        "@pid": "381/1675",
                        "text": "Serene"
                    },
                    {
                        "@pid": "58/8838",
                        "text": "Xiaokang Wang"
                    }
                ]
            },
            "title": "Snowflake, a censorship circumvention system using temporary WebRTC proxies.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BocovichBFSW24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/bocovich",
            "url": "https://dblp.org/rec/conf/uss/BocovichBFSW24",
            "abstract": "Snowflake is a system for circumventing Internet censorship. Its blocking resistance comes from the use of numerous, ultra-light, temporary proxies (\"snowflakes\"), which accept traffic from censored clients using peer-to-peer WebRTC protocols and forward it to a centralized bridge. The temporary proxies are simple enough to be implemented in JavaScript, in a web page or browser extension, making them much cheaper to run than a traditional proxy or VPN server. The large and changing pool of proxy addresses resists enumeration and blocking by a censor. The system is designed with the assumption that proxies may appear or disappear at any time. Clients discover proxies dynamically using a secure rendezvous protocol. When an in-use proxy goes offline, its client switches to another on the fly, invisibly to upper network layers.\nSnowflake has been deployed with success in Tor Browser and Orbot for several years. It has been a significant circumvention tool during high-profile network disruptions, including in Russia in 2021 and Iran in 2022. In this paper, we explain the composition of Snowflake's many parts, give a history of deployment and blocking attempts, and reflect on implications for circumvention generally.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-bocovich.pdf",
            "keywords": [
                "Censorship Circumvention",
                "WebRTC Proxies",
                "Peer-to-Peer Networking",
                "Internet Freedom",
                "Dynamic Proxy Discovery"
            ]
        },
        "url": "URL#379431",
        "sema_paperId": "0817cbaf93feeb91e0c805c5cc223f2ea7f34f77"
    },
    {
        "@score": "1",
        "@id": "379432",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "325/3751",
                        "text": "Marton Bognar"
                    },
                    {
                        "@pid": "381/1570",
                        "text": "Cas Magnus"
                    },
                    {
                        "@pid": "85/6647",
                        "text": "Frank Piessens"
                    },
                    {
                        "@pid": "167/1573",
                        "text": "Jo Van Bulck"
                    }
                ]
            },
            "title": "Intellectual Property Exposure: Subverting and Securing Intellectual Property Encapsulation in Texas Instruments Microcontrollers.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BognarMPB24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/bognar",
            "url": "https://dblp.org/rec/conf/uss/BognarMPB24",
            "abstract": "In contrast to high-end computing platforms, specialized memory protection features in low-end embedded devices remain relatively unexplored despite the ubiquity of these devices. Hence, we perform an in-depth security evaluation of the state-of-the-art Intellectual Property Encapsulation (IPE) technology found in widely used off-the-shelf, Texas Instruments MSP430 microcontrollers. While we find IPE to be promising, bearing remarkable similarities with trusted execution environments (TEEs) from research and industry, we reveal several fundamental protection shortcomings in current IPE hardware. We show that many software-level attack techniques from the academic TEE literature apply to this platform, and we discover a novel attack primitive, dubbed controlled call corruption , exploiting a vulnerability in the IPE access con-trol mechanism. Our practical, end-to-end attack scenarios demonstrate a complete bypass of confidentiality and integrity guarantees of IPE-protected programs. Informed by our systematic attack study on IPE and root-cause analysis, also considering related research prototypes, we propose lightweight hardware changes to secure IPE. Furthermore, we develop a prototype framework that transparently implements software responsibilities to reduce information leakage and repurposes the onboard memory protection unit to reinstate IPE security guarantees on currently vulnerable devices with low performance overheads.",
            "keywords": [
                "Embedded Security",
                "Intellectual Property Encapsulation",
                "Texas Instruments MSP430",
                "Controlled Call Corruption",
                "Memory Protection"
            ]
        },
        "url": "URL#379432",
        "sema_paperId": "62c2a11896bc906e3b2b246666b6003efd42a3a2"
    },
    {
        "@score": "1",
        "@id": "379434",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "280/6860",
                        "text": "Arthur Borem"
                    },
                    {
                        "@pid": "236/2322",
                        "text": "Elleen Pan"
                    },
                    {
                        "@pid": "381/1652",
                        "text": "Olufunmilola Obielodan"
                    },
                    {
                        "@pid": "381/1592",
                        "text": "Aurelie Roubinowitz"
                    },
                    {
                        "@pid": "374/9726",
                        "text": "Luca Dovichi"
                    },
                    {
                        "@pid": "20/7983",
                        "text": "Michelle L. Mazurek"
                    },
                    {
                        "@pid": "66/9786",
                        "text": "Blase Ur"
                    }
                ]
            },
            "title": "Data Subjects&apos; Reactions to Exercising Their Right of Access.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BoremPORDMU24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/borem",
            "url": "https://dblp.org/rec/conf/uss/BoremPORDMU24",
            "abstract": "Recent privacy laws have strengthened data subjects' right to access personal data collected by companies. Prior work has found that data exports companies provide consumers in response to Data Subject Access Requests (DSARs) can be overwhelming and hard to understand. To identify directions for improving the user experience of data exports, we conducted an online study in which 33 participants explored their own data from Amazon, Facebook, Google, Spotify, or Uber. Participants articulated questions they hoped to answer using the exports. They also annotated parts of the export they found confusing, creepy, interesting, or surprising. While participants hoped to learn either about their own usage of the platform or how the company collects and uses their personal data, these questions were often left unanswered. Participants' annotations documented their excitement at finding data records that triggered nostalgia, but also shock and anger about the privacy implications of other data they saw. Having examining their data, many participants hoped to request the company erase some, but not all, of the data. We discuss opportunities for future transparency-enhancing tools and enhanced laws.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-borem.pdf",
            "keywords": [
                "Data Subject Access Requests",
                "User Experience",
                "Data Privacy",
                "Data Transparency",
                "Consumer Reactions"
            ]
        },
        "url": "URL#379434",
        "sema_paperId": "1d94865b15ef67369eb2c03a3734ae5522452fd6"
    },
    {
        "@score": "1",
        "@id": "379435",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "367/9379",
                        "text": "Pallavi Borkar"
                    },
                    {
                        "@pid": "65/4423",
                        "text": "Chen Chen"
                    },
                    {
                        "@pid": "367/9214",
                        "text": "Mohamadreza Rostami"
                    },
                    {
                        "@pid": "301/9146",
                        "text": "Nikhilesh Singh"
                    },
                    {
                        "@pid": "295/3339",
                        "text": "Rahul Kande"
                    },
                    {
                        "@pid": "s/AhmadRezaSadeghi",
                        "text": "Ahmad-Reza Sadeghi"
                    },
                    {
                        "@pid": "37/4129",
                        "text": "Chester Rebeiro"
                    },
                    {
                        "@pid": "79/9006",
                        "text": "Jeyavijayan Rajendran"
                    }
                ]
            },
            "title": "WhisperFuzz: White-Box Fuzzing for Detecting and Locating Timing Vulnerabilities in Processors.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BorkarCRSKSRR24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/borkar",
            "url": "https://dblp.org/rec/conf/uss/BorkarCRSKSRR24",
            "abstract": "Timing vulnerabilities in processors have emerged as a potent threat. As processors are the foundation of any computing system, identifying these flaws is imperative. Recently fuzzing techniques, traditionally used for detecting software vulnerabilities, have shown promising results for uncovering vulnerabilities in large-scale hardware designs, such as processors. Researchers have adapted black-box or grey-box fuzzing to detect timing vulnerabilities in processors. However, they cannot identify the locations or root causes of these timing vulnerabilities, nor do they provide coverage feedback to enable the designer's confidence in the processor's security. To address the deficiencies of the existing fuzzers, we present WhisperFuzz--the first white-box fuzzer with static analysis--aiming to detect and locate timing vulnerabilities in processors and evaluate the coverage of microarchitectural timing behaviors. WhisperFuzz uses the fundamental nature of processors' timing behaviors, microarchitectural state transitions, to localize timing vulnerabilities. WhisperFuzz automatically extracts microarchitectural state transitions from a processor design at the register-transfer level (RTL) and instruments the design to monitor the state transitions as coverage. Moreover, WhisperFuzz measures the time a design-under-test (DUT) takes to process tests, identifying any minor, abnormal variations that may hint at a timing vulnerability. WhisperFuzz detects 12 new timing vulnerabilities across advanced open-sourced RISC-V processors: BOOM, Rocket Core, and CVA6. Eight of these violate the zero latency requirements of the Zkt extension and are considered serious security vulnerabilities. Moreover, WhisperFuzz also pinpoints the locations of the new and the existing vulnerabilities.",
            "keywords": [
                "Timing Vulnerabilities",
                "White-Box Fuzzing",
                "Microarchitectural State Transitions",
                "Processor Security",
                "RISC-V Processors"
            ]
        },
        "url": "URL#379435",
        "sema_paperId": "7681e3723c5ae33665d6352671af6026f4f09e70"
    },
    {
        "@score": "1",
        "@id": "379436",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "191/4595",
                        "text": "Ahmed Bouhoula"
                    },
                    {
                        "@pid": "233/8369-1",
                        "text": "Karel Kubicek 0001"
                    },
                    {
                        "@pid": "354/0900",
                        "text": "Amit Zac"
                    },
                    {
                        "@pid": "150/0652",
                        "text": "Carlos Cotrini"
                    },
                    {
                        "@pid": "b/DavidABasin",
                        "text": "David A. Basin"
                    }
                ]
            },
            "title": "Automated Large-Scale Analysis of Cookie Notice Compliance.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Bouhoula0ZCB24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/bouhoula",
            "url": "https://dblp.org/rec/conf/uss/Bouhoula0ZCB24",
            "abstract": "Privacy regulations such as the General Data Protection Regulation ( GDPR ) require websites to inform EU-based users about non-essential data collection and to request their consent to this practice. Previous studies have documented widespread violations of these regulations. However, these studies provide a limited view of the general compliance picture: they are either restricted to a subset of notice types, detect only simple violations using prescribed patterns, or analyze notices manually. Thus, they are restricted both in their scope and in their ability to analyze violations at scale. We present the first general, automated, large-scale analysis of cookie notice compliance. Our method interacts with cookie notices, e.g., by navigating through their settings. It observes declared processing purposes and available consent options using Natural Language Processing and compares them to the actual use of cookies. By virtue of the generality and scale of our analysis, we correct for the selection bias present in previous studies focusing on specific Consent Management Platforms ( CMP ). We also provide a more general view of the overall compliance picture using a set of 97k web-sites popular in the EU. We report, in particular, that 65.4% of websites offering a cookie rejection option likely collect user data despite explicit negative consent.",
            "keywords": [
                "Cookie Notice Compliance",
                "Privacy Regulations",
                "User Consent",
                "Data Collection Violations",
                "Automated Analysis"
            ]
        },
        "url": "URL#379436",
        "sema_paperId": "c1bd8b2eedee839f007053edf812e4a7d684cbd0"
    },
    {
        "@score": "1",
        "@id": "379437",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "01/3339",
                        "text": "Michael D. Brown"
                    },
                    {
                        "@pid": "154/7990",
                        "text": "Adam Meily"
                    },
                    {
                        "@pid": "365/6407",
                        "text": "Brian Fairservice"
                    },
                    {
                        "@pid": "230/4213",
                        "text": "Akshay Sood"
                    },
                    {
                        "@pid": "142/3204",
                        "text": "Jonathan Dorn"
                    },
                    {
                        "@pid": "365/6298",
                        "text": "Eric Kilmer"
                    },
                    {
                        "@pid": "365/6747",
                        "text": "Ronald Eytchison"
                    }
                ]
            },
            "title": "A Broad Comparative Evaluation of Software Debloating Tools.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BrownMFSDKE24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/brown",
            "url": "https://dblp.org/rec/conf/uss/BrownMFSDKE24",
            "abstract": "Software debloating tools seek to improve program security and performance by removing unnecessary code, called bloat. While many techniques have been proposed, several barriers to their adoption have emerged. Namely, debloating tools are highly specialized, making it difficult for adopters to find the right type of tool for their needs. This is further hindered by a lack of established metrics and comparative evaluations between tools. To close this information gap, we surveyed 10 years of debloating literature and several tools currently under commercial development to taxonomize knowledge about the debloating ecosystem. We then conducted a broad comparative evaluation of 10 debloating tools to determine their relative strengths and weaknesses. Our evaluation, conducted on a diverse set of 20 benchmark programs, measures tools across 12 performance, security, and correctness metrics.\nOur evaluation surfaces several concerning findings that contradict the prevailing narrative in the debloating literature. First, debloating tools lack the maturity required to be used on real-world software, evidenced by a slim 22% overall success rate for creating passable debloated versions of medium- and high-complexity benchmarks. Second, debloating tools struggle to produce sound and robust programs. Using our novel differential fuzzing tool, DIFFER, we discovered that only 13% of our debloating attempts produced a sound and robust debloated program. Finally, our results indicate that debloating tools typically do not improve the performance or security posture of debloated programs by a significant degree according to our evaluation metrics. We believe that our contributions in this paper will help potential adopters better understand the landscape of tools and will motivate future research and development of more capable debloating tools. To this end, we have made our benchmark set, data, and custom tools publicly available.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-brown.pdf",
            "keywords": [
                "Software Debloating",
                "Debloating Tools",
                "Performance Evaluation",
                "Security Metrics",
                "Program Robustness"
            ]
        },
        "url": "URL#379437"
    },
    {
        "@score": "1",
        "@id": "379438",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "294/4488",
                        "text": "Alexander Bulekov"
                    },
                    {
                        "@pid": "61/3234-34",
                        "text": "Qiang Liu 0034"
                    },
                    {
                        "@pid": "27/3108",
                        "text": "Manuel Egele"
                    },
                    {
                        "@pid": "31/1273",
                        "text": "Mathias Payer"
                    }
                ]
            },
            "title": "HYPERPILL: Fuzzing for Hypervisor-bugs by leveraging the Hardware Virtualization Interface.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BulekovLEP24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/bulekov",
            "url": "https://dblp.org/rec/conf/uss/BulekovLEP24",
            "abstract": "The security guarantees of cloud computing depend on the isolation guarantees of the underlying hypervisors. Prior works have presented effective methods for automatically identifying vulnerabilities in hypervisors. However, these approaches are limited in scope. For instance, their implementation is typically hypervisor-specific and limited by requirements for detailed grammars, access to source-code, and assumptions about hypervisor behaviors. In practice, complex closed-source and recent open-source hypervisors are often not suitable for off-the-shelf fuzzing techniques. H YPER P ILL introduces a generic approach for fuzzing arbitrary hypervisors. H YPER P ILL leverages the insight that although hypervisor implementations are diverse, all hypervi-sors rely on the identical underlying hardware-virtualization interface to manage virtual-machines. To take advantage of the hardware-virtualization interface, H YPER P ILL makes a snapshot of the hypervisor, inspects the snapshotted hardware state to enumerate the hypervisor\u2019s input-spaces, and leverages feedback-guided snapshot-fuzzing within an emulated environment to identify vulnerabilities in arbitrary hypervi-sors. In our evaluation, we found that beyond being the first hypervisor-fuzzer capable of identifying vulnerabilities in arbitrary hypervisors across all major attack-surfaces (i.e., PIO/MMIO/Hypercalls/DMA), H YPER P ILL also outperforms state-of-the-art approaches that rely on access to source-code, due to the granularity of feedback provided by H YPER P ILL \u2019s emulation-based approach. In terms of coverage, H YPER P",
            "keywords": [
                "Hypervisor Security",
                "Fuzzing Techniques",
                "Hardware Virtualization Interface",
                "Vulnerability Identification",
                "Snapshot-Fuzzing"
            ]
        },
        "url": "URL#379438",
        "sema_paperId": "09bb7e61142cb53011a336017a6ae27d6902ca16"
    },
    {
        "@score": "1",
        "@id": "379439",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "204/4058",
                        "text": "Marcel Busch"
                    },
                    {
                        "@pid": "204/9464",
                        "text": "Philipp Mao"
                    },
                    {
                        "@pid": "31/1273",
                        "text": "Mathias Payer"
                    }
                ]
            },
            "title": "Spill the TeA: An Empirical Study of Trusted Application Rollback Prevention on Android Smartphones.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BuschMP24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/busch-tea",
            "url": "https://dblp.org/rec/conf/uss/BuschMP24",
            "abstract": "The number and complexity of Trusted Applications (TAs, applications running in Trusted Execution Environments\u2014 TEEs) deployed on mobile devices has exploded. A vulnerability in a single TA impacts the security of the entire device. Thus, vendors must rapidly \ufb01x such vulnerabilities and revoke vulnerable versions to prevent rollback attacks , i.e., loading an old version of the TA to exploit a known vulnerability. In this paper, we assess the state of TA rollback prevention by conducting a large-scale cross-vendor study. First, we establish the largest TA dataset in existence, encompassing 35,541 TAs obtained from 1,330 \ufb01rmware images deployed on mobile devices across the top \ufb01ve most common vendors. Second, we identify 37 TA vulnerabilities that we leverage to assess the state of industry-wide TA rollback effectiveness. Third, we make the counterintuitive discovery that the un-coordinated usage of rollback prevention correlates with the leakage of security-critical information and has far-reaching consequences potentially negatively impacting the whole mobile ecosystem . Fourth, we demonstrate the severity of ineffective TA rollback prevention by exploiting two different TEEs on fully-updated mobile devices. In summary, our re-sults indicate severe de\ufb01ciencies in TA rollback prevention across the mobile ecosystem.",
            "keywords": [
                "Trusted Applications",
                "Rollback Prevention",
                "Trusted Execution Environments",
                "Vulnerability Assessment",
                "Mobile Ecosystem Security"
            ]
        },
        "url": "URL#379439",
        "sema_paperId": "1cc70214cb70110c7ee1c1375b51b8419d16dd42"
    },
    {
        "@score": "1",
        "@id": "379440",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "204/4058",
                        "text": "Marcel Busch"
                    },
                    {
                        "@pid": "204/9464",
                        "text": "Philipp Mao"
                    },
                    {
                        "@pid": "31/1273",
                        "text": "Mathias Payer"
                    }
                ]
            },
            "title": "GlobalConfusion: TrustZone Trusted Application 0-Days by Design.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BuschMP24a",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/busch-globalconfusion",
            "url": "https://dblp.org/rec/conf/uss/BuschMP24a",
            "abstract": "Trusted Execution Environments form the backbone of mobile device security architectures. The GlobalPlatform Internal Core API is the de-facto standard that unites the fragmented landscape of real-world implementations, providing compatibility between different TEEs. Unfortunately, our research reveals that this API standard is prone to a design weakness. Manifestations of this weakness result in critical type-confusion bugs in real-world user-space applications of the TEE, called Trusted Applications (TAs). At its core, the design weakness consists of a fail-open design leaving an optional type check for untrusted data to TA developers. The API does not mandate this easily forgettable check that in most cases results in arbitrary read-and-write exploitation primitives. To detect instances of these type-confusion bugs, we design and implement GPCheck, a static binary analysis system capable of vetting real-world TAs. We employ GPCheck to analyze 14,777 TAs deployed on widely used TEEs to investigate the prevalence of the issue. We recon-\ufb01rm known bugs that \ufb01t this pattern and discover unknown instances of the issue in the wild. In total, we con\ufb01rmed 9 known bugs, found 10 instances of silently-\ufb01xed bugs, and discovered a surprising amount of 14 critical 0-day vulnerabilities using our GPCheck prototype. Our \ufb01ndings affect mobile devices currently in use by billions of users. We responsibly disclosed these \ufb01ndings, already received 12,000 USD as bug bounty, and were assigned four CVEs. Ten of our 14 critical 0-day vulnerabilities are still in the responsible disclosure process. Finally, we propose an extension to the GP Internal Core API speci\ufb01cation to enforce a fail-safe mechanism that removes the underlying design weakness. We implement and successfully demonstrate our mitigation on OPTEE, an open-source TEE implementation. We shared our \ufb01ndings with GlobalPlatform and suggested our mitigation as an extension to their speci\ufb01cation to secure future TEE implementations.",
            "keywords": [
                "Trusted Execution Environments",
                "GlobalPlatform API",
                "Type-Confusion Bugs",
                "Trusted Applications",
                "0-Day Vulnerabilities"
            ]
        },
        "url": "URL#379440",
        "sema_paperId": "18b43a83b90ddfe277b1d7ca614c3d32cbbf8dd3"
    },
    {
        "@score": "1",
        "@id": "379441",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "295/3456",
                        "text": "Yuandao Cai"
                    },
                    {
                        "@pid": "381/1597",
                        "text": "Yibo Jin 0004"
                    },
                    {
                        "@pid": "51/7008-1",
                        "text": "Charles Zhang 0001"
                    }
                ]
            },
            "title": "Unleashing the Power of Type-Based Call Graph Construction by Using Regional Pointer Information.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CaiJ024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/cai-yuandao",
            "url": "https://dblp.org/rec/conf/uss/CaiJ024",
            "abstract": "When dealing with millions of lines of C code, we still cannot have the cake and eat it: type analysis for call graph construction is scalable yet highly imprecise. We address this precision issue through a practical observation: many function pointers are simple; they are not referenced by other pointers, nor do they derive their values by dereferencing other pointers. As a result, simple function pointers can be resolved with precise and affordable pointer aliasing information. In this work, we advocate K ELP with two concerted stages. First, instead of directly using type analysis, K ELP performs regional pointer analysis along def-use chains to early and precisely resolve the indirect calls through simple function pointers. Second, K ELP then leverages type analysis to handle the remaining indirect calls. The \ufb01rst stage is ef-\ufb01cient as K ELP selectively reasons about simple function pointers, thereby avoiding prohibitive performance penalties. The second stage is precise as the candidate address-taken functions for checking type compatibility are largely reduced thanks to the \ufb01rst stage. Our experiments on twenty large-scale and popular software programs show that, on average, K ELP can reduce spurious callees by 54.2% with only a negligible additional time cost of 8.5% (equivalent to 6.3 seconds) compared to the previous approach. More excitingly, when evaluating the call graphs through the lens of three various downstream clients (i.e., thread-sharing analysis, value-\ufb02ow bug detection, and directed grey-box fuzzing), K ELP can sig-ni\ufb01cantly enhance their effectiveness for better vulnerability understanding, hunting, and reproduction.",
            "keywords": [
                "Call Graph Construction",
                "Type-Based Analysis",
                "Function Pointer Resolution",
                "Pointer Aliasing",
                "Indirect Call Precision"
            ]
        },
        "url": "URL#379441",
        "sema_paperId": "b040a7f787ece04ce89c149b3578fc0a9059a633"
    },
    {
        "@score": "1",
        "@id": "379442",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "122/4894",
                        "text": "Yifeng Cai"
                    },
                    {
                        "@pid": "97/7236",
                        "text": "Ziqi Zhang"
                    },
                    {
                        "@pid": "119/1083",
                        "text": "Jiaping Gui"
                    },
                    {
                        "@pid": "198/1547",
                        "text": "Bingyan Liu"
                    },
                    {
                        "@pid": "134/9285",
                        "text": "Xiaoke Zhao"
                    },
                    {
                        "@pid": "08/10026",
                        "text": "Ruoyu Li"
                    },
                    {
                        "@pid": "11/751",
                        "text": "Zhe Li"
                    },
                    {
                        "@pid": "95/7132-1",
                        "text": "Ding Li 0001"
                    }
                ]
            },
            "title": "FAMOS: Robust Privacy-Preserving Authentication on Payment Apps via Federated Multi-Modal Contrastive Learning.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CaiZGLZLL024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/cai-yifeng",
            "url": "https://dblp.org/rec/conf/uss/CaiZGLZLL024",
            "abstract": "The rise of mobile payment apps necessitates robust user authentication to ensure legitimate user access. Traditional methods, like passwords and biometrics, are vulnerable once a device is compromised. To overcome these limitations, modern solutions utilize sensor data to achieve user-agnostic and scalable behavioral authentication. However, existing solutions face two problems when deployed to real-world applications. First, it is not robust to noisy background activities. Second, it faces the risks of privacy leakage as it relies on centralized training with users\u2019 sensor data. In this paper, we introduce FAMOS, a novel authentication framework based on federated multi-modal contrastive learning. The intuition of FAMOS is to fuse multi-modal sensor data and cluster the representation of one user\u2019s data by the action category so that we can eliminate the influence of background noise and guarantee the user\u2019s privacy. Furthermore, we incorporate FAMOS with federated learning to enhance performance while protecting users\u2019 privacy. We comprehensively evaluate FAMOS using real-world datasets and devices. Experimental results show that FAMOS is efficient and accurate for real-world deployment. FAMOS has an F1-Score of 0.91 and an AUC of 0.97, which are 42.19% and 27.63% higher than the baselines, respectively.",
            "keywords": [
                "Mobile Payment Authentication",
                "Federated Learning",
                "Behavioral Authentication",
                "Privacy Preservation",
                "Multi-Modal Sensor Data"
            ]
        },
        "url": "URL#379442",
        "sema_paperId": "4ce613a3879b61d0ce9c9681a3b39e20fccf675d"
    },
    {
        "@score": "1",
        "@id": "379443",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "381/1625",
                        "text": "Giuseppe Calderonio"
                    },
                    {
                        "@pid": "322/1111",
                        "text": "Mir Masood Ali"
                    },
                    {
                        "@pid": "47/8412",
                        "text": "Jason Polakis"
                    }
                ]
            },
            "title": "Fledging Will Continue Until Privacy Improves: Empirical Analysis of Google&apos;s Privacy-Preserving Targeted Advertising.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CalderonioAP24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/calderonio",
            "url": "https://dblp.org/rec/conf/uss/CalderonioAP24",
            "abstract": "Google recently announced plans to phase out third-party cookiesandiscurrentlyintheprocessofrollingouttheChrome Privacy Sandbox, a collection of APIs and web standards that offer privacy-preserving alternatives to existing technologies, particularlyforthe digitaladvertising ecosystem. This includes FLEDGE, also referred to as the Protected Audience, which provides the necessary mechanisms for effectively conducting real-time bidding and ad auctions directly within users\u2019 browsers. FLEDGE is designed to eliminate the invasive data collection and pervasive tracking practices used for remarket-ing and targeted advertising. In this paper, we provide a study of the FLEDGE ecosystem both before and after its official deployment in Chrome. We find that even though multiple prominent ad platforms have entered the space, Google ran 99.8% of the auctions we observed, highlighting its dominant role. Subsequently,we provide the first in-depth empirical analysis of FLEDGE, and uncover a series of severe design and implementation flaws. We leverage those for conducting 12 novel attacks, including tracking, cross-site leakage, service disruption, and pollution attacks. While FLEDGE aims to en-hanceuserprivacy,ourresearchdemonstratesthatitiscurrently exposing users to significant risks, and we outline mitigations for addressing the issues that we have uncovered. We have also responsibly disclosed our findings to Google so as to kickstart remediation efforts. We believe that our research highlights the dire need for more in-depth investigations of the entire Privacy Sandbox, due to the massive impact it will have on user privacy.",
            "keywords": [
                "Privacy-Preserving Advertising",
                "FLEDGE",
                "Digital Advertising Ecosystem",
                "User Privacy Risks",
                "Privacy Sandbox"
            ]
        },
        "url": "URL#379443",
        "sema_paperId": "1032212090fa2389a95732c9895273c1239d8c7c"
    },
    {
        "@score": "1",
        "@id": "379444",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "222/5438",
                        "text": "Guodong Cao"
                    },
                    {
                        "@pid": "31/5772-1",
                        "text": "Zhibo Wang 0001"
                    },
                    {
                        "@pid": "206/7646",
                        "text": "Yunhe Feng"
                    },
                    {
                        "@pid": "241/7878",
                        "text": "Xiaowei Dong"
                    }
                ]
            },
            "title": "DAAP: Privacy-Preserving Model Accuracy Estimation on Unlabeled Datasets Through Distribution-Aware Adversarial Perturbation.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Cao0FD24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/cao-guodong",
            "url": "https://dblp.org/rec/conf/uss/Cao0FD24",
            "abstract": "In the dynamic field of deep learning, accurately estimating model performance while ensuring data privacy against diverse and unlabeled test datasets presents a critical challenge. This is primarily due to the significant distributional shifts between training and test datasets, which complicates model evaluation. Traditional methods for assessing model accuracy often require direct access to the entire test dataset, posing significant risks of data leakage and model theft. To address these issues, we propose a novel approach: Distribution-Aware Ad-versarial Perturbation (DAAP). This method is designed to estimate the accuracy of deep learning models on unlabeled test datasets without compromising privacy. Specifically, DAAP leverages a publicly available dataset as an intermediary to bridge the gap between the model and the test data, effectively circumventing direct interaction and mitigating privacy concerns. By strategically applying adversarial perturbations, DAAP minimizes the distributional discrepancies between datasets, enabling precise estimation of model performance on unseen test data. We present two specialized strategies for white-box and black-box model contexts: the former focuses on reducing output entropy disparities, while the latter manipulates distribution discriminators. Overall, the DAAP introduces a novel framework for privacy-preserving accuracy estimation in model evaluation. This novel approach not only addresses critical challenges related to data privacy and distributional",
            "keywords": [
                "Privacy-Preserving Estimation",
                "Adversarial Perturbation",
                "Unlabeled Datasets",
                "Model Performance Evaluation",
                "Distributional Discrepancies"
            ]
        },
        "url": "URL#379444",
        "sema_paperId": "bcefd7fa7a1b3377ad865db425c5e13f9657fbcd"
    },
    {
        "@score": "1",
        "@id": "379445",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "77/721",
                        "text": "Leo Cao"
                    },
                    {
                        "@pid": "342/1564",
                        "text": "Luoxi Meng"
                    },
                    {
                        "@pid": "91/6118",
                        "text": "Deian Stefan"
                    },
                    {
                        "@pid": "16/10817",
                        "text": "Earlence Fernandes"
                    }
                ]
            },
            "title": "Stateful Least Privilege Authorization for the Cloud.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CaoMSF24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/cao-leo",
            "url": "https://dblp.org/rec/conf/uss/CaoMSF24",
            "abstract": "Widely-used authorization protocols like OAuth create over-privileged credentials because they do not provide developers of client apps and servers the tools to request and enforce minimal access. In the status quo, these overprivileged credentials are vulnerable to abuse when stolen or leaked. We introduce an authorization framework StatefulAuth that enables creating and using bearer tokens that are least privileged. This artifact evaluation aims to reproduce the key results presented in our paper. We will guide reviewers through the setup of stateful authorization using the provided example code. In this evaluation, the reviewers will observe that this artifact introduces only a modest performance overhead compared to standard OAuth 2.0 and the previous stateless authorization framework.",
            "keywords": [
                "Cloud Authorization",
                "Least Privilege",
                "Bearer Tokens",
                "StatefulAuth Framework",
                "Overprivileged Credentials"
            ]
        },
        "url": "URL#379445",
        "sema_paperId": "e3cd972cae8bdf1f1ab98802d20da7c9d3f50a5c"
    },
    {
        "@score": "1",
        "@id": "379446",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "268/4593",
                        "text": "Leo de Castro"
                    },
                    {
                        "@pid": "208/8581",
                        "text": "Keewoo Lee"
                    }
                ]
            },
            "title": "VeriSimplePIR: Verifiability in SimplePIR at No Online Cost for Honest Servers.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CastroL24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/de-castro",
            "url": "https://dblp.org/rec/conf/uss/CastroL24",
            "abstract": "We present VeriSimplePIR, a verifiable version of the state-of-the-art semi-honest SimplePIR protocol. VeriSimplePIR is a stateful verifiable PIR scheme guaranteeing that all queries are consistent with a fixed, well-formed database. It is the first efficient verifiable PIR scheme to not rely on an honest digest to ensure security; any digest, even one produced by a malicious server, is sufficient to commit to some database. This is due to our extractable verification procedure, which can extract the entire database from the consistency proof checked against each response. \nFurthermore, VeriSimplePIR ensures this strong security guarantee without compromising the performance of SimplePIR. The online communication overhead is roughly 1.1-1.5x SimplePIR, and the online computation time on the server is essentially the same. We achieve this low overhead via a novel one-time preprocessing protocol that generates a reusable proof that can verify any number of subsequent query-response pairs as long as no malicious behavior is detected. As soon as the verification procedure rejects a response from the server, the offline phase must be rerun to compute a new proof. VeriSimplePIR represents an approach to maliciously secure cryptography that is highly optimized for honest parties while maintaining security even in the presence of malicious adversaries.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-de-castro.pdf",
            "keywords": [
                "Verifiable Private Information Retrieval",
                "SimplePIR",
                "Malicious Security",
                "Consistency Proof",
                "Extractable Verification"
            ]
        },
        "url": "URL#379446"
    },
    {
        "@score": "1",
        "@id": "379447",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "248/8003",
                        "text": "Stefanos Chaliasos"
                    },
                    {
                        "@pid": "295/7928",
                        "text": "Jens Ernstberger"
                    },
                    {
                        "@pid": "295/5622",
                        "text": "David Theodore"
                    },
                    {
                        "@pid": "47/318",
                        "text": "David Wong"
                    },
                    {
                        "@pid": "360/1683",
                        "text": "Mohammad Jahanara"
                    },
                    {
                        "@pid": "46/2924",
                        "text": "Benjamin Livshits"
                    }
                ]
            },
            "title": "SoK: What don&apos;t we know? Understanding Security Vulnerabilities in SNARKs.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChaliasosETWJL24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/chaliasos",
            "url": "https://dblp.org/rec/conf/uss/ChaliasosETWJL24",
            "abstract": "Zero-knowledge proofs (ZKPs) have evolved from being a theoretical concept providing privacy and verifiability to having practical, real-world implementations, with SNARKs (Succinct Non-Interactive Argument of Knowledge) emerging as one of the most significant innovations. Prior work has mainly focused on designing more efficient SNARK systems and providing security proofs for them. Many think of SNARKs as \"just math,\" implying that what is proven to be correct and secure is correct in practice. In contrast, this paper focuses on assessing end-to-end security properties of real-life SNARK implementations. We start by building foundations with a system model and by establishing threat models and defining adversarial roles for systems that use SNARKs. Our study encompasses an extensive analysis of 141 actual vulnerabilities in SNARK implementations, providing a detailed taxonomy to aid developers and security researchers in understanding the security threats in systems employing SNARKs. Finally, we evaluate existing defense mechanisms and offer recommendations for enhancing the security of SNARK-based systems, paving the way for more robust and reliable implementations in the future.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-chaliasos.pdf",
            "keywords": [
                "Zero-Knowledge Proofs",
                "SNARKs",
                "Security Vulnerabilities",
                "Threat Models",
                "Defense Mechanisms"
            ]
        },
        "url": "URL#379447"
    },
    {
        "@score": "1",
        "@id": "379448",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "152/5447",
                        "text": "Hongyan Chang"
                    },
                    {
                        "@pid": "228/8071",
                        "text": "Brandon Edwards"
                    },
                    {
                        "@pid": "284/0858",
                        "text": "Anindya S. Paul"
                    },
                    {
                        "@pid": "20/3101",
                        "text": "Reza Shokri"
                    }
                ]
            },
            "title": "Efficient Privacy Auditing in Federated Learning.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChangEPS24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/chang",
            "url": "https://dblp.org/rec/conf/uss/ChangEPS24",
            "abstract": "We design a novel efficient membership inference attack to audit privacy risks in federated learning. Our approach involves computing the slope of specific model performance metrics (e.g., model's output and its loss) across FL rounds to differentiate members from non-members. Since these metrics are automatically computed during the FL process, our solution imposes negligible overhead and can be seamlessly integrated without disrupting training. We validate the effectiveness and superiority of our method over prior work across a wide range of FL settings and real-world datasets.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-chang.pdf",
            "keywords": [
                "Federated Learning",
                "Privacy Auditing",
                "Membership Inference Attack",
                "Model Performance Metrics",
                "Privacy Risks"
            ]
        },
        "url": "URL#379448",
        "sema_paperId": "fa50f3671148c9e6cdd8bdde463a6cf78554b93a"
    },
    {
        "@score": "1",
        "@id": "379449",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "362/1699",
                        "text": "Boru Chen"
                    },
                    {
                        "@pid": "216/4663",
                        "text": "Yingchen Wang"
                    },
                    {
                        "@pid": "298/8542",
                        "text": "Pradyumna Shome"
                    },
                    {
                        "@pid": "25/8166",
                        "text": "Christopher W. Fletcher"
                    },
                    {
                        "@pid": "131/5093",
                        "text": "David Kohlbrenner"
                    },
                    {
                        "@pid": "224/9301",
                        "text": "Riccardo Paccagnella"
                    },
                    {
                        "@pid": "98/8283",
                        "text": "Daniel Genkin"
                    }
                ]
            },
            "title": "GoFetch: Breaking Constant-Time Cryptographic Implementations Using Data Memory-Dependent Prefetchers.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChenWSFKPG24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/chen-boru",
            "url": "https://dblp.org/rec/conf/uss/ChenWSFKPG24",
            "abstract": "Microarchitectural side-channel attacks have shaken the foundations of modern processor design. The cornerstone defense against these attacks has been to ensure that security-critical programs do not use secret-dependent data as addresses. Put simply: do not pass secrets as addresses to, e.g., data memory instructions. Yet, the discovery of data memory-dependent prefetchers (DMPs)\u2014which turn program data into addresses directly from within the memory system\u2014calls into question whether this approach will continue to remain secure. This paper shows that the security threat from DMPs is significantly worse than previously thought and demonstrates the first end-to-end attacks on security-critical software using the Apple m -series DMP. Undergirding our attacks is a new understanding of how DMPs behave which shows, among other things, that the Apple DMP will activate on behalf of any victim program and attempt to \u201cleak\u201d any cached data that resembles a pointer. From this understanding, we de-sign a new type of chosen-input attack that uses the DMP to perform end-to-end key extraction on popular constant-time implementations of classical (OpenSSL Diffie-Hellman Key Exchange, Go RSA decryption) and post-quantum cryptography (CRYSTALS-Kyber and CRYSTALS-Dilithium).",
            "keywords": [
                "Microarchitectural Attacks",
                "Data Memory-Dependent Prefetchers",
                "Constant-Time Cryptography",
                "Key Extraction",
                "Side-Channel Vulnerabilities"
            ]
        },
        "url": "URL#379449",
        "sema_paperId": "c64a755b519cef7cf4c4cd3677d3eec282874bcb"
    },
    {
        "@score": "1",
        "@id": "379450",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "225/0180",
                        "text": "Baodong Chen"
                    },
                    {
                        "@pid": "35/7092",
                        "text": "Wei Wang"
                    },
                    {
                        "@pid": "378/1264",
                        "text": "Pascal Sikorski"
                    },
                    {
                        "@pid": "42/5105",
                        "text": "Ting Zhu"
                    }
                ]
            },
            "title": "Adversary is on the Road: Attacks on Visual SLAM using Unnoticeable Adversarial Patch.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChenWSZ24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/chen-baodong",
            "url": "https://dblp.org/rec/conf/uss/ChenWSZ24",
            "abstract": "Visual Simultaneous Localization and Mapping (vSLAM) plays a pivotal role in numerous emerging applications, including autonomous driving and robotic navigation. It mainly utilizes consecutive frames captured by image sensors to conduct localization and build high-definition maps. However, existing approaches mainly focus on building reliable and accurate vSLAM systems, while little work has been done to investigate the vulnerability of existing vSLAM systems. To fill the gap, we introduce an AoR ( A dversary is o n the R oad) attack, which can effectively alter localization and mapping results of widely used vSLAM systems without being detected by the legitimate user. To do this, we conducted in-depth investigations on existing vSLAM systems and found that these systems are very sensitive to environmental texture changes. Building upon this insight, we design a novel adversarial patch generation mechanism that can generate unnoticeable adversarial patches to attack existing vSLAM systems. We extensively evaluate the effectiveness of the AoR attack on industry-level vehicles, robotic platforms, and four well-known open-source datasets. The evaluation results show that the AoR attack can effectively attack existing vSLAM systems and introduce extremely high localization errors (up to 713% ). To mitigate this attack, we also designed an innovative defense module to simultaneously detect abnormal environmental texture distributions and support reliable vS-LAM. Our defense module is lightweight and has the potential to be applied to existing vSLAM systems.",
            "keywords": [
                "Visual SLAM",
                "Adversarial Attacks",
                "Localization Errors",
                "Adversarial Patch",
                "Environmental Texture Sensitivity"
            ]
        },
        "url": "URL#379450",
        "sema_paperId": "5174c9bd33a7cd5a6ac7642c2424e48cb7f79122"
    },
    {
        "@score": "1",
        "@id": "379451",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "25/687-11",
                        "text": "Meng Chen 0011"
                    },
                    {
                        "@pid": "172/1282-1",
                        "text": "Xiangyu Xu 0001"
                    },
                    {
                        "@pid": "49/2793-8",
                        "text": "Li Lu 0008"
                    },
                    {
                        "@pid": "139/5759",
                        "text": "Zhongjie Ba"
                    },
                    {
                        "@pid": "75/2611-4",
                        "text": "Feng Lin 0004"
                    },
                    {
                        "@pid": "20/6179-1",
                        "text": "Kui Ren 0001"
                    }
                ]
            },
            "title": "Devil in the Room: Triggering Audio Backdoors in the Physical World.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChenX0B0024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/chen-meng",
            "url": "https://dblp.org/rec/conf/uss/ChenX0B0024",
            "abstract": "Recent years have witnessed deep learning techniques en-dowing modern audio systems with powerful capabilities. However, the latest studies have revealed its strong reliance on training data, raising serious threats from backdoor attacks. Different from most existing works that study audio backdoors in the digital world, we investigate the mismatch between the trigger and backdoor in the physical space by examining sound channel distortion. Inspired by this observation, this paper proposes TrojanRoom to bridge the gap between digital and physical audio backdoor attacks. Trojan-Room utilizes the room impulse response (RIR) as a physical trigger to enable injection-free backdoor activation. By synthesizing dynamic RIRs and poisoning a source class of samples during data augmentation, TrojanRoom enables any adversary to launch an effective and stealthy attack using the specific impulse response in a room. The evaluation shows over 92% and 97% attack success rates on both state-of-the-art speech command recognition and speaker recognition systems with negligible impact on benign accuracy below 3% at a distance of over 5m. The experiments also demonstrate that TrojanRoom could bypass human inspection and voice liveness detection, as well as resist trigger disruption and backdoor defense.",
            "keywords": [
                "Audio Backdoor Attacks",
                "Physical World Security",
                "Room Impulse Response",
                "Trojan Attacks",
                "Stealthy Audio Manipulation"
            ]
        },
        "url": "URL#379451",
        "sema_paperId": "a0b37d864bf20ea17cd0b9a2a3c62d96b5e5eb27"
    },
    {
        "@score": "1",
        "@id": "379452",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "205/4031",
                        "text": "Yihao Chen"
                    },
                    {
                        "@pid": "230/1810",
                        "text": "Qilei Yin"
                    },
                    {
                        "@pid": "181/2688-2",
                        "text": "Qi Li 0002"
                    },
                    {
                        "@pid": "69/11514",
                        "text": "Zhuotao Liu"
                    },
                    {
                        "@pid": "181/2626-2",
                        "text": "Ke Xu 0002"
                    },
                    {
                        "@pid": "14/5580",
                        "text": "Yi Xu"
                    },
                    {
                        "@pid": "18/6055",
                        "text": "Mingwei Xu"
                    },
                    {
                        "@pid": "38/123",
                        "text": "Ziqian Liu"
                    },
                    {
                        "@pid": "82/4905",
                        "text": "Jianping Wu"
                    }
                ]
            },
            "title": "Learning with Semantics: Towards a Semantics-Aware Routing Anomaly Detection System.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChenY0L0XXLW24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/chen-yihao",
            "url": "https://dblp.org/rec/conf/uss/ChenY0L0XXLW24",
            "abstract": "BGP is the de facto inter-domain routing protocol to ensure global connectivity of the Internet. However, various reasons, such as deliberate attacks or misconfigurations, could cause BGP routing anomalies. Traditional methods for BGP routing anomaly detection require significant manual investigation of routes by network operators. Although machine learning has been applied to automate the process, prior arts typically impose significant training overhead (such as large-scale data labeling and feature crafting), and only produce uninterpretable results. To address these limitations, this paper presents a routing anomaly detection system centering around a novel network representation learning model named BEAM. The core design of BEAM is to accurately learn the unique properties (defined as \\emph{routing role}) of each Autonomous System (AS) in the Internet by incorporating BGP semantics. As a result, routing anomaly detection, given BEAM, is reduced to a matter of discovering unexpected routing role churns upon observing new route announcements. We implement a prototype of our routing anomaly detection system and extensively evaluate its performance. The experimental results, based on 18 real-world RouteViews datasets containing over 11 billion route announcement records, demonstrate that our system can detect all previously-confirmed routing anomalies, while only introducing at most five false alarms every 180 million route announcements. We also deploy our system at a large ISP to perform real-world detection for one month. During the course of deployment, our system detects 497 true anomalies in the wild with an average of only 1.65 false alarms per day.",
            "keywords": [
                "BGP Routing",
                "Anomaly Detection",
                "Autonomous Systems",
                "Network Representation Learning",
                "Routing Role Churns"
            ]
        },
        "url": "URL#379452",
        "sema_paperId": "4dd0076c55ce5c6882e3219c59332f1d54171733"
    },
    {
        "@score": "1",
        "@id": "379453",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "259/8951",
                        "text": "Kaiming Cheng"
                    },
                    {
                        "@pid": "372/4046",
                        "text": "Arkaprabha Bhattacharya"
                    },
                    {
                        "@pid": "251/1763",
                        "text": "Michelle Lin"
                    },
                    {
                        "@pid": "39/4985-5",
                        "text": "Jaewook Lee 0005"
                    },
                    {
                        "@pid": "304/1257",
                        "text": "Aroosh Kumar"
                    },
                    {
                        "@pid": "353/7586",
                        "text": "Jeffery F. Tian"
                    },
                    {
                        "@pid": "k/TadayoshiKohno",
                        "text": "Tadayoshi Kohno"
                    },
                    {
                        "@pid": "23/2758",
                        "text": "Franziska Roesner"
                    }
                ]
            },
            "title": "When the User Is Inside the User Interface: An Empirical Study of UI Security Properties in Augmented Reality.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChengBL0KTKR24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/cheng-kaiming",
            "url": "https://dblp.org/rec/conf/uss/ChengBL0KTKR24",
            "abstract": "Augmented reality (AR) experiences place users inside the user interface (UI), where they can see and interact with three-dimensional virtual content. This paper explores UI security for AR platforms, for which we identify three UI security-related properties: Same Space (how does the platform handle virtual content placed at the same coordinates?), Invisibility (how does the platform handle invisible virtual content?), and Synthetic Input (how does the platform handle simulated user input?). We demonstrate the security implications of different instantiations of these properties through five proof-of-concept attacks between distrusting AR application components (i.e., a main app and an included library) \u2014 including a clickjacking attack and an object erasure attack. We then empirically investigate these UI security properties on five current AR platforms: ARCore (Google), ARKit (Apple), Hololens (Microsoft), Oculus (Meta), and WebXR (browser). We find that all platforms enable at least three of our proof-of-concept attacks to succeed. We discuss potential future defenses, including applying lessons from 2D UI security and identifying new directions for AR UI security.",
            "keywords": [
                "Augmented Reality Security",
                "User Interface Security",
                "Virtual Content Interaction",
                "Proof-of-Concept Attacks",
                "UI Security Properties"
            ]
        },
        "url": "URL#379453",
        "sema_paperId": "a58a75d816713436e66fcdf872ffccb15d5fdac0"
    },
    {
        "@score": "1",
        "@id": "379454",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "00/6261",
                        "text": "Xiaoyu Cheng"
                    },
                    {
                        "@pid": "00/6750",
                        "text": "Fei Tong"
                    },
                    {
                        "@pid": "96/3995",
                        "text": "Hongyu Wang"
                    },
                    {
                        "@pid": "34/6503",
                        "text": "Zhe Zhou"
                    },
                    {
                        "@pid": "09/5767",
                        "text": "Fang Jiang"
                    },
                    {
                        "@pid": "04/477",
                        "text": "Yuxing Mao"
                    }
                ]
            },
            "title": "SpecLFB: Eliminating Cache Side Channels in Speculative Executions.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChengTWZJM24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/cheng-xiaoyu",
            "url": "https://dblp.org/rec/conf/uss/ChengTWZJM24",
            "abstract": "Cache side-channel attacks based on speculative executions are powerful and difficult to mitigate. Existing hardware defense schemes often require additional hardware data structures, data movement operations and/or complex logical computations, resulting in excessive overhead of both processor performance and hardware resources. To this end, this paper proposes SpecLFB, which utilizes the microarchitecture component, Line-Fill-Buffer, integrated with a proposed mechanism for load security check to prevent the establishment of cache side channels in speculative executions. To ensure the correctness and immediacy of load security check, a structure called ROB unsafe mask is designed for SpecLFB to track instruction state. To further reduce processor performance overhead, SpecLFB narrows down the protection scope of unsafe speculative loads and determines the time at which they can be deprotected as early as possible. SpecLFB has been implemented in the open-source RISC-V core, Sonic-BOOM, as well as in Gem5. For the enhanced SonicBOOM, its register-transfer-level (RTL) code is generated, and an FPGA hardware prototype burned with the core and running a Linux-kernel-based operating system is developed. Based on the evaluations in terms of security guarantee, performance overhead, and hardware resource overhead through RTL simulation, FPGA prototype experiment, and Gem5 simulation, it shows that SpecLFB effectively defends against attacks. It leads to a hardware resource overhead of only 0.6% and the performance overhead of only 1.85% and 3.20% in the FPGA prototype experiment and Gem5 simulation, respectively",
            "keywords": [
                "Cache Side-Channel Attacks",
                "Speculative Execution",
                "Load Security Check",
                "Line-Fill-Buffer",
                "Performance Overhead"
            ]
        },
        "url": "URL#379454",
        "sema_paperId": "55c6a6329afa460d81d9734337f48e6647745f65"
    },
    {
        "@score": "1",
        "@id": "379455",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "317/3956",
                        "text": "Seonyoung Cheon"
                    },
                    {
                        "@pid": "49/8558-1",
                        "text": "Yongwoo Lee 0001"
                    },
                    {
                        "@pid": "62/10307-2",
                        "text": "Dongkwan Kim 0002"
                    },
                    {
                        "@pid": "343/5240",
                        "text": "Ju Min Lee"
                    },
                    {
                        "@pid": "373/1403",
                        "text": "Sunchul Jung"
                    },
                    {
                        "@pid": "58/1619",
                        "text": "Taekyung Kim"
                    },
                    {
                        "@pid": "90/4053",
                        "text": "Dongyoon Lee"
                    },
                    {
                        "@pid": "29/7934",
                        "text": "Hanjun Kim 0001"
                    }
                ]
            },
            "title": "DaCapo: Automatic Bootstrapping Management for Efficient Fully Homomorphic Encryption.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Cheon00LJKL024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/cheon",
            "url": "https://dblp.org/rec/conf/uss/Cheon00LJKL024",
            "abstract": "By supporting computation on encrypted data, fully homomorphic encryption (FHE) offers the potential for privacy-preserving computation offloading. However, its applicability is constrained to small programs because each FHE multiplication increases the scale of a ciphertext with a limited scale capacity. By resetting the accumulated scale, bootstrapping enables a longer FHE multiplication chain. Nonetheless, manual bootstrapping placement poses a significant programming burden to avoid scale overflow from insufficient bootstrapping or the substantial computational overhead of unnecessary boot-strapping. Additionally, the bootstrapping placement affects costs of FHE operations due to changes in scale management, further complicating the overall management process. This work proposes D A C APO , the first automatic bootstrapping management compiler. Aiming to reduce bootstrapping counts, D A C APO analyzes live-out ciphertexts at each program point and identifies candidate points for inserting boot-strapping operations. D A C APO estimates the FHE operation latencies under different scale management scenarios for each bootstrapping placement plan at each candidate point, and decides the bootstrapping placement plan with minimal latency. This work evaluates D A C APO with deep learning models that existing FHE compilers cannot compile due to a lack of boot-strapping support. The evaluation achieves 1.21 \u00d7 speedup on average compared to manually implemented FHE programs.",
            "keywords": [
                "Fully Homomorphic Encryption",
                "Bootstrapping Management",
                "Ciphertext Scale Management",
                "Automatic Compiler",
                "Latency Optimization"
            ]
        },
        "url": "URL#379455",
        "sema_paperId": "dc23a702b2cc7b987a3fe94465412728a366afec"
    },
    {
        "@score": "1",
        "@id": "379456",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "160/9382",
                        "text": "Giovanni Cherubin"
                    },
                    {
                        "@pid": "10/3908",
                        "text": "Boris K\u00f6pf"
                    },
                    {
                        "@pid": "30/9784",
                        "text": "Andrew Paverd"
                    },
                    {
                        "@pid": "136/8442",
                        "text": "Shruti Tople"
                    },
                    {
                        "@pid": "263/8844",
                        "text": "Lukas Wutschitz"
                    },
                    {
                        "@pid": "70/2200",
                        "text": "Santiago Zanella B\u00e9guelin"
                    }
                ]
            },
            "title": "Closed-Form Bounds for DP-SGD against Record-level Inference.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CherubinKPTWB24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/cherubin",
            "url": "https://dblp.org/rec/conf/uss/CherubinKPTWB24",
            "abstract": "Machine learning models trained with differentially-private (DP) algorithms such as DP-SGD enjoy resilience against a wide range of privacy attacks. Although it is possible to derive bounds for some attacks based solely on an (\u03b5,\u03b4)-DP guarantee, meaningful bounds require a small enough privacy budget (i.e., injecting a large amount of noise), which results in a large loss in utility. This paper presents a new approach to evaluate the privacy of machine learning models against specific record-level threats, such as membership and attribute inference, without the indirection through DP. We focus on the popular DP-SGD algorithm, and derive simple closed-form bounds. Our proofs model DP-SGD as an information theoretic channel whose inputs are the secrets that an attacker wants to infer (e.g., membership of a data record) and whose outputs are the intermediate model parameters produced by iterative optimization. We obtain bounds for membership inference that match state-of-the-art techniques, whilst being orders of magnitude faster to compute. Additionally, we present a novel data-dependent bound against attribute inference. Our results provide a direct, interpretable, and practical way to evaluate the privacy of trained models against specific inference threats without sacrificing utility.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-cherubin.pdf",
            "keywords": [
                "Differential Privacy",
                "DP-SGD",
                "Record-level Inference",
                "Membership Inference",
                "Attribute Inference"
            ]
        },
        "url": "URL#379456"
    },
    {
        "@score": "1",
        "@id": "379457",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "211/7111",
                        "text": "Michael Chesser"
                    },
                    {
                        "@pid": "22/3939",
                        "text": "Surya Nepal"
                    },
                    {
                        "@pid": "56/8102",
                        "text": "Damith C. Ranasinghe"
                    }
                ]
            },
            "title": "MultiFuzz: A Multi-Stream Fuzzer For Testing Monolithic Firmware.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChesserNR24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/chesser",
            "url": "https://dblp.org/rec/conf/uss/ChesserNR24",
            "abstract": "Rapid embedded device proliferation is creating new targets and opportunities for adversaries. However, the complex interactions between firmware and hardware pose challenges to applying automated testing, such as fuzzing. State-of-the-art methods re-host firmware in emulators and facilitate complex interactions with hardware by provisioning for inputs from a diversity of methods (such as interrupts) from a plethora of devices (such as modems). We recognize a significant disconnect between how a fuzzer generates inputs (as a monolithic file) and how the inputs are consumed during re-hosted execution (as a stream, in slices, per peripheral). We demonstrate the disconnect to significantly impact a fuzzer\u2019s effectiveness at discovering inputs that explore deeper code and bugs. We rethink the input generation process for fuzzing mono-lithic firmware and propose a new approach\u2014 multi-stream input generation and representation ; inputs are now a collection of independent streams, one for each peripheral. We demonstrate the versatility and effectiveness of our approach by implementing: i) stream specific mutation strategies; ii) efficient methods for generating useful values for peripherals; iii) enhancing the use of information learned during fuzzing; and iv) improving a fuzzer\u2019s ability to handle roadblocks. We design and build a new fuzzer, M ULTI F UZZ , for testing monolithic firmware and evaluate our approach on synthetic and real-world targets. M ULTI F UZZ passes all 66 unit tests from a benchmark consisting of 46 synthetic binaries targeting a diverse set of microcontrollers. On an evaluation with 23 real-world firmware targets, M ULTI F UZZ outperforms the state-of-the-art fuzzers Fuzzware and Ember-IO. M ULTI F",
            "keywords": [
                "Embedded Firmware Testing",
                "Fuzzing",
                "Multi-Stream Input Generation",
                "Peripheral Interaction",
                "Monolithic Firmware"
            ]
        },
        "url": "URL#379457",
        "sema_paperId": "179750858fe15eb24c74d5d452921677eec9a31f"
    },
    {
        "@score": "1",
        "@id": "379458",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "46/8341",
                        "text": "Chongwon Cho"
                    },
                    {
                        "@pid": "263/6691",
                        "text": "Samuel Dittmer"
                    },
                    {
                        "@pid": "05/667",
                        "text": "Yuval Ishai"
                    },
                    {
                        "@pid": "98/5599-1",
                        "text": "Steve Lu 0001"
                    },
                    {
                        "@pid": "o/RafailOstrovsky",
                        "text": "Rafail Ostrovsky"
                    }
                ]
            },
            "title": "Rabbit-Mix: Robust Algebraic Anonymous Broadcast from Additive Bases.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChoDI0O24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/cho-chongwon",
            "url": "https://dblp.org/rec/conf/uss/ChoDI0O24",
            "abstract": "We present Rabbit-Mix, a robust algebraic mixing-based anonymous broadcast protocol in the client-server model. Rabbit-Mix is the first practical sender-anonymous broadcast protocol satisfying both robustness and 100% message delivery assuming a (strong) honest majority of servers. It presents roughly 3 \u00d7 improvement in comparison to Blinder (CCS 2020), a previous anonymous broadcast protocol in the same model, in terms of the number of algebraic operations and communication, while at the same time eliminating the non-negligible failure probability of Blinder. To obtain these improvements, we combine the use of Newton\u2019s identities for mixing with a novel way of exploiting an algebraic structure in the powers of field elements, based on an additive 2-basis , to compactly encode and decode client messages. We also introduce a simple and efficient distributed protocol to verify the well-formedness of client input encodings, which should consist of shares of multiple arithmetic progressions tied together.",
            "keywords": [
                "Anonymous Broadcast",
                "Algebraic Mixing",
                "Robustness",
                "Message Delivery",
                "Client-Server Model"
            ]
        },
        "url": "URL#379458",
        "sema_paperId": "a514d68ed5d7c9e3d6a2cd3afdef306d6aec4201"
    },
    {
        "@score": "1",
        "@id": "379459",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "357/3530",
                        "text": "Kyuwon Cho"
                    },
                    {
                        "@pid": "279/0055",
                        "text": "Jongyoon Kim"
                    },
                    {
                        "@pid": "305/7328",
                        "text": "Kha Dinh Duy"
                    },
                    {
                        "@pid": "381/1590",
                        "text": "Hajeong Lim"
                    },
                    {
                        "@pid": "119/7678-1",
                        "text": "Hojoon Lee 0001"
                    }
                ]
            },
            "title": "RustSan: Retrofitting AddressSanitizer for Efficient Sanitization of Rust.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChoKDL024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/cho-kyuwon",
            "url": "https://dblp.org/rec/conf/uss/ChoKDL024",
            "abstract": "Rust is gaining traction as a safe systems programming language with its strong type and memory safety guarantees. However, Rust's guarantees are not infallible. The use of unsafe Rust, a subvariant of Rust, allows the programmer to temporarily escape the strict Rust language semantics to trade security for flexibility. Memory errors within unsafe blocks in Rust have far-reaching ramifications for the program's safety. As a result, the conventional dynamic memory error detection (e.g., fuzzing) has been adapted as a common practice for Rust and proved its effectiveness through a trophy case of discovered CVEs.\nRUSTSAN is a retrofitted design of AddressSanitizer (ASan) for efficient dynamic memory error detection of Rust programs. Our observation is that a significant portion of instrumented memory access sites in a Rust program compiled with ASan is redundant, as the Rust security guarantees can still be valid at the site. RUSTSAN identifies and instruments the sites that definitely or may undermine Rust security guarantees while lifting instrumentation on safe sites. To this end, RUSTSAN employs a cross-IR program analysis for accurate tracking of unsafe sites and also extends ASan's shadow memory scheme for checking non-uniform memory access validation necessary for Rust. We conduct a comprehensive evaluation of RUSTSAN in terms of detection capability and performance using 57 Rust crates. RUSTSAN successfully detected all 31 tested cases of CVE-issued memory errors. Also, RUSTSAN shows an average of 62.3% performance increase against ASan in general benchmarks that involved 20 Rust crates. In the fuzzing experiment with 6 crates, RUSTSAN marked an average of 23.52%, and up to 57.08% of performance improvement.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-cho-kyuwon.pdf",
            "keywords": [
                "Rust Programming",
                "Memory Safety",
                "Dynamic Memory Error Detection",
                "AddressSanitizer",
                "Unsafe Rust"
            ]
        },
        "url": "URL#379459",
        "sema_paperId": "95e77f3802bcde89949ead97a71828fcfbca971f"
    },
    {
        "@score": "1",
        "@id": "379460",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "40/309",
                        "text": "Hyunwoo Choi"
                    },
                    {
                        "@pid": "177/6825",
                        "text": "Suryeon Kim"
                    },
                    {
                        "@pid": "84/3319-1",
                        "text": "Seungwon Shin 0001"
                    }
                ]
            },
            "title": "Prefetch for Fun and Profit: A Revisit of Prefetch Attacks on Apple M1.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Other",
            "access": "open",
            "key": "conf/uss/ChoiKS24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/choi",
            "url": "https://dblp.org/rec/conf/uss/ChoiKS24",
            "abstract": null,
            "keywords": [
                "Prefetch Attacks",
                "Apple M1",
                "Cache Timing Attacks",
                "Side-Channel Attacks",
                "Performance Exploitation"
            ]
        },
        "url": "URL#379460",
        "sema_paperId": "de771a550deba77261923c5d404785b340c90794"
    },
    {
        "@score": "1",
        "@id": "379461",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "160/8650",
                        "text": "Arka Rai Choudhuri"
                    },
                    {
                        "@pid": "33/5817",
                        "text": "Sanjam Garg"
                    },
                    {
                        "@pid": "237/0174",
                        "text": "Julien Piet"
                    },
                    {
                        "@pid": "276/0468",
                        "text": "Guru-Vamsi Policharla"
                    }
                ]
            },
            "title": "Mempool Privacy via Batched Threshold Encryption: Attacks and Defenses.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChoudhuriGPP24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/choudhuri",
            "url": "https://dblp.org/rec/conf/uss/ChoudhuriGPP24",
            "abstract": "With the rising popularity of DeFi applications it is important to implement protections for regular users of these DeFi platforms against large parties with massive amounts of resources allowing them to engage in market manipulation strategies such as frontrunning/backrunning. Moreover, there are many situations (such as recovery of funds from vulnerable smart contracts) where a user may not want to reveal their transaction until it has been executed. As such, it is clear that preserving the privacy of transactions in the mempool is an important goal.\nIn this work we focus on achieving mempool transaction privacy through a new primitive that we term batched-threshold encryption, which is a variant of threshold encryption with strict efficiency requirements to better model the needs of resource constrained environments such as blockchains. Unlike the naive use of threshold encryption, which requires communication proportional to O(nB) to decrypt B transactions with a committee of n parties, our batched-threshold encryption scheme only needs O(n) communication. We additionally discuss pitfalls in prior approaches that use (vanilla) threshold encryption for mempool privacy.\nTo show that our scheme is concretely efficient, we implement our scheme and find that transactions can be encrypted in under 6 ms, independent of committee size, and the communication required to decrypt an entire batch of B transactions is 80 bytes per party, independent of the number of transactions B, making it an attractive choice when communication is very expensive. If deployed on Ethereum, which processes close to 500 transaction per block, it takes close to 2.8 s for each committee member to compute a partial decryption and under 3.5 s to decrypt all transactions for a block in single-threaded mode.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-choudhuri.pdf",
            "keywords": [
                "Mempool Privacy",
                "Batched Threshold Encryption",
                "DeFi Applications",
                "Transaction Privacy",
                "Market Manipulation"
            ]
        },
        "url": "URL#379461"
    },
    {
        "@score": "1",
        "@id": "379462",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "361/1866",
                        "text": "Daniele Coppola"
                    },
                    {
                        "@pid": "224/9311",
                        "text": "Giovanni Camurati"
                    },
                    {
                        "@pid": "195/0397",
                        "text": "Claudio Anliker"
                    },
                    {
                        "@pid": "381/1662",
                        "text": "Xenia Hofmeier"
                    },
                    {
                        "@pid": "38/4101",
                        "text": "Patrick Schaller"
                    },
                    {
                        "@pid": "b/DavidABasin",
                        "text": "David A. Basin"
                    },
                    {
                        "@pid": "51/1639",
                        "text": "Srdjan Capkun"
                    }
                ]
            },
            "title": "PURE: Payments with UWB RElay-protection.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CoppolaCAHSBC24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/coppola",
            "url": "https://dblp.org/rec/conf/uss/CoppolaCAHSBC24",
            "abstract": "Contactless payments are now widely used and are expected to reach $10 trillion worth of transactions by 2027. Although convenient, contactless payments are vulnerable to relay attacks that enable attackers to execute fraudulent payments. A number of countermeasures have been proposed to address this issue, including Mastercard\u2019s relay protection mechanism. These countermeasures, although effective against some Commercial off-the-shelf (COTS) relays, fail to prevent physical-layer relay attacks. In this work, we leverage the Ultra-Wide Band (UWB) radios incorporated in major smartphones, smartwatches, tags and accessories, and introduce PURE, the first UWB-based relay protection that integrates smoothly into existing contact-less payment standards, and prevents even the most sophisticated physical layer attacks. PURE extends EMV payment protocols that are executed between cards and terminals, and does not require any modification to the backend of the issuer, acquirer, or payment network. PURE further tailors UWB ranging to the payment environment (i.e., wireless channels) to achieve both reliability and resistance to all known physical-layer distance reduction attacks against UWB 802.15.4z. We implement PURE within the EMV standard on modern smart-phones, and evaluate its performance in a realistic deployment. Our experiments show that PURE provides a sub-meter relay protection with minimal execution overhead (41 ms). We formally verify the security of PURE\u2019s integration within Mastercard\u2019s EMV protocol using the Tamarin prover.",
            "keywords": [
                "Contactless Payments",
                "Relay Attacks",
                "Ultra-Wide Band (UWB)",
                "Payment Security",
                "EMV Protocol"
            ]
        },
        "url": "URL#379462",
        "sema_paperId": "2f13dbcbe5aed6a60a383fbb638c44459f47c4c6"
    },
    {
        "@score": "1",
        "@id": "379463",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "286/6372",
                        "text": "Eric Cornelissen"
                    },
                    {
                        "@pid": "292/4657",
                        "text": "Mikhail Shcherbakov"
                    },
                    {
                        "@pid": "25/7796",
                        "text": "Musard Balliu"
                    }
                ]
            },
            "title": "GHunter: Universal Prototype Pollution Gadgets in JavaScript Runtimes.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CornelissenSB24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/cornelissen",
            "url": "https://dblp.org/rec/conf/uss/CornelissenSB24",
            "abstract": "Prototype pollution is a recent vulnerability that affects JavaScript code, leading to high impact attacks such as arbitrary code execution and privilege escalation. The vulnerability is rooted in JavaScript's prototype-based inheritance, enabling attackers to inject arbitrary properties into an object's prototype at runtime. The impact of prototype pollution depends on the existence of otherwise benign pieces of code (gadgets), which inadvertently read from these attacker-controlled properties to execute security-sensitive operations. While prior works primarily study gadgets in third-party libraries and client-side applications, gadgets in JavaScript runtime environments are arguably more impactful as they affect any application that executes on these runtimes.\nIn this paper we design, implement, and evaluate a pipeline, GHunter, to systematically detect gadgets in V8-based JavaScript runtimes with prime focus on Node.js and Deno. GHunter supports a lightweight dynamic taint analysis to automatically identify gadget candidates which we validate manually to derive proof-of-concept exploits. We implement GHunter by modifying the V8 engine and the targeted runtimes along with features for facilitating manual validation. Driven by the comprehensive test suites of Node.js and Deno, we use GHunter in a systematic study of gadgets in these runtimes. We identified a total of 56 new gadgets in Node.js and 67 gadgets in Deno, pertaining to vulnerabilities such as arbitrary code execution (19), privilege escalation (31), path traversal (13), and more. Moreover, we systematize, for the first time, existing mitigations for prototype pollution and gadgets in terms of development guidelines. We collect a list of vulnerable applications and revisit the fixes through the lens of our guidelines. Through this exercise, we also identified one high-severity CVE leading to remote code execution, which was due to incorrectly fixing a gadget.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-cornelissen.pdf",
            "keywords": [
                "Prototype Pollution",
                "JavaScript Runtimes",
                "Gadget Detection",
                "Node.js",
                "Deno"
            ]
        },
        "url": "URL#379463"
    },
    {
        "@score": "1",
        "@id": "379464",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "65/550",
                        "text": "V\u00e9ronique Cortier"
                    },
                    {
                        "@pid": "231/1869",
                        "text": "Alexandre Debant"
                    },
                    {
                        "@pid": "370/6972",
                        "text": "Anselme Goetschmann"
                    },
                    {
                        "@pid": "140/7281",
                        "text": "Lucca Hirschi"
                    }
                ]
            },
            "title": "Election Eligibility with OpenID: Turning Authentication into Transferable Proof of Eligibility.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CortierDGH24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/cortier",
            "url": "https://dblp.org/rec/conf/uss/CortierDGH24",
            "abstract": "Eligibility checks are often abstracted away or omitted in voting protocols, leading to situations where the voting server can easily stuff the ballot box. One reason for this is the difficulty of bootstraping the authentication material for voters without relying on trusting the voting server.\nIn this paper, we propose a new protocol that solves this problem by building on OpenID, a widely deployed authentication protocol. Instead of using it as a standard authentication means, we turn it into a mechanism that delivers transferable proofs of eligibility. Using zk-SNARK proofs, we show that this can be done without revealing any compromising information, in particular, protecting everlasting privacy. Our approach remains efficient and can easily be integrated into existing protocols, as we have done for the Belenios voting protocol. We provide a full-fledged proof of concept along with benchmarks showing our protocol could be realistically used in large-scale elections.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-cortier.pdf",
            "keywords": [
                "Voting Protocols",
                "OpenID",
                "Transferable Proofs",
                "Eligibility Verification",
                "zk-SNARK"
            ]
        },
        "url": "URL#379464"
    },
    {
        "@score": "1",
        "@id": "379465",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "306/8440",
                        "text": "Braden L. Crimmins"
                    },
                    {
                        "@pid": "381/1589",
                        "text": "Dhanya Narayanan"
                    },
                    {
                        "@pid": "153/5737",
                        "text": "Drew Springall"
                    },
                    {
                        "@pid": "h/JAlexHalderman",
                        "text": "J. Alex Halderman"
                    }
                ]
            },
            "title": "DVSorder: Ballot Randomization Flaws Threaten Voter Privacy.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CrimminsNSH24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/crimmins",
            "url": "https://dblp.org/rec/conf/uss/CrimminsNSH24",
            "abstract": "A trend towards publishing ballot-by-ballot election results has created new risks to voter privacy due to inadequate protections by election technology. These risks are manifested by a vulnerability we discovered in precinct-based ballot scanners made by Dominion Voting Systems, which are used in parts of 21 states and Canada. In a variety of scenarios, the flaw\u2014which we call DVSorder\u2014would allow attackers to link individuals with their votes and compromise ballot secrecy. The root cause is that the scanners assign pseudorandom ballot identifiers using a linear congruential generator, an approach known since the 1970s to be insecure. Dominion attempted to obfuscate the generator's output, but we show that it can be broken using only pen and paper to reveal the order in which all ballots were cast. Unlike past ballot randomization flaws, which typically required insider access to exploit or access to proprietary software to discover, DVSorder can be discovered and exploited using only public information.\nIn addition, the election sector's response to our findings provides a case study highlighting gaps in regulations and vulnerability management within this area of critical infrastructure. Although Dominion released a software update in response to DVSorder, some localities have continued to publish vulnerable data due to inadequate information sharing and mitigation planning, and at least one state has deferred addressing the flaw until after the 2024 presidential election, more than two years following our disclosure.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-crimmins.pdf",
            "keywords": [
                "Election Technology",
                "Voter Privacy",
                "Ballot Randomization",
                "Dominion Voting Systems",
                "DVSorder Vulnerability"
            ]
        },
        "url": "URL#379465",
        "sema_paperId": "0ed6dc2da769c208fb63897cfecc0d7d0c0b6132"
    },
    {
        "@score": "1",
        "@id": "379466",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "88/8709",
                        "text": "Alejandro Cuevas"
                    },
                    {
                        "@pid": "c/NicolasChristin",
                        "text": "Nicolas Christin"
                    }
                ]
            },
            "title": "Does Online Anonymous Market Vendor Reputation Matter?",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CuevasC24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/cuevas",
            "url": "https://dblp.org/rec/conf/uss/CuevasC24",
            "abstract": "Reputation is crucial for trust in underground markets such as online anonymous marketplaces (OAMs), where there is little recourse against unscrupulous vendors. These markets rely on eBay-like feedback scores and forum reviews as reputation signals to ensure market safety, driving away dishonest vendors and \ufb02agging low-quality or dangerous products. Despite their importance, there has been scant work exploring the correlation (or lack thereof) between reputation signals and vendor success. To \ufb01ll this gap, we study vendor success from two angles: (i) longevity and (ii) future \ufb01nancial success, by studying eight OAMs from 2011 to 2023. We complement market data with social network features extracted from a OAM forum, and by qualitatively coding reputation signals from over 15,000 posts and comments across two subreddits. Using survival analysis techniques and simple Random Forest models, we show that feedback scores (including those imported from other markets) can explain vendors\u2019 longevity, but fail to predict vendor disappearance in the short term. Further, feedback scores are not the main predictors of future \ufb01nancial success. Rather, vendors who quickly generate revenue when they start on a market typically end up acquiring the most wealth overall. We show that our models generalize across different markets and time periods spanning over a decade. Our \ufb01ndings provide empirical insights into early identi\ufb01cation of potential high-scale vendors, effectiveness of \u201creputation poisoning\u201d strategies, and how reputation systems could contribute to harm reduction in OAMs. We \ufb01nd in particular that, despite their coarseness, existing reputation signals are useful to identify potentially dishonest sellers, and highlight some possible improvements.",
            "keywords": [
                "Online Anonymous Marketplaces",
                "Vendor Reputation",
                "Market Longevity",
                "Financial Success",
                "Reputation Signals"
            ]
        },
        "url": "URL#379466",
        "sema_paperId": "cf3900b79033ebcf2504cef5418a1fe4835b9a09"
    },
    {
        "@score": "1",
        "@id": "379467",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "350/0904",
                        "text": "Pranav Dahiya"
                    },
                    {
                        "@pid": "213/8587",
                        "text": "Ilia Shumailov"
                    },
                    {
                        "@pid": "a/RJAnderson",
                        "text": "Ross Anderson 0001"
                    }
                ]
            },
            "title": "Machine Learning needs Better Randomness Standards: Randomised Smoothing and PRNG-based attacks.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DahiyaS024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/dahiya",
            "url": "https://dblp.org/rec/conf/uss/DahiyaS024",
            "abstract": "Randomness supports many critical functions in the field of machine learning (ML) including optimisation, data selection, privacy, and security. ML systems outsource the task of generating or harvesting randomness to the compiler, the cloud service provider or elsewhere in the toolchain. Yet there is a long history of attackers exploiting poor randomness, or even creating it -- as when the NSA put backdoors in random number generators to break cryptography. In this paper we consider whether attackers can compromise an ML system using only the randomness on which they commonly rely. We focus our effort on Randomised Smoothing, a popular approach to train certifiably robust models, and to certify specific input datapoints of an arbitrary model. We choose Randomised Smoothing since it is used for both security and safety -- to counteract adversarial examples and quantify uncertainty respectively. Under the hood, it relies on sampling Gaussian noise to explore the volume around a data point to certify that a model is not vulnerable to adversarial examples. We demonstrate an entirely novel attack, where an attacker backdoors the supplied randomness to falsely certify either an overestimate or an underestimate of robustness for up to 81 times. We demonstrate that such attacks are possible, that they require very small changes to randomness to succeed, and that they are hard to detect. As an example, we hide an attack in the random number generator and show that the randomness tests suggested by NIST fail to detect it. We advocate updating the NIST guidelines on random number testing to make them more appropriate for safety-critical and security-critical machine-learning applications.",
            "keywords": [
                "Randomised Smoothing",
                "Robustness Certification",
                "Adversarial Examples",
                "Randomness Vulnerabilities",
                "Backdoored Randomness"
            ]
        },
        "url": "URL#379467",
        "sema_paperId": "5d4a659a8f3787853fd80727d6a0e2b7c3f4b764"
    },
    {
        "@score": "1",
        "@id": "379468",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "319/7073",
                        "text": "Edoardo Debenedetti"
                    },
                    {
                        "@pid": "221/4233",
                        "text": "Giorgio Severi"
                    },
                    {
                        "@pid": "187/8997",
                        "text": "Milad Nasr"
                    },
                    {
                        "@pid": "250/9674",
                        "text": "Christopher A. Choquette-Choo"
                    },
                    {
                        "@pid": "218/5156",
                        "text": "Matthew Jagielski"
                    },
                    {
                        "@pid": "218/6165",
                        "text": "Eric Wallace"
                    },
                    {
                        "@pid": "145/1806",
                        "text": "Nicholas Carlini"
                    },
                    {
                        "@pid": "158/7224",
                        "text": "Florian Tram\u00e8r"
                    }
                ]
            },
            "title": "Privacy Side Channels in Machine Learning Systems.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DebenedettiSNCJ24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/debenedetti",
            "url": "https://dblp.org/rec/conf/uss/DebenedettiSNCJ24",
            "abstract": "Most current approaches for protecting privacy in machine learning (ML) assume that models exist in a vacuum. Yet, in reality, these models are part of larger systems that include components for training data filtering, output monitoring, and more. In this work, we introduce privacy side channels: attacks that exploit these system-level components to extract private information at far higher rates than is otherwise possible for standalone models. We propose four categories of side channels that span the entire ML lifecycle (training data filtering, input preprocessing, output post-processing, and query filtering) and allow for enhanced membership inference, data extraction, and even novel threats such as extraction of users' test queries. For example, we show that deduplicating training data before applying differentially-private training creates a side-channel that completely invalidates any provable privacy guarantees. We further show that systems which block language models from regenerating training data can be exploited to exfiltrate private keys contained in the training set\u2014even if the model did not memorize these keys. Taken together, our results demonstrate the need for a holistic, end-to-end privacy analysis of machine learning systems.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-debenedetti.pdf",
            "keywords": [
                "Privacy Side Channels",
                "Membership Inference",
                "Data Extraction",
                "Differential Privacy",
                "Holistic Privacy Analysis"
            ]
        },
        "url": "URL#379468"
    },
    {
        "@score": "1",
        "@id": "379469",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "67/5099",
                        "text": "St\u00e9phanie Delaune"
                    },
                    {
                        "@pid": "179/4217",
                        "text": "Joseph Lallemand"
                    },
                    {
                        "@pid": "318/9107",
                        "text": "Gwendal Patat"
                    },
                    {
                        "@pid": "381/1600",
                        "text": "Florian Roudot"
                    },
                    {
                        "@pid": "162/4179",
                        "text": "Mohamed Sabt"
                    }
                ]
            },
            "title": "Formal Security Analysis of Widevine through the W3C EME Standard.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DelauneLPRS24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/delaune",
            "url": "https://dblp.org/rec/conf/uss/DelauneLPRS24",
            "abstract": "Streaming services such as Net\ufb02ix, Amazon Prime Video, or Disney+ rely on the widespread EME standard to deliver their content to end users on all major web browsers. While providing an abstraction layer to the underlying DRM protocols of each device, the security of this API has never been formally studied. In this paper, we provide the \ufb01rst formal analysis of Widevine, the most deployed DRM instantiating EME. We de\ufb01ne security goals for EME, focusing on media protection and usage control. Then, relying on the T AMARIN prover, we conduct a detailed security analysis of these goals on some Widevine EME implementations, reverse-engineered by us for this study. Our investigation highlights a vulnerability that could allow for unlimited media consumption. Additionally, we present a patched protocol that is suitable for both mobile and desktop platforms, and that we formally proved secure using T AMARIN .",
            "keywords": [
                "Digital Rights Management",
                "Widevine",
                "W3C EME Standard",
                "Media Protection",
                "Usage Control Vulnerability"
            ]
        },
        "url": "URL#379469",
        "sema_paperId": "5993f0d1727d258e56651c2471fb1716a6ccd6f8"
    },
    {
        "@score": "1",
        "@id": "379470",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "236/9144",
                        "text": "Gelei Deng"
                    },
                    {
                        "@pid": "97/4626-69",
                        "text": "Yi Liu 0069"
                    },
                    {
                        "@pid": "185/0906",
                        "text": "V\u00edctor Mayoral Vilches"
                    },
                    {
                        "@pid": "21/6121",
                        "text": "Peng Liu"
                    },
                    {
                        "@pid": "204/3729",
                        "text": "Yuekang Li"
                    },
                    {
                        "@pid": "89/3127",
                        "text": "Yuan Xu"
                    },
                    {
                        "@pid": "98/5177",
                        "text": "Martin Pinzger 0001"
                    },
                    {
                        "@pid": "79/5181",
                        "text": "Stefan Rass"
                    },
                    {
                        "@pid": "77/7902-4",
                        "text": "Tianwei Zhang 0004"
                    },
                    {
                        "@pid": "51/3710-3",
                        "text": "Yang Liu 0003"
                    }
                ]
            },
            "title": "PentestGPT: Evaluating and Harnessing Large Language Models for Automated Penetration Testing.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DengLVLLX0R0024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/deng",
            "url": "https://dblp.org/rec/conf/uss/DengLVLLX0R0024",
            "abstract": "We introduce P ENTEST GPT, an LLM-empowered automated penetration testing framework that leverages the abundant domain knowledge inherent in LLMs. P ENTEST GPT is metic-ulously designed with three self-interacting modules, each addressing individual sub-tasks of penetration testing, to mitigate the challenges related to context loss. Our evaluation shows that P ENTEST GPT not only outperforms LLMs with a task-completion increase of 228.6% compared to the GPT-3.5 model among the benchmark targets, but also proves effective in tackling real-world penetration testing targets and CTF challenges. Having been open-sourced on GitHub, P ENTEST - GPT has garnered over 6,500 stars in 12 months and fostered active community engagement, attesting to its value and impact in both the academic and industrial spheres.",
            "keywords": [
                "Automated Penetration Testing",
                "Large Language Models",
                "Context Loss Mitigation",
                "Real-World Testing",
                "CTF Challenges"
            ]
        },
        "url": "URL#379470",
        "sema_paperId": "27d0561813c6134d62a48cdc42e1aede23e76f98"
    },
    {
        "@score": "1",
        "@id": "379471",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "379/6204",
                        "text": "J\u00e9r\u00e9mie Dentan"
                    },
                    {
                        "@pid": "345/8760",
                        "text": "Arnaud Paran"
                    },
                    {
                        "@pid": "33/8108",
                        "text": "Aymen Shabou"
                    }
                ]
            },
            "title": "Reconstructing training data from document understanding models.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DentanPS24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/dentan",
            "url": "https://dblp.org/rec/conf/uss/DentanPS24",
            "abstract": "Document understanding models are increasingly employed by companies to supplant humans in processing sensitive documents, such as invoices, tax notices, or even ID cards. However, the robustness of such models to privacy attacks remains vastly unexplored.\nThis paper presents CDMI, the first reconstruction attack designed to extract sensitive fields from the training data of these models. We attack LayoutLM and BROS architectures, demonstrating that an adversary can perfectly reconstruct up to 4.1% of the fields of the documents used for fine-tuning, including some names, dates, and invoice amounts up to six-digit numbers. When our reconstruction attack is combined with a membership inference attack, our attack accuracy escalates to 22.5%.\nIn addition, we introduce two new end-to-end metrics and evaluate our approach under various conditions: unimodal or bimodal data, LayoutLM or BROS backbones, four fine-tuning tasks, and two public datasets (FUNSD and SROIE). We also investigate the interplay between overfitting, predictive performance, and susceptibility to our attack. We conclude with a discussion on possible defenses against our attack and potential future research directions to construct robust document understanding models.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-dentan.pdf",
            "keywords": [
                "Document Understanding",
                "Reconstruction Attack",
                "Privacy Attacks",
                "Sensitive Data Extraction",
                "Membership Inference Attack"
            ]
        },
        "url": "URL#379471"
    },
    {
        "@score": "1",
        "@id": "379472",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "270/2424",
                        "text": "Karel Dhondt"
                    },
                    {
                        "@pid": "221/3626",
                        "text": "Victor Le Pochat"
                    },
                    {
                        "@pid": "286/1246",
                        "text": "Yana Dimova"
                    },
                    {
                        "@pid": "13/86",
                        "text": "Wouter Joosen"
                    },
                    {
                        "@pid": "127/6103",
                        "text": "Stijn Volckaert"
                    }
                ]
            },
            "title": "Swipe Left for Identity Theft: An Analysis of User Data Privacy Risks on Location-based Dating Apps.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DhondtPDJV24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/dhondt",
            "url": "https://dblp.org/rec/conf/uss/DhondtPDJV24",
            "abstract": "Location-based dating (LBD) apps enable users to meet new people nearby and online by browsing others\u2019 profiles, which often contain very personal and sensitive data. We systematically analyze 15 LBD apps on the prevalence of privacy risks that can result in abuse by adversarial users who want to stalk, harass, or harm others. Through a systematic manual analysis of these apps, we assess which personal and sensitive data is shared with other users, both as (intended) data exposure and as inadvertent yet powerful leaks in API traffic that is otherwise hidden from a user, violating their mental model of what they share on LBD apps. We also show that 6 apps allow for pinpointing a victim\u2019s exact location, enabling physical threats to users\u2019 personal safety. All these data exposures and leaks \u2013 supported by easy account creation \u2013 enable targeted or large-scale, long-term, and stealthy profiling and tracking of LBD app users. While privacy policies acknowledge personal data processing, and a tension exists between app functionality and user privacy, significant data privacy risks remain. We recommend user control, data minimization, and API hardening as countermeasures to protect users\u2019 privacy.",
            "keywords": [
                "Location-based Dating Apps",
                "User Data Privacy",
                "Privacy Risks",
                "Data Exposure",
                "Location Tracking"
            ]
        },
        "url": "URL#379472",
        "sema_paperId": "96e038d75dc133d2daf67268be1ca5aea61b6ec9"
    },
    {
        "@score": "1",
        "@id": "379473",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "325/5429",
                        "text": "Abdulrahman Diaa"
                    },
                    {
                        "@pid": "294/8935",
                        "text": "Lucas Fenaux"
                    },
                    {
                        "@pid": "228/2929",
                        "text": "Thomas Humphries"
                    },
                    {
                        "@pid": "349/4641",
                        "text": "Marian Dietz"
                    },
                    {
                        "@pid": "349/4964",
                        "text": "Faezeh Ebrahimianghazani"
                    },
                    {
                        "@pid": "205/0183",
                        "text": "Bailey Kacsmar"
                    },
                    {
                        "@pid": "296/4272",
                        "text": "Xinda Li 0001"
                    },
                    {
                        "@pid": "243/3102",
                        "text": "Nils Lukas"
                    },
                    {
                        "@pid": "280/8174",
                        "text": "Rasoul Akhavan Mahdavi"
                    },
                    {
                        "@pid": "147/1534",
                        "text": "Simon Oya"
                    },
                    {
                        "@pid": "158/8306",
                        "text": "Ehsan Amjadian"
                    },
                    {
                        "@pid": "26/5304",
                        "text": "Florian Kerschbaum"
                    }
                ]
            },
            "title": "Fast and Private Inference of Deep Neural Networks by Co-designing Activation Functions.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DiaaFHDEK0LMOAK24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/diaa",
            "url": "https://dblp.org/rec/conf/uss/DiaaFHDEK0LMOAK24",
            "abstract": "Machine Learning as a Service (MLaaS) is an increasingly popular design where a company with abundant computing resources trains a deep neural network and offers query access for tasks like image classification. The challenge with this design is that MLaaS requires the client to reveal their potentially sensitive queries to the company hosting the model. Multi-party computation (MPC) protects the client's data by allowing encrypted inferences. However, current approaches suffer from prohibitively large inference times. The inference time bottleneck in MPC is the evaluation of non-linear layers such as ReLU activation functions. Motivated by the success of previous work co-designing machine learning and MPC, we develop an activation function co-design. We replace all ReLUs with a polynomial approximation and evaluate them with single-round MPC protocols, which give state-of-the-art inference times in wide-area networks. Furthermore, to address the accuracy issues previously encountered with polynomial activations, we propose a novel training algorithm that gives accuracy competitive with plaintext models. Our evaluation shows between $3$ and $110\\times$ speedups in inference time on large models with up to $23$ million parameters while maintaining competitive inference accuracy.",
            "keywords": [
                "Machine Learning as a Service (MLaaS)",
                "Multi-party Computation (MPC)",
                "Activation Function Co-design",
                "Polynomial Approximation",
                "Inference Time Optimization"
            ]
        },
        "url": "URL#379473",
        "sema_paperId": "469ffe19bfc74081aa001ce1044c671658f01d53"
    },
    {
        "@score": "1",
        "@id": "379474",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "332/6360",
                        "text": "Zikan Dong"
                    },
                    {
                        "@pid": "96/5013-2",
                        "text": "Tianming Liu 0002"
                    },
                    {
                        "@pid": "370/5563",
                        "text": "Jiapeng Deng"
                    },
                    {
                        "@pid": "50/8499-1",
                        "text": "Haoyu Wang 0001"
                    },
                    {
                        "@pid": "53/2189-29",
                        "text": "Li Li 0029"
                    },
                    {
                        "@pid": "63/6144",
                        "text": "Minghui Yang"
                    },
                    {
                        "@pid": "93/6765",
                        "text": "Meng Wang"
                    },
                    {
                        "@pid": "130/0993-1",
                        "text": "Guosheng Xu 0001"
                    },
                    {
                        "@pid": "76/10013",
                        "text": "Guoai Xu"
                    }
                ]
            },
            "title": "Exploring Covert Third-party Identifiers through External Storage in the Android New Era.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DongLD00YW0X24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/dong-zikan",
            "url": "https://dblp.org/rec/conf/uss/DongLD00YW0X24",
            "abstract": "Third-party tracking plays a vital role in the mobile app ecosystem, which relies on identifiers to gather user data across multiple apps. In the early days of Android, tracking SDKs could effortlessly access non-resettable hardware identifiers for third-party tracking. However, as privacy concerns mounted, Google has progressively restricted device identifier usage through Android system updates. In the new era, tracking SDKs are only allowed to employ user-resettable identifiers which users can also opt out of, prompting SDKs to seek alternative methods for reliable user identification across apps. In this paper, we systematically explore the practice of third-party tracking SDKs covertly storing their own generated identifiers on external storage, thereby circumventing Android\u2019s identifier usage restriction and posing a considerable threat to user privacy. We devise an analysis pipeline for an extensive large-scale investigation of this phenomenon, leveraging kernel-level instrumentation and UI testing techniques to automate the recording of app file operations at runtime. Applying our pipeline to 8,000 Android apps, we identified 17 third-party tracking SDKs that store identifiers on external storage. Our analysis reveals that these SDKs employ a range of storage techniques, including hidden files and attaching to existing media files, to make their identifiers more discreet and persistent. We also found that most SDKs lack adequate security measures, compromising the confidentiality and integrity of identifiers and enabling deliberate attacks. Furthermore, we examined the impact of Scoped Storage - Android\u2019s latest defense mechanism for external storage on these covert third-party",
            "keywords": [
                "Mobile App Tracking",
                "Third-party SDKs",
                "User Privacy",
                "External Storage",
                "Covert Identifiers"
            ]
        },
        "url": "URL#379474",
        "sema_paperId": "ec506f6ce47397d8b65dc8daeeea98f3de7a5cc1"
    },
    {
        "@score": "1",
        "@id": "379475",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "88/7785",
                        "text": "Kai Dong"
                    },
                    {
                        "@pid": "181/2621",
                        "text": "Zheng Zhang"
                    },
                    {
                        "@pid": "360/9883",
                        "text": "Chuang Jia"
                    },
                    {
                        "@pid": "79/7563",
                        "text": "Zhen Ling"
                    },
                    {
                        "@pid": "98/2604-1",
                        "text": "Ming Yang 0001"
                    },
                    {
                        "@pid": "l/JunzhouLuo",
                        "text": "Junzhou Luo"
                    },
                    {
                        "@pid": "49/2189",
                        "text": "Xinwen Fu"
                    }
                ]
            },
            "title": "Relation Mining Under Local Differential Privacy.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DongZJL0LF24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/dong-kai",
            "url": "https://dblp.org/rec/conf/uss/DongZJL0LF24",
            "abstract": "Existing local differential privacy (LDP) techniques enable untrustworthy aggregators to perform only very simple data mining tasks on distributed private data, including statistical estimation and frequent item mining. There is currently no general LDP method that discovers relations between items. The main challenge lies in the curse of dimensionality, as the quantity of values to be estimated in mining relations is the square of the quantity of values to be estimated in mining item-level knowledge, leading to a considerable decrease in the final estimation accuracy. We propose LDP-RM, the first relation mining method under LDP. It represents items and relations in a matrix and utilizes singular value decomposition and low rank approximation to reduce the number of values to estimate from O ( k 2 ) to O ( r ) , where k is the number of all considered items, and r < k is a parameter determined by the aggregator, signifying the rank of the approximation. LDP-RM serves as a fundamental privacy-preserving method for enabling various complex data mining tasks.",
            "keywords": [
                "Local Differential Privacy",
                "Relation Mining",
                "Data Aggregation",
                "Estimation Accuracy",
                "Singular Value Decomposition"
            ]
        },
        "url": "URL#379475",
        "sema_paperId": "0a0b66f0fdc3add6512fbaed8eb4ebb7e4882220"
    },
    {
        "@score": "1",
        "@id": "379476",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "374/6768",
                        "text": "Niels Dossche"
                    },
                    {
                        "@pid": "93/7397",
                        "text": "Bart Coppens 0001"
                    }
                ]
            },
            "title": "Inference of Error Specifications and Bug Detection Using Structural Similarities.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Dossche024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/dossche",
            "url": "https://dblp.org/rec/conf/uss/Dossche024",
            "abstract": "Error-handling code is a crucial part of software to ensure stability and security. Failing to handle errors correctly can lead to security vulnerabilities such as DoS, privilege escalation, and data corruption. We propose a novel approach to automatically infer error specifications for system software without a priori domain knowledge, while still achieving a high re-call and precision. The key insight behind our approach is that we can identify error-handling paths automatically based on structural similarities between error-handling code. We use the inferred error specification to detect three kinds of bugs: missing error checks, incorrect error checks, and error propagation bugs. Our technique uses a combination of path-sensitive, flow-sensitive and both intra-procedural and inter-procedural data-flow analysis to achieve high accuracy and great scalability. We implemented our technique in a tool called ESSS to demonstrate the effectiveness and efficiency of our approach on 7 well-tested, widely-used open-source software projects: OpenSSL, OpenSSH, PHP, zlib, libpng, freetype2, and libwebp. Our tool reported 827 potential bugs in total for all 7 projects combined. We manually categorised these 827 issues into 279 false positives and 541 true positives. Out of these 541 true positives, we sent bug reports and corresponding patches for 46 of them. All the patches were accepted and applied.",
            "keywords": [
                "Error Handling",
                "Bug Detection",
                "Software Reliability",
                "Data-Flow Analysis",
                "Error Specification Inference"
            ]
        },
        "url": "URL#379476",
        "sema_paperId": "654d4de965e4d434d86a21cdab2a4adbc49f1454"
    },
    {
        "@score": "1",
        "@id": "379477",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "344/2527",
                        "text": "Luke Dramko"
                    },
                    {
                        "@pid": "223/2758",
                        "text": "Jeremy Lacomis"
                    },
                    {
                        "@pid": "21/8302",
                        "text": "Edward J. Schwartz"
                    },
                    {
                        "@pid": "43/10504",
                        "text": "Bogdan Vasilescu"
                    },
                    {
                        "@pid": "93/4573",
                        "text": "Claire Le Goues"
                    }
                ]
            },
            "title": "A Taxonomy of C Decompiler Fidelity Issues.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DramkoLSVG24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/dramko",
            "url": "https://dblp.org/rec/conf/uss/DramkoLSVG24",
            "abstract": "Decompilation is an important part of analyzing threats in computer security. Unfortunately, decompiled code contains less information than the corresponding original source code, which makes understanding it more dif\ufb01cult for the reverse engineers who manually perform threat analysis. Thus, the \ufb01delity of decompiled code to the original source code matters, as it can in\ufb02uence reverse engineers\u2019 productivity. There is some existing work in predicting some of the missing information using statistical methods, but these focus largely on variable names and variable types. In this work, we more holistically evaluate decompiler output from C-language exe-cutables and use our \ufb01ndings to inform directions for future decompiler development. More speci\ufb01cally, we use open-coding techniques to identify defects in decompiled code beyond missing names and types. To ensure that our study is robust, we compare and evaluate four different decompilers. Using thematic analysis, we build a taxonomy of decompiler defects. Using this taxonomy to reason about classes of issues, we suggest speci\ufb01c approaches that can be used to mitigate \ufb01delity issues in decompiled code.",
            "keywords": [
                "Decompilation",
                "C Language",
                "Decompiler Fidelity",
                "Reverse Engineering",
                "Taxonomy of Defects"
            ]
        },
        "url": "URL#379477",
        "sema_paperId": "1c6dce687b7e8c7761caddeede62d0b084e16de6"
    },
    {
        "@score": "1",
        "@id": "379478",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "52/10310",
                        "text": "Jannik Dreier"
                    },
                    {
                        "@pid": "l/PascalLafourcade",
                        "text": "Pascal Lafourcade 0001"
                    },
                    {
                        "@pid": "379/0166",
                        "text": "Dhekra Mahmoud"
                    }
                ]
            },
            "title": "Shaken, not Stirred - Automated Discovery of Subtle Attacks on Protocols using Mix-Nets.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Dreier0M24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/dreier",
            "url": "https://dblp.org/rec/conf/uss/Dreier0M24",
            "abstract": "Mix-Nets are used to provide anonymity by passing a list of inputs through a collection of mix servers. Each server mixes the entries to create a new anonymized list, so that the correspondence between the output and the input is hidden. These Mix-Nets are used in numerous protocols in which the anonymity of participants is required, for example voting or electronic exam protocols. Some of these protocols have been proven secure using automated tools such as the cryptographic protocol verifier ProVerif, although they use the Mix-Net incorrectly. We propose a more detailed formal model of exponentiation and re-encryption Mix-Nets in the applied \u03a0 -Calculus, the language used by ProVerif, and show that using this model we can automatically discover attacks based on the incorrect use of the Mix-Net. In particular, we (re-)discover attacks on four cryptographic protocols using ProVerif: we show that an electronic exam protocol, two electronic voting protocols, and the \u201cCrypto Santa\u201d protocol do not satisfy the desired privacy properties. We then fix the vulnerable protocols by adding missing zero-knowledge proofs and analyze the resulting protocols using ProVerif. Again, in addition to the common abstract modeling of Zero Knowledge Proofs (ZKP), we also use a special model corresponding to weak (malleable) ZKPs. We show that in this case all attacks persist, and that we (re)discover these attacks automatically.",
            "keywords": [
                "Mix-Nets",
                "Anonymity Protocols",
                "Cryptographic Protocol Verification",
                "Zero-Knowledge Proofs",
                "Privacy Attacks"
            ]
        },
        "url": "URL#379478",
        "sema_paperId": "75917d8e72a0fe361db3415038533a368a9be879"
    },
    {
        "@score": "1",
        "@id": "379479",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "201/5538",
                        "text": "Wenlong Du"
                    },
                    {
                        "@pid": "33/5448",
                        "text": "Jian Li"
                    },
                    {
                        "@pid": "123/2365",
                        "text": "Yanhao Wang"
                    },
                    {
                        "@pid": "08/4315-1",
                        "text": "Libo Chen 0001"
                    },
                    {
                        "@pid": "92/10854-1",
                        "text": "Ruijie Zhao 0001"
                    },
                    {
                        "@pid": "67/7955",
                        "text": "Junmin Zhu"
                    },
                    {
                        "@pid": "352/6659",
                        "text": "Zhengguang Han"
                    },
                    {
                        "@pid": "27/1332",
                        "text": "Yijun Wang"
                    },
                    {
                        "@pid": "44/3322",
                        "text": "Zhi Xue"
                    }
                ]
            },
            "title": "Vulnerability-oriented Testing for RESTful APIs.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DuLW00ZHWX24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/du",
            "url": "https://dblp.org/rec/conf/uss/DuLW00ZHWX24",
            "abstract": "With the increasing popularity of APIs, ensuring their security has become a crucial concern. However, existing security testing methods for RESTful APIs usually lack targeted approaches to identify and detect security vulnerabilities. In this paper, we propose V O API 2 , a vulnerability-oriented API inspection framework designed to directly expose vulnerabilities in RESTful APIs, based on our observation that the type of vulnerability hidden in an API interface is strongly associated with its functionality. By leveraging this insight, we first track commonly used strings as keywords to identify APIs\u2019 functionality. Then, we generate a stateful and suitable request sequence to inspect the candidate API function within a targeted payload. Finally, we verify whether vulnerabilities exist or not through feedback-based testing. Our experiments on real-world APIs demonstrate the effectiveness of our approach, with significant improvements in vulnerability detection compared to state-of-the-art methods. V O API 2 discovered 7 zero-day and 19 disclosed bugs on seven real-world RESTful APIs, and 23 of them have been assigned CVE IDs. Our findings highlight the importance of considering APIs\u2019 functionality when discovering their bugs, and our method provides a practical and efficient solution for securing RESTful APIs.",
            "keywords": [
                "RESTful API Security",
                "Vulnerability Detection",
                "API Inspection Framework",
                "Feedback-Based Testing",
                "Zero-Day Vulnerabilities"
            ]
        },
        "url": "URL#379479",
        "sema_paperId": "f11fc2d52a7bee74f9339c56c7d6da0f5e1d3f50"
    },
    {
        "@score": "1",
        "@id": "379480",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "191/7808",
                        "text": "Huayi Duan"
                    },
                    {
                        "@pid": "356/7822",
                        "text": "Marco Bearzi"
                    },
                    {
                        "@pid": "215/9909",
                        "text": "Jodok Vieli"
                    },
                    {
                        "@pid": "b/DavidABasin",
                        "text": "David A. Basin"
                    },
                    {
                        "@pid": "16/6873",
                        "text": "Adrian Perrig"
                    },
                    {
                        "@pid": "147/8363-3",
                        "text": "Si Liu 0003"
                    },
                    {
                        "@pid": "93/3619",
                        "text": "Bernhard Tellenbach"
                    }
                ]
            },
            "title": "CAMP: Compositional Amplification Attacks against DNS.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DuanBVBP0T24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/duan",
            "url": "https://dblp.org/rec/conf/uss/DuanBVBP0T24",
            "abstract": "While DNS is often exploited by reflective DoS attacks, it can also be weaponized as a powerful amplifier to overload itself, as evidenced by a stream of recently discovered application-layer amplification attacks. Given the importance of DNS, the question arises of what the fundamental traits are for such attacks. To answer this question, we perform a systematic investigation by establishing a taxonomy of amplification primitives intrinsic to DNS and a framework to analyze their composability. This approach leads to the discovery of a large family of compositional amplification (CAMP) vulnerabilities, which can produce multiplicative effects with message amplification factors of hundreds to thousands. Our measurements with popular DNS implementations and open resolvers indicate the ubiquity and severity of CAMP vulnerabilities and the serious threats they pose to the Internet's crucial naming infrastructure.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-duan.pdf",
            "keywords": [
                "DNS Security",
                "Amplification Attacks",
                "Compositional Amplification",
                "CAMP Vulnerabilities",
                "Internet Naming Infrastructure"
            ]
        },
        "url": "URL#379480",
        "sema_paperId": "4613e88ebc15dab9dc052ab6898221c5d94dbcab"
    },
    {
        "@score": "1",
        "@id": "379481",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "304/4740",
                        "text": "Martin Dunsche"
                    },
                    {
                        "@pid": "331/2735",
                        "text": "Marcel Maehren"
                    },
                    {
                        "@pid": "224/9173",
                        "text": "Nurullah Erinola"
                    },
                    {
                        "@pid": "248/1716",
                        "text": "Robert Merget"
                    },
                    {
                        "@pid": "11/8506",
                        "text": "Nicolai Bissantz"
                    },
                    {
                        "@pid": "27/8331",
                        "text": "Juraj Somorovsky"
                    },
                    {
                        "@pid": "58/5730",
                        "text": "J\u00f6rg Schwenk"
                    }
                ]
            },
            "title": "With Great Power Come Great Side Channels: Statistical Timing Side-Channel Analyses with Bounded Type-1 Errors.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DunscheMEMBSS24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/dunsche",
            "url": "https://dblp.org/rec/conf/uss/DunscheMEMBSS24",
            "abstract": "Constant-time implementations are essential to guarantee the security of secret-key operations. According to Jancar et al. [42], most cryptographic developers do not use statistical tests to evaluate their implementations for timing side-channel vulnerabilities. One of the main reasons is their high unreliability due to potential false positives caused by noisy data. In this work, we address this issue and present an improved statistical evaluation methodology with a controlled type-1 error ( \u03b1 ) that restricts false positives independently of the noise distribution. Simultaneously, we guarantee statistical power with increasing sample size. With the bounded type-1 error, the user can perform trade-offs between false positives and the size of the side channels they wish to detect. We achieve this by employing an empirical bootstrap that creates a decision rule based on the measured data. We implement this approach in an open-source tool called RTLF and compare it with three different competitors: Mona , dudect , and tlsfuzzer . We further compare our results to the t-test, a commonly used statistical test for side-channel analysis. To show the applicability of our tool in real cryptographic network scenarios, we performed a quantitative analysis with local timing measurements for CBC Padding Oracle attacks, Bleichenbacher\u2019s attack, and the Lucky13 attack in 823 available versions of eleven TLS libraries. Additionally, we performed a qualitative analysis of the most recent version of each library. We find that most libraries were long-time vulnerable to at least one of the considered attacks, with side channels big enough likely to be exploitable in a LAN setting. Through the qualitative analysis based on the results of RTLF, we identified seven vulnerabilities in recent versions.",
            "keywords": [
                "Timing Side-Channel Analysis",
                "Cryptographic Implementations",
                "Statistical Testing",
                "Type-1 Error Control",
                "Vulnerability Detection"
            ]
        },
        "url": "URL#379481",
        "sema_paperId": "1cc16715a1f36da709ee648ba133654a48da65f4"
    },
    {
        "@score": "1",
        "@id": "379482",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "290/4154",
                        "text": "Victor Duta"
                    },
                    {
                        "@pid": "236/7318",
                        "text": "Mitchel Aloserij"
                    },
                    {
                        "@pid": "75/8194",
                        "text": "Cristiano Giuffrida"
                    }
                ]
            },
            "title": "SafeFetch: Practical Double-Fetch Protection with Kernel-Fetch Caching.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DutaAG24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/duta",
            "url": "https://dblp.org/rec/conf/uss/DutaAG24",
            "abstract": "Double-fetch bugs (or vulnerabilities) stem from in-kernel system call execution fetching the same user data twice without proper data (re)sanitization, enabling TOCT-TOU attacks and posing a major threat to operating systems security. Existing double-fetch protection systems rely on the MMU to trap on writes to syscall-accessed user pages and provide the kernel with a consistent snap-shot of user memory. While this strategy can hinder attacks, it also introduces nontrivial runtime performance overhead due to the cost of trapping/remapping and the coarse ( page-granular ) write interposition mechanism. In this paper, we propose SafeFetch , a practical solu-tion to protect the kernel from double-fetch bugs. The key intuition is that most system calls fetch small amounts of user data (if at all), hence caching this data in the kernel can be done at a small performance cost. To this end, SafeFetch creates per-syscall caches to persist fetched user data and replay them when they are fetched again within the same syscall. This strategy neutralizes all double-fetch bugs, while eliminating trapping/remapping overheads and relying on e\ufb03cient byte-granular interposition. Our Linux prototype evaluation shows SafeFetch can provide comprehensive protection with low performance overheads (e.g., 4.4% geomean on LMBench), signi\ufb01cantly outperforming state-of-the-art solutions.",
            "keywords": [
                "Kernel Security",
                "Double-Fetch Bugs",
                "System Call Protection",
                "User Data Caching",
                "TOCTOU Attacks"
            ]
        },
        "url": "URL#379482",
        "sema_paperId": "9c312674f04e0cd0eb9cb8c1239bff833359d450"
    },
    {
        "@score": "1",
        "@id": "379483",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "331/5022",
                        "text": "Harry Eldridge"
                    },
                    {
                        "@pid": "224/2397",
                        "text": "Gabrielle Beck"
                    },
                    {
                        "@pid": "74/4531-1",
                        "text": "Matthew Green 0001"
                    },
                    {
                        "@pid": "12/3207",
                        "text": "Nadia Heninger"
                    },
                    {
                        "@pid": "34/3",
                        "text": "Abhishek Jain 0002"
                    }
                ]
            },
            "title": "Abuse-Resistant Location Tracking: Balancing Privacy and Safety in the Offline Finding Ecosystem.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/EldridgeB0H024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/eldridge",
            "url": "https://dblp.org/rec/conf/uss/EldridgeB0H024",
            "abstract": "Location tracking accessories (or \"tracking tags\") such as those sold by Apple, Samsung, and Tile, allow owners to track the location of their property via offline finding networks. The tracking protocols were designed to ensure that no entity (including the vendor) can use a tag's broadcasts to surveil its owner. These privacy guarantees, however, seem to be at odds with the phenomenon of tracker-based stalking, where attackers use these very tags to monitor a target's movements. Numerous such criminal incidents have been reported, and in response, manufacturers have chosen to substantially weaken privacy guarantees in order to allow users to detect stalker tags. This compromise has been adopted in a recent IETF draft jointly proposed by Apple and Google.\nWe put forth the notion of abuse-resistant offline finding protocols that aim to achieve a better balance between user privacy and stalker detection. We present an efficient protocol that achieves stalker detection under realistic conditions without sacrificing honest user privacy. At the heart of our result, and of independent interest, is a new notion of multi-dealer secret sharing which strengthens standard secret sharing with novel privacy and correctness guarantees. We show that this primitive can be instantiated efficiently on edge devices using variants of Interleaved Reed-Solomon codes combined with new lattice-based decoding algorithms.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-eldridge.pdf",
            "keywords": [
                "Location Tracking",
                "Privacy Preservation",
                "Stalker Detection",
                "Offline Finding Protocols",
                "Multi-Dealer Secret Sharing"
            ]
        },
        "url": "URL#379483"
    },
    {
        "@score": "1",
        "@id": "379484",
        "info": {
            "authors": {
                "author": {
                    "@pid": "198/0935",
                    "text": "Saba Eskandarian"
                }
            },
            "title": "Abuse Reporting for Metadata-Hiding Communication Based on Secret Sharing.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Eskandarian24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/eskandarian",
            "url": "https://dblp.org/rec/conf/uss/Eskandarian24",
            "abstract": "As interest in metadata-hiding communication grows in both research and practice, a need exists for stronger abuse reporting features on metadata-hiding platforms. While message franking has been deployed on major end-to-end encrypted platforms as a lightweight and effective abuse reporting feature, there is no comparable technique for metadata-hiding platforms. Existing efforts to support abuse reporting in this setting, such as asymmetric message franking or the Hecate scheme, require order of magnitude increases in client and server computation or fundamental changes to the architecture of messaging systems. As a result, while metadata-hiding communication inches closer to practice, critical content moderation concerns remain unaddressed.\nThis paper demonstrates that, for broad classes of metadata-hiding schemes, lightweight abuse reporting can be deployed with minimal changes to the overall architecture of the system. Our insight is that much of the structure needed to support abuse reporting already exists in these schemes. By taking a non-generic approach, we can reuse this structure to achieve abuse reporting with minimal overhead. In particular, we show how to modify schemes based on secret sharing user inputs to support a message franking-style protocol. Compared to prior work, our shared franking technique more than halves the time to prepare a franked message and gives order of magnitude reductions in server-side message processing times, as well as in the time to decrypt a message and verify a report.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-eskandarian.pdf",
            "keywords": [
                "Metadata-Hiding Communication",
                "Abuse Reporting",
                "Secret Sharing",
                "Message Franking",
                "Content Moderation"
            ]
        },
        "url": "URL#379484"
    },
    {
        "@score": "1",
        "@id": "379485",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "381/1682",
                        "text": "Aksel Ethembabaoglu"
                    },
                    {
                        "@pid": "224/9337",
                        "text": "Rolf van Wegberg"
                    },
                    {
                        "@pid": "94/10817",
                        "text": "Yury Zhauniarovich"
                    },
                    {
                        "@pid": "17/7444",
                        "text": "Michel van Eeten"
                    }
                ]
            },
            "title": "The Unpatchables: Why Municipalities Persist in Running Vulnerable Hosts.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/EthembabaogluWZ24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/ethembabaoglu",
            "url": "https://dblp.org/rec/conf/uss/EthembabaogluWZ24",
            "abstract": "Many organizations continue to expose vulnerable systems for which patches exist, opening themselves up for cyberat-tacks. Local governments are found to be especially affected by this problem. Why are these systems not patched? Prior work relied on vulnerability scanning to observe unpatched systems, notification studies on remediating them, and on user studies of sysadmins to describe self-reported patching behavior, but they are rarely used together as we do in this study. We analyze scan data following standard industry practices and detect unpatched hosts across the set of 322 Dutch municipalities. Our first question is: Are these detections false positives? We engage with 29 security professionals working for 54 municipalities to collect ground truth. All detections were accurate. Our approach also uncovers a major misalignment between systems that the responsible CERT attributes to the municipalities and the systems the practitioners at municipalities believe they are responsible for. We then interviewed the professionals as to why these vulnerable systems were still exposed. We identify four explanations for non-patching: unaware , unable , retired and shut down . The institutional framework to mitigate cyber threats assumes that vulnerable systems are first correctly identified, then correctly attributed and notified, and finally correctly mitigated. Our findings illustrate that the first assumption is correct, the second one is not and the third one is more complicated in practice. We end with reflections on how to better remediate vulnerable hosts.",
            "keywords": [
                "Cybersecurity Vulnerabilities",
                "Municipal IT Systems",
                "Patch Management",
                "Vulnerability Remediation",
                "Local Government Security"
            ]
        },
        "url": "URL#379485",
        "sema_paperId": "90309e3ad2f777224f2f31d34443f82c95f3fef8"
    },
    {
        "@score": "1",
        "@id": "379486",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "333/8848",
                        "text": "Andr\u00e9s F\u00e1brega"
                    },
                    {
                        "@pid": "301/5856",
                        "text": "Armin Namavari"
                    },
                    {
                        "@pid": "41/5447-1",
                        "text": "Rachit Agarwal 0001"
                    },
                    {
                        "@pid": "192/2096",
                        "text": "Ben Nassi"
                    },
                    {
                        "@pid": "26/3399",
                        "text": "Thomas Ristenpart"
                    }
                ]
            },
            "title": "Exploiting Leakage in Password Managers via Injection Attacks.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/FabregaN0NR24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/fabrega",
            "url": "https://dblp.org/rec/conf/uss/FabregaN0NR24",
            "abstract": "This work explores injection attacks against password managers. In this setting, the adversary (only) controls their own application client, which they use to ''inject\" chosen payloads to a victim's client via, for example, sharing credentials with them. The injections are interleaved with adversarial observations of some form of protected state (such as encrypted vault exports or the network traffic received by the application servers), from which the adversary backs out confidential information. We uncover a series of general design patterns in popular password managers that lead to vulnerabilities allowing an adversary to efficiently recover passwords, URLs, usernames, and attachments. We develop general attack templates to exploit these design patterns and experimentally showcase their practical efficacy via analysis of ten distinct password manager applications. We disclosed our findings to these vendors, many of which deployed mitigations.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-fabrega.pdf",
            "keywords": [
                "Password Manager Security",
                "Injection Attacks",
                "Confidential Information Leakage",
                "Vulnerability Exploitation",
                "Adversarial Payload Injection"
            ]
        },
        "url": "URL#379486"
    },
    {
        "@score": "1",
        "@id": "379487",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "232/9671",
                        "text": "Chongzhou Fang"
                    },
                    {
                        "@pid": "230/7777",
                        "text": "Ning Miao"
                    },
                    {
                        "@pid": "359/3279",
                        "text": "Shaurya Srivastav"
                    },
                    {
                        "@pid": "32/5050-6",
                        "text": "Jialin Liu 0006"
                    },
                    {
                        "@pid": "81/8054",
                        "text": "Ruoyu Zhang"
                    },
                    {
                        "@pid": "190/7161",
                        "text": "Ruijie Fang"
                    },
                    {
                        "@pid": "364/7717",
                        "text": "Asmita"
                    },
                    {
                        "@pid": "335/5778",
                        "text": "Ryan Tsang"
                    },
                    {
                        "@pid": "251/4305",
                        "text": "Najmeh Nazari"
                    },
                    {
                        "@pid": "67/1771",
                        "text": "Han Wang"
                    },
                    {
                        "@pid": "63/3012",
                        "text": "Houman Homayoun"
                    }
                ]
            },
            "title": "Large Language Models for Code Analysis: Do LLMs Really Do Their Job?",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/FangMS0ZFATNWH24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/fang",
            "url": "https://dblp.org/rec/conf/uss/FangMS0ZFATNWH24",
            "abstract": "Large language models (LLMs) have demonstrated significant potential in the realm of natural language understanding and programming code processing tasks. Their capacity to comprehend and generate human-like code has spurred research into harnessing LLMs for code analysis purposes. However, the existing body of literature falls short in delivering a systematic evaluation and assessment of LLMs' effectiveness in code analysis, particularly in the context of obfuscated code.\nThis paper seeks to bridge this gap by offering a comprehensive evaluation of LLMs' capabilities in performing code analysis tasks. Additionally, it presents real-world case studies that employ LLMs for code analysis. Our findings indicate that LLMs can indeed serve as valuable tools for automating code analysis, albeit with certain limitations. Through meticulous exploration, this research contributes to a deeper understanding of the potential and constraints associated with utilizing LLMs in code analysis, paving the way for enhanced applications in this critical domain.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-fang.pdf",
            "keywords": [
                "Large Language Models",
                "Code Analysis",
                "Obfuscated Code",
                "Automated Code Review",
                "Evaluation of LLMs"
            ]
        },
        "url": "URL#379487"
    },
    {
        "@score": "1",
        "@id": "379488",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "172/9363",
                        "text": "Yuanyuan Feng"
                    },
                    {
                        "@pid": "170/4795",
                        "text": "Abhilasha Ravichander"
                    },
                    {
                        "@pid": "142/7931",
                        "text": "Yaxing Yao"
                    },
                    {
                        "@pid": "83/3715",
                        "text": "Shikun Zhang"
                    },
                    {
                        "@pid": "13/4037",
                        "text": "Rex Chen"
                    },
                    {
                        "@pid": "98/8884",
                        "text": "Shomir Wilson"
                    },
                    {
                        "@pid": "18/5502",
                        "text": "Norman Sadeh 0001"
                    }
                ]
            },
            "title": "Understanding How to Inform Blind and Low-Vision Users about Data Privacy through Privacy Question Answering Assistants.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/FengRYZCW024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/feng-yuanyuan",
            "url": "https://dblp.org/rec/conf/uss/FengRYZCW024",
            "abstract": "Understanding and managing data privacy in the digital world can be challenging for sighted users, let alone blind and low-vision (BLV) users. There is limited research on how BLV users, who have special accessibility needs, navigate data privacy, and how potential privacy tools could assist them. We conducted an in-depth qualitative study with 21 US BLV participants to understand their data privacy risk perception and mitigation, as well as their information behaviors related to data privacy. We also explored BLV users' attitudes towards potential privacy question answering (Q&A) assistants that enable them to better navigate data privacy information. We found that BLV users face heightened security and privacy risks, but their risk mitigation is often insufficient.  They do not necessarily seek data privacy information but clearly recognize the benefits of a potential privacy Q&A assistant.  They also expect privacy Q&A assistants to possess cross-platform compatibility, support multi-modality, and demonstrate robust functionality. Our study sheds light on BLV users' expectations when it comes to usability, accessibility, trust and equity issues regarding digital data privacy.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-feng-yuanyuan.pdf",
            "keywords": [
                "Data Privacy",
                "Blind and Low-Vision Users",
                "Privacy Question Answering Assistants",
                "Accessibility",
                "Risk Mitigation"
            ]
        },
        "url": "URL#379488"
    },
    {
        "@score": "1",
        "@id": "379489",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "337/0846",
                        "text": "Siyue Feng"
                    },
                    {
                        "@pid": "77/8060-1",
                        "text": "Yueming Wu 0001"
                    },
                    {
                        "@pid": "281/9150",
                        "text": "Wenjie Xue"
                    },
                    {
                        "@pid": "381/1631",
                        "text": "Sikui Pan"
                    },
                    {
                        "@pid": "z/DeqingZou",
                        "text": "Deqing Zou"
                    },
                    {
                        "@pid": "51/3710-3",
                        "text": "Yang Liu 0003"
                    },
                    {
                        "@pid": "98/4156",
                        "text": "Hai Jin 0001"
                    }
                ]
            },
            "title": "FIRE: Combining Multi-Stage Filtering with Taint Analysis for Scalable Recurring Vulnerability Detection.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/FengWXPZ0024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/feng-siyue",
            "url": "https://dblp.org/rec/conf/uss/FengWXPZ0024",
            "abstract": "With the continuous development of software open-sourcing, the reuse of open-source software has led to a significant increase in the occurrence of recurring vulnerabilities. These vulnerabilities often arise through the practice of copying and pasting existing vulnerabilities. Many methods have been proposed for detecting recurring vulnerabilities, but they often struggle to ensure both high efficiency and consideration of semantic information about vulnerabilities and patches. In this paper, we introduce FIRE, a scalable method for large-scale recurring vulnerability detection. It utilizes multi-stage filtering and differential taint paths to achieve precise clone vulnerability scanning at an extensive scale. In our evaluation across ten open-source software projects, FIRE demonstrates a precision of 90.0% in detecting 298 recurring vulnerabilities out of 385 ground truth instance. This surpasses the performance of existing advanced recurring vulnerability detection tools, detecting 31.4% more vulnerabilities than VUDDY and 47.0% more than MOVERY. When detecting vulnerabilities in large-scale software, FIRE outperforms MOVERY by saving about twice the time, enabling the scanning of recurring vulnerabilities on an ultra-large scale.",
            "keywords": [
                "Recurring Vulnerability Detection",
                "Open-Source Software",
                "Taint Analysis",
                "Multi-Stage Filtering",
                "Clone Vulnerabilities"
            ]
        },
        "url": "URL#379489",
        "sema_paperId": "1193bfd36b212a482cec472e034995043948b03d"
    },
    {
        "@score": "1",
        "@id": "379490",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "325/2474",
                        "text": "Konstantin Fischer"
                    },
                    {
                        "@pid": "242/3169",
                        "text": "Ivana Trummov\u00e1"
                    },
                    {
                        "@pid": "246/8652",
                        "text": "Phillip Gajland"
                    },
                    {
                        "@pid": "132/9687",
                        "text": "Yasemin Acar"
                    },
                    {
                        "@pid": "38/9378",
                        "text": "Sascha Fahl"
                    },
                    {
                        "@pid": "s/MASasse",
                        "text": "M. Angela Sasse"
                    }
                ]
            },
            "title": "The Challenges of Bringing Cryptography from Research Papers to Products: Results from an Interview Study with Experts.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/FischerTGAFS24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/fischer",
            "url": "https://dblp.org/rec/conf/uss/FischerTGAFS24",
            "abstract": "Cryptography serves as the cornerstone of information security and privacy in modern society. While notable progress has been made in the implementation of cryptographic techniques, a substantial portion of research outputs in cryptography, which strive to offer robust security solutions, are either implemented inadequately or not at all. Our study aims to investigate the challenges involved in bringing cryptography innovations from papers to products. To address this open question, we conducted 21 semi-structured interviews with cryptography experts who possess extensive experience (10+ years) in academia, industry, and nonprofit and governmental organizations. We aimed to gain insights into their experiences with deploying cryptographic research outputs, their perspectives on the process of bringing cryptography to products, and the necessary changes within the cryptography ecosystem to facilitate faster, wider, and more secure adoption. We identified several challenges including misunderstandings and miscommunication among stakeholders, unclear de-lineation of responsibilities, misaligned or conflicting incentives, and usability challenges when bringing cryptography from theoretical papers to end user products. Drawing upon our findings, we provide a set of recommendations for cryptography researchers and practitioners. We encourage better supporting cross-disciplinary engagement between cryptogra-phers, standardization organizations, and software developers for increased cryptography adoption.",
            "keywords": [
                "Cryptography",
                "Research Implementation",
                "Stakeholder Communication",
                "Usability Challenges",
                "Cross-disciplinary Engagement"
            ]
        },
        "url": "URL#379490",
        "sema_paperId": "aab79caa07110aae2a395b41cbfffb046990a232"
    },
    {
        "@score": "1",
        "@id": "379491",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "138/4883",
                        "text": "Marcel Fourn\u00e9"
                    },
                    {
                        "@pid": "268/6572",
                        "text": "Daniel De Almeida Braga"
                    },
                    {
                        "@pid": "268/4450",
                        "text": "Jan Jancar"
                    },
                    {
                        "@pid": "162/4179",
                        "text": "Mohamed Sabt"
                    },
                    {
                        "@pid": "30/1431",
                        "text": "Peter Schwabe"
                    },
                    {
                        "@pid": "b/GBarthe",
                        "text": "Gilles Barthe"
                    },
                    {
                        "@pid": "76/6163",
                        "text": "Pierre-Alain Fouque"
                    },
                    {
                        "@pid": "132/9687",
                        "text": "Yasemin Acar"
                    }
                ]
            },
            "title": "&quot;These results must be false&quot;: A usability evaluation of constant-time analysis tools.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/FourneBJSSBFA24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/fourne",
            "url": "https://dblp.org/rec/conf/uss/FourneBJSSBFA24",
            "abstract": ".",
            "keywords": [
                "Constant-Time Analysis",
                "Usability Evaluation",
                "Analysis Tools",
                "Performance Metrics",
                "False Results Interpretation"
            ]
        },
        "url": "URL#379491",
        "sema_paperId": "fd4da16813fe2bad5da669050e9fa53a8eb2cc07"
    },
    {
        "@score": "1",
        "@id": "379493",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "246/8652",
                        "text": "Phillip Gajland"
                    },
                    {
                        "@pid": "275/3369",
                        "text": "Bor de Kock"
                    },
                    {
                        "@pid": "341/1778",
                        "text": "Miguel Quaresma"
                    },
                    {
                        "@pid": "148/1304",
                        "text": "Giulio Malavolta"
                    },
                    {
                        "@pid": "30/1431",
                        "text": "Peter Schwabe"
                    }
                ]
            },
            "title": "SWOOSH: Efficient Lattice-Based Non-Interactive Key Exchange.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GajlandKQMS24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/gajland",
            "url": "https://dblp.org/rec/conf/uss/GajlandKQMS24",
            "abstract": "The advent of quantum computers has sparked significant interest in post-quantum cryptographic schemes, as a replacement for currently used cryptographic primitives. In this context, lattice-based cryptography has emerged as the leading paradigm to build post-quantum cryptography. However, all existing viable replacements of the classical Diffie-Hellman key exchange require additional rounds of interactions, thus failing to achieve all the benefits of this protocol. Although earlier work has shown that lattice-based Non-Interactive Key Exchange (NIKE) is theoretically possible, it has been considered too inefficient for real-life applications. In this work, we challenge this folklore belief and provide the first evidence against it. We construct an efficient lattice-based NIKE whose security is based on the standard module learning with errors (M-LWE) problem in the quantum random oracle model. Our scheme is obtained in two steps: (i) A passively-secure construction that achieves a strong notion of correctness, coupled with (ii) a generic compiler that turns any such scheme into an actively-secure one. To substantiate our efficiency claim, we provide an optimised implementation of our passively-secure construction in Rust and Jasmin. Our implementation demonstrates the scheme\u2019s applicability to real-world scenarios, yielding public keys of approximately 220 KBs. Moreover, the computation of shared keys takes fewer than 12 million cycles on an Intel Skylake CPU, offering a post-quantum security level exceeding 120 bits.",
            "keywords": [
                "Lattice-Based Cryptography",
                "Non-Interactive Key Exchange",
                "Post-Quantum Cryptography",
                "Module Learning with Errors (M-LWE)",
                "Active Security"
            ]
        },
        "url": "URL#379493",
        "sema_paperId": "b1eea8fbd93c1df44224368c3298b8463cf70d39"
    },
    {
        "@score": "1",
        "@id": "379494",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "307/3291",
                        "text": "Stefan Gast"
                    },
                    {
                        "@pid": "351/3339",
                        "text": "Roland Czerny"
                    },
                    {
                        "@pid": "207/7615",
                        "text": "Jonas Juffinger"
                    },
                    {
                        "@pid": "362/2615",
                        "text": "Fabian Rauscher"
                    },
                    {
                        "@pid": "352/7249",
                        "text": "Simone Franza"
                    },
                    {
                        "@pid": "166/1494",
                        "text": "Daniel Gruss"
                    }
                ]
            },
            "title": "SnailLoad: Exploiting Remote Network Latency Measurements without JavaScript.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GastCJRFG24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/gast",
            "url": "https://dblp.org/rec/conf/uss/GastCJRFG24",
            "abstract": "Inferring user activities on a computer from network traffic is a well-studied attack vector. Previous work has shown that they can infer websites visited, videos watched, and even user actions within specific applications. However, all of these attacks require a scenario where the attacker can observe the (possibly encrypted) network traffic, e.g., through a person-in-the-middle (PITM) attack or sitting in physical proximity to monitor WiFi packets. In this paper, we present SnailLoad, a new side-channel attack where the victim loads an asset, e.g., a file or an image, from an attacker-controlled server, exploiting the victim\u2019s network latency as a side channel tied to activities on the victim system, e.g., watching videos or websites. SnailLoad requires no JavaScript, no form of code execution on the victim system, and no user interaction but only a constant exchange of network packets, e.g., a network connection in the background. SnailLoad measures the latency to the victim system and infers the network activity on the victim system from the latency variations. We demonstrate SnailLoad in a non-PITM video-fingerprinting attack, where we use a single SnailLoad trace to infer what video a victim user is watching momentarily. For our evaluation, we focused on a set of 10 YouTube videos the victim watches, and show that Snail-Load reaches classification F 1 scores of up to 98 %. We also evaluated SnailLoad in an open-world top 100 website fingerprinting attack, resulting in an F 1 score of 62 . 8 %. This shows that numerous prior works, based on network traffic observations in PITM attack scenarios, could potentially be lifted to non-PITM remote attack scenarios.",
            "keywords": [
                "Network Latency Measurement",
                "Side-Channel Attack",
                "Video Fingerprinting",
                "Website Fingerprinting",
                "Remote Network Activity Inference"
            ]
        },
        "url": "URL#379494",
        "sema_paperId": "6c8f25e95a68486abda419721a2613ded4c98017"
    },
    {
        "@score": "1",
        "@id": "379495",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "255/9411",
                        "text": "Yunjie Ge"
                    },
                    {
                        "@pid": "75/5723-2",
                        "text": "Qian Wang 0002"
                    },
                    {
                        "@pid": "275/6583",
                        "text": "Huayang Huang"
                    },
                    {
                        "@pid": "181/2688-2",
                        "text": "Qi Li 0002"
                    },
                    {
                        "@pid": "18/2771-1",
                        "text": "Cong Wang 0001"
                    },
                    {
                        "@pid": "48/4825-1",
                        "text": "Chao Shen 0001"
                    },
                    {
                        "@pid": "227/7192",
                        "text": "Lingchen Zhao"
                    },
                    {
                        "@pid": "137/9780-2",
                        "text": "Peipei Jiang 0002"
                    },
                    {
                        "@pid": "77/4730",
                        "text": "Zheng Fang"
                    },
                    {
                        "@pid": "52/10864",
                        "text": "Shenyi Zhang"
                    }
                ]
            },
            "title": "Hijacking Attacks against Neural Network by Analyzing Training Data.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Ge0H000Z0FZ24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/ge-hijacking",
            "url": "https://dblp.org/rec/conf/uss/Ge0H000Z0FZ24",
            "abstract": "Backdoors and adversarial examples are the two primary threats currently faced by deep neural networks (DNNs). Both attacks attempt to hijack the model behaviors with unintended outputs by introducing (small) perturbations to the inputs. Backdoor attacks, despite the high success rates, often require a strong assumption, which is not always easy to achieve in reality. Adversarial example attacks, which put relatively weaker assumptions on attackers, often demand high computational resources, yet do not always yield satisfactory success rates when attacking mainstream black-box models in the real world. These limitations motivate the following research question: can model hijacking be achieved more simply, with a higher attack success rate and more reasonable assumptions? In this paper, we propose CleanSheet, a new model hijacking attack that obtains the high performance of backdoor attacks without requiring the adversary to tamper with the model training process. CleanSheet exploits vulnerabilities in DNNs stemming from the training data. Specifically, our key idea is to treat part of the clean training data of the target model as\"poisoned data,\"and capture the characteristics of these data that are more sensitive to the model (typically called robust features) to construct\"triggers.\"These triggers can be added to any input example to mislead the target model, similar to backdoor attacks. We validate the effectiveness of CleanSheet through extensive experiments on 5 datasets, 79 normally trained models, 68 pruned models, and 39 defensive models. Results show that CleanSheet exhibits performance comparable to state-of-the-art backdoor attacks, achieving an average attack success rate (ASR) of 97.5% on CIFAR-100 and 92.4% on GTSRB, respectively. Furthermore, CleanSheet consistently maintains a high ASR, when confronted with various mainstream backdoor defenses.",
            "keywords": [
                "Model Hijacking",
                "Backdoor Attacks",
                "Adversarial Examples",
                "Training Data Vulnerabilities",
                "CleanSheet"
            ]
        },
        "url": "URL#379495",
        "sema_paperId": "4188a4e2c95350971b5ae45a9103fa28d4f3de59"
    },
    {
        "@score": "1",
        "@id": "379496",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "255/9411",
                        "text": "Yunjie Ge"
                    },
                    {
                        "@pid": "381/1608",
                        "text": "Pinji Chen"
                    },
                    {
                        "@pid": "75/5723-2",
                        "text": "Qian Wang 0002"
                    },
                    {
                        "@pid": "227/7192",
                        "text": "Lingchen Zhao"
                    },
                    {
                        "@pid": "325/1551",
                        "text": "Ningping Mou"
                    },
                    {
                        "@pid": "137/9780-2",
                        "text": "Peipei Jiang 0002"
                    },
                    {
                        "@pid": "18/2771-1",
                        "text": "Cong Wang 0001"
                    },
                    {
                        "@pid": "181/2688-2",
                        "text": "Qi Li 0002"
                    },
                    {
                        "@pid": "48/4825-1",
                        "text": "Chao Shen 0001"
                    }
                ]
            },
            "title": "More Simplicity for Trainers, More Opportunity for Attackers: Black-Box Attacks on Speaker Recognition Systems by Inferring Feature Extractor.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GeC0ZM000024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/ge-attacks",
            "url": "https://dblp.org/rec/conf/uss/GeC0ZM000024",
            "abstract": "Recent studies have revealed that deep learning-based speaker recognition systems (SRSs) are vulnerable to adversarial examples (AEs). However, the practicality of existing black-box AE attacks is restricted by the requirement for extensive querying of the target system or the limited attack success rates (ASR). In this paper, we introduce VoxCloak, a new targeted AE attack with superior performance in both these aspects. Distinct from existing methods that optimize AEs by querying the target model, VoxCloak initially employs a small number of queries (e.g., a few hundred) to infer the feature extractor used by the target system. It then utilizes this feature extractor to generate any number of AEs locally without the need for further queries. We evaluate Vox-Cloak on four commercial speaker recognition (SR) APIs and seven voice assistants. On the SR APIs, VoxCloak surpasses the existing transfer-based attacks, improving ASR by 76.25% and signal-to-noise ratio (SNR) by 13.46 dB, as well as the decision-based attacks, requiring 33 times fewer queries and improving SNR by 7.87 dB while achieving comparable ASRs. On the voice assistants, VoxCloak outperforms the existing methods with a 49.40% improvement in ASR and a 15.79 dB improvement in SNR.",
            "keywords": [
                "Speaker Recognition Systems",
                "Adversarial Examples",
                "Black-Box Attacks",
                "Feature Extractor Inference",
                "VoxCloak"
            ]
        },
        "url": "URL#379496",
        "sema_paperId": "692d42ed15d3b413984981864af8e4d989cd3b61"
    },
    {
        "@score": "1",
        "@id": "379497",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "337/8159",
                        "text": "Gabriel Karl Gegenhuber"
                    },
                    {
                        "@pid": "330/7966",
                        "text": "Florian Holzbauer"
                    },
                    {
                        "@pid": "372/3412",
                        "text": "Philipp \u00c9. Frenzel"
                    },
                    {
                        "@pid": "w/EdgarRWeippl",
                        "text": "Edgar R. Weippl"
                    },
                    {
                        "@pid": "138/2614",
                        "text": "Adrian Dabrowski"
                    }
                ]
            },
            "title": "Diffie-Hellman Picture Show: Key Exchange Stories from Commercial VoWiFi Deployments.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GegenhuberHFWD24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/gegenhuber",
            "url": "https://dblp.org/rec/conf/uss/GegenhuberHFWD24",
            "abstract": "Voice over Wi-Fi (VoWiFi) uses a series of IPsec tunnels to deliver IP-based telephony from the subscriber's phone (User Equipment, UE) into the Mobile Network Operator's (MNO) core network via an Internet-facing endpoint, the Evolved Packet Data Gateway (ePDG). IPsec tunnels are set up in phases. The first phase negotiates the cryptographic algorithm and parameters and performs a key exchange via the Internet Key Exchange protocol, while the second phase (protected by the above-established encryption) performs the authentication. An insecure key exchange would jeopardize the later stages and the data's security and confidentiality. In this paper, we analyze the phase 1 settings and implementations as they are found in phones as well as in commercially deployed networks worldwide. On the UE side, we identified a recent 5G baseband chipset from a major manufacturer that allows for fallback to weak, unannounced modes and verified it experimentally. On the MNO side -- among others -- we identified 13 operators (totaling an estimated 140 million subscribers) on three continents that all use the same globally static set of ten private keys, serving them at random. Those not-so-private keys allow the decryption of the shared keys of every VoWiFi user of all those operators. All these operators deployed their core network from one common manufacturer.",
            "keywords": [
                "Voice over Wi-Fi (VoWiFi)",
                "IPsec Tunnels",
                "Key Exchange",
                "Cryptographic Algorithms",
                "Security Vulnerabilities in Mobile Networks"
            ]
        },
        "url": "URL#379497",
        "sema_paperId": "cf669bdd889ff8ca07041584cabca627b9b19406"
    },
    {
        "@score": "1",
        "@id": "379498",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "160/7975",
                        "text": "Matthias Geihs"
                    },
                    {
                        "@pid": "44/8733",
                        "text": "Hart Montgomery"
                    }
                ]
            },
            "title": "LaKey: Efficient Lattice-Based Distributed PRFs Enable Scalable Distributed Key Management.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GeihsM24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/geihs",
            "url": "https://dblp.org/rec/conf/uss/GeihsM24",
            "abstract": "Distributed key management (DKM) services are multi-party services that allow their users to outsource the generation, storage, and usage of cryptographic private keys, while guar-anteeing that none of the involved service providers learn the private keys in the clear. This is typically achieved through distributed key generation (DKG) protocols, where the service providers generate the keys on behalf of the users in an interactive protocol, and each of the servers stores a share of each key as the result. However, with traditional DKM systems, the key material stored by each server grows linearly with the number of users. An alternative approach to DKM is via distributed key derivation (DKD) where the user key shares are derived on-demand from a constant-size (in the number of users) secret-shared master key and the corresponding user\u2019s identity, which is achieved by employing a suitable distributed pseudorandom function (dPRF). However, existing suitable dPRFs require on the order of 100 interaction rounds between the servers and are therefore insufficient for settings with high network latency and where users demand real-time interaction. To resolve the situation, we initiate the study of lattice-based distributed PRFs, with a particular focus on their application to DKD. Concretely, we show that the LWE-based PRF presented by Boneh et al. at CRYPTO\u201913 can be turned into a distributed PRF suitable for DKD that runs in only 8 online rounds, which is an improvement over the start-of-the-art by an order of magnitude. We further present optimizations of this basic construction. We show a new construction with improved communication efficiency proven secure under the same \u201cstandard\u201d assumptions. Then, we present even more efficient constructions, running in as low as 5 online rounds, from non-standard, new lattice-based assumptions. We support our findings by implementing and evaluating our protocol using the MP-SPDZ framework (Keller, CCS \u201920). Finally, we give a formal definition of our DKD in the UC framework and prove",
            "keywords": [
                "Distributed Key Management",
                "Lattice-Based Cryptography",
                "Distributed Pseudorandom Functions",
                "Key Derivation",
                "Network Latency"
            ]
        },
        "url": "URL#379498",
        "sema_paperId": "d17f881d0d4a6aafbf4efb01f791cdc7f09b3eb7"
    },
    {
        "@score": "1",
        "@id": "379499",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "256/8014",
                        "text": "Rahul George"
                    },
                    {
                        "@pid": "26/9777",
                        "text": "Mingming Chen"
                    },
                    {
                        "@pid": "35/5361",
                        "text": "Kaiming Huang"
                    },
                    {
                        "@pid": "31/8302",
                        "text": "Zhiyun Qian"
                    },
                    {
                        "@pid": "l/TomLaPorta",
                        "text": "Thomas La Porta"
                    },
                    {
                        "@pid": "45/576",
                        "text": "Trent Jaeger"
                    }
                ]
            },
            "title": "OPTISAN: Using Multiple Spatial Error Defenses to Optimize Stack Memory Protection within a Budget.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GeorgeCHQPJ24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/george",
            "url": "https://dblp.org/rec/conf/uss/GeorgeCHQPJ24",
            "abstract": "Spatial memory errors continue to be the cause of many vulnerabilities. While researchers have proposed several defenses to prevent exploitation of spatial memory errors, systems currently rely on defenses that only protect a small fraction of stack data (e.g., return addresses) and leave a window of vulnerability (e.g., by only enforcing on function returns). One proposal to address this problem is to place defenses at the lowest cost locations until a cost budget was met, but this approach only considers a single defense and does not account for the security implications of possible placements. In this paper, we propose the O PTI S AN system, which is the first system to apply multiple spatial memory defenses to maximize the number of objects protected from spatial memory errors within a cost budget. O PTI S AN analyzes each program to identify the stack objects that may be exploited by spatial memory errors, called usable targets , and estimates the overhead for individual defense operations, for both metadata management and spatial checks, to enable flexibility in placement choices. O PTI S AN applies this information in a novel Mixed-Integer Non-Linear Programming formulation to generate an optimal placement. We apply O PTI S AN to generate placements using a combination of identity-based (i.e., influential BaggyBounds) and location-based (i.e., widely used Ad-dressSanitizer (ASan)) spatial memory defenses, finding that O PTI S AN utilizes the more effective Baggy Bounds defense broadly, augmenting it with ASan to increase the number of memory operations with usable targets protected by 18.4% on average across a set of benchmark and server programs. O PTI S AN shows that using multiple spatial memory defenses provides valuable flexibility to prevent the exploitation of many spatial memory errors within a cost budget.",
            "keywords": [
                "Spatial Memory Errors",
                "Memory Protection",
                "Stack Memory",
                "Multiple Defenses",
                "Cost Optimization"
            ]
        },
        "url": "URL#379499",
        "sema_paperId": "cf9512c5ec66ccc842242822d6ca18b60e5b8331"
    },
    {
        "@score": "1",
        "@id": "379500",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "381/1613",
                        "text": "Tania Ghafourian"
                    },
                    {
                        "@pid": "130/8112",
                        "text": "Nicholas Micallef"
                    },
                    {
                        "@pid": "57/702",
                        "text": "Sameer Patil"
                    }
                ]
            },
            "title": "From the Childhood Past: Views of Young Adults on Parental Sharing of Children&apos;s Photos.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GhafourianMP24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/ghafourian",
            "url": "https://dblp.org/rec/conf/uss/GhafourianMP24",
            "abstract": "Parents increasingly post content about their children on social media. While such sharing serves benefcial interactive purposes, it can create immediate and longitudinal privacy risks for the children. Studies on parental content sharing have investigated perceptions of parents and children, leaving out those of young adults between the ages of 18 and 30. We addressed this gap via a questionnaire asking young adults about their perspectives on parental sharing of children\u2019s photos on social media. We found that young adults who had content about them shared by their parents during childhood and those who were parents expressed greater acceptance of parental sharing practices in terms of motives, content, and audiences. Our fndings indicate the need for system features, policies, and digital literacy campaigns to help parents balance the interactive benefts of sharing content about their children and protecting the children\u2019s online footprints.",
            "keywords": [
                "Social Media Sharing",
                "Parental Practices",
                "Children's Privacy",
                "Young Adults' Perspectives",
                "Digital Footprints"
            ]
        },
        "url": "URL#379500",
        "sema_paperId": "039a1d05d8b94494a27553a8de143b7c64b9894e"
    },
    {
        "@score": "1",
        "@id": "379501",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "353/7674",
                        "text": "Wil Gibbs"
                    },
                    {
                        "@pid": "185/3910",
                        "text": "Arvind S. Raj"
                    },
                    {
                        "@pid": "224/1548",
                        "text": "Jayakrishna Menon Vadayath"
                    },
                    {
                        "@pid": "175/6612",
                        "text": "Hui Jun Tay"
                    },
                    {
                        "@pid": "17/1191",
                        "text": "Justin Miller"
                    },
                    {
                        "@pid": "381/1607",
                        "text": "Akshay Ajayan"
                    },
                    {
                        "@pid": "332/3154",
                        "text": "Zion Leonahenahe Basque"
                    },
                    {
                        "@pid": "353/7612",
                        "text": "Audrey Dutcher"
                    },
                    {
                        "@pid": "296/5462",
                        "text": "Fangzhou Dong"
                    },
                    {
                        "@pid": "331/2225",
                        "text": "Xavier J. Maso"
                    },
                    {
                        "@pid": "v/GiovanniVigna",
                        "text": "Giovanni Vigna"
                    },
                    {
                        "@pid": "k/ChristopherKruegel",
                        "text": "Christopher Kruegel"
                    },
                    {
                        "@pid": "28/8280",
                        "text": "Adam Doup\u00e9"
                    },
                    {
                        "@pid": "119/7712",
                        "text": "Yan Shoshitaishvili"
                    },
                    {
                        "@pid": "127/9829",
                        "text": "Ruoyu Wang 0001"
                    }
                ]
            },
            "title": "Operation Mango: Scalable Discovery of Taint-Style Vulnerabilities in Binary Firmware Services.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GibbsRVTMABDDMV24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/gibbs",
            "url": "https://dblp.org/rec/conf/uss/GibbsRVTMABDDMV24",
            "abstract": "The rise of IoT (Internet of Things) devices has created a system of convenience, which allows users to control and automate almost everything in their homes. But this increase in convenience comes with increased security risks to the users of IoT devices, partially because IoT firmware is frequently complex, feature-rich, and very vulnerable. Existing solutions for automatically finding taint-style vulnerabilities significantly reduce the number of binaries analyzed to achieve scalability. However, we show that this trade-off results in missing significant numbers of vulnerabilities. In this paper, we propose a new direction: scaling static analysis of firmware binaries so that all binaries can be analyzed for command injection or buffer overflows. To achieve this, we developed M ANGO DFA, a novel binary data-flow analysis leveraging value analysis and data dependency analysis on binary code. Through key algorithmic optimizations in M ANGO DFA, our prototype Mango achieves fast analysis without sacrificing precision. On the same dataset used in prior work, Mango analyzed 27 \u00d7 more binaries in a comparable amount of time to the state-of-the-art in Linux-based user-space firmware taint-analysis SaTC. Mango achieved an average per-binary analysis",
            "keywords": [
                "IoT Firmware Security",
                "Static Analysis",
                "Taint-Style Vulnerabilities",
                "Binary Data-Flow Analysis",
                "Command Injection and Buffer Overflows"
            ]
        },
        "url": "URL#379501",
        "sema_paperId": "105150889b96a4b104751153bb1d89f0be5f8b84"
    },
    {
        "@score": "1",
        "@id": "379502",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "343/2871",
                        "text": "Jacob Ginesin"
                    },
                    {
                        "@pid": "262/3629",
                        "text": "Max von Hippel"
                    },
                    {
                        "@pid": "372/1983",
                        "text": "Evan Defloor"
                    },
                    {
                        "@pid": "n/CristinaNitaRotaru",
                        "text": "Cristina Nita-Rotaru"
                    },
                    {
                        "@pid": "43/6209",
                        "text": "Michael T\u00fcxen"
                    }
                ]
            },
            "title": "A Formal Analysis of SCTP: Attack Synthesis and Patch Verification.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GinesinHDNT24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/ginesin",
            "url": "https://dblp.org/rec/conf/uss/GinesinHDNT24",
            "abstract": "SCTP is a transport protocol offering features such as multi-homing, multi-streaming, and message-oriented delivery. Its two main implementations were subjected to conformance tests using the PacketDrill tool. Conformance testing is not exhaustive and a recent vulnerability (CVE-2021-3772) showed SCTP is not immune to attacks. Changes addressing the vulnerability were implemented, but the question remains whether other flaws might persist in the protocol design.\nWe study the security of the SCTP design, taking a rigorous approach rooted in formal methods. We create a formal Promela model of SCTP, and define 10 properties capturing the essential protocol functionality based on its RFC specification and consultation with the lead RFC author. Then we show using the SPIN model checker that our model satisfies these properties. We next define 4 representative attacker models \u2013 Off-Path, where the attacker is an outsider that can spoof the port and IP of a peer; Evil-Server, where the attacker is a malicious peer; Replay, where an attacker can capture and replay, but not modify, packets; and On-Path, where the attacker controls the channel between peers. SCTP was designed to be secure against Off-Path attackers, and we study the additional models in order to understand how its security degrades for successively more powerful attacker types. We modify an attack synthesis tool designed for transport protocols, KORG, to support our SCTP model and 4 attacker models.\nWe synthesize the vulnerability reported in CVE-2021- 3772 in the Off-Path attacker model, when the patch is disabled, and we show that when enabled, the patch eliminates the vulnerability. We also manually identify two ambiguities in the RFC, and using KORG, we show that each, if misinterpreted, opens the protocol to a new Off-Path attack. We show that SCTP is vulnerable to a variety of attacks when it is misused in the Evil-Server, Replay, or On-Path attacker models (for which it was not designed). We discuss these and, when possible, mitigations thereof. Finally, we propose two RFC errata \u2013 one to eliminate each ambiguity \u2013 of which so far, the SCTP RFC committee has accepted one.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-ginesin.pdf",
            "keywords": [
                "SCTP Protocol",
                "Formal Methods",
                "Attack Synthesis",
                "Vulnerability Analysis",
                "RFC Ambiguities"
            ]
        },
        "url": "URL#379502"
    },
    {
        "@score": "1",
        "@id": "379503",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "213/7355",
                        "text": "Vasudev Gohil"
                    },
                    {
                        "@pid": "199/8092",
                        "text": "Satwik Patnaik"
                    },
                    {
                        "@pid": "44/8356",
                        "text": "Dileep Kalathil"
                    },
                    {
                        "@pid": "79/9006",
                        "text": "Jeyavijayan Rajendran"
                    }
                ]
            },
            "title": "AttackGNN: Red-Teaming GNNs in Hardware Security Using Reinforcement Learning.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GohilPKR24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/gohil",
            "url": "https://dblp.org/rec/conf/uss/GohilPKR24",
            "abstract": "Machine learning has shown great promise in addressing several critical hardware security problems. In particular, researchers have developed novel graph neural network (GNN)-based techniques for detecting intellectual property (IP) piracy, detecting hardware Trojans (HTs), and reverse engineering circuits, to name a few. These techniques have demonstrated outstanding accuracy and have received much attention in the community. However, since these techniques are used for security applications, it is imperative to evaluate them thoroughly and ensure they are robust and do not compromise the security of integrated circuits.\nIn this work, we propose AttackGNN, the first red-team attack on GNN-based techniques in hardware security. To this end, we devise a novel reinforcement learning (RL) agent that generates adversarial examples, i.e., circuits, against the GNN-based techniques. We overcome three challenges related to effectiveness, scalability, and generality to devise a potent RL agent. We target five GNN-based techniques for four crucial classes of problems in hardware security: IP piracy, detecting/localizing HTs, reverse engineering, and hardware obfuscation. Through our approach, we craft circuits that fool all GNNs considered in this work. For instance, to evade IP piracy detection, we generate adversarial pirated circuits that fool the GNN-based defense into classifying our crafted circuits as not pirated. For attacking HT localization GNN, our attack generates HT-infested circuits that fool the defense on all tested circuits. We obtain a similar 100% success rate against GNNs for all classes of problems.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-gohil.pdf",
            "keywords": [
                "Hardware Security",
                "Graph Neural Networks",
                "Adversarial Attacks",
                "Intellectual Property Piracy",
                "Hardware Trojans"
            ]
        },
        "url": "URL#379503"
    },
    {
        "@score": "1",
        "@id": "379504",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "87/2320",
                        "text": "Sharon Goldberg"
                    },
                    {
                        "@pid": "266/1494",
                        "text": "Miro Haller"
                    },
                    {
                        "@pid": "12/3207",
                        "text": "Nadia Heninger"
                    },
                    {
                        "@pid": "325/3164",
                        "text": "Mike Milano"
                    },
                    {
                        "@pid": "24/7481",
                        "text": "Dan Shumow"
                    },
                    {
                        "@pid": "15/4413",
                        "text": "Marc Stevens 0001"
                    },
                    {
                        "@pid": "216/6745",
                        "text": "Adam Suhl"
                    }
                ]
            },
            "title": "RADIUS/UDP Considered Harmful.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GoldbergHHMS0S24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/goldberg",
            "url": "https://dblp.org/rec/conf/uss/GoldbergHHMS0S24",
            "abstract": "The RADIUS protocol is the de facto standard lightweight protocol for authentication, authorization, and accounting (AAA) for networked devices. It is used to support remote access for diverse use cases including network routers, industrial control systems, VPNs, enterprise Wi-Fi including the Eduroam network, Linux Pluggable Authentication Modules, and mobile roaming and Wi-Fi of\ufb02oad. We have discovered a protocol vulnerability in RADIUS that has been present for decades. Our attack allows a man-in-the-middle attacker to authenticate itself to a device using RADIUS for user authentication, or to assign itself arbitrary network privileges. Our attack exploits an MD5 chosen-pre\ufb01x collision on the ad hoc RADIUS packet authentication construction to produce Access-Accept and Access-Reject packets with identical Response Authenticators, allowing our attacker to transform a reject into an accept without knowledge of the shared secret between RADIUS client and server. We optimize the MD5 chosen-pre\ufb01x attack to produce collisions online in less than \ufb01ve minutes, and show how to \ufb01t the collision blocks within RADIUS attributes that will be echoed back from the server. We demonstrate our attack in a variety of settings against popular RADIUS implementations. It is our hope that this attack will provide the impetus for vendors and the IETF to deprecate RADIUS over UDP, and to require RADIUS to run over secure channels with modern cryptographic privacy and integrity guarantees.",
            "keywords": [
                "RADIUS Protocol",
                "Authentication",
                "Man-in-the-Middle Attack",
                "MD5 Collision",
                "Network Security Vulnerability"
            ]
        },
        "url": "URL#379504",
        "sema_paperId": "d98bfe65ead3fec6713b164adc2b4b15f5eecab0"
    },
    {
        "@score": "1",
        "@id": "379505",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "181/8259",
                        "text": "Lea Gr\u00f6ber"
                    },
                    {
                        "@pid": "181/3687",
                        "text": "Waleed Arshad"
                    },
                    {
                        "@pid": "381/1580",
                        "text": "Shanza"
                    },
                    {
                        "@pid": "304/4364",
                        "text": "Angelica Goetzen"
                    },
                    {
                        "@pid": "141/9244",
                        "text": "Elissa M. Redmiles"
                    },
                    {
                        "@pid": "52/4442",
                        "text": "Maryam Mustafa"
                    },
                    {
                        "@pid": "128/4803",
                        "text": "Katharina Krombholz"
                    }
                ]
            },
            "title": "&quot;I chose to fight, be brave, and to deal with it&quot;: Threat Experiences and Security Practices of Pakistani Content Creators.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GroberASGRMK24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/gr%C3%B6ber-content-creators",
            "url": "https://dblp.org/rec/conf/uss/GroberASGRMK24",
            "abstract": "Content creators are exposed to elevated risks compared to the general Internet user. This study explores the threat landscape that creators in Pakistan are exposed to, how they protect themselves, and which support structures they rely on. We conducted a semi-structured interview study with 23 creators from diverse backgrounds who create content on various topics. Our data suggests that online threats frequently spill over into the offline world, especially for gender minorities. Creating content on sensitive topics like politics, religion, and human rights is associated with elevated risks. We find that defensive mechanisms and external support structures are non-existent, lacking, or inadequately adjusted to the socio-cultural context of Pakistan. Disclaimer: This paper contains quotes describing harmful experiences relating to sexual and physical assault, eating disorders, and extreme threats of violence.",
            "keywords": [
                "Content Creation",
                "Online Threats",
                "Security Practices",
                "Gender Minorities",
                "Pakistan"
            ]
        },
        "url": "URL#379505",
        "sema_paperId": "718abe7074d9db869eeacbf32f517a53624cd2bb"
    },
    {
        "@score": "1",
        "@id": "379506",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "181/8259",
                        "text": "Lea Gr\u00f6ber"
                    },
                    {
                        "@pid": "344/8196",
                        "text": "Simon Lenau"
                    },
                    {
                        "@pid": "344/9517",
                        "text": "Rebecca Weil"
                    },
                    {
                        "@pid": "381/1694",
                        "text": "Elena Groben"
                    },
                    {
                        "@pid": "40/1587",
                        "text": "Michael Schilling 0001"
                    },
                    {
                        "@pid": "128/4803",
                        "text": "Katharina Krombholz"
                    }
                ]
            },
            "title": "Towards Privacy and Security in Private Clouds: A Representative Survey on the Prevalence of Private Hosting and Administrator Characteristics.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GroberLWG0K24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/gr%C3%B6ber-private-clouds",
            "url": "https://dblp.org/rec/conf/uss/GroberLWG0K24",
            "abstract": "Instead of relying on Software-as-a-Service solutions, some people self-host services from within their homes. In doing so they enhance their privacy but also assume responsibility for the security of their operations. However, little is currently known about how widespread private self-hosting is, which use cases are prominent, and what characteristics set self-hosters apart from the general population. In this work, we present two large-scale surveys: (1) We estimate the prevalence of private self-hosting in the U.S. across five use cases (communication, file storage, synchronized password managing, websites, and smart home) based on a representative survey on Prolific ( n = 1505 ). (2) We run a follow-up survey on Prolific ( n = 589 ) to contrast individual characteristics of identified self-hosters to people of the same demographics who do not show the behavior. We estimate an upper bound of 8.4% private self-hosters in the U.S. population. Websites are the most common use case for self-hosting, predominately running on home servers. All other use cases were equally frequent. Although past research identified privacy as a leading motivation for private self-hosting, we find that self-hosters are not more privacy-sensitive than the general population. Instead, we find that IT administration skills, IT background, affinity for technology interaction, and \u201cmaker\u201d self-identity positively correlate with self-hosting behavior.",
            "keywords": [
                "Private Cloud Hosting",
                "Self-Hosting",
                "Privacy Enhancement",
                "IT Administration Skills",
                "User Characteristics"
            ]
        },
        "url": "URL#379506",
        "sema_paperId": "7e0ffa8d22529d28f55be40a338a2aabb9b18a00"
    },
    {
        "@score": "1",
        "@id": "379507",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "120/1856",
                        "text": "Kathrin Grosse"
                    },
                    {
                        "@pid": "292/3892",
                        "text": "Lukas Bieringer"
                    },
                    {
                        "@pid": "61/7871",
                        "text": "Tarek R. Besold"
                    },
                    {
                        "@pid": "48/3455",
                        "text": "Alexandre Alahi"
                    }
                ]
            },
            "title": "Towards More Practical Threat Models in Artificial Intelligence Security.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GrosseBBA24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/grosse",
            "url": "https://dblp.org/rec/conf/uss/GrosseBBA24",
            "abstract": "Recent works have identified a gap between research and practice in artificial intelligence security: threats studied in academia do not always reflect the practical use and security risks of AI. For example, while models are often studied in isolation, they form part of larger ML pipelines in practice. Recent works also brought forward that adversarial manipulations introduced by academic attacks are impractical. We take a first step towards describing the full extent of this disparity. To this end, we revisit the threat models of the six most studied attacks in AI security research and match them to AI usage in practice via a survey with 271 industrial practitioners. On the one hand, we find that all existing threat models are indeed applicable. On the other hand, there are significant mismatches: research is often too generous with the attacker, assuming access to information not frequently available in real-world settings. Our paper is thus a call for action to study more practical threat models in artificial intelligence security.",
            "keywords": [
                "AI Security",
                "Threat Models",
                "Adversarial Attacks",
                "Industrial Practitioners",
                "Practical Threat Assessment"
            ]
        },
        "url": "URL#379507",
        "sema_paperId": "3544c345bd53fd79bc954ac7c410b1084508a5eb"
    },
    {
        "@score": "1",
        "@id": "379508",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "248/1578",
                        "text": "Emre G\u00fcler"
                    },
                    {
                        "@pid": "205/2072",
                        "text": "Sergej Schumilo"
                    },
                    {
                        "@pid": "207/4015",
                        "text": "Moritz Schloegel"
                    },
                    {
                        "@pid": "331/2788",
                        "text": "Nils Bars"
                    },
                    {
                        "@pid": "280/7837",
                        "text": "Philipp G\u00f6rz"
                    },
                    {
                        "@pid": "20/8606",
                        "text": "Xinyi Xu"
                    },
                    {
                        "@pid": "248/9744",
                        "text": "Cemal Kaygusuz"
                    },
                    {
                        "@pid": "h/ThorstenHolz",
                        "text": "Thorsten Holz"
                    }
                ]
            },
            "title": "Atropos: Effective Fuzzing of Web Applications for Server-Side Vulnerabilities.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GulerSSBGXKH24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/g%C3%BCler",
            "url": "https://dblp.org/rec/conf/uss/GulerSSBGXKH24",
            "abstract": "Server-side web applications are still predominantly implemented in the PHP programming language. Even nowadays, PHP-based web applications are plagued by many different types of security vulnerabilities, ranging from SQL injection to file inclusion and remote code execution. Automated security testing methods typically focus on static analysis and taint analysis. These methods are highly dependent on accurate modeling of the PHP language and often suffer from (potentially many) false positive alerts. Interestingly, dynamic testing techniques such as fuzzing have not gained acceptance in web applications testing, even though they avoid these common pitfalls and were rapidly adopted in other domains, e. g., for testing native applications written in C/C++. In this paper, we present A TROPOS , a snapshot-based, feedback-driven fuzzing method tailored for PHP-based web applications. Our approach considers the challenges associated with web applications, such as maintaining session state and generating highly structured inputs. Moreover, we propose a feedback mechanism to automatically infer the key-value structure used by web applications. Combined with eight new bug oracles, each covering a common class of vulnerabilities in server-side web applications, A TROPOS is the first approach to fuzz web applications effectively and efficiently. Our evaluation shows that A TROPOS significantly outperforms the current state of the art in web application testing. In particular, it finds, on average, at least 32% more bugs, while not reporting a single false positive on different test suites. When analyzing real-world web applications, we identify seven previously unknown vulnerabilities that can be exploited even by unauthenticated users.",
            "keywords": [
                "Web Application Fuzzing",
                "PHP Security",
                "Server-Side Vulnerabilities",
                "Dynamic Testing",
                "Bug Oracles"
            ]
        },
        "url": "URL#379508",
        "sema_paperId": "f7e99c9bda48ba835235cb2f322ee04ee4d6f075"
    },
    {
        "@score": "1",
        "@id": "379509",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "260/2998",
                        "text": "Yihao Guo"
                    },
                    {
                        "@pid": "84/7272-1",
                        "text": "Minghui Xu 0001"
                    },
                    {
                        "@pid": "c/XiuzhenCheng",
                        "text": "Xiuzhen Cheng 0001"
                    },
                    {
                        "@pid": "44/7265",
                        "text": "Dongxiao Yu"
                    },
                    {
                        "@pid": "332/4044",
                        "text": "Wangjie Qiu"
                    },
                    {
                        "@pid": "308/6751",
                        "text": "Gang Qu"
                    },
                    {
                        "@pid": "39/4757",
                        "text": "Weibing Wang"
                    },
                    {
                        "@pid": "197/6226",
                        "text": "Mingming Song"
                    }
                ]
            },
            "title": "zkCross: A Novel Architecture for Cross-Chain Privacy-Preserving Auditing.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Guo00YQQWS24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/guo-yihao",
            "url": "https://dblp.org/rec/conf/uss/Guo00YQQWS24",
            "abstract": "One of the key areas of focus in blockchain research is how to realize privacy-preserving auditing without sacrificing the system's security and trustworthiness. However, simultaneously achieving auditing and privacy protection, two seemingly contradictory objectives, is challenging because an auditing system would require transparency and accountability which might create privacy and security vulnerabilities. This becomes worse in cross-chain scenarios, where the information silos from multiple chains further complicate the problem. In this paper, we identify three important challenges in cross-chain privacy-preserving auditing, namely Cross-chain Linkability Exposure (CLE), Incompatibility of Privacy and Auditing (IPA), and Full Auditing Inefficiency (FAI). To overcome these challenges, we propose zkCross, which is a novel two-layer cross-chain architecture equipped with three cross-chain protocols to achieve privacy-preserving cross-chain auditing. Among these three protocols, two are privacy-preserving cross-chain protocols for transfer and exchange, respectively; the third one is an efficient cross-chain auditing protocol. These protocols are built on solid cross-chain schemes to guarantee privacy protection and audit efficiency. We implement zkCross on both local and cloud servers and perform comprehensive tests to validate that zkCross is well-suited for processing large-scale privacy-preserving auditing tasks. We evaluate the performance of the proposed protocols in terms of run time, latency, throughput, gas consumption, audit time, and proof size to demonstrate their practicality.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-guo-yihao.pdf",
            "keywords": [
                "Cross-Chain Privacy",
                "Blockchain Auditing",
                "Privacy-Preserving Protocols",
                "Cross-Chain Linkability Exposure",
                "Incompatibility of Privacy and Auditing"
            ]
        },
        "url": "URL#379509"
    },
    {
        "@score": "1",
        "@id": "379510",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "161/5675",
                        "text": "Ziyi Guo"
                    },
                    {
                        "@pid": "353/7560",
                        "text": "Dang K. Le"
                    },
                    {
                        "@pid": "277/7909",
                        "text": "Zhenpeng Lin"
                    },
                    {
                        "@pid": "270/2413",
                        "text": "Kyle Zeng"
                    },
                    {
                        "@pid": "127/9829",
                        "text": "Ruoyu Wang 0001"
                    },
                    {
                        "@pid": "150/5198",
                        "text": "Tiffany Bao"
                    },
                    {
                        "@pid": "119/7712",
                        "text": "Yan Shoshitaishvili"
                    },
                    {
                        "@pid": "28/8280",
                        "text": "Adam Doup\u00e9"
                    },
                    {
                        "@pid": "40/6431",
                        "text": "Xinyu Xing"
                    }
                ]
            },
            "title": "Take a Step Further: Understanding Page Spray in Linux Kernel Exploitation.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GuoLLZ0BSDX24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/guo-ziyi",
            "url": "https://dblp.org/rec/conf/uss/GuoLLZ0BSDX24",
            "abstract": "Recently, a novel method known as Page Spray emerges, focusing on page-level exploitation for kernel vulnerabilities. Despite the advantages it offers in terms of exploitability, stability, and compatibility, comprehensive research on Page Spray remains scarce. Questions regarding its root causes, exploitation model, comparative benefits over other exploitation techniques, and possible mitigation strategies have largely remained unanswered. In this paper, we conduct a systematic investigation into Page Spray, providing an in-depth understanding of this exploitation technique. We introduce a comprehensive exploit model termed the DirtyPage model, elucidating its fundamental principles. Additionally, we conduct a thorough analysis of the root causes underlying Page Spray occurrences within the Linux Kernel. We design an analyzer based on the Page Spray analysis model to identify Page Spray callsites. Subsequently, we evaluate the stability, exploitability, and compatibility of Page Spray through meticulously designed experiments. Finally, we propose mitigation principles for addressing Page Spray and introduce our own lightweight mitigation approach. This research aims to assist security researchers and developers in gaining insights into Page Spray, ultimately enhancing our collective understanding of this emerging exploitation technique and making improvements to community.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-guo-ziyi.pdf",
            "keywords": [
                "Kernel Exploitation",
                "Page Spray",
                "Exploit Model",
                "DirtyPage Model",
                "Mitigation Strategies"
            ]
        },
        "url": "URL#379510"
    },
    {
        "@score": "1",
        "@id": "379511",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "243/0215",
                        "text": "Ruoyang Guo"
                    },
                    {
                        "@pid": "177/2287",
                        "text": "Jiarui Li"
                    },
                    {
                        "@pid": "21/5356",
                        "text": "Shucheng Yu"
                    }
                ]
            },
            "title": "GridSE: Towards Practical Secure Geographic Search via Prefix Symmetric Searchable Encryption.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GuoLY24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/guo-ruoyang",
            "url": "https://dblp.org/rec/conf/uss/GuoLY24",
            "abstract": "The proliferation of location-based services and applications has brought significant attention to data and location privacy. While general secure computation and privacy-enhancing techniques can partially address this problem, one outstanding challenge is to provide near latency-free search and compatibility with mainstream geographic search techniques, especially the Discrete Global Grid Systems (DGGS). This paper proposes a new construction, namely GridSE, for efficient and DGGS-compatible Secure Geographic Search (SGS) with both backward and forward privacy. We first formulate the notion of a semantic-secure primitive called \\textit{symmetric prefix predicate encryption} (SP$^2$E), for predicting whether or not a keyword contains a given prefix, and provide a construction. Then we extend SP$^2$E for dynamic \\textit{prefix symmetric searchable encryption} (pSSE), namely GridSE, which supports both backward and forward privacy. GridSE only uses lightweight primitives including cryptographic hash and XOR operations and is extremely efficient. Furthermore, we provide a generic pSSE framework that enables prefix search for traditional dynamic SSE that supports only full keyword search. Experimental results over real-world geographic databases of sizes (by the number of entries) from $10^3$ to $10^7$ and mainstream DGGS techniques show that GridSE achieves a speedup of $150\\times$ - $5000\\times$ on search latency and a saving of $99\\%$ on communication overhead as compared to the state-of-the-art. Interestingly, even compared to plaintext search, GridSE introduces only $1.4\\times$ extra computational cost and $0.9\\times$ additional communication cost. Source code of our scheme is available at https://github.com/rykieguo1771/GridSE-RAM.",
            "keywords": [
                "Secure Geographic Search",
                "Prefix Symmetric Searchable Encryption",
                "Discrete Global Grid Systems",
                "Data Privacy",
                "Search Latency"
            ]
        },
        "url": "URL#379511",
        "sema_paperId": "e6cb4dd94b9e8b52ef709f810377fbf0f52ca0c9"
    },
    {
        "@score": "1",
        "@id": "379512",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "365/9559",
                        "text": "Keyan Guo"
                    },
                    {
                        "@pid": "182/3840",
                        "text": "Ayush Utkarsh"
                    },
                    {
                        "@pid": "22/10126",
                        "text": "Wenbo Ding"
                    },
                    {
                        "@pid": "365/9011",
                        "text": "Isabelle Ondracek"
                    },
                    {
                        "@pid": "11/7704-1",
                        "text": "Ziming Zhao 0001"
                    },
                    {
                        "@pid": "150/9240",
                        "text": "Guo Freeman"
                    },
                    {
                        "@pid": "194/5621",
                        "text": "Nishant Vishwamitra"
                    },
                    {
                        "@pid": "02/2870",
                        "text": "Hongxin Hu"
                    }
                ]
            },
            "title": "Moderating Illicit Online Image Promotion for Unsafe User Generated Content Games Using Large Vision-Language Models.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GuoUDO0FVH24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/guo-keyan",
            "url": "https://dblp.org/rec/conf/uss/GuoUDO0FVH24",
            "abstract": "Online user generated content games (UGCGs) are increasingly popular among children and adolescents for social interaction and more creative online entertainment. However, they pose a heightened risk of exposure to explicit content, raising growing concerns for the online safety of children and adolescents. Despite these concerns, few studies have addressed the issue of illicit image-based promotions of unsafe UGCGs on social media, which can inadvertently attract young users. This challenge arises from the difficulty of obtaining comprehensive training data for UGCG images and the unique nature of these images, which differ from traditional unsafe content. In this work, we take the first step towards studying the threat of illicit promotions of unsafe UGCGs. We collect a real-world dataset comprising 2,924 images that display diverse sexually explicit and violent content used to promote UGCGs by their game creators. Our in-depth studies reveal a new understanding of this problem and the urgent need for automatically flagging illicit UGCG promotions. We additionally create a cutting-edge system, UGCG-Guard, designed to aid social media platforms in effectively identifying images used for illicit UGCG promotions. This system leverages recently introduced large vision-language models (VLMs) and employs a novel conditional prompting strategy for zero-shot domain adaptation, along with chain-of-thought (CoT) reasoning for contextual identification. UGCG-Guard achieves outstanding results, with an accuracy rate of 94% in detecting these images used for the illicit promotion of such games in real-world scenarios.",
            "keywords": [
                "User Generated Content Games",
                "Illicit Image Promotion",
                "Child Online Safety",
                "Vision-Language Models",
                "UGCG-Guard"
            ]
        },
        "url": "URL#379512",
        "sema_paperId": "75987b1fddce2cc32b5ca80463d331ca2ecc5f57"
    },
    {
        "@score": "1",
        "@id": "379513",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "170/4838",
                        "text": "Naman Gupta"
                    },
                    {
                        "@pid": "374/9420",
                        "text": "Kate Walsh"
                    },
                    {
                        "@pid": "217/7358",
                        "text": "Sanchari Das"
                    },
                    {
                        "@pid": "03/9962",
                        "text": "Rahul Chatterjee 0001"
                    }
                ]
            },
            "title": "&quot;I really just leaned on my community for support&quot;: Barriers, Challenges and Coping Mechanisms Used by Survivors of Technology-Facilitated Abuse to Seek Social Support.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GuptaWD024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/gupta",
            "url": "https://dblp.org/rec/conf/uss/GuptaWD024",
            "abstract": "Technology-facilitated abuse (TFA) from an intimate partner is a growing concern for survivors\u2019 safety and security. Prior research introduced tailored interventions to support the survivors of TFA. However, most survivors do not have access to these interventions or are unaware of the appropriate support networks and resources in their community. We conducted nine semi-structured interviews to examine survivors\u2019 support-seeking dynamics from their social networks and the effectiveness of social networks in addressing survivors\u2019 needs. Through survivors\u2019 lived experiences, we systematize socio-technical barriers that impede the participant from seeking support and challenges in seeking support. Further, we identify coping mechanisms used by the survivors despite those barriers and challenges. Through a participatory lens, we echo survivors\u2019 call for action to improve support networks and propose recommendations for technology design to promote safer support-seeking practices and resources, consciousness-raising awareness campaigns, and collaborations with the community. Finally, we call for a restorative-justice-oriented framework that recognizes TFA.",
            "keywords": [
                "Technology-Facilitated Abuse",
                "Survivor Support Networks",
                "Social Support Dynamics",
                "Coping Mechanisms",
                "Socio-Technical Barriers"
            ]
        },
        "url": "URL#379513",
        "sema_paperId": "11454765cba9051d7967d02cd0617b10cac823b6"
    },
    {
        "@score": "1",
        "@id": "379514",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "292/1031",
                        "text": "Tianshuo Han"
                    },
                    {
                        "@pid": "33/10782",
                        "text": "Xiaorui Gong"
                    },
                    {
                        "@pid": "35/295-8",
                        "text": "Jian Liu 0008"
                    }
                ]
            },
            "title": "CARDSHARK: Understanding and Stablizing Linux Kernel Concurrency Bugs Against the Odds.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HanG024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/han-tianshuo",
            "url": "https://dblp.org/rec/conf/uss/HanG024",
            "abstract": "Concurrency bugs in the Linux kernel are notoriously difficult to reproduce and debug due to their non-deterministic nature. While they bring constant headaches to Linux kernel developers, the reasons behind the non-determinism and how to improve the efficiency in triggering concurrency bugs to ease the debugging process still need to be studied. This work aims to fill the gap. We comprehensively study the concurrency bug stability problem in the Linux kernel, dissect the factors behind the non-determinism, and system-atize the insights into a model to explain the non-deterministic nature of concurrency bugs. Based on insights derived from the model, we identify an under-studied factor, named misalignment , which plays a vital role in triggering concurrency bugs. By controlling this factor, we significantly reduce the randomness in the concurrency bug-triggering process. Inspired by this insight, we design a novel technique, named CARDSHARK, that can significantly improve the efficiency in triggering concurrency bugs when kernel instrumentation is possible. A variant of CARDSHARK, named BLIND-SHARK, enables developers to improve efficiency in triggering concurrency bugs without knowing their root causes, making the use of CARDSHARK practical.",
            "keywords": [
                "Linux Kernel",
                "Concurrency Bugs",
                "Non-Determinism",
                "Bug Triggering Efficiency",
                "Misalignment"
            ]
        },
        "url": "URL#379514",
        "sema_paperId": "b3ead864c9564c0844c0f9b0786dc8f75846b9af"
    },
    {
        "@score": "1",
        "@id": "379515",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "202/1615",
                        "text": "Seunghun Han"
                    },
                    {
                        "@pid": "126/5288",
                        "text": "Seong-Joong Kim"
                    },
                    {
                        "@pid": "43/2144",
                        "text": "Wook Shin"
                    },
                    {
                        "@pid": "06/4025",
                        "text": "Byung Joon Kim"
                    },
                    {
                        "@pid": "74/1775",
                        "text": "Jae-Cheol Ryou 0001"
                    }
                ]
            },
            "title": "Page-Oriented Programming: Subverting Control-Flow Integrity of Commodity Operating System Kernels with Non-Writable Code Pages.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HanKSKR24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/han-seunghun",
            "url": "https://dblp.org/rec/conf/uss/HanKSKR24",
            "abstract": "This paper presents a novel attack technique called page-oriented programming, which reuses existing code gadgets by remapping physical pages to the virtual address space of a program at runtime. The page remapping vulnerabilities may lead to data breaches or may damage kernel integrity. Therefore, manufacturers have recently released products equipped with hardware-assisted guest kernel integrity enforcement. This paper extends the notion of the page remapping attack to another type of code-reuse attack, which can not only be used for altering or sniffing kernel data but also for building and executing malicious code at runtime. We demonstrate the effectiveness of this attack on state-of-the-art hardware and software, where control-flow integrity policies are enforced, thus highlighting its capability to render most legacy systems vulnerable.",
            "keywords": [
                "Page-Oriented Programming",
                "Code Reuse Attacks",
                "Kernel Integrity",
                "Control-Flow Integrity",
                "Page Remapping Vulnerabilities"
            ]
        },
        "url": "URL#379515",
        "sema_paperId": "c68bafae50279c52dbdcd34ee62716d7c622bf82"
    },
    {
        "@score": "1",
        "@id": "379516",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "184/7209",
                        "text": "Meng Hao"
                    },
                    {
                        "@pid": "255/5224",
                        "text": "Hanxiao Chen"
                    },
                    {
                        "@pid": "39/5544-1",
                        "text": "Hongwei Li 0001"
                    },
                    {
                        "@pid": "251/1580",
                        "text": "Chenkai Weng"
                    },
                    {
                        "@pid": "48/2168-6",
                        "text": "Yuan Zhang 0006"
                    },
                    {
                        "@pid": "25/7558",
                        "text": "Haomiao Yang"
                    },
                    {
                        "@pid": "77/7902-4",
                        "text": "Tianwei Zhang 0004"
                    }
                ]
            },
            "title": "Scalable Zero-knowledge Proofs for Non-linear Functions in Machine Learning.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HaoC0WZY024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/hao-meng-scalable",
            "url": "https://dblp.org/rec/conf/uss/HaoC0WZY024",
            "abstract": "Zero-knowledge (ZK) proofs have been recently explored for the integrity of machine learning (ML) inference. However, these protocols suffer from high computational overhead, with the primary bottleneck stemming from the evaluation of non-linear functions. In this paper, we propose the first systematic ZK proof framework for non-linear mathematical functions in ML using the perspective of table lookup . The key challenge is that table lookup cannot be directly applied to non-linear functions in ML since it would suffer from in-efficiencies due to the intolerably large table. Therefore, we carefully design several important building blocks, including digital decomposition, comparison, and truncation, such that they can effectively utilize table lookup with a quite small table size while ensuring the soundness of proofs. Based on these building blocks, we implement complex mathematical operations and further construct ZK proofs for current mainstream non-linear functions in ML such as ReLU, sigmoid, and normalization. The extensive experimental evaluation shows that our framework achieves 50 \u223c 179 \u00d7 runtime improvement compared to the state-of-the-art work, while maintaining a similar level of communication efficiency.",
            "keywords": [
                "Zero-knowledge Proofs",
                "Non-linear Functions",
                "Table Lookup",
                "Machine Learning Integrity",
                "Computational Efficiency"
            ]
        },
        "url": "URL#379516",
        "sema_paperId": "7819511adc7a025f28480c9c3d7585f65c2c7860"
    },
    {
        "@score": "1",
        "@id": "379517",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "254/0865",
                        "text": "Qingying Hao"
                    },
                    {
                        "@pid": "263/9750",
                        "text": "Nirav Diwan"
                    },
                    {
                        "@pid": "94/5656-2",
                        "text": "Ying Yuan 0002"
                    },
                    {
                        "@pid": "210/6087",
                        "text": "Giovanni Apruzzese"
                    },
                    {
                        "@pid": "82/4386",
                        "text": "Mauro Conti"
                    },
                    {
                        "@pid": "71/4292-11",
                        "text": "Gang Wang 0011"
                    }
                ]
            },
            "title": "It Doesn&apos;t Look Like Anything to Me: Using Diffusion Model to Subvert Visual Phishing Detectors.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HaoDYAC024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/hao-qingying",
            "url": "https://dblp.org/rec/conf/uss/HaoDYAC024",
            "abstract": "Visual phishing detectors rely on website logos as the invariant identity indicator to detect phishing websites that mimic a target brand\u2019s website. Despite their promising performance, the robustness of these detectors is not yet well understood. In this paper, we challenge the invariant assumption of these detectors and propose new attack tactics, LogoMorph , with the ultimate purpose of enhancing these systems. LogoMorph is rooted in a key insight: users can neglect large visual perturbations on the logo as long as the perturbation preserves the original logo\u2019s semantics. We devise a range of attack meth-ods to create semantic-preserving adversarial logos, yielding phishing webpages that bypass state-of-the-art detectors. For text-based logos, we find that using alternative fonts can help to achieve the attack goal. For image-based logos, we find that an adversarial diffusion model can effectively capture the style of the logo while generating new variants with large visual differences. Practically, we evaluate LogoMorph with white-box and black-box experiments and test the resulting adversarial webpages against various visual phishing detectors end-to-end. User studies ( n = 150) confirm the effectiveness of our adversarial phishing webpages on end users (with a detection rate of 0.59, barely better than a coin toss). We also propose and evaluate countermeasures, and share our code.",
            "keywords": [
                "Visual Phishing Detection",
                "Adversarial Logos",
                "Semantic Perturbations",
                "Diffusion Models",
                "Phishing Website Bypass"
            ]
        },
        "url": "URL#379517",
        "sema_paperId": "908b7e5017ab36b86e9c6b5d1d7aaeeab0f83fe3"
    },
    {
        "@score": "1",
        "@id": "379518",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "184/7209",
                        "text": "Meng Hao"
                    },
                    {
                        "@pid": "71/10355",
                        "text": "Weiran Liu"
                    },
                    {
                        "@pid": "144/6285",
                        "text": "Liqiang Peng"
                    },
                    {
                        "@pid": "39/5544-1",
                        "text": "Hongwei Li 0001"
                    },
                    {
                        "@pid": "18/2908",
                        "text": "Cong Zhang"
                    },
                    {
                        "@pid": "255/5224",
                        "text": "Hanxiao Chen"
                    },
                    {
                        "@pid": "77/7902-4",
                        "text": "Tianwei Zhang 0004"
                    }
                ]
            },
            "title": "Unbalanced Circuit-PSI from Oblivious Key-Value Retrieval.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HaoLP0ZC024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/hao-meng-unbalanced",
            "url": "https://dblp.org/rec/conf/uss/HaoLP0ZC024",
            "abstract": "Circuit-based Private Set Intersection (circuit-PSI) empowers two parties, a client and a server, each with input sets X and Y, to securely compute a function f on the intersection X\u2229Y while preserving the confidentiality of X\u2229Y from both parties. Despite the recent proposals of computationally efficient circuit-PSI protocols, they primarily focus on the balanced scenario where |X| is similar to |Y|. However, in many practical situations, a circuit-PSI protocol may be applied in an unbalanced context, where |X| is significantly smaller than |Y|. Directly applying existing protocols to this scenario poses notable efficiency challenges due to the communication complexity of these protocols scaling at least linearly with the size of the larger set, i.e., max(|X|,|Y|).\nIn this work, we put forth efficient constructions for unbalanced circuit-PSI, demonstrating sublinear communication complexity in the size of the larger set. Our key insight lies in formalizing unbalanced circuit-PSI as the process of obliviously retrieving values corresponding to keys from a set of key-value pairs. To achieve this, we propose a new functionality named Oblivious Key-Value Retrieval (OKVR) and design the OKVR protocol based on a new notion termed sparse Oblivious Key-Value Store (sparse OKVS). We conduct comprehensive experiments and the results showcase substantial improvements over the state-of-the-art circuit-PSI schemes, i.e., 1.84\u223c48.86x communication improvement and 1.50\u223c39.81x faster computation. Compared to a very recent unbalanced circuit-PSI work, our constructions outperform them by 1.18\u223c15.99x and 1.22\u223c10.44x in communication and computation overhead, respectively, depending on set sizes and network environments.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-hao-meng-unbalanced.pdf",
            "keywords": [
                "Circuit-based Private Set Intersection",
                "Oblivious Key-Value Retrieval",
                "Unbalanced Protocols",
                "Communication Complexity",
                "Sparse Oblivious Key-Value Store"
            ]
        },
        "url": "URL#379518"
    },
    {
        "@score": "1",
        "@id": "379519",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "249/1158",
                        "text": "Ayako Akiyama Hasegawa"
                    },
                    {
                        "@pid": "62/5563",
                        "text": "Daisuke Inoue"
                    },
                    {
                        "@pid": "26/3158",
                        "text": "Mitsuaki Akiyama"
                    }
                ]
            },
            "title": "How WEIRD is Usable Privacy and Security Research?",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HasegawaIA24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/hasegawa",
            "url": "https://dblp.org/rec/conf/uss/HasegawaIA24",
            "abstract": "In human factor fields such as human-computer interaction (HCI) and psychology, researchers have been concerned that participants mostly come from WEIRD (Western, Educated, Industrialized, Rich, and Democratic) countries. This WEIRD skew may hinder understanding of diverse populations and their cultural differences. The usable privacy and security (UPS) field has inherited many research methodologies from research on human factor fields. We conducted a literature review to understand the extent to which participant samples in UPS papers were from WEIRD countries and the characteristics of the methodologies and research topics in each user study recruiting Western or non-Western participants. We found that the skew toward WEIRD countries in UPS is greater than that in HCI. Geographic and linguistic barriers in the study methods and recruitment methods may cause researchers to conduct user studies locally. In addition, many papers did not report participant demographics, which could hinder the replication of the reported studies, leading to low reproducibility. To improve geographic diversity, we provide the suggestions including facilitate replication studies, address geographic and linguistic issues of study/recruitment methods, and facilitate research on the topics for non-WEIRD populations.",
            "keywords": [
                "Usable Privacy and Security",
                "Human-Computer Interaction",
                "WEIRD Bias",
                "Participant Demographics",
                "Cultural Diversity in Research"
            ]
        },
        "url": "URL#379519",
        "sema_paperId": "7924d2025d5258331189c469adbc3696fff9dcb6"
    },
    {
        "@score": "1",
        "@id": "379520",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "65/425",
                        "text": "Yi He"
                    },
                    {
                        "@pid": "381/1656",
                        "text": "Yunchao Guan"
                    },
                    {
                        "@pid": "381/1603",
                        "text": "Ruoyu Lun"
                    },
                    {
                        "@pid": "328/8745",
                        "text": "Shangru Song"
                    },
                    {
                        "@pid": "92/6044",
                        "text": "Zhihao Guo"
                    },
                    {
                        "@pid": "15/3840",
                        "text": "Jianwei Zhuge"
                    },
                    {
                        "@pid": "20/1036-5",
                        "text": "Jianjun Chen 0005"
                    },
                    {
                        "@pid": "50/5190",
                        "text": "Qiang Wei"
                    },
                    {
                        "@pid": "158/3332",
                        "text": "Zehui Wu"
                    },
                    {
                        "@pid": "49/1749",
                        "text": "Miao Yu"
                    },
                    {
                        "@pid": "371/5865",
                        "text": "Hetian Shi"
                    },
                    {
                        "@pid": "181/2688-2",
                        "text": "Qi Li 0002"
                    }
                ]
            },
            "title": "Demystifying the Security Implications in IoT Device Rental Services.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HeGLSGZCWWYS024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/he-yi",
            "url": "https://dblp.org/rec/conf/uss/HeGLSGZCWWYS024",
            "abstract": "Nowadays, unattended device rental services with cellular IoT controllers, such as e-scooters and EV chargers, are widely deployed in public areas around the world, offering convenient access to users via mobile apps. While differing from traditional smart homes in functionality and implementation, the security of these devices remains largely unexplored. In this work, we conduct a systematic study to uncover security implications in IoT device rental services. By investigating 17 physical devices and 92 IoT apps, we identify multiple design and implementation flaws across a wide range of products, which can lead to severe security consequences, such as forcing all devices offline, remotely controlling all devices, or hijacking all users\u2019 accounts of the vendors. The root cause is that rentable IoT devices adopt weak resource identifiers (IDs), and attackers can infer these IDs at scale and exploit access control flaws to manipulate these resources. For instance, rentable IoT products allow authenticated users to find and use any device from the rentable IoT apps via a device serial number, which can be easily inferred by attackers and combined with other vulnerabilities to exploit remote devices on a large scale. To identify these risks, we propose a tool, called IDScope , to automatically detect the weak IDs in apps and assess if these IDs can be abused to scale the exploitation scope of existing access control vulnerabilities. Finally, we identify 57 vulnerabilities in 28 products which can lead to",
            "keywords": [
                "IoT Device Security",
                "Device Rental Services",
                "Access Control Flaws",
                "Weak Resource Identifiers",
                "Vulnerability Detection"
            ]
        },
        "url": "URL#379520",
        "sema_paperId": "fcebcd4b246e349f04e0a36e769095bfd32c752b"
    },
    {
        "@score": "1",
        "@id": "379521",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "348/3492",
                        "text": "Haojie He"
                    },
                    {
                        "@pid": "227/9139",
                        "text": "Xingwei Lin"
                    },
                    {
                        "@pid": "381/1651",
                        "text": "Ziang Weng"
                    },
                    {
                        "@pid": "92/10854-1",
                        "text": "Ruijie Zhao 0001"
                    },
                    {
                        "@pid": "153/0205",
                        "text": "Shuitao Gan"
                    },
                    {
                        "@pid": "08/4315-1",
                        "text": "Libo Chen 0001"
                    },
                    {
                        "@pid": "138/4316",
                        "text": "Yuede Ji"
                    },
                    {
                        "@pid": "301/5814",
                        "text": "Jiashui Wang"
                    },
                    {
                        "@pid": "44/3322",
                        "text": "Zhi Xue"
                    }
                ]
            },
            "title": "Code is not Natural Language: Unlock the Power of Semantics-Oriented Graph Representation for Binary Code Similarity Detection.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HeLW0G0JWX24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/he-haojie",
            "url": "https://dblp.org/rec/conf/uss/HeLW0G0JWX24",
            "abstract": "Binary code similarity detection (BCSD) has garnered significant attention in recent years due to its crucial role in various binary code-related tasks, such as vulnerability search and software plagiarism detection. Currently, BCSD systems are typically based on either instruction streams or control flow graphs (CFGs). However, these approaches have limitations. Instruction stream-based approaches treat binary code as natural languages, overlooking well-defined semantic structures. CFG-based approaches exploit only the control flow structures, neglecting other essential aspects of code. Our key insight is that unlike natural languages, binary code has well-defined semantic structures, including intra-instruction structures, inter-instruction relations (e.g., def-use, branches), and implicit conventions (e.g. calling conventions) . Motivated by that, we carefully examine the necessary relations and structures required to express the full semantics and expose them directly to the deep neural network through a novel semantics-oriented graph representation. Furthermore, we propose a lightweight multi-head softmax aggregator to effectively and efficiently fuse multiple aspects of the binary code. Extensive experiments show that our method significantly outperforms the state-of-the-art (e.g., in the x64-XC retrieval experiment with a pool size of 10000, our method achieves a recall score of 184%, 220",
            "keywords": [
                "Binary Code Similarity Detection",
                "Semantics-Oriented Graph Representation",
                "Control Flow Graphs",
                "Intra-Instruction Structures",
                "Inter-Instruction Relations"
            ]
        },
        "url": "URL#379521",
        "sema_paperId": "bd66e888ba8e5af7a578efb2a209ad802332c554"
    },
    {
        "@score": "1",
        "@id": "379523",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "296/3944",
                        "text": "Jonas Hielscher"
                    },
                    {
                        "@pid": "84/3561",
                        "text": "Simon Parkin"
                    }
                ]
            },
            "title": "&quot;What Keeps People Secure is That They Met The Security Team&quot;: Deconstructing Drivers And Goals of Organizational Security Awareness.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HielscherP24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/hielscher",
            "url": "https://dblp.org/rec/conf/uss/HielscherP24",
            "abstract": "Security awareness campaigns in organizations now collectively cost billions of dollars annually. There is increasing focus on ensuring certain security behaviors among employees. On the surface, this would imply a user-centered view of security in organizations. Despite this, the basis of what security awareness managers do and what decides this are unclear. We conducted n=15 semi-structured interviews with full-time security awareness managers, with experience across various national and international companies in European countries, with thousands of employees. Through thematic analysis, we identify that success in awareness management is fragile while having the potential to improve; there are a range of restrictions, and mismatched drivers and goals for security awareness, affecting how it is structured, delivered, measured, and improved. We find that security awareness as a practice is underspecified, and split between messaging around secure behaviors and connecting to employees, with a lack of recognition for the measures that awareness managers regard as important. We discuss ways forward, including alternative indicators of success, and security usability advocacy for employees.",
            "keywords": [
                "Security Awareness",
                "Organizational Behavior",
                "Awareness Management",
                "Employee Engagement",
                "Security Usability"
            ]
        },
        "url": "URL#379523",
        "sema_paperId": "1fde57eb35012c3ff6ded6c271339523868fe6db"
    },
    {
        "@score": "1",
        "@id": "379524",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "179/2240",
                        "text": "Nguyen Phong Hoang"
                    },
                    {
                        "@pid": "143/5671",
                        "text": "Jakub Dalek"
                    },
                    {
                        "@pid": "129/5380",
                        "text": "Masashi Crete-Nishihata"
                    },
                    {
                        "@pid": "c/NicolasChristin",
                        "text": "Nicolas Christin"
                    },
                    {
                        "@pid": "75/3570",
                        "text": "Vinod Yegneswaran"
                    },
                    {
                        "@pid": "09/1231",
                        "text": "Michalis Polychronakis"
                    },
                    {
                        "@pid": "87/840",
                        "text": "Nick Feamster"
                    }
                ]
            },
            "title": "GFWeb: Measuring the Great Firewall&apos;s Web Censorship at Scale.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HoangDCCYPF24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/hoang",
            "url": "https://dblp.org/rec/conf/uss/HoangDCCYPF24",
            "abstract": "Censorship systems such as the Great Firewall (GFW) have been continuously refined to enhance their filtering capabilities. However, most prior studies, and in particular the GFW, have been limited in scope and conducted over short time periods, leading to gaps in our understanding of the GFW\u2019s evolving Web censorship mechanisms over time. We introduce GFWeb, a novel system designed to discover domain blocklists used by the GFW for censoring Web access. GFWeb exploits GFW\u2019s bidirectional and loss-tolerant blocking behavior to enable testing hundreds of millions of domains on a monthly basis, thereby facilitating large-scale longitudinal measurement of HTTP and HTTPS blocking mechanisms. Over the course of 20 months, GFWeb has tested a total of 1.02 billion domains, and detected 943K and 55K pay-level domains censored by the GFW\u2019s HTTP and HTTPS filters, respectively. To the best of our knowledge, our study represents the most extensive set of domains censored by the GFW ever discovered to date, many of which have never been detected by prior systems. Analyzing the longitudinal dataset collected by GFWeb, we observe that the GFW has been up-graded to mitigate several issues previously identified by the research community, including overblocking and failure in reassembling fragmented packets. More importantly, we discover that the GFW\u2019s bidirectional blocking is not symmetric as previously thought, i.e., it can only be triggered by certain domains when probed from inside the country. We discuss the implications of our work on existing censorship measurement and circumvention efforts. We hope insights gained from our study can help inform future",
            "keywords": [
                "Web Censorship",
                "Great Firewall",
                "Domain Blocking",
                "Longitudinal Measurement",
                "Bidirectional Blocking"
            ]
        },
        "url": "URL#379524",
        "sema_paperId": "bcd633876e9ffe8d903a298628d3e7fd25891dd9"
    },
    {
        "@score": "1",
        "@id": "379525",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "349/7794",
                        "text": "Sandra H\u00f6ltervennhoff"
                    },
                    {
                        "@pid": "325/3563",
                        "text": "Noah W\u00f6hler"
                    },
                    {
                        "@pid": "381/1700",
                        "text": "Arne M\u00f6hle"
                    },
                    {
                        "@pid": "133/2390",
                        "text": "Marten Oltrogge"
                    },
                    {
                        "@pid": "132/9687",
                        "text": "Yasemin Acar"
                    },
                    {
                        "@pid": "186/0348",
                        "text": "Oliver Wiese"
                    },
                    {
                        "@pid": "38/9378",
                        "text": "Sascha Fahl"
                    }
                ]
            },
            "title": "A Mixed-Methods Study on User Experiences and Challenges of Recovery Codes for an End-to-End Encrypted Service.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HoltervennhoffW24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/h%C3%B6ltervennhoff",
            "url": "https://dblp.org/rec/conf/uss/HoltervennhoffW24",
            "abstract": "Recovery codes are a popular backup mechanism for online services to aid users who lost their passwords or two-factor authentication tokens in regaining access to their accounts or encrypted data. Especially for end-to-end encrypted services, recovery codes are a critical feature, as the service itself cannot access the encrypted user data and help users regain access. The way end-users manage recovery codes is not well understood. Hence, we investigate end-user perceptions and management strategies of recovery codes. Therefore, we survey users of an end-to-end encrypted email service provider, deploying recovery codes for accounts and encrypted data recovery in case of authentication credential loss. We performed an online survey with 281 users. In a second study, we analyzed 196 support requests on Reddit. Most of our participants stored the service provider\u2019s recovery code. We could identify six strategies for saving it, with using a pass-word manager being the most widespread. Participants were generally satisfied with the service provider\u2019s recovery code. However, while they appreciated its security, its usability was lacking. We found obstacles, such as losing access to the recovery code or non-functioning recovery codes and security misconceptions. These often resulted from users not understanding the underlying security implications, e.g., that the support cannot access or restore their unencrypted data.",
            "keywords": [
                "End-to-End Encryption",
                "User Experience",
                "Recovery Codes",
                "Account Recovery",
                "Usability Challenges"
            ]
        },
        "url": "URL#379525",
        "sema_paperId": "b2f2bee0e1adad5ea25c0f865c1aefd4f64a2ad6"
    },
    {
        "@score": "1",
        "@id": "379526",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "132/4924-1",
                        "text": "Alexander Hoover 0001"
                    },
                    {
                        "@pid": "242/3283",
                        "text": "Ruth Ng"
                    },
                    {
                        "@pid": "373/6656",
                        "text": "Daren Khu"
                    },
                    {
                        "@pid": "373/6111",
                        "text": "Yao&apos;an Li"
                    },
                    {
                        "@pid": "251/1435",
                        "text": "Joelle Lim"
                    },
                    {
                        "@pid": "329/4947",
                        "text": "Derrick Ng"
                    },
                    {
                        "@pid": "373/6618",
                        "text": "Jed Lim"
                    },
                    {
                        "@pid": "250/4023",
                        "text": "Yiyang Song"
                    }
                ]
            },
            "title": "Leakage-Abuse Attacks Against Structured Encryption for SQL.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HooverNKLLNLS24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/hoover",
            "url": "https://dblp.org/rec/conf/uss/HooverNKLLNLS24",
            "abstract": "Structured Encryption (StE) enables a client to securely store and query data stored on an untrusted server. Recent constructions of StE have moved beyond basic queries, and now support large subsets of SQL. However, the security of these constructions is poorly understood, and no systematic analysis has been performed.\nWe address this by providing the first leakage-abuse attacks against StE for SQL schemes. Our attacks can be run by a passive adversary on a server with access to some information about the distribution of underlying data, a common model in prior work. They achieve partial query recovery against select operations and partial plaintext recovery against join operations. We prove the optimality and near-optimality of two new attacks, in a Bayesian inference framework. We complement our theoretical results with an empirical investigation testing the performance of our attacks against real-world data and show they can successfully recover a substantial proportion of queries and plaintexts.\nIn addition to our new attacks, we provide proofs showing that the conditional optimality of a previously proposed leakage-abuse attack and that inference against join operations is NP-hard in general.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-hoover.pdf",
            "keywords": [
                "Structured Encryption",
                "SQL Queries",
                "Leakage-Abuse Attacks",
                "Data Privacy",
                "Join Operations"
            ]
        },
        "url": "URL#379526"
    },
    {
        "@score": "1",
        "@id": "379527",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "132/8240",
                        "text": "P\u00e9ter Horv\u00e1th"
                    },
                    {
                        "@pid": "279/3363",
                        "text": "Dirk Lauret"
                    },
                    {
                        "@pid": "137/6081-1",
                        "text": "Zhuoran Liu 0001"
                    },
                    {
                        "@pid": "67/1939",
                        "text": "Lejla Batina"
                    }
                ]
            },
            "title": "SoK: Neural Network Extraction Through Physical Side Channels.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HorvathL0B24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/horvath",
            "url": "https://dblp.org/rec/conf/uss/HorvathL0B24",
            "abstract": "Deep Neural Networks (DNNs) are widely used in various applications and are typically deployed on hardware accelerators. Physical Side-Channel Analysis (SCA) on DNN implementations is getting more attention from both industry and academia because of the potential to severely jeopar-dize the confidentiality of DNN Intellectual Property (IP) and the data privacy of end users. Current physical SCA attacks on DNNs are highly platform dependent and employ distinct threat models for different attack objectives and analysis tools, necessitating a general revision of attack methodology and assumptions. To this end, we provide a taxonomy of previous physical SCA attacks on DNNs and systematize findings toward model extraction and input recovery . Specifically, we discuss the dependencies of threat models on attack objectives and analysis methods, for which we present a novel systematic attack framework composed of fundamental stages derived from various attacks. Following the framework, we provide an in-depth analysis of common SCA attacks for each attack objective and reveal practical limitations, validated by experiments on a state-of-the-art commercial DNN accelerator. Based on our findings, we identify challenges and suggest future directions.",
            "keywords": [
                "Physical Side-Channel Analysis",
                "Model Extraction",
                "Input Recovery",
                "Attack Methodology",
                "DNN Intellectual Property"
            ]
        },
        "url": "URL#379527",
        "sema_paperId": "3f251c6f13e05c2433c3a8f2f8bbf1f07fe77568"
    },
    {
        "@score": "1",
        "@id": "379528",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "213/7298",
                        "text": "Nicolas Huaman"
                    },
                    {
                        "@pid": "378/5665",
                        "text": "Jacques Suray"
                    },
                    {
                        "@pid": "325/3232",
                        "text": "Jan H. Klemmer"
                    },
                    {
                        "@pid": "138/4883",
                        "text": "Marcel Fourn\u00e9"
                    },
                    {
                        "@pid": "251/3013",
                        "text": "Sabrina Amft"
                    },
                    {
                        "@pid": "242/3169",
                        "text": "Ivana Trummov\u00e1"
                    },
                    {
                        "@pid": "132/9687",
                        "text": "Yasemin Acar"
                    },
                    {
                        "@pid": "38/9378",
                        "text": "Sascha Fahl"
                    }
                ]
            },
            "title": "&quot;You have to read 50 different RFCs that contradict each other&quot;: An Interview Study on the Experiences of Implementing Cryptographic Standards.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HuamanSKFATAF24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/huaman",
            "url": "https://dblp.org/rec/conf/uss/HuamanSKFATAF24",
            "abstract": "Implementing cryptographic standards is a critical process for the cryptographic ecosystem. Cryptographic standards aim to support developers and engineers in implementing cryptographic primitives and protocols. However, past security incidents suggest that implementing cryptographic standards can be challenging and might jeopardize software and hardware security. We need to understand and mitigate the pain points of those implementing cryptographic standards to support them better. To shed light on the challenges and obstacles of implementing cryptographic standards, we conducted 20 semi-structured interviews with experienced cryptographers and cryptographic software engineers. We identify common practices when implementing standards, including the criticality of reference and third-party implementations, test vectors to verify implementations, and the open standard community as central support for questions and reviews of implementations. Based on our findings, we recommend transparent standardization processes, strong (ideally formal) verification, improved support for comparing implementations, and covering updates and error handling in the standardization process.",
            "keywords": [
                "Cryptographic Standards",
                "Implementation Challenges",
                "Cryptographic Primitives",
                "Standardization Processes",
                "Verification Methods"
            ]
        },
        "url": "URL#379528",
        "sema_paperId": "6362b743d5b9280d3796feafd07dcc2450d66947"
    },
    {
        "@score": "1",
        "@id": "379529",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "62/10077",
                        "text": "Zonghao Huang"
                    },
                    {
                        "@pid": "32/3440",
                        "text": "Lujo Bauer"
                    },
                    {
                        "@pid": "r/MichaelKReiter",
                        "text": "Michael K. Reiter"
                    }
                ]
            },
            "title": "The Impact of Exposed Passwords on Honeyword Efficacy.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HuangBR24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/huang-zonghao",
            "url": "https://dblp.org/rec/conf/uss/HuangBR24",
            "abstract": "Honeywords are decoy passwords that can be added to a credential database; if a login attempt uses a honeyword, this indicates that the site's credential database has been leaked. In this paper we explore the basic requirements for honeywords to be effective, in a threat model where the attacker knows passwords for the same users at other sites. First, we show that for user-chosen (vs. algorithmically generated, i.e., by a password manager) passwords, existing honeyword-generation algorithms do not simultaneously achieve false-positive and false-negative rates near their ideals of $\\approx 0$ and $\\approx \\frac{1}{1+n}$, respectively, in this threat model, where $n$ is the number of honeywords per account. Second, we show that for users leveraging algorithmically generated passwords, state-of-the-art methods for honeyword generation will produce honeywords that are not sufficiently deceptive, yielding many false negatives. Instead, we find that only a honeyword-generation algorithm that uses the \\textit{same} password generator as the user can provide deceptive honeywords in this case. However, when the defender's ability to infer the generator from the (one) account password is less accurate than the attacker's ability to infer the generator from potentially many, this deception can again wane. Taken together, our results provide a cautionary note for the state of honeyword research and pose new challenges to the field.",
            "keywords": [
                "Honeywords",
                "Password Security",
                "Credential Database",
                "Decoy Passwords",
                "Password Generation Algorithms"
            ]
        },
        "url": "URL#379529",
        "sema_paperId": "bb3113b6ba0daff9c0f481bb8458de15110aee9f"
    },
    {
        "@score": "1",
        "@id": "379530",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "152/1812",
                        "text": "Zirui Huang"
                    },
                    {
                        "@pid": "147/1311",
                        "text": "Yunlong Mao"
                    },
                    {
                        "@pid": "53/4506-2",
                        "text": "Sheng Zhong 0002"
                    }
                ]
            },
            "title": "UBA-Inf: Unlearning Activated Backdoor Attack with Influence-Driven Camouflage.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HuangM024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/huang-zirui",
            "url": "https://dblp.org/rec/conf/uss/HuangM024",
            "abstract": "Machine-Learning-as-a-Service (MLaaS) is an emerging product to meet the market demand. However, end users are required to upload data to the remote server when using MLaaS, raising privacy concerns. Since the right to be forgotten came into effect, data unlearning has been widely supported in on-cloud products for removing users\u2019 private data from remote datasets and machine learning models. Plenty of machine unlearning methods have been proposed recently to erase the influence of forgotten data. Unfortunately, we find that machine unlearning makes the on-cloud model highly vulnerable to backdoor attacks. In this paper, we report a new threat against models with unlearning enabled and implement an Unlearning Activated Backdoor Attack with Influence-driven camouflage (UBA-Inf). Unlike conventional backdoor attacks, UBA-Inf provides a new backdoor approach for effectiveness and stealthiness by activating the camouflaged back-door through machine unlearning. The proposed approach can be implemented using off-the-shelf backdoor generating algorithms. Moreover, UBA-Inf is an \u201con-demand\u201d attack, offering fine-grained control of backdoor activation through unlearning requests, overcoming backdoor vanishing and exposure problems. By extensively evaluating UBA-Inf, we conclude that UBA-Inf is a powerful backdoor approach that improves stealthiness, robustness, and persistence.",
            "keywords": [
                "Machine Learning as a Service (MLaaS)",
                "Data Unlearning",
                "Backdoor Attack",
                "Influence-Driven Camouflage",
                "Unlearning Activated Backdoor Attack (UBA-Inf)"
            ]
        },
        "url": "URL#379530",
        "sema_paperId": "3cbddd0096c05459f8589f0dd6ec2c49e3f8a00f"
    },
    {
        "@score": "1",
        "@id": "379531",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "286/8388",
                        "text": "Xuanbo Huang"
                    },
                    {
                        "@pid": "94/5600",
                        "text": "Kaiping Xue"
                    },
                    {
                        "@pid": "332/3015",
                        "text": "Lutong Chen"
                    },
                    {
                        "@pid": "332/3042",
                        "text": "Mingrui Ai"
                    },
                    {
                        "@pid": "243/6488",
                        "text": "Huancheng Zhou"
                    },
                    {
                        "@pid": "71/2890",
                        "text": "Bo Luo"
                    },
                    {
                        "@pid": "64/1147",
                        "text": "Guofei Gu"
                    },
                    {
                        "@pid": "01/1492",
                        "text": "Qibin Sun"
                    }
                ]
            },
            "title": "You Can Obfuscate, but You Cannot Hide: CrossPoint Attacks against Network Topology Obfuscation.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HuangXCAZLGS24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/huang-xuanbo",
            "url": "https://dblp.org/rec/conf/uss/HuangXCAZLGS24",
            "abstract": "Link-flooding attacks (LFAs) may disrupt Internet connections in targeted areas by flooding specific links. One effective mitigation strategy against these attacks is network topology obfuscation (NTO), which aims to obscure the network map and conceal critical links, preventing attackers from identifying bottleneck links. However, we argue that the attackers can still discover critical links in the presence of NTO defenses. In this paper, we introduce the CrossPoint attacks to escape the security protections of state-of-the-art NTO defenses by exploiting two network traffic features: correlated congestion and statistical disparities . Although NTO defenses create a complex and seemingly robust virtual topology, distinct information is still discoverable due to conflicting design objectives and inherent features of the Internet, resulting in novel side channels. Through comprehensive experiments, including a measurement study on the Internet, we demonstrate CrossPoint attacks\u2019 high success rate (80%-95%), minor overhead (10%- 20%), as well as attack stealthiness and feasibility.",
            "keywords": [
                "Network Topology Obfuscation",
                "Link-Flooding Attacks",
                "CrossPoint Attacks",
                "Network Traffic Analysis",
                "Congestion Correlation"
            ]
        },
        "url": "URL#379531",
        "sema_paperId": "2aeade77ea5a3901fc325fd111378ef2ade408c1"
    },
    {
        "@score": "1",
        "@id": "379532",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "290/1874",
                        "text": "Abdullah Al Ishtiaq"
                    },
                    {
                        "@pid": "255/4887",
                        "text": "Sarkar Snigdha Sarathi Das"
                    },
                    {
                        "@pid": "255/5036",
                        "text": "Syed Md. Mukit Rashid"
                    },
                    {
                        "@pid": "358/7127",
                        "text": "Ali Ranjbar"
                    },
                    {
                        "@pid": "87/1149",
                        "text": "Kai Tu"
                    },
                    {
                        "@pid": "261/5092",
                        "text": "Tianwei Wu"
                    },
                    {
                        "@pid": "323/1057",
                        "text": "Zhezheng Song"
                    },
                    {
                        "@pid": "214/9012",
                        "text": "Weixuan Wang"
                    },
                    {
                        "@pid": "301/5126",
                        "text": "Mujtahid Akon"
                    },
                    {
                        "@pid": "60/2536-37",
                        "text": "Rui Zhang 0037"
                    },
                    {
                        "@pid": "83/7270",
                        "text": "Syed Rafiul Hussain"
                    }
                ]
            },
            "title": "Hermes: Unlocking Security Analysis of Cellular Network Protocols by Synthesizing Finite State Machines from Natural Language Specifications.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/IshtiaqDRRTWSWA24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/al-ishtiaq",
            "url": "https://dblp.org/rec/conf/uss/IshtiaqDRRTWSWA24",
            "abstract": "In this paper, we present Hermes, an end-to-end framework to automatically generate formal representations from natural language cellular specifications. We first develop a neural constituency parser, NEUTREX, to process transition-relevant texts and extract transition components (i.e., states, conditions, and actions). We also design a domain-specific language to translate these transition components to logical formulas by leveraging dependency parse trees. Finally, we compile these logical formulas to generate transitions and create the formal model as finite state machines. To demonstrate the effectiveness of Hermes, we evaluate it on 4G NAS, 5G NAS, and 5G RRC specifications and obtain an overall accuracy of 81-87%, which is a substantial improvement over the state-of-the-art. Our security analysis of the extracted models uncovers 3 new vulnerabilities and identifies 19 previous attacks in 4G and 5G specifications, and 7 deviations in commercial 4G basebands.",
            "keywords": [
                "Cellular Network Protocols",
                "Finite State Machines",
                "Natural Language Processing",
                "Security Analysis",
                "Vulnerability Detection"
            ]
        },
        "url": "URL#379532",
        "sema_paperId": "e7ebbdc5bfd05873e8c4394c3a3c17eed9a512ea"
    },
    {
        "@score": "1",
        "@id": "379533",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "220/2510",
                        "text": "Rasoul Jahanshahi"
                    },
                    {
                        "@pid": "27/3108",
                        "text": "Manuel Egele"
                    }
                ]
            },
            "title": "Argus: All your (PHP) Injection-sinks are belong to us.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/JahanshahiE24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/jahanshahi",
            "url": "https://dblp.org/rec/conf/uss/JahanshahiE24",
            "abstract": "Injection-based vulnerabilities in web applications such as cross-site scripting (XSS), insecure deserialization, and command injection have proliferated in recent years, exposing both clients and web applications to security breaches. Current studies in this area focus on detecting injection vulnerabilities in applications. Crucially, existing systems rely on manually curated lists of functions, so-called sinks, to detect such vulnerabilities. However, current studies are oblivious to the internal mechanics of the underlying programming language. In such a case, existing systems rely on an incomplete set of sinks, which results in disregarding security vulnerabilities. Despite numerous studies on injection vulnerabilities, there has been no study that comprehensively identifies the set of functions that an attacker can exploit for injection attacks.\nThis paper addresses the drawbacks of relying on manually curated lists of sinks to identify such vulnerabilities. We devise a novel generic approach to automatically identify the set of sinks that can lead to injection-style security vulnerabilities. To demonstrate the generality, we focused on three types of injection vulnerabilities: XSS, command injection, and insecure deserialization. We implemented a prototype of our approach in a tool called Argus to identify the set of PHP functions that deserialize user-input, execute operating system (OS) commands, or write user-input to the output buffer. We evaluated our prototype on the three most popular major versions of the PHPinterpreter. Argus detected 284 deserialization functions that allow adversaries to perform deserialization attacks, an order of magnitude more than the most exhaustive manually curated list used in related work. Furthermore, we detected 22 functions that can lead to XSS attacks, which is twice the number of functions used in prior work. To demonstrate thatArgus produces security-relevant findings, we integrated its results with three existing analysis systems\u2013 Psalm and RIPS, two static taint analyses, and FUGIO, an exploit generation tool. Themodifiedtoolsdetected 13 previously unknown deserialization and XSS vulnerabilities in WordPress and its plugins, of which 11 have been assigned CVE IDs and designated as high-severity vulnerabilities.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-jahanshahi.pdf",
            "keywords": [
                "Injection Vulnerabilities",
                "PHP Functions",
                "Deserialization Attacks",
                "Cross-Site Scripting (XSS)",
                "Command Injection"
            ]
        },
        "url": "URL#379533",
        "sema_paperId": "c7055e87ca39f0ad7f73cb3ff7cf1d75c49f8c7a"
    },
    {
        "@score": "1",
        "@id": "379534",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "43/4464",
                        "text": "Pranay Jain"
                    },
                    {
                        "@pid": "298/8064",
                        "text": "Andrew C. Reed"
                    },
                    {
                        "@pid": "r/MichaelKReiter",
                        "text": "Michael K. Reiter"
                    }
                ]
            },
            "title": "Near-Optimal Constrained Padding for Object Retrievals with Dependencies.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/JainRR24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/jain",
            "url": "https://dblp.org/rec/conf/uss/JainRR24",
            "abstract": "The sizes of objects retrieved over the network are powerful indicators of the objects retrieved and are ingredients in numerous types of traf\ufb01c analysis, such as webpage \ufb01nger-printing. We present an algorithm by which a benevolent object store computes a memoryless padding scheme to pad objects before sending them, in a way that bounds the information gain that the padded sizes provide to the network observer about the objects being retrieved. Moreover, our al-gorithm innovates over previous works in two critical ways. First, the computed padding scheme satis\ufb01es constraints on the padding overhead: no object is padded to more than c \u00d7 its original size, for a tunable factor c > 1. Second, the privacy guarantees of the padding scheme allow for object retrievals that are not independent, as could be caused by hyperlinking. We show in empirical tests that our padding schemes improve dramatically over previous schemes for padding dependent object retrievals, providing better privacy at substantially lower padding overhead, and over known techniques for padding independent object retrievals subject to padding overhead constraints.",
            "keywords": [
                "Object Retrieval",
                "Padding Scheme",
                "Privacy Guarantees",
                "Traffic Analysis",
                "Dependent Object Retrievals"
            ]
        },
        "url": "URL#379534",
        "sema_paperId": "2d2b0c690bb8fb8fc508800114f2107e399f1388"
    },
    {
        "@score": "1",
        "@id": "379535",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "283/5559",
                        "text": "Patrick Jattke"
                    },
                    {
                        "@pid": "381/1641",
                        "text": "Max Wipfli"
                    },
                    {
                        "@pid": "264/9973",
                        "text": "Flavien Solt"
                    },
                    {
                        "@pid": "325/3514",
                        "text": "Michele Marazzi"
                    },
                    {
                        "@pid": "381/1639",
                        "text": "Matej B\u00f6lcskei"
                    },
                    {
                        "@pid": "121/2685",
                        "text": "Kaveh Razavi"
                    }
                ]
            },
            "title": "ZenHammer: Rowhammer Attacks on AMD Zen-based Platforms.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/JattkeWSMBR24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/jattke",
            "url": "https://dblp.org/rec/conf/uss/JattkeWSMBR24",
            "abstract": "AMD has gained a significant market share in recent years with the introduction of the Zen microarchitecture. While there are many recent Rowhammer attacks launched from Intel CPUs, they are completely absent on these newer AMD CPUs due to three non-trivial challenges: 1) reverse engineering the unknown DRAM addressing functions, 2) synchronizing with refresh commands for evading in-DRAM mitigations, and 3) achieving a sufficient row activation throughput. We address these challenges in the design of Z EN H AMMER , the first Rowhammer attack on recent AMD CPUs. Z EN H AM - MER reverse engineers DRAM addressing functions despite their non-linear nature, uses specially crafted access patterns for proper synchronization, and carefully schedules flush and fence instructions within a pattern to increase the activation throughput while preserving the access order necessary to bypass in-DRAM mitigations. Our evaluation with ten DDR4 devices shows that Z EN H AMMER finds bit flips on seven and six devices on AMD Zen 2 and Zen 3 , respectively, enabling Rowhammer exploitation on current AMD platforms. Furthermore, Z EN H AMMER triggers Rowhammer bit flips on a DDR5 device for the first time.",
            "keywords": [
                "Rowhammer Attack",
                "AMD Zen Microarchitecture",
                "DRAM Addressing Functions",
                "Bit Flips",
                "DDR5 Vulnerability"
            ]
        },
        "url": "URL#379535",
        "sema_paperId": "ff28262b65f3e4c6144ddfadb8de03091038c813"
    },
    {
        "@score": "1",
        "@id": "379536",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "295/8357",
                        "text": "Eric Jedermann"
                    },
                    {
                        "@pid": "117/8959",
                        "text": "Martin Strohmeier"
                    },
                    {
                        "@pid": "75/5939",
                        "text": "Vincent Lenders"
                    },
                    {
                        "@pid": "s/JensBSchmitt",
                        "text": "Jens B. Schmitt"
                    }
                ]
            },
            "title": "RECORD: A RECeption-Only Region Determination Attack on LEO Satellite Users.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/JedermannSLS24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/jedermann",
            "url": "https://dblp.org/rec/conf/uss/JedermannSLS24",
            "abstract": "Low Earth orbit (LEO) satellite communication has recently experienced a dramatic increase of usage in diverse application sectors. Naturally, the aspect of location privacy is becoming crucial, most notably in security or military applications. In this paper, we present a novel passive attack called RECORD, which is solely based on the reception of messages to LEO satellite users on the ground, threatening their location privacy. In particular, we show that by observing only the downlink of \u2018wandering\u2019 communication satellites over wide beams can be exploited at scale from passive attackers situated on Earth to estimate the region in which users are located. We build our own distributed satellite reception platform to implement the RECORD attack. We analyze the accuracy and limiting factors of this new attack using real-world measurements from our own Iridium satellite communication. Our experimental results reveal that by observing only 2.3 hours of traf\ufb01c, it is possible to narrow down the position of an Iridium user to an area below 11 km of radius (compared to the satellite beam size of 4700 km diameter). We conduct additional extensive simulative evaluations, which suggest that it is feasible to narrow down the unknown location of a user even further, for instance, to below 4 km radius when the observation period is increased to more than 16 hours. We \ufb01nally discuss the transferability of RECORD to different LEO constellations and highlight possible countermeasures.",
            "keywords": [
                "LEO Satellite Communication",
                "Location Privacy",
                "Passive Attack",
                "RECORD Attack",
                "User Location Estimation"
            ]
        },
        "url": "URL#379536",
        "sema_paperId": "fc0ba6a6e8332bb3497a86c8673da5f6d87231aa"
    },
    {
        "@score": "1",
        "@id": "379537",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "178/5180",
                        "text": "Tianxi Ji"
                    },
                    {
                        "@pid": "72/2643-1",
                        "text": "Pan Li 0001"
                    }
                ]
            },
            "title": "Less is More: Revisiting the Gaussian Mechanism for Differential Privacy.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Ji024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/ji",
            "url": "https://dblp.org/rec/conf/uss/Ji024",
            "abstract": "Differential privacy (DP) via output perturbation has been a de facto standard for releasing query or computation results on sensitive data. Different variants of the classic Gaussian mechanism have been developed to reduce the magnitude of the noise and improve the utility of sanitized query results.  However, we identify that all existing Gaussian mechanisms suffer from the curse of full-rank covariance matrices, and hence the expected accuracy losses of these mechanisms equal the trace of the covariance matrix of the noise. Particularly, for query results with multiple entries, in order to achieve DP, the expected accuracy loss of the classic Gaussian mechanism, that of the analytic Gaussian mechanism, and that of the  Matrix-Variate Gaussian (MVG) mechanism are lower bounded by terms that scales linearly with the number of entries.\nTo lift this curse, we design a Rank-1 Singular Multivariate Gaussian (R1SMG) mechanism. It achieves DP on high dimension query results by perturbing the results with noise following a singular multivariate Gaussian distribution, whose covariance matrix  is a randomly generated rank-1 positive semi-definite matrix.  In contrast, the classic Gaussian mechanism and its variants all consider deterministic full-rank covariance matrices. Our idea  is motivated by a clue from Dwork et al.'s seminal work on the classic Gaussian mechanism that has been ignored in the literature: when projecting multivariate Gaussian noise with a full-rank covariance matrix onto a set of orthonormal basis, only the coefficient of a single basis can contribute to the privacy guarantee.\nThis paper makes the following technical contributions.\n(i) The R1SMG mechanisms achieves DP guarantee on high dimension query results in, while its expected accuracy loss is lower bounded by a term that is on a lower order of magnitude by at least the dimension of query results compared with that of the classic Gaussian mechanism, of the analytic Gaussian mechanism, and of the MVG mechanism.\n(ii) Compared with other mechanisms, the R1SMG mechanism is  more stable and less likely to generate noise with large magnitude that overwhelms the query results, because the kurtosis and skewness of the nondeterministic accuracy loss introduced by this mechanism is larger than that introduced by other mechanisms.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-ji.pdf",
            "keywords": [
                "Differential Privacy",
                "Gaussian Mechanism",
                "Output Perturbation",
                "Rank-1 Singular Multivariate Gaussian",
                "Accuracy Loss"
            ]
        },
        "url": "URL#379537"
    },
    {
        "@score": "1",
        "@id": "379538",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "356/8580",
                        "text": "Grace Jia"
                    },
                    {
                        "@pid": "41/5447-1",
                        "text": "Rachit Agarwal 0001"
                    },
                    {
                        "@pid": "162/1936",
                        "text": "Anurag Khandelwal"
                    }
                ]
            },
            "title": "Length Leakage in Oblivious Data Access Mechanisms.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Jia0K24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/jia-grace",
            "url": "https://dblp.org/rec/conf/uss/Jia0K24",
            "abstract": "This paper explores the problem of preventing length leakage in oblivious data access mechanisms with passive persistent adversaries. We show that designing mechanisms that prevent both length leakage and access pattern leakage requires navigating a three-way tradeoff between storage footprint, bandwidth footprint, and the information leaked to the adversary. We establish powerful lower bounds on achievable storage and bandwidth footprints for a variety of leakage profiles, and present constructions that perfectly or near-perfectly match the lower bounds.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-jia-grace.pdf",
            "keywords": [
                "Oblivious Data Access",
                "Length Leakage",
                "Access Pattern Leakage",
                "Storage Footprint",
                "Bandwidth Footprint"
            ]
        },
        "url": "URL#379538"
    },
    {
        "@score": "1",
        "@id": "379539",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "231/8643",
                        "text": "Yanxue Jia"
                    },
                    {
                        "@pid": "117/3128-1",
                        "text": "Shi-Feng Sun 0001"
                    },
                    {
                        "@pid": "23/6726",
                        "text": "Hong-Sheng Zhou"
                    },
                    {
                        "@pid": "72/1963",
                        "text": "Dawu Gu"
                    }
                ]
            },
            "title": "Scalable Private Set Union, with Stronger Security.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Jia0ZG24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/jia-yanxue",
            "url": "https://dblp.org/rec/conf/uss/Jia0ZG24",
            "abstract": "Private Set Union (PSU) protocol allows parties, each holding an input set, to jointly compute the union of the sets without revealing anything else. In the literature, scalable PSU protocols follow the split-execute-assemble'' paradigm (Kolesnikov et al., ASIACRYPT 2019); in addition, those fast protocols often use Oblivious Transfer as building blocks. Kolesnikov et al.~(ASIACRYPT 2019) and Jia et al.~(USENIX Security 2022), pointed out that certain security issues can be introduced in thesplit-execute-assemble'' paradigm. In this work, surprisingly, we observe that the typical way of invoking Oblivious Transfer also causes unnecessary leakage, and only the PSU protocols based on additively homomorphic encryption (AHE) can avoid the leakage. However, the AHE-based PSU protocols are far from being practical.\nTo bridge the gap, we also design a new PSU protocol that can avoid the unnecessary leakage. Unlike the AHE-based PSU protocols, our new construction only relies on symmetric-key operations other than base OTs, thereby being much more scalable. The experimental results demonstrate that our protocol can obtain at least 873.74 x speedup over the best-performing AHE-based scheme. Moreover, our performance is comparable to that of the state-of-the-art PSU protocol (Chen et al., USENIX Security 2023), which also suffers from the unnecessary leakage.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-jia-yanxue.pdf",
            "keywords": [
                "Private Set Union",
                "Oblivious Transfer",
                "Homomorphic Encryption",
                "Security Leakage",
                "Scalability"
            ]
        },
        "url": "URL#379539"
    },
    {
        "@score": "1",
        "@id": "379540",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "330/8167",
                        "text": "Zian Jia"
                    },
                    {
                        "@pid": "67/4330",
                        "text": "Yun Xiong"
                    },
                    {
                        "@pid": "167/0416",
                        "text": "Yuhong Nan"
                    },
                    {
                        "@pid": "57/3892-9",
                        "text": "Yao Zhang 0009"
                    },
                    {
                        "@pid": "41/681",
                        "text": "Jinjing Zhao"
                    },
                    {
                        "@pid": "93/6953",
                        "text": "Mi Wen"
                    }
                ]
            },
            "title": "MAGIC: Detecting Advanced Persistent Threats via Masked Graph Representation Learning.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/JiaXN0ZW24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/jia-zian",
            "url": "https://dblp.org/rec/conf/uss/JiaXN0ZW24",
            "abstract": "Advance Persistent Threats (APTs), adopted by most delicate attackers, are becoming increasing common and pose great threat to various enterprises and institutions. Data provenance analysis on provenance graphs has emerged as a common approach in APT detection. However, previous works have exhibited several shortcomings: (1) requiring attack-containing data and a priori knowledge of APTs, (2) failing in extracting the rich contextual information buried within provenance graphs and (3) becoming impracticable due to their prohibitive computation overhead and memory consumption. In this paper, we introduce MAGIC, a novel and flexible self-supervised APT detection approach capable of performing multi-granularity detection under different level of supervision. MAGIC leverages masked graph representation learning to model benign system entities and behaviors, performing efficient deep feature extraction and structure abstraction on provenance graphs. By ferreting out anomalous system behaviors via outlier detection methods, MAGIC is able to perform both system entity level and batched log level APT detection. MAGIC is specially designed to handle concept drift with a model adaption mechanism and successfully applies to universal conditions and detection scenarios. We evaluate MAGIC on three widely-used datasets, including both real-world and simulated attacks. Evaluation results indicate that MAGIC achieves promising detection results in all scenarios and shows enormous advantage over state-of-the-art APT detection approaches in performance overhead.",
            "keywords": [
                "Advanced Persistent Threats",
                "Provenance Graphs",
                "Self-Supervised Learning",
                "Anomaly Detection",
                "Concept Drift"
            ]
        },
        "url": "URL#379540",
        "sema_paperId": "ea63e6d930b67babdda983bfa151058cec43ea6b"
    },
    {
        "@score": "1",
        "@id": "379541",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "220/8777-1",
                        "text": "Qisheng Jiang 0001"
                    },
                    {
                        "@pid": "09/11157",
                        "text": "Chundong Wang 0001"
                    }
                ]
            },
            "title": "Sync+Sync: A Covert Channel Built on fsync with Storage.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Jiang024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/jiang-qisheng",
            "url": "https://dblp.org/rec/conf/uss/Jiang024",
            "abstract": "Scientists have built a variety of covert channels for secretive information transmission with CPU cache and main memory. In this paper, we turn to a lower level in the memory hierarchy, i.e., persistent storage. Most programs store intermediate or eventual results in the form of files and some of them call fsync to synchronously persist a file with storage device for orderly persistence. Our quantitative study shows that one program would undergo significantly longer response time for fsync call if the other program is concurrently calling fsync, although they do not share any data. We further find that, concurrent fsync calls contend at multiple levels of storage stack due to sharing software structures (e.g., Ext4's journal) and hardware resources (e.g., disk's I/O dispatch queue). We accordingly build a covert channel named Sync+Sync. Sync+Sync delivers a transmission bandwidth of 20,000 bits per second at an error rate of about 0.40% with an ordinary solid-state drive. Sync+Sync can be conducted in cross-disk partition, cross-file system, cross-container, cross-virtual machine, and even cross-disk drive fashions, without sharing data between programs. Next, we launch side-channel attacks with Sync+Sync and manage to precisely detect operations of a victim database (e.g., insert/update and B-Tree node split). We also leverage Sync+Sync to distinguish applications and websites with high accuracy by detecting and analyzing their fsync frequencies and flushed data volumes. These attacks are useful to support further fine-grained information leakage.",
            "keywords": [
                "Covert Channels",
                "Persistent Storage",
                "Fsync Calls",
                "Information Leakage",
                "Side-Channel Attacks"
            ]
        },
        "url": "URL#379541",
        "sema_paperId": "23c82f8a67fe7cd74fddc0784aaab81df467dd9f"
    },
    {
        "@score": "1",
        "@id": "379542",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "06/4489",
                        "text": "Nan Jiang"
                    },
                    {
                        "@pid": "253/0434",
                        "text": "Bangjie Sun"
                    },
                    {
                        "@pid": "78/392",
                        "text": "Terence Sim"
                    },
                    {
                        "@pid": "02/3721-1",
                        "text": "Jun Han 0001"
                    }
                ]
            },
            "title": "Can I Hear Your Face? Pervasive Attack on Voice Authentication Systems with a Single Face Image.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/JiangSS024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/jiang-nan",
            "url": "https://dblp.org/rec/conf/uss/JiangSS024",
            "abstract": "We present Foice , a novel deepfake attack against voice authentication systems. Foice generates a synthetic voice of the victim from just a single image of the victim\u2019s face, without requiring any voice sample . This synthetic voice is realistic enough to fool commercial authentication systems. Since face images are generally easier to obtain than voice samples, Foice effectively makes it easier for an attacker to mount large-scale attacks. The key idea lies in learning the partial correlation between face and voice features, and adding to that a face-independent voice feature sampled from a Gaussian distribution. We demonstrate the effectiveness of Foice with a comprehensive set of real-world experiments involving ten offline participants and an online dataset of 1,029 unique individuals. By evaluating eight state-of-the-art systems, including WeChat\u2019s Voiceprint and Microsoft Azure, we show that all these systems are vulnerable to Foice attack.",
            "keywords": [
                "Voice Authentication",
                "Deepfake Attack",
                "Synthetic Voice Generation",
                "Face Image Exploitation",
                "Vulnerability Assessment"
            ]
        },
        "url": "URL#379542",
        "sema_paperId": "1de678b9138779207b8bccfa87dbb6d56f658c96"
    },
    {
        "@score": "1",
        "@id": "379543",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "82/4796-1",
                        "text": "Zhifeng Jiang 0001"
                    },
                    {
                        "@pid": "53/930",
                        "text": "Peng Ye"
                    },
                    {
                        "@pid": "318/3017",
                        "text": "Shiqi He"
                    },
                    {
                        "@pid": "35/7092-30",
                        "text": "Wei Wang 0030"
                    },
                    {
                        "@pid": "03/2050",
                        "text": "Ruichuan Chen"
                    },
                    {
                        "@pid": "50/3402-1",
                        "text": "Bo Li 0001"
                    }
                ]
            },
            "title": "Lotto: Secure Participant Selection against Adversarial Servers in Federated Learning.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/JiangYH0C024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/jiang-zhifeng",
            "url": "https://dblp.org/rec/conf/uss/JiangYH0C024",
            "abstract": "In Federated Learning (FL), common privacy-enhancing techniques, such as secure aggregation and distributed differential privacy, rely on the critical assumption of an honest majority among participants to withstand various attacks. In practice, however, servers are not always trusted, and an adversarial server can strategically select compromised clients to create a dishonest majority, thereby undermining the system's security guarantees. In this paper, we present Lotto, an FL system that addresses this fundamental, yet underexplored issue by providing secure participant selection against an adversarial server. Lotto supports two selection algorithms: random and informed. To ensure random selection without a trusted server, Lotto enables each client to autonomously determine their participation using verifiable randomness. For informed selection, which is more vulnerable to manipulation, Lotto approximates the algorithm by employing random selection within a refined client pool. Our theoretical analysis shows that Lotto effectively aligns the proportion of server-selected compromised participants with the base rate of dishonest clients in the population. Large-scale experiments further reveal that Lotto achieves time-to-accuracy performance comparable to that of insecure selection methods, indicating a low computational overhead for secure selection.",
            "keywords": [
                "Federated Learning",
                "Adversarial Server",
                "Participant Selection",
                "Secure Aggregation",
                "Compromised Clients"
            ]
        },
        "url": "URL#379543",
        "sema_paperId": "603f9c70ef1f8b37367b846cbc75dffbf7a4bb15"
    },
    {
        "@score": "1",
        "@id": "379544",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "347/1284",
                        "text": "Shuaifan Jin"
                    },
                    {
                        "@pid": "01/6368-5",
                        "text": "He Wang 0005"
                    },
                    {
                        "@pid": "31/5772-1",
                        "text": "Zhibo Wang 0001"
                    },
                    {
                        "@pid": "71/1116",
                        "text": "Feng Xiao"
                    },
                    {
                        "@pid": "132/9450",
                        "text": "Jiahui Hu"
                    },
                    {
                        "@pid": "11/1735",
                        "text": "Yuan He"
                    },
                    {
                        "@pid": "21/7628",
                        "text": "Wenwen Zhang"
                    },
                    {
                        "@pid": "139/5759",
                        "text": "Zhongjie Ba"
                    },
                    {
                        "@pid": "261/4609",
                        "text": "Weijie Fang"
                    },
                    {
                        "@pid": "364/4942",
                        "text": "Shuhong Yuan"
                    },
                    {
                        "@pid": "20/6179-1",
                        "text": "Kui Ren 0001"
                    }
                ]
            },
            "title": "FaceObfuscator: Defending Deep Learning-based Privacy Attacks with Gradient Descent-resistant Features in Face Recognition.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Jin00XHHZBFY024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/jin-shuaifan",
            "url": "https://dblp.org/rec/conf/uss/Jin00XHHZBFY024",
            "abstract": "As face recognition is widely used in various security-sensitive scenarios, face privacy issues are receiving increasing attention. Recently, many face recognition works have focused on privacy preservation and converted the original images into protected facial features. However, our study reveals that emerging Deep Learning-based (DL-based) reconstruction attacks exhibit notable ability in learning and removing the protection patterns introduced by existing schemes and recovering the original facial images, thus posing a signi\ufb01cant threat to face privacy. To address this threat, we introduce FaceObfuscator, a lightweight privacy-preserving face recognition system that \ufb01rst removes visual information that is non-crucial for face recognition from facial images via frequency domain and then generates obfuscated features interleaved in the feature space to resist gradient descent in DL-based reconstruction attacks. To minimize the loss in face recognition accuracy, obfuscated features with different identities are well-designed to be interleaved but non-duplicated in the feature space. This non-duplication ensures that FaceObfus-cator can extract identity information from the obfuscated features for accurate face recognition. Extensive experimental results demonstrate that FaceObfuscator\u2019s privacy protection capability improves around 90% compared to existing privacy-preserving methods in two major leakage scenarios including channel leakage and database leakage, with a negligible 0.3% loss in face recognition accuracy. Our approach has also been evaluated in a real-world environment and protected more than 100K people\u2019s face data of a major university.",
            "keywords": [
                "Face Recognition",
                "Privacy Preservation",
                "Deep Learning Attacks",
                "Feature Obfuscation",
                "Gradient Descent Resistance"
            ]
        },
        "url": "URL#379544",
        "sema_paperId": "1a6fabe21da3c3c9b7f38ac70aca2bf48bc80e74"
    },
    {
        "@score": "1",
        "@id": "379545",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "67/1861",
                        "text": "Di Jin"
                    },
                    {
                        "@pid": "344/1644",
                        "text": "Alexander J. Gaidis"
                    },
                    {
                        "@pid": "87/1029",
                        "text": "Vasileios P. Kemerlis"
                    }
                ]
            },
            "title": "BeeBox: Hardening BPF against Transient Execution Attacks.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/JinGK24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/jin-di",
            "url": "https://dblp.org/rec/conf/uss/JinGK24",
            "abstract": "The Berkeley Packet Filter (BPF) has emerged as the de-facto standard for carrying out safe and performant, user-specified computation(s) in kernel space. However, BPF also increases the attack surface of the OS kernel disproportionately, especially under the presence of transient execution vulnerabilities. In this work, we present BeeBox: a new security architecture that hardens BPF against transient execution attacks, allowing the OS kernel to expose eBPF functionality to unprivileged users and applications. At a high level, Bee-Box sandboxes the BPF runtime against speculative code execution in an SFI-like manner. Moreover, by using a combination of static analyses and domain-specific properties, BeeBox selectively elides enforcement checks, improving performance without sacrificing security. We implemented a prototype of BeeBox for the Linux kernel that supports popular features of eBPF (e.g., BPF maps and helper functions), and evaluated it both in terms of effectiveness and performance, demonstrating resilience against prevalent transient execution attacks (i.e., Spectre-PHT and Spectre-STL) with low overhead. On average, BeeBox incurs 20% overhead in the Katran benchmark, while the current mitigations of Linux incur 112% overhead. Lastly, BeeBox exhibits less than 1% throughput degradation in end-to-end, real-world settings that include seccomp-BPF and packet filtering.",
            "keywords": [
                "BPF Security",
                "Transient Execution Attacks",
                "Speculative Execution",
                "eBPF Hardening",
                "Performance Overhead"
            ]
        },
        "url": "URL#379545",
        "sema_paperId": "c651319c69fd427b49abf85971e26bebd059ba74"
    },
    {
        "@score": "1",
        "@id": "379546",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "157/3785",
                        "text": "Brian Johannesmeyer"
                    },
                    {
                        "@pid": "55/6285",
                        "text": "Asia Slowinska"
                    },
                    {
                        "@pid": "91/800",
                        "text": "Herbert Bos"
                    },
                    {
                        "@pid": "75/8194",
                        "text": "Cristiano Giuffrida"
                    }
                ]
            },
            "title": "Practical Data-Only Attack Generation.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/JohannesmeyerSB24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/johannesmeyer",
            "url": "https://dblp.org/rec/conf/uss/JohannesmeyerSB24",
            "abstract": "As control-\ufb02ow hijacking is getting harder due to increasingly sophisticated CFI solutions, recent work has instead focused on automatically building data-only attacks, typically using symbolic execution, simplifying assumptions that do not always match the attacker\u2019s goals, manual gadget chaining, or all of the above. As a result, the practical adoption of such methods is minimal. In this work, we abstract away unnecessary complexities and instead use a lightweight approach that targets the vulnerabilities that are both the most tractable for analysis, and the most promising for an attacker. In particular, we present E INSTEIN , a data-only attack exploitation pipeline that uses dynamic taint analysis policies to: (i) scan for chains of vulnerable system calls (e.g., to execute code or corrupt the \ufb01lesystem), and (ii) generate exploits for those that take unmodi\ufb01ed attacker data as input. E INSTEIN discovers thousands of vulnerable syscalls in common server applications\u2014well beyond the reach of existing approaches. Moreover, using nginx as a case study, we use E INSTEIN to generate 944 exploits, and we discuss two such exploits that bypass state-of-the-art mitigations.",
            "keywords": [
                "Data-Only Attacks",
                "Dynamic Taint Analysis",
                "Vulnerable System Calls",
                "Exploit Generation",
                "Control-Flow Hijacking"
            ]
        },
        "url": "URL#379546",
        "sema_paperId": "15eba960c975dd714030b72071072a334ec1ebd0"
    },
    {
        "@score": "1",
        "@id": "379547",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "241/1000",
                        "text": "Matthew Joslin"
                    },
                    {
                        "@pid": "06/2447",
                        "text": "Xian Wang"
                    },
                    {
                        "@pid": "07/6713-1",
                        "text": "Shuang Hao 0001"
                    }
                ]
            },
            "title": "Double Face: Leveraging User Intelligence to Characterize and Recognize AI-synthesized Faces.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/JoslinW024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/joslin",
            "url": "https://dblp.org/rec/conf/uss/JoslinW024",
            "abstract": "Artificial Intelligence (AI) techniques have advanced to generate face images of nonexistent yet photorealistic persons. Despite positive applications, AI-synthesized faces have been increasingly abused to deceive users and manipulate opinions, such as AI-generated profile photos for fake accounts. Deception using generated realistic-appearing images raises severe trust and security concerns. So far, techniques to analyze and recognize AI-synthesized face images are limited, mainly relying on off-the-shelf classification methods or heuristics of researchers\u2019 individual perceptions. As a complement to existing analysis techniques, we develop a novel approach that leverages crowdsourcing annotations to analyze and defend against AI-synthesized face images. We aggregate and characterize AI-synthesis artifacts annotated by multiple users (instead of by individual researchers or automated systems). Our quantitative findings systematically identify where the synthesis artifacts are likely to be located and what characteristics the synthesis patterns have. We further incorporate user annotated regions into an attention learning approach to detect AI-synthesized faces. Our work sheds light on involving human factors to enhance defense against AI-synthesized face images.",
            "keywords": [
                "AI-synthesized Faces",
                "Crowdsourcing Annotations",
                "Synthesis Artifacts",
                "User Intelligence",
                "Face Recognition"
            ]
        },
        "url": "URL#379547",
        "sema_paperId": "b50f15c27a946e390731ee1e9b10c52502ae61dd"
    },
    {
        "@score": "1",
        "@id": "379548",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "199/7713",
                        "text": "Ingab Kang"
                    },
                    {
                        "@pid": "58/3695",
                        "text": "Walter Wang"
                    },
                    {
                        "@pid": "325/3299",
                        "text": "Jason Kim 0007"
                    },
                    {
                        "@pid": "200/3206",
                        "text": "Stephan van Schaik"
                    },
                    {
                        "@pid": "221/1574",
                        "text": "Youssef Tobah"
                    },
                    {
                        "@pid": "98/8283",
                        "text": "Daniel Genkin"
                    },
                    {
                        "@pid": "176/8068",
                        "text": "Andrew Kwong"
                    },
                    {
                        "@pid": "90/10901",
                        "text": "Yuval Yarom"
                    }
                ]
            },
            "title": "SledgeHammer: Amplifying Rowhammer via Bank-level Parallelism.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KangW0STGKY24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/kang",
            "url": "https://dblp.org/rec/conf/uss/KangW0STGKY24",
            "abstract": "Rowhammer is a hardware vulnerability in DDR memory by which attackers can perform specific access patterns in their own memory to flip bits in adjacent, uncontrolled rows without accessing them. Since its discovery by Kim et. al. (ISCA 2014), Rowhammer attacks have emerged as an alarming threat to numerous security mechanisms. In this paper, we show that Rowhammer attacks can in fact be more effective when combined with bank-level parallelism, a technique in which the attacker hammers multiple memory banks simultaneously. This allows us to increase the amount of Rowhammer-induced flips 7-fold and significantly speed up prior Rowhammer attacks relying on native code execution. Furthermore, we tackle the task of mounting browser-based Rowhammer attacks. Here, we develop a self-evicting version of multi-bank hammering, allowing us to replace clflush instructions with cache evictions. We then develop a novel method for detecting contiguous physical addresses using memory access timings, thereby obviating the need for transparent huge pages. Finally, by combining both techniques, we are the first, to our knowledge, to obtain Rowhammer bit flips on DDR4 memory from the Chrome and Firefox browsers running on default Linux configurations, without enabling transparent huge pages.",
            "keywords": [
                "Rowhammer Vulnerability",
                "DDR Memory",
                "Bank-level Parallelism",
                "Browser-based Attacks",
                "Bit Flips"
            ]
        },
        "url": "URL#379548",
        "sema_paperId": "df76b1a38aabaa20592643186b178daa65052606"
    },
    {
        "@score": "1",
        "@id": "379549",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "381/1642",
                        "text": "Jonas Kaspereit"
                    },
                    {
                        "@pid": "381/1622",
                        "text": "Gurur \u00d6ndar\u00f6"
                    },
                    {
                        "@pid": "381/1583",
                        "text": "Gustavo Luvizotto Cesar"
                    },
                    {
                        "@pid": "294/8819",
                        "text": "Simon Ebbers"
                    },
                    {
                        "@pid": "224/9447",
                        "text": "Fabian Ising"
                    },
                    {
                        "@pid": "271/4882",
                        "text": "Christoph Saatjohann"
                    },
                    {
                        "@pid": "163/4064",
                        "text": "Mattijs Jonker"
                    },
                    {
                        "@pid": "42/1058",
                        "text": "Ralph Holz"
                    },
                    {
                        "@pid": "43/11495",
                        "text": "Sebastian Schinzel"
                    }
                ]
            },
            "title": "LanDscAPe: Exploring LDAP weaknesses and data leaks at Internet scale.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KaspereitOCEISJ24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/kaspereit",
            "url": "https://dblp.org/rec/conf/uss/KaspereitOCEISJ24",
            "abstract": "The Lightweight Directory Access Protocol (LDAP) is the standard technology to query information stored in directories. These directories can contain sensitive personal data such as usernames, email addresses, and passwords. LDAP is also used as a central, organization-wide storage of configuration data for other services. Hence, it is important to the security posture of many organizations, not least because it is also at the core of Microsoft's Active Directory, and other identity management and authentication services.\nWe report on a large-scale security analysis of deployed LDAP servers on the Internet. We developed LanDscAPe, a scanning tool that analyzes security-relevant misconfigurations of LDAP servers and the security of their TLS configurations. Our Internet-wide analysis revealed more than 10k servers that appear susceptible to a range of threats, including insecure configurations, deprecated software with known vulnerabilities, and insecure TLS setups. 4.9k LDAP servers host personal data, and 1.8k even leak passwords. We document, classify, and discuss these and briefly describe our notification campaign to address these concerning issues.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-kaspereit.pdf",
            "keywords": [
                "LDAP Security",
                "Data Leakage",
                "Misconfiguration",
                "TLS Vulnerabilities",
                "Personal Data Exposure"
            ]
        },
        "url": "URL#379549",
        "sema_paperId": "f493edb1a0559eedc9613adb9deced0cc75b7793"
    },
    {
        "@score": "1",
        "@id": "379550",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "353/7547",
                        "text": "Martin Kayondo"
                    },
                    {
                        "@pid": "282/0221",
                        "text": "Inyoung Bang"
                    },
                    {
                        "@pid": "381/1690",
                        "text": "Yeongjun Kwak"
                    },
                    {
                        "@pid": "119/7680",
                        "text": "Hyungon Moon"
                    },
                    {
                        "@pid": "65/3751",
                        "text": "Yunheung Paek"
                    }
                ]
            },
            "title": "MetaSafe: Compiling for Protecting Smart Pointer Metadata to Ensure Safe Rust Integrity.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KayondoBKMP24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/kayondo",
            "url": "https://dblp.org/rec/conf/uss/KayondoBKMP24",
            "abstract": "Rust is a programming language designed with a focus on memory safety. It introduces new concepts such as ownership and performs static bounds checks at compile time to ensure spatial and temporal memory safety. For memory operations or data types whose safety the compiler cannot prove at compile time, Rust either explicitly excludes such portions of the program, termed unsafe Rust, from static analysis, or it relies on runtime enforcement using smart pointers. Existing studies have shown that potential memory safety bugs in such unsafe Rust can bring down the entire program, proposing in-process isolation or compartmentalization as a remedy. However, in this study, we show that the safe Rust remains susceptible to memory safety bugs even with the proposed isolation applied. The smart pointers upon which safe Rust\u2019s memory safety is built rely on metadata often stored alongside program data, possibly within reach of attackers. Manipulating this meta-data, an attacker can nullify safe Rust\u2019s memory safety checks dependent on it, causing memory access bugs and exploitation. In response to this issue, we propose M ETA S AFE , a mechanism that safeguards smart pointer metadata from such attacks. M ETA S AFE stores smart pointer metadata in a gated memory region where only a predefined set of metadata management functions can write, ensuring that each smart pointer update does not cause safe Rust\u2019s memory safety violation. We have implemented M ETA S AFE by extending the official Rust compiler and evaluated it with a variety of micro-and application benchmarks. The overhead of M ETA S AFE is found to be low; it incurs a 3.5% average overhead on the execution time of a web browser benchmarks.",
            "keywords": [
                "Rust Programming Language",
                "Memory Safety",
                "Smart Pointer Metadata",
                "Unsafe Rust Vulnerabilities",
                "MetaSafe Mechanism"
            ]
        },
        "url": "URL#379550",
        "sema_paperId": "3aa1e1b7b29ddfa256ea38fae26e3b52a7ec6e59"
    },
    {
        "@score": "1",
        "@id": "379551",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "275/2625",
                        "text": "Rishabh Khandelwal"
                    },
                    {
                        "@pid": "318/1519",
                        "text": "Asmit Nayak"
                    },
                    {
                        "@pid": "58/5795",
                        "text": "Paul Chung"
                    },
                    {
                        "@pid": "97/535",
                        "text": "Kassem Fawaz"
                    }
                ]
            },
            "title": "Unpacking Privacy Labels: A Measurement and Developer Perspective on Google&apos;s Data Safety Section.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KhandelwalNCF24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/khandelwal",
            "url": "https://dblp.org/rec/conf/uss/KhandelwalNCF24",
            "abstract": "Google has mandated developers to use Data Safety Sections (DSS) to increase transparency in data collection and sharing practices. In this paper, we present a comprehensive analysis of Google's Data Safety Section (DSS) using both quantitative and qualitative methods. We conduct the first large-scale measurement study of DSS using apps from Android Play store (n=1.1M). We find that there are internal inconsistencies within the reported practices. We also find trends of both over and under-reporting practices in the DSSs. Next, we conduct a longitudinal study of DSS to explore how the reported practices evolve over time, and find that the developers are still adjusting their practices. To contextualize these findings, we conduct a developer study, uncovering the process that app developers undergo when working with DSS. We highlight the challenges faced and strategies employed by developers for DSS submission, and the factors contributing to changes in the DSS. Our research contributes valuable insights into the complexities of implementing and maintaining privacy labels, underlining the need for better resources, tools, and guidelines to aid developers. This understanding is crucial as the accuracy and reliability of privacy labels directly impact their effectiveness.",
            "keywords": [
                "Data Safety Section",
                "Privacy Labels",
                "App Developer Practices",
                "Data Collection Transparency",
                "Reporting Inconsistencies"
            ]
        },
        "url": "URL#379551",
        "sema_paperId": "1d75a47da5a0de1f1c66afec58e36c019c872dd1"
    },
    {
        "@score": "1",
        "@id": "379552",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "320/8636",
                        "text": "Robin Kirchner"
                    },
                    {
                        "@pid": "338/5209",
                        "text": "Jonas M\u00f6ller"
                    },
                    {
                        "@pid": "224/4374",
                        "text": "Marius Musch"
                    },
                    {
                        "@pid": "78/854-1",
                        "text": "David Klein 0001"
                    },
                    {
                        "@pid": "64/4020",
                        "text": "Konrad Rieck"
                    },
                    {
                        "@pid": "82/359",
                        "text": "Martin Johns"
                    }
                ]
            },
            "title": "Dancer in the Dark: Synthesizing and Evaluating Polyglots for Blind Cross-Site Scripting.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KirchnerMM0RJ24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/kirchner",
            "url": "https://dblp.org/rec/conf/uss/KirchnerMM0RJ24",
            "abstract": "Cross-Site Scripting (XSS) is a prevalent and well known security problem in web applications. Numerous methods to automatically analyze and detect these vulnerabilities exist. However, all of these methods require that either code or feed-back from the application is available to guide the detection process. In larger web applications, inputs can propagate from a frontend to an internal backend that provides no feedback to the outside. None of the previous approaches are applicable in this scenario, known as blind XSS (BXSS). In this paper, we address this problem and present the \ufb01rst comprehensive study on BXSS. As no feedback channel exists, we verify the presence of vulnerabilities through blind code execution. For this purpose, we develop a method for synthesizing polyglots , small XSS payloads that execute in all common injection contexts. Seven of these polyglots are already suf\ufb01cient to cover a state-of-the-art XSS testbed. In a validation on real-world client-side vulnerabilities, we show that their XSS detection rate is on par with existing taint tracking approaches. Based on these polyglots, we conduct a study of BXSS vulnerabilities on the Tranco Top 100 , 000 websites. We discover 20 vulnerabilities in 18 web-based backend systems. These \ufb01ndings demonstrate the ef\ufb01cacy of our detection approach and point at a largely unexplored attack surface in web security.",
            "keywords": [
                "Cross-Site Scripting",
                "Blind XSS",
                "Polyglots",
                "Vulnerability Detection",
                "Web Application Vulnerabilities"
            ]
        },
        "url": "URL#379552",
        "sema_paperId": "03c6a50cec74347e119393e1442f5845957f81dd"
    },
    {
        "@score": "1",
        "@id": "379553",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "250/9440",
                        "text": "David Koisser"
                    },
                    {
                        "@pid": "244/4957",
                        "text": "Richard Mitev"
                    },
                    {
                        "@pid": "133/8422",
                        "text": "Nikita Yadav"
                    },
                    {
                        "@pid": "381/1585",
                        "text": "Franziska Vollmer"
                    },
                    {
                        "@pid": "s/AhmadRezaSadeghi",
                        "text": "Ahmad-Reza Sadeghi"
                    }
                ]
            },
            "title": "Orbital Trust and Privacy: SoK on PKI and Location Privacy Challenges in Space Networks.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KoisserMYVS24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/koisser",
            "url": "https://dblp.org/rec/conf/uss/KoisserMYVS24",
            "abstract": "The dynamic evolution of the space sector, often referred to as \"New Space,\" has led to increased commercialization and innovation. This transformation is characterized by a surge in satellite numbers, the emergence of small, cost-effective satellites like CubeSats, and the development of space networks. As satellite networks play an increasingly vital role in providing essential services and supporting various activities, ensuring their security is crucial, especially concerning trust relationships among satellites and the protection of satellite service users.\nSatellite networks possess unique characteristics, such as orbital dynamics, delays, and limited bandwidth, posing challenges to trust and privacy. While prior research has explored various aspects of space network security, this paper systematically investigates two crucial yet unexplored dimensions: (i) The integrity of PKI components directly impacts the security and privacy of satellite communications and data transmission, with orbital delays and disruptions potentially hindering timely certificate revocation checks. (ii) Conversely, transmitting user signals to satellites requires careful consideration to prevent location tracking and unauthorized surveillance. By drawing on insights from terrestrial studies, we aim to provide a comprehensive understanding of these intertwined security aspects, identify research gaps, and stimulate further exploration to tackle these research challenges in the evolving domain of space network security.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-koisser.pdf",
            "keywords": [
                "Space Network Security",
                "Public Key Infrastructure (PKI)",
                "Location Privacy",
                "Satellite Communications",
                "Certificate Revocation Challenges"
            ]
        },
        "url": "URL#379553",
        "sema_paperId": "e785b371a53d2132abc1818dd9b7636082fab221"
    },
    {
        "@score": "1",
        "@id": "379554",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "332/2997",
                        "text": "Patrick Tser Jern Kon"
                    },
                    {
                        "@pid": "331/3579",
                        "text": "Sina Kamali"
                    },
                    {
                        "@pid": "381/1582",
                        "text": "Jinyu Pei"
                    },
                    {
                        "@pid": "204/5176",
                        "text": "Diogo Barradas"
                    },
                    {
                        "@pid": "59/146-1",
                        "text": "Ang Chen 0001"
                    },
                    {
                        "@pid": "57/3752",
                        "text": "Micah Sherr"
                    },
                    {
                        "@pid": "y/MotiYung",
                        "text": "Moti Yung"
                    }
                ]
            },
            "title": "SpotProxy: Rediscovering the Cloud for Censorship Circumvention.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KonKPB0SY24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/kon",
            "url": "https://dblp.org/rec/conf/uss/KonKPB0SY24",
            "abstract": "Censorship circumvention is often fueled by supporters out of goodwill. However, hosting circumvention proxies can be costly, especially when they are placed in the cloud. We argue for re-examining cloud features and leveraging them to achieve novel circumvention benefits, even though these features are not explicitly engineered for censorship circum-vention. SpotProxy is inspired by Spot VMs\u2014cloud instances backed with excess resources, sold at a fraction of the cost of regular instances, that can be taken away at a moment\u2019s notice if higher-paying requests arrive. We observe that for circum-vention proxies, Spot VMs not only translate to cost savings, but also create a high churn rate since proxies are constantly re-spawned at different IP addresses\u2014making them more difficult for a censor to enumerate and block. SpotProxy pushes this observation to the extreme and designs a circumvention infrastructure that constantly searches for cheaper VMs and refreshes the fleet for anti-blocking, for spot and regular VMs alike. We adapt Wireguard and Snowflake for use with Spot-Proxy, and demonstrate that our active migration mechanism allows clients to seamlessly move between proxies without degrading their performance or disrupting existing connections. We show that SpotProxy leads to significant cost savings, and that SpotProxy\u2019s rejuvenation mechanism enables proxies to be replenished frequently with new addresses.",
            "keywords": [
                "Censorship Circumvention",
                "Cloud Computing",
                "Spot VMs",
                "Proxy Infrastructure",
                "Cost-effective Anti-blocking"
            ]
        },
        "url": "URL#379554",
        "sema_paperId": "7f68188fd637e1bc960c94762e9d324dbe8be816"
    },
    {
        "@score": "1",
        "@id": "379555",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "272/8278",
                        "text": "Brian Kondracki"
                    },
                    {
                        "@pid": "04/8280",
                        "text": "Nick Nikiforakis"
                    }
                ]
            },
            "title": "Smudged Fingerprints: Characterizing and Improving the Performance of Web Application Fingerprinting.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KondrackiN24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/kondracki",
            "url": "https://dblp.org/rec/conf/uss/KondrackiN24",
            "abstract": "Open-source web applications have given everyone the ability to deploy complex web applications on their site(s), ranging from blogs and personal clouds, to server administration tools and webmail clients. Given that there exists millions of deployments of this software in the wild, the ability to fingerprint a particular release of a web application residing at a web endpoint is of interest to both attackers and defenders alike. In this work, we study modern web application finger-printing techniques and identify their inherent strengths and weaknesses. We design WASABO , a web application testing framework and use it to measure the performance of six web application fingerprinting tools against 1,360 releases of popular web applications. While 94.8% of all web application releases were correctly labeled by at least one fingerprinting tool in ideal conditions, many tools are unable to produce a single version prediction for a particular release. This leads to instances where a release is labeled as multiple disparate versions, resulting in administrator confusion on the security posture of an unknown web application. We also measure the accuracy of each tool against real-world deployments of the studied web applications, observing up to an 80% drop-off in performance compared to our offline results. To identify causes for this performance degradation, as well as to improve the robustness of these tools in the wild, we design a web-application-agnostic middleware which applies a series of transformations to the traffic of each fingerprinting tool. Overall, we are able to improve the performance of popular web application fingerprinting tools by up to 22.9%, without any modification to the evaluated tools.",
            "keywords": [
                "Web Application Fingerprinting",
                "Performance Evaluation",
                "Traffic Transformation",
                "Deployment Accuracy",
                "WASABO Framework"
            ]
        },
        "url": "URL#379555",
        "sema_paperId": "82e0b6458ba523dbf5946270e1841180b41f546f"
    },
    {
        "@score": "1",
        "@id": "379556",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "381/1679",
                        "text": "Anastassija Kostan"
                    },
                    {
                        "@pid": "381/1674",
                        "text": "Sara Olschar"
                    },
                    {
                        "@pid": "31/9612",
                        "text": "Lucy Simko"
                    },
                    {
                        "@pid": "132/9687",
                        "text": "Yasemin Acar"
                    }
                ]
            },
            "title": "Exploring digital security and privacy in relative poverty in Germany through qualitative interviews.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KostanOSA24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/kostan",
            "url": "https://dblp.org/rec/conf/uss/KostanOSA24",
            "abstract": "When developing security and privacy policy, technical solutions, and research for end users, assumptions about end users\u2019 financial means and technology use situations often fail to take users\u2019 income status into account. This means that the status quo may marginalize those affected by poverty in security and privacy, and exacerbate inequalities. To enable more equitable security and privacy for all, it is crucial to understand the overall situation of low income users, their security and privacy concerns, perceptions, behaviors, and challenges. In this paper, we report on a semi-structured, in-depth inter-view study with low income users living in Germany ( n = 28) which we understand as a case study for the growing number of low income users in global north countries. We find that low income end users may be literate regarding technology use and possess solid basic knowledge about security and privacy, and generally show awareness of security and privacy threats and risks. Despite these resources, we also find that low income users are driven to poor security and privacy practices like using an untrusted cloud due to little storage space, and relying on old, broken, or used hardware. Additionally we find the mindset of a\u2014potentially false\u2014sense of security and privacy because through attacking them, there is \u201cnot much to get\u201d. Based on our findings, we discuss how the security and privacy community can expand comprehension about diverse end users, increase awareness and design for the specific situation of low income users, and should take more vulnerable groups into account.",
            "keywords": [
                "Digital Security",
                "Privacy",
                "Low Income Users",
                "Qualitative Research",
                "Inequality in Technology"
            ]
        },
        "url": "URL#379556",
        "sema_paperId": "b9232a1320ed87f4d67ac05bd34dd926aa883717"
    },
    {
        "@score": "1",
        "@id": "379557",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "331/2127",
                        "text": "Torsten Krau\u00df"
                    },
                    {
                        "@pid": "295/8221",
                        "text": "Jasper Stang"
                    },
                    {
                        "@pid": "67/8264",
                        "text": "Alexandra Dmitrienko"
                    }
                ]
            },
            "title": "Verify your Labels! Trustworthy Predictions and Datasets via Confidence Scores.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KraussSD24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/kraub-verify",
            "url": "https://dblp.org/rec/conf/uss/KraussSD24",
            "abstract": "Machine learning is a rapidly evolving technology with manifold benefits. At its core lies the mapping between samples and corresponding target labels (SL-Mappings). Such mappings can originate from labeled dataset samples or from prediction generated during model inference. The correctness of SL-Mappings is crucial, both during training and for model predictions, especially when considering poisoning attacks. Existing standalone works from the dataset cleaning and prediction confidence scoring domains lack a dual-use tool offering an SL-Mappings score, which is impractical. Moreover, these works have drawbacks, e.g., dependence on specific model architectures and reliance on large datasets, which may not be accessible, or lack a meaningful confidence score. In this paper, we introduce LabelTrust, a versatile tool designed to generate confidence scores for SL-Mappings. We propose pipelines facilitating dataset cleaning and confidence scoring, mitigating the limitations of existing standalone approaches from each domain. Thereby, LabelTrust leverages a Siamese network trained via few-shot learning, requiring minimal clean samples and is agnostic to datasets and model architectures. We demonstrate LabelTrust\u2019s efficacy in detecting poisoning attacks within samples and predictions alike, with a modest one-time training overhead of 34.56 seconds and an evaluation time of less than 1 second per SL-Mapping.",
            "keywords": [
                "Confidence Scores",
                "SL-Mappings",
                "Dataset Cleaning",
                "Poisoning Attacks",
                "Few-Shot Learning"
            ]
        },
        "url": "URL#379557",
        "sema_paperId": "e59d0ccb0a50262d4b09ab74baac7919e48c3398"
    },
    {
        "@score": "1",
        "@id": "379558",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "331/2127",
                        "text": "Torsten Krau\u00df"
                    },
                    {
                        "@pid": "295/8221",
                        "text": "Jasper Stang"
                    },
                    {
                        "@pid": "67/8264",
                        "text": "Alexandra Dmitrienko"
                    }
                ]
            },
            "title": "ClearStamp: A Human-Visible and Robust Model-Ownership Proof based on Transposed Model Training.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KraussSD24a",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/kraub-clearstamp",
            "url": "https://dblp.org/rec/conf/uss/KraussSD24a",
            "abstract": "Due to costly efforts during data acquisition and model training, Deep Neural Networks (DNNs) belong to the intellectual property of the model creator. Hence, unauthorized use, theft, or modification may lead to legal repercussions. Existing DNN watermarking methods for ownership proof are often non-intuitive, embed human-invisible marks, require trust in algorithmic assessment that lacks human-understandable attributes, and rely on rigid thresholds, making it susceptible to failure in cases of partial watermark erasure. This paper introduces ClearStamp, the first DNN watermarking method designed for intuitive human assessment. ClearStamp embeds visible watermarks, enabling human decision-making without rigid value thresholds while allowing technology-assisted evaluations. ClearStamp defines a transposed model architecture allowing to use of the model in a backward fashion to interwove the watermark with the main task within all model parameters. Compared to existing watermarking methods, ClearStamp produces visual watermarks that are easy for humans to understand without requiring complex verification algorithms or strict thresholds. The watermark is embedded within all model parameters and entangled with the main task, exhibiting superior robustness. It shows an 8,544-bit watermark capacity comparable to the strongest existing work. Crucially, ClearStamp\u2019s effectiveness is model and dataset-agnostic, and resilient against adversarial model manipulations, as demonstrated in a comprehensive study performed with four datasets and seven architectures.",
            "keywords": [
                "DNN Watermarking",
                "Model Ownership Proof",
                "Visible Watermarks",
                "Transposed Model Architecture",
                "Robustness Against Manipulation"
            ]
        },
        "url": "URL#379558",
        "sema_paperId": "5fcce2dacaea5eba4229e27a8be312c041b7ab48"
    },
    {
        "@score": "1",
        "@id": "379559",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "338/4244",
                        "text": "Veena Krish"
                    },
                    {
                        "@pid": "15/10263",
                        "text": "Nicola Paoletti"
                    },
                    {
                        "@pid": "264/5120",
                        "text": "Milad Kazemi"
                    },
                    {
                        "@pid": "s/ScottASmolka",
                        "text": "Scott A. Smolka"
                    },
                    {
                        "@pid": "125/0358",
                        "text": "Amir Rahmati"
                    }
                ]
            },
            "title": "Biosignal Authentication Considered Harmful Today.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KrishPKSR24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/krish",
            "url": "https://dblp.org/rec/conf/uss/KrishPKSR24",
            "abstract": "User authentication systems based on cardiovascular biosig-nals have gained prominence in recent years, as these signals are presumed to be difficult to forge. We challenge this assumption by showing that an observer who has access to one type of cardiac data \u2013 such as a user\u2019s pulse waveform, readily obtain-able from video and commercial smartwatches \u2013 can design a spoofing attack strong enough to fool authentication systems based on other cardiovascular biosignals. We present BioForge , an approach that leverages a cycle-consistent generative adversarial network to synthesize realistic physiological signals for a given user without relying on simultaneously collected supervision data. We evaluate BioForge on multiple open-access datasets and an array of verification systems, many of which can be fooled over 50% of the time in 10 or fewer attempts. No-tably, we are able to fool systems that rely not just on heart rate and peak locations but also on the morphology of the wave-forms. We additionally showcase how BioForge can be used to spoof authentication systems from biosignal data extracted from video clips of a target user. Our work demonstrates that authentication systems should not rely on the secrecy of cardiovascular biosignals.",
            "keywords": [
                "Biosignal Authentication",
                "Cardiovascular Signals",
                "Spoofing Attacks",
                "Generative Adversarial Networks",
                "BioForge"
            ]
        },
        "url": "URL#379559",
        "sema_paperId": "02d1ac02f34ac109084ad4a625e751b8989245cf"
    },
    {
        "@score": "1",
        "@id": "379560",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "124/3795",
                        "text": "Kavita Kumari"
                    },
                    {
                        "@pid": "344/3222",
                        "text": "Alessandro Pegoraro"
                    },
                    {
                        "@pid": "151/8708",
                        "text": "Hossein Fereidooni"
                    },
                    {
                        "@pid": "s/AhmadRezaSadeghi",
                        "text": "Ahmad-Reza Sadeghi"
                    }
                ]
            },
            "title": "Xplain: Analyzing Invisible Correlations in Model Explanation.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KumariPFS24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/kumari",
            "url": "https://dblp.org/rec/conf/uss/KumariPFS24",
            "abstract": "Explanation methods analyze the features in backdoored input data that contribute to model misclassification. However, current methods like path techniques struggle to detect backdoor patterns in adversarial situations. They fail to grasp the hidden associations of backdoor features with other input features, leading to misclassification. Additionally, they suffer from irrelevant data attribution, imprecise feature connections, baseline dependence, and vulnerability to the \"saturation effect\".\nTo address these limitations, we propose Xplain. Our method aims to uncover hidden backdoor trigger patterns and the subtle relationships between backdoor features and other input objects, which are the main causes of model misclassification. Our algorithm improves existing path techniques by integrating an additional baseline into the Integrated Gradients (IG) formulation. This ensures that features selected in the baseline persist along the integration path, guaranteeing baseline independence. Additionally, we introduce quantitative noise to interpolate samples along the integration path, which reduces feature dependency and captures non-linear interactions. This approach effectively identifies the relevant features that significantly influence model predictions.\nFurthermore, Xplain proposes sensitivity analysis to enhance AI system resilience against backdoor attacks. This uncovers clear connections between the backdoor and other input data features, thus shedding light on relevant interactions. We thoroughly test the effectiveness of Xplain on the Imagenet and the multimodal domain of the Visual Question Answering dataset, showing its superiority over current path methods such as Integrated Gradient (IG), left-IG, Guided IG, and Adversarial Gradient Integration (AGI) techniques.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-kumari.pdf",
            "keywords": [
                "Backdoor Detection",
                "Model Misclassification",
                "Feature Attribution",
                "Integrated Gradients",
                "Sensitivity Analysis"
            ]
        },
        "url": "URL#379560",
        "sema_paperId": "026209b4e419a36f1c2ea8ea3c2f1f1203d900fd"
    },
    {
        "@score": "1",
        "@id": "379561",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "220/3453",
                        "text": "Lukas Lamster"
                    },
                    {
                        "@pid": "326/0603",
                        "text": "Martin Unterguggenberger"
                    },
                    {
                        "@pid": "272/7215",
                        "text": "David Schrammel"
                    },
                    {
                        "@pid": "91/4831",
                        "text": "Stefan Mangard"
                    }
                ]
            },
            "title": "Voodoo: Memory Tagging, Authenticated Encryption, and Error Correction through MAGIC.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LamsterUSM24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/lamster",
            "url": "https://dblp.org/rec/conf/uss/LamsterUSM24",
            "abstract": "Con\ufb01dentiality, authenticity, integrity of data, and runtime security are ubiquitous concerns in modern computer systems. However, these security concerns have traditionally been addressed by separate mechanisms. Error-correcting codes (ECC) detect and correct DRAM errors, ensuring the integrity of stored data. Authenticated memory encryption provides data con\ufb01dentiality and authenticity. Memory tagging enforces memory safety, thereby improving runtime security. The lack of a combined primitive increases system complexity, memory overheads, and the overall performance impact. In this work, we present Voodoo , the \ufb01rst combined scheme for authenticated encryption, DRAM error correction, and memory tagging. Our design extends the MAGIC mode for authenticated encryption and error correction proposed by Kounavis et al. [31]. With Voodoo , DRAM data is encrypted, and a tag-dependent message authentication code protects the integrity of the stored data while simultaneously allowing for the correction of DRAM faults. Thus, we can implement a wide range of tagged memory architectures without introducing additional memory requests or storage overheads . We present three tag encoding schemes providing up to 36 tag bits per cache line. Using the gem5 simulator, we implement and benchmark our design. Our evaluation shows a low runtime overhead of 1 . 4% on average compared to a system without any of the provided security features. We use a Monte-Carlo simulation of a DRAM fault model based on real-world DRAM fault behavior to demonstrate the corrective capabilities of Voodoo . Our results show that we consistently outperform traditional single-error correction, double-error detection (SEC-DED) codes in terms of error correction and detection. For multi-chip faults, Voodoo offers stronger error detection than commodity Chipkill solutions.",
            "keywords": [
                "Authenticated Encryption",
                "Error Correction",
                "Memory Tagging",
                "DRAM Fault Tolerance",
                "MAGIC Mode"
            ]
        },
        "url": "URL#379561",
        "sema_paperId": "c7824b90cca5d8ef8d614a4938886a051263910e"
    },
    {
        "@score": "1",
        "@id": "379563",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "301/5833",
                        "text": "Leona Lassak"
                    },
                    {
                        "@pid": "236/2322",
                        "text": "Elleen Pan"
                    },
                    {
                        "@pid": "66/9786",
                        "text": "Blase Ur"
                    },
                    {
                        "@pid": "177/0313",
                        "text": "Maximilian Golla"
                    }
                ]
            },
            "title": "Why Aren&apos;t We Using Passkeys? Obstacles Companies Face Deploying FIDO2 Passwordless Authentication.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LassakPUG24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/lassak",
            "url": "https://dblp.org/rec/conf/uss/LassakPUG24",
            "abstract": "When adopted by the W3C in 2019, the FIDO2 standard for passwordless authentication was touted as a replacement for passwords on the web. With FIDO2, users leverage passkeys (cryptographic credentials) to authenticate to websites. Even though major operating systems now support passkeys, compatible hardware is now widely available, and some major companies now offer passwordless options, both the deployment and adoption have been slow. As FIDO2 has many security and usability advantages over passwords, we investigate what obstacles hinder companies from large-scale deployment of passwordless authentication. We conducted 28 semi-structured interviews with chief information security officers (CISOs) and authentication managers from both companies that have and have not deployed passwordless authentication, as well as FIDO2 experts. Our results shed light on the current state of deployment and perception. We highlight key barriers to adoption, including account recovery, friction, technical issues, regulatory requirements, and security culture. From the obstacles identified, we make recommendations for increasing the adoption of passwordless authentication.",
            "keywords": [
                "FIDO2",
                "Passwordless Authentication",
                "Passkeys",
                "Deployment Barriers",
                "Security Culture"
            ]
        },
        "url": "URL#379563",
        "sema_paperId": "f87468f520c764c1d836236273b5422ae43595bc"
    },
    {
        "@score": "1",
        "@id": "379564",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "259/8738",
                        "text": "Seth Layton"
                    },
                    {
                        "@pid": "335/5811",
                        "text": "Tyler Tucker"
                    },
                    {
                        "@pid": "320/8828",
                        "text": "Daniel Olszewski"
                    },
                    {
                        "@pid": "250/9724",
                        "text": "Kevin Warren"
                    },
                    {
                        "@pid": "82/1935",
                        "text": "Kevin R. B. Butler"
                    },
                    {
                        "@pid": "14/3295",
                        "text": "Patrick Traynor"
                    }
                ]
            },
            "title": "SoK: The Good, The Bad, and The Unbalanced: Measuring Structural Limitations of Deepfake Media Datasets.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LaytonTOWBT24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/layton",
            "url": "https://dblp.org/rec/conf/uss/LaytonTOWBT24",
            "abstract": "Deepfake media represents an important and growing threat not only to computing systems but to society at large. Datasets of image, video, and voice deepfakes are being created to assist researchers in building strong defenses against these emerging threats. However, despite the growing number of datasets and the relative diversity of their samples, little guidance exists to help researchers select datasets and then mean-ingfully contrast their results against prior e \ufb00 orts. To assist in this process, this paper presents the \ufb01rst systematization of deepfake media. Using traditional anomaly detection datasets as a baseline, we characterize the metrics, generation techniques, and class distributions of existing datasets. Through this process, we discover signi\ufb01cant problems impacting the comparability of systems using these datasets, including unaccounted-for heavy class imbalance and reliance upon limited metrics. These observations have a potentially profound impact should such systems be transitioned to practice - as an example, we demonstrate that the widely-viewed best detector applied to a typical call center scenario would result in only 1 out of 333 \ufb02agged results being a true positive. To improve reproducibility and future comparisons, we provide a template for reporting results in this space and advocate for the release of model score \ufb01les such that a wider range of statistics can easily be found and / or calculated. Through this, and our recommendations for improving dataset construction, we provide important steps to move this community forward.",
            "keywords": [
                "Deepfake Media",
                "Dataset Evaluation",
                "Class Imbalance",
                "Anomaly Detection",
                "Reproducibility in Research"
            ]
        },
        "url": "URL#379564",
        "sema_paperId": "a8904791c9cd70444af0e68753374c845818e33d"
    },
    {
        "@score": "1",
        "@id": "379565",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "329/5777",
                        "text": "Arthur Lazzaretti"
                    },
                    {
                        "@pid": "p/CharalamposPapamanthou",
                        "text": "Charalampos Papamanthou"
                    }
                ]
            },
            "title": "Single Pass Client-Preprocessing Private Information Retrieval.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LazzarettiP24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/lazzaretti",
            "url": "https://dblp.org/rec/conf/uss/LazzarettiP24",
            "abstract": "Recently, many works have considered Private Information Retrieval (PIR) with client-preprocessing: In this model a client and a server jointly run a preprocessing phase, after which client queries run in time sublinear in the database size. However, the preprocessing phase is expensive\u2014proportional to \u03bb N, where \u03bb is the security parameter (e.g., \u03bb=128).\nIn this paper we propose SinglePass, the first PIR protocol that is concretely optimal with respect to client-preprocessing, requiring exactly a single linear pass over the database. Our approach yields a preprocessing speedup ranging from 45\u00d7 to 100\u00d7 and a query speedup of up to 20\u00d7 when compared to previous state-of-the-art schemes (e.g., Checklist, USENIX SECURITY 2021, making preprocessing PIR more attractive for a myriad of use cases that are \"session-based\".\nIn addition to practical preprocessing, SinglePass features constant-time updates (additions/edits). Previously, the best known approach for handling updates in client-preprocessing PIR had complexity OlogN, while also adding a logN factor to the bandwidth. We implement our update algorithm and show concrete speedups of about 20\u00d7 over previous state-of-the-art updatable schemes (e.g., Checklist).",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-lazzaretti.pdf",
            "keywords": [
                "Private Information Retrieval",
                "Client-Preprocessing",
                "Database Access",
                "Preprocessing Efficiency",
                "Constant-Time Updates"
            ]
        },
        "url": "URL#379565"
    },
    {
        "@score": "1",
        "@id": "379566",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "83/2787",
                        "text": "Tung Le"
                    },
                    {
                        "@pid": "118/0026",
                        "text": "Rouzbeh Behnia"
                    },
                    {
                        "@pid": "51/3023",
                        "text": "Jorge Guajardo"
                    },
                    {
                        "@pid": "132/2690",
                        "text": "Thang Hoang"
                    }
                ]
            },
            "title": "MUSES: Efficient Multi-User Searchable Encrypted Database.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LeBGH24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/le",
            "url": "https://dblp.org/rec/conf/uss/LeBGH24",
            "abstract": "Searchable encrypted systems enable privacy-preserving keyword search on encrypted data. Symmetric systems achieve high efficiency (e.g., sublinear search), but they mostly support single-user search. Although systems based on public-key or hybrid models support multi-user search, they incur inherent security weaknesses (e.g., keyword-guessing vulnerabilities) and scalability limitations due to costly public-key operations (e.g., pairing). More importantly, most encrypted search designs leak statistical information (e.g., search, result, and volume patterns) and thus are vulnerable to devastating leakage-abuse attacks. Some pattern-hiding schemes were proposed. However, they incur significant user bandwidth/computation costs, and thus are not desirable for large-scale outsourced databases with resource-constrained users.\nIn this paper, we propose MUSES, a new multi-user encrypted search platform that addresses the functionality, security, and performance limitations in the existing encrypted search designs. Specifically, MUSES permits multi-user functionalities (reader/writer separation, permission revocation) and hides all statistical information (including search, result, and volume patterns) while featuring minimal user overhead. In MUSES, we demonstrate a unique incorporation of various emerging distributed cryptographic protocols including Distributed Point Function, Distributed PRF, and Oblivious Linear Group Action. We also introduce novel distributed protocols for oblivious counting and shuffling on arithmetic shares for the general multi-party setting with a dishonest majority, which can be found useful in other applications. Our experimental results showed that the keyword search by MUSES is two orders of magnitude faster with up to 12\u00d7 lower user bandwidth cost than the state-of-the-art.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-le.pdf",
            "keywords": [
                "Searchable Encryption",
                "Multi-User Systems",
                "Statistical Information Leakage",
                "Distributed Cryptographic Protocols",
                "User Bandwidth Efficiency"
            ]
        },
        "url": "URL#379566"
    },
    {
        "@score": "1",
        "@id": "379567",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "205/5938",
                        "text": "Hao-Ping (Hank) Lee"
                    },
                    {
                        "@pid": "55/5352",
                        "text": "Lan Gao"
                    },
                    {
                        "@pid": "305/9447",
                        "text": "Stephanie S. Yang"
                    },
                    {
                        "@pid": "46/4227",
                        "text": "Jodi Forlizzi"
                    },
                    {
                        "@pid": "83/8570",
                        "text": "Sauvik Das"
                    }
                ]
            },
            "title": "&quot;I Don&apos;t Know If We&apos;re Doing Good. I Don&apos;t Know If We&apos;re Doing Bad&quot;: Investigating How Practitioners Scope, Motivate, and Conduct Privacy Work When Developing AI Products.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LeeGYFD24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/lee",
            "url": "https://dblp.org/rec/conf/uss/LeeGYFD24",
            "abstract": "How do practitioners who develop consumer AI products scope, motivate, and conduct privacy work? Respecting privacy is a key principle for developing ethical, human-centered AI systems, but we cannot hope to better support practitioners without answers to that question. We interviewed 35 industry AI practitioners to bridge that gap. We found that practitioners viewed privacy as actions taken against pre-defined intrusions that can be exacerbated by the capabilities and requirements of AI, but few were aware of AI-specific privacy intrusions documented in prior literature. We found that their privacy work was rigidly defined and situated, guided by compliance with privacy regulations and policies, and generally demoti-vated beyond meeting minimum requirements. Finally, we found that the methods, tools, and resources they used in their privacy work generally did not help address the unique privacy risks introduced or exacerbated by their use of AI in their products. Collectively, these findings reveal the need and opportunity to create tools, resources, and support structures to improve practitioners\u2019 awareness of AI-specific privacy risks, motivations to do AI privacy work, and ability to address privacy harms introduced or exacerbated by their use of AI in consumer products.",
            "keywords": [
                "AI Privacy Practices",
                "Consumer AI Products",
                "Privacy Compliance",
                "Privacy Risks",
                "Motivation for Privacy Work"
            ]
        },
        "url": "URL#379567",
        "sema_paperId": "270e70d8944f95ecf44e6ba7129449bd83871897"
    },
    {
        "@score": "1",
        "@id": "379568",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "284/4365",
                        "text": "Chongqing Lei"
                    },
                    {
                        "@pid": "79/7563",
                        "text": "Zhen Ling"
                    },
                    {
                        "@pid": "47/722-25",
                        "text": "Yue Zhang 0025"
                    },
                    {
                        "@pid": "37/1091",
                        "text": "Yan Yang"
                    },
                    {
                        "@pid": "l/JunzhouLuo",
                        "text": "Junzhou Luo"
                    },
                    {
                        "@pid": "49/2189",
                        "text": "Xinwen Fu"
                    }
                ]
            },
            "title": "A Friend&apos;s Eye is A Good Mirror: Synthesizing MCU Peripheral Models from Peripheral Drivers.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LeiLZYLF24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/lei",
            "url": "https://dblp.org/rec/conf/uss/LeiLZYLF24",
            "abstract": "The extensive integration of embedded devices within the Internet of Things (IoT) has given rise to significant security concerns. Various initiatives have been undertaken to bolster the security of these devices at the software level, involving the analysis of MCU firmware and the implementation of automatic MCU rehosting methods. However, existing hardware-oriented rehosting techniques often face scalability challenges, while firmware-oriented approaches may have limited universality and fidelity. To address these limitations, we propose P ERRY , a system that synthesizes faithful and extendable peripheral models for MCUs. By extracting peripheral models from hardware drivers, P ERRY ensures compatibility and accurate emulation of targeted MCUs. The process involves gathering hardware metadata, analyzing driver code, capturing traces of peripheral accesses, and converting software beliefs into hardware behaviors. P ERRY is implemented with approximately 19,000 lines of code. A comprehensive evaluation of 75 firmware samples has show-cased its effectiveness, consistency, universality, and scalability in generating hardware models for MCUs. P ERRY can efficiently synthesize hardware models consistent with the actual hardware and achieve a 74.24% unit test passing rate, outperforming the state-of-the-art techniques. The hardware models produced by P ERRY can faithfully emulate diverse firmware and can be readily expanded with minimal manual intervention. Through case studies, we show that P ERRY can help reproduce firmware vulnerabilities, discover specification-violation bugs in drivers, and fuzz RTOS for vulnerabilities. These case studies have led to the identification",
            "keywords": [
                "Embedded Systems",
                "Peripheral Modeling",
                "MCU Rehosting",
                "Firmware Analysis",
                "Driver Code Synthesis"
            ]
        },
        "url": "URL#379568",
        "sema_paperId": "b98dedf0d0807bf7c5f5975b401d2703e1b7b347"
    },
    {
        "@score": "1",
        "@id": "379569",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "207/6590",
                        "text": "Julia Len"
                    },
                    {
                        "@pid": "06/1661",
                        "text": "Melissa Chase"
                    },
                    {
                        "@pid": "48/9365",
                        "text": "Esha Ghosh"
                    },
                    {
                        "@pid": "146/7941",
                        "text": "Kim Laine"
                    },
                    {
                        "@pid": "300/9872",
                        "text": "Radames Cruz Moreno"
                    }
                ]
            },
            "title": "OPTIKS: An Optimized Key Transparency System.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LenCGLM24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/len",
            "url": "https://dblp.org/rec/conf/uss/LenCGLM24",
            "abstract": "Key Transparency (KT) refers to a public key distribution system with transparency mechanisms proving its correct operation, i.e., proving that it reports consistent values for each user's public key. While prior work on KT systems have offered new designs to tackle this problem, relatively little attention has been paid on the issue of scalability. Indeed, it is not straightforward to actually build a scalable and practical KT system from existing constructions, which may be too complex, inefficient, or non-resilient against machine failures.\nIn this paper, we present OPTIKS, a full featured and optimized KT system that focuses on scalability. Our system is simpler and more performant than prior work, supporting smaller storage overhead while still meeting strong notions of security and privacy. Our design also incorporates a crash-tolerant and scalable server architecture, which we demonstrate by presenting extensive benchmarks. Finally, we address several real-world problems in deploying KT systems that have received limited attention in prior work, including account decommissioning and user-to-device mapping.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-len.pdf",
            "keywords": [
                "Key Transparency",
                "Scalability",
                "Public Key Distribution",
                "Crash-Tolerant Architecture",
                "Account Decommissioning"
            ]
        },
        "url": "URL#379569"
    },
    {
        "@score": "1",
        "@id": "379570",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "209/9793",
                        "text": "Matan Levi"
                    },
                    {
                        "@pid": "20/10289",
                        "text": "Aryeh Kontorovich"
                    }
                ]
            },
            "title": "Splitting the Difference on Adversarial Training.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LeviK24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/levi",
            "url": "https://dblp.org/rec/conf/uss/LeviK24",
            "abstract": "The existence of adversarial examples points to a basic weakness of deep neural networks. One of the most effective defenses against such examples, adversarial training, entails training models with some degree of robustness, usually at the expense of a degraded natural accuracy. Most adversarial training methods aim to learn a model that finds, for each class, a common decision boundary encompassing both the clean and perturbed examples. In this work, we take a fundamentally different approach by treating the perturbed examples of each class as a separate class to be learned, effectively splitting each class into two classes:\"clean\"and\"adversarial.\"This split doubles the number of classes to be learned, but at the same time considerably simplifies the decision boundaries. We provide a theoretical plausibility argument that sheds some light on the conditions under which our approach can be expected to be beneficial. Likewise, we empirically demonstrate that our method learns robust models while attaining optimal or near-optimal natural accuracy, e.g., on CIFAR-10 we obtain near-optimal natural accuracy of $95.01\\%$ alongside significant robustness across multiple tasks. The ability to achieve such near-optimal natural accuracy, while maintaining a significant level of robustness, makes our method applicable to real-world applications where natural accuracy is at a premium. As a whole, our main contribution is a general method that confers a significant level of robustness upon classifiers with only minor or negligible degradation of their natural accuracy.",
            "keywords": [
                "Adversarial Training",
                "Robustness",
                "Decision Boundaries",
                "Natural Accuracy",
                "Adversarial Examples"
            ]
        },
        "url": "URL#379570",
        "sema_paperId": "39f6c84bbb20d848c48ff33ec5c1b31acd3407ba"
    },
    {
        "@score": "1",
        "@id": "379572",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "361/7589",
                        "text": "Kecen Li"
                    },
                    {
                        "@pid": "21/8587-5",
                        "text": "Chen Gong 0005"
                    },
                    {
                        "@pid": "48/2029",
                        "text": "Zhixiang Li"
                    },
                    {
                        "@pid": "42/8750",
                        "text": "Yuzhong Zhao"
                    },
                    {
                        "@pid": "76/5119",
                        "text": "Xinwen Hou"
                    },
                    {
                        "@pid": "145/3288-1",
                        "text": "Tianhao Wang 0001"
                    }
                ]
            },
            "title": "PrivImage: Differentially Private Synthetic Image Generation using Diffusion Models with Semantic-Aware Pretraining.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Li0LZH024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/li-kecen",
            "url": "https://dblp.org/rec/conf/uss/Li0LZH024",
            "abstract": "Differential Privacy (DP) image data synthesis, which leverages the DP technique to generate synthetic data to replace the sensitive data, allowing organizations to share and utilize synthetic images without privacy concerns. Previous methods incorporate the advanced techniques of generative models and pre-training on a public dataset to produce exceptional DP image data, but suffer from problems of unstable training and massive computational resource demands. This paper proposes a novel DP image synthesis method, termed PRIVIMAGE, which meticulously selects pre-training data, promoting the efficient creation of DP datasets with high fidelity and utility. PRIVIMAGE first establishes a semantic query function using a public dataset. Then, this function assists in querying the semantic distribution of the sensitive dataset, facilitating the selection of data from the public dataset with analogous semantics for pre-training. Finally, we pre-train an image generative model using the selected data and then fine-tune this model on the sensitive dataset using Differentially Private Stochastic Gradient Descent (DP-SGD). PRIVIMAGE allows us to train a lightly parameterized generative model, reducing the noise in the gradient during DP-SGD training and enhancing training stability. Extensive experiments demonstrate that PRIVIMAGE uses only 1% of the public dataset for pre-training and 7.6% of the parameters in the generative model compared to the state-of-the-art method, whereas achieves superior synthetic performance and conserves more computational resources. On average, PRIVIMAGE achieves 30.1% lower FID and 12.6% higher Classification Accuracy than the state-of-the-art method. The replication package and datasets can be accessed online.",
            "keywords": [
                "Differential Privacy",
                "Synthetic Image Generation",
                "Diffusion Models",
                "Semantic-Aware Pretraining",
                "Training Stability"
            ]
        },
        "url": "URL#379572",
        "sema_paperId": "e1dbf7ce3dcf707da231f8b2159cd22c70e3a7b1"
    },
    {
        "@score": "1",
        "@id": "379573",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "150/1609",
                        "text": "Tuo Li"
                    },
                    {
                        "@pid": "161/7805",
                        "text": "Jia-Ju Bai"
                    },
                    {
                        "@pid": "381/1574",
                        "text": "Gui-Dong Han"
                    },
                    {
                        "@pid": "h/ShiMinHu",
                        "text": "Shi-Min Hu 0001"
                    }
                ]
            },
            "title": "LR-Miner: Static Race Detection in OS Kernels by Mining Locking Rules.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiBH024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/li-tuo",
            "url": "https://dblp.org/rec/conf/uss/LiBH024",
            "abstract": "Data race is one of the most common concurrency issues in OS kernels, and it can cause severe problems like system crashes and privilege escalation. Therefore, detecting kernel races is important and necessary. A critical step of kernel race detection is to identify locking rules that which variable should be protected by which lock. However, due to insuf\ufb01-cient documents of kernel concurrency, it is challenging to identify accurate locking rules, causing existing approaches to produce many false results in kernel race detection. In this paper, we design a new static analysis approach named LR-Miner, to effectively detect data races in OS kernels by mining locking rules from kernel code. LR-Miner consists of three key techniques: (1) a \ufb01eld-aware mining method that constructs and statistically analyzes the structure \ufb01eld relation between locks and accessed variables, to mine accurate locking rules from kernel code; (2) an alias-aware checking method to detect data races that violate the mined locking rules; (3) a pattern-based estimation strategy to estimate the security impact of the found races and identify harmful ones. We have evaluated LR-Miner on two popular OS kernels including Linux and FreeBSD, and it \ufb01nds 306 real races with a false positive rate of 19.9%. Among these found races, 200 are estimated to be harmful, and 61 of them have been con\ufb01rmed by kernel developers. 10 harmful races have been assigned with CVE IDs.",
            "keywords": [
                "OS Kernel Concurrency",
                "Data Race Detection",
                "Locking Rules",
                "Static Analysis",
                "Kernel Vulnerabilities"
            ]
        },
        "url": "URL#379573",
        "sema_paperId": "03dda84b9f755a51d61046978f482e453a73d97c"
    },
    {
        "@score": "1",
        "@id": "379574",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "119/2630",
                        "text": "Songze Li"
                    },
                    {
                        "@pid": "321/6323",
                        "text": "Yanbo Dai"
                    }
                ]
            },
            "title": "BackdoorIndicator: Leveraging OOD Data for Proactive Backdoor Detection in Federated Learning.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiD24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/li-songze",
            "url": "https://dblp.org/rec/conf/uss/LiD24",
            "abstract": "In a federated learning (FL) system, decentralized data owners (clients) could upload their locally trained models to a central server, to jointly train a global model. Malicious clients may plant backdoors into the global model through uploading poisoned local models, causing misclassification to a target class when encountering attacker-defined triggers. Existing backdoor defenses show inconsistent performance under different system and adversarial settings, especially when the malicious updates are made statistically close to the benign ones. In this paper, we first reveal the fact that planting subsequent backdoors with the same target label could significantly help to maintain the accuracy of previously planted backdoors, and then propose a novel proactive backdoor detection mechanism for FL named BackdoorIndicator, which has the server inject indicator tasks into the global model leveraging out-of-distribution (OOD) data, and then utilizing the fact that any backdoor samples are OOD samples with respect to benign samples, the server, who is completely agnostic of the potential backdoor types and target labels, can accurately detect the presence of backdoors in uploaded models, via evaluating the indicator tasks. We perform systematic and extensive empirical studies to demonstrate the consistently superior performance and practicality of BackdoorIndicator over baseline defenses, across a wide range of system and adversarial settings.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-li-songze.pdf",
            "keywords": [
                "Federated Learning",
                "Backdoor Attack",
                "Proactive Detection",
                "Out-of-Distribution Data",
                "Model Poisoning"
            ]
        },
        "url": "URL#379574"
    },
    {
        "@score": "1",
        "@id": "379575",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "178/6410",
                        "text": "Yuexin Li"
                    },
                    {
                        "@pid": "116/8609-3",
                        "text": "Chengyu Huang 0003"
                    },
                    {
                        "@pid": "213/1853",
                        "text": "Shumin Deng"
                    },
                    {
                        "@pid": "371/8839",
                        "text": "Mei Lin Lock"
                    },
                    {
                        "@pid": "217/3502",
                        "text": "Tri Cao"
                    },
                    {
                        "@pid": "59/8759",
                        "text": "Nay Oo"
                    },
                    {
                        "@pid": "l/HWLim",
                        "text": "Hoon Wei Lim"
                    },
                    {
                        "@pid": "169/9975",
                        "text": "Bryan Hooi"
                    }
                ]
            },
            "title": "KnowPhish: Large Language Models Meet Multimodal Knowledge Graphs for Enhancing Reference-Based Phishing Detection.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiHDLCOLH24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/li-yuexin",
            "url": "https://dblp.org/rec/conf/uss/LiHDLCOLH24",
            "abstract": "Phishing attacks have inflicted substantial losses on individuals and businesses alike, necessitating the development of robust and efficient automated phishing detection approaches. Reference-based phishing detectors (RBPDs), which compare the logos on a target webpage to a known set of logos, have emerged as the state-of-the-art approach. However, a major limitation of existing RBPDs is that they rely on a manually constructed brand knowledge base, making it infeasible to scale to a large number of brands, which results in false negative errors due to the insufficient brand coverage of the knowledge base. To address this issue, we propose an automated knowledge collection pipeline, using which we collect a large-scale multimodal brand knowledge base, KnowPhish, containing 20k brands with rich information about each brand. KnowPhish can be used to boost the performance of existing RBPDs in a plug-and-play manner. A second limitation of existing RBPDs is that they solely rely on the image modality, ignoring useful textual information present in the webpage HTML. To utilize this textual information, we propose a Large Language Model (LLM)-based approach to extract brand information of webpages from text. Our resulting multimodal phishing detection approach, KnowPhish Detector (KPD), can detect phishing webpages with or without logos. We evaluate KnowPhish and KPD on a manually validated dataset, and a field study under Singapore's local context, showing substantial improvements in effectiveness and efficiency compared to state-of-the-art baselines.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-li-yuexin.pdf",
            "keywords": [
                "Phishing Detection",
                "Reference-Based Phishing Detectors",
                "Brand Knowledge Base",
                "Multimodal Approach",
                "Large Language Model (LLM)"
            ]
        },
        "url": "URL#379575"
    },
    {
        "@score": "1",
        "@id": "379576",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "18/5576",
                        "text": "Jiacheng Li"
                    },
                    {
                        "@pid": "l/NinghuiLi",
                        "text": "Ninghui Li"
                    },
                    {
                        "@pid": "15/606",
                        "text": "Bruno Ribeiro 0001"
                    }
                ]
            },
            "title": "MIST: Defending Against Membership Inference Attacks Through Membership-Invariant Subspace Training.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiL024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/li-jiacheng",
            "url": "https://dblp.org/rec/conf/uss/LiL024",
            "abstract": "In Member Inference (MI) attacks, the adversary try to determine whether an instance is used to train a machine learning (ML) model. MI attacks are a major privacy concern when using private data to train ML models. Most MI attacks in the literature take advantage of the fact that ML models are trained to fit the training data well, and thus have very low loss on training instances. Most defenses against MI attacks therefore try to make the model fit the training data less well. Doing so, however, generally results in lower accuracy.\nWe observe that training instances have different degrees of vulnerability to MI attacks. Most instances will have low loss even when not included in training. For these instances, the model can fit them well without concerns of MI attacks. An effective defense only needs to (possibly implicitly) identify instances that are vulnerable to MI attacks and avoids overfitting them. A major challenge is how to achieve such an effect in an efficient training process.\nLeveraging two distinct recent advancements in representation learning: counterfactually-invariant representations and subspace learning methods, we introduce a novel Membership-Invariant Subspace Training (MIST) method to defend against MI attacks. MIST avoids overfitting the vulnerable instances without significant impact on other instances. We have conducted extensive experimental studies, comparing MIST with various other state-of-the-art (SOTA) MI defenses against several SOTA MI attacks. We find that MIST outperforms other defenses while resulting in minimal reduction in testing accuracy.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-li-jiacheng.pdf",
            "keywords": [
                "Membership Inference Attacks",
                "Privacy Preservation",
                "Overfitting Defense",
                "Representation Learning",
                "Membership-Invariant Subspace Training (MIST)"
            ]
        },
        "url": "URL#379576"
    },
    {
        "@score": "1",
        "@id": "379577",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "12/3242",
                        "text": "Jiawei Li"
                    },
                    {
                        "@pid": "09/193",
                        "text": "Jian Mao"
                    },
                    {
                        "@pid": "04/1346",
                        "text": "Jun Zeng"
                    },
                    {
                        "@pid": "243/3828",
                        "text": "Qixiao Lin"
                    },
                    {
                        "@pid": "381/1593",
                        "text": "Shaowen Feng"
                    },
                    {
                        "@pid": "99/4951",
                        "text": "Zhenkai Liang"
                    }
                ]
            },
            "title": "UIHash: Detecting Similar Android UIs through Grid-Based Visual Appearance Representation.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiMZLFL24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/li-jiawei",
            "url": "https://dblp.org/rec/conf/uss/LiMZLFL24",
            "abstract": "User interfaces (UIs) is the main channel for users to interact with mobile apps. As such, attackers often create similar-looking UIs to deceive users, causing various security problems, such as spoofing and phishing. Prior studies identify these similar UIs based on their layout trees or screenshot images. These techniques, however, are susceptible to being evaded. Guided by how users perceive UIs and the features they prioritize, we design a novel grid-based UI representation to capture UI visual appearance while maintaining robustness against evasion. We develop an approach, UIH ASH , to detect similar Android UIs by comparing their visual appearance. It divides the UI into a #-shaped grid and abstracts UI controls across screen regions, then calculates UI similarity through a neural network architecture that includes a convolutional neural network and a Siamese network. Our evaluation shows that UIH ASH achieves an F1-score of 0.984 in detection, outperforming existing tree-based methods and image-based methods. Moreover, we have discovered evasion techniques that circumvent existing detection approaches.",
            "keywords": [
                "Android UI Detection",
                "Visual Appearance Representation",
                "UI Similarity Detection",
                "Evasion Techniques",
                "Spoofing and Phishing"
            ]
        },
        "url": "URL#379577",
        "sema_paperId": "b4816037111282e7600d580f6139019bf8858f46"
    },
    {
        "@score": "1",
        "@id": "379578",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "216/3218",
                        "text": "Changjiang Li"
                    },
                    {
                        "@pid": "252/5223",
                        "text": "Ren Pang"
                    },
                    {
                        "@pid": "334/3881",
                        "text": "Bochuan Cao"
                    },
                    {
                        "@pid": "224/9296",
                        "text": "Zhaohan Xi"
                    },
                    {
                        "@pid": "67/5633",
                        "text": "Jinghui Chen"
                    },
                    {
                        "@pid": "07/8388",
                        "text": "Shouling Ji"
                    },
                    {
                        "@pid": "12/2633-6",
                        "text": "Ting Wang 0006"
                    }
                ]
            },
            "title": "On the Difficulty of Defending Contrastive Learning against Backdoor Attacks.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiPCXCJ024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/li-changjiang",
            "url": "https://dblp.org/rec/conf/uss/LiPCXCJ024",
            "abstract": "Recent studies have shown that contrastive learning, like supervised learning, is highly vulnerable to backdoor attacks wherein malicious functions are injected into target models, only to be activated by specific triggers. However, thus far it remains under-explored how contrastive backdoor attacks fundamentally differ from their supervised counterparts, which impedes the development of effective defenses against the emerging threat. This work represents a solid step toward answering this critical question. Specifically, we define TRL, a unified framework that encompasses both supervised and contrastive backdoor attacks. Through the lens of TRL, we uncover that the two types of attacks operate through distinctive mechanisms: in supervised attacks, the learning of benign and backdoor tasks tends to occur independently, while in contrastive attacks, the two tasks are deeply intertwined both in their representations and throughout their learning processes. This distinction leads to the disparate learning dynamics and feature distributions of supervised and contrastive attacks. More importantly, we reveal that the specificities of contrastive backdoor attacks entail important implications from a defense perspective: existing defenses for supervised attacks are often inadequate and not easily retrofitted to contrastive attacks. We also explore several alternative defenses and discuss their potential challenges. Our findings highlight the need for defenses tailored to the specificities of contrastive backdoor attacks, pointing to promising directions for future research.",
            "keywords": [
                "Contrastive Learning",
                "Backdoor Attacks",
                "Defenses",
                "Learning Dynamics",
                "Feature Distributions"
            ]
        },
        "url": "URL#379578",
        "sema_paperId": "6a9b8b414c1aa02dab91daf9a626fa00d79332ca"
    },
    {
        "@score": "1",
        "@id": "379579",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "15/8202",
                        "text": "Shaofeng Li"
                    },
                    {
                        "@pid": "68/1277-4",
                        "text": "Xinyu Wang 0004"
                    },
                    {
                        "@pid": "166/1912",
                        "text": "Minhui Xue 0001"
                    },
                    {
                        "@pid": "22/5702",
                        "text": "Haojin Zhu"
                    },
                    {
                        "@pid": "36/5594-1",
                        "text": "Zhi Zhang 0001"
                    },
                    {
                        "@pid": "139/1152-1",
                        "text": "Yansong Gao 0001"
                    },
                    {
                        "@pid": "92/382-3",
                        "text": "Wen Wu 0003"
                    },
                    {
                        "@pid": "s/XueminShen",
                        "text": "Xuemin (Sherman) Shen"
                    }
                ]
            },
            "title": "Yes, One-Bit-Flip Matters! Universal DNN Model Inference Depletion with Runtime Code Fault Injection.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiWXZZG0S24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/li-shaofeng",
            "url": "https://dblp.org/rec/conf/uss/LiWXZZG0S24",
            "abstract": "We propose, FrameFlip, a novel attack for depleting DNN model inference with runtime code fault injections. Notably, FrameFlip operates independently of the DNN models deployed and succeeds with only a single bit-flip injection. This fundamentally distinguishes it from the existing DNN inference depletion paradigm that requires injecting tens of deterministic faults concurrently. Since our attack performs at the universal code or library level, the mandatory code snippet can be perversely called by all mainstream machine learning frameworks, such as PyTorch and TensorFlow, dependent on the library code. Using DRAM Rowhammer to facilitate end-to-end fault injection, we implement FrameFlip across diverse model architectures (LeNet, VGG-16, ResNet-34 and ResNet-50) with different datasets (FMNIST, CIFAR-10, GT-SRB, and ImageNet). With a single bit flipping, FrameFlip achieves high depletion efficacy that consistently renders the model inference utility as no better than guessing. We also experimentally verify that identified vulnerable bits are almost equally effective at depleting different deployed models. In contrast, transferability is unattainable for all existing state-of-the-art model inference depletion attacks. FrameFlip is shown to be evasive against all known defenses, generally due to the nature of current defenses operating at the model level (which is model-dependent) in lieu of the underlying code level.",
            "keywords": [
                "Runtime Code Fault Injection",
                "DNN Model Inference Depletion",
                "Single Bit-Flip Attack",
                "Transferability of Attacks",
                "Evasion of Defenses"
            ]
        },
        "url": "URL#379579",
        "sema_paperId": "ee3049484dc227be47e201b5e18102e3233b8750"
    },
    {
        "@score": "1",
        "@id": "379580",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "37/2019",
                        "text": "Luyi Li"
                    },
                    {
                        "@pid": "352/6508",
                        "text": "Hosein Yavarzadeh"
                    },
                    {
                        "@pid": "t/DeanMTullsen",
                        "text": "Dean M. Tullsen"
                    }
                ]
            },
            "title": "Indirector: High-Precision Branch Target Injection Attacks Exploiting the Indirect Branch Predictor.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiYT24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/li-luyi",
            "url": "https://dblp.org/rec/conf/uss/LiYT24",
            "abstract": "This paper introduces novel high-precision Branch Target Injection (BTI) attacks, leveraging the intricate structures of the Indirect Branch Predictor (IBP) and the Branch Target Buffer (BTB) in high-end Intel CPUs. It presents, for the first time, a comprehensive picture of the IBP and the BTB within the most recent Intel processors, revealing their size, structure, and the precise functions governing index and tag hashing. Additionally, this study reveals new details into the inner workings of Intel\u2019s hardware defenses, such as IBPB, IBRS, and STIBP, including previously unknown holes in their coverage. Leveraging insights from reverse engineering efforts, this research develops highly precise Branch Target Injection (BTI) attacks to breach security boundaries across diverse scenarios, including cross-process and cross-privilege scenarios and uses the IBP and the BTB to break Address Space Layout Randomization (ASLR).",
            "keywords": [
                "Branch Target Injection",
                "Indirect Branch Predictor",
                "Intel CPUs",
                "Security Vulnerabilities",
                "Address Space Layout Randomization (ASLR)"
            ]
        },
        "url": "URL#379580",
        "sema_paperId": "817969e6b5da97398adc50a2bd3d0f8da306dbd3"
    },
    {
        "@score": "1",
        "@id": "379581",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "227/2961-1",
                        "text": "Zilong Lin 0001"
                    },
                    {
                        "@pid": "41/5360",
                        "text": "Jian Cui"
                    },
                    {
                        "@pid": "129/1113",
                        "text": "Xiaojing Liao"
                    },
                    {
                        "@pid": "06/6268",
                        "text": "XiaoFeng Wang 0001"
                    }
                ]
            },
            "title": "Malla: Demystifying Real-world Large Language Model Integrated Malicious Services.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LinCL024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/lin-zilong",
            "url": "https://dblp.org/rec/conf/uss/LinCL024",
            "abstract": "The underground exploitation of large language models (LLMs) for malicious services (i.e., Malla) is witnessing an uptick, amplifying the cyber threat landscape and posing questions about the trustworthiness of LLM technologies. However, there has been little effort to understand this new cybercrime, in terms of its magnitude, impact, and techniques. In this paper, we conduct the first systematic study on 212 real-world Mallas, uncovering their proliferation in underground marketplaces and exposing their operational modalities. Our study discloses the Malla ecosystem, revealing its significant growth and impact on today's public LLM services. Through examining 212 Mallas, we uncovered eight backend LLMs used by Mallas, along with 182 prompts that circumvent the protective measures of public LLM APIs. We further demystify the tactics employed by Mallas, including the abuse of uncensored LLMs and the exploitation of public LLM APIs through jailbreak prompts. Our findings enable a better understanding of the real-world exploitation of LLMs by cybercriminals, offering insights into strategies to counteract this cybercrime.",
            "keywords": [
                "Large Language Models",
                "Cybercrime",
                "Malicious Services",
                "Underground Marketplaces",
                "Exploitation Techniques"
            ]
        },
        "url": "URL#379581",
        "sema_paperId": "97d4813d0fd37000a440d295ac6afad623234fcf"
    },
    {
        "@score": "1",
        "@id": "379582",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "09/1958",
                        "text": "Ziyu Lin"
                    },
                    {
                        "@pid": "98/9309",
                        "text": "Zhiwei Lin"
                    },
                    {
                        "@pid": "134/3945",
                        "text": "Ximeng Liu"
                    },
                    {
                        "@pid": "20/1036-5",
                        "text": "Jianjun Chen 0005"
                    },
                    {
                        "@pid": "234/0112",
                        "text": "Run Guo"
                    },
                    {
                        "@pid": "10/217",
                        "text": "Cheng Chen"
                    },
                    {
                        "@pid": "381/1601",
                        "text": "Shaodong Xiao"
                    }
                ]
            },
            "title": "CDN Cannon: Exploiting CDN Back-to-Origin Strategies for Amplification Attacks.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LinLL0GCX24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/lin-ziyu",
            "url": "https://dblp.org/rec/conf/uss/LinLL0GCX24",
            "abstract": "Content Delivery Networks (CDNs) provide high availability, speed up content delivery, and safeguard against DDoS attacks for their hosting websites. To achieve the aforementioned objectives, CDN designs several back-to-origin strategies that proactively pre-pull resources and modify HTTP requests and responses. However, our research reveals that these back-to-origin strategies prioritize performance over security, which can lead to excessive consumption of the website\u2019s bandwidth. We have proposed a new class of amplification attacks called Back-to-Origin Amplification ( BtOAmp ) Attacks. These attacks allow malicious attackers to exploit the back-to-origin strategies, triggering the CDN to greed-ily demand more-than-necessary resources from websites, which finally blows the websites. We evaluated the feasibility and real-world impacts of BtOAmp attacks on fourteen popular CDNs. With real-world threat evaluation, our attack threatens all mainstream websites hosted on CDNs. We responsibly disclosed the details of our attack to the affected CDN vendors and proposed possible mitigation solutions.",
            "keywords": [
                "Content Delivery Networks",
                "Back-to-Origin Strategies",
                "Amplification Attacks",
                "BtOAmp Attacks",
                "Bandwidth Consumption"
            ]
        },
        "url": "URL#379582",
        "sema_paperId": "bd8e90b41341f1507eb99788555e75450f7da382"
    },
    {
        "@score": "1",
        "@id": "379583",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "277/7909",
                        "text": "Zhenpeng Lin"
                    },
                    {
                        "@pid": "28/4466",
                        "text": "Zheng Yu"
                    },
                    {
                        "@pid": "161/5675",
                        "text": "Ziyi Guo"
                    },
                    {
                        "@pid": "39/2917",
                        "text": "Simone Campanoni"
                    },
                    {
                        "@pid": "95/2040",
                        "text": "Peter A. Dinda"
                    },
                    {
                        "@pid": "40/6431",
                        "text": "Xinyu Xing"
                    }
                ]
            },
            "title": "CAMP: Compiler and Allocator-based Heap Memory Protection.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LinYGCDX24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/lin-zhenpeng",
            "url": "https://dblp.org/rec/conf/uss/LinYGCDX24",
            "abstract": "The heap is a critical and widely used component of many applications. Due to its dynamic nature, combined with the complexity of heap management algorithms, it is also a frequent target for security exploits. To enhance the heap's security, various heap protection techniques have been introduced, but they either introduce significant runtime overhead or have limited protection. We present CAMP, a new sanitizer for detecting and capturing heap memory corruption. CAMP leverages a compiler and a customized memory allocator. The compiler adds boundary-checking and escape-tracking instructions to the target program, while the memory allocator tracks memory ranges, coordinates with the instrumentation, and neutralizes dangling pointers. With the novel error detection scheme, CAMP enables various compiler optimization strategies and thus eliminates redundant and unnecessary check instrumentation. This design minimizes runtime overhead without sacrificing security guarantees. Our evaluation and comparison of CAMP with existing tools, using both real-world applications and SPEC CPU benchmarks, show that it provides even better heap corruption detection capability with lower runtime overhead.",
            "keywords": [
                "Heap Memory Protection",
                "Memory Corruption",
                "Compiler Instrumentation",
                "Memory Allocator",
                "Runtime Overhead"
            ]
        },
        "url": "URL#379583",
        "sema_paperId": "9602301f9692c7bff5f9af606bb4cd03f32a48a8"
    },
    {
        "@score": "1",
        "@id": "379584",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "381/1579",
                        "text": "Christian Lindenmeier"
                    },
                    {
                        "@pid": "31/1273",
                        "text": "Mathias Payer"
                    },
                    {
                        "@pid": "204/4058",
                        "text": "Marcel Busch"
                    }
                ]
            },
            "title": "EL3XIR: Fuzzing COTS Secure Monitors.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LindenmeierPB24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/lindenmeier",
            "url": "https://dblp.org/rec/conf/uss/LindenmeierPB24",
            "abstract": "ARM TrustZone forms the security backbone of mobile devices. TrustZone-based Trusted Execution Environments (TEEs) facilitate security-sensitive tasks like user authentication, disk encryption, and digital rights management (DRM). As such, bugs in the TEE software stack may compromise the entire system\u2019s integrity. EL3XIR introduces a framework to effectively rehost and fuzz the secure monitor firmware layer of proprietary TrustZone-based TEEs. While other approaches have focused on naively rehosting or fuzzing Trusted Applications (EL0) or the TEE OS (EL1), EL3XIR targets the highly-privileged but unexplored secure monitor (EL3) and its unique challenges. Secure monitors expose complex functionality dependent on multiple peripherals through diverse secure monitor calls. In our evaluation, we demonstrate that state-of-the-art fuzzing approaches are insufficient to effectively fuzz COTS secure monitors. While naive fuzzing appears to achieve reasonable coverage it fails to overcome coverage walls due to missing peripheral emulation and is limited in the capability to trigger bugs due to the large input space and low quality of inputs. We followed responsible disclosure procedures and reported a total of 34 bugs, out of which 17 were classified as security critical. Affected vendors confirmed 14 of these bugs, and as a result, EL3XIR was assigned six CVEs.",
            "keywords": [
                "Trusted Execution Environments",
                "Secure Monitor",
                "Fuzzing",
                "Bug Detection",
                "ARM TrustZone"
            ]
        },
        "url": "URL#379584",
        "sema_paperId": "35e3c5be7f667def59e9efcb3cc02b60b4d761a1"
    },
    {
        "@score": "1",
        "@id": "379585",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "240/2099",
                        "text": "Felix Linker"
                    },
                    {
                        "@pid": "b/DavidABasin",
                        "text": "David A. Basin"
                    }
                ]
            },
            "title": "SOAP: A Social Authentication Protocol.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LinkerB24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/linker",
            "url": "https://dblp.org/rec/conf/uss/LinkerB24",
            "abstract": "Social authentication has been suggested as a usable authentication ceremony to replace manual key authentication in messaging applications. Using social authentication, chat partners authenticate their peers using digital identities managed by identity providers. In this paper, we formally define social authentication, present a protocol called SOAP that largely automates social authentication, formally prove SOAP's security, and demonstrate SOAP's practicality in two prototypes. One prototype is web-based, and the other is implemented in the open-source Signal messaging application. Using SOAP, users can significantly raise the bar for compromising their messaging accounts. In contrast to the default security provided by messaging applications such as Signal and WhatsApp, attackers must compromise both the messaging account and all identity provider-managed identities to attack a victim. In addition to its security and automation, SOAP is straightforward to adopt as it is built on top of the well-established OpenID Connect protocol.",
            "keywords": [
                "Social Authentication",
                "Messaging Applications",
                "Identity Providers",
                "Authentication Protocol",
                "SOAP Protocol"
            ]
        },
        "url": "URL#379585",
        "sema_paperId": "33d7f62305797a4562b553778532200ec61e1d7b"
    },
    {
        "@score": "1",
        "@id": "379586",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "381/1623",
                        "text": "Tomasz Piotr Lisowski"
                    },
                    {
                        "@pid": "241/1466",
                        "text": "Merlin Chlosta"
                    },
                    {
                        "@pid": "142/2186",
                        "text": "Jinjin Wang"
                    },
                    {
                        "@pid": "185/2352",
                        "text": "Marius Muench"
                    }
                ]
            },
            "title": "SIMurai: Slicing Through the Complexity of SIM Card Security Research.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LisowskiCWM24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/lisowski",
            "url": "https://dblp.org/rec/conf/uss/LisowskiCWM24",
            "abstract": "SIM cards are widely regarded as trusted entities within mobile networks. But what if they were not trustworthy? In this paper, we argue that malicious SIM cards are a realistic threat, and demonstrate that they can launch impactful attacks against mobile devices and their basebands.\nWe design and implement SIMURAI, a software platform for security-focused SIM exploration and experimentation. At its core, SIMURAI features a flexible software implementation of a SIM. In contrast to existing SIM research tooling that typically involves physical SIM cards, SIMURAI adds flexibility by enabling deliberate violation of application-level and transmission-level behavior\u2014a valuable asset for further exploration of SIM features and attack capabilities.\nWe integrate the platform into common cellular security test beds, demonstrating that smartphones can successfully connect to mobile networks using our software SIM. Additionally, we integrate SIMURAI with emulated baseband firmwares and carry out a fuzzing campaign that leads to the discovery of two high-severity vulnerabilities on recent flagship smartphones. We also demonstrate how rogue carriers and attackers with physical access can trigger these vulnerabilities with ease, emphasizing the need to recognize hostile SIMs in cellular security threat models.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-lisowski.pdf",
            "keywords": [
                "SIM Card Security",
                "Malicious SIM Threats",
                "Mobile Device Vulnerabilities",
                "Fuzzing Campaign",
                "Cellular Security Threat Models"
            ]
        },
        "url": "URL#379586",
        "sema_paperId": "49327c41ceadc89ab2d04c3df413dd1bdd517c7c"
    },
    {
        "@score": "1",
        "@id": "379587",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "379/1331",
                        "text": "Ryan Little"
                    },
                    {
                        "@pid": "221/4628",
                        "text": "Lucy Qin"
                    },
                    {
                        "@pid": "59/6288",
                        "text": "Mayank Varia"
                    }
                ]
            },
            "title": "Secure Account Recovery for a Privacy-Preserving Web Service.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LittleQV24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/little",
            "url": "https://dblp.org/rec/conf/uss/LittleQV24",
            "abstract": "If a web service is so secure that it does not even know\u2014and does not want to know\u2014the identity and contact info of its users, can it still offer account recovery if a user forgets their password? This paper is the culmination of the authors' work to design a cryptographic protocol for account recovery for use by a prominent secure matching system: a web-based service that allows survivors of sexual misconduct to become aware of other survivors harmed by the same perpetrator. In such a system, the list of account-holders must be safeguarded, even against the service provider itself.\nIn this work, we design an account recovery system that, on the surface, appears to follow the typical workflow: the user types in their email address, receives an email containing a one-time link, and answers some security questions. Behind the scenes, the defining feature of our recovery system is that the service provider can perform email-based account validation without knowing, or being able to learn, a list of users' email addresses. Our construction uses standardized cryptography for most components, and it has been deployed in production at the secure matching system.\nAs a building block toward our main construction, we design a new cryptographic primitive that may be of independent interest: an oblivious pseudorandom function that can either have a fully-private input or a partially-public input, and that reaches the same output either way. This primitive allows us to perform online rate limiting for account recovery attempts, without imposing a bound on the creation of new accounts. We provide an open-source implementation of this primitive and provide evaluation results showing that the end-to-end interaction time takes 8.4-60.4 ms in fully-private input mode and 3.1-41.2 ms in partially-public input mode.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-little.pdf",
            "keywords": [
                "Cryptographic Protocols",
                "Account Recovery",
                "Privacy-Preserving Systems",
                "Oblivious Pseudorandom Function",
                "Email-Based Validation"
            ]
        },
        "url": "URL#379587"
    },
    {
        "@score": "1",
        "@id": "379588",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "253/1172",
                        "text": "Dongli Liu"
                    },
                    {
                        "@pid": "35/7092-88",
                        "text": "Wei Wang 0088"
                    },
                    {
                        "@pid": "84/586-3",
                        "text": "Peng Xu 0003"
                    },
                    {
                        "@pid": "y/LaurenceTianruoYang",
                        "text": "Laurence T. Yang"
                    },
                    {
                        "@pid": "71/2890",
                        "text": "Bo Luo"
                    },
                    {
                        "@pid": "126/6037",
                        "text": "Kaitai Liang"
                    }
                ]
            },
            "title": "d-DSE: Distinct Dynamic Searchable Encryption Resisting Volume Leakage in Encrypted Databases.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Liu00YLL24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/liu-dongli",
            "url": "https://dblp.org/rec/conf/uss/Liu00YLL24",
            "abstract": "Dynamic Searchable Encryption (DSE) has emerged as a solution to efficiently handle and protect large-scale data storage in encrypted databases (EDBs). Volume leakage poses a significant threat, as it enables adversaries to reconstruct search queries and potentially compromise the security and privacy of data. Padding strategies are common countermeasures for the leakage, but they significantly increase storage and communication costs. In this work, we develop a new perspective to handle volume leakage. We start with distinct search and further explore a new concept called \\textit{distinct} DSE (\\textit{d}-DSE). We also define new security notions, in particular Distinct with Volume-Hiding security, as well as forward and backward privacy, for the new concept. Based on \\textit{d}-DSE, we construct the \\textit{d}-DSE designed EDB with related constructions for distinct keyword (d-KW-\\textit{d}DSE), keyword (KW-\\textit{d}DSE), and join queries (JOIN-\\textit{d}DSE) and update queries in encrypted databases. We instantiate a concrete scheme \\textsf{BF-SRE}, employing Symmetric Revocable Encryption. We conduct extensive experiments on real-world datasets, such as Crime, Wikipedia, and Enron, for performance evaluation. The results demonstrate that our scheme is practical in data search and with comparable computational performance to the SOTA DSE scheme (\\textsf{MITRA}*, \\textsf{AURA}) and padding strategies (\\textsf{SEAL}, \\textsf{ShieldDB}). Furthermore, our proposal sharply reduces the communication cost as compared to padding strategies, with roughly 6.36 to 53.14x advantage for search queries.",
            "keywords": [
                "Dynamic Searchable Encryption",
                "Encrypted Databases",
                "Volume Leakage",
                "Distinct Dynamic Searchable Encryption",
                "Communication Cost Reduction"
            ]
        },
        "url": "URL#379588",
        "sema_paperId": "cd5ff9aa8be1dde3d81d0120de4aef4b23bc702e"
    },
    {
        "@score": "1",
        "@id": "379589",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "55/6956",
                        "text": "Yijing Liu"
                    },
                    {
                        "@pid": "76/5416-9",
                        "text": "Yiming Zhang 0009"
                    },
                    {
                        "@pid": "89/10754",
                        "text": "Baojun Liu"
                    },
                    {
                        "@pid": "36/5143",
                        "text": "Haixin Duan"
                    },
                    {
                        "@pid": "72/872",
                        "text": "Qiang Li"
                    },
                    {
                        "@pid": "253/7461",
                        "text": "Mingxuan Liu"
                    },
                    {
                        "@pid": "364/5622",
                        "text": "Ruixuan Li 0008"
                    },
                    {
                        "@pid": "94/3514",
                        "text": "Jia Yao"
                    }
                ]
            },
            "title": "Tickets or Privacy? Understand the Ecosystem of Chinese Ticket Grabbing Apps.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Liu0LDLL0Y24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/liu-yijing",
            "url": "https://dblp.org/rec/conf/uss/Liu0LDLL0Y24",
            "abstract": "Due to the prevalence of scalping and the promotion of real-name ticketing systems, user-oriented mobile ticket grabbing apps have become a popular pattern for scalpers. Compared with traditional scalper-oriented scalping, ticket grabbing apps pose security and privacy risks to users directly. In our study, we take the \ufb01rst step towards revealing the ticket grabbing app ecosystem from the perspectives of app developers, app users, and target platforms synthetically. We built a large-scale dataset of ticket grabbing apps in the wild within China, containing 758 Chinese ticket grabbing apps with 3,121 versions. Based on the detailed analysis of these apps, we found that ticket grabbing has formed a mature industrial chain, with various specialized technical characteristics to enhance the success rate, such as the abuse of Android accessibility services. We also revealed the pro\ufb01t model of ticket grabbing apps, and disclosed severe security and privacy hazards they pose to end users, including the collection of sensitive information and continuous screenshots. We further conducted an online survey involving 184 participants to get users\u2019 usage and privacy concerns on ticket grabbing apps, and regrettably found that users prioritize \u201ctickets\u201d over \u201cpri-vacy\u201d. Finally, we proposed an \u201cIndirect Combat\u201d approach to assist in the defense mechanisms. In summary, our \ufb01ndings provide target platforms and users with a better understanding of the ticket grabbing app ecosystem in China, enabling them to better detect and combat these apps.",
            "keywords": [
                "Ticket Grabbing Apps",
                "Scalping Ecosystem",
                "User Privacy",
                "Security Risks",
                "Real-name Ticketing"
            ]
        },
        "url": "URL#379589",
        "sema_paperId": "c97ec9b8a0a44e7a7c5d50d4e063b98d72a22d1d"
    },
    {
        "@score": "1",
        "@id": "379590",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "301/5834",
                        "text": "Ruofan Liu"
                    },
                    {
                        "@pid": "77/1513-1",
                        "text": "Yun Lin 0001"
                    },
                    {
                        "@pid": "381/1686",
                        "text": "Xiwen Teoh"
                    },
                    {
                        "@pid": "02/2134",
                        "text": "Gongshen Liu"
                    },
                    {
                        "@pid": "181/2754",
                        "text": "Zhiyong Huang"
                    },
                    {
                        "@pid": "33/6517",
                        "text": "Jin Song Dong"
                    }
                ]
            },
            "title": "Less Defined Knowledge and More True Alarms: Reference-based Phishing Detection without a Pre-defined Reference List.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Liu0TLHD24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/liu-ruofan",
            "url": "https://dblp.org/rec/conf/uss/Liu0TLHD24",
            "abstract": "Phishing, a pervasive form of social engineering attack that compromises user credentials, has led to significant financial losses and undermined public trust. Modern phishing detection has gravitated to reference-based methods for their explainability and robustness against zero-day phishing attacks. These methods maintain and update predefined reference lists to specify domain-brand relationships, alarming phishing websites by the inconsistencies between its domain (e.g., payp0l.com) and intended brand (e.g., PayPal). However, the curated lists are largely limited by their lack of compre-hensiveness and high maintenance costs in practice. In this work, we present PhishLLM as a novel reference-based phishing detector that operates without an explicit pre-defined reference list. Our rationale lies in that modern LLMs have encoded far more extensive brand-domain information than any predefined list. Further, the detection of many web-page semantics such as credential-taking intention analysis is more like a linguistic problem, but they are processed as a vision problem now. Thus, we design PhishLLM to decode (or retrieve) the domain-brand relationships from LLM and effectively parse the credential-taking intention of a web-page, without the cost of maintaining and updating an explicit reference list. Moreover, to control the hallucination of LLMs, we introduce a search-engine-based validation mechanism to remove the misinformation. Our extensive experiments show that PhishLLM significantly outperforms state-of-the-art solutions such as Phishpedia and PhishIntention, improving the recall by 21% to 66%, at the cost of negligible precision. Our field studies show that PhishLLM discovers (1) 6 times more zero-day phishing webpages compared to existing approaches such as PhishIntention and (2) close to 2 times more zero-day phishing webpages even if it is enhanced by DynaPhish. Our code is available at https://github.com/code-philia/PhishLLM/ .",
            "keywords": [
                "Phishing Detection",
                "Reference-based Methods",
                "Credential-taking Intention",
                "Zero-day Phishing",
                "Domain-brand Relationships"
            ]
        },
        "url": "URL#379590",
        "sema_paperId": "0ad7e17948fa76033a38355468516fb29ca7fe0e"
    },
    {
        "@score": "1",
        "@id": "379591",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "88/2562",
                        "text": "Shigang Liu"
                    },
                    {
                        "@pid": "75/5028",
                        "text": "Di Cao"
                    },
                    {
                        "@pid": "89/5420",
                        "text": "Junae Kim"
                    },
                    {
                        "@pid": "97/1631",
                        "text": "Tamas Abraham"
                    },
                    {
                        "@pid": "50/805",
                        "text": "Paul Montague"
                    },
                    {
                        "@pid": "55/3548",
                        "text": "Seyit Camtepe"
                    },
                    {
                        "@pid": "z/JunZhang10",
                        "text": "Jun Zhang 0010"
                    },
                    {
                        "@pid": "50/2192-1",
                        "text": "Yang Xiang 0001"
                    }
                ]
            },
            "title": "EaTVul: ChatGPT-based Evasion Attack Against Software Vulnerability Detection.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiuCKAMC0024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/liu-shigang",
            "url": "https://dblp.org/rec/conf/uss/LiuCKAMC0024",
            "abstract": "Recently, deep learning has demonstrated promising results in enhancing the accuracy of vulnerability detection and identifying vulnerabilities in software. However, these techniques are still vulnerable to attacks. Adversarial examples can exploit vulnerabilities within deep neural networks, posing a significant threat to system security. This study showcases the susceptibility of deep learning models to adversarial attacks, which can achieve 100% attack success rate. The proposed method, EaTVul, encompasses six stages: identification of important adversarial samples using support vector machines, identification of important features using the attention mechanism, generation of adversarial data based on these features, preparation of an adversarial attack pool, selection of seed data using a fuzzy genetic algorithm, and the execution of an evasion attack. Extensive experiments demonstrate the effectiveness of EaTVul, achieving an attack success rate of more than 83% when the snippet size is greater than 2. Furthermore, in most cases with a snippet size of 4, EaTVul achieves a 100% attack success rate. The findings of this research emphasize the necessity of robust defenses against adversarial attacks in software vulnerability detection.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-liu-shigang.pdf",
            "keywords": [
                "Adversarial Attacks",
                "Vulnerability Detection",
                "Deep Learning Models",
                "Evasion Attack",
                "EaTVul"
            ]
        },
        "url": "URL#379591"
    },
    {
        "@score": "1",
        "@id": "379592",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "37/3887",
                        "text": "Mingyi Liu"
                    },
                    {
                        "@pid": "58/3207",
                        "text": "Jun Ho Huh"
                    },
                    {
                        "@pid": "207/6588",
                        "text": "HyungSeok Han"
                    },
                    {
                        "@pid": "127/7890",
                        "text": "Jaehyuk Lee"
                    },
                    {
                        "@pid": "380/6306",
                        "text": "Jihae Ahn"
                    },
                    {
                        "@pid": "53/10825",
                        "text": "Frank Li 0001"
                    },
                    {
                        "@pid": "64/5383",
                        "text": "Hyoungshick Kim"
                    },
                    {
                        "@pid": "38/8882",
                        "text": "Taesoo Kim"
                    }
                ]
            },
            "title": "I Experienced More than 10 DeFi Scams: On DeFi Users&apos; Perception of Security Breaches and Countermeasures.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiuHHLALKK24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/liu-mingyi",
            "url": "https://dblp.org/rec/conf/uss/LiuHHLALKK24",
            "abstract": "Decentralized Finance (DeFi) offers a whole new investment experience and has quickly emerged as an enticing alternative to Centralized Finance (CeFi). Rapidly growing market size and active users, however, have also made DeFi a lucrative target for scams and hacks, with 1.95 billion USD lost in 2023. Unfortunately, no prior research thoroughly investigates DeFi users' security risk awareness levels and the adequacy of their risk mitigation strategies. Based on a semi-structured interview study (N = 14) and a follow-up survey (N = 493), this paper investigates DeFi users' security perceptions and commonly adopted practices, and how those affected by previous scams or hacks (DeFi victims) respond and try to recover their losses. Our analysis shows that users often prefer DeFi over CeFi due to their decentralized nature and strong profitability. Despite being aware that DeFi, compared to CeFi, is prone to more severe attacks, users are willing to take those risks to explore new investment opportunities. Worryingly, most victims do not learn from previous experiences; unlike victims studied through traditional systems, DeFi victims tend to find new services, without revising their security practices, to recover their losses quickly. The abundance of various DeFi services and opportunities allows victims to continuously explore new financial opportunities, and this reality seems to cloud their security priorities. Indeed, our results indicate that DeFi users' strong financial motivations outweigh their security concerns - much like those who are addicted to gambling. Our observations about victims' post-incident behaviors suggest that stronger control in the form of industry regulations would be necessary to protect DeFi users from future breaches.",
            "keywords": [
                "Decentralized Finance (DeFi)",
                "Security Breaches",
                "User Perception",
                "Risk Mitigation",
                "DeFi Scams"
            ]
        },
        "url": "URL#379592",
        "sema_paperId": "6ea6aa8ba9c4ec851b5bd4e4c38dccdb5cf302fd"
    },
    {
        "@score": "1",
        "@id": "379593",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "204/1178",
                        "text": "Yupei Liu"
                    },
                    {
                        "@pid": "359/3184",
                        "text": "Yuqi Jia"
                    },
                    {
                        "@pid": "359/3325",
                        "text": "Runpeng Geng"
                    },
                    {
                        "@pid": "24/5124-1",
                        "text": "Jinyuan Jia 0001"
                    },
                    {
                        "@pid": "03/9437",
                        "text": "Neil Zhenqiang Gong"
                    }
                ]
            },
            "title": "Formalizing and Benchmarking Prompt Injection Attacks and Defenses.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiuJGJG24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/liu-yupei",
            "url": "https://dblp.org/rec/conf/uss/LiuJGJG24",
            "abstract": "A prompt injection attack aims to inject malicious instruction/data into the input of an LLM-Integrated Application such that it produces results as an attacker desires. Existing works are limited to case studies. As a result, the literature lacks a systematic understanding of prompt injection attacks and their defenses. We aim to bridge the gap in this work. In particular, we propose a framework to formalize prompt injection attacks. Existing attacks are special cases in our framework. Moreover, based on our framework, we design a new attack by combining existing ones. Using our framework, we conduct a systematic evaluation on 5 prompt injection attacks and 10 defenses with 10 LLMs and 7 tasks. Our work provides a common benchmark for quantitatively evaluating future prompt injection attacks and defenses. To facilitate research on this topic, we make our platform public at https://github.com/liu00222/Open-Prompt-Injection.",
            "keywords": [
                "Prompt Injection Attacks",
                "Large Language Models",
                "Attack Framework",
                "Defense Mechanisms",
                "Benchmarking Evaluation"
            ]
        },
        "url": "URL#379593",
        "sema_paperId": "9adddfe5a596d20b534a29d9937efcd3cb85d3cf"
    },
    {
        "@score": "1",
        "@id": "379594",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "306/1136",
                        "text": "Dinghao Liu"
                    },
                    {
                        "@pid": "07/8388",
                        "text": "Shouling Ji"
                    },
                    {
                        "@pid": "67/10639",
                        "text": "Kangjie Lu"
                    },
                    {
                        "@pid": "44/2784",
                        "text": "Qinming He"
                    }
                ]
            },
            "title": "Improving Indirect-Call Analysis in LLVM with Type and Data-Flow Co-Analysis.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiuJLH24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/liu-dinghao-improving",
            "url": "https://dblp.org/rec/conf/uss/LiuJLH24",
            "abstract": "Indirect function calls are widely used in building system software like OS kernels for their high flexibility and performance. Statically resolving indirect-call targets has been known to be a hard problem, which is a fundamental requirement for various program analysis and protection tasks. The state-of-the-art techniques, which use type analysis, are still imprecise. In this paper, we present a new approach, TFA , that precisely identifies indirect-call targets. The intuition behind TFA is that type-based analysis and data-flow analysis are inherently complementary in resolving indirect-call targets. TFA incorporates a co-analysis system that makes the best use of both type information and data-flow information. The co-analysis keeps refining the global call graph iteratively, allowing us to achieve an optimal indirect call analysis. We have implemented TFA in LLVM and evaluated it against five famous large-scale programs. The experimental results show that TFA eliminates additional 24% to 59% of indirect-call targets compared with the state-of-the-art approaches, without introducing new false negatives. With the precise indirect-call analysis, we further developed a strengthened fine-grained forward-edge control-flow integrity scheme and applied it to the Linux kernel. We have also used the refined indirect-call analysis results in bug detection, where we found 8 deep bugs in the Linux kernel. As a generic technique, the precise indirect-call analysis of TFA can also benefit other applications such as compiler optimization and software debloating.",
            "keywords": [
                "Indirect-Call Analysis",
                "LLVM",
                "Type and Data-Flow Co-Analysis",
                "Control-Flow Integrity",
                "Bug Detection in Linux Kernel"
            ]
        },
        "url": "URL#379594",
        "sema_paperId": "33d21b51f3ff9ebc510e0aa025ecd6f3e239c8c2"
    },
    {
        "@score": "1",
        "@id": "379595",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "306/1136",
                        "text": "Dinghao Liu"
                    },
                    {
                        "@pid": "24/3286",
                        "text": "Zhipeng Lu"
                    },
                    {
                        "@pid": "07/8388",
                        "text": "Shouling Ji"
                    },
                    {
                        "@pid": "67/10639",
                        "text": "Kangjie Lu"
                    },
                    {
                        "@pid": "55/8437",
                        "text": "Jianhai Chen"
                    },
                    {
                        "@pid": "145/1147",
                        "text": "Zhenguang Liu"
                    },
                    {
                        "@pid": "221/0791",
                        "text": "Dexin Liu"
                    },
                    {
                        "@pid": "381/1573",
                        "text": "Renyi Cai"
                    },
                    {
                        "@pid": "44/2784",
                        "text": "Qinming He"
                    }
                ]
            },
            "title": "Detecting Kernel Memory Bugs through Inconsistent Memory Management Intention Inferences.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiuLJLCLLCH24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/liu-dinghao-detecting",
            "url": "https://dblp.org/rec/conf/uss/LiuLJLCLLCH24",
            "abstract": "Modern operating system kernels, typically written in low-level languages such as C and C++, are tasked with managing extensive memory resources. Memory-related errors, such as memory leak and memory corruption, are common occurrences and constantly introduced. Traditional detection methods often rely on taint analysis, which suffer from scalability issues (i.e., path explosion) when applied to complex OS kernels. Recent research has pivoted towards leveraging techniques like function pairing or similarity analysis to overcome this challenge. These approaches identify memory errors by referencing code that is either frequently used or semantically similar. However, these techniques have limitations when applied to customized code, which may lack a sufficient corpus of code snippets to facilitate effective function pairing or similarity analysis. This deficiency hinders their applicability in kernel analysis where unique or proprietary code is prevalent. In this paper, we propose a novel methodology for detecting memory bugs based on inconsistent memory management intentions ( IMMI ). Our insight is that many memory bugs, despite their varied manifestations, stem from a common underlying issue: the ambiguity in ownership and lifecycle management of memory objects, especially when these objects are passed across various functions. Memory bugs emerge when the memory management strategies of the caller and callee functions misalign for a given memory",
            "keywords": [
                "Kernel Memory Management",
                "Memory Bugs Detection",
                "Inconsistent Memory Management Intentions",
                "Memory Ownership",
                "Memory Lifecycle Management"
            ]
        },
        "url": "URL#379595",
        "sema_paperId": "c733293d6834a330ab433c545212cdfc7c85f8a6"
    },
    {
        "@score": "1",
        "@id": "379596",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "24/8176",
                        "text": "Changming Liu"
                    },
                    {
                        "@pid": "249/2297",
                        "text": "Alejandro Mera"
                    },
                    {
                        "@pid": "k/EnginKirda",
                        "text": "Engin Kirda"
                    },
                    {
                        "@pid": "75/4287",
                        "text": "Meng Xu"
                    },
                    {
                        "@pid": "81/7428",
                        "text": "Long Lu"
                    }
                ]
            },
            "title": "CO3: Concolic Co-execution for Firmware.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiuMKXL24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/liu-changming",
            "url": "https://dblp.org/rec/conf/uss/LiuMKXL24",
            "abstract": "Firmware running on resource-constrained embedded microcontrollers (MCUs) is critical in this IoT era, yet their security is under-analyzed. At the same time, concolic execution has proven to be a successful program analysis technique on conventional workstation platforms. However, porting it to the MCUs faces challenges, such as incomplete and inaccurate emulation of hardware peripherals, reliance on customized hardware, and low execution speed.\nCO3 is a firmware-oriented concolic executor attempting to address these limitations. CO3 runs the firmware concretely on a real MCU to utilize its fidelity. Unlike previous designs, CO3 gets rid of the slow or proprietary debugging interfaces for synchronization between the MCU and workstation. Instead, CO3 instruments the firmware source code to strategically report runtime information via a basic serial port to a workstation where symbolic constraints are constructed and solved. We further combine CO3 with a semi-hosted firmware fuzzing framework to create a hybrid fuzzer (SHACO).\nThe evaluation shows that CO3 outperforms state-of-the-art (SoTA) firmware-oriented concolic executors by three orders of magnitude while incurring mild memory and runtime overheads. It is also faster than SymCC, a general concolic executor. When evaluated on the existing benchmark, SHACO finds all known bugs in a much shorter time. It also found seven bugs from three new firmware samples. All new bugs have been confirmed and patched responsibly.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-liu-changming.pdf",
            "keywords": [
                "Firmware Analysis",
                "Concolic Execution",
                "Embedded Systems",
                "Hybrid Fuzzing",
                "Runtime Information Reporting"
            ]
        },
        "url": "URL#379596",
        "sema_paperId": "3fd8bb2c17bcb770cadc023a9737a9db315a6119"
    },
    {
        "@score": "1",
        "@id": "379597",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "35/2899-12",
                        "text": "Han Liu 0012"
                    },
                    {
                        "@pid": "144/7556",
                        "text": "Daoyuan Wu"
                    },
                    {
                        "@pid": "36/7625-1",
                        "text": "Yuqiang Sun 0001"
                    },
                    {
                        "@pid": "46/1165",
                        "text": "Haijun Wang"
                    },
                    {
                        "@pid": "219/9925-2",
                        "text": "Kaixuan Li 0002"
                    },
                    {
                        "@pid": "51/3710-3",
                        "text": "Yang Liu 0003"
                    },
                    {
                        "@pid": "11/1917",
                        "text": "Yixiang Chen"
                    }
                ]
            },
            "title": "Using My Functions Should Follow My Checks: Understanding and Detecting Insecure OpenZeppelin Code in Smart Contracts.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiuW0WL0C24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/liu-han",
            "url": "https://dblp.org/rec/conf/uss/LiuW0WL0C24",
            "abstract": "OpenZeppelin is a popular framework for building smart contracts. It provides common libraries (e.g., SafeMath), implementations of Ethereum standards (e.g., ERC20), and reusable components for access control and upgradability. However, unlike traditional software libraries, which are typically imported as static linking libraries or dynamic loading libraries, OpenZeppelin is utilized by Solidity contracts in the form of source code. As a result, developers often make custom modifications to their copies of OpenZeppelin code, which may lead to unintended security consequences. In this paper, we conduct the first systematic study on the security of OpenZeppelin code used in real-world contracts. Specifically, we focus on the security checks in the official OpenZeppelin library and examine whether they are faithfully enforced in the relevant OpenZeppelin functions of real contracts. To this end, we propose a novel tool named ZepScope that comprises two components: M INER and C HECKER . First, M INER analyzes the official OpenZeppelin functions to extract the facts of explicit checks (i.e., the checks defined within the functions) and implicit checks (i.e., the conditions of calling the functions). Second, based on the facts extracted by M INER , C HECKER examines real contracts to identify their OpenZeppelin functions, match their checks with those in the facts, and validate the consequences for those inconsistent checks. By overcoming multiple challenges in developing ZepScope, we obtain not only the first taxonomy of OpenZep-pelin checks but also the comprehensive results of checking the top 35,882 contracts from three mainstream blockchains.",
            "keywords": [
                "Smart Contract Security",
                "OpenZeppelin Framework",
                "Security Checks",
                "Code Analysis",
                "Insecure Modifications"
            ]
        },
        "url": "URL#379597",
        "sema_paperId": "f6c9affdd571e1ba0d219ea165b9c864a708c9f5"
    },
    {
        "@score": "1",
        "@id": "379598",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "360/6399",
                        "text": "Shuofeng Liu"
                    },
                    {
                        "@pid": "152/5077",
                        "text": "Zihan Wang"
                    },
                    {
                        "@pid": "166/1912",
                        "text": "Minhui Xue 0001"
                    },
                    {
                        "@pid": "68/4459",
                        "text": "Long Wang"
                    },
                    {
                        "@pid": "05/2228",
                        "text": "Yuanchao Zhang"
                    },
                    {
                        "@pid": "86/9673",
                        "text": "Guangdong Bai"
                    }
                ]
            },
            "title": "Being Transparent is Merely the Beginning: Enforcing Purpose Limitation with Polynomial Approximation.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiuWXWZB24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/liu-shuofeng",
            "url": "https://dblp.org/rec/conf/uss/LiuWXWZB24",
            "abstract": "Obtaining the authorization of users (i.e., data owners ) prior to data collection has become commonplace for online service providers (i.e., data processors ), in light of the stringent data regulations around the world. However, it remains a challenge to uphold the principle of purpose limitation , which mandates that collected data should only be processed for the purpose that the data owner has originally authorized. In this work, we advocate algorithm specificity , as a means to enforce the purpose limitation principle. We propose A LGO S PEC , which obscures data to restrict its usability solely to an authorized algorithm or algorithm group. A LGO S PEC exploits the nature of polynomial approximation that given the input data and the highest order, any algorithm can be approximated with a unique polynomial. It converts the original authorized algo-rithm (or a part of it) into a polynomial and then creates a list of alternatives to the original data. To assess the efficacy and efficiency of A LGO S PEC , we apply it to the entropy method and Naive Bayes classification under datasets of different magnitudes from 10 2 to 10 6 . A LGO S PEC significantly out-performs cryptographic solutions such as fully homomorphic encryption (FHE) in efficiency. On accuracy, it achieves a negligible Mean Squared Error (MSE) of 0.289 in the entropy method against computation over plaintext data, and identical accuracy (92.11%) and similar F1 score (87.67%) in the Naive Bayes classification.",
            "keywords": [
                "Data Privacy",
                "Purpose Limitation",
                "Algorithm Specificity",
                "Polynomial Approximation",
                "Data Obfuscation"
            ]
        },
        "url": "URL#379598",
        "sema_paperId": "0a916984752bee13ff79264c21a0cd466bdce54c"
    },
    {
        "@score": "1",
        "@id": "379599",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "381/1644",
                        "text": "Fengrun Liu"
                    },
                    {
                        "@pid": "17/1712",
                        "text": "Xiang Xie"
                    },
                    {
                        "@pid": "33/0-1",
                        "text": "Yu Yu 0001"
                    }
                ]
            },
            "title": "Scalable Multi-Party Computation Protocols for Machine Learning in the Honest-Majority Setting.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiuX024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/liu-fengrun",
            "url": "https://dblp.org/rec/conf/uss/LiuX024",
            "abstract": "In this paper, we present a novel and scalable multi-party computation (MPC) protocol tailored for privacy-preserving machine learning (PPML) with semi-honest security in the honest-majority setting. Our protocol utilizes the Damg\u00e5rd-Nielsen (Crypto\u201907) protocol with Mersenne prime fields. By leveraging the special properties of Mersenne primes, we are able to design highly efficient protocols for securely computing operations such as truncation and comparison. Additionally, we extend the two-layer multiplication protocol in ATLAS (Crypto\u201921) to further reduce the round complexity of operations commonly used in neural networks. Our protocol is very scalable in terms of the number of parties involved. For instance, our protocol completes the online oblivious inference of a 4-layer convolutional neural network with 63 parties in 0.1 seconds and 4.6 seconds in the LAN and WAN settings, respectively. To the best of our knowledge, this is the first fully implemented protocol in the field of PPML that can successfully run with such a large number of parties. Notably, even in the three-party case, the online phase of our protocol is more than 1.4 \u00d7 faster than the Falcon (PETS\u201921) protocol.",
            "keywords": [
                "Multi-Party Computation",
                "Privacy-Preserving Machine Learning",
                "Honest-Majority Setting",
                "Scalable Protocols",
                "Round Complexity Reduction"
            ]
        },
        "url": "URL#379599",
        "sema_paperId": "8edbfd7f2723fd1eb3a2743734858c713325a375"
    },
    {
        "@score": "1",
        "@id": "379600",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "221/0791",
                        "text": "Dexin Liu"
                    },
                    {
                        "@pid": "80/6791-7",
                        "text": "Yue Xiao 0007"
                    },
                    {
                        "@pid": "381/1693",
                        "text": "Chaoqi Zhang 0006"
                    },
                    {
                        "@pid": "381/1654",
                        "text": "Kaitao Xie"
                    },
                    {
                        "@pid": "20/10240",
                        "text": "Xiaolong Bai"
                    },
                    {
                        "@pid": "83/3715",
                        "text": "Shikun Zhang"
                    },
                    {
                        "@pid": "34/8412",
                        "text": "Luyi Xing"
                    }
                ]
            },
            "title": "iHunter: Hunting Privacy Violations at Scale in the Software Supply Chain on iOS.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiuXZXBZX24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/liu-dexin",
            "url": "https://dblp.org/rec/conf/uss/LiuXZXBZX24",
            "abstract": "Privacy violations and compliance issues in mobile apps are serious concerns for users, developers, and regulators. With many off-the-shelf tools on Android, prior works extensively studied various privacy issues for Android apps. Privacy risks and compliance issues can be equally expected in iOS apps, but have been little studied. In particular, a prominent recent privacy concern was due to diverse third-party libraries widely integrated into mobile apps whose privacy practices are non-transparent. Such a critical supply chain problem, however, was never systematically studied for iOS apps, at least partially due to the lack of the necessary tools. This paper presents the first large-scale study, based on our new taint analysis system named iHunter , to analyze privacy violations in the iOS software supply chain. iHunter performs static taint analysis on iOS SDKs to extract taint traces representing privacy data collection and leakage practices. It is characterized by an innovative iOS-oriented symbolic execution that tackles dynamic features of Objective-C and Swift and an NLP-powered generator for taint sources and taint rules. iHunter identified non-compliance in 2,585 SDKs (accounting for 40.4%) out of 6,401 iOS SDKs, signifying a substantial presence of SDKs that fail to adhere to compliance standards. We further found a high proportion (47.2% in 32,478) of popular iOS apps using these SDKs, with practical non-compliance risks violating Apple policies and major privacy laws. These results shed light on the pervasiveness and severity of privacy violations in iOS apps\u2019 supply chain. iHunter is thoroughly evaluated",
            "keywords": [
                "iOS Privacy Violations",
                "Software Supply Chain",
                "Taint Analysis",
                "SDK Compliance",
                "Privacy Data Leakage"
            ]
        },
        "url": "URL#379600",
        "sema_paperId": "68753028dfb642060b09c908a50b7e896a7aea06"
    },
    {
        "@score": "1",
        "@id": "379601",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "35/295-12",
                        "text": "Jian Liu 0012"
                    },
                    {
                        "@pid": "60/2536",
                        "text": "Rui Zhang"
                    },
                    {
                        "@pid": "220/3272",
                        "text": "Sebastian Szyller"
                    },
                    {
                        "@pid": "20/6179-1",
                        "text": "Kui Ren 0001"
                    },
                    {
                        "@pid": "39/2508",
                        "text": "N. Asokan"
                    }
                ]
            },
            "title": "False Claims against Model Ownership Resolution.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiuZS0A24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/liu-jian",
            "url": "https://dblp.org/rec/conf/uss/LiuZS0A24",
            "abstract": "Deep neural network (DNN) models are valuable intellectual property of model owners, constituting a competitive advantage. Therefore, it is crucial to develop techniques to protect against model theft. Model ownership resolution (MOR) is a class of techniques that can deter model theft. A MOR scheme enables an accuser to assert an ownership claim for a suspect model by presenting evidence, such as a watermark or fingerprint, to show that the suspect model was stolen or derived from a source model owned by the accuser. Most of the existing MOR schemes prioritize robustness against malicious suspects, ensuring that the accuser will win if the suspect model is indeed a stolen model.\nIn this paper, we show that common MOR schemes in the literature are vulnerable to a different, equally important but insufficiently explored, robustness concern: a malicious accuser. We show how malicious accusers can successfully make false claims against independent suspect models that were not stolen. Our core idea is that a malicious accuser can deviate (without detection) from the specified MOR process by finding (transferable) adversarial examples that successfully serve as evidence against independent suspect models. To this end, we first generalize the procedures of common MOR schemes and show that, under this generalization, defending against false claims is as challenging as preventing (transferable) adversarial examples. Via systematic empirical evaluation we show that our false claim attacks always succeed in MOR schemes that follow our generalization, including in a real-world model: Amazon's Rekognition API.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-liu-jian.pdf",
            "keywords": [
                "Model Ownership Resolution",
                "Intellectual Property Protection",
                "False Claims",
                "Adversarial Examples",
                "Model Theft"
            ]
        },
        "url": "URL#379601"
    },
    {
        "@score": "1",
        "@id": "379602",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "36/5558",
                        "text": "Tong Liu"
                    },
                    {
                        "@pid": "04/376",
                        "text": "Yingjie Zhang"
                    },
                    {
                        "@pid": "28/6429",
                        "text": "Zhe Zhao"
                    },
                    {
                        "@pid": "183/0980",
                        "text": "Yinpeng Dong"
                    },
                    {
                        "@pid": "134/8681",
                        "text": "Guozhu Meng"
                    },
                    {
                        "@pid": "c/KaiChen12",
                        "text": "Kai Chen 0012"
                    }
                ]
            },
            "title": "Making Them Ask and Answer: Jailbreaking Large Language Models in Few Queries via Disguise and Reconstruction.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiuZZDM024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/liu-tong",
            "url": "https://dblp.org/rec/conf/uss/LiuZZDM024",
            "abstract": "In recent years, large language models (LLMs) have demonstrated notable success across various tasks, but the trustworthiness of LLMs is still an open problem. One specific threat is the potential to generate toxic or harmful responses. Attackers can craft adversarial prompts that induce harmful responses from LLMs. In this work, we pioneer a theoretical foundation in LLMs security by identifying bias vulnerabilities within the safety fine-tuning and design a black-box jailbreak method named DRA (Disguise and Reconstruction Attack), which conceals harmful instructions through disguise and prompts the model to reconstruct the original harmful instruction within its completion. We evaluate DRA across various open-source and closed-source models, showcasing state-of-the-art jailbreak success rates and attack efficiency. Notably, DRA boasts a 91.1% attack success rate on OpenAI GPT-4 chatbot.",
            "keywords": [
                "Large Language Models",
                "Jailbreaking",
                "Disguise and Reconstruction Attack",
                "Toxic Response Generation",
                "Bias Vulnerabilities"
            ]
        },
        "url": "URL#379602",
        "sema_paperId": "f6fa682b62c7981402336ca57da1196ccbf3fc54"
    },
    {
        "@score": "1",
        "@id": "379603",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "313/9640",
                        "text": "Giacomo Longo"
                    },
                    {
                        "@pid": "117/8959",
                        "text": "Martin Strohmeier"
                    },
                    {
                        "@pid": "35/11048-1",
                        "text": "Enrico Russo 0001"
                    },
                    {
                        "@pid": "54/3464",
                        "text": "Alessio Merlo"
                    },
                    {
                        "@pid": "75/5939",
                        "text": "Vincent Lenders"
                    }
                ]
            },
            "title": "On a Collision Course: Unveiling Wireless Attacks to the Aircraft Traffic Collision Avoidance System (TCAS).",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LongoS0ML24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/longo",
            "url": "https://dblp.org/rec/conf/uss/LongoS0ML24",
            "abstract": "Collision avoidance systems have been a safety net of last re-sort in aviation since their introduction in the 1980s. Through constantly refined safety procedures and hard lessons learned from mid-air collisions, the Traffic Collision Avoidance System (TCAS) II Version 7.1 has become the global standard, significantly improving safety in a fast-growing field. Despite this safety record, TCAS was not designed with security in mind, even in its newest versions. With the rise of software-defined radios, security researchers have shown many wireless technologies in aviation and critical infrastructures to be insecure against radio frequency (RF) attacks. However, while similar attacks have been postulated for TCAS with its built-in distance measurement, all attempts to execute them have failed so far. In this paper, we introduce the first working RF attacks on TCAS. We demonstrate how to take full control over the collision avoidance displays and create so-called Resolution Advisories (RAs) of arbitrary aircraft on a collision course. We build the necessary tooling using commercial off-the-shelf hardware, creating sufficient conditions for the attacker to spoof colliding aircraft from a distance of up to 4.2 km. We evaluate this and further attacks extensively on a live, real-world, certified aircraft test system and discuss potential countermeasures and mitigations that should be considered by aircraft and system manufacturers in the future.",
            "keywords": [
                "Aviation Safety Systems",
                "Traffic Collision Avoidance System (TCAS)",
                "Wireless Attacks",
                "Radio Frequency (RF) Spoofing",
                "Resolution Advisories (RAs)"
            ]
        },
        "url": "URL#379603",
        "sema_paperId": "1cca8bf390448c1364ec6df57d8d1b3cdcb62e76"
    },
    {
        "@score": "1",
        "@id": "379604",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "277/7996",
                        "text": "Efr\u00e9n L\u00f3pez-Morales"
                    },
                    {
                        "@pid": "371/8298",
                        "text": "Ulysse Planta"
                    },
                    {
                        "@pid": "11/3908",
                        "text": "Carlos E. Rubio-Medrano"
                    },
                    {
                        "@pid": "73/2297-2",
                        "text": "Ali Abbasi 0002"
                    },
                    {
                        "@pid": "48/6119",
                        "text": "Alvaro A. C\u00e1rdenas"
                    }
                ]
            },
            "title": "SoK: Security of Programmable Logic Controllers.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Lopez-MoralesPR24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/lopez-morales",
            "url": "https://dblp.org/rec/conf/uss/Lopez-MoralesPR24",
            "abstract": "Billions of people rely on essential utility and manufacturing infrastructures such as water treatment plants, energy management, and food production. Our dependence on reliable infrastructures makes them valuable targets for cyberattacks. One of the prime targets for adversaries attacking physical infrastructures are Programmable Logic Controllers (PLCs) because they connect the cyber and physical worlds. In this study, we conduct the first comprehensive systematization of knowledge that explores the security of PLCs: We present an in-depth analysis of PLC attacks and defenses and discover trends in the security of PLCs from the last 17 of research. We introduce a novel threat taxonomy for PLCs and Industrial Control Systems (ICS). Finally, we identify and point out research gaps that, if left ignored, could lead to new catastrophic attacks against critical infrastructures.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-lopez-morales.pdf",
            "keywords": [
                "Programmable Logic Controllers",
                "Industrial Control Systems",
                "Cyber-Physical Security",
                "Threat Taxonomy",
                "Critical Infrastructure Vulnerabilities"
            ]
        },
        "url": "URL#379604"
    },
    {
        "@score": "1",
        "@id": "379605",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "171/8502",
                        "text": "Benedikt Lorch"
                    },
                    {
                        "@pid": "52/6295",
                        "text": "Rainer B\u00f6hme"
                    }
                ]
            },
            "title": "Landscape More Secure Than Portrait? Zooming Into the Directionality of Digital Images With Security Implications.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LorchB24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/lorch",
            "url": "https://dblp.org/rec/conf/uss/LorchB24",
            "abstract": "The orientation in which a source image is captured can affect the resulting security in downstream applications. One reason for this is that many state-of-the-art methods in media security assume that image statistics are similar in the horizontal and vertical directions, allowing them to reduce the number of features (or trainable weights) by merging coefficients. We show that this artificial symmetrization tends to suppress important properties of natural images and common processing operations, causing a loss of performance. We also observe the opposite problem, where unaddressed directionality causes learning-based methods to overfit to a single orientation. These are vulnerable to manipulation if an adversary chooses inputs with the less common orientation. This paper takes a comprehensive approach, identifies and systematizes causes of directionality at several stages of a typical acquisition pipeline, measures their effect, and demonstrates for three selected security applications (steganalysis, forensic source identification, and the detection of synthetic images) how the performance of state-of-the-art methods can be improved by properly accounting for directionality.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-lorch.pdf",
            "keywords": [
                "Digital Image Security",
                "Image Orientation",
                "Directionality in Images",
                "Steganalysis",
                "Forensic Source Identification"
            ]
        },
        "url": "URL#379605"
    },
    {
        "@score": "1",
        "@id": "379606",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "06/8545",
                        "text": "Yang Lou"
                    },
                    {
                        "@pid": "67/4972-12",
                        "text": "Yi Zhu 0012"
                    },
                    {
                        "@pid": "29/4368-1",
                        "text": "Qun Song 0001"
                    },
                    {
                        "@pid": "00/5179-1",
                        "text": "Rui Tan 0001"
                    },
                    {
                        "@pid": "60/6865",
                        "text": "Chunming Qiao"
                    },
                    {
                        "@pid": "50/3431",
                        "text": "Wei-Bin Lee"
                    },
                    {
                        "@pid": "21/1550-1",
                        "text": "Jianping Wang 0001"
                    }
                ]
            },
            "title": "A First Physical-World Trajectory Prediction Attack via LiDAR-induced Deceptions in Autonomous Driving.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LouZ00QL024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/lou",
            "url": "https://dblp.org/rec/conf/uss/LouZ00QL024",
            "abstract": "Trajectory prediction forecasts nearby agents' moves based on their historical trajectories. Accurate trajectory prediction (or prediction in short) is crucial for autonomous vehicles (AVs). Existing attacks compromise the prediction model of a victim AV by directly manipulating the historical trajectory of an attacker AV, which has limited real-world applicability. This paper, for the first time, explores an indirect attack approach that induces prediction errors via attacks against the perception module of a victim AV. Although it has been shown that physically realizable attacks against LiDAR-based perception are possible by placing a few objects at strategic locations, it is still an open challenge to find an object location from the vast search space in order to launch effective attacks against prediction under varying victim AV velocities.\nThrough analysis, we observe that a prediction model is prone to an attack focusing on a single point in the scene. Consequently, we propose a novel two-stage attack framework to realize the single-point attack. The first stage of prediction-side attack efficiently identifies, guided by the distribution of detection results under object-based attacks against perception, the state perturbations for the prediction model that are effective and velocity-insensitive. In the second stage of location matching, we match the feasible object locations with the found state perturbations. Our evaluation using a public autonomous driving dataset shows that our attack causes a collision rate of up to 63% and various hazardous responses of the victim AV. The effectiveness of our attack is also demonstrated on a real testbed car. To the best of our knowledge, this study is the first security analysis spanning from LiDAR-based perception to prediction in autonomous driving, leading to a realistic attack on prediction. To counteract the proposed attack, potential defenses are discussed.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-lou.pdf",
            "keywords": [
                "Autonomous Driving",
                "Trajectory Prediction",
                "LiDAR Perception",
                "Indirect Attack",
                "Collision Rate"
            ]
        },
        "url": "URL#379606"
    },
    {
        "@score": "1",
        "@id": "379607",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "64/6723",
                        "text": "Hongyi Lu"
                    },
                    {
                        "@pid": "42/1503-11",
                        "text": "Shuai Wang 0011"
                    },
                    {
                        "@pid": "278/6783",
                        "text": "Yechang Wu"
                    },
                    {
                        "@pid": "317/4230",
                        "text": "Wanning He"
                    },
                    {
                        "@pid": "20/11242",
                        "text": "Fengwei Zhang"
                    }
                ]
            },
            "title": "MOAT: Towards Safe BPF Kernel Extension.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Lu0WHZ24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/lu-hongyi",
            "url": "https://dblp.org/rec/conf/uss/Lu0WHZ24",
            "abstract": "The Linux kernel extensively uses the Berkeley Packet Filter (BPF) to allow user-written BPF applications to execute in the kernel space. The BPF employs a verifier to check the security of user-supplied BPF code statically. Recent attacks show that BPF programs can evade security checks and gain unauthorized access to kernel memory, indicating that the verification process is not flawless. In this paper, we present MOAT, a system that isolates potentially malicious BPF programs using Intel Memory Protection Keys (MPK). Enforcing BPF program isolation with MPK is not straightforward; MOAT is designed to alleviate technical obstacles, such as limited hardware keys and the need to protect a wide variety of BPF helper functions. We implement MOAT on Linux (ver. 6.1.38), and our evaluation shows that MOAT delivers low-cost isolation of BPF programs under mainstream use cases, such as isolating a BPF packet filter with only 3% throughput loss.",
            "keywords": [
                "BPF",
                "Kernel Security",
                "Memory Protection Keys",
                "Program Isolation",
                "Unauthorized Access"
            ]
        },
        "url": "URL#379607",
        "sema_paperId": "34afab3f8b60a9409cfbc69c852579bc4e26d047"
    },
    {
        "@score": "1",
        "@id": "379608",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "122/4355",
                        "text": "Haoran Lu"
                    },
                    {
                        "@pid": "72/8807",
                        "text": "Yichen Liu"
                    },
                    {
                        "@pid": "129/1113",
                        "text": "Xiaojing Liao"
                    },
                    {
                        "@pid": "34/8412",
                        "text": "Luyi Xing"
                    }
                ]
            },
            "title": "Towards Privacy-Preserving Social-Media SDKs on Android.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LuLLX24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/lu-haoran",
            "url": "https://dblp.org/rec/conf/uss/LuLLX24",
            "abstract": "Integration of third-party SDKs are essential in the development of mobile apps. However, the rise of in-app privacy threat against mobile SDKs \u2014 called cross-library data harvesting (XLDH), targets social media/platform SDKs (called social SDKs ) that handles rich user data. Given the widespread integration of social SDKs in mobile apps, XLDH presents a signi\ufb01cant privacy risk, as well as raising pressing concerns regarding legal compliance for app developers, social media/platform stakeholders, and policymakers. The emerging XLDH threat, coupled with the increasing demand for privacy and compliance in line with societal expectations, introduces unique challenges that cannot be addressed by existing protection methods against privacy threats or malicious code on mobile platforms. In response to the XLDH threats, in our study, we generalize and de\ufb01ne the concept of privacy-preserving social SDKs and their in-app usage, characterize fundamental challenges for combating the XLDH threat and ensuring privacy in design and utilization of social SDKs . We introduce a practical, clean-slate design and end-to-end systems, called PESP , to facilitate privacy-preserving social SDKs . Our thorough evaluation demonstrates its satisfactory effectiveness, performance overhead and practicability for widespread adoption.",
            "keywords": [
                "Privacy-Preserving SDKs",
                "Mobile App Development",
                "Cross-Library Data Harvesting",
                "Social Media SDKs",
                "User Data Privacy"
            ]
        },
        "url": "URL#379608",
        "sema_paperId": "b7ee6cf9b7d6718e7d58f225f7cfaba852d5a8c1"
    },
    {
        "@score": "1",
        "@id": "379609",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "362/6434",
                        "text": "Daniel Luick"
                    },
                    {
                        "@pid": "322/0412",
                        "text": "John C. Kolesar"
                    },
                    {
                        "@pid": "62/6761",
                        "text": "Timos Antonopoulos"
                    },
                    {
                        "@pid": "38/7508",
                        "text": "William R. Harris"
                    },
                    {
                        "@pid": "00/2904",
                        "text": "James Parker"
                    },
                    {
                        "@pid": "p/RuzicaPiskac",
                        "text": "Ruzica Piskac"
                    },
                    {
                        "@pid": "t/EranTromer",
                        "text": "Eran Tromer"
                    },
                    {
                        "@pid": "150/9413",
                        "text": "Xiao Wang 0012"
                    },
                    {
                        "@pid": "26/848",
                        "text": "Ning Luo"
                    }
                ]
            },
            "title": "ZKSMT: A VM for Proving SMT Theorems in Zero Knowledge.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LuickKAHPPT0L24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/luick",
            "url": "https://dblp.org/rec/conf/uss/LuickKAHPPT0L24",
            "abstract": "Verification of program safety is often reducible to proving the unsatisfiability (i.e., validity) of a formula in Satisfiability Modulo Theories (SMT): Boolean logic combined with theories that formalize arbitrary first-order fragments. Zero-knowledge (ZK) proofs allow SMT formulas to be validated without revealing the underlying formulas or their proofs to other parties, which is a crucial building block for proving the safety of proprietary programs. Recently, Luo et al. (CCS 2022) studied the simpler problem of proving the unsatisfiability of pure Boolean formulas but does not support proofs generated by SMT solvers. This work presents ZKSMT, a novel framework for proving the validity of SMT formulas in ZK. We design a virtual machine (VM) tailored to efficiently represent the verification process of SMT validity proofs in ZK. Our VM can support the vast majority of popular theories when proving program safety while being complete and sound. To demonstrate this, we instantiate the commonly used theories of equality and linear integer arithmetic in our VM with theory-specific optimizations for proving them in ZK. ZKSMT achieves high practicality even when running on realistic SMT formulas generated by Boogie, a common tool for software verification. It achieves a three-order-of-magnitude improvement compared to a baseline that executes the proof verification code in a general ZK system.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-luick.pdf",
            "keywords": [
                "Zero-Knowledge Proofs",
                "Satisfiability Modulo Theories",
                "SMT Validity",
                "Program Safety Verification",
                "ZKSMT Framework"
            ]
        },
        "url": "URL#379609"
    },
    {
        "@score": "1",
        "@id": "379610",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "297/3204",
                        "text": "Hidde Lycklama"
                    },
                    {
                        "@pid": "231/9670",
                        "text": "Alexander Viand"
                    },
                    {
                        "@pid": "297/3254",
                        "text": "Nicolas K\u00fcchler"
                    },
                    {
                        "@pid": "325/5407",
                        "text": "Christian Knabenhans"
                    },
                    {
                        "@pid": "122/5664",
                        "text": "Anwar Hithnawi"
                    }
                ]
            },
            "title": "Holding Secrets Accountable: Auditing Privacy-Preserving Machine Learning.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LycklamaVKKH24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/lycklama",
            "url": "https://dblp.org/rec/conf/uss/LycklamaVKKH24",
            "abstract": "Recent advancements in privacy-preserving machine learning are paving the way to extend the benefits of ML to highly sensitive data that, until now, have been hard to utilize due to privacy concerns and regulatory constraints. Simultaneously, there is a growing emphasis on enhancing the transparency and accountability of machine learning, including the ability to audit ML deployments. While ML auditing and PPML have both been the subjects of intensive research, they have predominately been examined in isolation. However, their combination is becoming increasingly important. In this work, we introduce Arc, an MPC framework for auditing privacy-preserving machine learning. At the core of our framework is a new protocol for efficiently verifying MPC inputs against succinct commitments at scale. We evaluate the performance of our framework when instantiated with our consistency protocol and compare it to hashing-based and homomorphic-commitment-based approaches, demonstrating that it is up to 10^4x faster and up to 10^6x more concise.",
            "keywords": [
                "Privacy-Preserving Machine Learning",
                "Auditing Framework",
                "Multi-Party Computation",
                "Input Verification",
                "Performance Evaluation"
            ]
        },
        "url": "URL#379610",
        "sema_paperId": "0fe2ae6cfb0a9e93e633ab833fb3aad20ea75375"
    },
    {
        "@score": "1",
        "@id": "379611",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "275/9069",
                        "text": "Xiaoting Lyu"
                    },
                    {
                        "@pid": "74/2507",
                        "text": "Yufei Han"
                    },
                    {
                        "@pid": "w/WeiWang12",
                        "text": "Wei Wang 0012"
                    },
                    {
                        "@pid": "352/9569",
                        "text": "Jingkai Liu"
                    },
                    {
                        "@pid": "90/2052",
                        "text": "Yongsheng Zhu"
                    },
                    {
                        "@pid": "46/241",
                        "text": "Guangquan Xu"
                    },
                    {
                        "@pid": "27/4749",
                        "text": "Jiqiang Liu"
                    },
                    {
                        "@pid": "74/1890-1",
                        "text": "Xiangliang Zhang 0001"
                    }
                ]
            },
            "title": "Lurking in the shadows: Unveiling Stealthy Backdoor Attacks against Personalized Federated Learning.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LyuH0LZXL024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/lyu",
            "url": "https://dblp.org/rec/conf/uss/LyuH0LZXL024",
            "abstract": "Federated Learning (FL) is a collaborative machine learning technique where multiple clients work together with a central server to train a global model without sharing their private data. However, the distribution shift across non-IID datasets of clients poses a challenge to this one-model-fits-all method hindering the ability of the global model to effectively adapt to each client's unique local data. To echo this challenge, personalized FL (PFL) is designed to allow each client to create personalized local models tailored to their private data. While extensive research has scrutinized backdoor risks in FL, it has remained underexplored in PFL applications. In this study, we delve deep into the vulnerabilities of PFL to backdoor attacks. Our analysis showcases a tale of two cities. On the one hand, the personalization process in PFL can dilute the backdoor poisoning effects injected into the personalized local models. Furthermore, PFL systems can also deploy both server-end and client-end defense mechanisms to strengthen the barrier against backdoor attacks. On the other hand, our study shows that PFL fortified with these defense methods may offer a false sense of security. We propose \\textit{PFedBA}, a stealthy and effective backdoor attack strategy applicable to PFL systems. \\textit{PFedBA} ingeniously aligns the backdoor learning task with the main learning task of PFL by optimizing the trigger generation process. Our comprehensive experiments demonstrate the effectiveness of \\textit{PFedBA} in seamlessly embedding triggers into personalized local models. \\textit{PFedBA} yields outstanding attack performance across 10 state-of-the-art PFL algorithms, defeating the existing 6 defense mechanisms. Our study sheds light on the subtle yet potent backdoor threats to PFL systems, urging the community to bolster defenses against emerging backdoor challenges.",
            "keywords": [
                "Federated Learning",
                "Personalized Federated Learning",
                "Backdoor Attacks",
                "Model Personalization",
                "Stealthy Backdoor Attack Strategy"
            ]
        },
        "url": "URL#379611",
        "sema_paperId": "e3d32d04c2d429275e592b47f261b98a641dab21"
    },
    {
        "@score": "1",
        "@id": "379612",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "381/1616",
                        "text": "Jinrui Ma"
                    },
                    {
                        "@pid": "332/3015",
                        "text": "Lutong Chen"
                    },
                    {
                        "@pid": "94/5600",
                        "text": "Kaiping Xue"
                    },
                    {
                        "@pid": "71/2890",
                        "text": "Bo Luo"
                    },
                    {
                        "@pid": "286/8388",
                        "text": "Xuanbo Huang"
                    },
                    {
                        "@pid": "332/3042",
                        "text": "Mingrui Ai"
                    },
                    {
                        "@pid": "381/1576",
                        "text": "Huanjie Zhang"
                    },
                    {
                        "@pid": "65/4599",
                        "text": "David S. L. Wei"
                    },
                    {
                        "@pid": "02/5194",
                        "text": "Yan Zhuang"
                    }
                ]
            },
            "title": "FakeBehalf: Imperceptible Email Spoofing Attacks against the Delegation Mechanism in Email Systems.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MaCXLHAZWZ24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/ma-jinrui",
            "url": "https://dblp.org/rec/conf/uss/MaCXLHAZWZ24",
            "abstract": "Email has become an essential service for global communication. In email protocols, a Delegation Mechanism allows emails to be sent by other entities on behalf of the email author. Speci\ufb01cally, the Sender \ufb01eld indicates the agent for email delivery ( i.e. , the Delegate). Despite well-implemented security extensions ( e.g. , DKIM, DMARC) that validate the authenticity of email authors, vulnerabilities in the Delegation Mechanism can still be exploited to bypass these security measures with well-crafted spoo\ufb01ng emails. This paper systematically analyzes the security vulnerabilities within the Delegation Mechanism. Due to the absence of validation for the Sender \ufb01eld, adversaries can arbitrarily fabricate this \ufb01eld, thus spoo\ufb01ng the Delegate presented to email recipients. Our observations reveal that emails with a spoofed Sender \ufb01eld can pass authentications and reach the inboxes of all target providers. We also conduct a user study with 50 participants to assess the recipients\u2019 comprehension of spoofed Delegates, \ufb01nding that 50% are susceptible to de-ceiving Delegate information. Furthermore, we propose novel email spoo\ufb01ng attacks where adversaries can impersonate arbitrary entities as email authors to craft highly deceptive emails while passing security extensions. We assess their impact across 16 service providers and 20 clients, observing that half of the providers and all clients are vulnerable to the discovered",
            "keywords": [
                "Email Security",
                "Delegation Mechanism",
                "Email Spoofing",
                "Sender Field Vulnerability",
                "User Deception in Emails"
            ]
        },
        "url": "URL#379612",
        "sema_paperId": "2fe294bfc3894b19efcedcb9a92022b473077222"
    },
    {
        "@score": "1",
        "@id": "379613",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "98/8572",
                        "text": "Xiaoyue Ma"
                    },
                    {
                        "@pid": "153/5297",
                        "text": "Lannan Luo"
                    },
                    {
                        "@pid": "81/583-1",
                        "text": "Qiang Zeng 0001"
                    }
                ]
            },
            "title": "From One Thousand Pages of Specification to Unveiling Hidden Bugs: Large Language Model Assisted Fuzzing of Matter IoT Devices.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MaL024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/ma-xiaoyue",
            "url": "https://dblp.org/rec/conf/uss/MaL024",
            "abstract": "Matter is an IoT connectivity standard backed by over two hundred companies. Since the release of its specification in October 2022, numerous IoT devices have become Matter-compatible. Identifying bugs and vulnerabilities in Matter devices is thus an emerging important problem. This paper introduces mGPTFuzz , the first Matter fuzzer in the literature. Our approach harnesses the extensive and detailed information within the Matter specification to guide the generation of test inputs. However, due to the sheer volume of the Matter specification, surpassing one thousand pages, manually converting human-readable content to machine-readable information is tedious, time-consuming and error-prone. To overcome this challenge, we leverage a large language model to successfully automate the conversion process. mGPTFuzz conducts stateful analysis, which generates message sequences to uncover bugs that would be challenging to discover otherwise. The evaluation involves 23 various Matter devices and discovers 147 new bugs, with three CVEs assigned. In comparison, a state-of-the-art IoT fuzzer finds zero bugs from these devices.",
            "keywords": [
                "IoT Security",
                "Matter Protocol",
                "Fuzzing",
                "Bug Discovery",
                "Large Language Model"
            ]
        },
        "url": "URL#379613",
        "sema_paperId": "3e27c80ef6387282c0a7e87c7aec3ef80db4b33b"
    },
    {
        "@score": "1",
        "@id": "379614",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "362/2411",
                        "text": "Lukas Maar"
                    },
                    {
                        "@pid": "350/7967",
                        "text": "Florian Draschbacher"
                    },
                    {
                        "@pid": "220/3453",
                        "text": "Lukas Lamster"
                    },
                    {
                        "@pid": "91/4831",
                        "text": "Stefan Mangard"
                    }
                ]
            },
            "title": "Defects-in-Depth: Analyzing the Integration of Effective Defenses against One-Day Exploits in Android Kernels.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MaarDLM24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/maar-defects",
            "url": "https://dblp.org/rec/conf/uss/MaarDLM24",
            "abstract": "With the mobile phone market exceeding one billion units sold in 2023, ensuring the security of these devices is critical. However, recent research has revealed worrying delays in the deployment of security-critical kernel patches, leaving devices vulnerable to publicly known one-day exploits. While the mainline Android kernel has seen an increase in defense mechanisms, their integration and effectiveness in vendor-supplied kernels are unknown at a large scale. In this paper, we systematically analyze publicly available one-day exploits targeting the Android kernel over the past three years. We identify multiple exploitation flows representing vulnerability-agnostic strategies to gain high privileges. We then demonstrate that integrating defense-in-depth mechanisms from the mainline Android kernel could mitigate 84 . 6 % of these exploitation flows. In a subsequent analysis of 994 devices, we reveal a widespread absence of effective defenses across vendors. Depending on the vendor, only 28 . 8 % to 54 . 6 % of exploitation flows are mitigated, indicating a 4.62 to 2.95 1 times worse scenario than the mainline kernel. Further delving into defense mechanisms, we reveal weaknesses in vendor-specific defenses and advanced exploitation techniques bypassing defense implementations. As these developments pose additional threats, we discuss potential solutions. Lastly, we discuss factors contributing to the absence of effective defenses and offer improvement recommendations. We envision that our findings will guide the inclusion of effective defenses, ultimately enhancing Android security.",
            "keywords": [
                "Android Kernel Security",
                "One-Day Exploits",
                "Defense Mechanisms",
                "Vendor-Supplied Kernels",
                "Exploitation Flows"
            ]
        },
        "url": "URL#379614",
        "sema_paperId": "ca6157356e8fb96dd88ee7088f8f6044f290db3c"
    },
    {
        "@score": "1",
        "@id": "379615",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "362/2411",
                        "text": "Lukas Maar"
                    },
                    {
                        "@pid": "307/3291",
                        "text": "Stefan Gast"
                    },
                    {
                        "@pid": "326/0603",
                        "text": "Martin Unterguggenberger"
                    },
                    {
                        "@pid": "381/1695",
                        "text": "Mathias Oberhuber"
                    },
                    {
                        "@pid": "91/4831",
                        "text": "Stefan Mangard"
                    }
                ]
            },
            "title": "SLUBStick: Arbitrary Memory Writes through Practical Software Cross-Cache Attacks within the Linux Kernel.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MaarGUOM24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/maar-slubstick",
            "url": "https://dblp.org/rec/conf/uss/MaarGUOM24",
            "abstract": "We present SLUBStick, a novel kernel exploitation technique that elevates a limited heap vulnerability to an arbitrary memory read/write primitive. SLUBStick works in several steps: Initially, it exploits a timing side channel of the allocator to reliably perform a cross-cache attack with a better than 99 % success rate on commonly used generic caches. SLUBStick then exploits code patterns prevalent in the Linux kernel to perform a cross-cache attack and turn a limited heap vulnerability into a page table manipulation, thereby granting the capability to read and write memory arbitrarily. The artifacts demonstrate the timing side channel and end-to-end exploits, showing the versatility of SLUBStick. For both, we provide an environment of a Virtual Machine (VM) running the Linux kernel x86_64 v6.2. For the timing side channel, the evaluation presents success rates for slab pages, with and without noise. For the end-to-end exploits, our attacks exploit an artificial Double Free (DF) vulnerability to obtain an arbitrary physical read and write primitive. This primitive is then used to manipulate the /etc/passwd file to gain root privileges within the VM.",
            "keywords": [
                "Kernel Exploitation",
                "Memory Manipulation",
                "Cross-Cache Attack",
                "Heap Vulnerability",
                "Arbitrary Memory Access"
            ]
        },
        "url": "URL#379615",
        "sema_paperId": "609e7baaea050ddbe97cacdbdca0ec683aff4daf"
    },
    {
        "@score": "1",
        "@id": "379616",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "280/8174",
                        "text": "Rasoul Akhavan Mahdavi"
                    },
                    {
                        "@pid": "243/3102",
                        "text": "Nils Lukas"
                    },
                    {
                        "@pid": "349/4964",
                        "text": "Faezeh Ebrahimianghazani"
                    },
                    {
                        "@pid": "228/2929",
                        "text": "Thomas Humphries"
                    },
                    {
                        "@pid": "205/0183",
                        "text": "Bailey Kacsmar"
                    },
                    {
                        "@pid": "280/8286",
                        "text": "John A. Premkumar"
                    },
                    {
                        "@pid": "296/4272",
                        "text": "Xinda Li 0001"
                    },
                    {
                        "@pid": "147/1534",
                        "text": "Simon Oya"
                    },
                    {
                        "@pid": "158/8306",
                        "text": "Ehsan Amjadian"
                    },
                    {
                        "@pid": "26/5304",
                        "text": "Florian Kerschbaum"
                    }
                ]
            },
            "title": "PEPSI: Practically Efficient Private Set Intersection in the Unbalanced Setting.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MahdaviLEHKP0OA24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/mahdavi",
            "url": "https://dblp.org/rec/conf/uss/MahdaviLEHKP0OA24",
            "abstract": "Two parties with private data sets can find shared elements using a Private Set Intersection (PSI) protocol without revealing any information beyond the intersection. Circuit PSI protocols privately compute an arbitrary function of the intersection - such as its cardinality, and are often employed in an unbalanced setting where one party has more data than the other. Existing protocols are either computationally inefficient or require extensive server-client communication on the order of the larger set. We introduce Practically Efficient PSI or PEPSI, a non-interactive solution where only the client sends its encrypted data. PEPSI can process an intersection of 1024 client items with a million server items in under a second, using less than 5 MB of communication. Our work is over 4 orders of magnitude faster than an existing non-interactive circuit PSI protocol and requires only 10% of the communication. It is also up to 20 times faster than the work of Ion et al., which computes a limited set of functions and has communication costs proportional to the larger set. Our work is the first to demonstrate that non-interactive circuit PSI can be practically applied in an unbalanced setting.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-mahdavi.pdf",
            "keywords": [
                "Private Set Intersection",
                "Non-Interactive Protocols",
                "Unbalanced Data Sets",
                "Efficient Computation",
                "Encrypted Data Processing"
            ]
        },
        "url": "URL#379616"
    },
    {
        "@score": "1",
        "@id": "379617",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "354/8813",
                        "text": "Prianka Mandal"
                    },
                    {
                        "@pid": "186/6501",
                        "text": "Amit Seal Ami"
                    },
                    {
                        "@pid": "381/1624",
                        "text": "Victor Olaiya"
                    },
                    {
                        "@pid": "381/1611",
                        "text": "Sayyed Hadi Razmjo"
                    },
                    {
                        "@pid": "136/8334",
                        "text": "Adwait Nadkarni"
                    }
                ]
            },
            "title": "&quot;Belt and suspenders&quot; or &quot;just red tape&quot;?: Investigating Early Artifacts and User Perceptions of IoT App Security Certification.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MandalAORN24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/mandal",
            "url": "https://dblp.org/rec/conf/uss/MandalAORN24",
            "abstract": "As IoT security regulations and standards emerge, the industry has begun adopting the traditional enforcement model for software compliance to the IoT domain, wherein Commercially Licensed Evaluation Facilities (CLEFs) certify vendor products on behalf of regulators (and in turn consumers). Since IoT standards are in their formative stages, we investigate a simple but timely question: does the traditional model work for IoT security, and more importantly, does it work as well as consumers expect it to? This paper investigates the initial artifacts resultant from IoT compliance certi\ufb01cation, and user perceptions of compliance, in the context of certi\ufb01ed mobile-IoT apps, i.e., critical companion and automation apps that expose an important IoT attack surface, with a focus on three key questions: (1) are certi\ufb01ed IoT products vulnerable?, (2) are vulnerable-but-certi\ufb01ed products non-compliant?, and \ufb01nally, (3) how do consumers perceive compliance enforcement? Our systematic analysis of 11 mobile-IoT apps certi\ufb01ed by IO X T , along with an analysis of 5 popular compliance standards, and a user study with 173 users, together yield 17 key \ufb01ndings . We \ufb01nd signi\ufb01cant vulnerabilities that indicate gaps in certi\ufb01cation, but which do not violate the standards due to ambiguity and discretionary language. Further, these vulnerabilities contrast with the overwhelming trust that users place in compliance certi\ufb01cation and certi\ufb01ed apps. We conclude with a discussion on future directions towards a \u201cbelt and suspenders\u201d scenario of effective assurance that most users desire, from the status quo of \u201cjust red tape\u201d, through objec-tive checks and balances that empower the regulators",
            "keywords": [
                "IoT Security Certification",
                "Compliance Standards",
                "Mobile-IoT Apps",
                "User Perceptions",
                "Vulnerability Assessment"
            ]
        },
        "url": "URL#379617",
        "sema_paperId": "1ca29a00f78dc4e85a9f01bc24afa2c4e621820e"
    },
    {
        "@score": "1",
        "@id": "379618",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "336/7980",
                        "text": "Lakshmi Likhitha Mankali"
                    },
                    {
                        "@pid": "13/3403",
                        "text": "Ozgur Sinanoglu"
                    },
                    {
                        "@pid": "199/8092",
                        "text": "Satwik Patnaik"
                    }
                ]
            },
            "title": "INSIGHT: Attacking Industry-Adopted Learning Resilient Logic Locking Techniques Using Explainable Graph Neural Network.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MankaliSP24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/mankali",
            "url": "https://dblp.org/rec/conf/uss/MankaliSP24",
            "abstract": "Logic locking is a hardware-based solution that protects against hardware intellectual property (IP) piracy. With the advent of powerful machine learning (ML)-based attacks, in the last 5 years, researchers have developed several learning resilient locking techniques claiming superior security guarantees. However, these security guarantees are the result of evaluation against existing ML-based attacks having critical limitations, including (i) black-box operation, i.e., does not provide any explanations, (ii) are not practical, i.e., non-consideration of approaches followed by the semiconductor industry, and (iii) are not broadly applicable, i.e., evaluate the security of a speci\ufb01c logic locking technique. In this work , we question the security provided by learning resilient locking techniques by developing an attack (I NSIGHT ) using an explainable graph neural network (GNN). I NSIGHT recovers the secret key without requiring scan-access, i.e., in an oracle-less setting for 7 unbroken learning resilient locking techniques, including 2 industry-adopted logic locking techniques . I NSIGHT achieves an average key-prediction accuracy (KPA) of 2.87 \u00d7 , 1.75 \u00d7 , and 1.67 \u00d7 higher than existing ML-based attacks. We demonstrate the ef\ufb01cacy of I NSIGHT by evaluating locked designs ranging from widely used academic suites (ISCAS-85, ITC-99) to larger designs, such as MIPS , Google IBEX , and mor1kx processors. We perform 2 practical case studies: (i) recovering secret keys of locking techniques used in a widely used commercial EDA tool ( Synopsys TestMAX ) and (ii) showcasing the rami\ufb01ca-tions of leaking the secret key for an image processing application. We will open-source our artifacts to foster",
            "keywords": [
                "Logic Locking",
                "Hardware Security",
                "Graph Neural Networks",
                "Learning Resilient Techniques",
                "Key Recovery Attack"
            ]
        },
        "url": "URL#379618",
        "sema_paperId": "41b854c26d2ea330634cc94d2cfbee022bbd6db7"
    },
    {
        "@score": "1",
        "@id": "379619",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "371/0898",
                        "text": "William P. Maxam III"
                    },
                    {
                        "@pid": "182/5618-1",
                        "text": "James C. Davis 0001"
                    }
                ]
            },
            "title": "An Interview Study on Third-Party Cyber Threat Hunting Processes in the U.S. Department of Homeland Security.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Maxam024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/maxam",
            "url": "https://dblp.org/rec/conf/uss/Maxam024",
            "abstract": "Cybersecurity is a major challenge for large organizations. Traditional cybersecurity defense is reactive. Cybersecurity operations centers keep out adversaries and incident response teams clean up after break-ins. Recently a proactive stage has been introduced: Cyber Threat Hunting (TH) looks for potential compromises missed by other cyber defenses. TH is mandated for federal executive agencies and government contractors. As threat hunting is a new cybersecurity discipline, most TH teams operate without a defined process. The practices and challenges of TH have not yet been documented.\nTo address this gap, this paper describes the first interview study of threat hunt practitioners. We obtained access and interviewed 11 threat hunters associated with the U.S. government's Department of Homeland Security. Hour-long interviews were conducted. We analyzed the transcripts with process and thematic coding. We describe the diversity among their processes, show that their processes differ from the TH processes reported in the literature, and unify our subjects' descriptions into a single TH process. We enumerate common TH challenges and solutions according to the subjects. The two most common challenges were difficulty in assessing a Threat Hunter's expertise, and developing and maintaining automation. We conclude with recommendations for TH teams (improve planning, focus on automation, and apprentice new members) and highlight directions for future work (finding a TH process that balances flexibility and formalism, and identifying assessments for TH team performance).",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-maxam.pdf",
            "keywords": [
                "Cyber Threat Hunting",
                "Department of Homeland Security",
                "Proactive Cybersecurity",
                "Threat Hunter Processes",
                "Automation Challenges"
            ]
        },
        "url": "URL#379619"
    },
    {
        "@score": "1",
        "@id": "379620",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "302/2432",
                        "text": "Carlo Mazzocca"
                    },
                    {
                        "@pid": "195/5992",
                        "text": "Abbas Acar"
                    },
                    {
                        "@pid": "46/1500",
                        "text": "A. Selcuk Uluagac"
                    },
                    {
                        "@pid": "38/5309",
                        "text": "Rebecca Montanari"
                    }
                ]
            },
            "title": "EVOKE: Efficient Revocation of Verifiable Credentials in IoT Networks.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MazzoccaAUM24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/mazzocca",
            "url": "https://dblp.org/rec/conf/uss/MazzoccaAUM24",
            "abstract": "The lack of trust is one of the major factors that hinder collaboration among Internet of Things (IoT) devices and harness the usage of the vast amount of data generated. Traditional methods rely on Public Key Infrastructure (PKI), managed by centralized certification authorities (CAs), which suffer from scalability issues, single points of failure, and limited interoperability. To address these concerns, Decentralized Identifiers (DIDs) and Verifiable Credentials (VCs) have been proposed by the World Wide Web Consortium (W3C) and the European Union as viable solutions for promoting decentralization and \"electronic IDentification, Authentication, and trust Services\" (eIDAS). Nevertheless, at the state-of-the-art, there are no efficient revocation mechanisms for VCs specifically tailored for IoT devices, which are characterized by limited connectivity, storage, and computational power. This paper presents EVOKE , an efficient revocation mechanism of VCs in IoT networks. EVOKE leverages an ECC-based accumulator to manage VCs with minimal computing and storage overhead while offering additional features like mass and offline revocation . We designed, implemented, and evaluated a prototype of EVOKE across various deployment scenarios. Our experiments on commodity IoT devices demonstrate that each device only requires minimal storage (i.e., approximately 1.5 KB) to maintain verification information, and most notably half the storage required by the most efficient PKI certificates. Moreover, our experiments on hybrid networks, representing typical IoT protocols (e.g., Zigbee), also show minimal latency in the order of millisec-onds. Finally, our large-scale analysis demonstrates that",
            "keywords": [
                "IoT Networks",
                "Verifiable Credentials",
                "Revocation Mechanism",
                "Decentralized Identifiers",
                "ECC-based Accumulator"
            ]
        },
        "url": "URL#379620",
        "sema_paperId": "16eb205dae3b42c3271b3bc6ee1b4837cf51ba5f"
    },
    {
        "@score": "1",
        "@id": "379621",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "349/7882",
                        "text": "Matthieu Meeus"
                    },
                    {
                        "@pid": "132/6759",
                        "text": "Shubham Jain"
                    },
                    {
                        "@pid": "136/9233",
                        "text": "Marek Rei"
                    },
                    {
                        "@pid": "75/7560",
                        "text": "Yves-Alexandre de Montjoye"
                    }
                ]
            },
            "title": "Did the Neurons Read your Book? Document-level Membership Inference for Large Language Models.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MeeusJRM24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/meeus",
            "url": "https://dblp.org/rec/conf/uss/MeeusJRM24",
            "abstract": "With large language models (LLMs) poised to become embedded in our daily lives, questions are starting to be raised about the data they learned from. These questions range from potential bias or misinformation LLMs could retain from their training data to questions of copyright and fair use of human-generated text. However, while these questions emerge, developers of the recent state-of-the-art LLMs become increasingly reluctant to disclose details on their training corpus. We here introduce the task of document-level membership inference for real-world LLMs, i.e. inferring whether the LLM has seen a given document during training or not. First, we propose a procedure for the development and evaluation of document-level membership inference for LLMs by leveraging commonly used data sources for training and the model release date. We then propose a practical, black-box method to predict document-level membership and instantiate it on OpenLLaMA-7B with both books and academic papers. We show our methodology to perform very well, reaching an AUC of 0.856 for books and 0.678 for papers. We then show our approach to outperform the sentence-level membership inference attacks used in the privacy literature for the document-level membership task. We further evaluate whether smaller models might be less sensitive to document-level inference and show OpenLLaMA-3B to be approximately as sensitive as OpenLLaMA-7B to our approach. Finally, we consider two mitigation strategies and find the AUC to slowly decrease when only partial documents are considered but to remain fairly high when the model precision is reduced. Taken together, our results show that accurate document-level membership can be inferred for LLMs, increasing the transparency of technology poised to change our lives.",
            "keywords": [
                "Document-level Membership Inference",
                "Large Language Models",
                "Training Data Transparency",
                "Copyright Concerns",
                "Model Sensitivity"
            ]
        },
        "url": "URL#379621",
        "sema_paperId": "bc9705f7b05bc415a0c6514c4873750ed1fdbe36"
    },
    {
        "@score": "1",
        "@id": "379622",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "92/7038",
                        "text": "Long Meng"
                    },
                    {
                        "@pid": "22/150-2",
                        "text": "Liqun Chen 0002"
                    },
                    {
                        "@pid": "188/7576",
                        "text": "Yangguang Tian"
                    },
                    {
                        "@pid": "62/484",
                        "text": "Mark Manulis"
                    },
                    {
                        "@pid": "166/1411",
                        "text": "Suhui Liu"
                    }
                ]
            },
            "title": "FEASE: Fast and Expressive Asymmetric Searchable Encryption.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Meng0TML24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/meng",
            "url": "https://dblp.org/rec/conf/uss/Meng0TML24",
            "abstract": "Asymmetric Searchable Encryption (ASE) is a promising cryptographic mechanism that enables a semi-trusted cloud server to perform keyword searches over encrypted data for users. To be useful, an ASE scheme must support expressive search queries, which are expressed as conjunction, disjunction, or any Boolean formulas. In this paper, we propose a fast and expressive ASE scheme that is adaptively secure, called FEASE. It requires only 3 pairing operations for searching any conjunctive set of keywords independent of the set size and has linear complexity for encryption and trapdoor algorithms in the number of keywords. FEASE is based on a new fast Anonymous Key-Policy Attribute-Based Encryption (A-KP-ABE) scheme as our first proposal, which is of independent interest. To address optional protection against keyword guessing attacks, we extend FEASE into the first expressive Public-Key Authenticated Encryption with Keyword Search (PAEKS) scheme. We provide implementations and evaluate the performance of all three schemes, while also comparing them with the state of the art. We observe that FEASE outperforms all existing expressive ASE constructions and that our A-KP-ABE scheme offers anonymity with efficiency comparable to the currently fastest yet non-anonymous KP-ABE schemes FAME (ACM CCS 2017) and FABEO (ACM CCS 2022).",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-meng.pdf",
            "keywords": [
                "Asymmetric Searchable Encryption",
                "Expressive Search Queries",
                "Keyword Search",
                "Anonymous Key-Policy Attribute-Based Encryption",
                "Keyword Guessing Attacks"
            ]
        },
        "url": "URL#379622"
    },
    {
        "@score": "1",
        "@id": "379623",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "318/5022",
                        "text": "Samir Jordan Menon"
                    },
                    {
                        "@pid": "32/10400-1",
                        "text": "David J. Wu 0001"
                    }
                ]
            },
            "title": "YPIR: High-Throughput Single-Server PIR with Silent Preprocessing.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Menon024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/menon",
            "url": "https://dblp.org/rec/conf/uss/Menon024",
            "abstract": "We introduce YPIR, a single-server private information retrieval (PIR) protocol that achieves high throughput (up to 83% of the memory bandwidth of the machine) without any offline communication. For retrieving a 1-bit (or 1-byte) record from a 32 GB database, YPIR achieves 12.1 GB/s/core server throughput and requires 2.5 MB of total communication. On the same setup, the state-of-the-art SimplePIR protocol achieves a 12.5 GB/s/core server throughput, requires 1.5 MB total communication, but additionally requires downloading a 724 MB hint in an offline phase. YPIR leverages a new lightweight technique to remove the hint from high-throughput single-server PIR schemes with small overhead. We also show how to reduce the server preprocessing time in the SimplePIR family of protocols by a factor of 10\u201315\u00d7.\nBy removing the need for offline communication, YPIR significantly reduces the server-side costs for private auditing of Certificate Transparency logs. Compared to the best previous PIR-based approach, YPIR reduces the server-side costs by a factor of 8\u00d7. Note that to reduce communication costs, the previous approach assumed that updates to the Certificate Transparency log servers occurred in weekly batches. Since there is no offline communication in YPIR, our approach allows clients to always audit the most recent Certificate Transparency logs (e.g., updating once a day). Supporting daily updates using the prior scheme would cost 48\u00d7 more than YPIR (based on current AWS compute costs).",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-menon.pdf",
            "keywords": [
                "Private Information Retrieval",
                "Single-Server Protocols",
                "High-Throughput",
                "Certificate Transparency",
                "Server Preprocessing"
            ]
        },
        "url": "URL#379623"
    },
    {
        "@score": "1",
        "@id": "379624",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "249/2297",
                        "text": "Alejandro Mera"
                    },
                    {
                        "@pid": "24/8176",
                        "text": "Changming Liu"
                    },
                    {
                        "@pid": "123/7388",
                        "text": "Ruimin Sun"
                    },
                    {
                        "@pid": "k/EnginKirda",
                        "text": "Engin Kirda"
                    },
                    {
                        "@pid": "81/7428",
                        "text": "Long Lu"
                    }
                ]
            },
            "title": "SHiFT: Semi-hosted Fuzz Testing for Embedded Applications.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MeraLSKL24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/mera",
            "url": "https://dblp.org/rec/conf/uss/MeraLSKL24",
            "abstract": "Modern microcontrollers (MCU)s are ubiquitous on critical embedded applications in the IoT era. Therefore, securing MCU firmware is fundamental. To analyze MCU firmware security, existing works mostly adopt re-hosting based techniques. These techniques transplant firmware to an engineered platform and require tailored hardware or emulation of different parts of the MCU. As a result, security practitioners have observed low-fidelity, false positives, and reduced compatibility with real and complex hardware. This paper presents SHiFT, a framework that leverages the industry semihosting philosophy to provide a brand-new method that analyzes firmware natively in MCUs. This novel method provides high fidelity, reduces false positives, and grants compatibility with complex peripherals, asynchronous events, real-time operations, and direct memory access (DMA). We verified compatibility of SHiFT with thirteen popular embedded architectures, and fully evaluated prototypes for ARMv7-M, ARMv8-M and Xtensa architectures. Our evaluation shows that SHiFT can detect a wide range of firmware faults with instrumentation running natively in the MCU. In terms of performance, SHiFT is up to two orders of magnitude faster (i.e., \u00d7 100) than software-based emulation, and even comparable to fuzz testing native applications in a workstation. Thanks to SHiFT\u2019s unique characteristics, we discovered five previously unknown vulnerabilities, including a zero-day on the popular FreeRTOS kernel, with no false positives. Our prototypes and source code are publicly available at https://github.com/RiS3-Lab/SHiFT.",
            "keywords": [
                "Embedded Firmware Security",
                "Fuzz Testing",
                "Microcontroller Analysis",
                "Semihosting",
                "Firmware Vulnerabilities"
            ]
        },
        "url": "URL#379624",
        "sema_paperId": "7cf38b2184788e5c85152f63d7b239a328058fce"
    },
    {
        "@score": "1",
        "@id": "379625",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "244/9573",
                        "text": "Michael Mirkin"
                    },
                    {
                        "@pid": "157/9331",
                        "text": "Lulu Zhou"
                    },
                    {
                        "@pid": "86/8318",
                        "text": "Ittay Eyal"
                    },
                    {
                        "@pid": "21/3626-22",
                        "text": "Fan Zhang 0022"
                    }
                ]
            },
            "title": "Sprints: Intermittent Blockchain PoW Mining.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MirkinZE024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/mirkin",
            "url": "https://dblp.org/rec/conf/uss/MirkinZE024",
            "abstract": "Cryptocurrencies and decentralized platforms have been rapidly gaining traction since Nakamoto's discovery of Bitcoin's blockchain protocol. Prominent systems use Proof of Work (PoW) to achieve unprecedented security for digital assets. However, the significant carbon footprint due to the manufacturing and operation of PoW mining hardware is leading policymakers to consider stark measures against them and various systems to explore alternatives. But these alternatives imply stepping away from key security aspects of PoW.\nWe present Sprints, a blockchain protocol that achieves almost the same security guarantees as PoW blockchains, but with an order-of-magnitude lower carbon footprint while increasing the number of mining rigs by a factor 1.27x. Our conservative estimate of environmental footprint uses common metrics, taking into account both power and hardware. To achieve this reduction, Sprints forces miners to mine intermittently. It interleaves Proof of Delay (PoD, e.g., using a Verifiable Delay Function) and PoW, where only the latter bears a significant resource expenditure. We prove that in Sprints the attacker's success probability is the same as that of legacy PoW. To evaluate practical performance, we analyze the effect of shortened PoW duration, showing a minor reduction in resilience (49% instead of 50%). We confirm the results with a full implementation using 100 patched Bitcoin clients in an emulated network.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-mirkin.pdf",
            "keywords": [
                "Blockchain Protocols",
                "Proof of Work",
                "Environmental Impact",
                "Intermittent Mining",
                "Security Guarantees"
            ]
        },
        "url": "URL#379625"
    },
    {
        "@score": "1",
        "@id": "379626",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "381/1578",
                        "text": "Seyed Mohammad Mehdi Mirnajafizadeh"
                    },
                    {
                        "@pid": "381/1609",
                        "text": "Ashwin Raam Sethuram"
                    },
                    {
                        "@pid": "70/2832",
                        "text": "David Mohaisen"
                    },
                    {
                        "@pid": "13/3903",
                        "text": "DaeHun Nyang"
                    },
                    {
                        "@pid": "202/9093",
                        "text": "Rhongho Jang"
                    }
                ]
            },
            "title": "Enhancing Network Attack Detection with Distributed and In-Network Data Collection System.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MirnajafizadehS24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/mirnajafizadeh",
            "url": "https://dblp.org/rec/conf/uss/MirnajafizadehS24",
            "abstract": "The collection of network data poses a significant challenge for machine/deep learning-driven network defense systems. This paper proposes a new paradigm, namely In-network Serverless Data Collection (ISDC), to eliminate the bottle-neck between network infrastructure (where data is generated) and security application servers (where data is consumed). Considering the extremely mismatched scale between traffic volume and in-network resources, we stress the need to prioritize flows based on the application\u2019s interests, and a sub-linear prediction algorithm is proposed to prioritize specific flows to optimize resource consumption effectively. Additionally, a negotiation-free task migration mechanism with task-data isolation is introduced to allocate tasks dynamically across the network to enhance resource efficiency. Furthermore, ISDC incorporates a serverless data migration and aggregation mechanism to ensure data integrity and serves as a reliable and distributed data source for network defense systems. We present two use cases to demonstrate the feasibility of ISDC, namely covert channel detection and DoS/DDoS attack detection. In both scenarios, ISDC achieves significantly higher flow coverage and feature accuracy compared to existing schemes, leading to improved attack detection accuracy. Remarkably, ISDC\u2019s data integrity addresses a model self-poisoning issue caused by duplicated and fragmented flow measurements generated during collaborative measurements.",
            "keywords": [
                "In-network Data Collection",
                "Serverless Architecture",
                "Network Attack Detection",
                "Task Migration Mechanism",
                "Flow Prioritization"
            ]
        },
        "url": "URL#379626",
        "sema_paperId": "188f0d99848d8661b4fcfd9d35fba16dc85e402f"
    },
    {
        "@score": "1",
        "@id": "379627",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "140/7588",
                        "text": "Asya Mitseva"
                    },
                    {
                        "@pid": "82/5164-1",
                        "text": "Andriy Panchenko 0001"
                    }
                ]
            },
            "title": "Stop, Don&apos;t Click Here Anymore: Boosting Website Fingerprinting By Considering Sets of Subpages.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Mitseva024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/mitseva",
            "url": "https://dblp.org/rec/conf/uss/Mitseva024",
            "abstract": "A type of traffic analysis, website fingerprinting (WFP) , aims to reveal the website a user visits over an encrypted and anonymized connection by observing and analyzing data flow patterns. Its efficiency against anonymization networks such as Tor has been widely studied, resulting in methods that have steadily increased in both complexity and power. While modern WFP attacks have proven to be highly accurate in laboratory settings, their real-world feasibility is highly de-bated. These attacks also exclude valuable information by ignoring typical user browsing behavior: users often visit multiple pages of a single website sequentially, e.g., by following links. Inthis paper, we aim to provide a more realistic assessment of the degree to which Tor users are exposed to WFP. We propose both a novel WFP attack and efficient strategies for adapting existing methods to account for sequential visits of pages within a website. While existing WFP attacks fail to detect almost any website in real-world settings, our novel methods achieve F1-scores of 1.0 for more than half of the target websites. Our attacks remain robust against state-of-the-art WFP defenses, achieving 2.5 to 5 times the accuracy of prior work, and in some cases even rendering the defenses useless. Our methods enable to estimate and to communicate to the user the risk of successive page visits within a website (even in the presence of noise pages) to stop before the WFP attack reaches a critical level of confidence.",
            "keywords": [
                "Website Fingerprinting",
                "Traffic Analysis",
                "Tor Network",
                "Sequential Page Visits",
                "Anonymization Risks"
            ]
        },
        "url": "URL#379627",
        "sema_paperId": "f02e06d80ae0c64371c56a5211ffd7544bc18d29"
    },
    {
        "@score": "1",
        "@id": "379628",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "252/6137",
                        "text": "Priyanka Mondal"
                    },
                    {
                        "@pid": "227/9110",
                        "text": "Javad Ghareh Chamani"
                    },
                    {
                        "@pid": "181/5758",
                        "text": "Ioannis Demertzis"
                    },
                    {
                        "@pid": "18/9002",
                        "text": "Dimitrios Papadopoulos 0001"
                    }
                ]
            },
            "title": "I/O-Efficient Dynamic Searchable Encryption meets Forward &amp; Backward Privacy.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MondalCD024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/mondal",
            "url": "https://dblp.org/rec/conf/uss/MondalCD024",
            "abstract": "We focus on the problem of I/O-ef\ufb01cient Dynamic Search-able Encryption (DSE), i.e., schemes that perform well when executed with the dataset on-disk. Towards this direction, for HDDs, schemes have been proposed with good locality (i.e., low number of performed non-continuous memory reads) and read ef\ufb01ciency (the number of additional memory locations read per result item). Similarly, for SSDs, schemes with good page ef\ufb01ciency (reading as few pages as possible) have been proposed. However, the vast majority of these works are limited to the static case (i.e. no dataset modi\ufb01cations) and the only dynamic scheme fails to achieve forward and backward privacy, the de-facto leakage standard in the literature. In fact, prior related works (Bost [CCS\u201916] and Minaud and Reichle [CRYPTO\u201922]) claim that I/O-ef\ufb01ciency and forward-privacy are two irreconcilable notions. Contrary to that, in this work, we \u201creconcile\u201d for the \ufb01rst time forward and backward privacy with I/O-ef\ufb01ciency for DSE both for HDDs and SSDs. We pro-pose two families of DSE constructions which also improve the state-of-the-art (non I/O-ef\ufb01cient) both asymptotically and experimentally. Indeed, some of our schemes improve the in-memory performance of prior works. At a technical level, we revisit and enhance the lazy de-amortization DSE construction by Demertzis et al. [NDSS\u201920], transforming it into an I/O-preserving one. Importantly, we introduce an oblivious-merge protocol that merges two equal-sized databases without revealing any information, effectively replacing the costly oblivious data structures with more lightweight computations.",
            "keywords": [
                "Dynamic Searchable Encryption",
                "I/O-Efficiency",
                "Forward Privacy",
                "Backward Privacy",
                "Oblivious Merge Protocol"
            ]
        },
        "url": "URL#379628",
        "sema_paperId": "263b1f0862aefe93d07d85814f77327c0baab7df"
    },
    {
        "@score": "1",
        "@id": "379629",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "332/2911",
                        "text": "Raymond Muller"
                    },
                    {
                        "@pid": "174/4227",
                        "text": "Yanmao Man"
                    },
                    {
                        "@pid": "l/MingLi3",
                        "text": "Ming Li 0003"
                    },
                    {
                        "@pid": "73/1832",
                        "text": "Ryan M. Gerdes"
                    },
                    {
                        "@pid": "33/7861",
                        "text": "Jonathan Petit"
                    },
                    {
                        "@pid": "143/2298",
                        "text": "Z. Berkay Celik"
                    }
                ]
            },
            "title": "VOGUES: Validation of Object Guise using Estimated Components.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MullerM0GPC24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/muller",
            "url": "https://dblp.org/rec/conf/uss/MullerM0GPC24",
            "abstract": "Object Detection (OD) and Object Tracking (OT) are an important part of autonomous systems (AS), enabling them to perceive and reason about their surroundings. While both OD and OT have been successfully attacked, defenses only exist for OD. In this paper, we introduce V OGUES , which combines perception algorithms in AS with logical reasoning about object components to model human perception. V OGUES leverages pose estimation algorithms to reconstruct the constituent components of objects within a scene, which are then mapped via bipartite matching against OD/OT predictions to detect OT attacks. V OGUES \u2019s component reconstruction process is designed such that attacks against OD/OT will not implicitly affect its performance. To prevent adaptive attackers from simultaneously evading OD/OT and component reconstruction, V OGUES integrates an LSTM validator to ensure that the component behavior of objects remains consistent over time. Evaluations in both the physical domain and digital domain yield an average attack detection rate of 96 . 78% and an FPR of 3 . 29%. Meanwhile, adaptive attacks against V OGUES require perturbations 30 \u00d7 stronger than previously established in OT attack works, significantly increasing the attack difficulty and reducing their practicality.",
            "keywords": [
                "Object Detection",
                "Object Tracking",
                "Autonomous Systems",
                "OT Attacks",
                "Component Reconstruction"
            ]
        },
        "url": "URL#379629",
        "sema_paperId": "0eb9decbf11e78cf9e57991d47c6cf2d89159cfb"
    },
    {
        "@score": "1",
        "@id": "379630",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "290/6330",
                        "text": "Shaoor Munir"
                    },
                    {
                        "@pid": "71/1097",
                        "text": "Patrick Lee"
                    },
                    {
                        "@pid": "08/8604-2",
                        "text": "Umar Iqbal 0002"
                    },
                    {
                        "@pid": "156/5453",
                        "text": "Sandra Siby"
                    },
                    {
                        "@pid": "83/9528",
                        "text": "Zubair Shafiq"
                    }
                ]
            },
            "title": "PURL: Safe and Effective Sanitization of Link Decoration.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MunirL0SS24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/munir",
            "url": "https://dblp.org/rec/conf/uss/MunirL0SS24",
            "abstract": "While privacy-focused browsers have taken steps to block third-party cookies and mitigate browser fingerprinting, novel tracking techniques that can bypass existing countermeasures continue to emerge. Since trackers need to share information from the client-side to the server-side through link decoration regardless of the tracking technique they employ, a promising orthogonal approach is to detect and sanitize tracking information in decorated links. To this end, we present PURL (pronounced purel-l), a machine-learning approach that leverages a cross-layer graph representation of webpage execution to safely and effectively sanitize link decoration. Our evaluation shows that PURL significantly outperforms existing countermeasures in terms of accuracy and reducing website breakage while being robust to common evasion techniques. PURL's deployment on a sample of top-million websites shows that link decoration is abused for tracking on nearly three-quarters of the websites, often to share cookies, email addresses, and fingerprinting information.",
            "keywords": [
                "Web Privacy",
                "Link Decoration",
                "Tracking Techniques",
                "Sanitization",
                "Machine Learning for Privacy"
            ]
        },
        "url": "URL#379630",
        "sema_paperId": "2c8172ee76cd25dbd66535ef71a6de1b6e70ad63"
    },
    {
        "@score": "1",
        "@id": "379631",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "381/1577",
                        "text": "Tushar Nayan"
                    },
                    {
                        "@pid": "228/3397",
                        "text": "Qiming Guo"
                    },
                    {
                        "@pid": "370/0509",
                        "text": "Mohammed Alduniawi"
                    },
                    {
                        "@pid": "212/3475",
                        "text": "Marcus Botacin"
                    },
                    {
                        "@pid": "46/1500",
                        "text": "A. Selcuk Uluagac"
                    },
                    {
                        "@pid": "123/7388",
                        "text": "Ruimin Sun"
                    }
                ]
            },
            "title": "SoK: All You Need to Know About On-Device ML Model Extraction - The Gap Between Research and Practice.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/NayanGABUS24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/nayan",
            "url": "https://dblp.org/rec/conf/uss/NayanGABUS24",
            "abstract": "On-device ML is increasingly used in different applications. It brings convenience to offline tasks and avoids sending user-private data through the network. On-device ML models are valuable and may suffer from model extraction attacks from different categories. Existing studies lack a deep understanding of on-device ML model security, which creates a gap between research and practice. This paper provides a systematization approach to classify existing model extraction attacks and defenses based on different threat models. We evaluated well known research projects from existing work with real-world ML models, and discussed their reproducibility, computation complexity, and power consumption. We identified the challenges for research projects in wide adoption in practice. We also provided directions for future research in ML model extraction security.",
            "keywords": [
                "On-Device Machine Learning",
                "Model Extraction Attacks",
                "Model Security",
                "Threat Models",
                "Reproducibility Challenges"
            ]
        },
        "url": "URL#379631",
        "sema_paperId": "6d556b1dbb4a351b12a759c6581ed903e728c09e"
    },
    {
        "@score": "1",
        "@id": "379632",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "251/4305",
                        "text": "Najmeh Nazari"
                    },
                    {
                        "@pid": "210/6007",
                        "text": "Hosein Mohammadi Makrani"
                    },
                    {
                        "@pid": "232/9671",
                        "text": "Chongzhou Fang"
                    },
                    {
                        "@pid": "157/8958",
                        "text": "Hossein Sayadi"
                    },
                    {
                        "@pid": "99/7115",
                        "text": "Setareh Rafatirad"
                    },
                    {
                        "@pid": "169/7381",
                        "text": "Khaled N. Khasawneh"
                    },
                    {
                        "@pid": "63/3012",
                        "text": "Houman Homayoun"
                    }
                ]
            },
            "title": "Forget and Rewire: Enhancing the Resilience of Transformer-based Models against Bit-Flip Attacks.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/NazariMFSRKH24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/nazari",
            "url": "https://dblp.org/rec/conf/uss/NazariMFSRKH24",
            "abstract": "Bit-Flip Attacks (BFAs) involve adversaries manipulating a model\u2019s parameter bits to undermine its accuracy significantly. They typically target the most vulnerable parameters, causing maximal damage with minimal bit-flips. While BFAs\u2019 impact on Deep Neural Networks (DNNs) is well-studied, their effects on Large Language Models (LLMs) and Vision Transformers (ViTs) have not received the same attention. Inspired by \"brain rewiring,\" we explore enhancing Trans-formers\u2019 resilience against such attacks. This potential lies in the unique architecture of transformer-based models, particularly their Linear layers. Our novel approach, called Forget and Rewire (FaR), strategically applies rewiring to Linear layers to obfuscate neuron connections. By redistributing tasks from critical to non-essential neurons, we reduce the model\u2019s sensitivity to specific parameters while preserving its core functionality. This strategy thwarts adversaries\u2019 attempts to identify and target crucial parameters using gradient-based algorithms. Our approach conceals pivotal parameters and enhances robustness against random attacks. Comprehensive evaluations across widely used datasets and Transformer frameworks show that the FaR mechanism significantly reduces BFA success rates by 1.4 to 4.2 times with minimal accuracy loss (less than 2%).",
            "keywords": [
                "Bit-Flip Attacks",
                "Transformer Resilience",
                "Model Robustness",
                "Parameter Manipulation",
                "Forget and Rewire (FaR)"
            ]
        },
        "url": "URL#379632",
        "sema_paperId": "cd0794c1e5d3558dc90670af0f0c10f64b536b34"
    },
    {
        "@score": "1",
        "@id": "379633",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "52/5285",
                        "text": "Anh Nguyen"
                    },
                    {
                        "@pid": "158/4724",
                        "text": "Xiaokuan Zhang"
                    },
                    {
                        "@pid": "28/10126",
                        "text": "Zhisheng Yan"
                    }
                ]
            },
            "title": "Penetration Vision through Virtual Reality Headsets: Identifying 360-degree Videos from Head Movements.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/NguyenZY24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/nguyen",
            "url": "https://dblp.org/rec/conf/uss/NguyenZY24",
            "abstract": "In this paper, we present the first contactless side-channel attack for identifying 360 videos being viewed in a Virtual Reality (VR) Head Mounted Display (HMD). Although the video content is displayed inside the HMD without any external exposure, we observe that user head movements are driven by the video content, which creates a unique side channel that does not exist in traditional 2D videos. By recording the user whose vision is blocked by the HMD via a malicious camera, an attacker can analyze the correlation between the user's head movements and the victim video to infer the video title. To exploit this new vulnerability, we present INTRUDE, a system for identifying 360 videos from recordings of user head movements. INTRUDE is empowered by an HMD-based head movement estimation scheme to extract a head movement trace from the recording and a video saliency-based trace-fingerprint matching framework to infer the video title. Evaluation results show that INTRUDE achieves over 96% of accuracy for video identification and is robust under different recording environments. Moreover, INTRUDE maintains its effectiveness in the open-world identification scenario.",
            "keywords": [
                "Virtual Reality",
                "360-degree Videos",
                "Head Movement Analysis",
                "Side-channel Attack",
                "Video Identification"
            ]
        },
        "url": "URL#379633",
        "sema_paperId": "4d281b984751ea4c0a5807100e7733e446b36e03"
    },
    {
        "@score": "1",
        "@id": "379634",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "51/7293",
                        "text": "Hao Nie"
                    },
                    {
                        "@pid": "35/7092-88",
                        "text": "Wei Wang 0088"
                    },
                    {
                        "@pid": "84/586-3",
                        "text": "Peng Xu 0003"
                    },
                    {
                        "@pid": "29/9985",
                        "text": "Xianglong Zhang"
                    },
                    {
                        "@pid": "y/LaurenceTianruoYang",
                        "text": "Laurence T. Yang"
                    },
                    {
                        "@pid": "126/6037",
                        "text": "Kaitai Liang"
                    }
                ]
            },
            "title": "Query Recovery from Easy to Hard: Jigsaw Attack against SSE.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Nie00ZYL24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/nie",
            "url": "https://dblp.org/rec/conf/uss/Nie00ZYL24",
            "abstract": "Searchable symmetric encryption schemes often unintentionally disclose certain sensitive information, such as access, volume, and search patterns. Attackers can exploit such leakages and other available knowledge related to the user's database to recover queries. We find that the effectiveness of query recovery attacks depends on the volume/frequency distribution of keywords. Queries containing keywords with high volumes/frequencies are more susceptible to recovery, even when countermeasures are implemented. Attackers can also effectively leverage these \"special\" queries to recover all others.\nBy exploiting the above finding, we propose a Jigsaw attack that begins by accurately identifying and recovering those distinctive queries. Leveraging the volume, frequency, and cooccurrence information, our attack achieves 90% accuracy in three tested datasets, which is comparable to previous attacks (Oya et al., USENIX' 22 and Damie et al., USENIX' 21). With the same runtime, our attack demonstrates an advantage over the attack proposed by Oya et al (approximately 15% more accuracy when the keyword universe size is 15k). Furthermore, our proposed attack outperforms existing attacks against widely studied countermeasures, achieving roughly 60% and 85% accuracy against the padding and the obfuscation, respectively. In this context, with a large keyword universe (\u22653k), it surpasses current state-of-the-art attacks by more than 20%.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-nie.pdf",
            "keywords": [
                "Searchable Symmetric Encryption",
                "Query Recovery",
                "Jigsaw Attack",
                "Information Leakage",
                "Keyword Frequency Distribution"
            ]
        },
        "url": "URL#379634"
    },
    {
        "@score": "1",
        "@id": "379635",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "381/1673",
                        "text": "Nicolas Nino"
                    },
                    {
                        "@pid": "148/0920",
                        "text": "Ruibo Lu"
                    },
                    {
                        "@pid": "69/5011-26",
                        "text": "Wei Zhou 0026"
                    },
                    {
                        "@pid": "31/9698",
                        "text": "Kyu Hyung Lee"
                    },
                    {
                        "@pid": "11/7704-1",
                        "text": "Ziming Zhao 0001"
                    },
                    {
                        "@pid": "137/5266",
                        "text": "Le Guan"
                    }
                ]
            },
            "title": "Unveiling IoT Security in Reality: A Firmware-Centric Journey.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/NinoL0L0G24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/nino",
            "url": "https://dblp.org/rec/conf/uss/NinoL0L0G24",
            "abstract": "To study the security properties of the Internet of Things (IoT), firmware analysis is crucial. In the past, many works have been focused on analyzing Linux-based firmware. Less known is the security landscape of MCU-based IoT devices, an essential portion of the IoT ecosystem. Existing works on MCU firmware analysis either leverage the companion mobile apps to infer the security properties of the firmware (thus unable to collect low-level properties) or rely on small-scale firmware datasets collected in ad-hoc ways (thus cannot be generalized). To fill this gap, we create a large dataset of MCU firmware for real IoT devices. Our approach statically analyzes how MCU firmware is distributed and then captures the firmware. To reliably recognize the firmware, we develop a firmware signature database, which can match the footprints left in the firmware compilation and packing process. In total, we obtained 8,432 confirmed firmware images (3,692 unique) covering at least 11 chip vendors across 7 known architectures and 2 proprietary architectures. We also conducted a series of static analyses to assess the security properties of this dataset. The result reveals three disconcerting facts: 1) the lack of firmware protection, 2) the existence of N-day vulnerabilities, and 3) the rare adoption of security mitigation.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-nino.pdf",
            "keywords": [
                "IoT Firmware Security",
                "MCU Devices",
                "Firmware Analysis",
                "Vulnerabilities",
                "Security Mitigation"
            ]
        },
        "url": "URL#379635",
        "sema_paperId": "36a768144b8d0c14750065f7e8f7e07f8c595634"
    },
    {
        "@score": "1",
        "@id": "379636",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "364/1918",
                        "text": "Sayedeh Leila Noorbakhsh"
                    },
                    {
                        "@pid": "371/9175",
                        "text": "Binghui Zhang"
                    },
                    {
                        "@pid": "79/5433",
                        "text": "Yuan Hong"
                    },
                    {
                        "@pid": "123/7149",
                        "text": "Binghui Wang"
                    }
                ]
            },
            "title": "Inf2Guard: An Information-Theoretic Framework for Learning Privacy-Preserving Representations against Inference Attacks.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/NoorbakhshZHW24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/noorbakhsh",
            "url": "https://dblp.org/rec/conf/uss/NoorbakhshZHW24",
            "abstract": "Machine learning (ML) is vulnerable to inference (e.g., membership inference, property inference, and data reconstruction) attacks that aim to infer the private information of training data or dataset. Existing defenses are only designed for one specific type of attack and sacrifice significant utility or are soon broken by adaptive attacks. We address these limitations by proposing an information-theoretic defense framework, called Inf2Guard, against the three major types of inference attacks. Our framework, inspired by the success of representation learning, posits that learning shared representations not only saves time/costs but also benefits numerous downstream tasks. Generally, Inf2Guard involves two mutual information objectives, for privacy protection and utility preservation, respectively. Inf2Guard exhibits many merits: it facilitates the design of customized objectives against the specific inference attack; it provides a general defense framework which can treat certain existing defenses as special cases; and importantly, it aids in deriving theoretical results, e.g., inherent utility-privacy tradeoff and guaranteed privacy leakage. Extensive evaluations validate the effectiveness of Inf2Guard for learning privacy-preserving representations against inference attacks and demonstrate the superiority over the baselines.",
            "keywords": [
                "Privacy-Preserving Representations",
                "Inference Attacks",
                "Mutual Information",
                "Utility Preservation",
                "Information-Theoretic Defense"
            ]
        },
        "url": "URL#379636",
        "sema_paperId": "2354186ba6029e6aecb7f98137486ddbd2d8fef9"
    },
    {
        "@score": "1",
        "@id": "379637",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "207/7931",
                        "text": "Sioli O&apos;Connell"
                    },
                    {
                        "@pid": "381/1634",
                        "text": "Lishay Aben Sour"
                    },
                    {
                        "@pid": "381/1572",
                        "text": "Ron Magen"
                    },
                    {
                        "@pid": "98/8283",
                        "text": "Daniel Genkin"
                    },
                    {
                        "@pid": "69/39",
                        "text": "Yossi Oren"
                    },
                    {
                        "@pid": "35/1061",
                        "text": "Hovav Shacham"
                    },
                    {
                        "@pid": "90/10901",
                        "text": "Yuval Yarom"
                    }
                ]
            },
            "title": "Pixel Thief: Exploiting SVG Filter Leakage in Firefox and Chrome.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/OConnellSMGOSY24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/oconnell",
            "url": "https://dblp.org/rec/conf/uss/OConnellSMGOSY24",
            "abstract": "Web privacy is challenged by pixel-stealing attacks, which allow attackers to extract content from embedded iframe s and to detect visited links. To protect against multiple pixel-stealing attacks that exploited timing variations in SVG filters, browser vendors repeatedly adapted their implementations to eliminate timing variations. In this work we demonstrate that past efforts are still not sufficient. We show how web-based attackers can mount cache-based side-channel attacks to monitor data-dependent memory accesses in filter rendering functions. We identify conditions under which browsers elect the non-default CPU implementation of SVG filters, and develop techniques for achieving access to the high-resolution timers required for cache attacks. We then develop efficient techniques to use the pixel-stealing attack for text recovery from embedded pages and to achieve high-speed history sniffing. To the best of our knowledge, our attack is the first to leak multiple bits per screen refresh, achieving an overall rate of 267 bits per second.",
            "keywords": [
                "Web Privacy",
                "Pixel-Stealing Attacks",
                "SVG Filters",
                "Cache-Based Side-Channel Attacks",
                "History Sniffing"
            ]
        },
        "url": "URL#379637",
        "sema_paperId": "78d10f0ce0b6117a2cfe54a6eb6d9322d2785145"
    },
    {
        "@score": "1",
        "@id": "379639",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "351/5332",
                        "text": "Aysun Ogut"
                    },
                    {
                        "@pid": "381/1626",
                        "text": "Berke Turanlioglu"
                    },
                    {
                        "@pid": "381/1655",
                        "text": "Doruk Can Metiner"
                    },
                    {
                        "@pid": "82/2842",
                        "text": "Albert Levi"
                    },
                    {
                        "@pid": "54/530",
                        "text": "Cemal Yilmaz"
                    },
                    {
                        "@pid": "162/1897",
                        "text": "Or\u00e7un \u00c7etin"
                    },
                    {
                        "@pid": "46/1500",
                        "text": "A. Selcuk Uluagac"
                    }
                ]
            },
            "title": "Dissecting Privacy Perspectives of Websites Around the World: &quot;Aceptar Todo, Alle Akzeptieren, Accept All...&quot;.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/OgutTMLYCU24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/ogut",
            "url": "https://dblp.org/rec/conf/uss/OgutTMLYCU24",
            "abstract": "Privacy has become a significant concern as the processing, storage, and sharing of collected data expands. In order to take precautions against this increasing issue, countries and different government entities have enacted laws for the protection of privacy, and articles regarding acquiring consent from the user to collect data (i.e., via cookies) have been regulated such as the right of one to be informed and to manage their preferences. Even though there are many regulations, still many websites do not transparently provide their users with their privacy practices and cookie consent notices, and restrict one's rights or make it difficult to set/choose their privacy preferences. The main objective of this study is to analyze whether websites from around the world inform their users about the collection of their data and to identify how easy or difficult for users to set their privacy preferences in practice. While observing the differences between countries, we also aim to examine whether there is an effect of geographical location on privacy approaches and whether the applications and interpretations of countries that follow and comply with the same laws are similar. For this purpose, we have developed an automated tool to scan the privacy notices on the 500 most popular websites in different countries around the world. Our extensive analysis indicates that in some countries users are rarely informed and even in countries with high cookie consent notifications, offering the option to refuse is still very low despite the fact that it is part of their regulations. The highest rate of reject buttons on cookie banners in the countries studied is 35%. Overall, although the law gives the user the right to refuse consent and be informed, we have concluded that this does not apply in practice in most countries. Moreover, in many cases, the implementations are convoluted and not user-friendly at all.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-ogut.pdf",
            "keywords": [
                "Privacy Regulations",
                "Cookie Consent",
                "User Rights",
                "Data Collection Transparency",
                "Geographical Privacy Differences"
            ]
        },
        "url": "URL#379639",
        "sema_paperId": "0b4d9ce892eef017a827d7e0aa73588206c9ffba"
    },
    {
        "@score": "1",
        "@id": "379640",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "285/5355",
                        "text": "Ataberk Olgun"
                    },
                    {
                        "@pid": "304/0523",
                        "text": "Yahya Can Tugrul"
                    },
                    {
                        "@pid": "293/6888",
                        "text": "Nisa Bostanci"
                    },
                    {
                        "@pid": "264/5883",
                        "text": "Ismail Emir Yuksel"
                    },
                    {
                        "@pid": "266/1450",
                        "text": "Haocong Luo"
                    },
                    {
                        "@pid": "348/6678",
                        "text": "Steve Rhyner"
                    },
                    {
                        "@pid": "147/4019",
                        "text": "Abdullah Giray Yaglik\u00e7i"
                    },
                    {
                        "@pid": "197/9584",
                        "text": "Geraldo F. Oliveira"
                    },
                    {
                        "@pid": "m/OnurMutlu",
                        "text": "Onur Mutlu"
                    }
                ]
            },
            "title": "ABACuS: All-Bank Activation Counters for Scalable and Low Overhead RowHammer Mitigation.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/OlgunTBYLRYOM24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/olgun",
            "url": "https://dblp.org/rec/conf/uss/OlgunTBYLRYOM24",
            "abstract": "We introduce ABACuS, a new low-cost hardware-counter-based RowHammer mitigation technique that performance-, energy-, and area-efficiently scales with worsening RowHammer vulnerability. We observe that both benign workloads and RowHammer attacks tend to access DRAM rows with the same row address in multiple DRAM banks at around the same time. Based on this observation, ABACuS's key idea is to use a single shared row activation counter to track activations to the rows with the same row address in all DRAM banks. Unlike state-of-the-art RowHammer mitigation mechanisms that implement a separate row activation counter for each DRAM bank, ABACuS implements fewer counters (e.g., only one) to track an equal number of aggressor rows. Our evaluations show that ABACuS securely prevents RowHammer bitflips at low performance/energy overhead and low area cost. We compare ABACuS to four state-of-the-art mitigation mechanisms. At a near-future RowHammer threshold of 1000, ABACuS incurs only 0.58% (0.77%) performance and 1.66% (2.12%) DRAM energy overheads, averaged across 62 single-core (8-core) workloads, requiring only 9.47 KiB of storage per DRAM rank. At the RowHammer threshold of 1000, the best prior low-area-cost mitigation mechanism incurs 1.80% higher average performance overhead than ABACuS, while ABACuS requires 2.50X smaller chip area to implement. At a future RowHammer threshold of 125, ABACuS performs very similarly to (within 0.38% of the performance of) the best prior performance- and energy-efficient RowHammer mitigation mechanism while requiring 22.72X smaller chip area. ABACuS is freely and openly available at https://github.com/CMU-SAFARI/ABACuS.",
            "keywords": [
                "RowHammer Mitigation",
                "DRAM Security",
                "Hardware Counters",
                "Performance Overhead",
                "Energy Efficiency"
            ]
        },
        "url": "URL#379640",
        "sema_paperId": "7524cc310dba98bea6acaaa7be6802f20815b74a"
    },
    {
        "@score": "1",
        "@id": "379641",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "205/2116",
                        "text": "Momen Oqaily"
                    },
                    {
                        "@pid": "372/9017",
                        "text": "Hinddeep Purohit"
                    },
                    {
                        "@pid": "24/5158",
                        "text": "Yosr Jarraya"
                    },
                    {
                        "@pid": "w/LingyuWang",
                        "text": "Lingyu Wang 0001"
                    },
                    {
                        "@pid": "201/1271",
                        "text": "Boubakr Nour"
                    },
                    {
                        "@pid": "22/3167",
                        "text": "Makan Pourzandi"
                    },
                    {
                        "@pid": "d/MDebbabi",
                        "text": "Mourad Debbabi"
                    }
                ]
            },
            "title": "ChainPatrol: Balancing Attack Detection and Classification with Performance Overhead for Service Function Chains Using Virtual Trailers.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/OqailyPJ0NPD24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/oqaily",
            "url": "https://dblp.org/rec/conf/uss/OqailyPJ0NPD24",
            "abstract": "Network functions virtualization enables tenants to out-source their service function chains (SFCs) to third-party clouds for better agility and cost-effectiveness. However, outsourcing may limit tenants\u2019 ability to directly inspect cloud-level deployments to detect attacks on SFC forwarding paths, such as network function bypass or traf\ufb01c injection. Existing solutions requiring direct cloud access are unsuitable for outsourcing, and adding a cryptographic trailer to every packet may incur signi\ufb01cant performance overhead over large \ufb02ows. In this paper, we propose ChainPa-trol , a lightweight solution for tenants to continuously detect and classify cloud-level attacks on SFCs. Our main idea is to \u201cvirtualize\u201d cryptographic trailers by encoding them as side-channel watermarks,such that they can be transmitted without adding extra bits to packets. We tackle several key challenges like encoding virtual trailers within the limited side channel capacity, minimizing packet delay, and tolerating unexpected network jitters. We implement our solution on Amazon EC2, and our experiments with real-life data and applications demonstrate that ChainPatrol can achieve a better balance between security (e.g., 100% detection accuracy and 70% classi\ufb01cation accuracy) and overhead (e.g., almost zero increased traf\ufb01c and negligible end-to-end delay) than existing works (e.g., up to 45%",
            "keywords": [
                "Service Function Chains",
                "Network Functions Virtualization",
                "Cloud Security",
                "Attack Detection",
                "Performance Overhead"
            ]
        },
        "url": "URL#379641",
        "sema_paperId": "5c7764f03caab755fd84e98e67b8b35b25eeecbd"
    },
    {
        "@score": "1",
        "@id": "379642",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "381/1665",
                        "text": "David Oygenblik"
                    },
                    {
                        "@pid": "185/6250",
                        "text": "Carter Yagemann"
                    },
                    {
                        "@pid": "249/2614",
                        "text": "Joseph Zhang"
                    },
                    {
                        "@pid": "358/4776",
                        "text": "Arianna Mastali"
                    },
                    {
                        "@pid": "163/7414",
                        "text": "Jeman Park 0001"
                    },
                    {
                        "@pid": "150/5240",
                        "text": "Brendan Saltaformaggio"
                    }
                ]
            },
            "title": "AI Psychiatry: Forensic Investigation of Deep Learning Networks in Memory Images.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/OygenblikYZM0S24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/oygenblik",
            "url": "https://dblp.org/rec/conf/uss/OygenblikYZM0S24",
            "abstract": "Online learning is widely used in production to re\ufb01ne model parameters after initial deployment. This opens several vectors for covertly launching attacks against deployed models. To detect these attacks, prior work developed black-box and white-box testing methods. However, this has left a prohibitive open challenge: How is the investigator supposed to recover the model (uniquely re\ufb01ned on an in-the-\ufb01eld device) for testing in the \ufb01rst place. We propose a novel memory forensic technique, named AiP, that automatically recovers the unique deployment model and rehosts it in a lab environment for investigation. AiP navigates through both main memory and GPU memory spaces to recover complex ML data structures, using recovered Python objects to guide the recovery of lower-level C objects, ultimately leading to the recovery of the uniquely re\ufb01ned model. AiP then rehosts the model within the investigator\u2019s device, where the investigator can apply various white-box testing methodologies. We have evaluated AiP using three versions of TensorFlow and PyTorch with the CIFAR-10, LISA, and IMDB datasets. AiP recovered 30 models from main memory and GPU memory with 100% accuracy and rehosted them into a live process successfully.",
            "keywords": [
                "Memory Forensics",
                "Model Recovery",
                "Deep Learning Models",
                "Online Learning Attacks",
                "Model Rehosting"
            ]
        },
        "url": "URL#379642",
        "sema_paperId": "cbfe0ba37628b0cb5918d18236bc34ff67f67a87"
    },
    {
        "@score": "1",
        "@id": "379643",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "280/1544",
                        "text": "Marco Palazzo"
                    },
                    {
                        "@pid": "363/9857",
                        "text": "Florine W. Dekker"
                    },
                    {
                        "@pid": "196/4896",
                        "text": "Alessandro Brighente"
                    },
                    {
                        "@pid": "82/4386",
                        "text": "Mauro Conti"
                    },
                    {
                        "@pid": "37/7227",
                        "text": "Zekeriya Erkin"
                    }
                ]
            },
            "title": "Privacy-Preserving Data Aggregation with Public Verifiability Against Internal Adversaries.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PalazzoDBCE24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/palazzo",
            "url": "https://dblp.org/rec/conf/uss/PalazzoDBCE24",
            "abstract": "We consider the problem of publicly verifiable privacy-preserving data aggregation in the presence of a malicious aggregator colluding with malicious users. State-of-the-art solutions either split the aggregator into two parties under the assumption that they do not collude, or require many rounds of interactivity and have non-constant verification time.\nIn this work, we propose mPVAS, the first publicly verifiable privacy-preserving data aggregation protocol that allows arbitrary collusion, without relying on trusted third parties during execution, where verification runs in constant time. We also show three extensions to mPVAS: mPVAS+, for improved communication complexity, mPVAS-IV, for the identification of malicious users, and mPVAS-UD, for graceful handling of reduced user availability without the need to redo the setup. We show that our schemes achieve the desired confidentiality, integrity, and authenticity. Finally, through both theoretical and experimental evaluations, we show that our schemes are feasible for real-world applications.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-palazzo.pdf",
            "keywords": [
                "Privacy-Preserving Data Aggregation",
                "Public Verifiability",
                "Malicious Users",
                "Data Integrity",
                "User Availability"
            ]
        },
        "url": "URL#379643",
        "sema_paperId": "c6da151e3d397ba61d35ca17f3e6e20338a62217"
    },
    {
        "@score": "1",
        "@id": "379644",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "381/1650",
                        "text": "Yepeng Pan"
                    },
                    {
                        "@pid": "331/5937",
                        "text": "Anna Ascheman"
                    },
                    {
                        "@pid": "08/6024",
                        "text": "Christian Rossow"
                    }
                ]
            },
            "title": "Loopy Hell(ow): Infinite Traffic Loops at the Application Layer.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PanAR24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/pan-yepeng",
            "url": "https://dblp.org/rec/conf/uss/PanAR24",
            "abstract": "Denial-of-Service (DoS) attacks have long been a persistent threat to network infrastructures. Existing attack primitives require attackers to continuously send traffic, such as in SYN floods, amplification attacks, or application-layer DoS. In contrast, we study the threat of application-layer traffic loops, which are an almost cost-free attack primitive alternative. Such loops exist, e.g., if two servers consider messages sent to each other as malformed and respond with errors that again trigger error messages. Attackers can send a single IP-spoofed loop trigger packet to initiate an infinite loop among two servers. But despite the severity of traffic loops, to the best of our knowledge, they have never been studied in greater detail.\nIn this paper, we thus investigate the threat of application-layer traffic loops. To this end, we propose a systematic approach to identify loops among real servers. Our core idea is to learn the response functions of all servers of a given application-layer protocol, encode this knowledge into a loop graph, and finally, traverse the graph to spot looping server pairs. Using the proposed method, we examined traffic loops among servers running both popular (DNS, NTP, and TFTP) and legacy (Daytime, Time, Active Users, Chargen, QOTD, and Echo) UDP protocols and confirmed the prevalence of traffic loops. In total, we identified approximately 296k servers in IPv4 vulnerable to traffic loops, providing attackers the opportunity to abuse billions of loop pairs.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-pan-yepeng.pdf",
            "keywords": [
                "Application Layer Security",
                "Traffic Loops",
                "Denial-of-Service Attacks",
                "Server Vulnerabilities",
                "IP-Spoofed Attacks"
            ]
        },
        "url": "URL#379644",
        "sema_paperId": "3cd4bb8ba778e1fee18b51a5746f6ed16be039bd"
    },
    {
        "@score": "1",
        "@id": "379645",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "303/8542",
                        "text": "Shidong Pan"
                    },
                    {
                        "@pid": "239/7152",
                        "text": "Zhen Tao"
                    },
                    {
                        "@pid": "194/7742",
                        "text": "Thong Hoang"
                    },
                    {
                        "@pid": "274/6649",
                        "text": "Dawen Zhang"
                    },
                    {
                        "@pid": "59/9681-1",
                        "text": "Tianshi Li 0001"
                    },
                    {
                        "@pid": "52/6482",
                        "text": "Zhenchang Xing"
                    },
                    {
                        "@pid": "47/3196-1",
                        "text": "Xiwei Xu 0001"
                    },
                    {
                        "@pid": "s/MarkStaples",
                        "text": "Mark Staples"
                    },
                    {
                        "@pid": "49/2168",
                        "text": "Thierry Rakotoarivelo"
                    },
                    {
                        "@pid": "89/6793-1",
                        "text": "David Lo 0001"
                    }
                ]
            },
            "title": "A NEW HOPE: Contextual Privacy Policies for Mobile Applications and An Approach Toward Automated Generation.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PanTHZ0X0SR024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/pan-shidong-hope",
            "url": "https://dblp.org/rec/conf/uss/PanTHZ0X0SR024",
            "abstract": "Privacy policies have emerged as the predominant approach to conveying privacy notices to mobile application users. In an effort to enhance both readability and user engagement, the concept of contextual privacy policies (CPPs) has been proposed by researchers. The aim of CPPs is to fragment privacy policies into concise snippets, displaying them only within the corresponding contexts within the application's graphical user interfaces (GUIs). In this paper, we first formulate CPP in mobile application scenario, and then present a novel multimodal framework, named SeePrivacy, specifically designed to automatically generate CPPs for mobile applications. This method uniquely integrates vision-based GUI understanding with privacy policy analysis, achieving 0.88 precision and 0.90 recall to detect contexts, as well as 0.98 precision and 0.96 recall in extracting corresponding policy segments. A human evaluation shows that 77% of the extracted privacy policy segments were perceived as well-aligned with the detected contexts. These findings suggest that SeePrivacy could serve as a significant tool for bolstering user interaction with, and understanding of, privacy policies. Furthermore, our solution has the potential to make privacy notices more accessible and inclusive, thus appealing to a broader demographic. A demonstration of our work can be accessed at: https://cpp4app.github.io/SeePrivacy/",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-pan-shidong-hope.pdf",
            "keywords": [
                "Contextual Privacy Policies",
                "Mobile Applications",
                "Privacy Notices",
                "Automated Generation",
                "User Engagement"
            ]
        },
        "url": "URL#379645"
    },
    {
        "@score": "1",
        "@id": "379646",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "303/8542",
                        "text": "Shidong Pan"
                    },
                    {
                        "@pid": "274/6649",
                        "text": "Dawen Zhang"
                    },
                    {
                        "@pid": "s/MarkStaples",
                        "text": "Mark Staples"
                    },
                    {
                        "@pid": "52/6482",
                        "text": "Zhenchang Xing"
                    },
                    {
                        "@pid": "202/6440",
                        "text": "Jieshan Chen"
                    },
                    {
                        "@pid": "47/3196-1",
                        "text": "Xiwei Xu 0001"
                    },
                    {
                        "@pid": "194/7742",
                        "text": "Thong Hoang"
                    }
                ]
            },
            "title": "Is It a Trap? A Large-scale Empirical Study And Comprehensive Assessment of Online Automated Privacy Policy Generators for Mobile Apps.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PanZSXC0H24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/pan-shidong-trap",
            "url": "https://dblp.org/rec/conf/uss/PanZSXC0H24",
            "abstract": "Privacy regulations protect and promote the privacy of individuals by requiring mobile apps to provide a privacy policy that explains what personal information is collected and how these apps process this information. However, developers often do not have sufficient legal knowledge to create such privacy policies. Online Automated Privacy Policy Generators (APPGs) can create privacy policies, but their quality and other characteristics can vary. In this paper, we conduct the first large-scale empirical study and comprehensive assessment of APPGs for mobile apps. Specifically, we scrutinize 10 APPGs on multiple dimensions. We further perform the market penetration analysis by collecting 46,472 Android app privacy policies from Google Play, discovering that nearly 20.1% of privacy policies could be generated by existing APPGs. Lastly, we point out that generated policies in our study do not fully comply with GDPR, CCPA, or LGPD. In summary, app developers must carefully select and use the appropriate APPGs with careful consideration to avoid potential pitfalls.",
            "keywords": [
                "Privacy Policy Generation",
                "Automated Privacy Policy Generators",
                "Mobile App Privacy",
                "Compliance Assessment",
                "GDPR and CCPA Compliance"
            ]
        },
        "url": "URL#379646",
        "sema_paperId": "4154eb94d58ebc67fd47a2abc187ec963f87ff04"
    },
    {
        "@score": "1",
        "@id": "379647",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "381/1697",
                        "text": "Kabir Panahi"
                    },
                    {
                        "@pid": "235/7897",
                        "text": "Shawn Robertson"
                    },
                    {
                        "@pid": "132/9687",
                        "text": "Yasemin Acar"
                    },
                    {
                        "@pid": "145/6877",
                        "text": "Alexandru G. Bardas"
                    },
                    {
                        "@pid": "k/TadayoshiKohno",
                        "text": "Tadayoshi Kohno"
                    },
                    {
                        "@pid": "31/9612",
                        "text": "Lucy Simko"
                    }
                ]
            },
            "title": "&quot;But they have overlooked a few things in Afghanistan: &quot; An Analysis of the Integration of Biometric Voter Verification in the 2019 Afghan Presidential Elections.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PanahiRABKS24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/panahi",
            "url": "https://dblp.org/rec/conf/uss/PanahiRABKS24",
            "abstract": "Afghanistan deployed biometric voter verification (BVV) machines nationally for the first time in the critical 2019 presidential election. Through the leading authors\u2019 unique backgrounds and involvement in this election, which facilitated interviews with 18 Afghan nationals and international participants who had an active role in this Afghan election, we explore the gap between the expected outcomes of the electoral system, centered around BVVs, and the reality on election day and beyond. We find that BVVs supported and violated the electoral goals of voter enfranchisement, fraud prevention, enabling public trust, and created threats for voters, staff, and officials. We identify technical, usability, and bureaucratic underlying causes for these mismatches and discuss several vital factors that are part of an election.",
            "keywords": [
                "Biometric Voter Verification",
                "Afghan Presidential Elections",
                "Voter Enfranchisement",
                "Fraud Prevention",
                "Public Trust in Elections"
            ]
        },
        "url": "URL#379647",
        "sema_paperId": "9ad7274b836ff9def94c59a381a7bf4420faec36"
    },
    {
        "@score": "1",
        "@id": "379648",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "277/8303",
                        "text": "Nikolaos Pantelaios"
                    },
                    {
                        "@pid": "22/1459",
                        "text": "Alexandros Kapravelos"
                    }
                ]
            },
            "title": "FV8: A Forced Execution JavaScript Engine for Detecting Evasive Techniques.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PantelaiosK24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/pantelaios",
            "url": "https://dblp.org/rec/conf/uss/PantelaiosK24",
            "abstract": "Evasion techniques allow malicious code to never be observed. This impacts significantly the detection capabilities of tools that rely on either dynamic or static analysis, as they never get to process the malicious code. The dynamic nature of JavaScript, where code is often injected dynamically, makes evasions particularly effective. Yet, we lack tools that can detect evasive techniques in a challenging environment such as JavaScript. In this paper, we present FV8, a modified V8 JavaScript engine designed to identify evasion techniques in JavaScript code. FV8 selectively enforces code execution on APIs that conditionally inject dynamic code, thus enhancing code coverage and consequently improving visibility into malicious code. We integrate our tool in both the Node.js engine and the Chromium browser, compelling code execution in npm packages and Chrome browser extensions. Our tool increases code coverage by 11% compared to default V8 and detects 28 unique evasion categories, including five previously unreported techniques. In data confirmed as malicious from both ecosystems, our tool identifies 1,443 (14.6%) npm packages and 164 (82%) extensions containing at least one type of evasion. In previously unexamined extensions (39,592), our tool discovered 16,471 injected third-party scripts, and a total of 8,732,120 lines of code executed due to our forced execution instrumentation. Furthermore, it tagged a total of 423 extensions as both evasive and malicious and we manually verify 110 extensions (26%) to actually be malicious, impacting two million users. Our tool is open-source and serves both as an in-browser and standalone dynamic analysis tool, capable of detecting evasive code, bypassing obfuscation in certain cases, offering improved access to malicious code, and supporting recursive analysis of dynamic code injections",
            "keywords": [
                "JavaScript Security",
                "Evasion Techniques",
                "Dynamic Code Injection",
                "Malicious Code Detection",
                "V8 JavaScript Engine"
            ]
        },
        "url": "URL#379648",
        "sema_paperId": "993c9cd757385c096744cb7b209e5160d48749ca"
    },
    {
        "@score": "1",
        "@id": "379649",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "191/0014",
                        "text": "Giulio De Pasquale"
                    },
                    {
                        "@pid": "180/7263",
                        "text": "Ilya Grishchenko"
                    },
                    {
                        "@pid": "290/4182",
                        "text": "Riccardo Iesari"
                    },
                    {
                        "@pid": "381/1691",
                        "text": "Gabriel Pizarro"
                    },
                    {
                        "@pid": "95/5162",
                        "text": "Lorenzo Cavallaro"
                    },
                    {
                        "@pid": "k/ChristopherKruegel",
                        "text": "Christopher Kruegel"
                    },
                    {
                        "@pid": "v/GiovanniVigna",
                        "text": "Giovanni Vigna"
                    }
                ]
            },
            "title": "ChainReactor: Automated Privilege Escalation Chain Discovery via AI Planning.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PasqualeGIPCKV24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/de-pasqual",
            "url": "https://dblp.org/rec/conf/uss/PasqualeGIPCKV24",
            "abstract": "Current academic vulnerability research predominantly focuses on identifying individual bugs and exploits in programs and systems. However, this goes against the growing trend of modern, advanced attacks that rely on a sequence of steps (i.e., a chain of exploits) to achieve their goals, often incorporating individually benign actions. This paper introduces a novel approach to the automated discovery of such exploitation chains using AI planning. In particular, we aim to discover privilege escalation chains, some of the most critical and pervasive security threats, which involve exploiting vulnerabilities to gain unauthorized access and control over systems. We implement our approach as a tool, ChainReactor, that models the problem as a sequence of actions to achieve privilege escalation from the initial access to a target system. ChainReactor extracts information about available executables, system configurations, and known vulnerabilities on the target and encodes this data into a Planning Domain Definition Language (PDDL) problem. Using a modern planner, ChainReactor can generate chains incorporating vulnerabilities and benign actions. We evaluated ChainReactor on 3 synthetic vulnerable VMs, 504 real-world Amazon EC2 and 177 Digital Ocean instances, demonstrating its capacity to rediscover known privilege escalation exploits and identify new chains previously unreported. Specifically, the evaluation showed that ChainReactor successfully rediscovered the exploit chains in the Capture the Flag (CTF) machines and identified zero-day chains on 16 Amazon EC2 and 4 Digital Ocean VMs.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-de-pasquale.pdf",
            "keywords": [
                "Automated Exploit Discovery",
                "Privilege Escalation Chains",
                "AI Planning",
                "Vulnerability Exploitation",
                "Zero-Day Exploits"
            ]
        },
        "url": "URL#379649",
        "sema_paperId": "0336be12f8b0235b2a196bf37f093f5668a03157"
    },
    {
        "@score": "1",
        "@id": "379650",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "243/3868",
                        "text": "Pujan Paudel"
                    },
                    {
                        "@pid": "07/320-4",
                        "text": "Chen Ling 0004"
                    },
                    {
                        "@pid": "12/8780",
                        "text": "Jeremy Blackburn"
                    },
                    {
                        "@pid": "86/8823",
                        "text": "Gianluca Stringhini"
                    }
                ]
            },
            "title": "PIXELMOD: Improving Soft Moderation of Visual Misleading Information on Twitter.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PaudelLBS24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/paudel-pixelmod",
            "url": "https://dblp.org/rec/conf/uss/PaudelLBS24",
            "abstract": "Images are a powerful and immediate vehicle to carry misleading or outright false messages, yet identifying image-based misinformation at scale poses unique challenges. In this paper, we present PIXELMOD, a system that leverages perceptual hashes, vector databases, and optical character recognition (OCR) to efficiently identify images that are candidates to receive soft moderation labels on Twitter. We show that PIXELMOD outperforms existing image similarity approaches when applied to soft moderation, with negligible performance overhead. We then test PIXELMOD on a dataset of tweets surrounding the 2020 US Presidential Election, and find that it is able to identify visually misleading images that are candidates for soft moderation with 0.99% false detection and 2.06% false negatives.",
            "keywords": [
                "Visual Misinformation",
                "Soft Moderation",
                "Image Similarity",
                "Perceptual Hashing",
                "Optical Character Recognition (OCR)"
            ]
        },
        "url": "URL#379650",
        "sema_paperId": "a26d5acf23d1ddb645cf5efae6887aea92ddf2ce"
    },
    {
        "@score": "1",
        "@id": "379651",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "243/3868",
                        "text": "Pujan Paudel"
                    },
                    {
                        "@pid": "243/3120",
                        "text": "Mohammad Hammas Saeed"
                    },
                    {
                        "@pid": "381/1627",
                        "text": "Rebecca Auger"
                    },
                    {
                        "@pid": "10/2958",
                        "text": "Chris Wells"
                    },
                    {
                        "@pid": "86/8823",
                        "text": "Gianluca Stringhini"
                    }
                ]
            },
            "title": "Enabling Contextual Soft Moderation on Social Media through Contrastive Textual Deviation.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PaudelSAWS24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/paudel-enabling",
            "url": "https://dblp.org/rec/conf/uss/PaudelSAWS24",
            "abstract": "Automated soft moderation systems are unable to ascertain if a post supports or refutes a false claim, resulting in a large number of contextual false positives. This limits their effectiveness, for example undermining trust in health experts by adding warnings to their posts or resorting to vague warnings instead of granular fact-checks, which result in desensitizing users. In this paper, we propose to incorporate stance detection into existing automated soft-moderation pipelines, with the goal of ruling out contextual false positives and providing more precise recommendations for social media content that should receive warnings. We develop a textual deviation task called Contrastive Textual Deviation (CTD) and show that it outperforms existing stance detection approaches when applied to soft moderation.We then integrate CTD into the stateof-the-art system for automated soft moderation Lambretta, showing that our approach can reduce contextual false positives from 20% to 2.1%, providing another important building block towards deploying reliable automated soft moderation tools on social media.",
            "keywords": [
                "Automated Soft Moderation",
                "Stance Detection",
                "Contextual False Positives",
                "Contrastive Textual Deviation",
                "Social Media Content Moderation"
            ]
        },
        "url": "URL#379651",
        "sema_paperId": "518a008052d49cb4663cde3d9a95a23e89c85bea"
    },
    {
        "@score": "1",
        "@id": "379652",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "344/3222",
                        "text": "Alessandro Pegoraro"
                    },
                    {
                        "@pid": "372/0402",
                        "text": "Carlotta Segna"
                    },
                    {
                        "@pid": "124/3795",
                        "text": "Kavita Kumari"
                    },
                    {
                        "@pid": "s/AhmadRezaSadeghi",
                        "text": "Ahmad-Reza Sadeghi"
                    }
                ]
            },
            "title": "DeepEclipse: How to Break White-Box DNN-Watermarking Schemes.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PegoraroSKS24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/pegoraro",
            "url": "https://dblp.org/rec/conf/uss/PegoraroSKS24",
            "abstract": "Deep Learning (DL) models have become crucial in digital transformation, thus raising concerns about their intellectual property rights. Different watermarking techniques have been developed to protect Deep Neural Networks (DNNs) from IP infringement, creating a competitive field for DNN watermarking and removal methods. The predominant watermarking schemes use white-box techniques, which involve modifying weights by adding a unique signature to specific DNN layers. On the other hand, existing attacks on white-box watermarking usually require knowledge of the specific deployed watermarking scheme or access to the underlying data for further training and fine-tuning. We propose DeepEclipse, a novel and unified framework designed to remove white-box watermarks. We present obfuscation techniques that significantly differ from the existing white-box watermarking removal schemes. DeepEclipse can evade watermark detection without prior knowledge of the underlying watermarking scheme, additional data, or training and fine-tuning. Our evaluation reveals that DeepEclipse excels in breaking multiple white-box watermarking schemes, reducing watermark detection to random guessing while maintaining a similar model accuracy as the original one. Our framework showcases a promising solution to address the ongoing DNN watermark protection and removal challenges.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-pegoraro.pdf",
            "keywords": [
                "DNN Watermarking",
                "Watermark Removal",
                "Obfuscation Techniques",
                "Intellectual Property Protection",
                "White-Box Attacks"
            ]
        },
        "url": "URL#379652"
    },
    {
        "@score": "1",
        "@id": "379654",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "330/2141",
                        "text": "Sajjad Pourali"
                    },
                    {
                        "@pid": "26/7054",
                        "text": "Xiufen Yu"
                    },
                    {
                        "@pid": "140/6495",
                        "text": "Lianying Zhao"
                    },
                    {
                        "@pid": "m/MohammadMannan",
                        "text": "Mohammad Mannan"
                    },
                    {
                        "@pid": "05/4817",
                        "text": "Amr M. Youssef"
                    }
                ]
            },
            "title": "Racing for TLS Certificate Validation: A Hijacker&apos;s Guide to the Android TLS Galaxy.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PouraliYZMY24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/pourali",
            "url": "https://dblp.org/rec/conf/uss/PouraliYZMY24",
            "abstract": "Besides developers\u2019 code, current Android apps usually integrate code from third-party libraries, all of which may include code for TLS validation. We analyze well-known improper TLS certificate validation issues in popular Android apps, and attribute the validation issues to the offending code/- party in a fine-grained manner, unlike existing work labeling an entire app for validation failures. Surprisingly, we discovered a widely used practice of overriding the global default validation functions with improper validation logic, or simply performing no validation at all, affecting the entire app\u2019s TLS connections, which we call validation hijacking . We design and implement an automated dynamic analysis tool called Marvin to identify TLS validation failures, including validation hijacking, and the responsible parties behind such insecure practices. Among 7826 apps from a Chinese app store and Google Play analyzed by Marvin, we found many",
            "keywords": [
                "Android App Security",
                "TLS Certificate Validation",
                "Validation Hijacking",
                "Dynamic Analysis",
                "Third-party Libraries"
            ]
        },
        "url": "URL#379654",
        "sema_paperId": "3a91645396b04ca382c1a62d837fb1a96f8fcb77"
    },
    {
        "@score": "1",
        "@id": "379655",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "249/4946",
                        "text": "Zhenxiao Qi"
                    },
                    {
                        "@pid": "90/5064",
                        "text": "Jie Hu"
                    },
                    {
                        "@pid": "381/1575",
                        "text": "Zhaoqi Xiao"
                    },
                    {
                        "@pid": "77/6178-1",
                        "text": "Heng Yin 0001"
                    }
                ]
            },
            "title": "SymFit: Making the Common (Concrete) Case Fast for Binary-Code Concolic Execution.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/QiHX024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/qi",
            "url": "https://dblp.org/rec/conf/uss/QiHX024",
            "abstract": "Concolic execution is a powerful technique in software testing, as it can systematically explore the code paths and is capable of traversing complex branches. It combines concrete execution for environment modeling and symbolic execution for path exploration. While signi\ufb01cant research efforts in con-colic execution have been directed toward the improvement of symbolic execution and constraint solving, our study pivots toward the often overlooked yet most common aspect: concrete execution. Our analysis shows that state-of-the-art binary con-colic executors have largely overlooked the overhead in the execution of concrete instructions. In light of this observation, we propose optimizations to make the common (concrete) case fast. To validate this idea, we develop the prototype, S YM F IT , and evaluate it on standard benchmarks and real-world applications. The results showed that the performance of pure concrete execution is much faster than the baseline S YM QEMU, and is comparable to the vanilla QEMU. More-over, we showed that the fast symbolic tracing capability of S YM F IT can signi\ufb01cantly improve the ef\ufb01ciency of crash deduplication.",
            "keywords": [
                "Concolic Execution",
                "Binary Code Analysis",
                "Symbolic Execution",
                "Concrete Execution Optimization",
                "Crash Deduplication"
            ]
        },
        "url": "URL#379655",
        "sema_paperId": "5ecab8036fa3fc57a6c9930a3496125d76ba5e1a"
    },
    {
        "@score": "1",
        "@id": "379656",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "221/4628",
                        "text": "Lucy Qin"
                    },
                    {
                        "@pid": "314/5946",
                        "text": "Vaughn Hamilton"
                    },
                    {
                        "@pid": "13/6118",
                        "text": "Sharon Wang"
                    },
                    {
                        "@pid": "371/9848",
                        "text": "Yigit Aydinalp"
                    },
                    {
                        "@pid": "372/0843",
                        "text": "Marin Scarlett"
                    },
                    {
                        "@pid": "141/9244",
                        "text": "Elissa M. Redmiles"
                    }
                ]
            },
            "title": "&quot;Did They F***ing Consent to That?&quot;: Safer Digital Intimacy via Proactive Protection Against Image-Based Sexual Abuse.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/QinHWASR24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/qin",
            "url": "https://dblp.org/rec/conf/uss/QinHWASR24",
            "abstract": "As many as 8 in 10 adults share intimate content such as nude or lewd images. Sharing such content has significant benefits for relationship intimacy and body image, and can offer employment. However, stigmatizing attitudes and a lack of technological mitigations put those sharing such content at risk of sexual violence. An estimated 1 in 3 people have been subjected to image-based sexual abuse (IBSA), a spectrum of violence that includes the nonconsensual distribution or threat of distribution of consensually-created intimate content (also called NDII). In this work, we conducted a rigorous empirical interview study of 52 European creators of intimate content to examine the threats they face and how they defend against them, situated in the context of their different use cases for intimate content sharing and their choice of technologies for storing and sharing such content. Synthesizing our results with the limited body of prior work on technological prevention of NDII, we offer concrete next steps for both platforms and security&privacy researchers to work toward safer intimate content sharing through proactive protection. Content Warning: This work discusses sexual violence, specifically, the harms of image-based sexual abuse (particularly in Sections 2 and 6).",
            "keywords": [
                "technology",
                "finance",
                "healthcare",
                "education",
                "sustainability"
            ]
        },
        "url": "URL#379656",
        "sema_paperId": "5878677f61a75e626f269cb9816b553396acdce2"
    },
    {
        "@score": "1",
        "@id": "379657",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "171/1877",
                        "text": "Hany Ragab"
                    },
                    {
                        "@pid": "184/6002",
                        "text": "Andrea Mambretti"
                    },
                    {
                        "@pid": "62/8322",
                        "text": "Anil Kurmus"
                    },
                    {
                        "@pid": "75/8194",
                        "text": "Cristiano Giuffrida"
                    }
                ]
            },
            "title": "GhostRace: Exploiting and Mitigating Speculative Race Conditions.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RagabMKG24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/ragab",
            "url": "https://dblp.org/rec/conf/uss/RagabMKG24",
            "abstract": "Race conditions arise when multiple threads attempt to access a shared resource without proper synchronization, often leading to vulnerabilities such as concurrent use-after-free. To mitigate their occurrence, operating systems rely on synchronization primitives such as mutexes, spinlocks, etc. In this paper, we present GhostRace, the first security analysis of these primitives on speculatively executed code paths. Our key finding is that all the common synchronization primitives can be microarchitecturally bypassed on speculative paths, turning all architecturally race-free critical regions into Speculative Race Conditions (SRCs) . To study the severity of SRCs, we focus on Speculative Concurrent Use-After-Free (SCUAF) and uncover 1,283 potentially exploitable gadgets in the Linux kernel. Moreover, we demonstrate that SCUAF information disclosure attacks against the kernel are not only practical, but that their reliability can closely match that of traditional Spectre attacks, with our proof of concept leaking kernel memory at 12 KB/s. Crucially, we develop a new technique to create an unbounded race window, accommodating an arbitrary number of SCUAF invocations required by an end-to-end attack in a single race window. To address the new attack surface, we also propose a generic SRC mitigation to harden all the affected synchronization primitives on Linux. Our mitigation requires minimal kernel changes and incurs only \u2248 5% geomean performance overhead on LMBench.",
            "keywords": [
                "Speculative Execution",
                "Race Conditions",
                "Synchronization Primitives",
                "Use-After-Free Vulnerabilities",
                "Linux Kernel Security"
            ]
        },
        "url": "URL#379657",
        "sema_paperId": "9effc89e87a463499c2213a30823f3706910eaaa"
    },
    {
        "@score": "1",
        "@id": "379658",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "338/5678",
                        "text": "Mirza Masfiqur Rahman"
                    },
                    {
                        "@pid": "229/5471",
                        "text": "Imtiaz Karim"
                    },
                    {
                        "@pid": "b/ElisaBertino",
                        "text": "Elisa Bertino"
                    }
                ]
            },
            "title": "CellularLint: A Systematic Approach to Identify Inconsistent Behavior in Cellular Network Specifications.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RahmanKB24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/rahman",
            "url": "https://dblp.org/rec/conf/uss/RahmanKB24",
            "abstract": "In recent years, there has been a growing focus on scrutinizing the security of cellular networks, often attributing security vulnerabilities to issues in the underlying protocol design descriptions. These protocol design specifications, typically extensive documents that are thousands of pages long, can harbor inaccuracies, underspecifications, implicit assumptions, and internal inconsistencies. In light of the evolving landscape, we introduce CellularLint--a semi-automatic framework for inconsistency detection within the standards of 4G and 5G, capitalizing on a suite of natural language processing techniques. Our proposed method uses a revamped few-shot learning mechanism on domain-adapted large language models. Pre-trained on a vast corpus of cellular network protocols, this method enables CellularLint to simultaneously detect inconsistencies at various levels of semantics and practical use cases. In doing so, CellularLint significantly advances the automated analysis of protocol specifications in a scalable fashion. In our investigation, we focused on the Non-Access Stratum (NAS) and the security specifications of 4G and 5G networks, ultimately uncovering 157 inconsistencies with 82.67% accuracy. After verification of these inconsistencies on open-source implementations and 17 commercial devices, we confirm that they indeed have a substantial impact on design decisions, potentially leading to concerns related to privacy, integrity, availability, and interoperability.",
            "keywords": [
                "Cellular Network Protocols",
                "Inconsistency Detection",
                "4G and 5G Standards",
                "Natural Language Processing",
                "Non-Access Stratum (NAS)"
            ]
        },
        "url": "URL#379658",
        "sema_paperId": "e05cf0fbd82a98d4a1b7e4033b65e0accabae4e0"
    },
    {
        "@score": "1",
        "@id": "379659",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "219/8336",
                        "text": "Rohit Raj"
                    },
                    {
                        "@pid": "371/8924",
                        "text": "Mridul Newar"
                    },
                    {
                        "@pid": "87/8324",
                        "text": "Mainack Mondal"
                    }
                ]
            },
            "title": "&quot;I just hated it and I want my money back&quot;: Data-driven Understanding of Mobile VPN Service Switching Preferences in The Wild.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RajNM24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/raj",
            "url": "https://dblp.org/rec/conf/uss/RajNM24",
            "abstract": "Virtual Private Networks (VPNs) are a crucial Privacy-Enhancing Technology (PET) leveraged by millions of users and catered by multiple VPN providers worldwide; thus, understanding the user preferences for the choice of VPN apps should be of importance and interest to the security community. To that end, prior studies looked into the usage, awareness and adoption of VPN users and the perceptions of providers. However, no study so far has looked into the user preferences and underlying reasons for switching among VPN providers and identified features that presumably enhance users' VPN experience. This work aims to bridge this gap and shed light on the underlying factors that drive existing users when they switch from one VPN to another. In this work, we analyzed over 1.3 million reviews from 20 leading VPN apps, identifying 1,305 explicit mentions and intents to switch. Our NLP-based analysis unveiled distinct clusters of factors motivating users to switch. An examination of 376 blogs from six popular VPN recommendation sites revealed biases in the content, and we found ignorance towards user preferences. We conclude by identifying the key implications of our work for different stakeholders. The data and code for this work is available at https://github.com/Mainack/switch-vpn-datacode-sec24.",
            "keywords": [
                "Mobile VPN Services",
                "User Preferences",
                "VPN Provider Switching",
                "User Experience Factors",
                "NLP Analysis of Reviews"
            ]
        },
        "url": "URL#379659",
        "sema_paperId": "12577dc3928c7229f22309ff7dfd08e603e01f83"
    },
    {
        "@score": "1",
        "@id": "379660",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "270/2465",
                        "text": "Reethika Ramesh"
                    },
                    {
                        "@pid": "79/10265",
                        "text": "Philipp Winter"
                    },
                    {
                        "@pid": "381/1610",
                        "text": "Sam Korman"
                    },
                    {
                        "@pid": "24/973",
                        "text": "Roya Ensafi"
                    }
                ]
            },
            "title": "CalcuLatency: Leveraging Cross-Layer Network Latency Measurements to Detect Proxy-Enabled Abuse.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RameshWKE24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/ramesh",
            "url": "https://dblp.org/rec/conf/uss/RameshWKE24",
            "abstract": "Efforts from emerging technology companies aim to democ-ratize the ad delivery ecosystem and build systems that are privacy-centric and even share ad revenue benefits with their users. Other providers offer remuneration for users on their platform for interacting with and making use of services. But these efforts may suffer from coordinated abuse efforts aiming to defraud them. Attackers can use VPNs and proxies to fabricate their geolocation and earn disproportionate rewards. Balancing proxy-enabled abuse-prevention techniques with a privacy-focused business model is a hard challenge. Can service providers use minimal connection features to infer proxy use without jeopardizing user privacy? In this paper, we build and evaluate a solution, CalcuLa-tency, that incorporates various network latency measurement techniques and leverage the application-layer and network-layer differences in roundtrip-times when a user connects to the service using a proxy. We evaluate our four measurement techniques individually, and as an integrated system using a two-pronged evaluation. CalcuLatency is an easy-to-deploy, open-source solution that can serve as an inexpensive first-step to label proxies.",
            "keywords": [
                "Network Latency Measurement",
                "Proxy Detection",
                "Ad Delivery Ecosystem",
                "Coordinated Abuse",
                "Privacy-Preserving Techniques"
            ]
        },
        "url": "URL#379660",
        "sema_paperId": "9ee45ce109085e5ce707b55500e38d8a8d0a82f2"
    },
    {
        "@score": "1",
        "@id": "379661",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "252/6200",
                        "text": "Lana Ramjit"
                    },
                    {
                        "@pid": "381/1643",
                        "text": "Natalie Dolci"
                    },
                    {
                        "@pid": "r/FrancescaRossi",
                        "text": "Francesca Rossi 0001"
                    },
                    {
                        "@pid": "381/1602",
                        "text": "Ryan Garcia"
                    },
                    {
                        "@pid": "26/3399",
                        "text": "Thomas Ristenpart"
                    },
                    {
                        "@pid": "356/3064",
                        "text": "Dana Cuomo"
                    }
                ]
            },
            "title": "Navigating Traumatic Stress Reactions During Computer Security Interventions.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RamjitD0GRC24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/ramjit",
            "url": "https://dblp.org/rec/conf/uss/RamjitD0GRC24",
            "abstract": "At-risk populations need direct support from computer security and privacy consultants, what we refer to as a security intervention. However, at-risk populations often face security threats while experiencing traumatic events and ensuing traumatic stress reactions. While existing security interventions follow broad principles for trauma-informed care, no prior work has studied the domain-specific effects of trauma on intervention efficacy, nor how to improve the ability of tech abuse specialists to navigate them. We perform a multi-part study into traumatic stress in the context of digital security interventions. We first interview technology consultants from three computer security clinics that help intimate partner violence survivors with technology abuse. We identify four challenges reported by consultants emanating out of traumatic stress, some of which appear to be unique to the digital security context. To better understand these challenges, we analyze transcripts of sessions at one of the clinics, extracting five patterns of how stress reactions affect consultations. We use our findings to develop new recommended best practices, including a new intervention protocol design to help guide security interventions.",
            "keywords": [
                "Trauma-Informed Care",
                "Digital Security Interventions",
                "Technology Abuse",
                "Traumatic Stress Reactions",
                "Intimate Partner Violence"
            ]
        },
        "url": "URL#379661",
        "sema_paperId": "607d096429cfd0fdc345d0e8eacfb0c2895b927e"
    },
    {
        "@score": "1",
        "@id": "379662",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "327/6458",
                        "text": "Harshini Sri Ramulu"
                    },
                    {
                        "@pid": "381/1689",
                        "text": "Helen Schmitt"
                    },
                    {
                        "@pid": "203/1800",
                        "text": "Dominik Wermke"
                    },
                    {
                        "@pid": "132/9687",
                        "text": "Yasemin Acar"
                    }
                ]
            },
            "title": "Security and Privacy Software Creators&apos; Perspectives on Unintended Consequences.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RamuluSWA24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/ramulu",
            "url": "https://dblp.org/rec/conf/uss/RamuluSWA24",
            "abstract": "Security & Privacy (S&P) software is created to have positive impacts on people: to protect them from surveillance and attacks, enhance their privacy, and keep them safe. Despite these positive intentions, S&P software can have unintended consequences, such as enabling and protecting criminals, mis-leading people into using the software with a false sense of security, and being inaccessible to users without strong technical backgrounds or with specific accessibility needs. In this study, through 14 semi-structured expert interviews with S&P software creators, we explore whether and how S&P software creators foresee and mitigate unintended consequences. We find that unintended consequences are often overlooked and ignored. When addressed, they are done in unstructured ways\u2014often ad hoc and just based on user feedback\u2014thereby shifting the burden to users. To reduce this burden on users and more effectively create positive change, we recommend S&P software creators to proactively consider and mitigate un-intended consequences through increasing awareness and education, promoting accountability at the organizational level to mitigate issues, and using systematic toolkits for anticipating impacts.",
            "keywords": [
                "Security and Privacy Software",
                "Unintended Consequences",
                "User Awareness",
                "Software Accessibility",
                "Mitigation Strategies"
            ]
        },
        "url": "URL#379662",
        "sema_paperId": "26ece85881a397b6d14b046d0450309b9dce1a37"
    },
    {
        "@score": "1",
        "@id": "379663",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "303/1128",
                        "text": "Zhenghang Ren"
                    },
                    {
                        "@pid": "350/5035",
                        "text": "Mingxuan Fan"
                    },
                    {
                        "@pid": "42/898-7",
                        "text": "Zilong Wang 0007"
                    },
                    {
                        "@pid": "155/4434",
                        "text": "Junxue Zhang 0001"
                    },
                    {
                        "@pid": "257/6290",
                        "text": "Chaoliang Zeng"
                    },
                    {
                        "@pid": "128/9270",
                        "text": "Zhicong Huang"
                    },
                    {
                        "@pid": "78/10002",
                        "text": "Cheng Hong"
                    },
                    {
                        "@pid": "c/KaiChen5",
                        "text": "Kai Chen 0005"
                    }
                ]
            },
            "title": "Accelerating Secure Collaborative Machine Learning with Protocol-Aware RDMA.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RenF00ZHH024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/ren",
            "url": "https://dblp.org/rec/conf/uss/RenF00ZHH024",
            "abstract": "Secure Collaborative Machine Learning (SCML) suffers from high communication cost caused by secure computation protocols. While modern datacenters offer high-bandwidth and low-latency networks with Remote Direct Memory Access (RDMA) capability, existing SCML implementation remains to use TCP sockets, leading to inef\ufb01ciency. We present CORA 1 to implement SCML over RDMA. By us-ing a protocol-aware design, CORA identi\ufb01es the protocol used by the SCML program and sends messages directly to the remote party\u2019s protocol buffer, improving the ef\ufb01ciency of message exchange. CORA exploits the chance that the SCML task is determined before execution and the pattern is largely input-irrelevant, so that CORA can plan message destinations on remote hosts at compile time. CORA can be readily deployed with existing SCML frameworks such as Piranha with its socket-like interface. We evaluate CORA in SCML training tasks, and our results show that CORA can reduce communication cost by up to 11 \u21e5 and achieve 1 . 2 \u21e5\ufffd 4 . 2 \u21e5 end-to-end speedup over TCP in SCML training.",
            "keywords": [
                "Secure Collaborative Machine Learning",
                "Remote Direct Memory Access",
                "Communication Efficiency",
                "Protocol-Aware Design",
                "Message Exchange Optimization"
            ]
        },
        "url": "URL#379663",
        "sema_paperId": "5b63d4afab7d9503f684e3c1925b68b750e7f887"
    },
    {
        "@score": "1",
        "@id": "379664",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "263/6877",
                        "text": "Niklas Risse"
                    },
                    {
                        "@pid": "91/7541",
                        "text": "Marcel B\u00f6hme"
                    }
                ]
            },
            "title": "Uncovering the Limits of Machine Learning for Automatic Vulnerability Detection.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RisseB24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/risse",
            "url": "https://dblp.org/rec/conf/uss/RisseB24",
            "abstract": "Recent results of machine learning for automatic vulnerability detection (ML4VD) have been very promising. Given only the source code of a function $f$, ML4VD techniques can decide if $f$ contains a security flaw with up to 70% accuracy. However, as evident in our own experiments, the same top-performing models are unable to distinguish between functions that contain a vulnerability and functions where the vulnerability is patched. So, how can we explain this contradiction and how can we improve the way we evaluate ML4VD techniques to get a better picture of their actual capabilities? In this paper, we identify overfitting to unrelated features and out-of-distribution generalization as two problems, which are not captured by the traditional approach of evaluating ML4VD techniques. As a remedy, we propose a novel benchmarking methodology to help researchers better evaluate the true capabilities and limits of ML4VD techniques. Specifically, we propose (i) to augment the training and validation dataset according to our cross-validation algorithm, where a semantic preserving transformation is applied during the augmentation of either the training set or the testing set, and (ii) to augment the testing set with code snippets where the vulnerabilities are patched. Using six ML4VD techniques and two datasets, we find (a) that state-of-the-art models severely overfit to unrelated features for predicting the vulnerabilities in the testing data, (b) that the performance gained by data augmentation does not generalize beyond the specific augmentations applied during training, and (c) that state-of-the-art ML4VD techniques are unable to distinguish vulnerable functions from their patches.",
            "keywords": [
                "Automatic Vulnerability Detection",
                "Code Analysis",
                "Overfitting",
                "Data Augmentation",
                "Out-of-Distribution Generalization"
            ]
        },
        "url": "URL#379664",
        "sema_paperId": "1d788c10d9b8c52bb451f2dd4400583e7f9d731c"
    },
    {
        "@score": "1",
        "@id": "379665",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "359/3221",
                        "text": "Huanyao Rong"
                    },
                    {
                        "@pid": "87/6465",
                        "text": "Wei You"
                    },
                    {
                        "@pid": "06/6268",
                        "text": "Xiaofeng Wang 0006"
                    },
                    {
                        "@pid": "223/2627",
                        "text": "Tianhao Mao"
                    }
                ]
            },
            "title": "Toward Unbiased Multiple-Target Fuzzing with Path Diversity.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RongY0M24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/rong",
            "url": "https://dblp.org/rec/conf/uss/RongY0M24",
            "abstract": "In this paper, we propose a novel directed fuzzing solution named AFLRun, which features target path-diversity metric and unbiased energy assignment. Firstly, we develop a new coverage metric by maintaining extra virgin map for each covered target to track the coverage status of seeds that hit the target. This approach enables the storage of waypoints into the corpus that hit a target through interesting path, thus enriching the path diversity for each target. Additionally, we propose a corpus-level energy assignment strategy that guarantees fairness for each target. AFLRun starts with uniform target weight and propagates this weight to seeds to get a desired seed weight distribution. By assigning energy to each seed in the corpus according to such desired distribution, a precise and unbiased energy assignment can be achieved. We built a prototype system and assessed its performance using a standard benchmark and several extensively fuzzed real-world applications. The evaluation results demonstrate that AFLRun outperforms state-of-the-art fuzzers in terms of vulnerability detection, both in quantity and speed. Moreover, AFLRun uncovers 29 previously unidentified vulnerabilities, including 8 CVEs, across four distinct programs.",
            "keywords": [
                "Directed Fuzzing",
                "Path Diversity",
                "Vulnerability Detection",
                "Energy Assignment",
                "Coverage Metric"
            ]
        },
        "url": "URL#379665",
        "sema_paperId": "51afe2ce9af6e368df217b790a8781017db6a962"
    },
    {
        "@score": "1",
        "@id": "379666",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "244/5274",
                        "text": "Sebastian Roth"
                    },
                    {
                        "@pid": "181/8259",
                        "text": "Lea Gr\u00f6ber"
                    },
                    {
                        "@pid": "381/1571",
                        "text": "Philipp Baus"
                    },
                    {
                        "@pid": "128/4803",
                        "text": "Katharina Krombholz"
                    },
                    {
                        "@pid": "136/8343",
                        "text": "Ben Stock"
                    }
                ]
            },
            "title": "Trust Me If You Can - How Usable Is Trusted Types In Practice?",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RothGBKS24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/roth",
            "url": "https://dblp.org/rec/conf/uss/RothGBKS24",
            "abstract": "Many online services deal with sensitive information such as credit card data, making those applications a prime target for adversaries, e.g., through Cross-Site Scripting (XSS) attacks. Moreover, Web applications nowadays deploy their functionality via client-side code to lower the server\u2019s load, require fewer page reloads, and allow Web applications to work even if the connection is interrupted. Given this paradigm shift of increasing complexity on the browser side, client-side security issues such as client-side XSS are getting more prominent these days. A solution already deployed in server-side applications of major companies like Google is to use type-safe data, where potentially attacker-controlled string data can never be output with sanitization. The newly introduced Trusted Types API offers an analogous solution for client-side XSS. With Trusted Types, the browser enforces that no input can be passed to an execution sink without being sanitized first. Thus, a developer\u2019s only remaining task \u2013 in theory \u2013 is to create a proper sanitizer. This study aims to uncover roadblocks that occur during the deployment of the mechanism and strategies on how developers can circumvent those problems by conducting a semi-structured interview, including a coding task with 13 real-world Web developers. Our work also identifies key weaknesses in the design and documentation of Trusted Types, which we urge the standardization body to incorporate before the Trusted Types becomes a standard.",
            "keywords": [
                "Trusted Types",
                "Cross-Site Scripting (XSS)",
                "Client-Side Security",
                "Sanitization",
                "Developer Challenges"
            ]
        },
        "url": "URL#379666",
        "sema_paperId": "b180189c8795cbad55129e7d4195b0d57e35ec4b"
    },
    {
        "@score": "1",
        "@id": "379667",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "00/6232",
                        "text": "Guy N. Rothblum"
                    },
                    {
                        "@pid": "65/2027",
                        "text": "Eran Omri"
                    },
                    {
                        "@pid": "233/6535",
                        "text": "Junye Chen"
                    },
                    {
                        "@pid": "06/3696",
                        "text": "Kunal Talwar"
                    }
                ]
            },
            "title": "PINE: Efficient Verification of a Euclidean Norm Bound of a Secret-Shared Vector.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RothblumOCT24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/rothblum",
            "url": "https://dblp.org/rec/conf/uss/RothblumOCT24",
            "abstract": "Secure aggregation of high-dimensional vectors is a fundamental primitive in federated statistics and learning. A two-server system such as PRIO allows for scalable aggregation of secret-shared vectors. Adversarial clients might try to manipulate the aggregate, so it is important to ensure that each (secret-shared) contribution is well-formed. In this work, we focus on the important and well-studied goal of ensuring that each contribution vector has bounded Euclidean norm. Existing protocols for ensuring bounded-norm contributions either incur a large communication overhead, or only allow for approximate verification of the norm bound. We propose P rivate I nexpensive N orm E nforcement (PINE): a new protocol that allows exact norm verification with little communication overhead. For high-dimensional vectors, our approach has a communication overhead of a few percent, compared to the 16-32x overhead of previous approaches.",
            "keywords": [
                "Federated Learning",
                "Secret Sharing",
                "Norm Verification",
                "Communication Overhead",
                "Euclidean Norm Bound"
            ]
        },
        "url": "URL#379667",
        "sema_paperId": "498b038116ba22a205b30e3afd520045dd297862"
    },
    {
        "@score": "1",
        "@id": "379668",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "311/2792",
                        "text": "Amir Sabzi"
                    },
                    {
                        "@pid": "358/9292",
                        "text": "Rut Vora"
                    },
                    {
                        "@pid": "192/1291",
                        "text": "Swati Goswami"
                    },
                    {
                        "@pid": "s/MargoISeltzer",
                        "text": "Margo I. Seltzer"
                    },
                    {
                        "@pid": "130/0417",
                        "text": "Mathias L\u00e9cuyer"
                    },
                    {
                        "@pid": "161/0164",
                        "text": "Aastha Mehta"
                    }
                ]
            },
            "title": "NetShaper: A Differentially Private Network Side-Channel Mitigation System.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SabziVGSLM24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/sabzi",
            "url": "https://dblp.org/rec/conf/uss/SabziVGSLM24",
            "abstract": "The widespread adoption of encryption in network protocols has significantly improved the overall security of many Internet applications. However, these protocols cannot prevent network side-channel leaks -- leaks of sensitive information through the sizes and timing of network packets. We present NetShaper, a system that mitigates such leaks based on the principle of traffic shaping. NetShaper's traffic shaping provides differential privacy guarantees while adapting to the prevailing workload and congestion condition, and allows configuring a tradeoff between privacy guarantees, bandwidth and latency overheads. Furthermore, NetShaper provides a modular and portable tunnel endpoint design that can support diverse applications. We present a middlebox-based implementation of NetShaper and demonstrate its applicability in a video streaming and a web service application.",
            "keywords": [
                "Network Security",
                "Differential Privacy",
                "Traffic Shaping",
                "Side-Channel Leaks",
                "Packet Timing"
            ]
        },
        "url": "URL#379668",
        "sema_paperId": "c80bbcf8d540a49330733d024a92e1b30b3e54cf"
    },
    {
        "@score": "1",
        "@id": "379669",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "43/10041",
                        "text": "Yukiko Sawaya"
                    },
                    {
                        "@pid": "371/7819",
                        "text": "Sarah Lu"
                    },
                    {
                        "@pid": "86/7950",
                        "text": "Takamasa Isohara"
                    },
                    {
                        "@pid": "136/8393",
                        "text": "Mahmood Sharif"
                    }
                ]
            },
            "title": "A High Coverage Cybersecurity Scale Predictive of User Behavior.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SawayaLIS24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/sawaya",
            "url": "https://dblp.org/rec/conf/uss/SawayaLIS24",
            "abstract": "Psychometric security scales can enable various crucial tasks (e.g., measuring changes in user behavior over time), but, unfortunately, they often fail to accurately predict actual user behavior. We hypothesize that one can enhance prediction accuracy via more comprehensive scales measuring a wider range of security-related factors. To test this hypothesis, we ran a series of four online studies with a total of 1,471 participants. First, we developed the extended security behavior scale (ESBS), a high-coverage scale containing substantially more items than prior ones, and collected responses to characterize its underlying structure. Then, we conducted a follow-up study to confirm ESBS\u2019s structural validity and reliability. Finally, over the course of two studies, we elicited user responses to our scale and prior ones while measuring three security behaviors reflected by Internet browser data. Then, we constructed predictive machine-learning models and found that ESBS can predict these behaviors with statistically significantly higher accuracy than prior scales (6.17%\u20138.53% ROC AUC), thus supporting our hypothesis.",
            "keywords": [
                "Cybersecurity Behavior",
                "Extended Security Behavior Scale",
                "User Behavior Prediction",
                "Psychometric Scales",
                "Predictive Accuracy"
            ]
        },
        "url": "URL#379669",
        "sema_paperId": "f0487b0b7866ae24634d489ee34097b6d75a8624"
    },
    {
        "@score": "1",
        "@id": "379670",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "201/6435",
                        "text": "Matteo Scarlata"
                    },
                    {
                        "@pid": "225/9712",
                        "text": "Matilda Backendal"
                    },
                    {
                        "@pid": "266/1494",
                        "text": "Miro Haller"
                    }
                ]
            },
            "title": "MFKDF: Multiple Factors Knocked Down Flat.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ScarlataBH24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/scarlata",
            "url": "https://dblp.org/rec/conf/uss/ScarlataBH24",
            "abstract": "Nair and Song (USENIX 2023) introduce the concept of a Multi-Factor Key Derivation Function (MFKDF), along with constructions and a security analysis. MFKDF integrates dynamic authentication factors, such as HOTP and hardware tokens, into password-based key derivation. The aim is to improve the security of password-derived keys, which can then be used for encryption or as an alternative to multi-factor authentication. The authors claim an exponential security improvement compared to traditional password-based key derivation functions (PBKDF).\nWe show that the MFKDF constructions proposed by Nair and Song fall short of the stated security goals. Underspecified cryptographic primitives and the lack of integrity of the MFKDF state lead to several attacks, ranging from full key recovery when an HOTP factor is compromised, to bypassing factors entirely or severely reducing their entropy. We reflect on the different threat models of key-derivation and authentication, and conclude that MFKDF is always weaker than plain PBKDF and multi-factor authentication in each setting.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-scarlata.pdf",
            "keywords": [
                "Multi-Factor Key Derivation Function",
                "Password-Based Key Derivation",
                "Dynamic Authentication Factors",
                "Cryptographic Security Analysis",
                "Key Recovery Attacks"
            ]
        },
        "url": "URL#379670"
    },
    {
        "@score": "1",
        "@id": "379671",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "277/2071",
                        "text": "Joschua Schilling"
                    },
                    {
                        "@pid": "268/1769",
                        "text": "Andreas Wendler"
                    },
                    {
                        "@pid": "280/7837",
                        "text": "Philipp G\u00f6rz"
                    },
                    {
                        "@pid": "331/2788",
                        "text": "Nils Bars"
                    },
                    {
                        "@pid": "207/4015",
                        "text": "Moritz Schloegel"
                    },
                    {
                        "@pid": "h/ThorstenHolz",
                        "text": "Thorsten Holz"
                    }
                ]
            },
            "title": "A Binary-level Thread Sanitizer or Why Sanitizing on the Binary Level is Hard.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SchillingWGBSH24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/schilling",
            "url": "https://dblp.org/rec/conf/uss/SchillingWGBSH24",
            "abstract": "Dynamic software testing methods, such as fuzzing, have become a popular and effective method for detecting many types of faults in programs. While most research focuses on targets for which source code is available, much of the software used in practice is only available as closed source. Testing software without having access to source code forces a user to resort to binary-only testing methods, which are typically slower and lack support for crucial features, such as advanced bug oracles in the form of sanitizers , i. e., dynamic methods to detect faults based on unde\ufb01ned or suspicious behavior. Almost all existing sanitizers work by injecting instrumentation at compile time, requiring access to the target\u2019s source code. In this paper, we systematically identify the key challenges of applying sanitizers to binary-only targets. As a result of our analysis, we present the design and implementation of BIN TSAN, an approach to realize the data race detector TSAN targeting binary-only Linux x86-64 targets. We systematically evaluate BIN TSAN for correctness, effectiveness, and performance. We \ufb01nd that our approach has a run-time overhead of only 15% compared to source-based TSAN. Compared to existing binary solutions, our approach has better performance (up to 5.0\u00d7 performance improvement) and precision, while preserving compatibility with the compiler-based TSAN.",
            "keywords": [
                "Binary Analysis",
                "Dynamic Testing",
                "Data Race Detection",
                "Binary Sanitizers",
                "Closed Source Software"
            ]
        },
        "url": "URL#379671",
        "sema_paperId": "c37ceb3effa146a2dfada412e257b27da0ce900f"
    },
    {
        "@score": "1",
        "@id": "379672",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "348/6844",
                        "text": "Benedict Schl\u00fcter"
                    },
                    {
                        "@pid": "298/5443",
                        "text": "Supraja Sridhara"
                    },
                    {
                        "@pid": "333/1328",
                        "text": "Mark Kuhne"
                    },
                    {
                        "@pid": "348/6664",
                        "text": "Andrin Bertschi"
                    },
                    {
                        "@pid": "136/8404",
                        "text": "Shweta Shinde"
                    }
                ]
            },
            "title": "HECKLER: Breaking Confidential VMs with Malicious Interrupts.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SchluterSKBS24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/schl%C3%BCter",
            "url": "https://dblp.org/rec/conf/uss/SchluterSKBS24",
            "abstract": "Hardware-based Trusted execution environments (TEEs) offer an isolation granularity of virtual machine abstraction. They provide confidential VMs (CVMs) that host security-sensitive code and data. AMD SEV-SNP and Intel TDX enable CVMs and are now available on popular cloud platforms. The untrusted hypervisor in these settings is in control of several resource management and configuration tasks, including interrupts. We present Heckler, a new attack wherein the hypervisor injects malicious non-timer interrupts to break the confidentiality and integrity of CVMs. Our insight is to use the interrupt handlers that have global effects, such that we can manipulate a CVM's register states to change the data and control flow. With AMD SEV-SNP and Intel TDX, we demonstrate Heckler on OpenSSH and sudo to bypass authentication. On AMD SEV-SNP we break execution integrity of C, Java, and Julia applications that perform statistical and text analysis. We explain the gaps in current defenses and outline guidelines for future defenses.",
            "keywords": [
                "Trusted Execution Environments",
                "Confidential VMs",
                "Hypervisor Attacks",
                "Malicious Interrupts",
                "Execution Integrity"
            ]
        },
        "url": "URL#379672",
        "sema_paperId": "86bcc17bb001522adfeada1a77134eae6adc449f"
    },
    {
        "@score": "1",
        "@id": "379673",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "323/0206",
                        "text": "Markus Sch\u00f6ps"
                    },
                    {
                        "@pid": "308/6435",
                        "text": "Marco Gutfleisch"
                    },
                    {
                        "@pid": "381/1581",
                        "text": "Eric Wolter"
                    },
                    {
                        "@pid": "s/MASasse",
                        "text": "M. Angela Sasse"
                    }
                ]
            },
            "title": "Simulated Stress: A Case Study of the Effects of a Simulated Phishing Campaign on Employees&apos; Perception, Stress and Self-Efficacy.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SchopsGWS24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/sch%C3%B6ps",
            "url": "https://dblp.org/rec/conf/uss/SchopsGWS24",
            "abstract": "Many organizations are concerned about being attacked by phishing emails and buy Simulated Phishing Campaigns (SPC) to measure and reduce their employees\u2019 susceptibility to these attacks. Whilst some prior studies reported reduced click rates after SPCs, others have raised concerns that it may have undesirable side effects: causing some employees stress, and/or reducing their self-efficacy. This would be counter-productive, since stress and self-efficacy play a key role in learning and behavior change. We report the first study in which stress and self-efficacy were measured with n = 408 employees immediately after they clicked on or reported a simulated phishing email they received as part of an SPC in a large organization. To obtain richer data how employees experienced the SPC, we conducted semi-structured inter-views with n = 21 employees. We find that participants who clicked on and reported simulated phishing emails generally perceived SPCs as positive and effective, even though recent research casts doubt on this effectiveness. We further find that participants who clicked on simulated phishing emails had significantly higher stress levels and significantly lower phishing self-efficacy than participants who reported them. We further discuss the impact of our findings and conclude that the effect of SPCs on the perceived stress of employees is an important relationship that needs to be investigated in future studies.",
            "keywords": [
                "Simulated Phishing Campaigns",
                "Employee Stress",
                "Self-Efficacy",
                "Phishing Susceptibility",
                "Employee Perception"
            ]
        },
        "url": "URL#379673",
        "sema_paperId": "9e29e8da676fef765c1ffcb74f58f14da58c9f1a"
    },
    {
        "@score": "1",
        "@id": "379674",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "279/3409",
                        "text": "Robin Leander Schr\u00f6der"
                    },
                    {
                        "@pid": "307/3291",
                        "text": "Stefan Gast"
                    },
                    {
                        "@pid": "22/2222-1",
                        "text": "Qian Guo 0001"
                    }
                ]
            },
            "title": "Divide and Surrender: Exploiting Variable Division Instruction Timing in HQC Key Recovery Attacks.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SchroderG024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/schr%C3%B6der",
            "url": "https://dblp.org/rec/conf/uss/SchroderG024",
            "abstract": "We uncover a critical side-channel vulnerability in the Hamming Quasi-Cyclic (HQC) round 4 optimized implementation arising due to the use of the modulo operator. In some cases, compilers optimize uses of the modulo operator with compile-time known divisors into constant-time Barrett reductions. However, this optimization is not guaranteed: for example, when a modulo operation is used in a loop the compiler may emit division (div) instructions which have variable execution time depending on the numerator. When the numerator depends on secret data, this may yield a timing side-channel. We name vulnerabilities of this kind Divide and Surrender (DaS) vulnerabilities.\nFor processors supporting Simultaneous Multithreading (SMT) we propose a new approach called DIV-SMT which enables precisely measuring small division timing variations using scheduler and/or execution unit contention. We show that using only 100 such side-channel traces we can build a Plaintext-Checking (PC) oracle with above 90% accuracy. Our approach might also prove applicable to other instances of the DaS vulnerability, such as KyberSlash. We stress that exploitation with DIV-SMT requires co-location of the attacker on the same physical core as the victim.\nWe then apply our methodology to HQC and present a novel way to recover HQC secret keys faster, achieving an 8-fold decrease in the number of idealized oracle queries when compared to previous approaches. Our new PC oracle attack uses our newly developed Zero Tester method to quickly determine whether an entire block of bits contains only zero-bits. The Zero Tester method enables the DIV-SMT powered attack on HQC-128 to complete in under 2 minutes on our targeted AMD Zen2 machine.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-schroder.pdf",
            "keywords": [
                "Hamming Quasi-Cyclic (HQC)",
                "Side-Channel Attacks",
                "Timing Vulnerabilities",
                "Key Recovery",
                "Divide and Surrender (DaS)"
            ]
        },
        "url": "URL#379674"
    },
    {
        "@score": "1",
        "@id": "379676",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "272/7031",
                        "text": "Fabian Schwarz"
                    },
                    {
                        "@pid": "08/6024",
                        "text": "Christian Rossow"
                    }
                ]
            },
            "title": "00SEVen - Re-enabling Virtual Machine Forensics: Introspecting Confidential VMs Using Privileged in-VM Agents.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SchwarzR24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/schwarz",
            "url": "https://dblp.org/rec/conf/uss/SchwarzR24",
            "abstract": "The security guarantees of confidential VMs (e.g., AMD's SEV) are a double-edged sword: Their protection against undesired VM inspection by malicious or compromised cloud operators inherently renders existing VM introspection (VMI) services infeasible. However, considering that these VMs particularly target sensitive workloads (e.g., finance), their customers demand secure forensic capabilities.\nIn this paper, we enable VM owners to remotely inspect their confidential VMs without weakening the VMs' protection against the cloud platform. In contrast to na\u00efve in-VM memory aggregation tools, our approach (dubbed 00SEVen) is isolated from strong in-VM attackers and thus resistant against kernel-level attacks, and it provides VMI features beyond memory access. 00SEVen leverages the recent intra-VM privilege domains of AMD SEV-SNP\u2014called VMPLs\u2014and extends the QEMU/KVM hypervisor to provide VMPL-aware network I/O and VMI-assisting hypercalls. That way, we can serve VM owners with a protected in-VM forensic agent. The agent provides VM owners with attested remote memory and VM register introspection, secure pausing of the analysis target, and page access traps and function traps, all isolated from the cloud platform (incl. hypervisor) and in-VM rootkits.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-schwarz.pdf",
            "keywords": [
                "Confidential Virtual Machines",
                "VM Introspection",
                "Forensic Capabilities",
                "In-VM Agents",
                "AMD SEV-SNP"
            ]
        },
        "url": "URL#379676",
        "sema_paperId": "0a701d787f6fb39d4da81a12dc7a28e9690c9b12"
    },
    {
        "@score": "1",
        "@id": "379677",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "353/6883",
                        "text": "Raphael Serafini"
                    },
                    {
                        "@pid": "287/4547",
                        "text": "Stefan Albert Horstmann"
                    },
                    {
                        "@pid": "201/9227",
                        "text": "Alena Naiakshina"
                    }
                ]
            },
            "title": "Engaging Company Developers in Security Research Studies: A Comprehensive Literature Review and Quantitative Survey.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SerafiniHN24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/serafini",
            "url": "https://dblp.org/rec/conf/uss/SerafiniHN24",
            "abstract": "Previous research demonstrated that company developers excel compared to freelancers and computer science students, with the corporate environment significantly influencing security and privacy behavior. Still, the challenge of recruiting a substantial number of company developers persists, primarily due to a lack of knowledge on how to motivate their participation in empirical research studies. To bridge this gap, we performed a literature review and identified a conspicuous absence of information regarding compensation and study length in the domain of security developer studies. To support researchers struggling with the recruitment of company developers, we conducted an extensive quantitative survey with 340 professionals. Our study revealed that 62.5% of developers prioritize security tasks over software engineering tasks, and 96.5% are willing to participate in security studies. Developers consistently ranked security higher than other barriers and motivators. However, repeat participants perceived security tasks as more challenging than first-time participants despite having 40% more general experience and 50% more security-related experience. Further, we discuss Qualtrics as a potential recruitment channel for engaging company developers, acknowledging various challenges. Based on our findings, we provide recommendations for recruiting a high number of company developers.",
            "keywords": [
                "Security Research Studies",
                "Company Developers",
                "Recruitment Challenges",
                "Motivation Factors",
                "Quantitative Survey"
            ]
        },
        "url": "URL#379677",
        "sema_paperId": "0ba5cce13b7b1f4c9b836bc243b04dc1fa7ab4b7"
    },
    {
        "@score": "1",
        "@id": "379678",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "62/6624",
                        "text": "William Seymour"
                    },
                    {
                        "@pid": "248/1666",
                        "text": "Noura Abdi"
                    },
                    {
                        "@pid": "190/2066",
                        "text": "Kopo M. Ramokapane"
                    },
                    {
                        "@pid": "237/9757",
                        "text": "Jide S. Edu"
                    },
                    {
                        "@pid": "56/9730",
                        "text": "Guillermo Suarez-Tangil"
                    },
                    {
                        "@pid": "18/4101",
                        "text": "Jose Such"
                    }
                ]
            },
            "title": "Voice App Developer Experiences with Alexa and Google Assistant: Juggling Risks, Liability, and Security.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SeymourARESS24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/seymour",
            "url": "https://dblp.org/rec/conf/uss/SeymourARESS24",
            "abstract": "Voice applications (voice apps) are a key element in Voice Assistant ecosystems such as Amazon Alexa and Google Assistant, as they provide assistants with a wide range of capabilities that users can invoke with a voice command. Most voice apps, however, are developed by third parties\u2014i.e., not by Amazon/Google\u2014and they are included in the ecosystem through marketplaces akin to smartphone app stores but with crucial differences, e.g., the voice app code is not hosted by the marketplace and is not run on the local device. Previous research has studied the security and privacy issues of voice apps in the wild, finding evidence of bad practices by voice app developers. However, developers' perspectives are yet to be explored.\nIn this paper, we report a qualitative study of the experiences of voice app developers and the challenges they face. Our findings suggest that: 1) developers face several risks due to liability pushed on to them by the more powerful voice assistant platforms, which are linked to negative privacy and security outcomes on voice assistant platforms; and 2) there are key issues around monetization, privacy, design, and testing rooted in problems with the voice app certification process. We discuss the implications of our results for voice app developers, platforms, regulators, and research on voice app development and certification.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-seymour.pdf",
            "keywords": [
                "Voice App Development",
                "Voice Assistant Ecosystems",
                "Developer Liability",
                "Privacy and Security Risks",
                "Voice App Certification Process"
            ]
        },
        "url": "URL#379678"
    },
    {
        "@score": "1",
        "@id": "379679",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "192/1361",
                        "text": "Michal Shagam"
                    },
                    {
                        "@pid": "180/7297",
                        "text": "Eyal Ronen"
                    }
                ]
            },
            "title": "Windows into the Past: Exploiting Legacy Crypto in Modern OS&apos;s Kerberos Implementation.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ShagamR24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/shagam",
            "url": "https://dblp.org/rec/conf/uss/ShagamR24",
            "abstract": "The Kerberos protocol is used by millions of users and network administrators worldwide for secure authentication, key distribution, and access control management to enterprise networks and services. Since its initial public deployment in 1989, the protocol has undergone many revisions to incorporate new cryptographic primitives and improve security. For example, initially based solely on users\u2019 passwords and symmetric cryptographic primitives, current implementations also support smartcard-based authentication with asymmetric cryptographic primitives for improved security. However, this iterative revision process has resulted in implementations riddled with legacy crypto primitives and protocol designs. In this work, we show how we can exploit this legacy crypto to completely break the security of the enterprise network. Firstly, while arguably more secure, smartcard-based authentication uses RSA encryption with the notorious PKCS #1 v1.5 padding scheme. Although the RSA decryption is done securely inside the smartcard, a non-constant time unpadding code runs on the client\u2019s CPU. This makes both Windows\u2019s and several Linux distributions\u2019 implementations vulnerable to the Bleichenbacher attack that can recover cryptographic session tokens. Secondly, we show that the RSA smartcard-based authentication does not provide forward secrecy to the cryptographic tokens that the server provisions to the client. Thirdly, we propose and analyze different algorithmic approaches to minimize the overhead required to handle noisy oracles in the Bleichenbacher attack. This general Bleichen-bacher attack analysis may be of independent interest. Finally, we demonstrate microarchitectural side channel-based end-to-end attacks on the Windows Kerberos implementation. We start by showing how to recover tokens used to encrypt session transferred remote files by Samba. We then show how to amplify the number of decryptions performed with a single user\u2019s PIN code input, allowing us to accelerate our attack and recover users\u2019 (and admins\u2019) credentials before expiration",
            "keywords": [
                "Kerberos Protocol",
                "Legacy Cryptography",
                "Bleichenbacher Attack",
                "Smartcard Authentication",
                "Microarchitectural Side Channels"
            ]
        },
        "url": "URL#379679",
        "sema_paperId": "d078b7376e05fa9aa09954a3da31813b09fde98e"
    },
    {
        "@score": "1",
        "@id": "379680",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "269/4753",
                        "text": "Miaomiao Shao"
                    },
                    {
                        "@pid": "49/999",
                        "text": "Yuxin Ding"
                    }
                ]
            },
            "title": "FVD-DPM: Fine-grained Vulnerability Detection via Conditional Diffusion Probabilistic Models.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ShaoD24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/shao",
            "url": "https://dblp.org/rec/conf/uss/ShaoD24",
            "abstract": "Software vulnerabilities pose a significant threat to software security. Nevertheless, existing vulnerability detection methods still struggle to effectively identify vulnerabilities and pinpoint vulnerable statements. In this paper, we introduce FVD-DPM: a novel Fine-grained Vulnerability Detection approach via a conditional Diffusion Probabilistic Model. FVD-DPM formalizes vulnerability detection as a diffusion-based graph-structured prediction problem. Firstly, it generates a new fine-grained code representation by extracting graph-level program slices from the Code Joint Graph. Then, a conditional diffusion probabilistic model is employed to model the node label distribution in the program slices, predicting which nodes are vulnerable. FVD-DPM achieves both precise vulnerability identification (slice-level detection) and vulnerability localization (statement-level detection). We evaluate FVD-DPM on five collected datasets and compare it against nine state-of-the-art vulnerability detection approaches. Experimental results demonstrate that FVD-DPM significantly outperforms the baseline approaches across various evaluation settings.",
            "keywords": [
                "Vulnerability Detection",
                "Diffusion Probabilistic Models",
                "Fine-grained Code Representation",
                "Vulnerability Localization",
                "Graph-structured Prediction"
            ]
        },
        "url": "URL#379680",
        "sema_paperId": "0b2befb7731d77cc6ccd332b0a8053350d83bb3c"
    },
    {
        "@score": "1",
        "@id": "379681",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "154/7105",
                        "text": "Filipo Sharevski"
                    },
                    {
                        "@pid": "354/8487",
                        "text": "Aziz Zeidieh"
                    }
                ]
            },
            "title": "Assessing Suspicious Emails with Banner Warnings Among Blind and Low-Vision Users in Realistic Settings.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SharevskiZ24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/sharevski",
            "url": "https://dblp.org/rec/conf/uss/SharevskiZ24",
            "abstract": "Warning users about suspicious emails usually happens through visual interventions such as banners. Evidence from laboratory experiments shows that email banner warnings are unsuitable for blind and low-vision (BLV) users as they tend to miss or make no use of them. However, the laboratory settings preclude a full understanding of how BLV users would realistically behave around these banner warnings because the experiments don\u2019t use the individuals\u2019 own email addresses, devices, or emails of their choice. To address this limitation, we devised a study with n =21 BLV email users in realistic settings . Our findings indicate that this user population misses or makes no use of Gmail and Outlook banner warnings because these are implemented in a narrow sense, that is, (i) they allow access to the warning text without providing context relevant to the risk of associated email, and (ii) the formatting, together with the possible actions, is confusing as to how a user should deal with the email in question. To address these barriers, our participants proposed designs to accommodate the accessibility preferences and usability habits of individuals with visual disabilities according to their capabilities to engage with email banner warnings.",
            "keywords": [
                "Email Accessibility",
                "Blind and Low-Vision Users",
                "Banner Warnings",
                "Usability Challenges",
                "Email Security Awareness"
            ]
        },
        "url": "URL#379681",
        "sema_paperId": "fed17466433d9328767304a6faf6d942b1f23bac"
    },
    {
        "@score": "1",
        "@id": "379682",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "221/3567",
                        "text": "Tanusree Sharma"
                    },
                    {
                        "@pid": "344/8877",
                        "text": "Lin Kyi"
                    },
                    {
                        "@pid": "w/YangWang5",
                        "text": "Yang Wang 0005"
                    },
                    {
                        "@pid": "130/0373",
                        "text": "Asia J. Biega"
                    }
                ]
            },
            "title": "&quot;I&apos;m not convinced that they don&apos;t collect more than is necessary&quot;: User-Controlled Data Minimization Design in Search Engines.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SharmaK0B24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/sharma",
            "url": "https://dblp.org/rec/conf/uss/SharmaK0B24",
            "abstract": "Data minimization is a legal and privacy-by-design principle mandating that online services collect only data that is necessary for pre-specified purposes. While the principle has thus far mostly been interpreted from a system-centered perspective, there is a lack of understanding about how data minimization could be designed from a user-centered perspective, and in particular, what factors might influence user decision-making with regard to the necessity of data for different processing purposes. To address this gap, in this paper, we gain a deeper understanding of users\u2019 design expectations and decision-making processes related to data minimization, focusing on a case study of search engines. We also elicit expert evaluations of the feasibility of user-generated design ideas. We conducted interviews with 25 end users and 10 experts from the EU and UK to provide concrete design recommendations for data minimization that incorporate user needs, concerns, and preferences. Our study (i) surfaces how users reason about the necessity of data in the context of search result quality, and (ii) examines the impact of several factors on user decision-making about data processing, including specific types of search data, or the volume and recency of data. Most participants emphasized the particular importance of data minimization in the context of sensitive searches, such as political, financial, or health-related search queries. In a think-aloud conceptual design session, participants recommended search profile customization as a solution for retaining data they considered necessary, as well as alert systems that would inform users to minimize data in instances of excessive collection. We propose actionable design features that could provide users with greater agency over their data through user-controlled data minimization , combined with relevant implementation insights from experts",
            "keywords": [
                "User-Controlled Data Minimization",
                "Search Engine Privacy",
                "Data Collection Necessity",
                "User Decision-Making",
                "Sensitive Search Queries"
            ]
        },
        "url": "URL#379682",
        "sema_paperId": "1fe77b67d2814f5d87d28aea0e0c8062a3cd3708"
    },
    {
        "@score": "1",
        "@id": "379683",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "148/9731",
                        "text": "Xinyue Shen"
                    },
                    {
                        "@pid": "142/6261",
                        "text": "Yiting Qu"
                    },
                    {
                        "@pid": "b/MichaelBackes1",
                        "text": "Michael Backes 0001"
                    },
                    {
                        "@pid": "06/6785-16",
                        "text": "Yang Zhang 0016"
                    }
                ]
            },
            "title": "Prompt Stealing Attacks Against Text-to-Image Generation Models.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ShenQ0024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/shen-xinyue",
            "url": "https://dblp.org/rec/conf/uss/ShenQ0024",
            "abstract": "Text-to-Image generation models have revolutionized the artwork design process and enabled anyone to create high-quality images by entering text descriptions called prompts. Creating a high-quality prompt that consists of a subject and several modifiers can be time-consuming and costly. In consequence, a trend of trading high-quality prompts on specialized marketplaces has emerged. In this paper, we perform the first study on understanding the threat of a novel attack, namely prompt stealing attack, which aims to steal prompts from generated images by text-to-image generation models. Successful prompt stealing attacks directly violate the intellectual property of prompt engineers and jeopardize the business model of prompt marketplaces. We first perform a systematic analysis on a dataset collected by ourselves and show that a successful prompt stealing attack should consider a prompt's subject as well as its modifiers. Based on this observation, we propose a simple yet effective prompt stealing attack, PromptStealer. It consists of two modules: a subject generator trained to infer the subject and a modifier detector for identifying the modifiers within the generated image. Experimental results demonstrate that PromptStealer is superior over three baseline methods, both quantitatively and qualitatively. We also make some initial attempts to defend PromptStealer. In general, our study uncovers a new attack vector within the ecosystem established by the popular text-to-image generation models. We hope our results can contribute to understanding and mitigating this emerging threat.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-shen-xinyue.pdf",
            "keywords": [
                "Text-to-Image Generation",
                "Prompt Engineering",
                "Prompt Stealing Attack",
                "Intellectual Property Theft",
                "Prompt Marketplace"
            ]
        },
        "url": "URL#379683"
    },
    {
        "@score": "1",
        "@id": "379684",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "322/0743",
                        "text": "Samiha Shimmi"
                    },
                    {
                        "@pid": "40/10048",
                        "text": "Ashiqur Rahman"
                    },
                    {
                        "@pid": "381/1670",
                        "text": "Mohan Gadde"
                    },
                    {
                        "@pid": "14/5114",
                        "text": "Hamed Okhravi"
                    },
                    {
                        "@pid": "150/9109",
                        "text": "Mona Rahimi"
                    }
                ]
            },
            "title": "VulSim: Leveraging Similarity of Multi-Dimensional Neighbor Embeddings for Vulnerability Detection.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ShimmiRGOR24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/shimmi",
            "url": "https://dblp.org/rec/conf/uss/ShimmiRGOR24",
            "abstract": "Despite decades of research in vulnerability detection, vulnerabilities in source code remain a growing problem, and more effective techniques are needed in this domain. To enhance software vulnerability detection, in this paper, we first show that various vulnerability classes in the C programming language share common characteristics, encompassing semantic, contextual, and syntactic properties. We then leverage this knowledge to enhance the learning process of Deep Learning (DL) models for vulnerability detection when only sparse data is available. To achieve this, we extract multiple dimensions of information from the available, albeit limited, data. We then consolidate this information into a unified space, allowing for the identification of similarities among vulnerabilities through nearest-neighbor embeddings. The combination of these steps allows us to improve the effectiveness and efficiency of vulnerability detection using DL models. Evaluation results demonstrate that our approach surpasses existing State-of-the-art (SOTA) models and exhibits strong performance on unseen data, thereby enhancing generalizability.",
            "keywords": [
                "Vulnerability Detection",
                "C Programming Language",
                "Deep Learning Models",
                "Multi-Dimensional Embeddings",
                "Similarity Identification"
            ]
        },
        "url": "URL#379684",
        "sema_paperId": "beca27d59016fa787c0dfcd6c93cfd29f9db2a09"
    },
    {
        "@score": "1",
        "@id": "379685",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "286/5330",
                        "text": "Ravindu De Silva"
                    },
                    {
                        "@pid": "144/1238-2",
                        "text": "Wenbo Guo 0002"
                    },
                    {
                        "@pid": "218/0179",
                        "text": "Nicola Ruaro"
                    },
                    {
                        "@pid": "180/7263",
                        "text": "Ilya Grishchenko"
                    },
                    {
                        "@pid": "k/ChristopherKruegel",
                        "text": "Christopher Kruegel"
                    },
                    {
                        "@pid": "v/GiovanniVigna",
                        "text": "Giovanni Vigna"
                    }
                ]
            },
            "title": "GuideEnricher: Protecting the Anonymity of Ethereum Mixing Service Users with Deep Reinforcement Learning.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Silva0RGKV24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/de-silva",
            "url": "https://dblp.org/rec/conf/uss/Silva0RGKV24",
            "abstract": "Mixing services are widely employed to enhance anonymity on public blockchains. However, recent research has shown that user identities and transaction associations can be derived even with mixing services. This is mainly due to the lack of guidelines for properly using these services. In fact, mixing service developers often provide guidebooks with lists of actions that might break anonymity, and hence, should be avoided. However, such guidebooks remain incomplete, leaving users unaware of potential actions that might compromise their anonymity. This highlights the necessity for providing users with a more comprehensive guidebook. Unfortunately, existing methods for compiling anonymity-compromising patterns rely on postmortem analyses, and they cannot proactively discover patterns before the mixing service is deployed. We introduce GuideEnricher, a proactive approach for extending user guidebooks with limited human intervention. Our key novelty is a deep reinforcement learning (DRL) agent, which automatically explores patterns for transferring tokens via a mixing service. We introduce two customized designs to better guide the agent in discovering yet-unknown anonymity-compromising patterns: design proper tasks for the agent that possibly lead to compromised anonymity, and include a rule-based detector to detect the known patterns. We train the agent to finish the task while evading the detector. Using a trained agent, we conduct a second analysis step, employing clustering methods and manual inspection, to extract yet-unknown patterns from the agent\u2019s actions. Through extensive evaluation, we demonstrate that GuideEnricher can train effective agents under multiple mixing services. We show that our agents facilitate the discovery of yet-unknown anonymity-compromising patterns. Furthermore,",
            "keywords": [
                "Ethereum Mixing Services",
                "Anonymity Preservation",
                "Deep Reinforcement Learning",
                "Anonymity-Compromising Patterns",
                "User Guidebooks"
            ]
        },
        "url": "URL#379685",
        "sema_paperId": "7fcac57f0bfed664f4326daa6e624a00e9027526"
    },
    {
        "@score": "1",
        "@id": "379686",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "252/4834",
                        "text": "Carter Slocum"
                    },
                    {
                        "@pid": "186/7504",
                        "text": "Yicheng Zhang"
                    },
                    {
                        "@pid": "353/2686",
                        "text": "Erfan Shayegani"
                    },
                    {
                        "@pid": "352/4841",
                        "text": "Pedram Zaree"
                    },
                    {
                        "@pid": "86/2654",
                        "text": "Nael B. Abu-Ghazaleh"
                    },
                    {
                        "@pid": "35/9005",
                        "text": "Jiasi Chen"
                    }
                ]
            },
            "title": "That Doesn&apos;t Go There: Attacks on Shared State in Multi-User Augmented Reality Applications.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SlocumZSZAC24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/slocum",
            "url": "https://dblp.org/rec/conf/uss/SlocumZSZAC24",
            "abstract": "Augmented Reality (AR) is expected to become a pervasive component in enabling shared virtual experiences. In order to facilitate collaboration among multiple users, it is crucial for multi-user AR applications to establish a consensus on the\"shared state\"of the virtual world and its augmentations, through which they interact within augmented reality spaces. Current methods to create and access shared state collect sensor data from devices (e.g., camera images), process them, and integrate them into the shared state. However, this process introduces new vulnerabilities and opportunities for attacks. Maliciously writing false data to\"poison\"the shared state is a major concern for the security of the downstream victims that depend on it. Another type of vulnerability arises when reading the shared state; by providing false inputs, an attacker can view hologram augmentations at locations they are not allowed to access. In this work, we demonstrate a series of novel attacks on multiple AR frameworks with shared states, focusing on three publicly-accessible frameworks. We show that these frameworks, while using different underlying implementations, scopes, and mechanisms to read from and write to the shared state, have shared vulnerability to a unified threat model. Our evaluation of these state-of-art AR applications demonstrates reliable attacks both on updating and accessing shared state across the different systems. To defend against such threats, we discuss a number of potential mitigation strategies that can help enhance the security of multi-user AR applications.",
            "keywords": [
                "Augmented Reality",
                "Multi-User Interaction",
                "Shared State",
                "Vulnerabilities",
                "Attacks on Shared State"
            ]
        },
        "url": "URL#379686",
        "sema_paperId": "4bca0efef8b3ce5514611c3caaaca40056142566"
    },
    {
        "@score": "1",
        "@id": "379687",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "328/4559",
                        "text": "Saidu Sokoto"
                    },
                    {
                        "@pid": "290/7735",
                        "text": "Leonhard Balduf"
                    },
                    {
                        "@pid": "294/8712",
                        "text": "Dennis Trautwein"
                    },
                    {
                        "@pid": "368/2907",
                        "text": "Yiluo Wei"
                    },
                    {
                        "@pid": "85/85",
                        "text": "Gareth Tyson"
                    },
                    {
                        "@pid": "99/11343",
                        "text": "Ignacio Castro"
                    },
                    {
                        "@pid": "62/7401",
                        "text": "Onur Ascigil"
                    },
                    {
                        "@pid": "p/GeorgePavlou",
                        "text": "George Pavlou"
                    },
                    {
                        "@pid": "06/10585",
                        "text": "Maciej Korczynski"
                    },
                    {
                        "@pid": "15/503-1",
                        "text": "Bj\u00f6rn Scheuermann 0001"
                    },
                    {
                        "@pid": "157/4436",
                        "text": "Michal Kr\u00f3l"
                    }
                ]
            },
            "title": "Guardians of the Galaxy: Content Moderation in the InterPlanetary File System.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SokotoBTWTCAPK024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/sokoto",
            "url": "https://dblp.org/rec/conf/uss/SokotoBTWTCAPK024",
            "abstract": "The InterPlanetary File System (IPFS) is one of the largest platforms in the growing \u201cDecentralized Web\u201d. The increasing popularity of IPFS has attracted large volumes of users and content. Unfortunately, some of this content could be considered \u201cproblematic\u201d. Content moderation is always hard. With a completely decentralized infrastructure and administration, content moderation in IPFS is even more difficult. In this paper, we examine this challenge. We identify, characterize, and measure the presence of problematic content in IPFS ( e.g. subject to takedown notices). Our analysis covers 368,762 files. We analyze the complete content moderation process including how these files are flagged, who hosts and retrieves them. We also measure the efficacy of the process. We analyze content submitted to denylist, showing that notable volumes of problematic content are served, and the lack of a centralized approach facilitates its spread. While we identify fast reactions to takedown requests, we also test the resilience of multiple gateways and show that existing means to filter problematic content can be circumvented. We end by proposing improvements to content moderation that result in 227% increase in the detection of phishing content and reduce the average time to filter such content by 43%.",
            "keywords": [
                "Decentralized Web",
                "InterPlanetary File System",
                "Content Moderation",
                "Problematic Content",
                "Takedown Notices"
            ]
        },
        "url": "URL#379687",
        "sema_paperId": "d19122c46914c0128a6fc27dbe42ef699e196503"
    },
    {
        "@score": "1",
        "@id": "379688",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "264/9973",
                        "text": "Flavien Solt"
                    },
                    {
                        "@pid": "272/8141",
                        "text": "Katharina Ceesay-Seitz"
                    },
                    {
                        "@pid": "121/2685",
                        "text": "Kaveh Razavi"
                    }
                ]
            },
            "title": "Cascade: CPU Fuzzing via Intricate Program Generation.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SoltCR24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/solt",
            "url": "https://dblp.org/rec/conf/uss/SoltCR24",
            "abstract": "Generating interesting test cases for CPU fuzzing is akin to generating programs that exercise unusual states inside the CPU. The performance of CPU fuzzing is heavily influenced by the quality of these programs and by the overhead of bug detection. Our analysis of existing state-of-the-art CPU fuzzers shows that they generate programs that are either overly simple or execute a small fraction of their instructions due to invalid control flows. Combined with expensive instruction-granular bug detection mechanisms, this leads to inefficient fuzzing campaigns. We present Cascade, a new approach for generating valid RISC-V programs of arbitrary length with highly randomized and interdependent control and data flows. Cascade relies on a new technique called asymmetric ISA pre-simulation for entangling control flows with data flows when generating programs. This entanglement results in non-termination when a program triggers a bug in the target CPU, enabling Cascade to detect a CPU bug at program granularity without introducing any runtime overhead. Our evaluation shows that long Cascade programs are more effective in exercising the CPU\u2019s internal design. Cascade achieves 28.2x to 97x more coverage than the state-of-the-art CPU fuzzers and uncovers 37 new bugs (28 new CVEs) in 5 RISC-V CPUs with varying degrees of complexity. The programs that trigger these bugs are long and intricate, impeding triaging. To address this challenge, Cascade features an automated pruning method that reduces a program to a minimal number of instructions that trigger the bug.",
            "keywords": [
                "CPU Fuzzing",
                "RISC-V",
                "Program Generation",
                "Control Flow",
                "Bug Detection"
            ]
        },
        "url": "URL#379688",
        "sema_paperId": "c76df245cdd929c9a9b564a8615fcf518f3f99ad"
    },
    {
        "@score": "1",
        "@id": "379689",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "252/4043",
                        "text": "Ananta Soneji"
                    },
                    {
                        "@pid": "314/5946",
                        "text": "Vaughn Hamilton"
                    },
                    {
                        "@pid": "28/8280",
                        "text": "Adam Doup\u00e9"
                    },
                    {
                        "@pid": "205/2107",
                        "text": "Allison McDonald"
                    },
                    {
                        "@pid": "141/9244",
                        "text": "Elissa M. Redmiles"
                    }
                ]
            },
            "title": "&quot;I feel physically safe but not politically safe&quot;: Understanding the Digital Threats and Safety Practices of OnlyFans Creators.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SonejiHDMR24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/soneji",
            "url": "https://dblp.org/rec/conf/uss/SonejiHDMR24",
            "abstract": "OnlyFans is a subscription-based social media platform with over 1.5 million content creators and 150 million users world-wide. OnlyFans creators primarily produce intimate content for sale on the platform. As such, they are distinctly positioned as content creators and sex workers. Through a qualitative interview study with OnlyFans creators (n=43), building on an existing framework of online hate and harassment, we shed light on the nuanced threats they face and their safety practices. Additionally, we examine the impact of factors such as stigma, prominence, and platform policies on shaping the threat landscape for OnlyFans creators and detail the preemptive practices they undertake to protect themselves. Leveraging these results, we synthesize opportunities to address the challenges of sexual content creators.",
            "keywords": [
                "OnlyFans",
                "Content Creators",
                "Digital Threats",
                "Safety Practices",
                "Stigma and Harassment"
            ]
        },
        "url": "URL#379689",
        "sema_paperId": "374e040369c08398548fb87b85f151c18342dc4a"
    },
    {
        "@score": "1",
        "@id": "379690",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "62/1539",
                        "text": "Wei Song"
                    },
                    {
                        "@pid": "226/4314",
                        "text": "Cong Cong"
                    },
                    {
                        "@pid": "228/2099",
                        "text": "Haonan Zhong"
                    },
                    {
                        "@pid": "x/JinglingXue",
                        "text": "Jingling Xue"
                    }
                ]
            },
            "title": "Correction-based Defense Against Adversarial Video Attacks via Discretization-Enhanced Video Compressive Sensing.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SongCZX24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/song-wei",
            "url": "https://dblp.org/rec/conf/uss/SongCZX24",
            "abstract": "We introduce S EC VID, a correction-based framework that defends video recognition systems against adversarial attacks without prior adversarial knowledge. It uses discretization-enhanced video compressive sensing in a black-box pre-processing module, transforming videos into a sparse domain to disperse and neutralize perturbations. While S EC VID\u2019s discretized compression disrupts perturbation continuity, its reconstruction process minimizes adversarial elements, causing only minor distortions to the original videos. Though not completely restoring adversarial videos, S EC VID significantly enhances their quality, enabling accurate classification by S EC VID-enhanced video classifiers and preventing adversarial attacks. Tested on C3D and I3D with the UCF-101 and HMDB-51 datasets against five types of advanced video attacks, S EC VID outperforms existing defenses, improving detection accuracy by 38.5% to 866.2%. Specifically designed for high-risk environments, S EC VID addresses trade-offs like minor accuracy reduction, additional pre-processing training, and longer inference times, with potential optimization through selective security impacting strategies.",
            "keywords": [
                "Adversarial Video Attacks",
                "Video Recognition Systems",
                "Compressive Sensing",
                "Discretization",
                "Perturbation Neutralization"
            ]
        },
        "url": "URL#379690",
        "sema_paperId": "c8224d9d96de52a72b359bb92a44eb9bee0324e2"
    },
    {
        "@score": "1",
        "@id": "379691",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "246/1384-2",
                        "text": "Yuanming Song 0002"
                    },
                    {
                        "@pid": "208/7022",
                        "text": "Lenka Marekov\u00e1"
                    },
                    {
                        "@pid": "39/780",
                        "text": "Kenneth G. Paterson"
                    }
                ]
            },
            "title": "Cryptographic Analysis of Delta Chat.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SongMP24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/song-yuanming",
            "url": "https://dblp.org/rec/conf/uss/SongMP24",
            "abstract": "We analyse the cryptographic protocols underlying Delta Chat, a decentralised messaging application which uses e-mail infrastructure for message delivery. It provides end-to-end encryption by implementing the Autocrypt standard and the SecureJoin protocols, both making use of the OpenPGP standard. Delta Chat's adoption by categories of high-risk users such as journalists and activists, but also more generally users in regions affected by Internet censorship, makes it a target for powerful adversaries. Yet, the security of its protocols has not been studied to date. We describe five new attacks on Delta Chat in its own threat model, exploiting cross-protocol interactions between its implementation of SecureJoin and Autocrypt, as well as bugs in rPGP, its OpenPGP library. The findings have been disclosed to the Delta Chat team, who implemented fixes.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-song-yuanming.pdf",
            "keywords": [
                "Cryptographic Protocols",
                "Delta Chat",
                "End-to-End Encryption",
                "OpenPGP",
                "SecureJoin Vulnerabilities"
            ]
        },
        "url": "URL#379691"
    },
    {
        "@score": "1",
        "@id": "379692",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "298/5443",
                        "text": "Supraja Sridhara"
                    },
                    {
                        "@pid": "348/6664",
                        "text": "Andrin Bertschi"
                    },
                    {
                        "@pid": "348/6844",
                        "text": "Benedict Schl\u00fcter"
                    },
                    {
                        "@pid": "333/1328",
                        "text": "Mark Kuhne"
                    },
                    {
                        "@pid": "348/6451",
                        "text": "Fabio Aliberti"
                    },
                    {
                        "@pid": "136/8404",
                        "text": "Shweta Shinde"
                    }
                ]
            },
            "title": "ACAI: Protecting Accelerator Execution with Arm Confidential Computing Architecture.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SridharaBSKAS24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/sridhara",
            "url": "https://dblp.org/rec/conf/uss/SridharaBSKAS24",
            "abstract": "Trusted execution environments in several existing and upcoming CPUs demonstrate the success of confidential computing, with the caveat that tenants cannot securely use accelerators such as GPUs and FPGAs. In this paper, we reconsider the Arm Confidential Computing Architecture (CCA) design, an upcoming TEE feature in Armv9-A, to address this gap. We observe that CCA offers the right abstraction and mechanisms to allow confidential VMs to use accelerators as a first-class abstraction. We build ACAI, a CCA-based solution, with a principled approach of extending CCA security invariants to device-side access to address several critical security gaps. Our experimental results on GPU and FPGA demonstrate the feasibility of ACAI while maintaining security guarantees.",
            "keywords": [
                "Confidential Computing",
                "Arm Confidential Computing Architecture",
                "Trusted Execution Environments",
                "Accelerator Security",
                "Device-side Access Security"
            ]
        },
        "url": "URL#379692",
        "sema_paperId": "0b99444b27ccccf9e0fc5d91fae02d4f92455bbe"
    },
    {
        "@score": "1",
        "@id": "379693",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "381/1630",
                        "text": "Aleksei Stafeev"
                    },
                    {
                        "@pid": "35/9056",
                        "text": "Giancarlo Pellegrino"
                    }
                ]
            },
            "title": "SoK: State of the Krawlers - Evaluating the Effectiveness of Crawling Algorithms for Web Security Measurements.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/StafeevP24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/stafeev",
            "url": "https://dblp.org/rec/conf/uss/StafeevP24",
            "abstract": "Web crawlers are tools widely used in web security measurements whose performance and impact have been limitedly studied so far. In this paper, we bridge this gap. Starting from the past 12 years of the top security, web measurement, and software engineering literature, we categorize and decompose in building blocks crawling techniques and methodologic choices. We then reimplement and patch crawling techniques and integrate them into Arachnarium , a framework for comparative evaluations, which we use to run one of the most comprehensive experimental evaluations against nine real and two benchmark web applications and top 10K CrUX websites to assess the performance and adequacy of algorithms across three metrics (code, link, and JavaScript source coverage). Finally, we distill 14 insights and lessons learned. Our results show that despite a lack of clear and homogeneous descriptions hindering reimplementations, proposed and commonly used crawling algorithms offer a lower coverage than randomized ones, indicating room for improvement. Also, our results show a complex relationship between experiment parameters, the study\u2019s domain, and the available computing resources, where no single best-performing crawler con\ufb01guration exists. We hope our results will guide future researchers when setting up their studies.",
            "keywords": [
                "Web Crawling",
                "Web Security Measurements",
                "Crawling Algorithms",
                "Coverage Evaluation",
                "Arachnarium Framework"
            ]
        },
        "url": "URL#379693",
        "sema_paperId": "0f5ae8c109c098bd91e90621934a91570dd7d0a7"
    },
    {
        "@score": "1",
        "@id": "379694",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "239/3429",
                        "text": "Zihao Su"
                    },
                    {
                        "@pid": "329/3620",
                        "text": "Kunlin Cai"
                    },
                    {
                        "@pid": "378/2011",
                        "text": "Reuben Beeler"
                    },
                    {
                        "@pid": "191/8034",
                        "text": "Lukas Dresel"
                    },
                    {
                        "@pid": "378/2331",
                        "text": "Allan Garcia"
                    },
                    {
                        "@pid": "180/7263",
                        "text": "Ilya Grishchenko"
                    },
                    {
                        "@pid": "39/5423-1",
                        "text": "Yuan Tian 0001"
                    },
                    {
                        "@pid": "k/ChristopherKruegel",
                        "text": "Christopher Kruegel"
                    },
                    {
                        "@pid": "v/GiovanniVigna",
                        "text": "Giovanni Vigna"
                    }
                ]
            },
            "title": "Remote Keylogging Attacks in Multi-user VR Applications.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SuCBDGG0KV24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/su-zihao",
            "url": "https://dblp.org/rec/conf/uss/SuCBDGG0KV24",
            "abstract": "As Virtual Reality (VR) applications grow in popularity, they have bridged distances and brought users closer together. However, with this growth, there have been increasing concerns about security and privacy, especially related to the motion data used to create immersive experiences. In this study, we highlight a significant security threat in multi-user VR applications, which are applications that allow multiple users to interact with each other in the same virtual space. Specifically, we propose a remote attack that utilizes the avatar rendering information collected from an adversary's game clients to extract user-typed secrets like credit card information, passwords, or private conversations. We do this by (1) extracting motion data from network packets, and (2) mapping motion data to keystroke entries. We conducted a user study to verify the attack's effectiveness, in which our attack successfully inferred 97.62% of the keystrokes. Besides, we performed an additional experiment to underline that our attack is practical, confirming its effectiveness even when (1) there are multiple users in a room, and (2) the attacker cannot see the victims. Moreover, we replicated our proposed attack on four applications to demonstrate the generalizability of the attack. These results underscore the severity of the vulnerability and its potential impact on millions of VR social platform users.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-su-zihao.pdf",
            "keywords": [
                "Virtual Reality Security",
                "Multi-user VR Applications",
                "Keylogging Attacks",
                "Motion Data Exploitation",
                "User Privacy Threats"
            ]
        },
        "url": "URL#379694"
    },
    {
        "@score": "1",
        "@id": "379695",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "362/1176",
                        "text": "Weihao Su"
                    },
                    {
                        "@pid": "74/3859",
                        "text": "Hong Huang"
                    },
                    {
                        "@pid": "331/2626",
                        "text": "Rongchen Li"
                    },
                    {
                        "@pid": "75/248",
                        "text": "Haiming Chen"
                    },
                    {
                        "@pid": "25/2228",
                        "text": "Tingjian Ge"
                    }
                ]
            },
            "title": "Towards an Effective Method of ReDoS Detection for Non-backtracking Engines.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SuHLCG24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/su-weihao",
            "url": "https://dblp.org/rec/conf/uss/SuHLCG24",
            "abstract": "Regular expressions (regexes) are a fundamental concept across the fields of computer science. However, they can also induce the Regular expression Denial of Service (Re-DoS) attacks, which are a class of denial of service attacks, caused by super-linear worst-case matching time. Due to the severity and prevalence of ReDoS attacks, the detection of ReDoS-vulnerable regexes in software is thus vital. Although various ReDoS detection approaches have been proposed, these methods have focused mainly on backtracking regex engines, leaving the problem of ReDoS vulnerability detection on non-backtracking regex engines largely open. To address the above challenges, in this paper, we first systematically analyze the major causes that could contribute to ReDoS vulnerabilities on non-backtracking regex engines. We then propose a novel type of ReDoS attack strings that builds on the concept of simple strings. Next we propose E VIL S TR G EN , a tool for generating attack strings for ReDoS-vulnerable regexes on non-backtracking engines. It is based on a novel incremental determinisation algorithm with heuristic strategies to lazily find the k -simple strings without explicit construction of finite automata. We evaluate E VIL S TR G EN against six state-of-the-art approaches on a broad range of publicly available datasets containing 736,535 unique regexes. The results illustrate the significant efficacy of our tool. We also apply our tool to 85 intensively-tested projects, and have identified 34 unrevealed ReDoS vulnerabilities.",
            "keywords": [
                "Regular Expressions",
                "ReDoS Detection",
                "Non-backtracking Engines",
                "Vulnerability Detection",
                "Attack String Generation"
            ]
        },
        "url": "URL#379695",
        "sema_paperId": "670c12f7f83eaf5cafc31f923fe4834e0563a3e8"
    },
    {
        "@score": "1",
        "@id": "379696",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "30/5583",
                        "text": "Bing Sun"
                    },
                    {
                        "@pid": "s/JunSun1",
                        "text": "Jun Sun 0001"
                    },
                    {
                        "@pid": "381/1614",
                        "text": "Wayne Koh"
                    },
                    {
                        "@pid": "38/5467",
                        "text": "Jie Shi"
                    }
                ]
            },
            "title": "Neural Network Semantic Backdoor Detection and Mitigation: A Causality-Based Approach.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Sun0KS24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/sun-bing",
            "url": "https://dblp.org/rec/conf/uss/Sun0KS24",
            "abstract": "Different from ordinary backdoors in neural networks which are introduced with artificial triggers (e.g., certain specific patch) and/or by tampering the samples, semantic backdoors are introduced by simply manipulating the semantic, e.g., by labeling green cars as frogs in the training set. By focusing on samples with rare semantic features (such as green cars), the accuracy of the model is often minimally affected. Since the attacker is not required to modify the input sample during training nor inference time, semantic backdoors are challenging to detect and remove. Existing backdoor detection and mitigation techniques are shown to be ineffective with respect to semantic backdoors. In this work, we propose a method to systematically detect and remove semantic back-doors. Specifically we propose SODA ( S emantic Backd O or D etection and Mitig A tion) with the key idea of conducting lightweight causality analysis to identify potential semantic backdoor based on how hidden neurons contribute to the predictions and to remove the backdoor by adjusting the responsible neurons\u2019 contribution towards the correct predictions through optimization. SODA is evaluated with 21 neural networks trained on 6 benchmark datasets and 2 kinds of semantic backdoor attacks for each dataset. The results show that it effectively detects and removes semantic backdoors and preserves the accuracy of the neural networks.",
            "keywords": [
                "Semantic Backdoor Detection",
                "Causality Analysis",
                "Neural Network Robustness",
                "Backdoor Mitigation",
                "SODA Method"
            ]
        },
        "url": "URL#379696",
        "sema_paperId": "74d80a66ab436f039d973f71a86a0409a246cd97"
    },
    {
        "@score": "1",
        "@id": "379697",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "378/5144",
                        "text": "Tianle Sun"
                    },
                    {
                        "@pid": "228/1460",
                        "text": "Ningyu He"
                    },
                    {
                        "@pid": "09/7637",
                        "text": "Jiang Xiao"
                    },
                    {
                        "@pid": "63/6849",
                        "text": "Yinliang Yue"
                    },
                    {
                        "@pid": "53/1565",
                        "text": "Xiapu Luo"
                    },
                    {
                        "@pid": "50/8499-1",
                        "text": "Haoyu Wang 0001"
                    }
                ]
            },
            "title": "All Your Tokens are Belong to Us: Demystifying Address Verification Vulnerabilities in Solidity Smart Contracts.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SunHXYL024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/sun-tianle",
            "url": "https://dblp.org/rec/conf/uss/SunHXYL024",
            "abstract": "In Ethereum, the practice of verifying the validity of the passed addresses is a common practice, which is a crucial step to ensure the secure execution of smart contracts. Vulnerabilities in the process of address verification can lead to great security issues, and anecdotal evidence has been reported by our community. However, this type of vulnerability has not been well studied. To fill the void, in this paper, we aim to characterize and detect this kind of emerging vulnerability. We design and implement AVVERIFIER, a lightweight taint analyzer based on static EVM opcode simulation. Its three-phase detector can progressively rule out false positives and false negatives based on the intrinsic characteristics. Upon a well-established and unbiased benchmark, AVVERIFIER can improve efficiency 2 to 5 times than the SOTA while maintaining a 94.3% precision and 100% recall. After a large-scale evaluation of over 5 million Ethereum smart contracts, we have identified 812 vulnerable smart contracts that were undisclosed by our community before this work, and 348 open source smart contracts were further verified, whose largest total value locked is over $11.2 billion. We further deploy AVVERIFIER as a real-time detector on Ethereum and Binance Smart Chain, and the results suggest that AVVERIFIER can raise timely warnings once contracts are deployed.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-sun-tianle.pdf",
            "keywords": [
                "Smart Contract Security",
                "Address Verification",
                "Vulnerability Detection",
                "Taint Analysis",
                "Ethereum"
            ]
        },
        "url": "URL#379697"
    },
    {
        "@score": "1",
        "@id": "379698",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "226/9872",
                        "text": "Chenxin Sun"
                    },
                    {
                        "@pid": "85/1383",
                        "text": "Kai Ye"
                    },
                    {
                        "@pid": "289/2669",
                        "text": "Liangcai Su"
                    },
                    {
                        "@pid": "23/8208",
                        "text": "Jiayi Zhang"
                    },
                    {
                        "@pid": "147/2276",
                        "text": "Chenxiong Qian"
                    }
                ]
            },
            "title": "Invisibility Cloak: Proactive Defense Against Visual Game Cheating.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SunYSZQ24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/sun-chenxin",
            "url": "https://dblp.org/rec/conf/uss/SunYSZQ24",
            "abstract": "The gaming industry has experienced remarkable innovation and rapid growth in recent years. However, this progress has been accompanied by a concerning increase in First-person Shooter game cheating, with aimbots being the most prevalent and harmful tool. Visual aimbots, in particular, utilize game visuals and integrated visual models to extract game information, providing cheaters with automatic shooting abilities. Unfortunately, existing anti-cheating methods have proven ineffective against visual aimbots. To combat visual aimbots, we introduce the first proactive defense framework against visual game cheating, called Invisibility Cloak. Our approach adds imperceptible perturbations to game visuals, making them unrecognizable to AI models. We conducted extensive experiments on popular games CrossFire (CF) and Counter-Strike 2 (CS2), and our results demonstrate that Invisibility Cloak achieves real-time re-rendering of high-quality game visuals while effectively impeding various mainstream visual cheating models. By deploying Invisibility Cloak online in both CF and CS2, we successfully eliminated almost all aiming and shooting behaviors associated with aimbots, significantly enhancing the gaming experience for legitimate players.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-sun-chenxin.pdf",
            "keywords": [
                "Game Cheating Prevention",
                "Visual Aimbots",
                "Proactive Defense",
                "Invisibility Cloak",
                "Real-time Game Rendering"
            ]
        },
        "url": "URL#379698",
        "sema_paperId": "d0d9071f5fac6b724d41f2f723ad2c06182b79e9"
    },
    {
        "@score": "1",
        "@id": "379699",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "157/6614",
                        "text": "Madiha Tabassum"
                    },
                    {
                        "@pid": "381/1659",
                        "text": "Alana Mackey"
                    },
                    {
                        "@pid": "381/1647",
                        "text": "Ashley Schuett"
                    },
                    {
                        "@pid": "136/8449",
                        "text": "Ada Lerner"
                    }
                ]
            },
            "title": "Investigating Moderation Challenges to Combating Hate and Harassment: The Case of Mod-Admin Power Dynamics and Feature Misuse on Reddit.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/TabassumMSL24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/tabassum",
            "url": "https://dblp.org/rec/conf/uss/TabassumMSL24",
            "abstract": "Social media platforms often rely on volunteer moderators to combat hate and harassment and create safe online environments. In the face of challenges combating hate and harassment, moderators engage in mutual support with one another. We conducted a qualitative content analysis of 115 hate and harassment-related threads from r/ModSupport and r/modhelp, two major subreddit forums for this type of mutual support. We analyze the challenges moderators face; complex tradeoffs related to privacy, utility, and harassment; and major challenges in the relationship between moderators and platform admins. We also present the \ufb01rst systematization of how platform features (including especially security, privacy, and safety features) are misused for online abuse, and drawing on this systematization we articulate design themes for platforms that want to resist such misuse.",
            "keywords": [
                "Social Media Moderation",
                "Hate Speech",
                "Harassment",
                "Moderator-Admin Dynamics",
                "Feature Misuse"
            ]
        },
        "url": "URL#379699",
        "sema_paperId": "4edb0338ea80ceba058c4567908eaccbe9196bec"
    },
    {
        "@score": "1",
        "@id": "379700",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "77/6056",
                        "text": "Qi Tan"
                    },
                    {
                        "@pid": "181/2688-2",
                        "text": "Qi Li 0002"
                    },
                    {
                        "@pid": "51/4138-11",
                        "text": "Yi Zhao 0011"
                    },
                    {
                        "@pid": "69/11514",
                        "text": "Zhuotao Liu"
                    },
                    {
                        "@pid": "170/2427",
                        "text": "Xiaobing Guo"
                    },
                    {
                        "@pid": "181/2626-2",
                        "text": "Ke Xu 0002"
                    }
                ]
            },
            "title": "Defending Against Data Reconstruction Attacks in Federated Learning: An Information Theory Approach.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Tan00LG024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/tan",
            "url": "https://dblp.org/rec/conf/uss/Tan00LG024",
            "abstract": "Federated Learning (FL) trains a black-box and high-dimensional model among different clients by exchanging parameters instead of direct data sharing, which mitigates the privacy leak incurred by machine learning. However, FL still suffers from membership inference attacks (MIA) or data reconstruction attacks (DRA). In particular, an attacker can extract the information from local datasets by constructing DRA, which cannot be effectively throttled by existing techniques, e.g., Differential Privacy (DP). In this paper, we aim to ensure a strong privacy guarantee for FL under DRA. We prove that reconstruction errors under DRA are constrained by the information acquired by an attacker, which means that constraining the transmitted information can effectively throttle DRA. To quantify the information leakage incurred by FL, we establish a channel model, which depends on the upper bound of joint mutual information between the local dataset and multiple transmitted parameters. Moreover, the channel model indicates that the transmitted information can be constrained through data space operation, which can improve training efficiency and the model accuracy under constrained information. According to the channel model, we propose algorithms to constrain the information transmitted in a single round of local training. With a limited number of training rounds, the algorithms ensure that the total amount of transmitted information is limited. Furthermore, our channel model can be applied to various privacy-enhancing techniques (such as DP) to enhance privacy guarantees against DRA. Extensive experiments with real-world datasets validate the effectiveness of our methods.",
            "keywords": [
                "Federated Learning",
                "Data Reconstruction Attacks",
                "Information Leakage",
                "Membership Inference Attacks",
                "Privacy Guarantees"
            ]
        },
        "url": "URL#379700",
        "sema_paperId": "9f42150602cd7d37f192b04a2e4739d9eca7e161"
    },
    {
        "@score": "1",
        "@id": "379701",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "250/9350",
                        "text": "Minxue Tang"
                    },
                    {
                        "@pid": "214/9595",
                        "text": "Anna Dai"
                    },
                    {
                        "@pid": "304/8912",
                        "text": "Louis DiValentin"
                    },
                    {
                        "@pid": "303/4560",
                        "text": "Aolin Ding"
                    },
                    {
                        "@pid": "354/2191",
                        "text": "Amin Hass"
                    },
                    {
                        "@pid": "03/9437",
                        "text": "Neil Zhenqiang Gong"
                    },
                    {
                        "@pid": "80/1641",
                        "text": "Yiran Chen 0001"
                    },
                    {
                        "@pid": "30/5330-1",
                        "text": "Hai (Helen) Li"
                    }
                ]
            },
            "title": "ModelGuard: Information-Theoretic Defense Against Model Extraction Attacks.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/TangDDDHG0L24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/tang",
            "url": "https://dblp.org/rec/conf/uss/TangDDDHG0L24",
            "abstract": "Malicious utilization of a query interface can compromise the confidentiality of ML-as-a-Service (MLaaS) systems via model extraction attacks. Previous studies have proposed to perturb the predictions of the MLaaS system as a defense against model extraction attacks. However, existing prediction perturbation methods suffer from a poor privacy-utility balance and cannot effectively defend against the latest adaptive model extraction attacks. In this paper, we propose a novel prediction perturbation defense named M ODEL G UARD , which aims at defending against adaptive model extraction attacks while maintaining a high utility of the protected system. We develop a general optimization problem that considers different kinds of model extraction attacks, and M ODEL G UARD provides an information-theoretic defense to efficiently solve the optimization problem and achieve resistance against adaptive attacks. Experiments show that M ODEL G UARD attains significantly better defensive performance against adaptive attacks with less loss of utility compared to previous defenses.",
            "keywords": [
                "Model Extraction Attacks",
                "ML-as-a-Service",
                "Prediction Perturbation",
                "Information-Theoretic Defense",
                "Adaptive Attacks"
            ]
        },
        "url": "URL#379701",
        "sema_paperId": "650f6db095276ca03d03f4951587d7383ca3b39d"
    },
    {
        "@score": "1",
        "@id": "379702",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "381/1686",
                        "text": "Xiwen Teoh"
                    },
                    {
                        "@pid": "77/1513-1",
                        "text": "Yun Lin 0001"
                    },
                    {
                        "@pid": "301/5834",
                        "text": "Ruofan Liu"
                    },
                    {
                        "@pid": "181/2754",
                        "text": "Zhiyong Huang"
                    },
                    {
                        "@pid": "33/6517",
                        "text": "Jin Song Dong"
                    }
                ]
            },
            "title": "PhishDecloaker: Detecting CAPTCHA-cloaked Phishing Websites via Hybrid Vision-based Interactive Models.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Teoh0LHD24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/teoh",
            "url": "https://dblp.org/rec/conf/uss/Teoh0LHD24",
            "abstract": "Phishing is a cybersecurity attack based on social engineering that incurs signi\ufb01cant \ufb01nancial losses and erodes societal trust. While phishing detection techniques are emerging, attackers continually strive to bypass state-of-the-arts. Recent phishing campaigns have shown that emerging phishing attacks adopt CAPTCHA-based cloaking techniques, marking a new round of cat-and-mouse game. Our study shows that phishing web-sites, hardened by CAPTCHA-cloaking, can compromise all known state-of-the-art industrial and academic detectors with almost zero cost. In this work, we develop PhishDecloaker, an AI-powered solution to soften the shield of the CAPTCHA-cloaking used by phishing websites. PhishDecloaker is designed to mimic human behaviors to solve the CAPTCHAs, allowing modern security-crawlers to see the uncloaked phishing content. Technically, PhishDecloaker orchestrates \ufb01ve deep computer vision models to detect the existence of CAPTCHAs, analyze its type, and solve the challenge in an interactive manner. We conduct extensive experiments to evaluate PhishDecloaker in terms of its effectiveness, ef\ufb01ciency, and robustness against potential adversaries. The results show that PhishDecloaker (1) recovers the phishing detection rate of many state-of-the-art phishing detectors from 0% to up to on average 74.25% on diverse CAPTCHA-cloaked phishing websites (2) generalizes to unseen CAPTCHA (with precision of 86% and recall of 69%), and (3) is robust against various adversaries such as FGSM, JSMA, PGD, DeepFool, and DPatch, which allows the existing phishing detectors to achieve new state-of-the-art performance on CAPTCHA-cloaked phishing webpages. Our \ufb01eld study over 30 days shows that PhishDecloaker can help us uniquely discover 7.6% more phishing websites cloaked by CAPTCHAs, raising alarm of the emergence of CAPTCHA-cloaked features in the modern phishing campaigns.",
            "keywords": [
                "Phishing Detection",
                "CAPTCHA Cloaking",
                "Cybersecurity Attacks",
                "AI-powered Solutions",
                "Phishing Websites"
            ]
        },
        "url": "URL#379702",
        "sema_paperId": "ca69bc4ff6dcfbf4952083b84f3a503de389ccc1"
    },
    {
        "@score": "1",
        "@id": "379703",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "57/10514",
                        "text": "Saravanan Thirumuruganathan"
                    },
                    {
                        "@pid": "116/0894",
                        "text": "Fatih Deniz"
                    },
                    {
                        "@pid": "115/8715",
                        "text": "Issa Khalil"
                    },
                    {
                        "@pid": "y/TingYu-1",
                        "text": "Ting Yu 0001"
                    },
                    {
                        "@pid": "65/4357",
                        "text": "Mohamed Nabeel"
                    },
                    {
                        "@pid": "o/MouradOuzzani",
                        "text": "Mourad Ouzzani"
                    }
                ]
            },
            "title": "Detecting and Mitigating Sampling Bias in Cybersecurity with Unlabeled Data.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Thirumuruganathan24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/thirumuruganathan",
            "url": "https://dblp.org/rec/conf/uss/Thirumuruganathan24",
            "abstract": "Machine Learning (ML) based systems have demonstrated remarkable success in addressing various challenges within the ever-evolving cybersecurity landscape, particularly in the domain of malware detection/classification. However, a notable performance gap becomes evident when such classifiers are deployed in production. This discrepancy, often observed between accuracy scores reported in research papers and their real-world deployments, can be largely attributed to sampling bias. Intuitively, the data distribution in the production differs from that of training resulting in reduced performance of the classifier. How to deal with such sampling bias is an important problem in cybersecurity practice. In this paper, we propose principled approaches to detect and mitigate the adverse effects of sampling bias. First, we propose two simple and intuitive algorithms based on domain discrimination and distribution of k-th nearest neighbor distance to detect discrepancies between training and production data distributions. Second, we propose two algorithms based on the self-training paradigm to alleviate the impact of sampling bias. Our approaches are inspired by domain adaptation and judiciously harness the unlabeled data for enhancing the generalizability of ML classifiers. Critically, our approach does not require any modifications to the classifiers themselves, thus ensuring seamless integration into existing deployments. We conducted extensive experiments on four diverse datasets from malware, web domains, and intrusion detection. In an adversarial setting with large sampling bias, our proposed algorithms can improve the F-score by as much as 10-16 percentage points. Concretely, the F-score of a malware classifier on AndroZoo dataset increases from 0.83 to 0.937.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-thirumuruganathan_1.pdf",
            "keywords": [
                "Cybersecurity",
                "Sampling Bias",
                "Malware Detection",
                "Domain Adaptation",
                "Unlabeled Data"
            ]
        },
        "url": "URL#379703",
        "sema_paperId": "b688b9ce5cd8b7306653852b4cb995a966d32431"
    },
    {
        "@score": "1",
        "@id": "379704",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "381/1653",
                        "text": "Ronald Thompson"
                    },
                    {
                        "@pid": "334/9022",
                        "text": "Madeline McLaughlin"
                    },
                    {
                        "@pid": "377/9115",
                        "text": "Carson Powers"
                    },
                    {
                        "@pid": "61/11094",
                        "text": "Daniel Votipka"
                    }
                ]
            },
            "title": "&quot;There are rabbit holes I want to go down that I&apos;m not allowed to go down&quot;: An Investigation of Security Expert Threat Modeling Practices for Medical Devices.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ThompsonMPV24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/thompson",
            "url": "https://dblp.org/rec/conf/uss/ThompsonMPV24",
            "abstract": "Threat modeling is considered an essential \ufb01rst step for \u201cse-cure by design\u201d development. Signi\ufb01cant prior work and industry efforts have created novel methods for this type of threat modeling, and evaluated them in various simulated settings. Because threat modeling is context-speci\ufb01c, we focused on medical device security experts as regulators require it, and \u201csecure by design\u201d medical devices are seen as a critical step to securing healthcare. We conducted 12 semi-structured interviews with medical device security experts, having participants brainstorm threats and mitigations for two medical devices. We saw these experts do not sequentially work through a list of threats or mitigations according to the rigorous processes described in existing methods and, instead, regularly switch strategies. Our work consists of three major contributions. The \ufb01rst is a two-part process model that describes how security experts 1) determine threats and mitigations for a particular component and 2) move between components. Second, we observed participants leveraging use cases, a strategy not addressed in prior work for threat modeling. Third, we found that integrating safety into threat modeling is critical, albeit unclear. We also provide recommendations for future work.",
            "keywords": [
                "Medical Device Security",
                "Threat Modeling",
                "Security Expert Practices",
                "Mitigation Strategies",
                "Safety Integration"
            ]
        },
        "url": "URL#379704",
        "sema_paperId": "7ebc4332d82b9476535cfe41939f81146781eb53"
    },
    {
        "@score": "1",
        "@id": "379705",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "287/4822",
                        "text": "Anvith Thudi"
                    },
                    {
                        "@pid": "255/4934",
                        "text": "Hengrui Jia"
                    },
                    {
                        "@pid": "255/5544",
                        "text": "Casey Meehan"
                    },
                    {
                        "@pid": "213/8587",
                        "text": "Ilia Shumailov"
                    },
                    {
                        "@pid": "162/1405",
                        "text": "Nicolas Papernot"
                    }
                ]
            },
            "title": "Gradients Look Alike: Sensitivity is Often Overestimated in DP-SGD.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ThudiJMSP24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/thudi",
            "url": "https://dblp.org/rec/conf/uss/ThudiJMSP24",
            "abstract": "Differentially private stochastic gradient descent (DP-SGD) is the canonical approach to private deep learning. While the current privacy analysis of DP-SGD is known to be tight in some settings, several empirical results suggest that models trained on common benchmark datasets leak significantly less privacy for many datapoints. Yet, despite past attempts, a rigorous explanation for why this is the case has not been reached. Is it because there exist tighter privacy upper bounds when restricted to these dataset settings, or are our attacks not strong enough for certain datapoints? In this paper, we provide the first per-instance (i.e., ``data-dependent\") DP analysis of DP-SGD. Our analysis captures the intuition that points with similar neighbors in the dataset enjoy better data-dependent privacy than outliers. Formally, this is done by modifying the per-step privacy analysis of DP-SGD to introduce a dependence on the distribution of model updates computed from a training dataset. We further develop a new composition theorem to effectively use this new per-step analysis to reason about an entire training run. Put all together, our evaluation shows that this novel DP-SGD analysis allows us to now formally show that DP-SGD leaks significantly less privacy for many datapoints (when trained on common benchmarks) than the current data-independent guarantee. This implies privacy attacks will necessarily fail against many datapoints if the adversary does not have sufficient control over the possible training datasets.",
            "keywords": [
                "Differential Privacy",
                "Stochastic Gradient Descent",
                "Data-Dependent Privacy",
                "Privacy Analysis",
                "Model Update Sensitivity"
            ]
        },
        "url": "URL#379705",
        "sema_paperId": "11984837284dc773638d6e6dd91372a98f6cb69d"
    },
    {
        "@score": "1",
        "@id": "379706",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "213/1083",
                        "text": "Trishita Tiwari"
                    },
                    {
                        "@pid": "217/1570",
                        "text": "Suchin Gururangan"
                    },
                    {
                        "@pid": "147/5346",
                        "text": "Chuan Guo 0001"
                    },
                    {
                        "@pid": "184/1257",
                        "text": "Weizhe Hua"
                    },
                    {
                        "@pid": "223/6062",
                        "text": "Sanjay Kariyappa"
                    },
                    {
                        "@pid": "79/8759",
                        "text": "Udit Gupta"
                    },
                    {
                        "@pid": "177/2257",
                        "text": "Wenjie Xiong 0001"
                    },
                    {
                        "@pid": "200/5551",
                        "text": "Kiwan Maeng"
                    },
                    {
                        "@pid": "168/5992",
                        "text": "Hsien-Hsin S. Lee"
                    },
                    {
                        "@pid": "09/5657",
                        "text": "G. Edward Suh"
                    }
                ]
            },
            "title": "Information Flow Control in Machine Learning through Modular Model Architecture.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/TiwariGGHKG0MLS24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/tiwari",
            "url": "https://dblp.org/rec/conf/uss/TiwariGGHKG0MLS24",
            "abstract": "In today's machine learning (ML) models, any part of the training data can affect the model output. This lack of control for information flow from training data to model output is a major obstacle in training models on sensitive data when access control only allows individual users to access a subset of data. To enable secure machine learning for access-controlled data, we propose the notion of information flow control for machine learning, and develop an extension to the Transformer language model architecture that strictly adheres to the IFC definition we propose. Our architecture controls information flow by limiting the influence of training data from each security domain to a single expert module, and only enables a subset of experts at inference time based on the access control policy. The evaluation using large text and code datasets show that our proposed parametric IFC architecture has minimal (1.9%) performance overhead and can significantly improve model accuracy (by 38% for the text dataset, and between 44%\u201362% for the code datasets) by enabling training on access-controlled data.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-tiwari.pdf",
            "keywords": [
                "Information Flow Control",
                "Modular Model Architecture",
                "Access-Controlled Data",
                "Transformer Language Model",
                "Sensitive Data Training"
            ]
        },
        "url": "URL#379706"
    },
    {
        "@score": "1",
        "@id": "379707",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "221/1574",
                        "text": "Youssef Tobah"
                    },
                    {
                        "@pid": "176/8068",
                        "text": "Andrew Kwong"
                    },
                    {
                        "@pid": "199/7713",
                        "text": "Ingab Kang"
                    },
                    {
                        "@pid": "98/8283",
                        "text": "Daniel Genkin"
                    },
                    {
                        "@pid": "s/KangGShin",
                        "text": "Kang G. Shin"
                    }
                ]
            },
            "title": "Go Go Gadget Hammer: Flipping Nested Pointers for Arbitrary Data Leakage.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/TobahKKGS24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/tobah",
            "url": "https://dblp.org/rec/conf/uss/TobahKKGS24",
            "abstract": "Rowhammer is an increasingly threatening vulnerability that grants an attacker the ability to \ufb02ip bits in memory without directly accessing them. Despite efforts to mitigate Rowhammer via software and defenses built directly into DRAM modules, more recent generations of DRAM are actually more susceptible to malicious bit-\ufb02ips than their predecessors. This phenomenon has spawned numerous exploits, showing how Rowhammer acts as the basis for various vulnerabilities that target sensitive structures, such as Page Table Entries (PTEs) or opcodes, to grant control over a victim machine. However, in this paper, we consider Rowhammer as a more general vulnerability, presenting a novel exploit vector for Rowhammer that targets particular code patterns . We show that if victim code is designed to return benign data to an unprivileged user, and uses nested pointer dereferences, Rowhammer can \ufb02ip these pointers to gain arbitrary read access in the victim\u2019s address space. Furthermore, we identify gadgets present in the Linux kernel, and demonstrate an end-to-end attack that precisely \ufb02ips a targeted pointer. To do so we developed a number of improved Rowhammer primitives, including kernel memory massaging, Rowhammer synchronization, and testing for kernel \ufb02ips, which may be of broader interest to the Rowhammer community. Compared to prior works\u2019 leakage rate of .3 bits/s, we show that such gadgets can be used to read out kernel data at a rate of 82.6 bits/s. By targeting code gadgets, this work expands the scope and attack surface exposed by Rowhammer. It is no longer suf\ufb01-cient for software defenses to selectively pad previously exploited memory structures in",
            "keywords": [
                "Rowhammer Vulnerability",
                "Memory Exploitation",
                "Pointer Dereferencing",
                "Kernel Data Leakage",
                "Arbitrary Read Access"
            ]
        },
        "url": "URL#379707",
        "sema_paperId": "a1ed3b35e24ab793f0a2eec177e7d38bd0e6eb78"
    },
    {
        "@score": "1",
        "@id": "379708",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "335/5778",
                        "text": "Ryan Tsang"
                    },
                    {
                        "@pid": "364/7717",
                        "text": "Asmita"
                    },
                    {
                        "@pid": "335/5799",
                        "text": "Doreen Joseph"
                    },
                    {
                        "@pid": "166/3227",
                        "text": "Soheil Salehi"
                    },
                    {
                        "@pid": "m/PrasantMohapatra",
                        "text": "Prasant Mohapatra"
                    },
                    {
                        "@pid": "63/3012",
                        "text": "Houman Homayoun"
                    }
                ]
            },
            "title": "FFXE: Dynamic Control Flow Graph Recovery for Embedded Firmware Binaries.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/TsangAJSMH24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/tsang",
            "url": "https://dblp.org/rec/conf/uss/TsangAJSMH24",
            "abstract": "Control Flow Graphs (CFG) play a significant role as an intermediary analysis in many advanced static and dynamic software analysis techniques. As firmware security and validation for embedded systems becomes a greater concern, accurate CFGs for embedded firmware binaries are crucial for adapting many valuable software analysis techniques to firmware, which can enable more thorough functionality and security analysis. In this work, we present a portable new dynamic CFG recovery technique based on dynamic forced execution that allows us to resolve indirect branches to registered callback functions, which are dependent on asynchronous changes to volatile memory. Our implementation, the Forced Firmware Execution Engine (FFXE), written in Python using the Unicorn emulation framework, is able to identify 100% of known callback functions in our test set of 36 firmware images, something none of the other techniques we tested against were able to do reliably. Using our results and observations, we compare our engine to 4 other CFG recovery techniques and provide both our thoughts on how this work might enhance other tools, and how it might be further developed. With our contributions, we hope to help enable the application of traditionally software-focused security analysis techniques to the hardware interactions that are integral to embedded system firmware.",
            "keywords": [
                "Embedded Firmware Analysis",
                "Control Flow Graph Recovery",
                "Dynamic CFG Recovery",
                "Callback Function Resolution",
                "Forced Firmware Execution Engine (FFXE)"
            ]
        },
        "url": "URL#379708",
        "sema_paperId": "c610489a331d5d736c9c997245369d42ced781ad"
    },
    {
        "@score": "1",
        "@id": "379710",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "87/1149",
                        "text": "Kai Tu"
                    },
                    {
                        "@pid": "290/1874",
                        "text": "Abdullah Al Ishtiaq"
                    },
                    {
                        "@pid": "255/5036",
                        "text": "Syed Md. Mukit Rashid"
                    },
                    {
                        "@pid": "361/1683",
                        "text": "Yilu Dong"
                    },
                    {
                        "@pid": "214/9012",
                        "text": "Weixuan Wang"
                    },
                    {
                        "@pid": "261/5092",
                        "text": "Tianwei Wu"
                    },
                    {
                        "@pid": "83/7270",
                        "text": "Syed Rafiul Hussain"
                    }
                ]
            },
            "title": "Logic Gone Astray: A Security Analysis Framework for the Control Plane Protocols of 5G Basebands.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/TuIRDWWH24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/tu",
            "url": "https://dblp.org/rec/conf/uss/TuIRDWWH24",
            "abstract": "We develop 5GBaseChecker \u2014 an efficient, scalable, and dynamic security analysis framework based on differential testing for analyzing 5G basebands\u2019 control plane protocol interactions. 5GBaseChecker first captures basebands\u2019 protocol behaviors as a finite state machine (FSM) through black-box automata learning. To facilitate efficient learning and improve scalability, 5GBaseChecker introduces novel hybrid and collaborative learning techniques. 5GBaseChecker then identifies input sequences for which the extracted FSMs provide deviating outputs. Finally, 5GBaseChecker leverages these deviations to efficiently identify the security properties from specifications and use those to triage if the deviations found in 5G basebands violate any properties. We evaluated 5GBaseChecker with 17 commercial 5G basebands and 2 open-source UE implementations and uncovered 22 implementation-level issues, including 13 exploitable vulnerabilities and 2 interoperability issues.",
            "keywords": [
                "5G Security",
                "Control Plane Protocols",
                "Differential Testing",
                "Finite State Machine",
                "Exploitable Vulnerabilities"
            ]
        },
        "url": "URL#379710",
        "sema_paperId": "aedc462040b020891ea2fceff6788ed6cf88f334"
    },
    {
        "@score": "1",
        "@id": "379711",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "156/1670",
                        "text": "Rafael Uetz"
                    },
                    {
                        "@pid": "205/2502",
                        "text": "Marco Herzog"
                    },
                    {
                        "@pid": "306/1240",
                        "text": "Louis Hackl\u00e4nder"
                    },
                    {
                        "@pid": "247/3518",
                        "text": "Simon Schwarz"
                    },
                    {
                        "@pid": "126/0576",
                        "text": "Martin Henze"
                    }
                ]
            },
            "title": "You Cannot Escape Me: Detecting Evasions of SIEM Rules in Enterprise Networks.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/UetzHHSH24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/uetz",
            "url": "https://dblp.org/rec/conf/uss/UetzHHSH24",
            "abstract": "Cyberattacks have grown into a major risk for organizations, with common consequences being data theft, sabotage, and extortion. Since preventive measures do not suffice to repel attacks, timely detection of successful intruders is crucial to stop them from reaching their final goals. For this purpose, many organizations utilize Security Information and Event Management (SIEM) systems to centrally collect security-related events and scan them for attack indicators using expert-written detection rules. However, as we show by analyzing a set of widespread SIEM detection rules, adversaries can evade almost half of them easily, allowing them to perform common malicious actions within an enterprise network without being detected. To remedy these critical detection blind spots, we propose the idea of adaptive misuse detection, which utilizes machine learning to compare incoming events to SIEM rules on the one hand and known-benign events on the other hand to discover successful evasions. Based on this idea, we present AMIDES, an open-source proof-of-concept adaptive misuse detection system. Using four weeks of SIEM events from a large enterprise network and more than 500 hand-crafted evasions, we show that AMIDES successfully detects a majority of these evasions without any false alerts. In addition, AMIDES eases alert analysis by assessing which rules were evaded. Its computational efficiency qualifies AMIDES for real-world operation and hence enables organizations to significantly reduce detection blind spots with moderate effort.",
            "keywords": [
                "SIEM Systems",
                "Adaptive Misuse Detection",
                "Evasion Detection",
                "Cyberattack Detection",
                "Event Analysis"
            ]
        },
        "url": "URL#379711",
        "sema_paperId": "6e0e1664ab4334e79a03ed7d8ca05cff19081479"
    },
    {
        "@score": "1",
        "@id": "379713",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "353/7673",
                        "text": "Swaathi Vetrivel"
                    },
                    {
                        "@pid": "301/5817",
                        "text": "Brennen Bouwmeester"
                    },
                    {
                        "@pid": "17/7444",
                        "text": "Michel van Eeten"
                    },
                    {
                        "@pid": "22/7256",
                        "text": "Carlos Hernandez Ga\u00f1\u00e1n"
                    }
                ]
            },
            "title": "IoT Market Dynamics: An Analysis of Device Sales, Security and Privacy Signals, and their Interactions.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/VetrivelBEG24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/vetrivel",
            "url": "https://dblp.org/rec/conf/uss/VetrivelBEG24",
            "abstract": "We explore the relationship between the Security and Privacy (S&P) of IoT devices and their sales, considering the S&P signals in the context of these sales. We obtained expert S&P ratings of IoT devices from a European consumer association and the corresponding sales data from a leading Dutch online store. We complemented this with additional information like user ratings, the number of reviews and update support duration from two Dutch online stores. Our regression model shows that, holding other variables constant, a one-standard-deviation increase in S&P ratings corresponds to a noteworthy 56% boost in sales. Crucially, we observe a possible correlation between price and demand for S&P; at lower prices, the sales of IoT devices are directly proportional to the S&P rating, but this relationship diminishes as price increases. Further, we \ufb01nd that the presence of update support duration information, intended as a security signal, corresponds to higher S&P ratings and, all else being constant, also corresponds to a 69% increase in sales. While the exact causal mechanisms for the boost in sales remain unclear, our \ufb01ndings suggest positive incentives might be at play for IoT devices offering S&P at affordable prices and presenting relevant S&P information at the point of purchase.",
            "keywords": [
                "IoT Device Sales",
                "Security and Privacy Ratings",
                "Consumer Behavior",
                "Sales Dynamics",
                "Update Support Duration"
            ]
        },
        "url": "URL#379713",
        "sema_paperId": "dff194ed3e44c5e1d9b62feda5f094f267a5546e"
    },
    {
        "@score": "1",
        "@id": "379714",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "331/2188",
                        "text": "Apurva Virkud"
                    },
                    {
                        "@pid": "331/2710",
                        "text": "Muhammad Adil Inam"
                    },
                    {
                        "@pid": "365/4120",
                        "text": "Andy Riddle"
                    },
                    {
                        "@pid": "07/6819-2",
                        "text": "Jason Liu 0002"
                    },
                    {
                        "@pid": "71/4292-11",
                        "text": "Gang Wang 0011"
                    },
                    {
                        "@pid": "126/3601",
                        "text": "Adam Bates 0001"
                    }
                ]
            },
            "title": "How does Endpoint Detection use the MITRE ATT&amp;CK Framework?",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/VirkudIR00024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/virkud",
            "url": "https://dblp.org/rec/conf/uss/VirkudIR00024",
            "abstract": "MITRE ATT&CK is an open-source taxonomy of adversary tactics, techniques, and procedures based on real-world observations. Increasingly, organizations leverage ATT&CK technique \u201ccoverage\u201d as the basis for evaluating their security posture, while Endpoint Detection and Response (EDR) and Security Indicator and Event Management (SIEM) products integrate ATT&CK into their design as well as marketing. However, the extent to which ATT&CK coverage is suitable to serve as a security metric remains unclear\u2014 Does ATT&CK coverage vary meaningfully across different products? Is it possible to achieve total coverage of ATT&CK? Do endpoint products that detect the same attack behaviors even claim to cover the same ATT&CK techniques? In this work, we attempt to answer these questions by conducting a comprehensive (and, to our knowledge, the first) analysis of endpoint detection products\u2019 use of MITRE ATT&CK. We begin by evaluating 3 ATT&CK-annotated detection rulesets from major commercial providers (Carbon Black, Splunk, Elastic) and a crowdsourced ruleset (Sigma) to identify commonalities and underutilized regions of the ATT&CK matrix. We continue by performing a qualitative analysis of unimplemented ATT&CK techniques to determine their feasibility as detection rules. Finally, we perform a consistency analysis of ATT&CK labeling by examining 37 specific threat entities for which at least 2 products include specific detection rules. Combined, our findings high-light the limitations of overdepending on ATT&CK coverage when evaluating security posture; most notably, many techniques are unrealizable as detection rules, and coverage of an ATT&CK technique does not consistently imply coverage of the same real-world threats.",
            "keywords": [
                "Endpoint Detection",
                "MITRE ATT&CK Framework",
                "Security Posture Evaluation",
                "Detection Rule Analysis",
                "Threat Coverage Consistency"
            ]
        },
        "url": "URL#379714",
        "sema_paperId": "56f08ad070e04aa3721515a6c42093007affcf17"
    },
    {
        "@score": "1",
        "@id": "379715",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "22/7148",
                        "text": "Jiming Wang"
                    },
                    {
                        "@pid": "32/1654-2",
                        "text": "Yan Kang 0002"
                    },
                    {
                        "@pid": "51/3529-2",
                        "text": "Chenggang Wu 0002"
                    },
                    {
                        "@pid": "235/2673",
                        "text": "Yuhao Hu"
                    },
                    {
                        "@pid": "69/4248",
                        "text": "Yue Sun"
                    },
                    {
                        "@pid": "381/1619",
                        "text": "Jikai Ren"
                    },
                    {
                        "@pid": "198/8150",
                        "text": "Yuanming Lai"
                    },
                    {
                        "@pid": "190/5112",
                        "text": "Mengyao Xie"
                    },
                    {
                        "@pid": "51/7008",
                        "text": "Charles Zhang"
                    },
                    {
                        "@pid": "75/4601-22",
                        "text": "Tao Li 0022"
                    },
                    {
                        "@pid": "75/3158-17",
                        "text": "Zhe Wang 0017"
                    }
                ]
            },
            "title": "OptFuzz: Optimization Path Guided Fuzzing for JavaScript JIT Compilers.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Wang00HSRLXZ0024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/wang-jiming",
            "url": "https://dblp.org/rec/conf/uss/Wang00HSRLXZ0024",
            "abstract": "Just-In-Time (JIT) compiler is a core component of JavaScript engines, which takes a snippet of JavaScript code as input and applies a series of optimization passes on it and then transforms it to machine code. The optimization passes often have some assumptions (e.g., variable types) on the target JavaScript code, and therefore will yield vulnerabilities if the assumptions do not hold. To discover such bugs, it is essential to thoroughly test different optimization passes, but previous work fails to do so and mainly focused on exploring code coverage. In this paper, we present the first optimization path guided fuzzing solution for JavaScript JIT compilers, namely OptFuzz, which focuses on exploring optimization path coverage. Specifically, we utilize an optimization trunk path metric to approximate the optimization path coverage, and use it as a feedback to guide seed preservation and seed scheduling of the fuzzing process. We have implemented a prototype of OptFuzz and evaluated it on 4 mainstream JavaScript engines. On earlier versions of JavaScript engines, OptFuzz found several times more bugs than baseline solutions. On the latest JavaScript engines, OptFuzz discovered 36 unknown bugs, while baseline solutions found none.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-wang-jiming.pdf",
            "keywords": [
                "JavaScript JIT Compilers",
                "Optimization Path Coverage",
                "Fuzzing",
                "Vulnerability Discovery",
                "Optimization Trunk Path Metric"
            ]
        },
        "url": "URL#379715",
        "sema_paperId": "f85fab903ff59ec35e365ca3348b1362c0f662f4"
    },
    {
        "@score": "1",
        "@id": "379716",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "223/6095",
                        "text": "Jialai Wang"
                    },
                    {
                        "@pid": "94/3019-8",
                        "text": "Chao Zhang 0008"
                    },
                    {
                        "@pid": "62/8898",
                        "text": "Longfei Chen"
                    },
                    {
                        "@pid": "34/4919",
                        "text": "Yi Rong"
                    },
                    {
                        "@pid": "169/9816",
                        "text": "Yuxiao Wu"
                    },
                    {
                        "@pid": "181/2812",
                        "text": "Hao Wang"
                    },
                    {
                        "@pid": "228/6653",
                        "text": "Wende Tan"
                    },
                    {
                        "@pid": "181/2688-2",
                        "text": "Qi Li 0002"
                    },
                    {
                        "@pid": "24/1320",
                        "text": "Zongpeng Li"
                    }
                ]
            },
            "title": "Improving ML-based Binary Function Similarity Detection by Assessing and Deprioritizing Control Flow Graph Features.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Wang0CRWWT0L24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/wang-jialai",
            "url": "https://dblp.org/rec/conf/uss/Wang0CRWWT0L24",
            "abstract": "Machine learning-based binary function similarity detection (ML-BFSD) has witnessed significant progress recently. They often choose control flow graph (CFG) as an important feature to learn out of functions, as CFGs characterize the control dependencies between basic code blocks. However, the exact role of CFGs in model decisions is not explored, and the extent to which CFGs might lead to model errors is unknown. This work takes a first step towards assessing the role of CFGs in ML-BFSD solutions both theoretically and practically, and promotes their performance accordingly. First, we adapt existing explanation methods to interpreting ML-BFSD solutions, and theoretically reveal that existing models heavily rely on CFG features . Then, we design a solution \u03b4 CFG to manipulate CFGs and practically demonstrate the lack of robustness of existing models. We have extensively evaluated \u03b4 CFG on 11 state-of-the-art (SOTA) ML-BFSD solutions, and find that the models\u2019 results would flip if we manipulate the query functions\u2019 CFGs but keep semantics, showing that most models have bias on CFG features . Our theoretic and practical assessment solutions can also serve as a robustness validator for the development of future ML-BFSD solutions. Lastly, we present a solution to utilize \u03b4 CFG to augment training data, which helps deprioritize CFG features",
            "keywords": [
                "Binary Function Similarity Detection",
                "Control Flow Graphs",
                "Model Robustness",
                "Feature Assessment",
                "Training Data Augmentation"
            ]
        },
        "url": "URL#379716",
        "sema_paperId": "a78817a3f430d3f046ab70e7c0eda2c56a40c502"
    },
    {
        "@score": "1",
        "@id": "379717",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "00/8454",
                        "text": "Yujie Wang"
                    },
                    {
                        "@pid": "54/2788-6",
                        "text": "Ao Li 0006"
                    },
                    {
                        "@pid": "03/2885",
                        "text": "Jinwen Wang"
                    },
                    {
                        "@pid": "b/SKBaruah",
                        "text": "Sanjoy K. Baruah"
                    },
                    {
                        "@pid": "181/2597-17",
                        "text": "Ning Zhang 0017"
                    }
                ]
            },
            "title": "Opportunistic Data Flow Integrity for Real-time Cyber-physical Systems Using Worst Case Execution Time Reservation.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Wang0WB024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/wang-yujie",
            "url": "https://dblp.org/rec/conf/uss/Wang0WB024",
            "abstract": "With the proliferation of safety-critical real-time systems in our daily life, it is imperative that their security is protected to guarantee their functionalities. To this end, one of the most powerful modern security primitives is the enforcement of data flow integrity. However, the run-time overhead can be prohibitive for real-time cyber-physical systems. On the other hand, due to strong safety requirements on such real-time cyber-physical systems, platforms are often designed with enough reservation such that the system remains real-time even if it is experiencing the worst-case execution time. We conducted a measurement study on eight popular CPS systems and found the worst-case execution time is often at least five times the average run time. In this paper, we propose opportunistic data flow integrity, OP-DFI, that takes advantage of the system reservation to enforce data flow integrity to the CPS software. To avoid impacting the real-time property, OP-DFI tackles the challenge of slack estimation and run-time policy swapping to take advantage of the extra time in the system opportunistically. To ensure the security protection remains coherent, OP-DFI leverages in-line reference monitors and hardware-assisted features to perform dynamic fine-grained sandboxing. We evaluated OP-DFI on eight real-time CPS. With a worst-case execution time overhead of 2.7%, OP-DFI effectively performs DFI checking on 95.5% of all memory operations and 99.3% of safety-critical control-related memory operations on average.",
            "keywords": [
                "Cyber-Physical Systems",
                "Data Flow Integrity",
                "Real-time Systems",
                "Execution Time Reservation",
                "Opportunistic Security"
            ]
        },
        "url": "URL#379717",
        "sema_paperId": "edac11c23621840d53ab8e0c283367950907eb0a"
    },
    {
        "@score": "1",
        "@id": "379718",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "64/9796",
                        "text": "Mingzhe Wang"
                    },
                    {
                        "@pid": "51/239-6",
                        "text": "Jie Liang 0006"
                    },
                    {
                        "@pid": "228/5716",
                        "text": "Chijin Zhou"
                    },
                    {
                        "@pid": "24/968-10",
                        "text": "Zhiyong Wu 0010"
                    },
                    {
                        "@pid": "337/0812",
                        "text": "Jingzhou Fu"
                    },
                    {
                        "@pid": "02/10578-5",
                        "text": "Zhuo Su 0005"
                    },
                    {
                        "@pid": "09/8600-1",
                        "text": "Qing Liao 0001"
                    },
                    {
                        "@pid": "29/1758-6",
                        "text": "Bin Gu 0006"
                    },
                    {
                        "@pid": "381/1667",
                        "text": "Bodong Wu"
                    },
                    {
                        "@pid": "21/4633-1",
                        "text": "Yu Jiang 0001"
                    }
                ]
            },
            "title": "Data Coverage for Guided Fuzzing.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Wang0ZWF000W024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/wang-mingzhe",
            "url": "https://dblp.org/rec/conf/uss/Wang0ZWF000W024",
            "abstract": "Code coverage is crucial for fuzzing. It helps fuzzers identify areas of a program that have not been explored, which are often the most likely to contain bugs. However, code coverage only reflects a small part of a program's structure. Many crucial program constructs, such as constraints, automata, and Turing-complete domain-specific languages, are embedded in a program as constant data. Since this data cannot be effectively reflected by code coverage, it remains a major challenge for modern fuzzing practices.\nTo address this challenge, we propose data coverage for guided fuzzing. The idea is to detect novel constant data references and maximize their coverage. However, the widespread use of constant data can significantly impact fuzzing throughput if not handled carefully. To overcome this issue, we optimize for real-world fuzzing practices by classifying data access according to semantics and designing customized collection strategies. We also develop novel storage and utilization techniques for improved fuzzing efficiency. Finally, we enhance libFuzzer with data coverage and submit it to Google's FuzzBench for evaluation. Our approach outperforms many state-of-the-art fuzzers and achieves the best coverage score in the experiment. Furthermore, we have discovered 28 previously-unknown bugs on OSS-Fuzz projects that were well-fuzzed using code coverage.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-wang-mingzhe.pdf",
            "keywords": [
                "Guided Fuzzing",
                "Code Coverage",
                "Constant Data",
                "Fuzzing Efficiency",
                "Bug Detection"
            ]
        },
        "url": "URL#379718",
        "sema_paperId": "b749d00c072d1446be9a458e8a6d4ca2e94dc985"
    },
    {
        "@score": "1",
        "@id": "379719",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "24/10098",
                        "text": "Zicheng Wang"
                    },
                    {
                        "@pid": "381/1645",
                        "text": "Yicheng Guang"
                    },
                    {
                        "@pid": "16/6884-1",
                        "text": "Yueqi Chen 0001"
                    },
                    {
                        "@pid": "277/7909",
                        "text": "Zhenpeng Lin"
                    },
                    {
                        "@pid": "290/7624",
                        "text": "Michael V. Le"
                    },
                    {
                        "@pid": "353/7560",
                        "text": "Dang K. Le"
                    },
                    {
                        "@pid": "96/2005",
                        "text": "Dan Williams 0001"
                    },
                    {
                        "@pid": "40/6431",
                        "text": "Xinyu Xing"
                    },
                    {
                        "@pid": "76/10471",
                        "text": "Zhongshu Gu"
                    },
                    {
                        "@pid": "45/1350",
                        "text": "Hani Jamjoom"
                    }
                ]
            },
            "title": "SeaK: Rethinking the Design of a Secure Allocator for OS Kernel.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WangG0LLL0XGJ24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/wang-zicheng",
            "url": "https://dblp.org/rec/conf/uss/WangG0LLL0XGJ24",
            "abstract": "In recent years, heap-based exploitation has become the most dominant attack against the Linux kernel. Securing the kernel heap is of vital importance for kernel protection. Though the Linux kernel allocator has some security designs in place to counter exploitation, our analytical experiments reveal that they can barely provide the expected results. This shortfall is rooted in the current strategy of designing secure kernel allocators which insists on protecting every object all the time. Such strategy inherently conflicts with the kernel nature. To this end, we advocate for rethinking the design of secure kernel allocator. In this work, we explore a new strategy which centers around the \u201catomic alleviation\u201d concept, featuring flexibility and efficiency in design and deployment. Recent advancements in kernel design and research outcomes on exploitation techniques enable us to prototype this strategy in a tool named SeaK . We used real-world cases to thoroughly evaluate SeaK . The results validate that SeaK substantially strengthens heap security, outperforming all existing features, without incurring noticeable performance and memory cost. Besides, SeaK shows excellent scalability and stability in the production scenario.",
            "keywords": [
                "Kernel Allocator Security",
                "Heap Exploitation",
                "Atomic Alleviation",
                "Memory Management",
                "Linux Kernel Protection"
            ]
        },
        "url": "URL#379719",
        "sema_paperId": "3b154052977b160b278356b2a3a2c94a8f91286e"
    },
    {
        "@score": "1",
        "@id": "379720",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "63/1591-12",
                        "text": "Shuo Wang 0012"
                    },
                    {
                        "@pid": "122/0826",
                        "text": "Hongsheng Hu"
                    },
                    {
                        "@pid": "342/7693",
                        "text": "Jiamin Chang"
                    },
                    {
                        "@pid": "188/6037",
                        "text": "Benjamin Zi Hao Zhao"
                    },
                    {
                        "@pid": "150/3272",
                        "text": "Qi Alfred Chen"
                    },
                    {
                        "@pid": "166/1912",
                        "text": "Minhui Xue 0001"
                    }
                ]
            },
            "title": "DNN-GP: Diagnosing and Mitigating Model&apos;s Faults Using Latent Concepts.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WangHCZCX24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/wang-shuo",
            "url": "https://dblp.org/rec/conf/uss/WangHCZCX24",
            "abstract": "Despite the impressive capabilities of Deep Neural Networks (DNN), these systems remain fault-prone due to unresolved issues of robustness to perturbations and concept drift. Existing approaches to interpreting faults often provide only low-level abstractions, while struggling to extract meaningful concepts to understand the root cause. Furthermore, these prior methods lack integration and generalization across multiple types of faults. To address these limitations, we present a fault diagnosis tool (akin to a General Practitioner) DNN-GP, an integrated interpreter designed to diagnose various types of model faults through the interpretation of latent concepts. DNN-GP incorporates probing samples derived from adversarial attacks, semantic attacks, and samples exhibiting drifting issues to provide a comprehensible interpretation of a model\u2019s erroneous decisions. Armed with an awareness of the faults, DNN-GP derives countermeasures from the concept space to bolster the model\u2019s resilience. DNN-GP is trained once on a dataset and can be transferred to provide versatile, unsupervised diagnoses for other models, and is sufficiently general to effectively mitigate unseen attacks. DNN-GP is evaluated on three real-world datasets covering both attack and drift scenarios to demonstrate state-to-the-art detection accuracy (near 100%) with low false positive rates ( < 5%).",
            "keywords": [
                "Fault Diagnosis",
                "Model Robustness",
                "Latent Concepts",
                "Adversarial Attacks",
                "Concept Drift"
            ]
        },
        "url": "URL#379720",
        "sema_paperId": "305457b6d5465dbf477d09843c096b4fe6eb76ab"
    },
    {
        "@score": "1",
        "@id": "379721",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "08/10205",
                        "text": "Haichen Wang"
                    },
                    {
                        "@pid": "146/9250",
                        "text": "Shuchao Pang"
                    },
                    {
                        "@pid": "91/7802-1",
                        "text": "Zhigang Lu 0001"
                    },
                    {
                        "@pid": "371/5850",
                        "text": "Yihang Rao"
                    },
                    {
                        "@pid": "03/4413",
                        "text": "Yongbin Zhou"
                    },
                    {
                        "@pid": "166/1912",
                        "text": "Minhui Xue 0001"
                    }
                ]
            },
            "title": "dp-promise: Differentially Private Diffusion Probabilistic Models for Image Synthesis.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WangP0RZX24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/wang-haichen",
            "url": "https://dblp.org/rec/conf/uss/WangP0RZX24",
            "abstract": "Utilizing sensitive images (e.g., human faces) for training DL models raises privacy concerns. One straightforward solution is to replace the private images with synthetic ones generated by deep generative models. Among all image synthesis meth-ods, diffusion models (DMs) yield impressive performance. Unfortunately, recent studies have revealed that DMs incur privacy challenges due to the memorization of the training instances. To preserve the existence of a single private sample of DMs, many works have explored to apply DP on DMs from different perspectives. However, existing works on differentially private DMs only consider DMs as regular deep models, such that they inject unnecessary DP noise in addition to the forward process noise in DMs, damaging the model utility. To address the issue, this paper proposes Differentially Private Diffusion Probabilistic Models for Image Synthesis, dp-promise, which theoretically guarantees approximate DP by leveraging the DM noise during the forward process. Extensive experiments demonstrate that, given the same privacy budget, dp-promise outperforms the state-of-the-art on the image quality of differentially private image synthesis across the standard metrics and datasets.",
            "keywords": [
                "Differential Privacy",
                "Diffusion Models",
                "Image Synthesis",
                "Privacy Preservation",
                "Synthetic Image Generation"
            ]
        },
        "url": "URL#379721",
        "sema_paperId": "222dfc9cade139a47f482d870358fe30249488ff"
    },
    {
        "@score": "1",
        "@id": "379722",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "264/2819",
                        "text": "Ping-Lun Wang"
                    },
                    {
                        "@pid": "224/9301",
                        "text": "Riccardo Paccagnella"
                    },
                    {
                        "@pid": "150/9448",
                        "text": "Riad S. Wahby"
                    },
                    {
                        "@pid": "177/8590",
                        "text": "Fraser Brown"
                    }
                ]
            },
            "title": "Bending microarchitectural weird machines towards practicality.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WangPWB24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/wang-ping-lun",
            "url": "https://dblp.org/rec/conf/uss/WangPWB24",
            "abstract": ",",
            "keywords": [
                "Microarchitectural Attacks",
                "Weird Machines",
                "Practical Applications",
                "Vulnerability Exploitation",
                "System Security"
            ]
        },
        "url": "URL#379722",
        "sema_paperId": "ef5f7a27c699fc3532b911cd4753f8c73094f2a4"
    },
    {
        "@score": "1",
        "@id": "379723",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "212/1333",
                        "text": "Xingkai Wang"
                    },
                    {
                        "@pid": "18/5040",
                        "text": "Wenbo Shen"
                    },
                    {
                        "@pid": "381/1663",
                        "text": "Yujie Bu"
                    },
                    {
                        "@pid": "179/8187",
                        "text": "Jinmeng Zhou"
                    },
                    {
                        "@pid": "15/7381",
                        "text": "Yajin Zhou"
                    }
                ]
            },
            "title": "DMAAUTH: A Lightweight Pointer Integrity-based Secure Architecture to Defeat DMA Attacks.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WangSBZZ24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/wang-xingkai",
            "url": "https://dblp.org/rec/conf/uss/WangSBZZ24",
            "abstract": "IOMMU has been introduced to thwart DMA attacks. However, the performance degradation prevents it from being enabled on most systems. Even worse, recent studies show that IOMMU is still vulnerable to sub-page and deferred invalidation attacks, posing threats to systems with IOMMU enabled. This paper aims to provide a lightweight and secure so-lution to defend against DMA attacks. Based on our measurement and characterizing of DMA behavior, we propose D MA A UTH , a lightweight pointer integrity-based hardware-software co-design architecture. D MA A UTH utilizes a novel technique named Arithmetic-capable Pointer AuthentiCation (APAC), which protects the DMA pointer integrity while supporting pointer arithmetic. It also places a dedicated hardware named Authenticator on the bus to authenticate all the DMA transactions. Combining APAC, per-mapping metadata, and the Authenticator, D MA A UTH achieves strict byte-grained spatial protection and temporal protection. We implement D MA A UTH on a real FPGA hardware board. Specifically, we first realize a PCIe-customizable SoC on real FPGA, based on which we implement hardware version D MA A UTH and conduct a thorough evaluation. We also implement D MA A UTH on both ARM and RISC-V emulators to demonstrate its cross-architecture capability. Our evaluation shows that D MA A UTH is faster and safer than IOMMU while being transparent to devices, drivers, and IOMMU.",
            "keywords": [
                "DMA Attacks",
                "Pointer Integrity",
                "IOMMU Vulnerabilities",
                "Hardware-Software Co-design",
                "Arithmetic-capable Pointer Authentication (APAC)"
            ]
        },
        "url": "URL#379723",
        "sema_paperId": "5682c2a5a2ce05c576e6ec1243ec59de80db64aa"
    },
    {
        "@score": "1",
        "@id": "379724",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "25/4764-6",
                        "text": "Yibo Wang 0006"
                    },
                    {
                        "@pid": "09/1770",
                        "text": "Yuzhe Tang"
                    },
                    {
                        "@pid": "181/2853-17",
                        "text": "Kai Li 0017"
                    },
                    {
                        "@pid": "269/2842",
                        "text": "Wanning Ding"
                    },
                    {
                        "@pid": "31/4676",
                        "text": "Zhihua Yang"
                    }
                ]
            },
            "title": "Understanding Ethereum Mempool Security under Asymmetric DoS by Symbolized Stateful Fuzzing.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WangT0DY24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/wang-yibo",
            "url": "https://dblp.org/rec/conf/uss/WangT0DY24",
            "abstract": "In blockchains, mempool controls transaction flow before consensus, denial of whose service hurts the health and security of blockchain networks. This paper presents MPFUZZ, the first mempool fuzzer to find asymmetric DoS bugs by symbolically exploring mempool state space and optimistically estimating the promisingness an intermediate state is in reaching bug oracles. Compared to the baseline blockchain fuzzers, MPFUZZ achieves a>100x speedup in finding known DETER exploits. Running MPFUZZ on six major Ethereum clients leads to the discovering of new mempool vulnerabilities, which exhibit a wide variety of sophisticated patterns including stealthy mempool eviction and mempool locking. Rule-based mitigation schemes are proposed against newly discovered vulnerabilities.",
            "keywords": [
                "Ethereum Mempool",
                "Denial of Service",
                "MPFUZZ",
                "Mempool Vulnerabilities",
                "Asymmetric DoS"
            ]
        },
        "url": "URL#379724",
        "sema_paperId": "4e14c13fa3110f4d8175db33f97bdecbae2a8193"
    },
    {
        "@score": "1",
        "@id": "379725",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "148/9655",
                        "text": "Zihao Wang"
                    },
                    {
                        "@pid": "77/1147-1",
                        "text": "Di Tang 0001"
                    },
                    {
                        "@pid": "06/6268",
                        "text": "XiaoFeng Wang 0001"
                    },
                    {
                        "@pid": "20/6417",
                        "text": "Wei He"
                    },
                    {
                        "@pid": "381/1696",
                        "text": "Zhaoyang Geng"
                    },
                    {
                        "@pid": "57/9813-1",
                        "text": "Wenhao Wang 0001"
                    }
                ]
            },
            "title": "Tossing in the Dark: Practical Bit-Flipping on Gray-box Deep Neural Networks for Runtime Trojan Injection.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WangT0HG024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/wang-zihao-tossing",
            "url": "https://dblp.org/rec/conf/uss/WangT0HG024",
            "abstract": "Although Trojan attacks on deep neural networks (DNNs) have been extensively studied, the threat of run-time Trojan injection has only recently been brought to attention. Unlike data poisoning attacks that target the training stage of a DNN model, a run-time attack executes an exploit such as Rowham-mer on memory to flip the bits of the target model and thereby implant a Trojan. This threat is stealthier but more challenging, as it requires flipping a set of bits in the target model to introduce an effective Trojan without noticeably downgrading the model\u2019s accuracy. This has been achieved only under the less realistic assumption that the target model is fully shared with the adversary through memory, thus enabling them to flip bits across all model layers, including the last few layers. For the first time, we have investigated run-time Trojan Injection under a more realistic gray-box scenario. In this scenario, a model is perceived in an encoder-decoder manner: the encoder is public and shared through memory, while the decoder is private and so considered to be black-box and inaccessible to unauthorized parties. To address the unique challenge posed by the black-box decoder to Trojan injection in this scenario, we developed a suite of innovative techniques. Using these techniques, we constructed our gray-box attack, Groan, which stands out as both effective and stealthy. Our experiments show that Groan is capable of injecting a highly effective Trojan into the target model, while also largely preserving its performance, even in the presence of state-of-the-art memory protection.",
            "keywords": [
                "Trojan Injection",
                "Gray-box Attack",
                "Bit-Flipping",
                "Deep Neural Network Vulnerabilities",
                "Runtime Exploits"
            ]
        },
        "url": "URL#379725",
        "sema_paperId": "b48b94de174e2f6968978454f9bb61a45a15008d"
    },
    {
        "@score": "1",
        "@id": "379726",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "73/9584",
                        "text": "Lijin Wang"
                    },
                    {
                        "@pid": "62/2631",
                        "text": "Jingjing Wang"
                    },
                    {
                        "@pid": "22/2422",
                        "text": "Jie Wan"
                    },
                    {
                        "@pid": "339/3387",
                        "text": "Lin Long"
                    },
                    {
                        "@pid": "206/0840",
                        "text": "Ziqi Yang"
                    },
                    {
                        "@pid": "148/4477",
                        "text": "Zhan Qin"
                    }
                ]
            },
            "title": "Property Existence Inference against Generative Models.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WangWWLYQ24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/wang-lijin",
            "url": "https://dblp.org/rec/conf/uss/WangWWLYQ24",
            "abstract": "Generative models have served as the backbone of versatile tools with a wide range of applications across various \ufb01elds in recent years. However, it has been demonstrated that privacy concerns, such as membership information leakage of the training dataset, exist for generative models. In this paper, we perform property existence inference against generative models as a new type of information leakage, which aims to infer whether any samples with a given property are contained in the training set. For example, to infer if any images (i.e., samples) of a speci\ufb01c brand of cars (i.e., property) are used to train the target model. We focus on the leakage of existence information of properties with very low proportions in the training set, which has been overlooked in previous works. We leverage the feature-level consistency of the generated data with the training data to launch inferences and validate the property existence information leakage across diverse architectures of generative models. We have examined various factors in\ufb02uencing the property existence inference and investigated how generated samples leak property existence information. In our conclusion, most generative models are vulnerable to property existence inferences. Ad-ditionally, we have validated our attack in Stable Diffusion which is a large-scale open-source generative model in real-world scenarios, and demonstrated its risk of property existence information leakage. The source code is available at https://github.com/wljLlla/PEI_Code .",
            "keywords": [
                "Generative Models",
                "Information Leakage",
                "Property Existence Inference",
                "Training Dataset Privacy",
                "Stable Diffusion"
            ]
        },
        "url": "URL#379726",
        "sema_paperId": "735553000aab84eefc040360916fe51a362ab1cc"
    },
    {
        "@score": "1",
        "@id": "379727",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "314/5373",
                        "text": "Songlei Wang"
                    },
                    {
                        "@pid": "60/3312",
                        "text": "Yifeng Zheng"
                    },
                    {
                        "@pid": "j/XiaohuaJia",
                        "text": "Xiaohua Jia"
                    }
                ]
            },
            "title": "GraphGuard: Private Time-Constrained Pattern Detection Over Streaming Graphs in the Cloud.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WangZJ24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/wang-songlei",
            "url": "https://dblp.org/rec/conf/uss/WangZJ24",
            "abstract": "Streaming graphs have seen wide adoption in diverse scenarios due to their superior ability to capture temporal interactions among entities. With the proliferation of cloud computing, it has become increasingly common to utilize the cloud for storing and querying streaming graphs. Among others, streaming graphs-based time-constrained pattern detection, which aims to continuously detect subgraphs matching a given query pattern within a sliding time window, benefits various applications such as credit card fraud detection and cyber-attack detection. Deploying such services on the cloud, however, entails severe security and privacy risks. This paper presents GraphGuard, the first system for privacy-preserving outsourcing of time-constrained pattern detection over streaming graphs. GraphGuard is constructed from a customized synergy of insights on graph modeling, lightweight secret sharing, edge differential privacy, and data encoding and padding, safeguarding the confidentiality of edge/vertex labels and the connections between vertices in the streaming graph and query patterns. We implement and evaluate GraphGuard on several real-world graph datasets. The evaluation results show that GraphGuard takes only a few seconds to securely process an encrypted query pattern over an encrypted snapshot of streaming graphs within a time window of size 50,000. Compared to a baseline built on generic secure multiparty computation, GraphGuard achieves up to 60\u00d7 improvement in query latency and up to 98% savings in communication.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-wang-songlei.pdf",
            "keywords": [
                "Streaming Graphs",
                "Privacy-Preserving Computation",
                "Pattern Detection",
                "Time-Constrained Queries",
                "Graph Confidentiality"
            ]
        },
        "url": "URL#379727",
        "sema_paperId": "0d72706a19b34a7e962a12c0db2587e2a111be25"
    },
    {
        "@score": "1",
        "@id": "379728",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "148/9655",
                        "text": "Zihao Wang"
                    },
                    {
                        "@pid": "72/1974",
                        "text": "Rui Zhu"
                    },
                    {
                        "@pid": "215/3401",
                        "text": "Dongruo Zhou"
                    },
                    {
                        "@pid": "90/545-1",
                        "text": "Zhikun Zhang 0001"
                    },
                    {
                        "@pid": "85/5397",
                        "text": "John Mitchell"
                    },
                    {
                        "@pid": "90/3951",
                        "text": "Haixu Tang"
                    },
                    {
                        "@pid": "06/6268",
                        "text": "XiaoFeng Wang 0001"
                    }
                ]
            },
            "title": "DPAdapter: Improving Differentially Private Deep Learning through Noise Tolerance Pre-training.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WangZZZMT024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/wang-zihao-dpadapter",
            "url": "https://dblp.org/rec/conf/uss/WangZZZMT024",
            "abstract": "Recent developments have underscored the critical role of \\textit{differential privacy} (DP) in safeguarding individual data for training machine learning models. However, integrating DP oftentimes incurs significant model performance degradation due to the perturbation introduced into the training process, presenting a formidable challenge in the {differentially private machine learning} (DPML) field. To this end, several mitigative efforts have been proposed, typically revolving around formulating new DPML algorithms or relaxing DP definitions to harmonize with distinct contexts. In spite of these initiatives, the diminishment induced by DP on models, particularly large-scale models, remains substantial and thus, necessitates an innovative solution that adeptly circumnavigates the consequential impairment of model utility. In response, we introduce DPAdapter, a pioneering technique designed to amplify the model performance of DPML algorithms by enhancing parameter robustness. The fundamental intuition behind this strategy is that models with robust parameters are inherently more resistant to the noise introduced by DP, thereby retaining better performance despite the perturbations. DPAdapter modifies and enhances the sharpness-aware minimization (SAM) technique, utilizing a two-batch strategy to provide a more accurate perturbation estimate and an efficient gradient descent, thereby improving parameter robustness against noise. Notably, DPAdapter can act as a plug-and-play component and be combined with existing DPML algorithms to further improve their performance. Our experiments show that DPAdapter vastly enhances state-of-the-art DPML algorithms, increasing average accuracy from 72.92\\% to 77.09\\% with a privacy budget of $\\epsilon=4$.",
            "keywords": [
                "Differential Privacy",
                "DPML Algorithms",
                "Model Performance",
                "Parameter Robustness",
                "Noise Tolerance"
            ]
        },
        "url": "URL#379728",
        "sema_paperId": "4b8efb06e954a61138f1bd49fb3266840f4abdb4"
    },
    {
        "@score": "1",
        "@id": "379729",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "217/4562",
                        "text": "Miranda Wei"
                    },
                    {
                        "@pid": "61/1413",
                        "text": "Sunny Consolvo"
                    },
                    {
                        "@pid": "15/3631",
                        "text": "Patrick Gage Kelley"
                    },
                    {
                        "@pid": "k/TadayoshiKohno",
                        "text": "Tadayoshi Kohno"
                    },
                    {
                        "@pid": "57/1705",
                        "text": "Tara Matthews"
                    },
                    {
                        "@pid": "94/8813",
                        "text": "Sarah Meiklejohn"
                    },
                    {
                        "@pid": "23/2758",
                        "text": "Franziska Roesner"
                    },
                    {
                        "@pid": "322/0210",
                        "text": "Renee Shelby"
                    },
                    {
                        "@pid": "68/8283",
                        "text": "Kurt Thomas"
                    },
                    {
                        "@pid": "367/7077",
                        "text": "Rebecca Umbach"
                    }
                ]
            },
            "title": "Understanding Help-Seeking and Help-Giving on Social Media for Image-Based Sexual Abuse.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WeiCKKMMRSTU24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/wei-miranda-understanding",
            "url": "https://dblp.org/rec/conf/uss/WeiCKKMMRSTU24",
            "abstract": "Image-based sexual abuse (IBSA), like other forms of technology-facilitated abuse, is a growing threat to people's digital safety. Attacks include unwanted solicitations for sexually explicit images, extorting people under threat of leaking their images, or purposefully leaking images to enact revenge or exert control. In this paper, we explore how people seek and receive help for IBSA on social media. Specifically, we identify over 100,000 Reddit posts that engage relationship and advice communities for help related to IBSA. We draw on a stratified sample of 261 posts to qualitatively examine how various types of IBSA unfold, including the mapping of gender, relationship dynamics, and technology involvement to different types of IBSA. We also explore the support needs of victim-survivors experiencing IBSA and how communities help victim-survivors navigate their abuse through technical, emotional, and relationship advice. Finally, we highlight sociotechnical gaps in connecting victim-survivors with important care, regardless of whom they turn to for help.",
            "keywords": [
                "Image-Based Sexual Abuse",
                "Social Media Support",
                "Victim-Survivor Help-Seeking",
                "Technology-Facilitated Abuse",
                "Community Advice Dynamics"
            ]
        },
        "url": "URL#379729",
        "sema_paperId": "fd38ebbafdd66d5e9deb082bfdc5dcdd0ffbb522"
    },
    {
        "@score": "1",
        "@id": "379730",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "217/4562",
                        "text": "Miranda Wei"
                    },
                    {
                        "@pid": "280/8210",
                        "text": "Jaron Mink"
                    },
                    {
                        "@pid": "347/2148",
                        "text": "Yael Eiger"
                    },
                    {
                        "@pid": "k/TadayoshiKohno",
                        "text": "Tadayoshi Kohno"
                    },
                    {
                        "@pid": "141/9244",
                        "text": "Elissa M. Redmiles"
                    },
                    {
                        "@pid": "23/2758",
                        "text": "Franziska Roesner"
                    }
                ]
            },
            "title": "SoK (or SoLK?): On the Quantitative Study of Sociodemographic Factors and Computer Security Behaviors.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WeiMEKRR24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/wei-miranda-solk",
            "url": "https://dblp.org/rec/conf/uss/WeiMEKRR24",
            "abstract": "Researchers are increasingly exploring how gender, culture, and other sociodemographic factors correlate with user computer security and privacy behaviors. To more holistically understand relationships between these factors and behaviors, we make two contributions. First, we broadly survey existing scholarship on sociodemographics and secure behavior (151 papers) before conducting a focused literature review of 47 papers to synthesize what is currently known and identify open questions for future research. Second, by incorporating contemporary social and critical theories, we establish guidelines for future studies of sociodemographic factors and security behaviors that address how to overcome common pitfalls. We present a case study to demonstrate our guidelines in action, at-scale, that conduct a measurement study of the relationships between sociodemographics and de-identified, aggregated log data of security and privacy behaviors among 16,829 users on Facebook across 16 countries. Through these contributions, we position our work as a systemization of a lack of knowledge (SoLK). Overall, we find contradictory results and vast unknowns about how identity shapes security behavior. Through our guidelines and discussion, we chart new directions to more deeply examine how and why sociodemographic factors affect security behaviors.",
            "keywords": [
                "Sociodemographic Factors",
                "Computer Security Behaviors",
                "User Privacy",
                "Cultural Influence",
                "Gender Differences"
            ]
        },
        "url": "URL#379730",
        "sema_paperId": "b4ac36c3ec567e4344a59082cd80013fb0cd4dce"
    },
    {
        "@score": "1",
        "@id": "379731",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "119/5639",
                        "text": "Jianghong Wei"
                    },
                    {
                        "@pid": "245/3781",
                        "text": "Guohua Tian"
                    },
                    {
                        "@pid": "99/4292-2",
                        "text": "Ding Wang 0002"
                    },
                    {
                        "@pid": "13/93",
                        "text": "Fuchun Guo"
                    },
                    {
                        "@pid": "12/3447",
                        "text": "Willy Susilo"
                    },
                    {
                        "@pid": "c/XiaofengChen1",
                        "text": "Xiaofeng Chen 0001"
                    }
                ]
            },
            "title": "Pixel+ and Pixel++: Compact and Efficient Forward-Secure Multi-Signatures for PoS Blockchain Consensus.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WeiTWGS024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/wei-jianghong",
            "url": "https://dblp.org/rec/conf/uss/WeiTWGS024",
            "abstract": "Multi-signature schemes have attracted considerable attention in recent years due to their popular applications in PoS blockchains. However, the use of general multi-signature schemes poses a critical threat to the security of PoS blockchains once signing keys get corrupted. That is, after an adversary obtains enough signing keys, it can break the immutable nature of PoS blockchains by forking the chain and modifying the history from some point in the past. Forward-secure multi-signature (FS-MS) schemes can overcome this issue by periodically updating signing keys. The only FS-MS construction currently available is Drijvers et al\u2019s Pixel , which builds on pairing groups and only achieves forward security at the time period level. In this work, we present new FS-MS constructions that either are free from pairing or capture forward security at the individual message level (i.e., fine-grained forward security). Our first construction Pixel+ works for a maximum number of time periods T . Pixel+ signatures consist of only one group element, and can be verified using two exponentiations. It is the first FS-MS from RSA assumption, and has 3.5x and 22.8x faster signing and verification than Pixel , respectively. Our second FS-MS construction Pixel++ is a pairing-based one. It immediately revokes the signing key\u2019s capacity of re-signing the message after creating a signature on this message, rather than at the end of the current time period. Thus, it provides more practical forward security than Pixel . On the other hand, Pixel++ is almost as efficient as Pixel in terms of signing and verification. Both Pixel+ and Pixel++ allow for non-interactive aggregation of signatures from independent signers and are proven to be secure in the random oracle model. In addition, they also support the aggregation of public keys, significantly reducing the storage overhead on PoS blockchains. We demonstrate how to integrate Pixel+ and Pixel++ into PoS blockchains. As a proof-of-concept, we provide implementations of Pixel+ and Pixel++ , and conduct several representative experiments to show that Pixel+ and Pixel++ have good concrete efficiency and are practical.",
            "keywords": [
                "Forward-Secure Multi-Signatures",
                "Proof-of-Stake Blockchain",
                "Key Revocation",
                "Signature Aggregation",
                "Efficiency in Cryptography"
            ]
        },
        "url": "URL#379731",
        "sema_paperId": "af26aebe99ee497303c9d266b4389cd97c73bc10"
    },
    {
        "@score": "1",
        "@id": "379732",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "155/8493",
                        "text": "Roy Weiss"
                    },
                    {
                        "@pid": "372/2581",
                        "text": "Daniel Ayzenshteyn"
                    },
                    {
                        "@pid": "67/4350",
                        "text": "Guy Amit"
                    },
                    {
                        "@pid": "160/6851",
                        "text": "Yisroel Mirsky"
                    }
                ]
            },
            "title": "What Was Your Prompt? A Remote Keylogging Attack on AI Assistants.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WeissAAM24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/weiss",
            "url": "https://dblp.org/rec/conf/uss/WeissAAM24",
            "abstract": "AI assistants are becoming an integral part of society, used for asking advice or help in personal and confidential issues. In this paper, we unveil a novel side-channel that can be used to read encrypted responses from AI Assistants over the web: the token-length side-channel. The side-channel reveals the character-lengths of a response's tokens (akin to word lengths). We found that many vendors, including OpenAI and Microsoft, had this side-channel prior to our disclosure.\nHowever, inferring a response's content with this side-channel is challenging. This is because, even with knowledge of token-lengths, a response can have hundreds of words resulting in millions of grammatically correct sentences. In this paper, we show how this can be overcome by (1) utilizing the power of a large language model (LLM) to translate these token-length sequences, (2) providing the LLM with inter-sentence context to narrow the search space and (3) performing a known-plaintext attack by fine-tuning the model on the target model's writing style.\nUsing these methods, we were able to accurately reconstruct 27% of an AI assistant's responses and successfully infer the topic from 53% of them. To demonstrate the threat, we performed the attack on OpenAI's ChatGPT-4 and Microsoft's Copilot on both browser and API traffic.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-weiss.pdf",
            "keywords": [
                "AI Assistants",
                "Token-Length Side-Channel",
                "Remote Keylogging Attack",
                "Response Reconstruction",
                "Known-Plaintext Attack"
            ]
        },
        "url": "URL#379732"
    },
    {
        "@score": "1",
        "@id": "379733",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "271/1209",
                        "text": "Hongbo Wen"
                    },
                    {
                        "@pid": "196/8839",
                        "text": "Jon Stephens"
                    },
                    {
                        "@pid": "05/4034",
                        "text": "Yanju Chen"
                    },
                    {
                        "@pid": "202/1679",
                        "text": "Kostas Ferles"
                    },
                    {
                        "@pid": "224/9387",
                        "text": "Shankara Pailoor"
                    },
                    {
                        "@pid": "341/2214",
                        "text": "Kyle Charbonnet"
                    },
                    {
                        "@pid": "85/3688",
                        "text": "Isil Dillig"
                    },
                    {
                        "@pid": "30/4550-1",
                        "text": "Yu Feng 0001"
                    }
                ]
            },
            "title": "Practical Security Analysis of Zero-Knowledge Proof Circuits.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WenSCFPCD024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/wen",
            "url": "https://dblp.org/rec/conf/uss/WenSCFPCD024",
            "abstract": "As privacy-sensitive applications based on zero-knowledge proofs (ZKPs) gain increasing traction, there is a pressing need to detect vulnerabilities in ZKP circuits. This paper studies common vulnerabilities in Circom (the most popular domain-specific language for ZKP circuits) and describes a static analysis framework for detecting these vulnerabilities. Our technique operates over an abstraction called the circuit dependence graph (CDG) that captures key properties of the circuit and allows expressing semantic vulnerability patterns as queries over the CDG abstraction. We have implemented 9 different detectors using this framework and performed an experimental evaluation on over 258 circuits from popular Circom projects on GitHub. According to our evaluation, these detectors can identify vulnerabilities, including previously unknown ones, with high precision and recall.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-wen_1.pdf",
            "keywords": [
                "Zero-Knowledge Proofs",
                "Circom",
                "Static Analysis",
                "Vulnerability Detection",
                "Circuit Dependence Graph (CDG)"
            ]
        },
        "url": "URL#379733"
    },
    {
        "@score": "1",
        "@id": "379734",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "329/9183",
                        "text": "Malte Wessels"
                    },
                    {
                        "@pid": "168/9554",
                        "text": "Simon Koch"
                    },
                    {
                        "@pid": "35/9056",
                        "text": "Giancarlo Pellegrino"
                    },
                    {
                        "@pid": "82/359",
                        "text": "Martin Johns"
                    }
                ]
            },
            "title": "SSRF vs. Developers: A Study of SSRF-Defenses in PHP Applications.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WesselsKPJ24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/wessels",
            "url": "https://dblp.org/rec/conf/uss/WesselsKPJ24",
            "abstract": "Server-side requests (SSR) are a potent and important tool for modern web applications, as they enable features such as link preview and web hooks. Unfortunately, naive usage of SSR opens the underlying application up to Server-Side Request Forgery \u2013 an underappreciated vulnerability risk. To shed light on this vulnerability class, we conduct an in-depth analysis of known exploitation methods as well as defenses and mitigations across PHP. We then proceed to study the prevalence of the vulnerability and defenses across 27,078 open-source PHP applications. For this we perform an initial data flow analysis, identifying attacker-controlled inputs into known SSR functions, followed up by a manual analysis of our results to gain a detailed understanding of the involved vulnerabilities and present defenses. Our results show that defenses are sparse. The hypermajority of our 237 detected data flows are vulnerable. Only two analyzed applications implement safe SSR features.\nSince known defenses are not used and detected attacker-controlled flows are almost always vulnerable, we can only conclude that developers are still unaware of SSR abuses and the need to defend against them. Consequently, SSRF is a present and underappreciated danger in modern web applications.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-wessels.pdf",
            "keywords": [
                "Server-Side Request Forgery",
                "PHP Applications",
                "Vulnerability Analysis",
                "Data Flow Analysis",
                "SSRF Defenses"
            ]
        },
        "url": "URL#379734",
        "sema_paperId": "0086aec00b06dc2a1783fc3c34baf750cb8c016b"
    },
    {
        "@score": "1",
        "@id": "379735",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "334/0589",
                        "text": "Sander Wiebing"
                    },
                    {
                        "@pid": "329/6265",
                        "text": "Alvise de Faveri Tron"
                    },
                    {
                        "@pid": "91/800",
                        "text": "Herbert Bos"
                    },
                    {
                        "@pid": "75/8194",
                        "text": "Cristiano Giuffrida"
                    }
                ]
            },
            "title": "InSpectre Gadget: Inspecting the Residual Attack Surface of Cross-privilege Spectre v2.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WiebingTBG24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/wiebing",
            "url": "https://dblp.org/rec/conf/uss/WiebingTBG24",
            "abstract": "Spectre v2 is one of the most severe transient execution vulnerabilities, as it allows an unprivileged attacker to lure a privileged (e.g., kernel) victim into speculatively jumping to a chosen gadget , which then leaks data back to the attacker. Spectre v2 is hard to eradicate. Even on last-generation Intel CPUs, security hinges on the unavailability of exploitable gadgets. Nonetheless, with (i) deployed mitigations\u2014eIBRS, no-eBPF, (Fine)IBT\u2014all aimed at hindering many usable gad-gets, (ii) existing exploits relying on now-privileged features (eBPF), and (iii) recent Linux kernel gadget analysis studies reporting no exploitable gadgets, the common belief is that there is no residual attack surface of practical concern. In this paper, we challenge this belief and uncover a significant residual attack surface for cross-privilege Spectre-v2 attacks. To this end, we present InSpectre Gadget , a new gadget analysis tool for in-depth inspection of Spectre gadgets. Unlike existing tools, ours performs generic constraint analysis and models knowledge of advanced exploitation techniques to accurately reason over gadget exploitability in an automated fashion. We show that our tool can not only uncover new (un-conventionally) exploitable gadgets in the Linux kernel, but that those gadgets are sufficient to bypass all deployed Intel mitigations. As a demonstration, we present the first native Spectre-v2 exploit against the Linux kernel on last-generation Intel CPUs, based on the recent BHI variant and able to leak arbitrary kernel memory at 3.5 kB/sec. We also present a number of gadgets and exploitation techniques to bypass the recent FineIBT mitigation, along with a case study on a 13th Gen Intel CPU that can leak kernel memory at 18 bytes/sec.",
            "keywords": [
                "Spectre v2",
                "Transient Execution Vulnerabilities",
                "Cross-Privilege Attacks",
                "Gadget Analysis",
                "Kernel Memory Leak"
            ]
        },
        "url": "URL#379735",
        "sema_paperId": "cb4c3d6d5bf1fb4913b23e2a3f990ad2014d0171"
    },
    {
        "@score": "1",
        "@id": "379736",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "183/3769",
                        "text": "Grant Williams"
                    },
                    {
                        "@pid": "251/0475",
                        "text": "Mert Erdemir"
                    },
                    {
                        "@pid": "247/7391",
                        "text": "Amanda Hsu"
                    },
                    {
                        "@pid": "381/1687",
                        "text": "Shraddha Bhat"
                    },
                    {
                        "@pid": "331/2323",
                        "text": "Abhishek Bhaskar"
                    },
                    {
                        "@pid": "53/10825",
                        "text": "Frank Li 0001"
                    },
                    {
                        "@pid": "61/1749",
                        "text": "Paul Pearce"
                    }
                ]
            },
            "title": "6Sense: Internet-Wide IPv6 Scanning and its Security Applications.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WilliamsEHBB0P24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/williams",
            "url": "https://dblp.org/rec/conf/uss/WilliamsEHBB0P24",
            "abstract": "Internet-wide scanning is a critical tool for security researchers and practitioners alike. By exhaustively exploring the entire IPv4 address space, Internet scanning has driven the development of new security protocols, found and tracked vulnerabilities, improved DDoS defenses, and illuminated global censorship. Unfortunately, the vast scale of the IPv6 address space\u2014340 trillion trillion trillion addresses\u2014precludes exhaustive scanning, necessitating entirely new IPv6-specific scanning methods. As IPv6 adoption continues to grow, developing IPv6 scanning methods is vital for maintaining our capability to comprehensively investigate Internet security. We present 6S ENSE , an end-to-end Internet-wide IPv6 scanning system. 6S ENSE utilizes reinforcement learning coupled with an online scanner to iteratively reduce the space of possible IPv6 addresses into a tractable scannable subspace, thus discovering new IPv6 Internet hosts. 6S ENSE is driven by a set of metrics we identify and define as key for evaluating the generality, diversity, and correctness of IPv6 scanning. We evaluate 6S ENSE and prior generative IPv6 discovery methods across these metrics, showing that 6S ENSE is able to identify tens of millions of IPv6 hosts, which compared to prior approaches, is up to 3.6x more hosts and 4x more end-site assignments, across a more diverse set of networks. From our analysis, we identify limitations in prior generative approaches that preclude their use for Internet-scale security scans. We also conduct the first Internet-wide scanning-driven security analysis of IPv6 hosts, focusing on TLS certificates unique to IPv6, surveying open ports and security-sensitive services, and identifying potential CVEs.",
            "keywords": [
                "IPv6 Scanning",
                "Internet-Wide Scanning",
                "Security Analysis",
                "TLS Certificates",
                "Vulnerabilities Identification"
            ]
        },
        "url": "URL#379736",
        "sema_paperId": "e9cddb01d8eb8a0d8379abcc46bb2bc218883034"
    },
    {
        "@score": "1",
        "@id": "379737",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "47/2819",
                        "text": "Yixin Wu"
                    },
                    {
                        "@pid": "63/10765-2",
                        "text": "Rui Wen 0002"
                    },
                    {
                        "@pid": "b/MichaelBackes1",
                        "text": "Michael Backes 0001"
                    },
                    {
                        "@pid": "124/6255",
                        "text": "Pascal Berrang"
                    },
                    {
                        "@pid": "83/8816",
                        "text": "Mathias Humbert"
                    },
                    {
                        "@pid": "14/4412",
                        "text": "Yun Shen"
                    },
                    {
                        "@pid": "06/6785-16",
                        "text": "Yang Zhang 0016"
                    }
                ]
            },
            "title": "Quantifying Privacy Risks of Prompts in Visual Prompt Learning.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Wu00BHS024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/wu-yixin",
            "url": "https://dblp.org/rec/conf/uss/Wu00BHS024",
            "abstract": "Large-scale pre-trained models are increasingly adapted to downstream tasks through a new paradigm called prompt learning. In contrast to fine-tuning, prompt learning does not update the pre-trained model's parameters. Instead, it only learns an input perturbation, namely prompt, to be added to the downstream task data for predictions. Given the fast development of prompt learning, a well-generalized prompt inevitably becomes a valuable asset as significant effort and proprietary data are used to create it. This naturally raises the question of whether a prompt may leak the proprietary information of its training data. In this paper, we perform the first comprehensive privacy assessment of prompts learned by visual prompt learning through the lens of property inference and membership inference attacks. Our empirical evaluation shows that the prompts are vulnerable to both attacks. We also demonstrate that the adversary can mount a successful property inference attack with limited cost. Moreover, we show that membership inference attacks against prompts can be successful with relaxed adversarial assumptions. We further make some initial investigations on the defenses and observe that our method can mitigate the membership inference attacks with a decent utility-defense trade-off but fails to defend against property inference attacks. We hope our results can shed light on the privacy risks of the popular prompt learning paradigm. To facilitate the research in this direction, we will share our code and models with the community.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-wu-yixin.pdf",
            "keywords": [
                "Visual Prompt Learning",
                "Privacy Assessment",
                "Property Inference Attacks",
                "Membership Inference Attacks",
                "Prompt Vulnerability"
            ]
        },
        "url": "URL#379737"
    },
    {
        "@score": "1",
        "@id": "379738",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "322/6647",
                        "text": "Chuxiong Wu"
                    },
                    {
                        "@pid": "81/583-1",
                        "text": "Qiang Zeng 0001"
                    }
                ]
            },
            "title": "Do You See How I Pose? Using Poses as an Implicit Authentication Factor for QR Code Payment.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Wu024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/wu-chuxiong",
            "url": "https://dblp.org/rec/conf/uss/Wu024",
            "abstract": "QR code payment has gained enormous popularity in the realm of mobile transactions, but concerns regarding its security keep growing. To bolster the security of QR code payment, we propose P QRA UTH , an innovative implicit second-factor authentication approach that exploits smartphone poses. In the proposed approach, when a consumer presents a payment QR code on her smartphone to a merchant\u2019s QR code scanner, the scanner\u2019s camera captures not only the QR code itself but also the smartphone\u2019s poses. By utilizing poses as an additional factor, in conjunction with QR code decoding, the scanner verifies the authenticity of the smartphone presenting the QR code. Our comprehensive evaluation demonstrates the effectiveness of P QRA UTH , affirming its security, accuracy and robustness.",
            "keywords": [
                "QR Code Payment",
                "Implicit Authentication",
                "Smartphone Poses",
                "Payment Security",
                "P QRA UTH"
            ]
        },
        "url": "URL#379738",
        "sema_paperId": "758c93010d1200acb0bee7cf955ff66ecacfbe65"
    },
    {
        "@score": "1",
        "@id": "379739",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "16/5608",
                        "text": "Jianliang Wu"
                    },
                    {
                        "@pid": "14/3295",
                        "text": "Patrick Traynor"
                    },
                    {
                        "@pid": "59/5539",
                        "text": "Dongyan Xu"
                    },
                    {
                        "@pid": "159/0537",
                        "text": "Dave (Jing) Tian"
                    },
                    {
                        "@pid": "99/3883",
                        "text": "Antonio Bianchi"
                    }
                ]
            },
            "title": "Finding Traceability Attacks in the Bluetooth Low Energy Specification and Its Implementations.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WuTXTB24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/wu-jianliang",
            "url": "https://dblp.org/rec/conf/uss/WuTXTB24",
            "abstract": "Bluetooth Low Energy (BLE) provides an efficient and convenient means for connecting a wide range of devices and peripherals. While its designers attempted to make tracking devices difficult through the use of MAC address randomization, a comprehensive analysis of the untraceability for the entire BLE protocol has not previously been conducted. In this paper, we create a formal model for BLE untraceability to reason about additional ways in which the specification allows for user tracking. Our model, implemented using ProVerif, transforms the untraceability problem into a reachability problem, and uncovers four previously unknown issues, namely IRK (Identity Resolving Key) reuse, BD_ADDR (MAC Address of Bluetooth Classic) reuse, CSRK (Connection Signature Re-solving Key) reuse, and ID_ADDR (Identity Address) reuse, enabling eight passive or active tracking attacks against BLE. We then build another formal model using Diff-Equivalence (DE) as a comparison to our reachability model. Our evaluation of the two models demonstrates the soundness of our reachability model, whereas the DE model is neither sound nor complete. We further confirm these vulnerabilities in 13 different devices, ranging from embedded systems to laptop computers, with each device having at least 2 of the 4 issues. We finally provide mitigations for both developers and end users. In so doing, we demonstrate that BLE systems remain trackable under several common scenarios.",
            "keywords": [
                "Bluetooth Low Energy",
                "Untraceability",
                "Tracking Attacks",
                "Identity Resolving Key",
                "MAC Address Reuse"
            ]
        },
        "url": "URL#379739",
        "sema_paperId": "6c85cbd198f83ec47def9424ecfb1fb0d7b6844b"
    },
    {
        "@score": "1",
        "@id": "379740",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "166/4902",
                        "text": "Yuhao Wu"
                    },
                    {
                        "@pid": "03/2885",
                        "text": "Jinwen Wang"
                    },
                    {
                        "@pid": "00/8454",
                        "text": "Yujie Wang"
                    },
                    {
                        "@pid": "336/4249",
                        "text": "Shixuan Zhai"
                    },
                    {
                        "@pid": "233/6392",
                        "text": "Zihan Li"
                    },
                    {
                        "@pid": "65/425",
                        "text": "Yi He"
                    },
                    {
                        "@pid": "30/3530-1",
                        "text": "Kun Sun 0001"
                    },
                    {
                        "@pid": "181/2688-2",
                        "text": "Qi Li 0002"
                    },
                    {
                        "@pid": "181/2597-17",
                        "text": "Ning Zhang 0017"
                    }
                ]
            },
            "title": "Your Firmware Has Arrived: A Study of Firmware Update Vulnerabilities.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WuWWZLH00024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/wu-yuhao",
            "url": "https://dblp.org/rec/conf/uss/WuWWZLH00024",
            "abstract": "Embedded devices are increasingly ubiquitous in our society. Firmware updates are one of the primary mechanisms to mitigate vulnerabilities in embedded systems. However, the firmware update procedure also introduces new attack surfaces, particularly through vulnerable firmware verification procedures. Unlike memory corruption bugs, numerous vulnerabilities in firmware updates stem from incomplete or incorrect verification steps, to which existing firmware analysis methods are not applicable. To bridge this gap, we propose ChkUp, an approach to Check for firmware Update vulnerabilities. ChkUp can resolve the program execution paths during firmware updates using cross-language inter-process control flow analysis and program slicing. With these paths, ChkUp locates firmware verification procedures, examining and validating their vulnerabilities. We implemented ChkUp and conducted a comprehensive analysis on 12,000 firmware images. Then, we validated the alerts in 150 firmware images from 33 device families, leading to the discovery of both zero-day and n-day vulnerabilities. Our findings were disclosed responsibly, resulting in the assignment of 25 CVE IDs and one PSV ID at the time of writing.",
            "keywords": [
                "Firmware Security",
                "Firmware Updates",
                "Vulnerability Verification",
                "Cross-Language Analysis",
                "ChkUp Tool"
            ]
        },
        "url": "URL#379740",
        "sema_paperId": "dcb135a814804ab2618e67da3932d212f254506d"
    },
    {
        "@score": "1",
        "@id": "379741",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "22/1911",
                        "text": "Mingli Wu"
                    },
                    {
                        "@pid": "10/6625",
                        "text": "Tsz Hon Yuen"
                    },
                    {
                        "@pid": "333/0485",
                        "text": "Kwan Yin Chan"
                    }
                ]
            },
            "title": "O-Ring and K-Star: Efficient Multi-party Private Set Intersection.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WuYC24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/wu-mingli",
            "url": "https://dblp.org/rec/conf/uss/WuYC24",
            "abstract": "Multi-party private set intersection (mPSI) securely enables multiple parties to know the intersection of their sets without disclosing anything else. Many mPSI protocols are not efficient in practice. In this paper, we propose two efficient mPSI protocols that are secure against an arbitrary number of colluding parties. In the protocol O-Ring, we take advantage of the ring network topology such that the communication costs of the party with the largest workload can be cheaper than other mPSI protocols with a star topology. In the protocol K-Star, we take advantage of the star topology to support better concurrency such that the protocol can run fast. K-Star is suitable for applications with a powerful centralized server. Different from KMPRT (CCS'17) and CDGOSS (CCS'21) that rely on Oblivious Programmable PRF primitive, we simply utilize the cheaper Oblivious PRF (OPRF) and a data structure Oblivious Key-value Store (OKVS). We further propose two fine-grained optimizations for OKVS and OPRF in multi-party cases to improve runtime performance.\nAfter extensive experiments, we demonstrate that both protocols run the fastest and achieve the lowest total communication costs compared with the state-of-the-art counterparts in most settings. Specifically, O-Ring/K-Star is respectively 1.6 \u00d7 \u223c 48.3 \u00d7 1.6\u00d7\u223c48.3\u00d7 and 4.0 \u00d7 \u223c 39.8 \u00d7 4.0\u00d7\u223c39.8\u00d7 (except one setting) cheaper than KMPRT (CCS'17) and CDGOSS (CCS'21) in the total communication costs. For the total running time, K-Star can be respectively 1.4 \u00d7 \u223c 9.0 \u00d7 1.4\u00d7\u223c9.0\u00d7 and 1.0 \u00d7 \u223c 15.3 \u00d7 1.0\u00d7\u223c15.3\u00d7 as fast as them in the LAN setting.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-wu-mingli.pdf",
            "keywords": [
                "Multi-party Private Set Intersection",
                "Efficient Protocols",
                "Communication Costs",
                "Oblivious PRF",
                "Ring and Star Topology"
            ]
        },
        "url": "URL#379741",
        "sema_paperId": "dfe5f696de01ae59e1865050e0168d74197d49aa"
    },
    {
        "@score": "1",
        "@id": "379742",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "227/7984",
                        "text": "Marc Wyss"
                    },
                    {
                        "@pid": "16/6873",
                        "text": "Adrian Perrig"
                    }
                ]
            },
            "title": "Zero-setup Intermediate-rate Communication Guarantees in a Global Internet.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WyssP24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/wyss",
            "url": "https://dblp.org/rec/conf/uss/WyssP24",
            "abstract": "Network-targeting volumetric DDoS attacks remain a major threat to Internet communication. Unfortunately, existing solutions fall short of providing forwarding guarantees to the important class of short-lived intermediate-rate communication such as web traffic in a secure, scalable, light-weight, low-cost, and incrementally deployable fashion. To overcome those limitations we design Z-Lane, a system achieving those objectives by ensuring bandwidth isolation among authenticated traffic from (groups of) autonomous systems, thus safe-guarding intermediate-rate communication against even the largest volumetric DDoS attacks. Our evaluation on a global testbed and our high-speed implementation on commodity hardware demonstrate Z-Lane\u2019s effectiveness and scalability.",
            "keywords": [
                "DDoS Mitigation",
                "Bandwidth Isolation",
                "Intermediate-rate Communication",
                "Autonomous Systems",
                "Z-Lane"
            ]
        },
        "url": "URL#379742",
        "sema_paperId": "7711b6ea5faf54f909813baddf0aca592ac067c1"
    },
    {
        "@score": "1",
        "@id": "379743",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "274/0900",
                        "text": "Tianrou Xia"
                    },
                    {
                        "@pid": "70/2543-4",
                        "text": "Hong Hu 0004"
                    },
                    {
                        "@pid": "54/2696",
                        "text": "Dinghao Wu"
                    }
                ]
            },
            "title": "DEEPTYPE: Refining Indirect Call Targets with Strong Multi-layer Type Analysis.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Xia0W24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/xia",
            "url": "https://dblp.org/rec/conf/uss/Xia0W24",
            "abstract": "Indirect calls, while facilitating dynamic execution characteristics in C and C++ programs, impose challenges on precise construction of the control-flow graphs (CFG). This hinders effective program analyses for bug detection (e.g., fuzzing) and program protection (e.g., control-flow integrity). Solutions using data-tracking and type-based analysis are proposed for identifying indirect call targets, but are either time-consuming or imprecise for obtaining the analysis results. Multi-layer type analysis (MLTA), as the state-of-the-art approach, upgrades type-based analysis by leveraging multi-layer type hierarchy, but their solution to dealing with the information flow between multi-layer types introduces false positives. In this paper, we propose strong multi-layer type analysis (SMLTA) and implement the prototype, D EEP T YPE , to further refine indirect call targets. It adopts a robust solution to record and retrieve type information, avoiding information loss and enhancing accuracy. We evaluate D EEP T YPE on Linux kernel, 5 web servers, and 14 user applications. Compared to TypeDive, the prototype of MLTA, D EEP T YPE is able to narrow down the scope of indirect call targets by 43.11% on average across most benchmarks and reduce run-time overhead by 5.45% to 72.95%, which demonstrates the effectiveness, efficiency and applicability of SMLTA.",
            "keywords": [
                "Indirect Call Targets",
                "Control-Flow Graphs",
                "Type Analysis",
                "Multi-layer Type Hierarchy",
                "Strong Multi-layer Type Analysis (SMLTA)"
            ]
        },
        "url": "URL#379743",
        "sema_paperId": "83d3a2d415eb90d7a828463f6ff5a13564ecb5e5"
    },
    {
        "@score": "1",
        "@id": "379744",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "40/9479",
                        "text": "Yi Xiang"
                    },
                    {
                        "@pid": "139/6932-2",
                        "text": "Xuhong Zhang 0002"
                    },
                    {
                        "@pid": "85/670-3",
                        "text": "Peiyu Liu 0003"
                    },
                    {
                        "@pid": "07/8388",
                        "text": "Shouling Ji"
                    },
                    {
                        "@pid": "89/6248",
                        "text": "Xiao Xiao"
                    },
                    {
                        "@pid": "56/2376",
                        "text": "Hong Liang"
                    },
                    {
                        "@pid": "188/6025",
                        "text": "Jiacheng Xu"
                    },
                    {
                        "@pid": "122/3593",
                        "text": "Wenhai Wang"
                    }
                ]
            },
            "title": "Critical Code Guided Directed Greybox Fuzzing for Commits.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Xiang00JXLXW24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/xiang-yi",
            "url": "https://dblp.org/rec/conf/uss/Xiang00JXLXW24",
            "abstract": "Newly submitted commits are prone to introducing vulnerabilities into programs. As a promising countermeasure, directed greybox fuzzers can be employed to test commit changes by designating the commit change sites as targets. However, existing directed fuzzers primarily focus on reaching a single target and neglect the diverse exploration of the additional affected code. As a result, they may overlook bugs that crash at a distant site from the change site and lack direct-ness in multi-target scenarios, which are both very common in the context of commit testing. In this paper, we propose WAFLG O , a direct greybox fuzzer, to effectively discover vulnerabilities introduced by commits. WAFLG O employs a novel critical code guided input generation strategy to thoroughly explore the affected code. Specifically, we identify two types of critical code: path-prefix code and data-suffix code. The critical code first guides the input generation to gradually and incrementally reach the change sites. Then while maintaining the reachability of the critical code, the input generation strategy further encourages the diversity of the generated inputs in exploring the affected code. Additionally, WAFLG O introduces a lightweight multi-target distance metric for directness and thorough examination of all change sites. We implement WAFLG O and evaluate it with 30 real-world bugs introduced by commits. Compared to eight state-of-the-art tools, WAFLG O achieves an average speedup of 10.3 \u00d7 . Furthermore, WAFLG O discovers seven new vulnerabilities including four CVEs while testing the most recent 50 commits of real-world software, including libtiff",
            "keywords": [
                "Directed Greybox Fuzzing",
                "Vulnerability Discovery",
                "Commit Testing",
                "Critical Code Guidance",
                "Multi-Target Exploration"
            ]
        },
        "url": "URL#379744",
        "sema_paperId": "d478554565763e51790b4c69007428dc49073411"
    },
    {
        "@score": "1",
        "@id": "379745",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "17/1712",
                        "text": "Xiang Xie"
                    },
                    {
                        "@pid": "86/8501-2",
                        "text": "Kang Yang 0002"
                    },
                    {
                        "@pid": "150/9413",
                        "text": "Xiao Wang 0012"
                    },
                    {
                        "@pid": "33/0-1",
                        "text": "Yu Yu 0001"
                    }
                ]
            },
            "title": "Lightweight Authentication of Web Data via Garble-Then-Prove.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Xie00024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/xie-xiang",
            "url": "https://dblp.org/rec/conf/uss/Xie00024",
            "abstract": "Transport Layer Security (TLS) establishes an authenticated and confidential channel to deliver data for almost all Internet applications. A recent work (Zhang et al., CCS'20) proposed a protocol to prove the TLS payload to a third party, without any modification of TLS servers, while ensuring the privacy and originality of the data in the presence of malicious adversaries. However, it required maliciously secure Two-Party Computation (2PC) for generic circuits, leading to significant computational and communication overhead.\nThis paper proposes the garble-then-prove technique to achieve the same security requirement without using any heavy mechanism like generic malicious 2PC. Our end-to-end implementation shows 14x improvement in communication and an order of magnitude improvement in computation over the state-of-the-art protocol. We also show worldwide performance when using our protocol to authenticate payload data from Coinbase and Twitter APIs. Finally, we propose an efficient gadget to privately convert the above authenticated TLS payload to additively homomorphic commitments so that the properties of the payload can be proven efficiently using zkSNARKs.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-xie-xiang.pdf",
            "keywords": [
                "Transport Layer Security",
                "Data Authentication",
                "Garble-Then-Prove",
                "Two-Party Computation",
                "zkSNARKs"
            ]
        },
        "url": "URL#379745"
    },
    {
        "@score": "1",
        "@id": "379746",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "205/5853",
                        "text": "Qinge Xie"
                    },
                    {
                        "@pid": "381/1688",
                        "text": "Manoj Vignesh Kasi Murali"
                    },
                    {
                        "@pid": "61/1749",
                        "text": "Paul Pearce"
                    },
                    {
                        "@pid": "53/10825",
                        "text": "Frank Li 0001"
                    }
                ]
            },
            "title": "Arcanum: Detecting and Evaluating the Privacy Risks of Browser Extensions on Web Pages and Web Content.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/XieMP024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/xie-qinge",
            "url": "https://dblp.org/rec/conf/uss/XieMP024",
            "abstract": "Modern web browsers support rich extension ecosystems that provide users with customized and flexible browsing experiences. Unfortunately, the flexibility of extensions also introduces the potential for abuse, as an extension with sufficient permissions can access and surreptitiously leak sensitive and private browsing data to the extension\u2019s authors or third parties. Prior work has explored such extension behavior, but has been limited largely to meta-data about browsing rather than the contents of web pages, and is also based on older versions of browsers, web standards, and APIs, precluding its use for analysis in a modern setting. In this work, we develop Arcanum, a dynamic taint tracking system for modern Chrome extensions designed to monitor the flow of user content from web pages. Arcanum defines a variety of taint sources and sinks, allowing researchers to taint specific parts of pages at runtime via JavaScript, and works on modern extension APIs, JavaScript APIs, and versions of Chromium. We deploy Arcanum to test all functional extensions currently in the Chrome Web Store for the automated exfiltration of user data across seven sensitive websites: Amazon, Facebook, Gmail, Instagram, LinkedIn, Outlook, and PayPal. We observe significant privacy risks across thousands of extensions, including hundreds of extensions automatically extracting user content from within web pages, impacting millions of users. Our findings demonstrate the importance of user content within web pages, and the need for stricter privacy controls on extensions.",
            "keywords": [
                "Browser Extension Privacy",
                "Taint Tracking",
                "Data Exfiltration",
                "User Content Leakage",
                "Privacy Risks"
            ]
        },
        "url": "URL#379746",
        "sema_paperId": "26894db6dde67a2893bc308ad5ba8194b9291aab"
    },
    {
        "@score": "1",
        "@id": "379747",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "151/6222",
                        "text": "Jiajun Xin"
                    },
                    {
                        "@pid": "366/5183",
                        "text": "Arman Haghighi"
                    },
                    {
                        "@pid": "332/2918",
                        "text": "Xiangan Tian"
                    },
                    {
                        "@pid": "18/9002",
                        "text": "Dimitrios Papadopoulos 0001"
                    }
                ]
            },
            "title": "Notus: Dynamic Proofs of Liabilities from Zero-knowledge RSA Accumulators.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/XinHT024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/xin",
            "url": "https://dblp.org/rec/conf/uss/XinHT024",
            "abstract": "Proofs of Liabilities (PoL) allow an untrusted prover to commit to its liabilities towards a set of users and then prove independent users' amounts or the total sum of liabilities, upon queries by users or third-party auditors. This application setting is highly dynamic. User liabilities may increase/decrease arbitrarily and the prover needs to update proofs in epoch increments (e.g., once a day for a crypto-asset exchange platform). However, prior works mostly focus on the static case and trivial extensions to the dynamic setting open the system to windows of opportunity for the prover to under-report its liabilities and rectify its books in time for the next check, unless all users check their liabilities at all epochs. In this work, we develop Notus, the first dynamic PoL system for general liability updates that avoids this issue. Moreover, it achieves O(1) query proof size, verification time, and auditor overhead-per-epoch. The core building blocks underlying Notus are a novel zero-knowledge (and SNARK-friendly) RSA accumulator and a corresponding zero-knowledge MultiSwap protocol, which may be of independent interest. We then propose optimizations to reduce the prover's update overhead and make Notus scale to large numbers of users (10^6 in our experiments). Our results are very encouraging, e.g., it takes less than 2ms to verify a user's liability and the proof size is 256 Bytes. On the prover side, deploying Notus on a cloud-based testbed with 256 cores and exploiting parallelism, it takes about 3 minutes to perform the complete epoch update, after which all proofs have already been computed.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-xin.pdf",
            "keywords": [
                "Proofs of Liabilities",
                "Zero-knowledge Accumulators",
                "Dynamic Liability Updates",
                "Auditor Overhead",
                "RSA Accumulator"
            ]
        },
        "url": "URL#379747"
    },
    {
        "@score": "1",
        "@id": "379748",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "300/5803",
                        "text": "Yunlong Xing"
                    },
                    {
                        "@pid": "32/5536-4",
                        "text": "Shu Wang 0004"
                    },
                    {
                        "@pid": "244/4445",
                        "text": "Shiyu Sun"
                    },
                    {
                        "@pid": "89/3991",
                        "text": "Xu He"
                    },
                    {
                        "@pid": "30/3530-1",
                        "text": "Kun Sun 0001"
                    },
                    {
                        "@pid": "181/2688-2",
                        "text": "Qi Li 0002"
                    }
                ]
            },
            "title": "What IF Is Not Enough? Fixing Null Pointer Dereference With Contextual Check.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/XingWSH0024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/xing-yunlong",
            "url": "https://dblp.org/rec/conf/uss/XingWSH0024",
            "abstract": "Null pointer dereference (NPD) errors pose the risk of unexpected behavior and system instability, potentially leading to abrupt program termination due to exceptions or segmentation faults. When generating NPD fixes, all existing solutions are confined to the function level fixes and ignore the valuable intraprocedural and interprocedural contextual information, potentially resulting in incorrect patches. In this paper, we introduce C ONCH , a novel approach that addresses the challenges of generating correct fixes for NPD issues by incorporating contextual checks. Our method first constructs an NPD context graph to maintain the semantics related to patch generation. Then we summarize distinct fixing position selection policies based on the distribution of the error positions, ensuring the resolution of bugs without introducing duplicate code. Next, the intraprocedural state retrogression builds the if condition, retrogresses the local resources, and constructs return statements as an initial patch. Finally, we conduct interproce-dural state propagation to assess the correctness of the initial patch in the entire call chain. We evaluate the effectiveness of C ONCH over two real-world datasets. The experimental results demonstrate that C ONCH outperforms the SOTA meth-ods and yields over 85% accurate patches.",
            "keywords": [
                "Null Pointer Dereference",
                "Contextual Checks",
                "Patch Generation",
                "Intraprocedural Analysis",
                "Interprocedural State Propagation"
            ]
        },
        "url": "URL#379748",
        "sema_paperId": "af63301a58c0347f9df4b6523831b96319e65d05"
    },
    {
        "@score": "1",
        "@id": "379749",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "217/0857",
                        "text": "Jiarong Xing"
                    },
                    {
                        "@pid": "300/2962",
                        "text": "Sophia Yoo"
                    },
                    {
                        "@pid": "159/1948",
                        "text": "Xenofon Foukas"
                    },
                    {
                        "@pid": "115/6369",
                        "text": "Daehyeok Kim"
                    },
                    {
                        "@pid": "r/MichaelKReiter",
                        "text": "Michael K. Reiter"
                    }
                ]
            },
            "title": "On the Criticality of Integrity Protection in 5G Fronthaul Networks.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/XingYFKR24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/xing-jiarong",
            "url": "https://dblp.org/rec/conf/uss/XingYFKR24",
            "abstract": "The modern 5G fronthaul , which connects the base stations to radio units in cellular networks, is designed to deliver microsecond-level performance guarantees using Ethernet-based protocols. Unfortunately, due to potential performance overheads, as well as misconceptions about the low risk and impact of possible attacks, integrity protection is not considered a mandatory feature in the 5G fronthaul standards. In this work, we show how vulnerabilities from the lack of protection can be exploited, making attacks easier and more powerful than ever. We present a novel class of powerful attacks and a set of traditional attacks, which can both be fully launched from software over open packet-based interfaces, to cause performance degradation or denial of service to users over large geographical regions. Our attacks do not require a physical radio presence or signal-based attack mechanisms, do not affect the network\u2019s operation ( e.g., not crashing the radios), and are highly severe ( e.g., impacting multiple cells). We demonstrate the impact of our attacks in an end-to-end manner on a commercial-grade, multi-cell 5G testbed, showing that adversaries can degrade performance of connected users by more than 80%, completely block a selected subset of users from ever attaching to the cell, or even generate signaling storm attacks of more than 2500 signaling messages per minute, with just two compromised cells and four mobile users. We also present an analysis of countermeasures that meet the strict performance requirements of the fronthaul.",
            "keywords": [
                "5G Fronthaul Networks",
                "Integrity Protection",
                "Denial of Service",
                "Performance Degradation",
                "Signaling Storm Attacks"
            ]
        },
        "url": "URL#379749",
        "sema_paperId": "5eb90fddad73a7c29f2fe9162300b452a27cd3dd"
    },
    {
        "@score": "1",
        "@id": "379750",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "353/7603",
                        "text": "Kedong Xiu"
                    },
                    {
                        "@pid": "99/4292-2",
                        "text": "Ding Wang 0002"
                    }
                ]
            },
            "title": "PointerGuess: Targeted Password Guessing Model Using Pointer Mechanism.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Xiu024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/xiu",
            "url": "https://dblp.org/rec/conf/uss/Xiu024",
            "abstract": "Most existing targeted password guessing models view users\u2019 reuse behaviors as sequences of edit operations (e.g., insert and delete) performed on old passwords. These atomic edit operations are limited to modifying one character at a time and cannot fully cover users\u2019 complex password modi\ufb01ca-tion behaviors (e.g., modifying the password structure). This partially leads to a signi\ufb01cant gap between the proportion of users\u2019 reused passwords and the success rates that existing targeted guessing models can achieve. To \ufb01ll this gap, this paper models users\u2019 reuse behaviors by focusing on two key components: (1) What they want to copy/keep; (2) What they want to tweak. More speci\ufb01cally, we introduce the pointer mechanism and propose a new targeted guessing model, namely P OINT - ER G UESS . By hierarchically rede\ufb01ning password reuse from both personal and population-wide perspectives, we can accurately and comprehensively characterize users\u2019 password reuse behaviors. Moreover, we propose MS-P OINTER G UESS , which can employ the victim\u2019s multiple leaked passwords. By employing 13 large-scale real-world password datasets, we demonstrate that P OINTER G UESS is effective: (1) When the victim\u2019s password at site A (namely pw A ) is known, within 100 guesses, the average success rate of P OINTER G UESS in guessing her password at site B (namely pw B , pw A (cid:2) = pw B ) is 25.21% (for common users) and 12.34% (for security-savvy users), respectively, which is 21.23% \u223c 71.54% (38.37% on average) higher than its",
            "keywords": [
                "Password Guessing",
                "Password Reuse",
                "Pointer Mechanism",
                "Targeted Attacks",
                "User Behavior Modeling"
            ]
        },
        "url": "URL#379750",
        "sema_paperId": "0209731f669c4994b4e4cc2adde79de87aad8777"
    },
    {
        "@score": "1",
        "@id": "379751",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "350/1187",
                        "text": "Zhangchen Xu"
                    },
                    {
                        "@pid": "294/4119",
                        "text": "Fengqing Jiang"
                    },
                    {
                        "@pid": "181/8375",
                        "text": "Luyao Niu"
                    },
                    {
                        "@pid": "24/5124-1",
                        "text": "Jinyuan Jia 0001"
                    },
                    {
                        "@pid": "50/3402-26",
                        "text": "Bo Li 0026"
                    },
                    {
                        "@pid": "29/5044",
                        "text": "Radha Poovendran"
                    }
                ]
            },
            "title": "ACE: A Model Poisoning Attack on Contribution Evaluation Methods in Federated Learning.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/XuJNJ0P24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/xu-zhangchen",
            "url": "https://dblp.org/rec/conf/uss/XuJNJ0P24",
            "abstract": "In Federated Learning (FL), a set of clients collaboratively train a machine learning model (called global model) without sharing their local training data. The local training data of clients is typically non-i.i.d. and heterogeneous, resulting in varying contributions from individual clients to the final performance of the global model. In response, many contribution evaluation methods were proposed, where the server could evaluate the contribution made by each client and incentivize the high-contributing clients to sustain their long-term participation in FL. Existing studies mainly focus on developing new metrics or algorithms to better measure the contribution of each client. However, the security of contribution evaluation methods of FL operating in adversarial environments is largely unexplored. In this paper, we propose the first model poisoning attack on contribution evaluation methods in FL, termed ACE. Specifically, we show that any malicious client utilizing ACE could manipulate the parameters of its local model such that it is evaluated to have a high contribution by the server, even when its local training data is indeed of low quality. We perform both theoretical analysis and empirical evaluations of ACE. Theoretically, we show our design of ACE can effectively boost the malicious client's perceived contribution when the server employs the widely-used cosine distance metric to measure contribution. Empirically, our results show ACE effectively and efficiently deceive five state-of-the-art contribution evaluation methods. In addition, ACE preserves the accuracy of the final global models on testing inputs. We also explore six countermeasures to defend ACE. Our results show they are inadequate to thwart ACE, highlighting the urgent need for new defenses to safeguard the contribution evaluation methods in FL.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-xu-zhangchen.pdf",
            "keywords": [
                "Federated Learning",
                "Contribution Evaluation",
                "Model Poisoning Attack",
                "Adversarial Environment",
                "Client Manipulation"
            ]
        },
        "url": "URL#379751"
    },
    {
        "@score": "1",
        "@id": "379752",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "145/6354",
                        "text": "Zhibo Xu"
                    },
                    {
                        "@pid": "176/9676",
                        "text": "Shangqi Lai"
                    },
                    {
                        "@pid": "51/5617-2",
                        "text": "Xiaoning Liu 0002"
                    },
                    {
                        "@pid": "165/0106",
                        "text": "Alsharif Abuadbba"
                    },
                    {
                        "@pid": "21/8884",
                        "text": "Xingliang Yuan"
                    },
                    {
                        "@pid": "94/4423",
                        "text": "Xun Yi"
                    }
                ]
            },
            "title": "OblivGNN: Oblivious Inference on Transductive and Inductive Graph Neural Network.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/XuL0AYY24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/xu-zhibo",
            "url": "https://dblp.org/rec/conf/uss/XuL0AYY24",
            "abstract": "Graph Neural Networks (GNNs) have emerged as a powerful tool for analysing graph-structured data across various domains, including social networks, banking, and bioinformatics. In the meantime, graph data contains sensitive information, such as social relations, financial transactions, and chemical structures, and GNN models are IPs of the model owner. Thus, deploying GNNs in cloud-based Machine Learning as a Service (MLaaS) raises significant privacy concerns. In this paper, we present a comprehensive solution to enable secure GNN inference in MLaaS, named OblivGNN . OblivGNN is designed to support both transductive (static graph) and inductive (dynamic graph) inference services without revealing either graph data or GNN models. In particular, we adopt a lightweight cryptographic primitive, i.e., function secret sharing, to achieve low communication and computation overhead during inference. Furthermore, we are the first to propose a secure update protocol for the inductive setting, which can obliviously update the graph without revealing which parts of the graph are updated. Particularly, our results with three widely-used graph datasets (Cora, Citeseer, and Pubmed) show that OblivGNN can achieve comparable accuracy to an Additive Secret Sharing-based baseline. Nonethe-less, our design reduces the runtime cost by up to 38% and the communication cost by 10 \u00d7 to 151 \u00d7 , highlighting its practicality when processing large graphs with GNN models.",
            "keywords": [
                "Graph Neural Networks",
                "Secure Inference",
                "Privacy Preservation",
                "Function Secret Sharing",
                "Inductive Graph Updates"
            ]
        },
        "url": "URL#379752",
        "sema_paperId": "c7f53a53e5b89793cb493f36d1c635a1280ac644"
    },
    {
        "@score": "1",
        "@id": "379753",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "94/8594",
                        "text": "Dandan Xu"
                    },
                    {
                        "@pid": "77/1147-1",
                        "text": "Di Tang 0001"
                    },
                    {
                        "@pid": "49/6574",
                        "text": "Yi Chen"
                    },
                    {
                        "@pid": "06/6268",
                        "text": "XiaoFeng Wang 0001"
                    },
                    {
                        "@pid": "c/KaiChen12",
                        "text": "Kai Chen 0012"
                    },
                    {
                        "@pid": "90/3951",
                        "text": "Haixu Tang"
                    },
                    {
                        "@pid": "178/6433",
                        "text": "Longxing Li"
                    }
                ]
            },
            "title": "Racing on the Negative Force: Efficient Vulnerability Root-Cause Analysis through Reinforcement Learning on Counterexamples.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/XuTC00TL24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/xu-dandan",
            "url": "https://dblp.org/rec/conf/uss/XuTC00TL24",
            "abstract": "Root-Cause Analysis (RCA) is crucial for discovering security vulnerabilities from fuzzing outcomes. Automating this process through triaging the crashes observed during the fuzzing process, however, is considered to be challenging. Particularly, today\u2019s statistical RCA approaches are known to be exceedingly slow, often taking tens of hours or even a week to analyze a crash. This problem comes from the biased sampling such approaches perform. More specifically, given an input inducing a crash in a program, these approaches sample around the input by mutating it to generate new test cases; these cases are used to fuzz the program, in a hope that a set of program elements (blocks, instructions or predicates) on the execution path of the original input can be adequately sampled so their correlations with the crash can be determined. This process, however, tends to generate the input samples more likely causing the crash, with their execution paths involving a similar set of elements, which become less distinguishable until a large number of samples have been made. We found that this problem can be effectively addressed by sampling around \u201ccounterexamples\u201d, the inputs causing a significant change to the current estimates of correlations. These inputs though still involving the elements often do not lead to the crash. They are found to be effective in differentiating program elements, thereby accelerating the RCA process. Based upon the understanding, we designed and implemented a reinforcement learning (RL) technique that rewards the operations involving counterexamples. By balancing random sampling with the exploitation on the counterexamples, our new approach",
            "keywords": [
                "Root-Cause Analysis",
                "Fuzzing Outcomes",
                "Vulnerability Detection",
                "Reinforcement Learning",
                "Counterexamples"
            ]
        },
        "url": "URL#379753",
        "sema_paperId": "64c6cd4c66c41e11b7970a6f65fb51854605ba14"
    },
    {
        "@score": "1",
        "@id": "379754",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "268/6595",
                        "text": "Haichuan Xu"
                    },
                    {
                        "@pid": "210/4952",
                        "text": "Mingxuan Yao"
                    },
                    {
                        "@pid": "144/1374",
                        "text": "Runze Zhang"
                    },
                    {
                        "@pid": "381/1649",
                        "text": "Mohamed Moustafa Dawoud"
                    },
                    {
                        "@pid": "163/7414",
                        "text": "Jeman Park 0001"
                    },
                    {
                        "@pid": "150/5240",
                        "text": "Brendan Saltaformaggio"
                    }
                ]
            },
            "title": "DVa: Extracting Victims and Abuse Vectors from Android Accessibility Malware.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/XuYZD0S24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/xu-haichuan",
            "url": "https://dblp.org/rec/conf/uss/XuYZD0S24",
            "abstract": "The Android accessibility (a11y) service is widely abused by malware to conduct on-device monetization fraud. Existing mitigation techniques focus on malware detection but overlook providing users evidence of abuses that have already occurred and notifying victims to facilitate defenses. We developed DVa, a malware analysis pipeline based on dynamic victim-guided execution and abuse-vector-guided symbolic analysis, to help investigators uncover a11y malware\u2019s targeted victims, victim-specific abuse vectors, and persistence mechanisms. We deployed DVa to investigate Android devices infected with 9,850 a11y malware. From the extractions, DVa uncovered 215 unique victims targeted with an average of 13.9 abuse routines. DVa also extracted six persistence mechanisms empowered by the a11y service.",
            "keywords": [
                "Android Accessibility Malware",
                "Malware Analysis",
                "Victim Extraction",
                "Abuse Vectors",
                "Persistence Mechanisms"
            ]
        },
        "url": "URL#379754",
        "sema_paperId": "2712536443a57996b0d6e54bbc8aaa6b0d3ef76e"
    },
    {
        "@score": "1",
        "@id": "379755",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "259/6190",
                        "text": "Diwen Xue"
                    },
                    {
                        "@pid": "68/4656",
                        "text": "Michalis Kallitsis 0001"
                    },
                    {
                        "@pid": "22/1797",
                        "text": "Amir Houmansadr"
                    },
                    {
                        "@pid": "24/973",
                        "text": "Roya Ensafi"
                    }
                ]
            },
            "title": "Fingerprinting Obfuscated Proxy Traffic with Encapsulated TLS Handshakes.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Xue0HE24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/xue-fingerprinting",
            "url": "https://dblp.org/rec/conf/uss/Xue0HE24",
            "abstract": "The global escalation of Internet censorship by nation-state actors has led to an ongoing arms race between censors and obfuscated circumvention proxies. Research over the past decade has extensively examined various fingerprinting attacks against individual proxy protocols and their respective countermeasures. In this paper, however, we demonstrate the feasibility of a protocol-agnostic approach to proxy detection, enabled by the shared characteristic of nested protocol stacks inherent to all forms of proxying and tunneling activities. We showcase the practicality of such an approach by identifying one specific fingerprint\u2013encapsulated TLS handshakes\u2013that results from nested protocol stacks, and building similarity-based classifiers to isolate this unique fingerprint within encrypted traffic streams. Assuming the role of a censor, we build a detection framework and deploy it within a mid-size ISP serving upwards of one million users. Our evaluation demonstrates that the traffic of obfuscated proxies, even with random padding and multiple layers of encapsulations, can be reliably detected with minimal collateral damage by fingerprinting encapsulated TLS handshakes. While stream multiplexing shows promise as a viable countermeasure, we caution that existing obfuscations based on multiplexing and random padding alone are inherently limited, due to their inability to reduce the size of traffic bursts or the number of round trips within a connection. Proxy developers should be aware of these limitations, anticipate the potential exploitation of encapsulated TLS handshakes by the censors, and equip their tools with proactive countermeasures.",
            "keywords": [
                "Proxy Detection",
                "Traffic Fingerprinting",
                "Encapsulated TLS Handshakes",
                "Internet Censorship",
                "Obfuscated Proxies"
            ]
        },
        "url": "URL#379755",
        "sema_paperId": "cecf86f2346e14752941fc4519fc8ff37a55a31a"
    },
    {
        "@score": "1",
        "@id": "379756",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "259/6190",
                        "text": "Diwen Xue"
                    },
                    {
                        "@pid": "331/5842",
                        "text": "Anna Ablove"
                    },
                    {
                        "@pid": "270/2465",
                        "text": "Reethika Ramesh"
                    },
                    {
                        "@pid": "381/1681",
                        "text": "Grace Kwak Danciu"
                    },
                    {
                        "@pid": "24/973",
                        "text": "Roya Ensafi"
                    }
                ]
            },
            "title": "Bridging Barriers: A Survey of Challenges and Priorities in the Censorship Circumvention Landscape.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/XueARDE24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/xue-bridging",
            "url": "https://dblp.org/rec/conf/uss/XueARDE24",
            "abstract": "The ecosystem of censorship circumvention tools (CTs) remains one of the most opaque and least understood, overshad-owed by the precarious legal status around their usage and operation, and the risks facing those directly involved. Used by hundreds of millions of users across the most restricted networks, these tools circulate not through advertisements but word-of-mouth, distributed not through appstores but under-ground networks, and adopted not out of trust but from the sheer necessity for information access. This paper aims to elucidate the dynamics and challenges of the CT ecosystem, and the needs and priorities of its stake-holders. We perform the first multi-perspective study, sur-veying 12 leading CT providers that service upwards of 100 million users, combined with experiences from CT users in Russia and China. Beyond the commonly cited technical challenges and disruptions from censors, our study also highlights funding constraints, usability issues, misconceptions, and misbehaving players, all of which similarly plague the CT ecosystem. Having the unique opportunity to survey these at-risk CT stakeholders, we outline key future priorities for those involved. We hope our work encourages further research to advance our understanding of this complex and uniquely challenged ecosystem.",
            "keywords": [
                "Censorship Circumvention Tools",
                "Information Access",
                "User Privacy",
                "Technical Challenges",
                "Funding Constraints"
            ]
        },
        "url": "URL#379756",
        "sema_paperId": "1d96624f0732b75f4119d6c686ff73ed96ed8b56"
    },
    {
        "@score": "1",
        "@id": "379757",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "259/2375",
                        "text": "Aviv Yaish"
                    },
                    {
                        "@pid": "246/5857",
                        "text": "Kaihua Qin"
                    },
                    {
                        "@pid": "246/6069",
                        "text": "Liyi Zhou"
                    },
                    {
                        "@pid": "92/4269",
                        "text": "Aviv Zohar"
                    },
                    {
                        "@pid": "138/9020",
                        "text": "Arthur Gervais"
                    }
                ]
            },
            "title": "Speculative Denial-of-Service Attacks In Ethereum.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YaishQZZG24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/yaish",
            "url": "https://dblp.org/rec/conf/uss/YaishQZZG24",
            "abstract": "Transaction fees compensate actors for resources expended on transactions and can only be charged from transactions included in blocks. But, the expressiveness of Turing-complete contracts implies that verifying if transactions can be included requires executing them on the current blockchain state.\nIn this work, we show that adversaries can craft malicious transactions that decouple the work imposed on blockchain actors from the compensation offered in return. We introduce three attacks: (i) ConditionalExhaust, a conditional resource-exhaustion attack against blockchain actors. (ii) MemPurge, an attack for evicting transactions from actors' mempools. (iii) GhostTX, an attack on the reputation system used in Ethereum's proposer-builder separation ecosystem.\nWe evaluate our attacks on an Ethereum testnet and find that by combining ConditionalExhaust and MemPurge, adversaries can simultaneously burden victims' computational resources and clog their mempools to the point where victims are unable to include transactions in blocks. Thus, victims create empty blocks, thereby hurting the system's liveness. The attack's expected cost is $376, but becomes cheaper if adversaries are validators. For other attackers, costs decrease if censorship is prevalent in the network.\nConditionalExhaust and MemPurge are made possible by inherent features of Turing-complete blockchains, and potential mitigations may result in reducing a ledger's scalability.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-yaish.pdf",
            "keywords": [
                "Ethereum",
                "Denial-of-Service Attacks",
                "Turing-complete Contracts",
                "Resource Exhaustion",
                "Transaction Censorship"
            ]
        },
        "url": "URL#379757"
    },
    {
        "@score": "1",
        "@id": "379758",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "228/2025",
                        "text": "Shenao Yan"
                    },
                    {
                        "@pid": "80/920",
                        "text": "Shen Wang"
                    },
                    {
                        "@pid": "10/9994",
                        "text": "Yue Duan"
                    },
                    {
                        "@pid": "271/7093",
                        "text": "Hanbin Hong"
                    },
                    {
                        "@pid": "04/5599",
                        "text": "Kiho Lee"
                    },
                    {
                        "@pid": "133/4707",
                        "text": "Doowon Kim"
                    },
                    {
                        "@pid": "79/5433",
                        "text": "Yuan Hong"
                    }
                ]
            },
            "title": "An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities against Strong Detection.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YanWDHLKH24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/yan",
            "url": "https://dblp.org/rec/conf/uss/YanWDHLKH24",
            "abstract": "Large Language Models (LLMs) have transformed code completion tasks, providing context-based suggestions to boost developer productivity in software engineering. As users often fine-tune these models for specific applications, poisoning and backdoor attacks can covertly alter the model outputs. To address this critical security challenge, we introduce CodeBreaker, a pioneering LLM-assisted backdoor attack framework on code completion models. Unlike recent attacks that embed malicious payloads in detectable or irrelevant sections of the code (e.g., comments), CodeBreaker leverages LLMs (e.g., GPT-4) for sophisticated payload transformation (without affecting functionalities), ensuring that both the poisoned data for fine-tuning and generated code can evade strong vulnerability detection. CodeBreaker stands out with its comprehensive coverage of vulnerabilities, making it the first to provide such an extensive set for evaluation. Our extensive experimental evaluations and user studies underline the strong attack performance of CodeBreaker across various settings, validating its superiority over existing approaches. By integrating malicious payloads directly into the source code with minimal transformation, CodeBreaker challenges current security measures, underscoring the critical need for more robust defenses for code completion.",
            "keywords": [
                "Code Completion Models",
                "Backdoor Attacks",
                "LLM-Assisted Security",
                "Malicious Payloads",
                "Vulnerability Detection"
            ]
        },
        "url": "URL#379758",
        "sema_paperId": "e72a1b8e5e297e71c5e559502381ea2a35e05a31"
    },
    {
        "@score": "1",
        "@id": "379759",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "06/6358",
                        "text": "Limin Yang"
                    },
                    {
                        "@pid": "05/1539-28",
                        "text": "Zhi Chen 0028"
                    },
                    {
                        "@pid": "319/0898",
                        "text": "Chenkai Wang"
                    },
                    {
                        "@pid": "147/1584",
                        "text": "Zhenning Zhang"
                    },
                    {
                        "@pid": "381/1698",
                        "text": "Sushruth Booma"
                    },
                    {
                        "@pid": "117/7967",
                        "text": "Phuong Cao"
                    },
                    {
                        "@pid": "29/3366",
                        "text": "Constantin Adam"
                    },
                    {
                        "@pid": "162/1375",
                        "text": "Alexander Withers"
                    },
                    {
                        "@pid": "18/5985",
                        "text": "Zbigniew Kalbarczyk"
                    },
                    {
                        "@pid": "i/RavishankarKIyer",
                        "text": "Ravishankar K. Iyer"
                    },
                    {
                        "@pid": "71/4292-11",
                        "text": "Gang Wang 0011"
                    }
                ]
            },
            "title": "True Attacks, Attack Attempts, or Benign Triggers? An Empirical Measurement of Network Alerts in a Security Operations Center.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Yang0WZBCAWKI024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/yang-limin",
            "url": "https://dblp.org/rec/conf/uss/Yang0WZBCAWKI024",
            "abstract": ".",
            "keywords": [
                "Network Security",
                "Security Operations Center",
                "Alert Analysis",
                "Attack Detection",
                "False Positives"
            ]
        },
        "url": "URL#379759",
        "sema_paperId": "c09b2c58a6e4cf7f3a6edaf52b62f6072c410371"
    },
    {
        "@score": "1",
        "@id": "379760",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "297/3970",
                        "text": "Yupeng Yang"
                    },
                    {
                        "@pid": "44/9048",
                        "text": "Yongheng Chen"
                    },
                    {
                        "@pid": "95/305",
                        "text": "Rui Zhong"
                    },
                    {
                        "@pid": "301/5888",
                        "text": "Jizhou Chen"
                    },
                    {
                        "@pid": "29/5976",
                        "text": "Wenke Lee"
                    }
                ]
            },
            "title": "Towards Generic Database Management System Fuzzing.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YangCZCL24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/yang-yupeng",
            "url": "https://dblp.org/rec/conf/uss/YangCZCL24",
            "abstract": "Database Management Systems play an indispensable role in modern cyberspace. While multiple fuzzing frameworks have been proposed in recent years to test relational (SQL) DBMSs to improve their security, non-relational (NoSQL) DBMSs have yet to experience the same scrutiny and lack an effective testing solution in general. In this work, we identify three limitations of existing approaches when extended to fuzz the DBMSs effectively in general: being non-generic, using static constraints, and generating loose data dependencies. Then, we propose effective solutions to address these limitations. We implement our solutions into an end-to-end fuzzing framework, B UZZ B EE , which can effectively fuzz both relational and non-relational DBMSs. B UZZ B EE successfully discovered 40 vulnerabilities in eight DBMSs of four different data models, of which 25 have been fixed with 4 new CVEs assigned. In our evaluation, B UZZ B EE outperforms state-of-the-art generic fuzzers by up to 177% in terms of code coverage and discovers 30x more bugs than the second-best fuzzer for non-relational DBMSs, while achieving comparable results with specialized SQL fuzzers for the relational counterpart.",
            "keywords": [
                "Database Management Systems",
                "Fuzzing Frameworks",
                "Vulnerability Discovery",
                "Non-relational Databases",
                "Code Coverage"
            ]
        },
        "url": "URL#379760",
        "sema_paperId": "d933042eb3c2a8f2e208515490d6b6a400e00fec"
    },
    {
        "@score": "1",
        "@id": "379761",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "243/9314",
                        "text": "Fangfei Yang"
                    },
                    {
                        "@pid": "231/1893",
                        "text": "Bumjin Im"
                    },
                    {
                        "@pid": "57/10219",
                        "text": "Weijie Huang"
                    },
                    {
                        "@pid": "203/6456",
                        "text": "Kelly Kaoudis"
                    },
                    {
                        "@pid": "161/0161",
                        "text": "Anjo Vahldiek-Oberwagner"
                    },
                    {
                        "@pid": "277/2163",
                        "text": "Chia-Che Tsai"
                    },
                    {
                        "@pid": "20/10299",
                        "text": "Nathan Dautenhahn"
                    }
                ]
            },
            "title": "Endokernel: A Thread Safe Monitor for Lightweight Subprocess Isolation.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YangIHKVTD24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/yang-fangfei",
            "url": "https://dblp.org/rec/conf/uss/YangIHKVTD24",
            "abstract": "Compartmentalization decomposes applications into isolated components, effectively confining the scope of potential security breaches. Recent approaches nest the protection monitor within processes for efficient memory isolation at the cost of security. However, these systems lack solutions for efficient multithreaded safety and neglect kernel semantics that can be abused to bypass the monitor.\nThe Endokernel is an intra-process security monitor that isolates memory at subprocess granularity. It ensures backwards-compatible and secure emulation of system interfaces, a task uniquely challenging due to the need to analyze OS and hardware semantics beyond mere interface usability. We introduce an inside-out methodology where we identify core OS primitives that allow bypass and map that back to the interfaces that depend on them. This approach led to the identification of several missing policies as well as aided in developing a fine-grained locking approach to deal with complex thread safety when inserting a monitor between the OS and the application. Results indicate that we can achieve fast isolation while greatly enhancing security and maintaining backwards-compatibility, and also showing a new method for systematically finding gaps in policies.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-yang-fangfei.pdf",
            "keywords": [
                "Intra-process Security Monitor",
                "Subprocess Isolation",
                "Thread Safety",
                "Memory Isolation",
                "OS Semantics"
            ]
        },
        "url": "URL#379761",
        "sema_paperId": "0e3654c1475437ddd4a2bcf6f938e4ec802b4118"
    },
    {
        "@score": "1",
        "@id": "379762",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "154/4724",
                        "text": "Tianchang Yang"
                    },
                    {
                        "@pid": "255/5036",
                        "text": "Syed Md. Mukit Rashid"
                    },
                    {
                        "@pid": "358/7127",
                        "text": "Ali Ranjbar"
                    },
                    {
                        "@pid": "91/6206",
                        "text": "Gang Tan"
                    },
                    {
                        "@pid": "83/7270",
                        "text": "Syed Rafiul Hussain"
                    }
                ]
            },
            "title": "ORANalyst: Systematic Testing Framework for Open RAN Implementations.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YangRRTH24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/yang-tianchang",
            "url": "https://dblp.org/rec/conf/uss/YangRRTH24",
            "abstract": "We develop ORANalyst, the first systematic testing framework tailored for analyzing the robustness and operational integrity of Open RAN (O-RAN) implementations. O-RAN systems are composed of numerous microservice-based components. ORANalyst initially gains insights into these complex component dependencies by combining efficient static analysis with dynamic tracing. Applying these insights, ORANalyst crafts test inputs that effectively navigate these dependencies and thoroughly test each target component. We evaluate ORANalyst on two O-RAN implementations, O-RAN-SC and SD-RAN, and identify 19 previously undiscovered vulnerabilities. If exploited, these vulnerabilities could lead to various denial-of-service attacks, resulting from component crashes and disruptions in communication channels.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-yang-tianchang.pdf",
            "keywords": [
                "Open RAN",
                "Testing Framework",
                "Component Dependencies",
                "Vulnerability Discovery",
                "Denial-of-Service Attacks"
            ]
        },
        "url": "URL#379762",
        "sema_paperId": "e8cc2e1034c4e89ac27bf96608962024e6f39b59"
    },
    {
        "@score": "1",
        "@id": "379763",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "152/4206",
                        "text": "Zhuolin Yang"
                    },
                    {
                        "@pid": "331/5331",
                        "text": "Zain Sarwar"
                    },
                    {
                        "@pid": "225/0166",
                        "text": "Iris Hwang"
                    },
                    {
                        "@pid": "359/4253",
                        "text": "Ronik Bhaskar"
                    },
                    {
                        "@pid": "z/BenYZhao",
                        "text": "Ben Y. Zhao"
                    },
                    {
                        "@pid": "43/4261",
                        "text": "Haitao Zheng 0001"
                    }
                ]
            },
            "title": "Can Virtual Reality Protect Users from Keystroke Inference Attacks?",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YangSHBZ024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/yang-zhuolin",
            "url": "https://dblp.org/rec/conf/uss/YangSHBZ024",
            "abstract": "Virtual Reality (VR) has gained popularity by providing immersive and interactive experiences without geographical limitations. It also provides a sense of personal privacy through physical separation. In this paper, we show that despite assumptions of enhanced privacy, VR is unable to shield its users from side-channel attacks that steal private information. Ironically, this vulnerability arises from VR's greatest strength, its immersive and interactive nature. We demonstrate this by designing and implementing a new set of keystroke inference attacks in shared virtual environments, where an attacker (VR user) can recover the content typed by another VR user by observing their avatar. While the avatar displays noisy telemetry of the user's hand motion, an intelligent attacker can use that data to recognize typed keys and reconstruct typed content, without knowing the keyboard layout or gathering labeled data. We evaluate the proposed attacks using IRB-approved user studies across multiple VR scenarios. For 13 out of 15 tested users, our attacks accurately recognize 86%-98% of typed keys, and the recovered content retains up to 98% of the meaning of the original typed content. We also discuss potential defenses.",
            "keywords": [
                "Virtual Reality",
                "Keystroke Inference",
                "Side-Channel Attacks",
                "User Privacy",
                "Immersive Environments"
            ]
        },
        "url": "URL#379763",
        "sema_paperId": "18c95690fbcaa1f6094ef38d9fb2d06e0f4cb213"
    },
    {
        "@score": "1",
        "@id": "379764",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "332/5984",
                        "text": "Chengfeng Ye"
                    },
                    {
                        "@pid": "295/3456",
                        "text": "Yuandao Cai"
                    },
                    {
                        "@pid": "51/7008-1",
                        "text": "Charles Zhang 0001"
                    }
                ]
            },
            "title": "When Threads Meet Interrupts: Effective Static Detection of Interrupt-Based Deadlocks in Linux.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YeC024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/ye",
            "url": "https://dblp.org/rec/conf/uss/YeC024",
            "abstract": "Deadlocking is an unresponsive state of software that arises when threads hold locks while trying to acquire other locks that are already held by other threads, resulting in a circular lock dependency. Interrupt-based deadlocks, a speci\ufb01c and prevalent type of deadlocks that occur within the OS kernel due to interrupt preemption, pose signi\ufb01cant risks to system functionality, performance, and security. However, existing static analysis tools focus on resource-based deadlocks without characterizing the interrupt preemption. In this paper, we introduce Archer\ufb01sh, the \ufb01rst static analysis approach for effectively identifying interrupt-based deadlocks in the large-scale Linux kernel. At its core, Archer\ufb01sh utilizes an Interrupt-Aware Lock Graph (ILG) to capture both regular and interrupt-related lock dependencies, reducing the deadlock detection problem to graph cycle discovery and re\ufb01nement. Furthermore, Archer\ufb01sh incorporates four effective analysis components to construct ILG and re\ufb01ne the deadlock cycles, addressing three core challenges, including the extensive interrupt-involving concurrency space, identifying potential interrupt handlers, and validating the feasibility of deadlock cycles. Our experimental results show that Archer\ufb01sh can precisely analyze the Linux kernel (19.8 MLoC) in approximately one hour. At the time of writing, we have discovered 76 previously unknown deadlocks, with 53 bugs con\ufb01rmed, 46 bugs already \ufb01xed by the Linux community, and 2 CVE IDs assigned. Notably, those found deadlocks are long-latent, hiding for an average of 9.9 years.",
            "keywords": [
                "Linux Kernel",
                "Static Analysis",
                "Interrupt-Based Deadlocks",
                "Lock Dependencies",
                "Deadlock Detection"
            ]
        },
        "url": "URL#379764",
        "sema_paperId": "6d1a22f149a61b83967df75f6f4fdf35fcc8a12f"
    },
    {
        "@score": "1",
        "@id": "379765",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "300/2962",
                        "text": "Sophia Yoo"
                    },
                    {
                        "@pid": "32/2568",
                        "text": "Xiaoqi Chen"
                    },
                    {
                        "@pid": "r/JenniferRexford",
                        "text": "Jennifer Rexford"
                    }
                ]
            },
            "title": "SmartCookie: Blocking Large-Scale SYN Floods with a Split-Proxy Defense on Programmable Data Planes.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YooCR24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/yoo",
            "url": "https://dblp.org/rec/conf/uss/YooCR24",
            "abstract": "Despite decades of mitigation efforts, SYN flooding attacks continue to increase in frequency and scale, and adaptive ad-versaries continue to evolve. Meanwhile, volumes of benign traffic in modern networks are also growing rampantly. As a result, network providers, which run thousands of servers and process 100s of Gbps of traffic, find themselves urgently requiring defenses that are secure against adaptive adversaries, scalable against large volumes of traffic, and highly performant for benign applications. Unfortunately, existing defenses local to a single device (e.g., purely software-based or hardware-based) are failing to keep up with growing attacks and struggle to provide performance, security, or both. In this paper, we present S MART C OOKIE , the first system to run cryptographically secure SYN cookie checks on high-speed programmable switches, for both security and performance . Our novel split-proxy defense leverages emerging programmable switches to block 100% of SYN floods in the switch data plane and also uses state-of-the-art kernel technologies such as eBPF to enable scalability for serving benign traffic. S MART C OOKIE defends against adaptive ad-versaries at two orders of magnitude greater attack traffic than traditional CPU-based software defenses, blocking attacks of 136.9 Mpps without packet loss . We also achieve 2x-6.5x lower end-to-end latency for benign traffic compared to existing switch-based hardware defenses.",
            "keywords": [
                "SYN Flood Mitigation",
                "Programmable Data Planes",
                "Split-Proxy Defense",
                "Cryptographically Secure SYN Cookies",
                "High-Speed Network Security"
            ]
        },
        "url": "URL#379765",
        "sema_paperId": "59614381ee593e5442f7daa4e6e4765bb5a4f7c4"
    },
    {
        "@score": "1",
        "@id": "379766",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "332/1161",
                        "text": "Tingfeng Yu"
                    },
                    {
                        "@pid": "317/9099",
                        "text": "James Henderson"
                    },
                    {
                        "@pid": "t/AlwenTiu",
                        "text": "Alwen Tiu"
                    },
                    {
                        "@pid": "175/6283",
                        "text": "Thomas Haines"
                    }
                ]
            },
            "title": "Security and Privacy Analysis of Samsung&apos;s Crowd-Sourced Bluetooth Location Tracking System.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YuHTH24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/yu-tingfeng",
            "url": "https://dblp.org/rec/conf/uss/YuHTH24",
            "abstract": "We present a detailed analysis of Samsung\u2019s Offline Finding (OF) protocol, which is part of Samsung\u2019s Find My Mobile system for locating Samsung mobile devices and Galaxy SmartTags. The OF protocol uses Bluetooth Low Energy (BLE) to broadcast a unique beacon for a lost device. This beacon is then picked up by nearby Samsung phones or tablets (the helper devices), which then forward the beacon and the location it was detected at, to a vendor server. The owner of a lost device can then query the server to locate their device. We examine several security and privacy related properties of the OF protocol and its implementation. These include: the feasibility of tracking an OF device through its BLE data, the feasibility of unwanted tracking of a person by exploiting the OF network, the feasibility for the vendor to de-anonymise location reports to determine the locations of the owner or the helper devices, and the feasibility for an attacker to compromise the integrity of the location reports. Our findings suggest that there are privacy risks on all accounts, arising from issues in the design and the implementation of the OF protocol.",
            "keywords": [
                "Bluetooth Location Tracking",
                "Privacy Risks",
                "Crowd-Sourced Systems",
                "De-anonymization",
                "Location Integrity"
            ]
        },
        "url": "URL#379766",
        "sema_paperId": "c4bcc2a8e4e642d4936bc5b372cc6cc839df13f9"
    },
    {
        "@score": "1",
        "@id": "379767",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "172/4550-1",
                        "text": "Zhiyuan Yu 0001"
                    },
                    {
                        "@pid": "304/1538",
                        "text": "Xiaogeng Liu"
                    },
                    {
                        "@pid": "372/6516",
                        "text": "Shunning Liang"
                    },
                    {
                        "@pid": "261/7052",
                        "text": "Zach Cameron"
                    },
                    {
                        "@pid": "150/3317",
                        "text": "Chaowei Xiao"
                    },
                    {
                        "@pid": "181/2597-17",
                        "text": "Ning Zhang 0017"
                    }
                ]
            },
            "title": "Don&apos;t Listen To Me: Understanding and Exploring Jailbreak Prompts of Large Language Models.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YuLLCXZ24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/yu-zhiyuan",
            "url": "https://dblp.org/rec/conf/uss/YuLLCXZ24",
            "abstract": "Recent advancements in generative AI have enabled ubiquitous access to large language models (LLMs). Empowered by their exceptional capabilities to understand and generate human-like text, these models are being increasingly integrated into our society. At the same time, there are also concerns on the potential misuse of this powerful technology, prompting defensive measures from service providers. To overcome such protection, jailbreaking prompts have recently emerged as one of the most effective mechanisms to circumvent security restrictions and elicit harmful content originally designed to be prohibited. Due to the rapid development of LLMs and their ease of access via natural languages, the frontline of jailbreak prompts is largely seen in online forums and among hobbyists. To gain a better understanding of the threat landscape of semantically meaningful jailbreak prompts, we systemized existing prompts and measured their jailbreak effectiveness empirically. Further, we conducted a user study involving 92 participants with diverse backgrounds to unveil the process of manually creating jailbreak prompts. We observed that users often succeeded in jailbreak prompts generation regardless of their expertise in LLMs. Building on the insights from the user study, we also developed a system using AI as the assistant to automate the process of jailbreak prompt generation.",
            "keywords": [
                "Jailbreak Prompts",
                "Large Language Models",
                "AI Misuse",
                "Prompt Engineering",
                "User Studies"
            ]
        },
        "url": "URL#379767",
        "sema_paperId": "dfc73a8a906e2e72a52eec35912bf7e87b1693da"
    },
    {
        "@score": "1",
        "@id": "379768",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "181/7063",
                        "text": "Yinbo Yu"
                    },
                    {
                        "@pid": "381/1586",
                        "text": "Yuanqi Xu"
                    },
                    {
                        "@pid": "319/9488",
                        "text": "Kepu Huang"
                    },
                    {
                        "@pid": "40/6246-1",
                        "text": "Jiajia Liu 0001"
                    }
                ]
            },
            "title": "TAPFixer: Automatic Detection and Repair of Home Automation Vulnerabilities based on Negated-property Reasoning.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YuXH024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/yu-yinbo",
            "url": "https://dblp.org/rec/conf/uss/YuXH024",
            "abstract": "Trigger-Action Programming (TAP) is a popular end-user programming framework in the home automation (HA) system, which eases users to customize home automation and control devices as expected. However, its simplified syntax also introduces new safety threats to HA systems through vulnerable rule interactions. Accurately fixing these vulnerabilities by logically and physically eliminating their root causes is essential before rules are deployed. However, it has not been well studied. In this paper, we present TAPFixer, a novel framework to automatically detect and repair rule interaction vulnerabilities in HA systems. It extracts TAP rules from HA profiles, translates them into an automaton model with physical and latency features, and performs model checking with various correctness properties. It then uses a novel negated-property reasoning algorithm to automatically infer a patch via model abstraction and refinement and model checking based on negated-properties. We evaluate TAPFixer on market HA apps (1177 TAP rules and 53 properties) and find that it can achieve an 86.65% success rate in repairing rule interaction vulnerabilities. We additionally recruit 23 HA users to conduct a user study that demonstrates the usefulness of TAPFixer for vulnerability repair in practical HA scenarios.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-yu-yinbo.pdf",
            "keywords": [
                "Home Automation Systems",
                "Trigger-Action Programming",
                "Vulnerability Detection",
                "Rule Interaction Vulnerabilities",
                "Negated-property Reasoning"
            ]
        },
        "url": "URL#379768"
    },
    {
        "@score": "1",
        "@id": "379769",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "23/7122",
                        "text": "Le Yu"
                    },
                    {
                        "@pid": "184/8303",
                        "text": "Yapeng Ye"
                    },
                    {
                        "@pid": "16/1234-2",
                        "text": "Zhuo Zhang 0002"
                    },
                    {
                        "@pid": "95/3760-1",
                        "text": "Xiangyu Zhang 0001"
                    }
                ]
            },
            "title": "Cost-effective Attack Forensics by Recording and Correlating File System Changes.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YuY0024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/yu-le",
            "url": "https://dblp.org/rec/conf/uss/YuY0024",
            "abstract": "Attack forensics is particularly challenging for systems with restrictive resource constraints, such as IoT systems, because most existing methods entail logging high frequency events in the temporal dimension, which is costly. We propose a novel and cost-effective forensics technique that records information in the spatial dimension. It takes regular file-system snapshots that only record deltas between two timestamps. It infers causality by analyzing and correlating file changes (e.g., through methods similar to information retrieval). We show that in practice the resulting provenance graphs are as informative as the traditional attack provenance graphs based on temporal event logging. In the context of IoT attacks, they are better than those by existing techniques. In addition, our runtime and space overheads are only 8.08% and 5.13% of those for the state-of-the-arts, respectively.",
            "keywords": [
                "IoT Forensics",
                "File System Changes",
                "Provenance Graphs",
                "Cost-effective Techniques",
                "Event Correlation"
            ]
        },
        "url": "URL#379769",
        "sema_paperId": "b01bb8cf58def449af22bf2ada2cb68995a57811"
    },
    {
        "@score": "1",
        "@id": "379770",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "28/4466",
                        "text": "Zheng Yu"
                    },
                    {
                        "@pid": "379/5070",
                        "text": "Ganxiang Yang"
                    },
                    {
                        "@pid": "40/6431",
                        "text": "Xinyu Xing"
                    }
                ]
            },
            "title": "ShadowBound: Efficient Heap Memory Protection Through Advanced Metadata Management and Customized Compiler Optimization.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YuYX24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/yu-zheng",
            "url": "https://dblp.org/rec/conf/uss/YuYX24",
            "abstract": "In software development, the prevalence of unsafe languages such as C and C++ introduces potential vulnerabilities, especially within the heap, a pivotal component for dynamic memory allocation. Despite its significance, heap management complexities have made heap corruption pervasive, posing severe threats to system security. While prior solutions aiming for temporal and spatial memory safety exhibit overheads deemed impractical, we present ShadowBound, a unique heap memory protection design. At its core, ShadowBound is an efficient out-of-bounds defense that can work with various use-after-free defenses (e.g. MarkUS, FFMalloc, PUMM) without compatibility constraints. We harness a shadow memory-based metadata management mechanism to store heap chunk boundaries and apply customized compiler optimizations tailored for boundary checking. We implemented ShadowBound atop the LLVM framework and integrated three state-of-the-art use-after-free defenses. Our evaluations show that ShadowBound provides robust heap protection with minimal time and memory overhead, suggesting its effectiveness and efficiency in safeguarding real-world programs against prevalent heap vulnerabilities.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-yu-zheng.pdf",
            "keywords": [
                "Heap Memory Protection",
                "Dynamic Memory Allocation",
                "Heap Corruption",
                "Out-of-Bounds Defense",
                "Use-After-Free Vulnerabilities"
            ]
        },
        "url": "URL#379770"
    },
    {
        "@score": "1",
        "@id": "379771",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "83/1704",
                        "text": "Feiyang Yu"
                    },
                    {
                        "@pid": "29/5849",
                        "text": "Quan Zhou"
                    },
                    {
                        "@pid": "83/7270",
                        "text": "Syed Rafiul Hussain"
                    },
                    {
                        "@pid": "23/3719",
                        "text": "Danfeng Zhang"
                    }
                ]
            },
            "title": "Athena: Analyzing and Quantifying Side Channels of Transport Layer Protocols.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YuZHZ24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/yu-feiyang",
            "url": "https://dblp.org/rec/conf/uss/YuZHZ24",
            "abstract": "Recent research has shown a growing number of side-channel vulnerabilities in transport layer protocols, such as TCP and UDP. Those side channels can be exploited by adversaries to launch nefarious attacks. In this paper, we present Athena, an automated tool for detecting, quantifying and explaining side-channel vulnerabilities in vanilla implementations of transport layer protocols. Unlike prior tools, Athena adopts a novel graph-based analysis, making it scalable enough to be the first side-channel analysis tool that can comprehensively analyze the TCP and UDP implementations in several operating systems with significantly higher coverage than the state-of-the-art. Moreover, Athena uses an entropy-based algorithm to identify the most important vulnerabilities. Evaluation on several benchmarks including Linux, FreeBSD, OpenBSD and two open-source IPv4 implementations suggests that Athena can narrow down critical side channels to a single digit (among over 1000 candidates) with a low false positive rate. Besides covering known side channels, Athena also discovers 30 new potential attack surfaces.",
            "keywords": [
                "Transport Layer Protocols",
                "Side-Channel Vulnerabilities",
                "Automated Analysis",
                "Graph-Based Analysis",
                "Entropy-Based Algorithm"
            ]
        },
        "url": "URL#379771",
        "sema_paperId": "ccf8a61c5025f503859928484d694a6791d2e0a7"
    },
    {
        "@score": "1",
        "@id": "379772",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "345/3968-2",
                        "text": "Boshi Yuan 0002"
                    },
                    {
                        "@pid": "189/8655",
                        "text": "Shixuan Yang"
                    },
                    {
                        "@pid": "94/2347",
                        "text": "Yongxiang Zhang"
                    },
                    {
                        "@pid": "04/4910-1",
                        "text": "Ning Ding 0001"
                    },
                    {
                        "@pid": "72/1963",
                        "text": "Dawu Gu"
                    },
                    {
                        "@pid": "117/3128-1",
                        "text": "Shi-Feng Sun 0001"
                    }
                ]
            },
            "title": "MD-ML: Super Fast Privacy-Preserving Machine Learning for Malicious Security with a Dishonest Majority.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YuanYZ0G024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/yuan",
            "url": "https://dblp.org/rec/conf/uss/YuanYZ0G024",
            "abstract": "Privacy-preserving machine learning (PPML) enables the training and inference of models on private data, addressing security concerns in machine learning. PPML based on secure multi-party computation (MPC) has garnered significant attention from both the academic and industrial communities. Nevertheless, only a few PPML works provide malicious security with a dishonest majority. The state of the art by Damg\u00e5rd et al. (SP\u201919) fails to meet the demand for large models in practice, due to insufficient efficiency. In this work, we propose MD-ML, a framework for Maliciously secure Dishonest majority PPML, with a focus on boosting online efficiency. MD-ML works for n parties, tolerating corruption of up to n \u2212 1 parties. We construct our novel protocols for PPML, including truncation, dot product, matrix multiplication, and comparison. The online communication of our dot product protocol is one single element per party, independent of input length. In addition, the online cost of our multiply-then-truncate protocol is identical to multiplication, which means truncation incurs no additional online cost. These features are achieved for the first time in the literature concerning maliciously secure dishonest majority PPML. Benchmarking of MD-ML is conducted for SVM and NN including LeNet, AlexNet, and ResNet-18. For NN inference, compared to the state of the art (Damg\u00e5rd et al. , SP\u201919), we are about 3.4\u201311.0 \u00d7 (LAN) and 9.7\u2013157.7 \u00d7 (WAN) faster in online execution time.",
            "keywords": [
                "Privacy-Preserving Machine Learning",
                "Malicious Security",
                "Dishonest Majority",
                "Secure Multi-Party Computation",
                "Online Efficiency"
            ]
        },
        "url": "URL#379772",
        "sema_paperId": "e24c5a16ec3ff692402450b9ef78ca1bee7452cd"
    },
    {
        "@score": "1",
        "@id": "379773",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "303/6148",
                        "text": "Chang Yue"
                    },
                    {
                        "@pid": "98/10416",
                        "text": "Chen Zhong"
                    },
                    {
                        "@pid": "c/KaiChen12",
                        "text": "Kai Chen 0012"
                    },
                    {
                        "@pid": "45/6271",
                        "text": "Zhiyu Zhang"
                    },
                    {
                        "@pid": "153/5787",
                        "text": "Yeonjoon Lee"
                    }
                ]
            },
            "title": "DARKFLEECE: Probing the Dark Side of Android Subscription Apps.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/YueZ0ZL24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/yue",
            "url": "https://dblp.org/rec/conf/uss/YueZ0ZL24",
            "abstract": "Fleeceware, a novel category of malicious subscription apps, is increasingly tricking users into expensive subscriptions, leading to substantial \ufb01nancial consequences. These apps\u2019 ambiguous nature, closely resembling legitimate subscription apps, complicates their detection in app markets. To address this, our study aims to devise an automated method, named D ARK F LEECE , to identify \ufb02eeceware through their prevalent use of dark patterns. By recruiting domain experts, we curated the \ufb01rst-ever \ufb02eeceware feature library, based on dark patterns extracted from user interfaces (UI). A unique extraction method, which integrates UI elements, layout, and multifaceted extraction rules, has been developed. D ARK F LEECE boasts a detection accuracy of 93.43% on our dataset and utilizes Explainable Arti\ufb01cial Intelligence (XAI) to present user-friendly alerts about potential \ufb02eece-ware risks. When deployed to assess Google Play\u2019s app landscape, D ARK F LEECE examined 13,597 apps and identi\ufb01ed an alarming 75.21% of 589 subscription apps that displayed different levels of \ufb02eeceware, totaling around 5 billion down-loads. Our results are consistent with user reviews on Google Play. Our detailed exploration into the implications of our results for ethical app developers, app users, and app market regulators provides crucial insights for different stakeholders. This underscores the need for proactive measures against the rise of \ufb02eeceware.",
            "keywords": [
                "Fleeceware",
                "Dark Patterns",
                "Subscription Apps",
                "Automated Detection",
                "User Interface Risks"
            ]
        },
        "url": "URL#379773",
        "sema_paperId": "fa03ea1ae63a347ee565b20b69b0c66bdd575209"
    },
    {
        "@score": "1",
        "@id": "379774",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "278/0316",
                        "text": "Yizhuo Zhai"
                    },
                    {
                        "@pid": "31/8302",
                        "text": "Zhiyun Qian"
                    },
                    {
                        "@pid": "69/6818",
                        "text": "Chengyu Song"
                    },
                    {
                        "@pid": "83/2559",
                        "text": "Manu Sridharan"
                    },
                    {
                        "@pid": "45/576",
                        "text": "Trent Jaeger"
                    },
                    {
                        "@pid": "12/6699",
                        "text": "Paul L. Yu"
                    },
                    {
                        "@pid": "k/SrikanthVKrishnamurthy",
                        "text": "Srikanth V. Krishnamurthy"
                    }
                ]
            },
            "title": "Don&apos;t Waste My Efforts: Pruning Redundant Sanitizer Checks by Developer-Implemented Type Checks.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhaiQSSJYK24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/zhai",
            "url": "https://dblp.org/rec/conf/uss/ZhaiQSSJYK24",
            "abstract": ".",
            "keywords": [
                "Software Security",
                "Input Sanitization",
                "Type Checking",
                "Redundant Checks",
                "Developer-Implemented Checks"
            ]
        },
        "url": "URL#379774",
        "sema_paperId": "6211099c1d8c5671214300ef76c835829ca7bb99"
    },
    {
        "@score": "1",
        "@id": "379775",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "195/9266",
                        "text": "Zihao Zhan"
                    },
                    {
                        "@pid": "304/5153",
                        "text": "Yirui Yang"
                    },
                    {
                        "@pid": "211/3822",
                        "text": "Haoqi Shan"
                    },
                    {
                        "@pid": "329/3017",
                        "text": "Hanqiu Wang"
                    },
                    {
                        "@pid": "34/756",
                        "text": "Yier Jin"
                    },
                    {
                        "@pid": "63/1591-3",
                        "text": "Shuo Wang 0003"
                    }
                ]
            },
            "title": "VoltSchemer: Use Voltage Noise to Manipulate Your Wireless Charger.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhanYSWJ024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/zhan",
            "url": "https://dblp.org/rec/conf/uss/ZhanYSWJ024",
            "abstract": "Wireless charging is becoming an increasingly popular charging solution in portable electronic products for a more convenient and safer charging experience than conventional wired charging. However, our research identified new vulnerabilities in wireless charging systems, making them susceptible to intentional electromagnetic interference. These vulnerabilities facilitate a set of novel attack vectors, enabling adversaries to manipulate the charger and perform a series of attacks. In this paper, we propose VoltSchemer, a set of innovative attacks that grant attackers control over commercial-off-the-shelf wireless chargers merely by modulating the voltage from the power supply. These attacks represent the first of its kind, exploiting voltage noises from the power supply to manipulate wireless chargers without necessitating any malicious modifications to the chargers themselves. The significant threats imposed by VoltSchemer are substantiated by three practical attacks, where a charger can be manipulated to: control voice assistants via inaudible voice commands, damage devices being charged through overcharging or overheating, and bypass Qi-standard specified foreign-object-detection mechanism to damage valuable items exposed to intense magnetic fields. We demonstrate the effectiveness and practicality of the VoltSchemer attacks with successful attacks on 9 top-selling COTS wireless chargers. Furthermore, we discuss the security implications of our findings and suggest possible countermeasures to mitigate potential threats.",
            "keywords": [
                "Wireless Charging Security",
                "Electromagnetic Interference",
                "Voltage Manipulation",
                "Attack Vectors",
                "Foreign Object Detection Bypass"
            ]
        },
        "url": "URL#379775",
        "sema_paperId": "28e4aad7388ae9b51eb8a6982e809474fe8dbb66"
    },
    {
        "@score": "1",
        "@id": "379776",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "34/10139",
                        "text": "Boyang Zhang"
                    },
                    {
                        "@pid": "10/1143-23",
                        "text": "Zheng Li 0023"
                    },
                    {
                        "@pid": "243/3448-2",
                        "text": "Ziqing Yang 0002"
                    },
                    {
                        "@pid": "227/7262-1",
                        "text": "Xinlei He 0001"
                    },
                    {
                        "@pid": "b/MichaelBackes1",
                        "text": "Michael Backes 0001"
                    },
                    {
                        "@pid": "07/5701",
                        "text": "Mario Fritz"
                    },
                    {
                        "@pid": "06/6785-16",
                        "text": "Yang Zhang 0016"
                    }
                ]
            },
            "title": "SecurityNet: Assessing Machine Learning Vulnerabilities on Public Models.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Zhang00H0F024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/zhang-boyang",
            "url": "https://dblp.org/rec/conf/uss/Zhang00H0F024",
            "abstract": "While advanced machine learning (ML) models are deployed in numerous real-world applications, previous works demonstrate these models have security and privacy vulnerabilities. Various empirical research has been done in this field. However, most of the experiments are performed on target ML models trained by the security researchers themselves. Due to the high computational resource requirement for training advanced models with complex architectures, researchers generally choose to train a few target models using relatively simple architectures on typical experiment datasets. We argue that to understand ML models' vulnerabilities comprehensively, experiments should be performed on a large set of models trained with various purposes (not just the purpose of evaluating ML attacks and defenses). To this end, we propose using publicly available models with weights from the Internet (public models) for evaluating attacks and defenses on ML models. We establish a database, namely SecurityNet, containing 910 annotated image classification models. We then analyze the effectiveness of several representative attacks/defenses, including model stealing attacks, membership inference attacks, and backdoor detection on these public models. Our evaluation empirically shows the performance of these attacks/defenses can vary significantly on public models compared to self-trained models. We share SecurityNet with the research community. and advocate researchers to perform experiments on public models to better demonstrate their proposed methods' effectiveness in the future.",
            "keywords": [
                "Public Machine Learning Models",
                "Model Vulnerabilities",
                "Security Assessment",
                "Attack and Defense Evaluation",
                "SecurityNet Database"
            ]
        },
        "url": "URL#379776",
        "sema_paperId": "468a78d431be0d6290bb3007e6920e15761b751e"
    },
    {
        "@score": "1",
        "@id": "379777",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "08/7975",
                        "text": "Ruiyi Zhang"
                    },
                    {
                        "@pid": "156/3555",
                        "text": "Lukas Gerlach 0001"
                    },
                    {
                        "@pid": "04/5465-7",
                        "text": "Daniel Weber 0007"
                    },
                    {
                        "@pid": "323/3235",
                        "text": "Lorenz Hetterich"
                    },
                    {
                        "@pid": "381/1620",
                        "text": "Youheng L\u00fc"
                    },
                    {
                        "@pid": "280/4649",
                        "text": "Andreas Kogler"
                    },
                    {
                        "@pid": "08/1117-1",
                        "text": "Michael Schwarz 0001"
                    }
                ]
            },
            "title": "CacheWarp: Software-based Fault Injection using Selective State Reset.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Zhang00HLK024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/zhang-ruiyi",
            "url": "https://dblp.org/rec/conf/uss/Zhang00HLK024",
            "abstract": "AMD SEV is a trusted-execution environment (TEE), providing confidentiality and integrity for virtual machines (VMs). With AMD SEV, it is possible to securely run VMs on an untrusted hypervisor. While previous attacks demonstrated architectural shortcomings of earlier SEV versions, AMD claims that SEV-SNP prevents all attacks on the integrity. In this paper, we introduce CacheWarp, a new software-based fault attack on AMD SEV-ES and SEV-SNP, exploiting the possibility to architecturally revert modified cache lines of guest VMs to their previous (stale) state. Unlike previous attacks on the integrity, CacheWarp is not mitigated on the newest SEV-SNP implementation, and it does not rely on specifics of the guest VM. CacheWarp only has to interrupt the VM at an attacker-chosen point to invalidate modified cache lines without them being written back to memory. Consequently, the VM continues with architecturally stale data. In 3 case studies, we demonstrate an attack on RSA in the Intel IPP crypto library, recovering the entire private key, logging into an OpenSSH server without authentication, and escalating privileges to root via the sudo binary. While we implement a software-based mitigation proof-of-concept, we argue that mitigations are difficult, as the root cause is in the hardware.",
            "keywords": [
                "Trusted Execution Environment",
                "AMD SEV",
                "Cache Attack",
                "Fault Injection",
                "Data Integrity Vulnerabilities"
            ]
        },
        "url": "URL#379777",
        "sema_paperId": "04012c90f7d0843175baccd02224eb91180bb80e"
    },
    {
        "@score": "1",
        "@id": "379778",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "60/2536",
                        "text": "Rui Zhang"
                    },
                    {
                        "@pid": "39/5544-1",
                        "text": "Hongwei Li 0001"
                    },
                    {
                        "@pid": "63/10765-2",
                        "text": "Rui Wen 0002"
                    },
                    {
                        "@pid": "34/10703",
                        "text": "Wenbo Jiang"
                    },
                    {
                        "@pid": "48/2168-6",
                        "text": "Yuan Zhang 0006"
                    },
                    {
                        "@pid": "b/MichaelBackes1",
                        "text": "Michael Backes 0001"
                    },
                    {
                        "@pid": "14/4412",
                        "text": "Yun Shen"
                    },
                    {
                        "@pid": "06/6785-16",
                        "text": "Yang Zhang 0016"
                    }
                ]
            },
            "title": "Instruction Backdoor Attacks Against Customized LLMs.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Zhang00JZ0S024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/zhang-rui",
            "url": "https://dblp.org/rec/conf/uss/Zhang00JZ0S024",
            "abstract": "The increasing demand for customized Large Language Models (LLMs) has led to the development of solutions like GPTs. These solutions facilitate tailored LLM creation via natural language prompts without coding. However, the trustworthiness of third-party custom versions of LLMs remains an essential concern. In this paper, we propose the first instruction backdoor attacks against applications integrated with untrusted customized LLMs (e.g., GPTs). Specifically, these attacks embed the backdoor into the custom version of LLMs by designing prompts with backdoor instructions, outputting the attacker's desired result when inputs contain the pre-defined triggers. Our attack includes 3 levels of attacks: word-level, syntax-level, and semantic-level, which adopt different types of triggers with progressive stealthiness. We stress that our attacks do not require fine-tuning or any modification to the backend LLMs, adhering strictly to GPTs development guidelines. We conduct extensive experiments on 6 prominent LLMs and 5 benchmark text classification datasets. The results show that our instruction backdoor attacks achieve the desired attack performance without compromising utility. Additionally, we propose two defense strategies and demonstrate their effectiveness in reducing such attacks. Our findings highlight the vulnerability and the potential risks of LLM customization such as GPTs.",
            "keywords": [
                "Customized Large Language Models",
                "Instruction Backdoor Attacks",
                "Backdoor Instructions",
                "LLM Vulnerability",
                "GPT Customization Risks"
            ]
        },
        "url": "URL#379778",
        "sema_paperId": "e6d94c50c5a471a584922a03c405587b59bf18e4"
    },
    {
        "@score": "1",
        "@id": "379779",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "181/2621",
                        "text": "Zheng Zhang"
                    },
                    {
                        "@pid": "33/3270-6",
                        "text": "Yu Hao 0006"
                    },
                    {
                        "@pid": "224/9379",
                        "text": "Weiteng Chen"
                    },
                    {
                        "@pid": "210/0533",
                        "text": "Xiaochen Zou"
                    },
                    {
                        "@pid": "45/2385",
                        "text": "Xingyu Li"
                    },
                    {
                        "@pid": "354/0344",
                        "text": "Haonan Li"
                    },
                    {
                        "@pid": "278/0316",
                        "text": "Yizhuo Zhai"
                    },
                    {
                        "@pid": "31/8302",
                        "text": "Zhiyun Qian"
                    },
                    {
                        "@pid": "91/8881",
                        "text": "Billy Lau"
                    }
                ]
            },
            "title": "SymBisect: Accurate Bisection for Fuzzer-Exposed Vulnerabilities.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Zhang0CZLLZQL24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/zhang-zheng",
            "url": "https://dblp.org/rec/conf/uss/Zhang0CZLLZQL24",
            "abstract": "The popularity of fuzzing has led to its tight integration into the software development process as a routine part of the build and test, i.e., continuous fuzzing. This has resulted in a substantial increase in the reporting of bugs in open-source software, including the Linux kernel. To keep up with the volume of bugs, it is crucial to automatically analyze the bugs to assist developers and maintainers. Bug bisection, i.e., locating the commit that introduced a vulnerability, is one such analysis that can reveal the range of affected software versions and help bug prioritization and patching. However, existing automated solutions fall short in a number of ways: most of them either (1) directly run the same PoC on older software versions without adapting to changes in bug-triggering conditions and are prone to broken dynamic environments or (2) require patches that may not be available when the bug is discovered. In this work, we take a different approach to looking for evidence of fuzzer-exposed vulnerabilities by looking for the underlying bug logic. In this way, we can perform bug bisection much more precisely and accurately. Specifically, we apply under-constrained symbolic execution with several principled guiding techniques to search for the presence of the bug logic efficiently. We show that our approach achieves significantly better accuracy than the state-of-the-art so-lution by 16% (from 74.7% to 90.7%).",
            "keywords": [
                "Fuzzing",
                "Bug Bisection",
                "Vulnerability Analysis",
                "Symbolic Execution",
                "Fuzzer-Exposed Vulnerabilities"
            ]
        },
        "url": "URL#379779",
        "sema_paperId": "28c9f6015272f5bf13dee83d6cb1ce837a5f070f"
    },
    {
        "@score": "1",
        "@id": "379780",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "119/3086",
                        "text": "Peihua Zhang"
                    },
                    {
                        "@pid": "51/3529-2",
                        "text": "Chenggang Wu 0002"
                    },
                    {
                        "@pid": "16/8083",
                        "text": "Xiangyu Meng"
                    },
                    {
                        "@pid": "77/3503",
                        "text": "Yinqian Zhang"
                    },
                    {
                        "@pid": "338/9421",
                        "text": "Mingfan Peng"
                    },
                    {
                        "@pid": "211/5900",
                        "text": "Shiyang Zhang"
                    },
                    {
                        "@pid": "25/5631",
                        "text": "Bing Hu"
                    },
                    {
                        "@pid": "190/5112",
                        "text": "Mengyao Xie"
                    },
                    {
                        "@pid": "198/8150",
                        "text": "Yuanming Lai"
                    },
                    {
                        "@pid": "32/1654-2",
                        "text": "Yan Kang 0002"
                    },
                    {
                        "@pid": "75/3158-17",
                        "text": "Zhe Wang 0017"
                    }
                ]
            },
            "title": "HIVE: A Hardware-assisted Isolated Execution Environment for eBPF on AArch64.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Zhang0MZPZHXL0024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/zhang-peihua",
            "url": "https://dblp.org/rec/conf/uss/Zhang0MZPZHXL0024",
            "abstract": "eBPF has become a critical component in Linux. To ensure kernel security, BPF programs are statically verified before being loaded and executed in the kernel. However, the state-of-the-art eBPF verifier has both security and complexity issues. To this end, we choose to look at BPF programs from a new perspective and regard them as a new type of kernel-mode application, thus an isolation-based rather than a verificationbased approach is needed. In this paper, we propose HIVE, an isolation execution environment for BPF programs on AArch64. To provide the equivalent security guarantees, we systematize the security aims of the eBPF verifier and categorize two types of pointers in eBPF: the inclusive type pointer that points to BPF objects and the exclusive type pointer that points to kernel objects. For the former, HIVE compartmentalizes all BPF memory from the kernel and de-privileges the memory accesses in the BPF programs by leveraging the load/store unprivileged instructions; for the latter, HIVE utilizes the pointer authentication feature to enforce access controls of kernel objects. Evaluation results show that HIVE is not only efficient but also supports complex BPF programs.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-zhang-peihua.pdf",
            "keywords": [
                "eBPF",
                "Isolation Execution Environment",
                "AArch64",
                "Kernel Security",
                "Pointer Authentication"
            ]
        },
        "url": "URL#379780",
        "sema_paperId": "f6e515a3e5320fe899d11b1a4f35bc9817c59d63"
    },
    {
        "@score": "1",
        "@id": "379781",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "64/6322-4",
                        "text": "Guangsheng Zhang 0004"
                    },
                    {
                        "@pid": "58/2670-1",
                        "text": "Bo Liu 0001"
                    },
                    {
                        "@pid": "274/6709",
                        "text": "Huan Tian"
                    },
                    {
                        "@pid": "19/8310",
                        "text": "Tianqing Zhu"
                    },
                    {
                        "@pid": "48/3462-1",
                        "text": "Ming Ding 0001"
                    },
                    {
                        "@pid": "92/2939",
                        "text": "Wanlei Zhou 0001"
                    }
                ]
            },
            "title": "How Does a Deep Learning Model Architecture Impact Its Privacy? A Comprehensive Study of Privacy Attacks on CNNs and Transformers.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Zhang0TZ0024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/zhang-guangsheng",
            "url": "https://dblp.org/rec/conf/uss/Zhang0TZ0024",
            "abstract": "As a booming research area in the past decade, deep learning technologies have been driven by big data collected and processed on an unprecedented scale. However, privacy concerns arise due to the potential leakage of sensitive information from the training data. Recent research has revealed that deep learning models are vulnerable to various privacy attacks, including membership inference attacks, attribute inference attacks, and gradient inversion attacks. Notably, the efficacy of these attacks varies from model to model. In this paper, we answer a fundamental question: Does model architecture affect model privacy? By investigating representative model architectures from convolutional neural networks (CNNs) to Transformers, we demonstrate that Transformers generally exhibit higher vulnerability to privacy attacks than CNNs. Additionally, we identify the micro design of activation layers, stem layers, and LN layers, as major factors contributing to the resilience of CNNs against privacy attacks, while the presence of attention modules is another main factor that exacerbates the privacy vulnerability of Transformers. Our discovery reveals valuable insights for deep learning models to defend against privacy attacks and inspires the research community to develop privacy-friendly model architectures.",
            "keywords": [
                "Model Architecture",
                "Privacy Attacks",
                "Convolutional Neural Networks",
                "Transformers",
                "Vulnerability Analysis"
            ]
        },
        "url": "URL#379781",
        "sema_paperId": "4760379726db3c6e0e33e25a0fd23652281330e3"
    },
    {
        "@score": "1",
        "@id": "379782",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "44/8211",
                        "text": "Qifan Zhang"
                    },
                    {
                        "@pid": "57/7699",
                        "text": "Xuesong Bai"
                    },
                    {
                        "@pid": "40/1491-108",
                        "text": "Xiang Li 0108"
                    },
                    {
                        "@pid": "36/5143",
                        "text": "Haixin Duan"
                    },
                    {
                        "@pid": "181/2688-2",
                        "text": "Qi Li 0002"
                    },
                    {
                        "@pid": "62/4119-1",
                        "text": "Zhou Li 0001"
                    }
                ]
            },
            "title": "ResolverFuzz: Automated Discovery of DNS Resolver Vulnerabilities with Query-Response Fuzzing.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhangBLD0024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/zhang-qifan",
            "url": "https://dblp.org/rec/conf/uss/ZhangBLD0024",
            "abstract": "Domain Name System (DNS) is a critical component of the Internet. DNS resolvers, which act as the cache between DNS clients and DNS nameservers, are the central piece of the DNS infrastructure, essential to the scalability of DNS. However, finding the resolver vulnerabilities is non-trivial, and this problem is not well addressed by the existing tools. To list a few reasons, first, most of the known resolver vulnerabilities are non-crash bugs that cannot be directly detected by the existing oracles (or sanitizers). Second, there lacks rigorous specifications to be used as references to classify a test case as a resolver bug. Third, DNS resolvers are stateful, and stateful fuzzing is still challenging due to the large input space.In this paper, we present a new fuzzing system termed ResolverFuzz to address the aforementioned challenges related to DNS resolvers, with a suite of new techniques being developed. First, ResolverFuzz performs constrained stateful fuzzing by focusing on the short query-response sequence, which has been demonstrated as the most effective way to find resolver bugs, based on our study of the published DNS CVEs. Second, to generate test cases that are more likely to trigger resolver bugs, we combine probabilistic context-free grammar (PCFG) based input generation with byte-level mutation for both queries and responses. Third, we leverage differential testing and clustering to identify non-crash bugs like cache poisoning bugs. We evaluated ResolverFuzz against 6 mainstream DNS software under 4 resolver modes. Overall, we identify 23 vulnerabilities that can result in cache poisoning, resource consumption, and crash attacks. After responsible disclosure, 19 of them have been confirmed or fixed, and 15 CVE numbers have been assigned.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-zhang-qifan.pdf",
            "keywords": [
                "DNS Resolver Security",
                "Fuzzing Techniques",
                "Cache Poisoning",
                "Stateful Fuzzing",
                "Non-Crash Vulnerabilities"
            ]
        },
        "url": "URL#379782"
    },
    {
        "@score": "1",
        "@id": "379783",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "117/0017",
                        "text": "Zhenkai Zhang"
                    },
                    {
                        "@pid": "326/4249",
                        "text": "Kunbei Cai"
                    },
                    {
                        "@pid": "120/5486",
                        "text": "Yanan Guo"
                    },
                    {
                        "@pid": "139/7075",
                        "text": "Fan Yao"
                    },
                    {
                        "@pid": "87/4866-1",
                        "text": "Xing Gao 0001"
                    }
                ]
            },
            "title": "Invalidate+Compare: A Timer-Free GPU Cache Attack Primitive.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhangCGY024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/zhang-zhenkai",
            "url": "https://dblp.org/rec/conf/uss/ZhangCGY024",
            "abstract": "While extensive research has been conducted on CPU cache side-channel attacks, the landscape of similar studies on modern GPUs remains largely uncharted. In this paper, we investigate potential information leakage threats posed by the caches in GPUs of NVIDIA's latest Ampere and Ada Lovelace generations. We first exploit a GPU cache maintenance instruction to reverse engineer certain key properties of the cache hierarchy in these GPUs, and then we introduce a novel GPU cache side-channel attack primitive named Invalidate+Compare that is designed to spy on the GPU cache activities of a victim in a timer-free manner. We further showcase the use of this primitive with two case studies. The first one is a website fingerprinting attack that can accurately identify the web pages visited by a user, while the second one uncovers keystroke data entered via a virtual keyboard. To our knowledge, these stand as the first demonstrations of timer-free cache side-channel attacks on GPUs.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-zhang-zhenkai.pdf",
            "keywords": [
                "GPU Cache Attacks",
                "Side-Channel Attacks",
                "Information Leakage",
                "Timer-Free Attacks",
                "Invalidate+Compare Primitive"
            ]
        },
        "url": "URL#379783",
        "sema_paperId": "bbb788e462eab28dc17fa323039dd0824560594b"
    },
    {
        "@score": "1",
        "@id": "379784",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "187/5246",
                        "text": "Ruisi Zhang"
                    },
                    {
                        "@pid": "227/2207",
                        "text": "Shehzeen Samarah Hussain"
                    },
                    {
                        "@pid": "194/3168",
                        "text": "Paarth Neekhara"
                    },
                    {
                        "@pid": "k/FarinazKoushanfar",
                        "text": "Farinaz Koushanfar"
                    }
                ]
            },
            "title": "REMARK-LLM: A Robust and Efficient Watermarking Framework for Generative Large Language Models.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhangHNK24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/zhang-ruisi",
            "url": "https://dblp.org/rec/conf/uss/ZhangHNK24",
            "abstract": "We present REMARK-LLM, a novel efficient, and robust watermarking framework designed for texts generated by large language models (LLMs). Synthesizing human-like content using LLMs necessitates vast computational resources and extensive datasets, encapsulating critical intellectual property (IP). However, the generated content is prone to malicious exploitation, including spamming and plagiarism. To address the challenges, REMARK-LLM proposes three new components: (i) a learning-based message encoding module to infuse binary signatures into LLM-generated texts; (ii) a reparameterization module to transform the dense distributions from the message encoding to the sparse distribution of the watermarked textual tokens; (iii) a decoding module dedicated for signature extraction; Furthermore, we introduce an optimized beam search algorithm to guarantee the coherence and consistency of the generated content. REMARK-LLM is rigorously trained to encourage the preservation of semantic integrity in watermarked content, while ensuring effective watermark retrieval. Extensive evaluations on multiple unseen datasets highlight REMARK-LLM proficiency and transferability in inserting 2 times more signature bits into the same texts when compared to prior art, all while maintaining semantic integrity. Furthermore, REMARK-LLM exhibits better resilience against a spectrum of watermark detection and removal attacks.",
            "keywords": [
                "Watermarking Framework",
                "Generative Language Models",
                "Intellectual Property Protection",
                "Signature Encoding",
                "Watermark Resilience"
            ]
        },
        "url": "URL#379784",
        "sema_paperId": "8ff1dd6e15408581592f91434be870acc5f1bdd4"
    },
    {
        "@score": "1",
        "@id": "379785",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "245/3547",
                        "text": "Jipeng Zhang"
                    },
                    {
                        "@pid": "185/5207",
                        "text": "Junhao Huang"
                    },
                    {
                        "@pid": "319/7866",
                        "text": "Lirui Zhao"
                    },
                    {
                        "@pid": "124/7193",
                        "text": "Donglong Chen"
                    },
                    {
                        "@pid": "01/4208",
                        "text": "\u00c7etin Kaya Ko\u00e7"
                    }
                ]
            },
            "title": "ENG25519: Faster TLS 1.3 handshake using optimized X25519 and Ed25519.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhangHZCK24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/zhang-jipeng",
            "url": "https://dblp.org/rec/conf/uss/ZhangHZCK24",
            "abstract": "The IETF released RFC 8446 in 2018 as the new TLS 1.3 standard, which recommends using X25519 for key exchange and Ed25519 for identity veri\ufb01cation. These computations are the most time-consuming steps in the TLS handshake. Intel introduced AVX-512 in 2013 as an extension of AVX2, and in 2018, AVX-512IFMA, a submodule of AVX-512 to further support 52-bit (integer) multipliers, was implemented on Cannon Lake CPUs. This paper \ufb01rst revisits various optimization strategies for ECC and presents a more performant X25519/Ed25519 implementation using the AVX-512IFMA instructions. These optimization strategies cover all levels of ECC arithmetic, including \ufb01nite \ufb01eld arithmetic, point arithmetic, and scalar multiplication computations. Furthermore, we formally verify our \ufb01nite \ufb01eld implementation to ensure its correctness and robustness.",
            "keywords": [
                "TLS 1.3",
                "X25519",
                "Ed25519",
                "ECC Optimization",
                "AVX-512IFMA"
            ]
        },
        "url": "URL#379785",
        "sema_paperId": "b4f964ef7acd42b1362f205c479f9a40b2bd49a0"
    },
    {
        "@score": "1",
        "@id": "379786",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "217/3089",
                        "text": "Tingwei Zhang"
                    },
                    {
                        "@pid": "359/6028",
                        "text": "Rishi D. Jha"
                    },
                    {
                        "@pid": "213/9150",
                        "text": "Eugene Bagdasaryan"
                    },
                    {
                        "@pid": "46/6275",
                        "text": "Vitaly Shmatikov"
                    }
                ]
            },
            "title": "Adversarial Illusions in Multi-Modal Embeddings.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhangJBS24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/zhang-tingwei",
            "url": "https://dblp.org/rec/conf/uss/ZhangJBS24",
            "abstract": "Multi-modal embeddings encode texts, images, thermal images, sounds, and videos into a single embedding space, aligning representations across different modalities (e.g., associate an image of a dog with a barking sound). In this paper, we show that multi-modal embeddings can be vulnerable to an attack we call\"adversarial illusions.\"Given an image or a sound, an adversary can perturb it to make its embedding close to an arbitrary, adversary-chosen input in another modality. These attacks are cross-modal and targeted: the adversary can align any image or sound with any target of his choice. Adversarial illusions exploit proximity in the embedding space and are thus agnostic to downstream tasks and modalities, enabling a wholesale compromise of current and future tasks, as well as modalities not available to the adversary. Using ImageBind and AudioCLIP embeddings, we demonstrate how adversarially aligned inputs, generated without knowledge of specific downstream tasks, mislead image generation, text generation, zero-shot classification, and audio retrieval. We investigate transferability of illusions across different embeddings and develop a black-box version of our method that we use to demonstrate the first adversarial alignment attack on Amazon's commercial, proprietary Titan embedding. Finally, we analyze countermeasures and evasion attacks.",
            "keywords": [
                "Multi-Modal Embeddings",
                "Adversarial Attacks",
                "Cross-Modal Alignment",
                "Embedding Vulnerabilities",
                "Adversarial Illusions"
            ]
        },
        "url": "URL#379786",
        "sema_paperId": "e31982f936526829c67dc5f11ab415c52bc8c573"
    },
    {
        "@score": "1",
        "@id": "379787",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "132/5633",
                        "text": "Qingzhao Zhang"
                    },
                    {
                        "@pid": "246/2987",
                        "text": "Shuowei Jin"
                    },
                    {
                        "@pid": "299/2248",
                        "text": "Ruiyang Zhu"
                    },
                    {
                        "@pid": "174/9967",
                        "text": "Jiachen Sun"
                    },
                    {
                        "@pid": "207/1740",
                        "text": "Xumiao Zhang"
                    },
                    {
                        "@pid": "150/3272",
                        "text": "Qi Alfred Chen"
                    },
                    {
                        "@pid": "91/584",
                        "text": "Z. Morley Mao"
                    }
                ]
            },
            "title": "On Data Fabrication in Collaborative Vehicular Perception: Attacks and Countermeasures.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhangJZSZCM24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/zhang-qingzhao",
            "url": "https://dblp.org/rec/conf/uss/ZhangJZSZCM24",
            "abstract": "Collaborative perception, which greatly enhances the sensing capability of connected and autonomous vehicles (CAVs) by incorporating data from external resources, also brings forth potential security risks. CAVs' driving decisions rely on remote untrusted data, making them susceptible to attacks carried out by malicious participants in the collaborative perception system. However, security analysis and countermeasures for such threats are absent. To understand the impact of the vulnerability, we break the ground by proposing various real-time data fabrication attacks in which the attacker delivers crafted malicious data to victims in order to perturb their perception results, leading to hard brakes or increased collision risks. Our attacks demonstrate a high success rate of over 86% on high-fidelity simulated scenarios and are realizable in real-world experiments. To mitigate the vulnerability, we present a systematic anomaly detection approach that enables benign vehicles to jointly reveal malicious fabrication. It detects 91.5% of attacks with a false positive rate of 3% in simulated scenarios and significantly mitigates attack impacts in real-world scenarios.",
            "keywords": [
                "Collaborative Perception",
                "Connected Autonomous Vehicles",
                "Data Fabrication Attacks",
                "Anomaly Detection",
                "Malicious Data Injection"
            ]
        },
        "url": "URL#379787",
        "sema_paperId": "70e9ce33aeb5f43d743b926e0ba627ac62310c70"
    },
    {
        "@score": "1",
        "@id": "379788",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "22/9541",
                        "text": "Mingfei Zhang"
                    },
                    {
                        "@pid": "246/5130",
                        "text": "Rujia Li"
                    },
                    {
                        "@pid": "146/0078",
                        "text": "Sisi Duan"
                    }
                ]
            },
            "title": "Max Attestation Matters: Making Honest Parties Lose Their Incentives in Ethereum PoS.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhangLD24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/zhang-mingfei",
            "url": "https://dblp.org/rec/conf/uss/ZhangLD24",
            "abstract": "We present staircase attack, the first attack on the incentive mechanism of the Proof-of-Stake (PoS) protocol used in Ethereum 2.0 beacon chain. Our attack targets the penalty of the incentive mechanism that penalizes inactive participation. Our attack can make honest validators suffer from penalties, even if they strictly follow the specification of the protocol. We show both theoretically and experimentally that if the adversary controls 29.6% stake in a moderate-size system, the attack can be launched continuously, so eventually all honest validators will lose their incentives. In contrast, the adversarial validators can still receive incentives, and the stake owned by the adversary can eventually exceed the one-third threshold (system assumption), posing a threat to the security properties of the system.\nIn practice, the attack feasibility is directly related to two parameters: the number of validators and the parameter MAX_ATTESTATION, the maximum number of attestations (i.e., votes) that can be included in each block. We further modify our attack such that, with the current system setup (900,000 validators and MAX_ATTESTATION=128), our attack can be launched continuously with a probability of 80.25%. As a result, the incentives any honest validator receives are only 28.9% of its fair share.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-zhang-mingfei.pdf",
            "keywords": [
                "Ethereum 2.0",
                "Proof-of-Stake",
                "Staircase Attack",
                "Validator Incentives",
                "Max Attestation"
            ]
        },
        "url": "URL#379788"
    },
    {
        "@score": "1",
        "@id": "379789",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "44/4491",
                        "text": "Yunyi Zhang"
                    },
                    {
                        "@pid": "89/10754",
                        "text": "Baojun Liu"
                    },
                    {
                        "@pid": "36/5143",
                        "text": "Haixin Duan"
                    },
                    {
                        "@pid": "83/5342",
                        "text": "Min Zhang"
                    },
                    {
                        "@pid": "40/1491-108",
                        "text": "Xiang Li 0108"
                    },
                    {
                        "@pid": "96/8708",
                        "text": "Fan Shi"
                    },
                    {
                        "@pid": "273/1561",
                        "text": "Chengxi Xu"
                    },
                    {
                        "@pid": "150/5254",
                        "text": "Eihal Alowaisheq"
                    }
                ]
            },
            "title": "Rethinking the Security Threats of Stale DNS Glue Records.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhangLDZLSXA24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/zhang-yunyi-rethinking",
            "url": "https://dblp.org/rec/conf/uss/ZhangLDZLSXA24",
            "abstract": "The Domain Name System (DNS) fundamentally relies on glue records to provide authoritative nameserver IP addresses, enabling essential in-domain delegation. While previous studies have identified potential security risks associated with glue records, the exploitation of these records, especially in the context of out-domain delegation, remains unclear due to their inherently low trust level and the diverse ways in which resolvers handle them. This paper undertakes the first systematic exploration of the potential threats posed by DNS glue records, uncovering significant real-world security risks. We empirically identify that 23.18% of glue records across 1,096 TLDs are outdated yet still served in practice. More concerningly, through reverse engineering 9 mainstream DNS implementations (e.g., BIND 9 and Microsoft DNS), we reveal manipulable behaviors associated with glue records. The convergence of these systemic issues allows us to propose the novel threat model that could enable large-scale domain hijacking and denial-of-service attacks. Furthermore, our analysis determines over 193,558 exploitable records exist, placing more than 6 million domains at risk. Additional measurement studies on global open resolvers demonstrate that 90% of them use unvalidated and outdated glue records, including OpenDNS and AliDNS. Our responsible disclosure has already prompted mitigation efforts by affected stakeholders. Microsoft DNS, PowerDNS, OpenDNS, and Alibaba Cloud DNS have acknowledged our reported vulnerability. In summary, this work highlights that glue records constitute a forgotten foundation of DNS architecture requiring renewed security prioritization",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-zhang-yunyi-rethinking.pdf",
            "keywords": [
                "DNS Glue Records",
                "Domain Name System",
                "Security Vulnerabilities",
                "Domain Hijacking",
                "Denial-of-Service Attacks"
            ]
        },
        "url": "URL#379789",
        "sema_paperId": "2a44b0c56d7d457ec5abcdb7a71c30d02c1181d3"
    },
    {
        "@score": "1",
        "@id": "379790",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "37/6352",
                        "text": "Zongyang Zhang"
                    },
                    {
                        "@pid": "24/8923",
                        "text": "Weihan Li"
                    },
                    {
                        "@pid": "292/3041",
                        "text": "Yanpei Guo"
                    },
                    {
                        "@pid": "175/5377",
                        "text": "Kexin Shi"
                    },
                    {
                        "@pid": "c/ShermanSMChow",
                        "text": "Sherman S. M. Chow"
                    },
                    {
                        "@pid": "134/3945",
                        "text": "Ximeng Liu"
                    },
                    {
                        "@pid": "31/507",
                        "text": "Jin Dong"
                    }
                ]
            },
            "title": "Fast RS-IOP Multivariate Polynomial Commitments and Verifiable Secret Sharing.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhangLGSCLD24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/zhang-zongyang",
            "url": "https://dblp.org/rec/conf/uss/ZhangLGSCLD24",
            "abstract": "Supporting proofs of evaluations, polynomial commitment schemes (PCS) are crucial in secure distributed systems. Schemes based on fast Reed\u2013Solomon interactive oracle proofs (RS-IOP) of proximity have recently emerged, offering transparent setup, plausible post-quantum security, efficient operations, and, notably, sublinear proof size and verification. Manifesting a new paradigm, PCS with one-to-many proof can enhance the performance of (asynchronous) verifiable secret sharing ((A)VSS), a cornerstone in distributed computing, for proving multiple evaluations to multiple verifiers. Current RS-IOP-based multivariate PCS, including Hyper-Plonk (Eurocrypt \u201923) and Virgo (S&P \u201920), however, only offer quasi-linear prover complexity in the polynomial size. We propose PolyFRIM , a fast RS-IOP-based multivariate PCS with optimal linear prover complexity, 5-25 \u00d7 faster than prior arts while ensuring competent proof size and verification. Heeding the challenging absence of FFT circuits for multi-variate evaluation, PolyFRIM surpasses Zhang et al.\u2019s (Usenix Sec. \u201922) one-to-many univariate PCS, accelerating proving by 4-7 \u00d7 and verification by 2-4 \u00d7 with 25% shorter proof. Leveraging PolyFRIM , we propose an AVSS scheme FRISS with a better efficiency tradeoff than prior arts from multivariate PCS, including Bingo (Crypto \u201923) and Haven (FC \u201921).",
            "keywords": [
                "Polynomial Commitment Schemes",
                "Interactive Oracle Proofs",
                "Verifiable Secret Sharing",
                "Prover Complexity",
                "Multivariate Evaluation"
            ]
        },
        "url": "URL#379790",
        "sema_paperId": "27c8fdeebd66c382075a787316481c49c71cf9bf"
    },
    {
        "@score": "1",
        "@id": "379791",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "44/4491",
                        "text": "Yunyi Zhang"
                    },
                    {
                        "@pid": "253/7461",
                        "text": "Mingxuan Liu"
                    },
                    {
                        "@pid": "89/10754",
                        "text": "Baojun Liu"
                    },
                    {
                        "@pid": "76/5416-9",
                        "text": "Yiming Zhang 0009"
                    },
                    {
                        "@pid": "36/5143",
                        "text": "Haixin Duan"
                    },
                    {
                        "@pid": "83/5342",
                        "text": "Min Zhang"
                    },
                    {
                        "@pid": "64/3246",
                        "text": "Hui Jiang"
                    },
                    {
                        "@pid": "121/0825",
                        "text": "Yanzhe Li"
                    },
                    {
                        "@pid": "96/8708",
                        "text": "Fan Shi"
                    }
                ]
            },
            "title": "Into the Dark: Unveiling Internal Site Search Abused for Black Hat SEO.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhangLLZDZJLS24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/zhang-yunyi-dark",
            "url": "https://dblp.org/rec/conf/uss/ZhangLLZDZJLS24",
            "abstract": "I nternal site S earch A buse P romotion ( ISAP ) is a prevalent Black Hat Search Engine Optimization (SEO) technique, which exploits the reputation of abused internal search web-sites with minimal effort. However, ISAP is underappreciated and not systematically understood by the security community. To shed light on ISAP risks, we established a collaboration with Baidu, a leading search engine in China. The key challenge of efficiently detecting ISAP risks stems from the sheer volume of daily search traffic, which involves billions of URLs. To address these efficiency bottlenecks, we introduced a first-of-its-kind lightweight detector utilizing a funnel-like approach, tailored to the unique characteristics of ISAP. This approach allows us to single out 3,222,864 ISAP URLs from 10,209 abused websites from Baidu\u2019s traffic data. We found that the businesses most likely to fall prey to this practice are porn and gambling, with two emerging areas: self-promotion for SEO and promotion for anonymous servers. By analyzing Baidu\u2019s search logs, we discovered that these malicious web-sites had reached millions of users in just 4 days. We further evaluated this threat on Google and Bing, thereby confirming the widespread presence of ISAP across various search engines. Moreover, we responsibly disclosed the issue to affected search engines and websites, and actively helped them fix it. In summary, our findings highlight the widespread impact and prevalence of ISAP, emphasizing the urgent need for the security community to prioritize and address such risks.",
            "keywords": [
                "Internal Site Search Abuse",
                "Black Hat SEO",
                "Search Engine Exploitation",
                "Malicious URLs",
                "Baidu Traffic Analysis"
            ]
        },
        "url": "URL#379791",
        "sema_paperId": "24a5b8cce4cc394fd0a6da8107a955f38206936e"
    },
    {
        "@score": "1",
        "@id": "379792",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "09/8586",
                        "text": "Qibo Zhang"
                    },
                    {
                        "@pid": "141/1957",
                        "text": "Daibo Liu"
                    },
                    {
                        "@pid": "58/4582",
                        "text": "Xinyu Zhang"
                    },
                    {
                        "@pid": "05/7548-1",
                        "text": "Zhichao Cao 0001"
                    },
                    {
                        "@pid": "81/655",
                        "text": "Fanzi Zeng"
                    },
                    {
                        "@pid": "25/4108-1",
                        "text": "Hongbo Jiang 0001"
                    },
                    {
                        "@pid": "196/7070",
                        "text": "Wenqiang Jin"
                    }
                ]
            },
            "title": "Eye of Sauron: Long-Range Hidden Spy Camera Detection and Positioning with Inbuilt Memory EM Radiation.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhangLZ0Z0J24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/zhang-qibo",
            "url": "https://dblp.org/rec/conf/uss/ZhangLZ0Z0J24",
            "abstract": "In this paper, we present ESauron \u2014 the \ufb01rst proof-of-concept system that can detect diverse forms of spy cameras (i.e., wireless, wired and of\ufb02ine devices) and quickly pinpoint their locations. The key observation is that, for all spy cameras, the captured raw images must be \ufb01rst digested (e.g., encoding and compression) in the video-capture devices before transferring to target receiver or storage medium. This digestion process takes place in an inbuilt read-write memory whose operations cause electromagnetic radiation (EMR). Speci\ufb01cally, the memory clock drives a variable number of switching voltage regulator activities depending on the workloads, causing \ufb02uctuating currents injected into memory units, thus emitting EMR signals at the clock frequency. Whenever the visual scene changes, bursts of video data processing (e.g., video encoding) suddenly aggravate the memory workload, bringing responsive EMR patterns. ESauron can detect spy cameras by intentionally stimulating scene changes and then sensing the surge of EMRs even from a considerable distance. We implemented a proof-of-concept prototype of the ESauron by carefully designing techniques to sense and differentiate memory EMRs, assert the existence of spy cameras, and pinpoint their locations. Experiments with 50 camera products show that ESauron can detect all spy cameras with an accuracy of 100% after only 4 stimuli, the detection range can exceed 20 meters even in the presence of blockages, and all spy cameras can be accurately located.",
            "keywords": [
                "Spy Camera Detection",
                "Electromagnetic Radiation",
                "Memory EMR Patterns",
                "Location Pinpointing",
                "Scene Change Stimuli"
            ]
        },
        "url": "URL#379792",
        "sema_paperId": "4ae3c404222fd6a54ede1f9cb6c698012e43f612"
    },
    {
        "@score": "1",
        "@id": "379793",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "163/3092",
                        "text": "Guoming Zhang"
                    },
                    {
                        "@pid": "77/9338",
                        "text": "Xiaohui Ma"
                    },
                    {
                        "@pid": "53/9787",
                        "text": "Huiting Zhang"
                    },
                    {
                        "@pid": "313/5061",
                        "text": "Zhijie Xiang"
                    },
                    {
                        "@pid": "39/1697-1",
                        "text": "Xiaoyu Ji 0001"
                    },
                    {
                        "@pid": "187/1683",
                        "text": "Yanni Yang"
                    },
                    {
                        "@pid": "c/XiuzhenCheng",
                        "text": "Xiuzhen Cheng 0001"
                    },
                    {
                        "@pid": "71/9969-1",
                        "text": "Pengfei Hu 0001"
                    }
                ]
            },
            "title": "LaserAdv: Laser Adversarial Attacks on Speech Recognition Systems.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhangMZX0Y0024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/zhang-guoming",
            "url": "https://dblp.org/rec/conf/uss/ZhangMZX0Y0024",
            "abstract": "Audio adversarial perturbations are imperceptible to humans but can mislead machine learning models, posing a security threat to automatic speech recognition (ASR) systems. Existing methods aim to minimize perturbation values, use acoustic masking, or mimic environmental sounds to render them undetectable. However, these perturbations, being audible frequency range sounds, are still audibly detectable. The slow propagation and rapid attenuation of sound limit their temporal sensitivity and attack range. In this study, we propose LaserAdv, a method that employs lasers to launch adversarial attacks, thereby overcoming the aforementioned challenges due to the superior properties of lasers. In the presence of victim speech, laser adversarial perturbations are superimposed on the speech rather than simply drowning it out, so LaserAdv has higher attack efficiency and longer attack range than LightCommands. LaserAdv introduces a selective amplitude enhancement method based on time-frequency interconversion (SAE-TFI) to deal with distortion. Meanwhile, to simultaneously achieve inaudible, targeted, universal, synchronization-free (over 0.5 s), long-range, and black-box attacks in the physical world, we introduced a series of strategies into the objective function. Our experimental results show that a single perturbation can cause DeepSpeech, Whisper and iFlytek, to misinterpret any of the 12,260 voice commands as the target command with accuracy of up to 100%, 92% and 88%, respectively. The attack distance can be up to 120 m.",
            "pdf_url": "https://www.usenix.org/system/files/usenixsecurity24-zhang-guoming.pdf",
            "keywords": [
                "Laser Adversarial Attacks",
                "Speech Recognition Systems",
                "Audio Perturbations",
                "Inaudible Attacks",
                "Long-Range Attacks"
            ]
        },
        "url": "URL#379793",
        "sema_paperId": "94b613e32ad6095702a39a9755ac01a60263190b"
    },
    {
        "@score": "1",
        "@id": "379794",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "44/4491",
                        "text": "Yunyi Zhang"
                    },
                    {
                        "@pid": "29/3959",
                        "text": "Mingming Zhang"
                    },
                    {
                        "@pid": "89/10754",
                        "text": "Baojun Liu"
                    },
                    {
                        "@pid": "02/6247",
                        "text": "Zhan Liu"
                    },
                    {
                        "@pid": "80/2266-4",
                        "text": "Jia Zhang 0004"
                    },
                    {
                        "@pid": "36/5143",
                        "text": "Haixin Duan"
                    },
                    {
                        "@pid": "83/5342",
                        "text": "Min Zhang"
                    },
                    {
                        "@pid": "96/8708",
                        "text": "Fan Shi"
                    },
                    {
                        "@pid": "273/1561",
                        "text": "Chengxi Xu"
                    }
                ]
            },
            "title": "Cross the Zone: Toward a Covert Domain Hijacking via Shared DNS Infrastructure.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhangZLL0DZSX24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/zhang-yunyi-zone",
            "url": "https://dblp.org/rec/conf/uss/ZhangZLL0DZSX24",
            "abstract": "Domain Name System (DNS) establishes clear responsibility boundaries among nameservers for managing DNS records via authoritative delegation. However, the rise of third-party public services has blurred this boundary. In this paper, we uncover a novel attack surface, named XDAuth , arising from public authoritative nameserver infrastructure\u2019s failure to isolate data across zones adequately. This flaw enables adversaries to inject arbitrary resource records across logical authority boundaries and covertly hijack domain names without authority. Unlike prior research on stale NS records, which concentrated on domain names delegated to expired nameservers or those of hosting service providers, XDAuth targets enterprises that maintain their authoritative domain names. We demonstrate that XDAuth is entirely feasible, and through comprehensive measurements, we identify 12 potential vulnerable providers (e.g., Amazon Route 53, NSONE, and DigiCert DNS), affecting 125,124 domains of notable enterprises, including the World Bank, and the BBC. More-over, we responsibly disclose the issue to the affected vendors. Some DNS providers and enterprises (e.g., Amazon Route 53) have recognized the issue and are adopting mitigation measures based on our suggestions.",
            "keywords": [
                "Domain Name System (DNS)",
                "Covert Domain Hijacking",
                "XDAuth Attack",
                "Authoritative Nameserver Vulnerabilities",
                "Resource Record Injection"
            ]
        },
        "url": "URL#379794",
        "sema_paperId": "f4da055352d34b1582300b382907927a6be81a9e"
    },
    {
        "@score": "1",
        "@id": "379795",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "381/1598",
                        "text": "Jiaxu Zhao 0004"
                    },
                    {
                        "@pid": "204/3729",
                        "text": "Yuekang Li"
                    },
                    {
                        "@pid": "48/6274",
                        "text": "Yanyan Zou"
                    },
                    {
                        "@pid": "69/9342",
                        "text": "Zhaohui Liang"
                    },
                    {
                        "@pid": "181/1848-11",
                        "text": "Yang Xiao 0011"
                    },
                    {
                        "@pid": "185/7953",
                        "text": "Yeting Li"
                    },
                    {
                        "@pid": "381/1637",
                        "text": "Bingwei Peng"
                    },
                    {
                        "@pid": "333/4316",
                        "text": "Nanyu Zhong"
                    },
                    {
                        "@pid": "14/7249",
                        "text": "Xinyi Wang"
                    },
                    {
                        "@pid": "35/7092",
                        "text": "Wei Wang"
                    },
                    {
                        "@pid": "24/679",
                        "text": "Wei Huo"
                    }
                ]
            },
            "title": "Leveraging Semantic Relations in Code and Data to Enhance Taint Analysis of Embedded Systems.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhaoLZL0LPZWWH24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/zhao",
            "url": "https://dblp.org/rec/conf/uss/ZhaoLZL0LPZWWH24",
            "abstract": "IoT devices have significantly impacted our daily lives, and detecting vulnerabilities in embedded systems early on is critical for ensuring their security. Among the existing vulnerability detection techniques for embedded systems, static taint analysis has been proven effective in detecting severe vulnerabilities, such as command injection vulnerabilities, which can cause remote code execution. Nevertheless, static taint analysis is faced with the problem of identifying sources comprehensively and accurately. This paper presents L ARA , a novel static taint analysis technique to detect vulnerabilities in embedded systems. The design of L ARA is inspired by an observation that pertains to semantic relations within and between the code and data of embedded software: user input entries can be categorized as URIs or keys ( data ), and identifying their handling code ( code ) and relations can help systematically and comprehensively identify the sources for taint analysis. Transforming the observation into a practical methodology poses challenges. To address these challenges, L ARA employs a combination of pattern-based static analysis and large language model(LLM)- aided analysis, aiming to replicate how human experts would utilize the findings during analysis and enhance it. The pattern-based static analysis simulates human experience, while the LLM-aided analysis captures the way human experts perceive code semantics. We implemented L ARA and evaluated it on 203 IoT devices from 21 vendors. In general, L ARA detects 556 and 602 more known vulnerabilities than S A TC and K ARONTE while reducing false positives by 57.0% and 54.3%. Meanwhile, with more sources and sinks from L ARA , E M T AINT can detect 245 more vulnerabilities. To date, L ARA has found 245 0-day vulnerabilities in 57 devices, all of which were confirmed or fixed with 162 CVE IDs assigned.",
            "keywords": [
                "Embedded Systems Security",
                "Static Taint Analysis",
                "Vulnerability Detection",
                "Semantic Relations",
                "IoT Device Vulnerabilities"
            ]
        },
        "url": "URL#379795",
        "sema_paperId": "1cfe6c0ff054faa9ec16b35737b705148307f92a"
    },
    {
        "@score": "1",
        "@id": "379796",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "205/2918",
                        "text": "Tianyue Zheng"
                    },
                    {
                        "@pid": "174/3780",
                        "text": "Jingzhi Hu"
                    },
                    {
                        "@pid": "00/5179",
                        "text": "Rui Tan"
                    },
                    {
                        "@pid": "77/3503",
                        "text": "Yinqian Zhang"
                    },
                    {
                        "@pid": "h/YingHe1",
                        "text": "Ying He 0001"
                    },
                    {
                        "@pid": "42/2501-1",
                        "text": "Jun Luo 0001"
                    }
                ]
            },
            "title": "pi-Jack: Physical-World Adversarial Attack on Monocular Depth Estimation with Perspective Hijacking.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhengHTZ0024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/zheng",
            "url": "https://dblp.org/rec/conf/uss/ZhengHTZ0024",
            "abstract": "Monocular depth estimation (MDE) plays a crucial role in modern autonomous driving (AD) by facilitating 3-D scene understanding and interaction. While vulnerabilities in deep neural networks (e.g., adversarial perturbations) have been exploited to compromise MDE, existing attacks face challenges in target accessibility and stealthiness. To address these limitations, we introduce \u03c0 -Jack, a novel physical-world attack on MDE via perspective hijacking . It is based on an observation that MDE relies heavily on perspective cues to infer depth, yet these cues can be manipulated by strategically placing common 3-D objects in AD scenes. With an optimization-based approach, \u03c0 -Jack \u201chijacks\u201d the perspective information and alters the target pixels\u2019 depths perceived by the MDE model in a black-box manner. We also show via experiments that \u03c0 -Jack is effective across various MDE models and scenarios, confirming generalizability of perspective hijacking. Our extensive evaluations demonstrate that \u03c0 -Jack is effective across different target and attack vectors, and increases the mean depth error by over 14 meters. Moreover, in our end-to-end AD simulation, \u03c0 -Jack results in compromised lane change, sudden braking, and life-threatening collisions.",
            "keywords": [
                "Monocular Depth Estimation",
                "Adversarial Attack",
                "Perspective Hijacking",
                "Autonomous Driving",
                "Depth Perception Manipulation"
            ]
        },
        "url": "URL#379796",
        "sema_paperId": "fdc8fb1e7499132392f2cce061893b24c49b9d8e"
    },
    {
        "@score": "1",
        "@id": "379797",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "41/2797",
                        "text": "Chang Zhu"
                    },
                    {
                        "@pid": "90/10939",
                        "text": "Ziyang Li"
                    },
                    {
                        "@pid": "242/4544",
                        "text": "Anton Xue"
                    },
                    {
                        "@pid": "364/0510",
                        "text": "Ati Priya Bajaj"
                    },
                    {
                        "@pid": "353/7674",
                        "text": "Wil Gibbs"
                    },
                    {
                        "@pid": "07/8499",
                        "text": "Yibo Liu"
                    },
                    {
                        "@pid": "a/RAlur",
                        "text": "Rajeev Alur"
                    },
                    {
                        "@pid": "150/5198",
                        "text": "Tiffany Bao"
                    },
                    {
                        "@pid": "144/7311",
                        "text": "Hanjun Dai"
                    },
                    {
                        "@pid": "28/8280",
                        "text": "Adam Doup\u00e9"
                    },
                    {
                        "@pid": "92/6794",
                        "text": "Mayur Naik"
                    },
                    {
                        "@pid": "119/7712",
                        "text": "Yan Shoshitaishvili"
                    },
                    {
                        "@pid": "127/9829",
                        "text": "Ruoyu Wang 0001"
                    },
                    {
                        "@pid": "133/8188",
                        "text": "Aravind Machiry"
                    }
                ]
            },
            "title": "TYGR: Type Inference on Stripped Binaries using Graph Neural Networks.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhuLXBGLABDDNS024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/zhu-chang",
            "url": "https://dblp.org/rec/conf/uss/ZhuLXBGLABDDNS024",
            "abstract": "Binary type inference is a core research challenge in binary program analysis and reverse engineering. It concerns identifying the data types of registers and memory values in a stripped executable (or object file), whose type information is discarded during compilation. Current methods rely on either manually crafted inference rules, which are brittle and demand significant effort to update, or machine learning-based approaches that suffer from low accuracy. In this paper we propose T Y G R , a graph neural network based solution that encodes data-flow information for inferring both basic and struct variable types in stripped binary programs. To support different architectures and compiler optimizations, T Y G R was implemented on top of the ANGR binary analysis platform and uses an architecture-agnostic data-flow analysis to extract a graph-based intra-procedural representation of data-flow information. We noticed a severe lack of diversity in existing binary executables datasets and created T Y D A , a large dataset of diverse binary executables. The sole publicly available dataset, provided by S TATE F ORMER , contains only 1% of the total number of functions in T Y D A . T Y G R is trained and evaluated on a subset of T Y D A and generalizes to the rest of the dataset. T Y G R demonstrates an overall accuracy of 76.6% and a struct",
            "keywords": [
                "Binary Program Analysis",
                "Type Inference",
                "Stripped Executables",
                "Graph Neural Networks",
                "Data-Flow Analysis"
            ]
        },
        "url": "URL#379797",
        "sema_paperId": "6ab60f799996fcf20de1786ac139edb3b5769899"
    },
    {
        "@score": "1",
        "@id": "379798",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "277/3333",
                        "text": "Shenchen Zhu"
                    },
                    {
                        "@pid": "48/76-18",
                        "text": "Yue Zhao 0018"
                    },
                    {
                        "@pid": "c/KaiChen12",
                        "text": "Kai Chen 0012"
                    },
                    {
                        "@pid": "72/6811",
                        "text": "Bo Wang"
                    },
                    {
                        "@pid": "307/2737",
                        "text": "Hualong Ma"
                    },
                    {
                        "@pid": "353/7546",
                        "text": "Cheng&apos;an Wei"
                    }
                ]
            },
            "title": "AE-Morpher: Improve Physical Robustness of Adversarial Objects against LiDAR-based Detectors via Object Reconstruction.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhuZ0WMW24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/zhu-shenchen",
            "url": "https://dblp.org/rec/conf/uss/ZhuZ0WMW24",
            "abstract": ".",
            "keywords": [
                "Adversarial Object Detection",
                "LiDAR Sensors",
                "Physical Robustness",
                "Object Reconstruction",
                "Adversarial Attacks"
            ]
        },
        "url": "URL#379798",
        "sema_paperId": "9b2d872a306309fdc50de3c505203fee8f033d10"
    },
    {
        "@score": "1",
        "@id": "379799",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "301/6349",
                        "text": "Yuanxin Zhuang"
                    },
                    {
                        "@pid": "64/3041",
                        "text": "Chuan Shi"
                    },
                    {
                        "@pid": "234/4670",
                        "text": "Mengmei Zhang"
                    },
                    {
                        "@pid": "67/5633",
                        "text": "Jinghui Chen"
                    },
                    {
                        "@pid": "178/9876",
                        "text": "Lingjuan Lyu"
                    },
                    {
                        "@pid": "84/6614-1",
                        "text": "Pan Zhou 0001"
                    },
                    {
                        "@pid": "121/0780-1",
                        "text": "Lichao Sun 0001"
                    }
                ]
            },
            "title": "Unveiling the Secrets without Data: Can Graph Neural Networks Be Exploited through Data-Free Model Extraction Attacks?",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhuangSZCLZ024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/zhuang",
            "url": "https://dblp.org/rec/conf/uss/ZhuangSZCLZ024",
            "abstract": "Graph neural networks (GNNs) play a crucial role in various graph applications, such as social science, biology, and molecular chemistry. Despite their popularity, GNNs are still vulnerable to intellectual property threats. Previous studies have demonstrated the susceptibility of GNN models to model extraction attacks, where attackers steal the functionality of GNNs by sending queries and obtaining model responses. However, existing model extraction attacks often assume that the attacker has access to specific information about the victim model\u2019s training data, including node attributes, connections, and the shadow dataset. This assumption is impractical in real-world scenarios. To address this issue, we propose S TEAL - GNN, the first data-free model extraction attack framework against GNNs. S TEAL GNN advances prior GNN extraction attacks in three key aspects: 1) It is completely data-free , as it does not require actual node features or graph structures to extract GNN models. 2) It constitutes a full-rank attack that can be applied to node classification and link prediction tasks, posing significant intellectual property threats across a wide range of graph applications. 3) It can handle the most challenging hard-label attack setting, where the attacker possesses no knowledge about the target GNN model and can only obtain predicted labels through querying the victim model. Our experimental results on four benchmark graph datasets demonstrate the effectiveness of S TEAL GNN in attacking representative GNN models.",
            "keywords": [
                "Graph Neural Networks",
                "Model Extraction Attacks",
                "Data-Free Attacks",
                "Intellectual Property Threats",
                "Node Classification and Link Prediction"
            ]
        },
        "url": "URL#379799",
        "sema_paperId": "40d2bc169204b49a9cfa659b5398791ac5860caf"
    },
    {
        "@score": "1",
        "@id": "379800",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "353/5298",
                        "text": "Muqi Zou"
                    },
                    {
                        "@pid": "271/4490",
                        "text": "Arslan Khan"
                    },
                    {
                        "@pid": "40/5102",
                        "text": "Ruoyu Wu"
                    },
                    {
                        "@pid": "56/1065",
                        "text": "Han Gao"
                    },
                    {
                        "@pid": "99/3883",
                        "text": "Antonio Bianchi"
                    },
                    {
                        "@pid": "159/0537",
                        "text": "Dave (Jing) Tian"
                    }
                ]
            },
            "title": "D-Helix: A Generic Decompiler Testing Framework Using Symbolic Differentiation.",
            "venue": "USENIX Security Symposium",
            "year": "2024",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZouKWGBT24",
            "ee": "https://www.usenix.org/conference/usenixsecurity24/presentation/zou",
            "url": "https://dblp.org/rec/conf/uss/ZouKWGBT24",
            "abstract": "Decompilers, one of the widely used security tools, transform low-level binary programs back into their high-level source representations, such as C/C++. While state-of-the-art de-compilers try to generate more human-readable outputs, for instance, by eliminating goto statements in their decompiled code, the correctness of a decompilation process is largely ignored due to the complexity of decompilers, e.g., involving hundreds of heuristic rules. As a result, outputs from decom-pilers are often not accurate, which a\ufb00ects the e\ufb00ectiveness of downstream security tasks. In this paper, we propose D-H ELIX , a generic decom-piler testing framework that can automatically vet the de-compilation correctness on the function level. D-H ELIX uses R ECOMPILER to compile the decompiled code at the functional level. It then uses S YMDIFF to compare the symbolic model of the original binary with the one of the decompiled code, detecting potential errors introduced by the decompila-tion process. D-H ELIX further provides T UNER to help debug the incorrect decompilation via toggling decompilation heuristic rules automatically. We evaluated D-H ELIX on Ghidra and angr using 2,004 binaries and object \ufb01les ending up with 93K decompiled functions in total. D-H ELIX detected 4,515 in-correctly decompiled functions, reproduced 8 known bugs, found 17 distinct previously unknown bugs within these two decompilers, and \ufb01xed 7 bugs automatically.",
            "keywords": [
                "Decompilation",
                "Binary Analysis",
                "Testing Framework",
                "Symbolic Differentiation",
                "Decompilation Correctness"
            ]
        },
        "url": "URL#379800",
        "sema_paperId": "85f9aaacf96c303d3c9903b1c0875d8d520a7bde"
    },
    {
        "@score": "1",
        "@id": "391260",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "56/490",
                        "text": "Davide Balzarotti"
                    },
                    {
                        "@pid": "10/3878-1",
                        "text": "Wenyuan Xu 0001"
                    }
                ]
            },
            "title": "33rd USENIX Security Symposium, USENIX Security 2024, Philadelphia, PA, USA, August 14-16, 2024",
            "venue": "USENIX Security Symposium",
            "publisher": "USENIX Association",
            "year": "2024",
            "type": "Editorship",
            "access": "open",
            "key": "conf/uss/2024",
            "ee": "https://www.usenix.org/conference/usenixsecurity24",
            "url": "https://dblp.org/rec/conf/uss/2024",
            "abstract": null
        },
        "url": "URL#391260",
        "sema_paperId": "7ec857f079c8a7798b3d657ab2471f28dc6c18be"
    }
]