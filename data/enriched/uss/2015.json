[
    {
        "@score": "1",
        "@id": "4144938",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "b/MichaelBackes1",
                        "text": "Michael Backes 0001"
                    },
                    {
                        "@pid": "31/7561",
                        "text": "Sven Bugiel"
                    },
                    {
                        "@pid": "h/ChristianHammer1",
                        "text": "Christian Hammer 0001"
                    },
                    {
                        "@pid": "167/0506",
                        "text": "Oliver Schranz"
                    },
                    {
                        "@pid": "94/9829",
                        "text": "Philipp von Styp-Rekowsky"
                    }
                ]
            },
            "title": "Boxify: Full-fledged App Sandboxing for Stock Android.",
            "venue": "USENIX Security Symposium",
            "pages": "691-706",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0001B0SS15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/backes",
            "url": "https://dblp.org/rec/conf/uss/0001B0SS15",
            "abstract": "We present the first concept for full-fledged app sandboxing on stock Android. Our approach is based on application virtualization and process-based privilege separation to securely encapsulate untrusted apps in an isolated environment. In contrast to all related work on stock Android, we eliminate the necessity to modify the code of monitored apps, and thereby overcome existing legal concerns and deployment problems that rewriting-based approaches have been facing. We realize our concept as a regular Android app called Boxify that can be deployed without firmware modifications or root privileges. A systematic evaluation of Boxify demonstrates its capability to enforce established security policies without incurring a significant runtime performance overhead.",
            "keywords": [
                "App Sandboxing",
                "Application Virtualization",
                "Process-based Privilege Separation",
                "Untrusted Apps",
                "Security Policies Enforcement"
            ]
        },
        "url": "URL#4144938",
        "sema_paperId": "1a445f9eabdf5e88daad83993be18f5a64ba5563"
    },
    {
        "@score": "1",
        "@id": "4144939",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "c/KaiChen12",
                        "text": "Kai Chen 0012"
                    },
                    {
                        "@pid": "95/4442-88",
                        "text": "Peng Wang 0088"
                    },
                    {
                        "@pid": "153/5787",
                        "text": "Yeonjoon Lee"
                    },
                    {
                        "@pid": "06/6268",
                        "text": "XiaoFeng Wang 0001"
                    },
                    {
                        "@pid": "28/6297-18",
                        "text": "Nan Zhang 0018"
                    },
                    {
                        "@pid": "78/7690-1",
                        "text": "Heqing Huang 0001"
                    },
                    {
                        "@pid": "10/328",
                        "text": "Wei Zou"
                    },
                    {
                        "@pid": "21/6121-5",
                        "text": "Peng Liu 0005"
                    }
                ]
            },
            "title": "Finding Unknown Malice in 10 Seconds: Mass Vetting for New Threats at the Google-Play Scale.",
            "venue": "USENIX Security Symposium",
            "pages": "659-674",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/0012WLWZHZ015",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/chen-kai",
            "url": "https://dblp.org/rec/conf/uss/0012WLWZHZ015",
            "abstract": "An app market's vetting process is expected to be scalable and effective. However, today's vetting mechanisms are slow and less capable of catching new threats. In our research, we found that a more powerful solution can be found by exploiting the way Android malware is constructed and disseminated, which is typically through repackaging legitimate apps with similar malicious components. As a result, such attack payloads often stand out from those of the same repackaging origin and also show up in the apps not supposed to relate to each other. \n \nBased upon this observation, we developed a new technique, called MassVet, for vetting apps at a massive scale, without knowing what malware looks like and how it behaves. Unlike existing detection mechanisms, which often utilize heavyweight program analysis techniques, our approach simply compares a submitted app with all those already on a market, focusing on the difference between those sharing a similar UI structure (indicating a possible repackaging relation), and the commonality among those seemingly unrelated. Once public libraries and other legitimate code reuse are removed, such diff/common program components become highly suspicious. In our research, we built this \"Diff-Com\" analysis on top of an efficient similarity comparison algorithm, which maps the salient features of an app's UI structure or a method's control-flow graph to a value for a fast comparison. We implemented MassVet over a stream processing engine and evaluated it nearly 1.2 million apps from 33 app markets around the world, the scale of Google Play. Our study shows that the technique can vet an app within 10 seconds at a low false detection rate. Also, it outperformed all 54 scanners in VirusTotal (NOD32, Symantec, McAfee, etc.) in terms of detection coverage, capturing over a hundred thousand malicious apps, including over 20 likely zero-day malware and those installed millions of times. A close look at these apps brings to light intriguing new observations e.g., Google's detection strategy and malware authors' countermoves that cause the mysterious disappearance and reappearance of some Google Play apps.",
            "keywords": [
                "Android Malware Detection",
                "App Vetting Process",
                "Repackaging Attack",
                "Diff-Com Analysis",
                "MassVet Technique"
            ]
        },
        "url": "URL#4144939",
        "sema_paperId": "6f9700600eed7d4df3573e2da1ab27557aa7624d"
    },
    {
        "@score": "1",
        "@id": "4144940",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "126/9907",
                        "text": "Frederico Araujo"
                    },
                    {
                        "@pid": "60/1400",
                        "text": "Kevin W. Hamlen"
                    }
                ]
            },
            "title": "Compiler-instrumented, Dynamic Secret-Redaction of Legacy Processes for Attacker Deception.",
            "venue": "USENIX Security Symposium",
            "pages": "145-159",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AraujoH15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/araujo",
            "url": "https://dblp.org/rec/conf/uss/AraujoH15",
            "abstract": "An enhanced dynamic taint-tracking semantics is presented and implemented, facilitating fast and precise runtime secret redaction from legacy processes, such as those compiled from C/C++. The enhanced semantics reduce the annotation burden imposed upon developers seeking to add secret-redaction capabilities to legacy code, while curtailing over-tainting and label creep. \n \nAn implementation for LLVM's DataFlow Sanitizer automatically instruments taint-tracking and secret-redaction support into annotated C/C++ programs at compile-time, yielding programs that can self-censor their address spaces in response to emerging cyber-attacks. The technology is applied to produce the first information flow-based honey-patching architecture for the Apache web server. Rather than merely blocking intrusions, the modified server deceptively diverts attacker connections to secret-sanitized process clones that monitor attacker activities and disinform adversaries with honey-data.",
            "keywords": [
                "Dynamic Taint Tracking",
                "Secret Redaction",
                "Legacy Processes",
                "Honey-Patching Architecture",
                "Attacker Deception"
            ]
        },
        "url": "URL#4144940",
        "sema_paperId": "52fa4bd47d77c173691f1f3af6a645f23d8c75b8"
    },
    {
        "@score": "1",
        "@id": "4144941",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "117/2519",
                        "text": "Hadi Asghari"
                    },
                    {
                        "@pid": "167/0628",
                        "text": "Michael Ciere"
                    },
                    {
                        "@pid": "17/7444",
                        "text": "Michel J. G. van Eeten"
                    }
                ]
            },
            "title": "Post-Mortem of a Zombie: Conficker Cleanup After Six Years.",
            "venue": "USENIX Security Symposium",
            "pages": "1-16",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/AsghariCE15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/asghari",
            "url": "https://dblp.org/rec/conf/uss/AsghariCE15",
            "abstract": "Research on botnet mitigation has focused predominantly on methods to technically disrupt the command-and-control infrastructure. Much less is known about the effectiveness of large-scale efforts to clean up infected machines. We analyze longitudinal data from the sinkhole of Conficker, one the largest botnets ever seen, to assess the impact of what has been emerging as a best practice: national anti-botnet initiatives that support large-scale cleanup of end user machines. It has been six years since the Conficker botnet was sinkholed. The attackers have abandoned it. Still, nearly a million machines remain infected. Conficker provides us with a unique opportunity to estimate cleanup rates, because there are relatively few interfering factors at work. This paper is the first to propose a systematic approach to transform noisy sinkhole data into comparative infection metrics and normalized estimates of cleanup rates. We compare the growth, peak, and decay of Conficker across countries. We find that institutional differences, such as ICT development or unlicensed software use, explain much of the variance, while the national anti-botnet centers have had no visible impact. Cleanup seems even slower than the replacement of machines running Windows XP. In general, the infected users appear outside the reach of current remediation practices. Some ISPs may have judged the neutralized botnet an insufficient threat to merit remediation. These machines can however be magnets for other threats -- we find an overlap between GameoverZeus and Conficker infections. We conclude by reflecting on what this means for the future of botnet mitigation.",
            "keywords": [
                "Botnet Mitigation",
                "Conficker",
                "Infection Cleanup",
                "National Anti-Botnet Initiatives",
                "Longitudinal Data Analysis"
            ]
        },
        "url": "URL#4144941",
        "sema_paperId": "1977d8a3ba48d221747212bc8f63cfc9793fbd14"
    },
    {
        "@score": "1",
        "@id": "4144942",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "126/3601",
                        "text": "Adam Bates 0001"
                    },
                    {
                        "@pid": "159/0537",
                        "text": "Dave Tian"
                    },
                    {
                        "@pid": "82/1935",
                        "text": "Kevin R. B. Butler"
                    },
                    {
                        "@pid": "13/4686",
                        "text": "Thomas Moyer"
                    }
                ]
            },
            "title": "Trustworthy Whole-System Provenance for the Linux Kernel.",
            "venue": "USENIX Security Symposium",
            "pages": "319-334",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BatesTBM15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/bates",
            "url": "https://dblp.org/rec/conf/uss/BatesTBM15",
            "abstract": "In a provenance-aware system, mechanisms gather and report metadata that describes the history of each object being processed on the system, allowing users to understand how data objects came to exist in their present state. However, while past work has demonstrated the usefulness of provenance, less attention has been given to securing provenance-aware systems. Provenance itself is a ripe attack vector, and its authenticity and integrity must be guaranteed before it can be put to use. \n \nWe present Linux Provenance Modules (LPM), the first general framework for the development of provenance-aware systems. We demonstrate that LPM creates a trusted provenance-aware execution environment, collecting complete whole-system provenance while imposing as little as 2.7% performance overhead on normal system operation. LPM introduces new mechanisms for secure provenance layering and authenticated communication between provenance-aware hosts, and also interoperates with existing mechanisms to provide strong security assurances. To demonstrate the potential uses of LPM, we design a Provenance-Based Data Loss Prevention (PB-DLP) system. We implement PBDLP as a file transfer application that blocks the transmission of files derived from sensitive ancestors while imposing just tens of milliseconds overhead. LPM is the first step towards widespread deployment of trustworthy provenance-aware applications.",
            "keywords": [
                "Provenance-Aware Systems",
                "Linux Kernel",
                "Trusted Execution Environment",
                "Data Integrity",
                "Provenance-Based Data Loss Prevention (PB-DLP)"
            ]
        },
        "url": "URL#4144942",
        "sema_paperId": "114f664a25c411b708c0f0058c3f455b5a1f3e9b"
    },
    {
        "@score": "1",
        "@id": "4144943",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "b/LBeringer",
                        "text": "Lennart Beringer"
                    },
                    {
                        "@pid": "90/7791",
                        "text": "Adam Petcher"
                    },
                    {
                        "@pid": "167/0489",
                        "text": "Katherine Q. Ye"
                    },
                    {
                        "@pid": "a/AWAppel",
                        "text": "Andrew W. Appel"
                    }
                ]
            },
            "title": "Verified Correctness and Security of OpenSSL HMAC.",
            "venue": "USENIX Security Symposium",
            "pages": "207-221",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BeringerPYA15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/beringer",
            "url": "https://dblp.org/rec/conf/uss/BeringerPYA15",
            "abstract": "We have proved, with machine-checked proofs in Coq, that an OpenSSL implementation of HMAC with SHA- 256 correctly implements its FIPS functional specification and that its functional specification guarantees the expected cryptographic properties. This is the first machine-checked cryptographic proof that combines a source-program implementation proof, a compiler-correctness proof, and a cryptographic-security proof, with no gaps at the specification interfaces. \n \nThe verification was done using three systems within the Coq proof assistant: the Foundational Cryptography Framework, to verify crypto properties of functional specs; the Verified Software Toolchain, to verify C programs w.r.t. functional specs; and CompCert, for verified compilation of C to assembly language.",
            "keywords": [
                "Cryptographic Verification",
                "HMAC",
                "OpenSSL",
                "Functional Specification",
                "Coq Proof Assistant"
            ]
        },
        "url": "URL#4144943",
        "sema_paperId": "614f3b72660eed2ce7b62970fa73ba8eae4d278b"
    },
    {
        "@score": "1",
        "@id": "4144944",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "136/8461",
                        "text": "Kevin Borgolte"
                    },
                    {
                        "@pid": "k/ChristopherKruegel",
                        "text": "Christopher Kruegel"
                    },
                    {
                        "@pid": "v/GiovanniVigna",
                        "text": "Giovanni Vigna"
                    }
                ]
            },
            "title": "Meerkat: Detecting Website Defacements through Image-based Object Recognition.",
            "venue": "USENIX Security Symposium",
            "pages": "595-610",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/BorgolteKV15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/borgolte",
            "url": "https://dblp.org/rec/conf/uss/BorgolteKV15",
            "abstract": "Website defacements and website vandalism can inflict significant harm on the website owner through the loss of sales, the loss in reputation, or because of legal ramifications. \n \nPrior work on website defacements detection focused on detecting unauthorized changes to the web server, e.g., via host-based intrusion detection systems or file-based integrity checks. However, most prior approaches lack the capabilities to detect the most prevailing defacement techniques used today: code and/or data injection attacks, and DNS hijacking. This is because these attacks do not actually modify the code or configuration of the website, but instead they introduce new content or redirect the user to a different website. \n \nIn this paper, we approach the problem of defacement detection from a different angle: we use computer vision techniques to recognize if a website was defaced, similarly to how a human analyst decides if a website was defaced when viewing it in a web browser. We introduce MEERKAT, a defacement detection system that requires no prior knowledge about the website's content or its structure, but only its URL. Upon detection of a defacement, the system notifies the website operator that his website is defaced, who can then take appropriate action. To detect defacements, MEERKAT automatically learns high-level features from screenshots of defaced websites by combining recent advances in machine learning, like stacked autoencoders and deep neural networks, with techniques from computer vision. These features are then used to create models that allow for the detection of newly-defaced websites. \n \nWe show the practicality of MEERKAT on the largest website defacement dataset to date, comprising of 10,053,772 defacements observed between January 1998 and May 2014, and 2,554,905 legitimate websites. Overall, MEERKAT achieves true positive rates between 97.422% and 98.816%, false positive rates between 0.547% and 1.528%, and Bayesian detection rates between 98.583% and 99.845%, thus significantly outperforming existing approaches.",
            "keywords": [
                "Website Defacement Detection",
                "Image-based Object Recognition",
                "Computer Vision",
                "Defacement Techniques",
                "Content Injection Attacks"
            ]
        },
        "url": "URL#4144944",
        "sema_paperId": "6d286eb199548b02eb994e472159c13e9b062a8e"
    },
    {
        "@score": "1",
        "@id": "4144945",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "04/11495",
                        "text": "Niklas B\u00fcscher"
                    },
                    {
                        "@pid": "66/3585-1",
                        "text": "Stefan Katzenbeisser 0001"
                    }
                ]
            },
            "title": "Faster Secure Computation through Automatic Parallelization.",
            "venue": "USENIX Security Symposium",
            "pages": "531-546",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Buscher015",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/buescher",
            "url": "https://dblp.org/rec/conf/uss/Buscher015",
            "abstract": "Secure two-party computation (TPC) based on Yao's garbled circuits has seen a lot of progress over the past decade. Yet, compared with generic computation, TPC is still multiple orders of magnitude slower. To improve the efficiency of secure computation based on Yao's protocol, we propose a practical parallelization scheme. Its advances over existing parallelization approaches are twofold. First, we present a compiler that detects parallelism at the source code level and automatically transforms C code into parallel circuits. Second, by switching the roles of circuit generator and evaluator between both computing parties in the semi-honest model, our scheme makes better use of computation and network resources. This inter-party parallelization approach leads to significant efficiency increases already on single-core hardware without compromising security. Multiple implementations illustrate the practicality of our approach. For instance, we report speed-ups of up to 2.18 on 2 cores and 4.36 on 4 cores for the example application of parallel modular exponentiation.",
            "keywords": [
                "Secure Two-Party Computation",
                "Garbled Circuits",
                "Automatic Parallelization",
                "Efficiency Improvement",
                "Inter-Party Resource Utilization"
            ]
        },
        "url": "URL#4144945",
        "sema_paperId": "379010410434731a05d77728fe26ed5a7b53985c"
    },
    {
        "@score": "1",
        "@id": "4144946",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "145/1806",
                        "text": "Nicholas Carlini"
                    },
                    {
                        "@pid": "149/2319",
                        "text": "Antonio Barresi"
                    },
                    {
                        "@pid": "31/1273",
                        "text": "Mathias Payer"
                    },
                    {
                        "@pid": "42/5626",
                        "text": "David A. Wagner 0001"
                    },
                    {
                        "@pid": "g/ThomasRGross",
                        "text": "Thomas R. Gross"
                    }
                ]
            },
            "title": "Control-Flow Bending: On the Effectiveness of Control-Flow Integrity.",
            "venue": "USENIX Security Symposium",
            "pages": "161-176",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/CarliniBPWG15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/carlini",
            "url": "https://dblp.org/rec/conf/uss/CarliniBPWG15",
            "abstract": "Control-Flow Integrity (CFI) is a defense which prevents control-flow hijacking attacks. While recent research has shown that coarse-grained CFI does not stop attacks, fine-grained CFI is believed to be secure. \n \nWe argue that assessing the effectiveness of practical CFI implementations is non-trivial and that common evaluation metrics fail to do so. We then evaluate fullyprecise static CFI -- the most restrictive CFI policy that does not break functionality -- and reveal limitations in its security. Using a generalization of non-control-data attacks which we call Control-Flow Bending (CFB), we show how an attacker can leverage a memory corruption vulnerability to achieve Turing-complete computation on memory using just calls to the standard library. We use this attack technique to evaluate fully-precise static CFI on six real binaries and show that in five out of six cases, powerful attacks are still possible. Our results suggest that CFI may not be a reliable defense against memory corruption vulnerabilities. \n \nWe further evaluate shadow stacks in combination with CFI and find that their presence for security is necessary: deploying shadow stacks removes arbitrary code execution capabilities of attackers in three of six cases.",
            "keywords": [
                "Control-Flow Integrity",
                "Memory Corruption",
                "Control-Flow Bending",
                "Static Analysis",
                "Shadow Stacks"
            ]
        },
        "url": "URL#4144946",
        "sema_paperId": "4841c7f17d293d56930039fe9fca6830acbb38b5"
    },
    {
        "@score": "1",
        "@id": "4144947",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "03/5287",
                        "text": "Jin Chen"
                    },
                    {
                        "@pid": "31/6601-1",
                        "text": "Haibo Chen 0001"
                    },
                    {
                        "@pid": "160/9772",
                        "text": "Erick Bauman"
                    },
                    {
                        "@pid": "49/4102",
                        "text": "Zhiqiang Lin"
                    },
                    {
                        "@pid": "86/680",
                        "text": "Binyu Zang"
                    },
                    {
                        "@pid": "96/5680",
                        "text": "Haibing Guan"
                    }
                ]
            },
            "title": "You Shouldn&apos;t Collect My Secrets: Thwarting Sensitive Keystroke Leakage in Mobile IME Apps.",
            "venue": "USENIX Security Symposium",
            "pages": "657-690",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ChenCBLZG15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/chen-jin",
            "url": "https://dblp.org/rec/conf/uss/ChenCBLZG15",
            "abstract": "IME (input method editor) apps are the primary means of interaction on mobile touch screen devices and thus are usually granted with access to a wealth of private user input. In order to understand the (in)security of mobile IME apps, this paper first performs a systematic study and uncovers that many IME apps may (intentionally or unintentionally) leak users' sensitive data to the outside world (mainly due to the incentives of improving the user's experience). To thwart the threat of sensitive information leakage while retaining the benefits of an improved user experience, this paper then proposes I-BOX, an app-transparent oblivious sandbox that minimizes sensitive input leakage by confining untrusted IME apps to predefined security policies. Several key challenges have to be addressed due to the proprietary and closed-source nature of most IME apps and the fact that an IME app can arbitrarily store and transform user input before sending it out. By designing system-level transactional execution, I-BOX works seamlessly and transparently with IME apps. Specifically, I-BOX first checkpoints an IME app's state before the first keystroke of an input, monitors and analyzes the user's input, and rolls back the state to the checkpoint if it detects the potential danger that sensitive input may be leaked. A proof of concept I-BOX prototype has been built for Android and tested with a set of popular IME apps. Experimental results show that I-BOX is able to thwart the leakage of sensitive input for untrusted IME apps, while incurring very small runtime overhead and little impact on user experience.",
            "keywords": [
                "Mobile IME Apps",
                "Sensitive Data Leakage",
                "Input Method Editor",
                "Oblivious Sandbox",
                "I-BOX Prototype"
            ]
        },
        "url": "URL#4144947",
        "sema_paperId": "1e4dda489becb84864cfc0caff0b1ec29cf6ab7a"
    },
    {
        "@score": "1",
        "@id": "4144948",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "24/1541",
                        "text": "Tien Tuan Anh Dinh"
                    },
                    {
                        "@pid": "90/105",
                        "text": "Prateek Saxena"
                    },
                    {
                        "@pid": "67/4662",
                        "text": "Ee-Chien Chang"
                    },
                    {
                        "@pid": "o/BengChinOoi",
                        "text": "Beng Chin Ooi"
                    },
                    {
                        "@pid": "117/6964",
                        "text": "Chunwang Zhang"
                    }
                ]
            },
            "title": "M2R: Enabling Stronger Privacy in MapReduce Computation.",
            "venue": "USENIX Security Symposium",
            "pages": "447-462",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DinhSCOZ15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/dinh",
            "url": "https://dblp.org/rec/conf/uss/DinhSCOZ15",
            "abstract": "New big-data analysis platforms can enable distributed computation on encrypted data by utilizing trusted computing primitives available in commodity server hardware. We study techniques for ensuring privacy-preserving computation in the popular MapReduce framework. In this paper, we first show that protecting only individual units of distributed computation (e.g. map and reduce units), as proposed in recent works, leaves several important channels of information leakage exposed to the adversary. Next, we analyze a variety of design choices in achieving a stronger notion of private execution that is the analogue of using a distributed oblivious-RAM (ORAM) across the platform. We develop a simple solution which avoids using the expensive ORAM construction, and incurs only an additive logarithmic factor of overhead to the latency. We implement our solution in a system called M2R, which enhances an existing Hadoop implementation, and evaluate it on seven standard MapReduce benchmarks. We show that it is easy to port most existing applications to M2R by changing fewer than 43 lines of code. M2R adds fewer than 500 lines of code to the TCB, which is less than 0.16% of the Hadoop codebase. M2R offers a factor of 1.3\u00d7 to 44.6\u00d7 lower overhead than extensions of previous solutions with equivalent privacy. M2R adds a total of 17% to 130% overhead over the insecure baseline solution that ignores the leakage channels M2R addresses.",
            "keywords": [
                "Privacy-Preserving Computation",
                "MapReduce Framework",
                "Distributed Computing",
                "Information Leakage",
                "M2R System"
            ]
        },
        "url": "URL#4144948",
        "sema_paperId": "1bb07c114cb447552d36a95445cc207f496d85aa"
    },
    {
        "@score": "1",
        "@id": "4144949",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "116/8359",
                        "text": "Kevin P. Dyer"
                    },
                    {
                        "@pid": "43/4410",
                        "text": "Scott E. Coull"
                    },
                    {
                        "@pid": "s/ThomasShrimpton",
                        "text": "Thomas Shrimpton"
                    }
                ]
            },
            "title": "Marionette: A Programmable Network Traffic Obfuscation System.",
            "venue": "USENIX Security Symposium",
            "pages": "367-382",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/DyerCS15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/dyer",
            "url": "https://dblp.org/rec/conf/uss/DyerCS15",
            "abstract": "Recently, a number of obfuscation systems have been developed to aid in censorship circumvention scenarios where encrypted network traffic is filtered. In this paper, we present Marionette, the first programmable network traffic obfuscation system capable of simultaneously controlling encrypted traffic features at a variety of levels, including ciphertext formats, stateful protocol semantics, and statistical properties. The behavior of the system is directed by a powerful type of probabilistic automata and specified in a user-friendly domain-specific language, which allows the user to easily adjust their obfuscation strategy to meet the unique needs of their network environment. In fact, the Marionette system is capable of emulating many existing obfuscation systems, and enables developers to explore a breadth of protocols and depth of traffic features that have, so far, been unattainable. We evaluate Marionette through a series of case studies inspired by censor capabilities demonstrated in the real-world and research literature, including passive network monitors, stateful proxies, and active probing. The results of our experiments not only show that Marionette provides outstanding flexibility and control over traffic features, but it is also capable of achieving throughput of up to 6.7Mbps when generating RFC-compliant cover traffic.",
            "keywords": [
                "Network Traffic Obfuscation",
                "Censorship Circumvention",
                "Programmable Systems",
                "Traffic Features Control",
                "Cover Traffic Generation"
            ]
        },
        "url": "URL#4144949",
        "sema_paperId": "d2e6106f7548d8736e7ce3a683de799f81e1d117"
    },
    {
        "@score": "1",
        "@id": "4144950",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "26/4437",
                        "text": "Adam Everspaugh"
                    },
                    {
                        "@pid": "03/9962",
                        "text": "Rahul Chatterjee 0001"
                    },
                    {
                        "@pid": "165/8373",
                        "text": "Samuel Scott"
                    },
                    {
                        "@pid": "j/AriJuels",
                        "text": "Ari Juels"
                    },
                    {
                        "@pid": "26/3399",
                        "text": "Thomas Ristenpart"
                    }
                ]
            },
            "title": "The Pythia PRF Service.",
            "venue": "USENIX Security Symposium",
            "pages": "547-562",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/EverspaughCSJR15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/everspaugh",
            "url": "https://dblp.org/rec/conf/uss/EverspaughCSJR15",
            "abstract": "Conventional cryptographic services such as hardware-security modules and software-based key-management systems offer the ability to apply a pseudorandom function (PRF) such as HMAC to inputs of a client's choosing. These services are used, for example, to harden stored password hashes against offline brute-force attacks. \n \nWe propose a modern PRF service called PYTHIA designed to offer a level of flexibility, security, and ease-of-deployability lacking in prior approaches. The keystone of PYTHIA is a new cryptographic primitive called a verifiable partially-oblivious PRF that reveals a portion of an input message to the service but hides the rest. We give a construction that additionally supports efficient bulk rotation of previously obtained PRF values to new keys. Performance measurements show that our construction, which relies on bilinear pairings and zero-knowledge proofs, is highly practical. We also give accompanying formal definitions and proofs of security. \n \nWe implement PYTHIA as a multi-tenant, scalable PRF service that can scale up to hundreds of millions of distinct client applications on commodity systems. In our prototype implementation, query latencies are 15 ms in local-area settings and throughput is within a factor of two of a standard HTTPS server. We further report on implementations of two applications using PYTHIA, showing how to bring its security benefits to a new enterprise password storage system and a new brainwallet system for Bitcoin.",
            "keywords": [
                "Pseudorandom Function",
                "Cryptographic Primitive",
                "Verifiable Partially-Oblivious PRF",
                "Password Storage Security",
                "Brainwallet System for Bitcoin"
            ]
        },
        "url": "URL#4144950",
        "sema_paperId": "a62ec2c86c53329f039bc9693758b91911396d81"
    },
    {
        "@score": "1",
        "@id": "4144951",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "97/535",
                        "text": "Kassem Fawaz"
                    },
                    {
                        "@pid": "153/5744",
                        "text": "Huan Feng"
                    },
                    {
                        "@pid": "s/KangGShin",
                        "text": "Kang G. Shin"
                    }
                ]
            },
            "title": "Anatomization and Protection of Mobile Apps&apos; Location Privacy Threats.",
            "venue": "USENIX Security Symposium",
            "pages": "753-768",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/FawazFS15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/fawaz",
            "url": "https://dblp.org/rec/conf/uss/FawazFS15",
            "abstract": "Mobile users are becoming increasingly aware of the privacy threats resulting from apps' access of their location. Few of the solutions proposed thus far to mitigate these threats have been deployed as they require either app or platform modifications. Mobile operating systems (OSes) also provide users with location access controls. In this paper, we analyze the efficacy of these controls in combating the location-privacy threats. For this analysis, we conducted the first location measurement campaign of its kind, analyzing more than 1000 free apps from Google Play and collecting detailed usage of location by more than 400 location-aware apps and 70 Advertisement and Analytics (A&A) libraries from more than 100 participants over a period ranging from 1 week to 1 year. Surprisingly, 70% of the apps and the A&A libraries pose considerable profiling threats even when they sporadically access the user's location. Existing OS controls are found ineffective and inefficient in mitigating these threats, thus calling for a finer-grained location access control. To meet this need, we propose LP-Doctor, a light-weight user-level tool that allows Android users to effectively utilize the OS's location access controls while maintaining the required app's functionality as our userstudy (with 227 participants) shows.",
            "keywords": [
                "Mobile App Privacy",
                "Location Access Control",
                "Location Privacy Threats",
                "User-Level Tool",
                "LP-Doctor"
            ]
        },
        "url": "URL#4144951",
        "sema_paperId": "db0cabda6a78c993b40be74e11a3ac890e406ac8"
    },
    {
        "@score": "1",
        "@id": "4144952",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "03/3113",
                        "text": "Seyed Kaveh Fayaz"
                    },
                    {
                        "@pid": "163/2206",
                        "text": "Yoshiaki Tobioka"
                    },
                    {
                        "@pid": "45/4044",
                        "text": "Vyas Sekar"
                    },
                    {
                        "@pid": "359/0958",
                        "text": "Michael D. Bailey"
                    }
                ]
            },
            "title": "Bohatei: Flexible and Elastic DDoS Defense.",
            "venue": "USENIX Security Symposium",
            "pages": "817-832",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/FayazTSB15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/fayaz",
            "url": "https://dblp.org/rec/conf/uss/FayazTSB15",
            "abstract": "DDoS defense today relies on expensive and proprietary hardware appliances deployed at fixed locations. This introduces key limitations with respect to flexibility (e.g., complex routing to get traffic to these \"chokepoints\") and elasticity in handling changing attack patterns. We observe an opportunity to address these limitations using new networking paradigms such as software-defined networking (SDN) and network functions virtualization (NFV). Based on this observation, we design and implement Bohatei, a flexible and elastic DDoS defense system. In designing Bohatei, we address key challenges with respect to scalability, responsiveness, and adversary-resilience. We have implemented defenses for several DDoS attacks using Bohatei. Our evaluations show that Bohatei is scalable (handling 500 Gbps attacks), responsive (mitigating attacks within one minute), and resilient to dynamic adversaries.",
            "keywords": [
                "DDoS Defense",
                "Software-Defined Networking",
                "Network Functions Virtualization",
                "Scalability",
                "Adversary-Resilience"
            ]
        },
        "url": "URL#4144952",
        "sema_paperId": "5ade210263cc57e4e8925b45036a60518ecf7ba5"
    },
    {
        "@score": "1",
        "@id": "4144953",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "123/3267",
                        "text": "Alessandro Di Federico"
                    },
                    {
                        "@pid": "167/0438",
                        "text": "Amat Cama"
                    },
                    {
                        "@pid": "119/7712",
                        "text": "Yan Shoshitaishvili"
                    },
                    {
                        "@pid": "k/ChristopherKruegel",
                        "text": "Christopher Kruegel"
                    },
                    {
                        "@pid": "v/GiovanniVigna",
                        "text": "Giovanni Vigna"
                    }
                ]
            },
            "title": "How the ELF Ruined Christmas.",
            "venue": "USENIX Security Symposium",
            "pages": "643-658",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/FedericoCSKV15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/di-frederico",
            "url": "https://dblp.org/rec/conf/uss/FedericoCSKV15",
            "abstract": "Throughout the last few decades, computer software has experienced an arms race between exploitation techniques leveraging memory corruption and detection/protection mechanisms. Effective mitigation techniques, such as Address Space Layout Randomization, have significantly increased the difficulty of successfully exploiting a vulnerability. A modern exploit is often two-stage: a first information disclosure step to identify the memory layout, and a second step with the actual exploit. However, because of the wide range of conditions under which memory corruption occurs, retrieving memory layout information from the program is not always possible. \n \nIn this paper, we present a technique that uses the dynamic loader's ability to identify the locations of critical functions directly and call them, without requiring an information leak. We identified several fundamental weak points in the design of ELF standard and dynamic loader implementations that can be exploited to resolve and execute arbitrary library functions. Through these, we are able to bypass specific security mitigation techniques, including partial and full RELRO, which are specifically designed to protect ELF data-structures from being coopted by attackers. We implemented a prototype tool, Leakless, and evaluated it against different dynamic loader implementations, previous attack techniques, and real-life case studies to determine the impact of our findings. Among other implications, Leakless provides attackers with reliable and non-invasive attacks, less likely to trigger intrusion detection systems.",
            "keywords": [
                "Memory Corruption",
                "Dynamic Loader",
                "ELF Exploitation",
                "Security Mitigation Techniques",
                "Leakless Tool"
            ]
        },
        "url": "URL#4144953",
        "sema_paperId": "f0f2d9e9fc761aa96a26422ae40b48f56c0acc76"
    },
    {
        "@score": "1",
        "@id": "4144954",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "153/5744",
                        "text": "Huan Feng"
                    },
                    {
                        "@pid": "97/535",
                        "text": "Kassem Fawaz"
                    },
                    {
                        "@pid": "s/KangGShin",
                        "text": "Kang G. Shin"
                    }
                ]
            },
            "title": "LinkDroid: Reducing Unregulated Aggregation of App Usage Behaviors.",
            "venue": "USENIX Security Symposium",
            "pages": "769-783",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/FengFS15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/feng",
            "url": "https://dblp.org/rec/conf/uss/FengFS15",
            "abstract": "Usage behaviors of different smartphone apps capture different views of an individual's life, and are largely independent of each other. However, in the current mobile app ecosystem, a curious party can covertly link and aggregate usage behaviors of the same user across different apps. We refer to this as unregulated aggregation of appusage behaviors. In this paper, we present a fresh perspective of unregulated aggregation, focusing on monitoring, characterizing and reducing the underlying linkability across apps. The cornerstone of our study is the Dynamic Linkability Graph (DLG) which tracks applevel linkability during runtime. We observed how DLG evolves on real-world users and identified real-world evidence of apps abusing IPCs and OS-level identifying information to establish linkability. Based on these observations, we propose a linkability-aware extension to current-mobile operating systems, called LinkDroid, which provides runtime monitoring and mediation of linkability across different apps. LinkDroid is a client-side solution and compatible with the existing smartphone ecosystem. It helps end-users \"sense\" this emerging threat and provides them intuitive opt-out options.",
            "keywords": [
                "Mobile App Privacy",
                "Linkability",
                "Dynamic Linkability Graph",
                "Unregulated Aggregation",
                "LinkDroid"
            ]
        },
        "url": "URL#4144954",
        "sema_paperId": "7d8b0f3ccbad763d0012bd4def6c5561bd43d23d"
    },
    {
        "@score": "1",
        "@id": "4144955",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "129/9491",
                        "text": "Christina Garman"
                    },
                    {
                        "@pid": "39/780",
                        "text": "Kenneth G. Paterson"
                    },
                    {
                        "@pid": "184/6051",
                        "text": "Thyla van der Merwe"
                    }
                ]
            },
            "title": "Attacks Only Get Better: Password Recovery Attacks Against RC4 in TLS.",
            "venue": "USENIX Security Symposium",
            "pages": "113-128",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GarmanPM15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/garman",
            "url": "https://dblp.org/rec/conf/uss/GarmanPM15",
            "abstract": "Despite recent high-profile attacks on the RC4 algorithm in TLS, its usage is still running at about 30% of all TLS traffic. We provide new attacks against RC4 in TLS that are focussed on recovering user passwords, still the pre-eminent means of user authentication on the Internet today. Our new attacks use a generally applicable Bayesian inference approach to transform a priori information about passwords in combination with gathered ciphertexts into a posteriori likelihoods for passwords. We report on extensive simulations of the attacks. We also report on a \"proof of concept\" implementation of the attacks for a specific application layer protocol, namely BasicAuth. Our work validates the truism that attacks only get better with time: we obtain good success rates in recovering user passwords with 226 encryptions, whereas the previous generation of attacks required around 234 encryptions to recover an HTTP session cookie.",
            "keywords": [
                "RC4",
                "TLS",
                "Password Recovery",
                "Bayesian Inference",
                "Ciphertext Analysis"
            ]
        },
        "url": "URL#4144955",
        "sema_paperId": "698a16014ca19866c247348e1f00af48d5b2acfe"
    },
    {
        "@score": "1",
        "@id": "4144956",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "123/3219",
                        "text": "Mariano Graziano"
                    },
                    {
                        "@pid": "42/9376",
                        "text": "Davide Canali"
                    },
                    {
                        "@pid": "15/6037",
                        "text": "Leyla Bilge"
                    },
                    {
                        "@pid": "33/2316",
                        "text": "Andrea Lanzi"
                    },
                    {
                        "@pid": "56/490",
                        "text": "Davide Balzarotti"
                    }
                ]
            },
            "title": "Needles in a Haystack: Mining Information from Public Dynamic Analysis Sandboxes for Malware Intelligence.",
            "venue": "USENIX Security Symposium",
            "pages": "1057-1072",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GrazianoCBLB15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/graziano",
            "url": "https://dblp.org/rec/conf/uss/GrazianoCBLB15",
            "abstract": "Malware sandboxes are automated dynamic analysis systems that execute programs in a controlled environment. Within the large volumes of samples submitted every day to these services, some submissions appear to be different from others, and show interesting characteristics. For example, we observed that malware samples involved in famous targeted attacks - like the Regin APT framework or the recently disclosed malwares from the Equation Group - were submitted to our sandbox months or even years before they were detected in the wild. In other cases, the malware developers themselves interact with public sandboxes to test their creations or to develop a new evasion technique. We refer to similar cases as malware developments. \n \nIn this paper, we propose a novel methodology to automatically identify malware development cases from the samples submitted to a malware analysis sandbox. The results of our experiments show that, by combining dynamic and static analysis with features based on the file submission, it is possible to achieve a good accuracy in automatically identifying cases of malware development. Our goal is to raise awareness on this problem and on the importance of looking at these samples from an intelligence and threat prevention point of view.",
            "keywords": [
                "Malware Analysis",
                "Dynamic Analysis Sandboxes",
                "Malware Development",
                "Threat Intelligence",
                "Evasion Techniques"
            ]
        },
        "url": "URL#4144956",
        "sema_paperId": "e33f910829939417e6273e0e5e6b26887f6e1ce1"
    },
    {
        "@score": "1",
        "@id": "4144957",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "166/1494",
                        "text": "Daniel Gruss"
                    },
                    {
                        "@pid": "128/5169",
                        "text": "Raphael Spreitzer"
                    },
                    {
                        "@pid": "91/4831",
                        "text": "Stefan Mangard"
                    }
                ]
            },
            "title": "Cache Template Attacks: Automating Attacks on Inclusive Last-Level Caches.",
            "venue": "USENIX Security Symposium",
            "pages": "897-912",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GrussSM15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/gruss",
            "url": "https://dblp.org/rec/conf/uss/GrussSM15",
            "abstract": "Recent work on cache attacks has shown that CPU caches represent a powerful source of information leakage. However, existing attacks require manual identification of vulnerabilities, i.e., data accesses or instruction execution depending on secret information. In this paper, we present Cache Template Attacks. This generic attack technique allows us to profile and exploit cache-based information leakage of any program automatically, without prior knowledge of specific software versions or even specific system information. Cache Template Attacks can be executed online on a remote system without any prior offline computations or measurements. \n \nCache Template Attacks consist of two phases. In the profiling phase, we determine dependencies between the processing of secret information, e.g., specific key inputs or private keys of cryptographic primitives, and specific cache accesses. In the exploitation phase, we derive the secret values based on observed cache accesses. We illustrate the power of the presented approach in several attacks, but also in a useful application for developers. Among the presented attacks is the application of Cache Template Attacks to infer keystrokes and--even more severe--the identification of specific keys on Linux and Windows user interfaces. More specifically, for lowercase only passwords, we can reduce the entropy per character from log2(26) = 4.7 to 1.4 bits on Linux systems. Furthermore, we perform an automated attack on the T-table-based AES implementation of OpenSSL that is as efficient as state-of-the-art manual cache attacks.",
            "keywords": [
                "Cache Attacks",
                "Information Leakage",
                "Inclusive Last-Level Caches",
                "Keystroke Inference",
                "Automated Exploitation"
            ]
        },
        "url": "URL#4144957",
        "sema_paperId": "70fb3cea8335aefdf849597e9d9dd7512d722d88"
    },
    {
        "@score": "1",
        "@id": "4144958",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "133/4693",
                        "text": "Mordechai Guri"
                    },
                    {
                        "@pid": "154/6452",
                        "text": "Assaf Kachlon"
                    },
                    {
                        "@pid": "167/0414",
                        "text": "Ofer Hasson"
                    },
                    {
                        "@pid": "37/9075",
                        "text": "Gabi Kedma"
                    },
                    {
                        "@pid": "160/6851",
                        "text": "Yisroel Mirsky"
                    },
                    {
                        "@pid": "38/4086",
                        "text": "Yuval Elovici"
                    }
                ]
            },
            "title": "GSMem: Data Exfiltration from Air-Gapped Computers over GSM Frequencies.",
            "venue": "USENIX Security Symposium",
            "pages": "849-864",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/GuriKHKME15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/guri",
            "url": "https://dblp.org/rec/conf/uss/GuriKHKME15",
            "abstract": "Air-gapped networks are isolated, separated both logically and physically from public networks. Although the feasibility of invading such systems has been demonstrated in recent years, exfiltration of data from air-gapped networks is still a challenging task. In this paper we present GSMem, a malware that can exfiltrate data through an air-gap over cellular frequencies. Rogue software on an infected target computer modulates and transmits electromagnetic signals at cellular frequencies by invoking specific memory-related instructions and utilizing the multichannel memory architecture to amplify the transmission. Furthermore, we show that the transmitted signals can be received and demodulated by a rootkit placed in the baseband firmware of a nearby cellular phone. We present crucial design issues such as signal generation and reception, data modulation, and transmission detection. We implement a prototype of GSMem consisting of a transmitter and a receiver and evaluate its performance and limitations. Our current results demonstrate its efficacy and feasibility, achieving an effective transmission distance of 1 - 5.5 meters with a standard mobile phone. When using a dedicated, yet affordable hardware receiver, the effective distance reached over 30 meters.",
            "keywords": [
                "Air-Gapped Networks",
                "Data Exfiltration",
                "GSM Frequencies",
                "Malware Transmission",
                "Signal Modulation"
            ]
        },
        "url": "URL#4144958",
        "sema_paperId": "9610afd9c8f3d97b4b952b2e34ab8d0482739939"
    },
    {
        "@score": "1",
        "@id": "4144959",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "42/10309",
                        "text": "Ethan Heilman"
                    },
                    {
                        "@pid": "161/6298",
                        "text": "Alison Kendler"
                    },
                    {
                        "@pid": "92/4269",
                        "text": "Aviv Zohar"
                    },
                    {
                        "@pid": "87/2320",
                        "text": "Sharon Goldberg"
                    }
                ]
            },
            "title": "Eclipse Attacks on Bitcoin&apos;s Peer-to-Peer Network.",
            "venue": "USENIX Security Symposium",
            "pages": "129-144",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HeilmanKZG15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/heilman",
            "url": "https://dblp.org/rec/conf/uss/HeilmanKZG15",
            "abstract": "We present eclipse attacks on bitcoin's peer-to-peer network. Our attack allows an adversary controlling a sufficient number of IP addresses to monopolize all connections to and from a victim bitcoin node. The attacker can then exploit the victim for attacks on bitcoin's mining and consensus system, including N-confirmation double spending, selfish mining, and adversarial forks in the blockchain. We take a detailed look at bitcoin's peer-to-peer network, and quantify the resources involved in our attack via probabilistic analysis, Monte Carlo simulations, measurements and experiments with live bitcoin nodes. Finally, we present countermeasures, inspired by botnet architectures, that are designed to raise the bar for eclipse attacks while preserving the openness and decentralization of bitcoin's current network architecture.",
            "keywords": [
                "Bitcoin Network",
                "Eclipse Attacks",
                "Peer-to-Peer Network",
                "Consensus Mechanism",
                "Double Spending"
            ]
        },
        "url": "URL#4144959",
        "sema_paperId": "4cf86ff3f5231cf499f9d9b0e23fa17f296182b3"
    },
    {
        "@score": "1",
        "@id": "4144960",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "70/2543-4",
                        "text": "Hong Hu 0004"
                    },
                    {
                        "@pid": "150/5333",
                        "text": "Zheng Leong Chua"
                    },
                    {
                        "@pid": "167/0585",
                        "text": "Sendroiu Adrian"
                    },
                    {
                        "@pid": "90/105",
                        "text": "Prateek Saxena"
                    },
                    {
                        "@pid": "99/4951",
                        "text": "Zhenkai Liang"
                    }
                ]
            },
            "title": "Automatic Generation of Data-Oriented Exploits.",
            "venue": "USENIX Security Symposium",
            "pages": "177-192",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HuCASL15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/hu",
            "url": "https://dblp.org/rec/conf/uss/HuCASL15",
            "abstract": "As defense solutions against control-flow hijacking attacks gain wide deployment, control-oriented exploits from memory errors become difficult. As an alternative, attacks targeting non-control data do not require diverting the application's control flow during an attack. Although it is known that such data-oriented attacks can mount significant damage, no systematic methods to automatically construct them from memory errors have been developed. In this work, we develop a new technique called data-flow stitching, which systematically finds ways to join data flows in the program to generate data-oriented exploits. We build a prototype embodying our technique in a tool called FLOWSTITCH that works directly on Windows and Linux binaries. In our experiments, we find that FLOWSTITCH automatically constructs 16 previously unknown and three known data-oriented attacks from eight real-world vulnerable programs. All the automatically-crafted exploits respect fine-grained CFI and DEP constraints, and 10 out of the 19 exploits work with standard ASLR defenses enabled. The constructed exploits can cause significant damage, such as disclosure of sensitive information (e.g., passwords and encryption keys) and escalation of privilege.",
            "keywords": [
                "Data-Oriented Exploits",
                "Control-Flow Hijacking",
                "Memory Errors",
                "Data-Flow Stitching",
                "Automated Exploit Generation"
            ]
        },
        "url": "URL#4144960",
        "sema_paperId": "3c1e1428365d6a2229589a07bebbb82dfff23516"
    },
    {
        "@score": "1",
        "@id": "4144961",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "41/2181-1",
                        "text": "Jianjun Huang 0001"
                    },
                    {
                        "@pid": "55/4022",
                        "text": "Zhichun Li"
                    },
                    {
                        "@pid": "13/9656",
                        "text": "Xusheng Xiao"
                    },
                    {
                        "@pid": "87/6581-3",
                        "text": "Zhenyu Wu 0003"
                    },
                    {
                        "@pid": "67/10639",
                        "text": "Kangjie Lu"
                    },
                    {
                        "@pid": "95/3760-1",
                        "text": "Xiangyu Zhang 0001"
                    },
                    {
                        "@pid": "47/4422",
                        "text": "Guofei Jiang"
                    }
                ]
            },
            "title": "SUPOR: Precise and Scalable Sensitive User Input Detection for Android Apps.",
            "venue": "USENIX Security Symposium",
            "pages": "977-992",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/HuangLXWLZJ15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/huang",
            "url": "https://dblp.org/rec/conf/uss/HuangLXWLZJ15",
            "abstract": "While smartphones and mobile apps have been an essential part of our lives, privacy is a serious concern. Previous mobile privacy related research efforts have largely focused on predefined known sources managed by smartphones. Sensitive user inputs through UI (User Interface), another information source that may contain a lot of sensitive information, have been mostly neglected. \n \nIn this paper, we examine the possibility of scalably detecting sensitive user inputs from mobile apps. In particular, we design and implement SUPOR, a novel static analysis tool that automatically examines the UIs to identify sensitive user inputs containing critical user data, such as user credentials, finance, and medical data. SUPOR enables existing privacy analysis approaches to be applied on sensitive user inputs as well. To demonstrate the usefulness of SUPOR, we build a system that detects privacy disclosures of sensitive user inputs by combining SUPOR with off-the-shelf static taint analysis We apply the system to 16,000 popular Android apps, and conduct a measurement study on the privacy disclosures. SUPOR achieves an average precision of 97.3% and an average recall of 97.3% for sensitive user input identification. SUPOR finds 355 apps with privacy disclosures and the false positive rate is 8.7%. We discover interesting cases related to national ID, username/password, credit card and health information.",
            "keywords": [
                "Mobile Privacy",
                "Sensitive User Inputs",
                "Static Analysis",
                "Privacy Disclosures",
                "Android Apps"
            ]
        },
        "url": "URL#4144961",
        "sema_paperId": "e9e4c8b161172afad35170ca6e0e3379155d4cb8"
    },
    {
        "@score": "1",
        "@id": "4144962",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "116/4680",
                        "text": "Aylin Caliskan Islam"
                    },
                    {
                        "@pid": "119/2618",
                        "text": "Richard E. Harang"
                    },
                    {
                        "@pid": "21/501",
                        "text": "Andrew Liu"
                    },
                    {
                        "@pid": "08/3080",
                        "text": "Arvind Narayanan"
                    },
                    {
                        "@pid": "41/3792",
                        "text": "Clare R. Voss"
                    },
                    {
                        "@pid": "66/11094",
                        "text": "Fabian Yamaguchi"
                    },
                    {
                        "@pid": "93/655",
                        "text": "Rachel Greenstadt"
                    }
                ]
            },
            "title": "De-anonymizing Programmers via Code Stylometry.",
            "venue": "USENIX Security Symposium",
            "pages": "255-270",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/IslamHLNVYG15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/caliskan-islam",
            "url": "https://dblp.org/rec/conf/uss/IslamHLNVYG15",
            "abstract": "Source code authorship attribution is a significant privacy threat to anonymous code contributors. However, it may also enable attribution of successful attacks from code left behind on an infected system, or aid in resolving copyright, copyleft, and plagiarism issues in the programming fields. In this work, we investigate machine learning methods to de-anonymize source code authors of C/C++ using coding style. Our Code Stylometry Feature Set is a novel representation of coding style found in source code that reflects coding style from properties derived from abstract syntax trees. \n \nOur random forest and abstract syntax tree-based approach attributes more authors (1,600 and 250) with significantly higher accuracy (94% and 98%) on a larger data set (Google Code Jam) than has been previously achieved. Furthermore, these novel features are robust, difficult to obfuscate, and can be used in other programming languages, such as Python. We also find that (i) the code resulting from difficult programming tasks is easier to attribute than easier tasks and (ii) skilled programmers (who can complete the more difficult tasks) are easier to attribute than less skilled programmers.",
            "keywords": [
                "Code Authorship Attribution",
                "Code Stylometry",
                "C/C++ Programming",
                "Machine Learning Methods",
                "Programming Skill Attribution"
            ]
        },
        "url": "URL#4144962",
        "sema_paperId": "a70d55a840866b7d0bb7d0644b71c27bab5aac1b"
    },
    {
        "@score": "1",
        "@id": "4144963",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "165/5508",
                        "text": "Nav Jagpal"
                    },
                    {
                        "@pid": "167/0405",
                        "text": "Eric Dingle"
                    },
                    {
                        "@pid": "167/0518",
                        "text": "Jean-Philippe Gravel"
                    },
                    {
                        "@pid": "94/2405",
                        "text": "Panayiotis Mavrommatis"
                    },
                    {
                        "@pid": "90/6745",
                        "text": "Niels Provos"
                    },
                    {
                        "@pid": "25/3948",
                        "text": "Moheeb Abu Rajab"
                    },
                    {
                        "@pid": "68/8283",
                        "text": "Kurt Thomas"
                    }
                ]
            },
            "title": "Trends and Lessons from Three Years Fighting Malicious Extensions.",
            "venue": "USENIX Security Symposium",
            "pages": "579-593",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/JagpalDGMPRT15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/jagpal",
            "url": "https://dblp.org/rec/conf/uss/JagpalDGMPRT15",
            "abstract": "In this work we expose wide-spread efforts by criminals to abuse the Chrome Web Store as a platform for distributing malicious extensions. A central component of our study is the design and implementation of WebEval, the first system that broadly identifies malicious extensions with a concrete, measurable detection rate of 96.5%. Over the last three years we detected 9,523 malicious extensions: nearly 10% of every extension submitted to the store. Despite a short window of operation--we removed 50% of malware within 25 minutes of creation--a handful of under 100 extensions escaped immediate detection and infected over 50 million Chrome users. Our results highlight that the extension abuse ecosystem is drastically different from malicious binaries: miscreants profit from web traffic and user tracking rather than email spam or banking theft.",
            "keywords": [
                "Malicious Extensions",
                "Chrome Web Store",
                "Web Traffic Abuse",
                "User Tracking",
                "Malware Detection"
            ]
        },
        "url": "URL#4144963",
        "sema_paperId": "c1f4f5347645ae93728ff76a76034c78c16a82ea"
    },
    {
        "@score": "1",
        "@id": "4144964",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "07/8388",
                        "text": "Shouling Ji"
                    },
                    {
                        "@pid": "15/3702",
                        "text": "Weiqing Li"
                    },
                    {
                        "@pid": "39/6266",
                        "text": "Prateek Mittal"
                    },
                    {
                        "@pid": "13/6380-1",
                        "text": "Xin Hu 0001"
                    },
                    {
                        "@pid": "12/6354",
                        "text": "Raheem A. Beyah"
                    }
                ]
            },
            "title": "SecGraph: A Uniform and Open-source Evaluation System for Graph Data Anonymization and De-anonymization.",
            "venue": "USENIX Security Symposium",
            "pages": "303-318",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/JiLMHB15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/ji",
            "url": "https://dblp.org/rec/conf/uss/JiLMHB15",
            "abstract": "In this paper, we analyze and systematize the state-of-the-art graph data privacy and utility techniques. Specifically, we propose and develop SecGraph (available at [1]), a uniform and open-source Secure Graph data sharing/publishing system. In SecGraph, we systematically study, implement, and evaluate 11 graph data anonymization algorithms, 19 data utility metrics, and 15 modern Structure-based De-Anonymization (SDA) attacks. To the best of our knowledge, SecGraph is the first such system that enables data owners to anonymize data by state-of-the-art anonymization techniques, measure the data's utility, and evaluate the data's vulnerability against modern De-Anonymization (DA) attacks. In addition, SecGraph enables researchers to conduct fair analysis and evaluation of existing and newly developed anonymization/DA techniques. Leveraging SecGraph, we conduct extensive experiments to systematically evaluate the existing graph data anonymization and DA techniques. The results demonstrate that (i) most anonymization schemes can partially or conditionally preserve most graph utilities while losing some application utility; (ii) no DA attack is optimum in all scenarios. The DA performance depends on several factors, e.g., similarity between anonymized and auxiliary data, graph density, and DA heuristics; and (iii) all the state-of-the-art anonymization schemes are vulnerable to several or all of the modern SDA attacks. The degree of vulnerability of each anonymization scheme depends on how much and which data utility it preserves.",
            "keywords": [
                "Graph Data Privacy",
                "Data Anonymization",
                "De-Anonymization Attacks",
                "Data Utility Metrics",
                "Secure Graph Sharing"
            ]
        },
        "url": "URL#4144964",
        "sema_paperId": "8818a218e04fd4f0a88d7799cb651576ad4aed0c"
    },
    {
        "@score": "1",
        "@id": "4144965",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "167/0508",
                        "text": "David Kaloper-Mersinjak"
                    },
                    {
                        "@pid": "09/9538",
                        "text": "Hannes Mehnert"
                    },
                    {
                        "@pid": "32/1528",
                        "text": "Anil Madhavapeddy"
                    },
                    {
                        "@pid": "74/185",
                        "text": "Peter Sewell"
                    }
                ]
            },
            "title": "Not-Quite-So-Broken TLS: Lessons in Re-Engineering a Security Protocol Specification and Implementation.",
            "venue": "USENIX Security Symposium",
            "pages": "223-238",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Kaloper-Mersinjak15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/kaloper-mersinjak",
            "url": "https://dblp.org/rec/conf/uss/Kaloper-Mersinjak15",
            "abstract": "Transport Layer Security (TLS) implementations have a history of security flaws. The immediate causes of these are often programming errors, e.g. in memory management, but the root causes are more fundamental: the challenges of interpreting the ambiguous prose specification, the complexities inherent in large APIs and code bases, inherently unsafe programming choices, and the impossibility of directly testing conformance between implementations and the specification. \n \nWe present nqsb-TLS, the result of our re-engineered approach to security protocol specification and implementation that addresses these root causes. The same code serves two roles: it is both a specification of TLS, executable as a test oracle to check conformance of traces from arbitrary implementations, and a usable implementation of TLS; a modular and declarative programming style provides clean separation between its components. Many security flaws are thus excluded by construction. \n \nnqsb-TLS can be used in standalone Unix applications, which we demonstrate with a messaging client, and can also be compiled into Xen unikernels (specialised virtual machine image) with a trusted computing base (TCB) that is 4% of a standalone system running a standard Linux/OpenSSL stack, with all network traffic being handled in a memory-safe language; this supports applications including HTTPS, IMAP, Git, and Websocket clients and servers. Despite the dual-role design, the high-level implementation style, and the functional programming language we still achieve reasonable performance, with the same handshake performance as OpenSSL and 73% - 84% for bulk throughput.",
            "keywords": [
                "Transport Layer Security (TLS)",
                "Security Protocols",
                "Re-engineering",
                "Conformance Testing",
                "Memory Safety"
            ]
        },
        "url": "URL#4144965",
        "sema_paperId": "26ed1e7726ba8fb295847dbba1b012ce3a5604a9"
    },
    {
        "@score": "1",
        "@id": "4144966",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "140/6542",
                        "text": "Nikolaos Karapanos"
                    },
                    {
                        "@pid": "11/9829",
                        "text": "Claudio Marforio"
                    },
                    {
                        "@pid": "57/1338",
                        "text": "Claudio Soriente"
                    },
                    {
                        "@pid": "51/1639",
                        "text": "Srdjan Capkun"
                    }
                ]
            },
            "title": "Sound-Proof: Usable Two-Factor Authentication Based on Ambient Sound.",
            "venue": "USENIX Security Symposium",
            "pages": "483-498",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KarapanosMSC15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/karapanos",
            "url": "https://dblp.org/rec/conf/uss/KarapanosMSC15",
            "abstract": "Two-factor authentication protects online accounts even if passwords are leaked. Most users, however, prefer password-only authentication. One reason why two-factor authentication is so unpopular is the extra steps that the user must complete in order to log in. Currently deployed two-factor authentication mechanisms require the user to interact with his phone to, for example, copy a verification code to the browser. Two-factor authentication schemes that eliminate user-phone interaction exist, but require additional software to be deployed. \n \nIn this paper we propose Sound-Proof, a usable and deployable two-factor authentication mechanism. Sound-Proof does not require interaction between the user and his phone. In Sound-Proof the second authentication factor is the proximity of the user's phone to the device being used to log in. The proximity of the two devices is verified by comparing the ambient noise recorded by their microphones. Audio recording and comparison are transparent to the user, so that the user experience is similar to the one of password-only authentication. Sound-Proof can be easily deployed as it works with current phones and major browsers without plugins. We build a prototype for both Android and iOS. We provide empirical evidence that ambient noise is a robust discriminant to determine the proximity of two devices both indoors and outdoors, and even if the phone is in a pocket or purse. We conduct a user study designed to compare the perceived usability of Sound-Proof with Google 2-Step Verification. Participants ranked Sound-Proof as more usable and the majority would be willing to use Sound-Proof even for scenarios in which two-factor authentication is optional.",
            "keywords": [
                "Two-Factor Authentication",
                "Usability",
                "Ambient Sound",
                "Proximity Verification",
                "User Experience"
            ]
        },
        "url": "URL#4144966",
        "sema_paperId": "5de8d36639ca5ee7b380466317bddbafceb9c1ff"
    },
    {
        "@score": "1",
        "@id": "4144967",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "17/1201",
                        "text": "Albert Kwon"
                    },
                    {
                        "@pid": "213/7971",
                        "text": "Mashael AlSabah"
                    },
                    {
                        "@pid": "117/9944",
                        "text": "David Lazar"
                    },
                    {
                        "@pid": "76/5806",
                        "text": "Marc Dacier"
                    },
                    {
                        "@pid": "14/3973",
                        "text": "Srinivas Devadas"
                    }
                ]
            },
            "title": "Circuit Fingerprinting Attacks: Passive Deanonymization of Tor Hidden Services.",
            "venue": "USENIX Security Symposium",
            "pages": "287-302",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/KwonALDD15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/kwon",
            "url": "https://dblp.org/rec/conf/uss/KwonALDD15",
            "abstract": "This paper sheds light on crucial weaknesses in the design of hidden services that allow us to break the anonymity of hidden service clients and operators passively. In particular, we show that the circuits, paths established through the Tor network, used to communicate with hidden services exhibit a very different behavior compared to a general circuit. We propose two attacks, under two slightly different threat models, that could identify a hidden service client or operator using these weaknesses. We found that we can identify the users' involvement with hidden services with more than 98% true positive rate and less than 0.1% false positive rate with the first attack, and 99% true positive rate and 0.07% false positive rate with the second. We then revisit the threat model of previous website fingerprinting attacks, and show that previous results are directly applicable, with greater efficiency, in the realm of hidden services. Indeed, we show that we can correctly determine which of the 50 monitored pages the client is visiting with 88% true positive rate and false positive rate as low as 2.9%, and correctly deanonymize 50 monitored hidden service servers with true positive rate of 88% and false positive rate of 7.8% in an open world setting.",
            "keywords": [
                "Tor Network",
                "Hidden Services",
                "Anonymity",
                "Circuit Fingerprinting",
                "Deanonymization Attacks"
            ]
        },
        "url": "URL#4144967",
        "sema_paperId": "fb4cb1f1c57ee56e9a014570debf7d3d6871ddf3"
    },
    {
        "@score": "1",
        "@id": "4144968",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "45/7986",
                        "text": "Byoungyoung Lee"
                    },
                    {
                        "@pid": "69/6818",
                        "text": "Chengyu Song"
                    },
                    {
                        "@pid": "38/8882",
                        "text": "Taesoo Kim"
                    },
                    {
                        "@pid": "29/5976",
                        "text": "Wenke Lee"
                    }
                ]
            },
            "title": "Type Casting Verification: Stopping an Emerging Attack Vector.",
            "venue": "USENIX Security Symposium",
            "pages": "81-96",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LeeSKL15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/lee",
            "url": "https://dblp.org/rec/conf/uss/LeeSKL15",
            "abstract": "Many applications such as the Chrome and Firefox browsers are largely implemented in C++ for its performance and modularity. Type casting, which converts one type of an object to another, plays an essential role in enabling polymorphism in C++ because it allows a program to utilize certain general or specific implementations in the class hierarchies. However, if not correctly used, it may return unsafe and incorrectly casted values, leading to so-called bad-casting or type-confusion vulnerabilities. Since a bad-casted pointer violates a programmer's intended pointer semantics and enables an attacker to corrupt memory, bad-casting has critical security implications similar to those of other memory corruption vulnerabilities. Despite the increasing number of bad-casting vulnerabilities, the bad-casting detection problem has not been addressed by the security community. \n \nIn this paper, we present CAVER, a runtime bad-casting detection tool. It performs program instrumentation at compile time and uses a new runtime type tracing mechanism--the type hierarchy table--to overcome the limitation of existing approaches and efficiently verify type casting dynamically. In particular, CAVER can be easily and automatically adopted to target applications, achieves broader detection coverage, and incurs reasonable runtime overhead. We have applied CAVER to large-scale software including Chrome and Firefox browsers, and discovered 11 previously unknown security vulnerabilities: nine in GNU libstdc++ and two in Firefox, all of which have been confirmed and subsequently fixed by vendors. Our evaluation showed that CAVER imposes up to 7.6% and 64.6% overhead for performance-intensive benchmarks on the Chromium and Firefox browsers, respectively.",
            "keywords": [
                "C++ Security",
                "Type Casting",
                "Bad-Casting Vulnerabilities",
                "Runtime Type Tracing",
                "Memory Corruption"
            ]
        },
        "url": "URL#4144968",
        "sema_paperId": "c68aa444565e10897b21e33a67e4643a322a2bfa"
    },
    {
        "@score": "1",
        "@id": "4144969",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "43/9795",
                        "text": "Sebastian Lekies"
                    },
                    {
                        "@pid": "136/8343",
                        "text": "Ben Stock"
                    },
                    {
                        "@pid": "167/0532",
                        "text": "Martin Wentzel"
                    },
                    {
                        "@pid": "82/359",
                        "text": "Martin Johns"
                    }
                ]
            },
            "title": "The Unexpected Dangers of Dynamic JavaScript.",
            "venue": "USENIX Security Symposium",
            "pages": "723-735",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LekiesSWJ15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/lekies",
            "url": "https://dblp.org/rec/conf/uss/LekiesSWJ15",
            "abstract": "Modern Web sites frequently generate JavaScript on-the-fly via server-side scripting, incorporating personalized user data in the process. In general, cross-domain access to such sensitive resources is prevented by the Same-Origin Policy. The inclusion of remote scripts via the HTML script tag, however, is exempt from this policy. This exemption allows an adversary to import and execute dynamically generated scripts while a user visits an attacker-controlled Web site. By observing the execution behavior and the side effects the inclusion of the dynamic script causes, the attacker is able to leak private user data leading to severe consequences ranging from privacy violations up to full compromise of user accounts. \n \nAlthough this issues has been known for several years under the term Cross-Site Script Inclusion, it has not been analyzed in-depth on the Web. Therefore, to systematically investigate the issue, we conduct a study on its prevalence in a set of 150 top-ranked domains. We observe that a third of the surveyed sites utilize dynamic JavaScript. After evaluating the effectiveness of the deployed countermeasures, we show that more than 80% of the sites are susceptible to attacks via remote script inclusion. Given the results of our study, we provide a secure and functionally equivalent alternative to the use of dynamic scripts.",
            "keywords": [
                "Dynamic JavaScript",
                "Cross-Site Script Inclusion",
                "Remote Script Inclusion",
                "User Data Leakage",
                "Web Application Vulnerabilities"
            ]
        },
        "url": "URL#4144969",
        "sema_paperId": "bdb77b1357b39511213d910a00a398d734873df0"
    },
    {
        "@score": "1",
        "@id": "4144970",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "51/3710-18",
                        "text": "Yang Liu 0018"
                    },
                    {
                        "@pid": "151/8748",
                        "text": "Armin Sarabi"
                    },
                    {
                        "@pid": "05/3499-27",
                        "text": "Jing Zhang 0027"
                    },
                    {
                        "@pid": "122/6031",
                        "text": "Parinaz Naghizadeh"
                    },
                    {
                        "@pid": "17/164",
                        "text": "Manish Karir"
                    },
                    {
                        "@pid": "359/0958",
                        "text": "Michael D. Bailey"
                    },
                    {
                        "@pid": "97/5725",
                        "text": "Mingyan Liu"
                    }
                ]
            },
            "title": "Cloudy with a Chance of Breach: Forecasting Cyber Security Incidents.",
            "venue": "USENIX Security Symposium",
            "pages": "1009-1024",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/LiuSZNKBL15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/liu",
            "url": "https://dblp.org/rec/conf/uss/LiuSZNKBL15",
            "abstract": "In this study we characterize the extent to which cyber security incidents, such as those referenced by Verizon in its annual Data Breach Investigations Reports (DBIR), can be predicted based on externally observable properties of an organization's network. We seek to proactively forecast an organization's breaches and to do so without cooperation of the organization itself. To accomplish this goal, we collect 258 externally measurable features about an organization's network from two main categories: mismanagement symptoms, such as misconfigured DNS or BGP within a network, and malicious activity time series, which include spam, phishing, and scanning activity sourced from these organizations. Using these features we train and test a Random Forest (RF) classifier against more than 1,000 incident reports taken from the VERIS community database, Hackmageddon, and the Web Hacking Incidents Database that cover events from mid-2013 to the end of 2014. The resulting classifier is able to achieve a 90% True Positive (TP) rate, a 10% False Positive (FP) rate, and an overall 90% accuracy.",
            "keywords": [
                "Cyber Security Forecasting",
                "Data Breach Prediction",
                "Network Mismanagement",
                "Malicious Activity Analysis",
                "Random Forest Classifier"
            ]
        },
        "url": "URL#4144970",
        "sema_paperId": "0530678bcb59d49ba27aea3304768db4f2e3ef77"
    },
    {
        "@score": "1",
        "@id": "4144971",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "19/10639",
                        "text": "Ramya Jayaram Masti"
                    },
                    {
                        "@pid": "87/7837",
                        "text": "Devendra Rai"
                    },
                    {
                        "@pid": "23/11190",
                        "text": "Aanjhan Ranganathan"
                    },
                    {
                        "@pid": "50/5380",
                        "text": "Christian M\u00fcller"
                    },
                    {
                        "@pid": "t/LotharThiele",
                        "text": "Lothar Thiele"
                    },
                    {
                        "@pid": "51/1639",
                        "text": "Srdjan Capkun"
                    }
                ]
            },
            "title": "Thermal Covert Channels on Multi-core Platforms.",
            "venue": "USENIX Security Symposium",
            "pages": "865-880",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MastiRRMTC15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/masti",
            "url": "https://dblp.org/rec/conf/uss/MastiRRMTC15",
            "abstract": "Side channels remain a challenge to information flow control and security in modern computing platforms. Resource partitioning techniques that minimise the number of shared resources among processes are often used to address this challenge. In this work, we focus on multicore platforms and we demonstrate that even seemingly strong isolation techniques based on dedicated cores can be circumvented through the use of thermal channels. Specifically, we show that the processor core temperature can be used both as a side channel as well as a covert communication channel even when the system implements strong spatial and temporal partitioning. Our experiments on an Intel Xeon server platform demonstrate covert thermal channels that achieve up to 12.5 bps and weak thermal side channels that can detect processes executed on neighbouring cores. This work therefore shows a limitation in the isolation that can be achieved on existing multi-core systems.",
            "keywords": [
                "Thermal Covert Channels",
                "Multi-core Platforms",
                "Side Channels",
                "Resource Partitioning",
                "Thermal Communication"
            ]
        },
        "url": "URL#4144971",
        "sema_paperId": "5a0938f659cbd268f5ede4885c8f72cb1313926e"
    },
    {
        "@score": "1",
        "@id": "4144972",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "130/0483",
                        "text": "Susan E. McGregor"
                    },
                    {
                        "@pid": "141/9433",
                        "text": "Polina Charters"
                    },
                    {
                        "@pid": "167/0481",
                        "text": "Tobin Holliday"
                    },
                    {
                        "@pid": "23/2758",
                        "text": "Franziska Roesner"
                    }
                ]
            },
            "title": "Investigating the Computer Security Practices and Needs of Journalists.",
            "venue": "USENIX Security Symposium",
            "pages": "399-414",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/McGregorCHR15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/mcgregor",
            "url": "https://dblp.org/rec/conf/uss/McGregorCHR15",
            "abstract": "Though journalists are often cited as potential users of computer security technologies, their practices and mental models have not been deeply studied by the academic computer security community. Such an understanding, however, is critical to developing technical solutions that can address the real needs of journalists and integrate into their existing practices. We seek to provide that insight in this paper, by investigating the general and computer security practices of 15 journalists in the U.S. and France via in-depth, semi-structured interviews. Among our findings is evidence that existing security tools fail not only due to usability issues but when they actively interfere with other aspects of the journalistic process; that communication methods are typically driven by sources rather than journalists; and that journalists' organizations play an important role in influencing journalists' behaviors. Based on these and other findings, we make recommendations to the computer security community for improvements to existing tools and future lines of research.",
            "keywords": [
                "Journalism Security Practices",
                "Computer Security Tools",
                "Usability Issues",
                "Journalistic Communication",
                "Influence of Organizations"
            ]
        },
        "url": "URL#4144972",
        "sema_paperId": "daee0d28a45964f8ebf352cbcaa7ad19ce2939fd"
    },
    {
        "@score": "1",
        "@id": "4144973",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "157/0143",
                        "text": "Marcela S. Melara"
                    },
                    {
                        "@pid": "123/8712",
                        "text": "Aaron Blankstein"
                    },
                    {
                        "@pid": "27/3087",
                        "text": "Joseph Bonneau"
                    },
                    {
                        "@pid": "f/EdwardWFelten",
                        "text": "Edward W. Felten"
                    },
                    {
                        "@pid": "65/1370",
                        "text": "Michael J. Freedman"
                    }
                ]
            },
            "title": "CONIKS: Bringing Key Transparency to End Users.",
            "venue": "USENIX Security Symposium",
            "pages": "383-398",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MelaraBBFF15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/melara",
            "url": "https://dblp.org/rec/conf/uss/MelaraBBFF15",
            "abstract": "We present CONIKS, an end-user key verification service capable of integration in end-to-end encrypted communication systems. CONIKS builds on transparency log proposals for web server certificates but solves several new challenges specific to key verification for end users. CONIKS obviates the need for global third-party monitors and enables users to efficiently monitor their own key bindings for consistency, downloading less than 20 kB per day to do so even for a provider with billions of users. CONIKS users and providers can collectively audit providers for non-equivocation, and this requires downloading a constant 2.5 kB per provider per day. Additionally, CONIKS preserves the level of privacy offered by today's major communication services, hiding the list of usernames present and even allowing providers to conceal the total number of users in the system.",
            "keywords": [
                "Key Transparency",
                "End-to-End Encryption",
                "Key Verification",
                "User Privacy",
                "Non-equivocation Auditing"
            ]
        },
        "url": "URL#4144973",
        "sema_paperId": "507067837b06f0bd2504a63e7af6a8b947e93152"
    },
    {
        "@score": "1",
        "@id": "4144974",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "70/10805",
                        "text": "Yan Michalevsky"
                    },
                    {
                        "@pid": "77/3626",
                        "text": "Aaron Schulman"
                    },
                    {
                        "@pid": "167/0703",
                        "text": "Gunaa Arumugam Veerapandian"
                    },
                    {
                        "@pid": "b/DanBoneh",
                        "text": "Dan Boneh"
                    },
                    {
                        "@pid": "42/5782",
                        "text": "Gabi Nakibly"
                    }
                ]
            },
            "title": "PowerSpy: Location Tracking Using Mobile Device Power Analysis.",
            "venue": "USENIX Security Symposium",
            "pages": "785-800",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MichalevskySVBN15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/michalevsky",
            "url": "https://dblp.org/rec/conf/uss/MichalevskySVBN15",
            "abstract": "Modern mobile platforms like Android enable applications to read aggregate power usage on the phone. This information is considered harmless and reading it requires no user permission or notification. We show that by simply reading the phone's aggregate power consumption over a period of a few minutes an application can learn information about the user's location. Aggregate phone power consumption data is extremely noisy due to the multitude of components and applications that simultaneously consume power. Nevertheless, by using machine learning algorithms we are able to successfully infer the phone's location. We discuss several ways in which this privacy leak can be remedied.",
            "keywords": [
                "Mobile Device Privacy",
                "Location Tracking",
                "Power Consumption Analysis",
                "Privacy Leak",
                "Machine Learning Inference"
            ]
        },
        "url": "URL#4144974",
        "sema_paperId": "8d1fd1bfd390a326d66bd44b7ee78f93c1d8dceb"
    },
    {
        "@score": "1",
        "@id": "4144975",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "09/6585-2",
                        "text": "Jiang Ming 0002"
                    },
                    {
                        "@pid": "54/2696",
                        "text": "Dinghao Wu"
                    },
                    {
                        "@pid": "167/0624",
                        "text": "Gaoyao Xiao"
                    },
                    {
                        "@pid": "125/8189-141",
                        "text": "Jun Wang 0141"
                    },
                    {
                        "@pid": "21/6121-5",
                        "text": "Peng Liu 0005"
                    }
                ]
            },
            "title": "TaintPipe: Pipelined Symbolic Taint Analysis.",
            "venue": "USENIX Security Symposium",
            "pages": "65-80",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MingWXW015",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/ming",
            "url": "https://dblp.org/rec/conf/uss/MingWXW015",
            "abstract": "Taint analysis has a wide variety of compelling applications in security tasks, from software attack detection to data lifetime analysis. Static taint analysis propagates taint values following all possible paths with no need for concrete execution, but is generally less accurate than dynamic analysis. Unfortunately, the high performance penalty incurred by dynamic taint analyses makes its deployment impractical in production systems. To ameliorate this performance bottleneck, recent research efforts aim to decouple data flow tracking logic from program execution. We continue this line of research in this paper and propose pipelined symbolic taint analysis, a novel technique for parallelizing and pipelining taint analysis to take advantage of ubiquitous multi-core platforms. We have developed a prototype system called TaintPipe. TaintPipe performs very lightweight runtime logging to produce compact control flow profiles, and spawns multiple threads as different stages of a pipeline to carry out symbolic taint analysis in parallel. Our experiments show that TaintPipe imposes low overhead on application runtime performance and accelerates taint analysis significantly. Compared to a state-of-the-art inlined dynamic data flow tracking tool, TaintPipe achieves 2.38 times speedup for taint analysis on SPEC 2006 and 2.43 times for a set of common utilities, respectively. In addition, we demonstrate the strength of TaintPipe such as natural support of multi-tag taint analysis with several security applications.",
            "keywords": [
                "Taint Analysis",
                "Symbolic Execution",
                "Dynamic Data Flow Tracking",
                "Multi-Core Processing",
                "Pipelined Analysis"
            ]
        },
        "url": "URL#4144975",
        "sema_paperId": "2784864964db743a1d666704b75e5455b880edeb"
    },
    {
        "@score": "1",
        "@id": "4144976",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "123/3234",
                        "text": "Michael Mitchell"
                    },
                    {
                        "@pid": "w/AnIWang",
                        "text": "An-I Andy Wang"
                    },
                    {
                        "@pid": "r/PLReiher",
                        "text": "Peter L. Reiher"
                    }
                ]
            },
            "title": "Cashtags: Protecting the Input and Display of Sensitive Data.",
            "venue": "USENIX Security Symposium",
            "pages": "961-976",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/MitchellWR15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/mitchell",
            "url": "https://dblp.org/rec/conf/uss/MitchellWR15",
            "abstract": "Mobile computing is the new norm. As people feel increasingly comfortable computing in public places such as coffee shops and transportation hubs, the threat of exposing sensitive information increases. While solutions exist to guard the communication channels used by mobile devices, the visual channel remains largely open. Shoulder surfing is becoming a viable threat in a world where users are often surrounded by high-power cameras, and sensitive information can be extracted from images using only modest computing power. \n \nIn response, we present Cashtags: a system to defend against attacks on mobile devices based on visual observations. The system allows users to safely access pieces of sensitive information in public by intercepting and replacing sensitive data elements with nonsensitive data elements before they are displayed on the screen. In addition, the system provides a means of computing with sensitive data in a non-observable way, while maintaining full functionality and legacy compatibility across applications.",
            "keywords": [
                "Mobile Computing Security",
                "Visual Data Protection",
                "Shoulder Surfing",
                "Sensitive Information Display",
                "Data Element Replacement"
            ]
        },
        "url": "URL#4144976",
        "sema_paperId": "e8fcaf997b393015823fb59c1959bed473ede4e9"
    },
    {
        "@score": "1",
        "@id": "4144977",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "167/0416",
                        "text": "Yuhong Nan"
                    },
                    {
                        "@pid": "02/1640-2",
                        "text": "Min Yang 0002"
                    },
                    {
                        "@pid": "55/11040",
                        "text": "Zhemin Yang"
                    },
                    {
                        "@pid": "167/0431",
                        "text": "Shunfan Zhou"
                    },
                    {
                        "@pid": "64/1147",
                        "text": "Guofei Gu"
                    },
                    {
                        "@pid": "06/6268",
                        "text": "Xiaofeng Wang 0006"
                    }
                ]
            },
            "title": "UIPicker: User-Input Privacy Identification in Mobile Applications.",
            "venue": "USENIX Security Symposium",
            "pages": "993-1008",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/NanYYZGW15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/nan",
            "url": "https://dblp.org/rec/conf/uss/NanYYZGW15",
            "abstract": "Identifying sensitive user inputs is a prerequisite for privacy protection. When it comes to today's program analysis systems, however, only those data that go through well-defined system APIs can be automatically labelled. In our research, we show that this conventional approach is far from adequate, as most sensitive inputs are actually entered by the user at an app's runtime: in our research, we inspect 17, 425 top apps from Google Play, and find that 35.46% of them involve sensitive user inputs. Manually marking them involves a lot of effort, impeding a large-scale, automated analysis of apps for potential information leaks. To address this important issue, we present UIPicker, an adaptable framework for automatic identification of sensitive user inputs. UIPicker is designed to detect the semantic information within the application layout resources and program code, and further analyze it for the locations where security-critical information may show up. This approach can support a variety of existing security analysis on mobile apps. We further develop a runtime protection mechanism on top of the technique, which helps the user make informed decisions when her sensitive data is about to leave the device in an unexpected way. We evaluate our approach over 200 randomly selected popular apps on Google-Play. UIPicker is able to accurately label sensitive user inputs most of the time, with 93.6% precision and 90.1% recall.",
            "keywords": [
                "Mobile Application Security",
                "User Input Privacy",
                "Sensitive Data Identification",
                "Automated Analysis",
                "Runtime Protection Mechanism"
            ]
        },
        "url": "URL#4144977",
        "sema_paperId": "ea91780c48701e99e24edadc8e2853fdf4c5c44e"
    },
    {
        "@score": "1",
        "@id": "4144978",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "70/6029",
                        "text": "Terry Nelms"
                    },
                    {
                        "@pid": "60/6768",
                        "text": "Roberto Perdisci"
                    },
                    {
                        "@pid": "26/216",
                        "text": "Manos Antonakakis"
                    },
                    {
                        "@pid": "73/3162",
                        "text": "Mustaque Ahamad"
                    }
                ]
            },
            "title": "WebWitness: Investigating, Categorizing, and Mitigating Malware Download Paths.",
            "venue": "USENIX Security Symposium",
            "pages": "1025-1040",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/NelmsPAA15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/nelms",
            "url": "https://dblp.org/rec/conf/uss/NelmsPAA15",
            "abstract": "Most modern malware download attacks occur via the browser, typically due to social engineering and drive-by downloads. In this paper, we study the \"origin\" of malware download attacks experienced by real network users, with the objective of improving malware download defenses. Specifically, we study the web paths followed by users who eventually fall victim to different types of malware downloads. To this end, we propose a novel incident investigation system, named WebWitness. Our system targets two main goals: 1) automatically trace back and label the sequence of events (e.g., visited web pages) preceding malware downloads, to highlight how users reach attack pages on the web; and 2) leverage these automatically labeled in-the-wild malware download paths to better understand current attack trends, and to develop more effective defenses. \n \nWe deployed WebWitness on a large academic network for a period of ten months, where we collected and categorized thousands of live malicious download paths. An analysis of this labeled data allowed us to design a new defense against drive-by downloads that rely on injecting malicious content into (hacked) legitimate web pages. For example, we show that by leveraging the incident investigation information output by WebWitness we can decrease the infection rate for this type of drive-by downloads by almost six times, on average, compared to existing URL blacklisting approaches.",
            "keywords": [
                "Malware Download Attacks",
                "Web Path Analysis",
                "Incident Investigation",
                "Drive-by Downloads",
                "Malicious Content Injection"
            ]
        },
        "url": "URL#4144978",
        "sema_paperId": "0d14221e3bbb1a58f115a7c7301dc4d4048be13f"
    },
    {
        "@score": "1",
        "@id": "4144979",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "133/2390",
                        "text": "Marten Oltrogge"
                    },
                    {
                        "@pid": "132/9687",
                        "text": "Yasemin Acar"
                    },
                    {
                        "@pid": "146/8228",
                        "text": "Sergej Dechand"
                    },
                    {
                        "@pid": "88/5808-1",
                        "text": "Matthew Smith 0001"
                    },
                    {
                        "@pid": "38/9378",
                        "text": "Sascha Fahl"
                    }
                ]
            },
            "title": "To Pin or Not to Pin-Helping App Developers Bullet Proof Their TLS Connections.",
            "venue": "USENIX Security Symposium",
            "pages": "239-254",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/OltroggeAD0F15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/oltrogge",
            "url": "https://dblp.org/rec/conf/uss/OltroggeAD0F15",
            "abstract": "For increased security during TLS certificate validation, a common recommendation is to use a variation of pinning. Especially non-browser software developers are encouraged to limit the number of trusted certificates to a minimum, since the default CA-based approach is known to be vulnerable to serious security threats. \n \nThe decision for or against pinning is always a tradeoff between increasing security and keeping maintenance efforts at an acceptable level. In this paper, we present an extensive study on the applicability of pinning for non-browser software by analyzing 639,283 Android apps. Conservatively, we propose pinning as an appropriate strategy for 11,547 (1.8%) apps or for 45,247 TLS connections (4.25%) in our sample set. With a more optimistic classification of borderline cases, we propose pinning for consideration for 58,817 (9.1%) apps or for 140,020 (3.8%1) TLS connections. This weakens the assumption that pinning is a widely usable strategy for TLS security in non-browser software. However, in a nominalactual comparison, we find that only 45 apps actually implement pinning. We collected developer feedback from 45 respondents and learned that only a quarter of them grasp the concept of pinning, but still find pinning too complex to use. Based on their feedback, we built an easy-to-use web-application that supports developers in the decision process and guides them through the correct deployment of a pinning-protected TLS implementation.",
            "keywords": [
                "TLS Certificate Pinning",
                "Android App Security",
                "Non-Browser Software",
                "Certificate Validation",
                "Developer Usability"
            ]
        },
        "url": "URL#4144979",
        "sema_paperId": "f0987b07fe295b47b1d9a825daca9dde152450a3"
    },
    {
        "@score": "1",
        "@id": "4144980",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "35/9056",
                        "text": "Giancarlo Pellegrino"
                    },
                    {
                        "@pid": "56/490",
                        "text": "Davide Balzarotti"
                    },
                    {
                        "@pid": "46/1655-1",
                        "text": "Stefan Winter 0001"
                    },
                    {
                        "@pid": "s/NeerajSuri",
                        "text": "Neeraj Suri"
                    }
                ]
            },
            "title": "In the Compression Hornet&apos;s Nest: A Security Study of Data Compression in Network Services.",
            "venue": "USENIX Security Symposium",
            "pages": "801-816",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/PellegrinoBWS15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/pellegrino",
            "url": "https://dblp.org/rec/conf/uss/PellegrinoBWS15",
            "abstract": "In this paper, we investigate the current use of data compression in network services that are at the core of modern web-based applications. While compression reduces network traffic, if not properly implemented it may make an application vulnerable to DoS attacks. Despite the popularity of similar attacks in the past, such as zip bombs or XML bombs, current protocol specifications and design patterns indicate that developers are still mostly unaware of the proper way to handle compressed streams in protocols and web applications. In this paper, we show that denial of services due to improper handling of data compression is a persistent and widespread threat. In our experiments, we review three popular communication protocols and test 19 implementations against highly-compressed protocol messages. Based on the results of our analysis, we list 12 common pitfalls that we observed at the implementation, specification, and configuration levels. Additionally, we discuss a number of previously unknown resource exhaustion vulnerabilities that can be exploited to mount DoS attacks against popular network service implementations.",
            "keywords": [
                "Data Compression",
                "Network Services",
                "Denial of Service (DoS)",
                "Resource Exhaustion Vulnerabilities",
                "Compression Protocols"
            ]
        },
        "url": "URL#4144980",
        "sema_paperId": "e301f4ad844b051688afbde5ec4aa96e0fea8992"
    },
    {
        "@score": "1",
        "@id": "4144981",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "31/1735",
                        "text": "Benny Pinkas"
                    },
                    {
                        "@pid": "06/3872-3",
                        "text": "Thomas Schneider 0003"
                    },
                    {
                        "@pid": "s/GilSegev",
                        "text": "Gil Segev 0001"
                    },
                    {
                        "@pid": "73/11043",
                        "text": "Michael Zohner"
                    }
                ]
            },
            "title": "Phasing: Private Set Intersection Using Permutation-based Hashing.",
            "venue": "USENIX Security Symposium",
            "pages": "515-530",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/Pinkas0SZ15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/pinkas",
            "url": "https://dblp.org/rec/conf/uss/Pinkas0SZ15",
            "abstract": "Private Set Intersection (PSI) allows two parties to compute the intersection of private sets while revealing nothing more than the intersection itself. PSI needs to be applied to large data sets in scenarios such as measurement of ad conversion rates, data sharing, or contact discovery. Existing PSI protocols do not scale up well, and therefore some applications use insecure solutions instead.\nWe describe a new approach for designing PSI protocols based on permutation-based hashing, which enables to reduce the length of items mapped to bins while ensuring that no collisions occur. We denote this approach as Phasing, for Permutation-based Hashing Set Intersection. Phasing can dramatically improve the performance of PSI protocols whose overhead depends on the length of the representations of input items.\nWe apply Phasing to design a new approach for circuit-based PSI protocols. The resulting protocol is up to 5 times faster than the previously best Sort-Compare- Shuffle circuit of Huang et al. (NDSS 2012). We also apply Phasing to the OT-based PSI protocol of Pinkas et al. (USENIX Security 2014), which is the fastest PSI protocol to date. Together with additional improvements that reduce the computation complexity by a logarithmic factor, the resulting protocol improves run-time by a factor of up to 20 and can also have similar communication overhead as the previously best PSI protocol in that respect. The new protocol is only moderately less efficient than an insecure PSI protocol that is currently used by real-world applications, and is therefore the first secure PSI protocol that is scalable to the demands and the constraints of current real-world settings.",
            "pdf_url": "",
            "keywords": [
                "Private Set Intersection",
                "Permutation-based Hashing",
                "Scalable Protocols",
                "Secure Data Sharing",
                "Performance Improvement"
            ]
        },
        "url": "URL#4144981"
    },
    {
        "@score": "1",
        "@id": "4144982",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "32/1943",
                        "text": "David A. Ramos"
                    },
                    {
                        "@pid": "e/DREngler",
                        "text": "Dawson R. Engler"
                    }
                ]
            },
            "title": "Under-Constrained Symbolic Execution: Correctness Checking for Real Code.",
            "venue": "USENIX Security Symposium",
            "pages": "49-64",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RamosE15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/ramos",
            "url": "https://dblp.org/rec/conf/uss/RamosE15",
            "abstract": "Software bugs are a well-known source of security vulnerabilities. One technique for finding bugs, symbolic execution, considers all possible inputs to a program but suffers from scalability limitations. This paper uses a variant, under-constrained symbolic execution, that improves scalability by directly checking individual functions, rather than whole programs. We present UC-KLEE, a novel, scalable framework for checking C/C++ systems code, along with two use cases. First, we use UC-KLEE to check whether patches introduce crashes. We check over 800 patches from BIND and OpenSSL and find 12 bugs, including two OpenSSL denial-of-service vulnerabilities. We also verify (with caveats) that 115 patches do not introduce crashes. Second, we use UC-KLEE as a generalized checking framework and implement checkers to find memory leaks, uninitialized data, and unsafe user input. We evaluate the checkers on over 20,000 functions from BIND, OpenSSL, and the Linux kernel, find 67 bugs, and verify that hundreds of functions are leak free and that thousands of functions do not access uninitialized data.",
            "pdf_url": "",
            "keywords": [
                "Symbolic Execution",
                "Software Verification",
                "Bug Detection",
                "Memory Safety",
                "Under-Constrained Symbolic Execution"
            ]
        },
        "url": "URL#4144982"
    },
    {
        "@score": "1",
        "@id": "4144983",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "63/10367",
                        "text": "Ashay Rane"
                    },
                    {
                        "@pid": "65/1026",
                        "text": "Calvin Lin"
                    },
                    {
                        "@pid": "33/65",
                        "text": "Mohit Tiwari"
                    }
                ]
            },
            "title": "Raccoon: Closing Digital Side-Channels through Obfuscated Execution.",
            "venue": "USENIX Security Symposium",
            "pages": "431-446",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RaneLT15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/rane",
            "url": "https://dblp.org/rec/conf/uss/RaneLT15",
            "abstract": "Side-channel attacks monitor some aspect of a computer system's behavior to infer the values of secret data. Numerous side-channels have been exploited, including those that monitor caches, the branch predictor, and the memory address bus. This paper presents a method of defending against a broad class of side-channel attacks, which we refer to as digital side-channel attacks. The key idea is to obfuscate the program at the source code level to provide the illusion that many extraneous program paths are executed. This paper describes the technical issues involved in using this idea to provide confidentiality while minimizing execution overhead. We argue about the correctness and security of our compiler transformations and demonstrate that our transformations are safe in the context of a modern processor. Our empirical evaluation shows that our solution is 8.9\u00d7 faster than prior work (GhostRider [20]) that specifically defends against memory trace-based side-channel attacks.",
            "keywords": [
                "Digital Side-Channel Attacks",
                "Obfuscated Execution",
                "Program Obfuscation",
                "Compiler Transformations",
                "Memory Trace-Based Attacks"
            ]
        },
        "url": "URL#4144983",
        "sema_paperId": "b965c3128c5002f9fbaad5851acfed5f92774847"
    },
    {
        "@score": "1",
        "@id": "4144984",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "117/3983",
                        "text": "Bradley Reaves"
                    },
                    {
                        "@pid": "164/0043",
                        "text": "Ethan Shernan"
                    },
                    {
                        "@pid": "126/3601",
                        "text": "Adam Bates 0001"
                    },
                    {
                        "@pid": "01/10299",
                        "text": "Henry Carter"
                    },
                    {
                        "@pid": "14/3295",
                        "text": "Patrick Traynor"
                    }
                ]
            },
            "title": "Boxed Out: Blocking Cellular Interconnect Bypass Fraud at the Network Edge.",
            "venue": "USENIX Security Symposium",
            "pages": "833-848",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ReavesSBCT15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/reaves-boxed",
            "url": "https://dblp.org/rec/conf/uss/ReavesSBCT15",
            "abstract": "The high price of incoming international calls is a common method of subsidizing telephony infrastructure in the developing world. Accordingly, international telephone system interconnects are regulated to ensure call quality and accurate billing. High call tariffs create a strong incentive to evade such interconnects and deliver costly international calls illicitly. Specifically, adversaries use VoIP-GSM gateways informally known as \"simboxes\" to receive incoming calls over wired data connections and deliver them into a cellular voice network through a local call that appears to originate from a customer's phone. This practice is not only extremely profitable for simboxers, but also dramatically degrades network experience for legitimate customers, violates telecommunications laws in many countries, and results in significant revenue loss. In this paper, we present a passive detection technique for combating simboxes at a cellular base station. Our system relies on the raw voice data received by the tower during a call to distinguish errors in GSM transmission from the distinct audio artifacts caused by delivering the call over a VoIP link. Our experiments demonstrate that this approach is highly effective, and can detect 87% of real simbox calls in only 30 seconds of audio with no false positives. Moreover, we demonstrate that evading our detection across multiple calls is only possible with a small probability. In so doing, we demonstrate that fraud that degrades network quality and costs telecommunications billions of dollars annually can easily be detected and counteracted in real time.",
            "keywords": [
                "Telecommunications Fraud",
                "Simbox Detection",
                "VoIP-GSM Gateways",
                "Cellular Network Integrity",
                "Interconnect Bypass Fraud"
            ]
        },
        "url": "URL#4144984",
        "sema_paperId": "f316f4311d1e8d3ce79acd13ceb1e5464c1e98ac"
    },
    {
        "@score": "1",
        "@id": "4144985",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "117/3983",
                        "text": "Bradley Reaves"
                    },
                    {
                        "@pid": "167/0436",
                        "text": "Nolen Scaife"
                    },
                    {
                        "@pid": "126/3601",
                        "text": "Adam Bates 0001"
                    },
                    {
                        "@pid": "14/3295",
                        "text": "Patrick Traynor"
                    },
                    {
                        "@pid": "82/1935",
                        "text": "Kevin R. B. Butler"
                    }
                ]
            },
            "title": "Mo(bile) Money, Mo(bile) Problems: Analysis of Branchless Banking Applications in the Developing World.",
            "venue": "USENIX Security Symposium",
            "pages": "17-32",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ReavesSBTB15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/reaves",
            "url": "https://dblp.org/rec/conf/uss/ReavesSBTB15",
            "abstract": "Mobile money, also known as branchless banking, brings much-needed financial services to the unbanked in the developing world. Leveraging ubiquitous cellular networks, these services are now being deployed as smart phone apps, providing an electronic payment infrastructure where alternatives such as credit cards generally do not exist. Although widely marketed as a more secure option to cash, these applications are often not subject to the traditional regulations applied in the financial sector, leaving doubt as to the veracity of such claims. In this paper, we evaluate these claims and perform the first in-depth measurement analysis of branchless banking applications. We first perform an automated analysis of all 46 known Android mobile money apps across the 246 known mobile money providers and demonstrate that automated analysis fails to provide reliable insights. We subsequently perform comprehensive manual teardown of the registration, login, and transaction procedures of a diverse 15% of these apps. We uncover pervasive and systemic vulnerabilities spanning botched certification validation, do-it-yourself cryptography, and myriad other forms of information leakage that allow an attacker to impersonate legitimate users, modify transactions in flight, and steal financial records. These findings confirm that the majority of these apps fail to provide the protections needed by financial services. Finally, through inspection of providers' terms of service, we also discover that liability for these problems unfairly rests on the shoulders of the customer, threatening to erode trust in branchless banking and hinder efforts for global financial inclusion.",
            "keywords": [
                "Branchless Banking",
                "Mobile Money",
                "Financial Inclusion",
                "Security Vulnerabilities",
                "User Liability"
            ]
        },
        "url": "URL#4144985",
        "sema_paperId": "d955bb35a43611bdf3d8b1c76904c77fe5d266df"
    },
    {
        "@score": "1",
        "@id": "4144986",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "30/10661",
                        "text": "Ling Ren 0001"
                    },
                    {
                        "@pid": "25/8166",
                        "text": "Christopher W. Fletcher"
                    },
                    {
                        "@pid": "17/1201",
                        "text": "Albert Kwon"
                    },
                    {
                        "@pid": "61/9827",
                        "text": "Emil Stefanov"
                    },
                    {
                        "@pid": "80/4580",
                        "text": "Elaine Shi"
                    },
                    {
                        "@pid": "32/1399",
                        "text": "Marten van Dijk"
                    },
                    {
                        "@pid": "14/3973",
                        "text": "Srinivas Devadas"
                    }
                ]
            },
            "title": "Constants Count: Practical Improvements to Oblivious RAM.",
            "venue": "USENIX Security Symposium",
            "pages": "415-430",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RenFKSSDD15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/ren-ling",
            "url": "https://dblp.org/rec/conf/uss/RenFKSSDD15",
            "abstract": "Oblivious RAM (ORAM) is a cryptographic primitive that hides memory access patterns as seen by untrusted storage. This paper proposes Ring ORAM, the most bandwidth-efficient ORAM scheme for the small client storage setting in both theory and practice. Ring ORAM is the first tree-based ORAM whose bandwidth is independent of the ORAM bucket size, a property that unlocks multiple performance improvements. First, Ring ORAM's overall bandwidth is 2.3\u00d7 to 4\u00d7 better than Path ORAM, the prior-art scheme for small client storage. Second, if memory can perform simple untrusted computation, Ring ORAM achieves constant online bandwidth (\u223c 60\u00d7 improvement over Path ORAM for practical parameters). As a case study, we show Ring ORAM speeds up program completion time in a secure processor by 1.5\u00d7 relative to Path ORAM. On the theory side, Ring ORAM features a tighter and significantly simpler analysis than Path ORAM.",
            "keywords": [
                "Oblivious RAM",
                "Ring ORAM",
                "Memory Access Patterns",
                "Bandwidth Efficiency",
                "Client Storage"
            ]
        },
        "url": "URL#4144986",
        "sema_paperId": "c8d31bb1f6947d12a45e2f64b068907df2238b0d"
    },
    {
        "@score": "1",
        "@id": "4144987",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "38/11514",
                        "text": "Chuangang Ren"
                    },
                    {
                        "@pid": "32/9374",
                        "text": "Yulong Zhang"
                    },
                    {
                        "@pid": "27/3541-3",
                        "text": "Hui Xue 0003"
                    },
                    {
                        "@pid": "64/5099",
                        "text": "Tao Wei"
                    },
                    {
                        "@pid": "21/6121-5",
                        "text": "Peng Liu 0005"
                    }
                ]
            },
            "title": "Towards Discovering and Understanding Task Hijacking in Android.",
            "venue": "USENIX Security Symposium",
            "pages": "945-959",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RenZXW015",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/ren-chuangang",
            "url": "https://dblp.org/rec/conf/uss/RenZXW015",
            "abstract": "Android multitasking provides rich features to enhance user experience and offers great flexibility for app developers to promote app personalization. However, the security implication of Android multitasking remains under-investigated. With a systematic study of the complex tasks dynamics, we find design flaws of Android multitasking which make all recent versions of Android vulnerable to task hijacking attacks. We demonstrate proof-of-concept examples utilizing the task hijacking attack surface to implement UI spoofing, denial-of-service and user monitoring attacks. Attackers may steal login credentials, implement ransomware and spy on user's activities. We have collected and analyzed over 6.8 million apps from various Android markets. Our analysis shows that the task hijacking risk is prevalent. Since many apps depend on the current multitasking design, defeating task hijacking is not easy. We have notified the Android team about these issues and we discuss possible mitigation techniques in this paper.",
            "keywords": [
                "Android Multitasking",
                "Task Hijacking",
                "UI Spoofing",
                "Denial-of-Service",
                "User Monitoring Attacks"
            ]
        },
        "url": "URL#4144987",
        "sema_paperId": "4301542658dd07a9775ea921282b20acd3ffc446"
    },
    {
        "@score": "1",
        "@id": "4144988",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "24/10823",
                        "text": "Joeri de Ruiter"
                    },
                    {
                        "@pid": "p/ErikPoll",
                        "text": "Erik Poll"
                    }
                ]
            },
            "title": "Protocol State Fuzzing of TLS Implementations.",
            "venue": "USENIX Security Symposium",
            "pages": "193-206",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/RuiterP15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/de-ruiter",
            "url": "https://dblp.org/rec/conf/uss/RuiterP15",
            "abstract": "We describe a largely automated and systematic analysis of TLS implementations by what we call 'protocol state fuzzing': we use state machine learning to infer state machines from protocol implementations, using only blackbox testing, and then inspect the inferred state machines to look for spurious behaviour which might be an indication of flaws in the program logic. For detecting the presence of spurious behaviour the approach is almost fully automatic: we automatically obtain state machines and any spurious behaviour is then trivial to see. Detecting whether the spurious behaviour introduces exploitable security weaknesses does require manual investigation. Still, we take the point of view that any spurious functionality in a security protocol implementation is dangerous and should be removed. \n \nWe analysed both server- and client-side implementations with a test harness that supports several key exchange algorithms and the option of client certificate authentication. We show that this approach can catch an interesting class of implementation flaws that is apparently common in security protocol implementations: in three of the TLS implementations analysed new security flaws were found (in GnuTLS, the Java Secure Socket Extension, and OpenSSL). This shows that protocol state fuzzing is a useful technique to systematically analyse security protocol implementations. As our analysis of different TLS implementations resulted in different and unique state machines for each one, the technique can also be used for fingerprinting TLS implementations.",
            "keywords": [
                "TLS Implementations",
                "Protocol State Fuzzing",
                "State Machine Learning",
                "Security Flaws",
                "Blackbox Testing"
            ]
        },
        "url": "URL#4144988",
        "sema_paperId": "82cd1e7619f076c29dbee77634ebc57e6d0ceefe"
    },
    {
        "@score": "1",
        "@id": "4144989",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "167/0386",
                        "text": "Carl Sabottke"
                    },
                    {
                        "@pid": "167/0439",
                        "text": "Octavian Suciu"
                    },
                    {
                        "@pid": "01/4921",
                        "text": "Tudor Dumitras"
                    }
                ]
            },
            "title": "Vulnerability Disclosure in the Age of Social Media: Exploiting Twitter for Predicting Real-World Exploits.",
            "venue": "USENIX Security Symposium",
            "pages": "1041-1056",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SabottkeSD15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/sabottke",
            "url": "https://dblp.org/rec/conf/uss/SabottkeSD15",
            "abstract": "In recent years, the number of software vulnerabilities discovered has grown significantly. This creates a need for prioritizing the response to new disclosures by assessing which vulnerabilities are likely to be exploited and by quickly ruling out the vulnerabilities that are not actually exploited in the real world. We conduct a quantitative and qualitative exploration of the vulnerability-related information disseminated on Twitter. We then describe the design of a Twitter-based exploit detector, and we introduce a threat model specific to our problem. In addition to response prioritization, our detection techniques have applications in risk modeling for cyber-insurance and they highlight the value of information provided by the victims of attacks.",
            "keywords": [
                "Vulnerability Disclosure",
                "Social Media Analysis",
                "Exploit Prediction",
                "Cyber Risk Modeling",
                "Twitter-based Exploit Detection"
            ]
        },
        "url": "URL#4144989",
        "sema_paperId": "f9f7c51aa688a02d65addd118fd88e0019c78b28"
    },
    {
        "@score": "1",
        "@id": "4144990",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "13/8735",
                        "text": "Eui Chul Richard Shin"
                    },
                    {
                        "@pid": "s/DXSong",
                        "text": "Dawn Song"
                    },
                    {
                        "@pid": "91/8763",
                        "text": "Reza Moazzezi"
                    }
                ]
            },
            "title": "Recognizing Functions in Binaries with Neural Networks.",
            "venue": "USENIX Security Symposium",
            "pages": "611-626",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ShinSM15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/shin",
            "url": "https://dblp.org/rec/conf/uss/ShinSM15",
            "abstract": "Binary analysis facilitates many important applications like malware detection and automatically fixing vulnerable software. In this paper, we propose to apply artificial neural networks to solve important yet difficult problems in binary analysis. Specifically, we tackle the problem of function identification, a crucial first step in many binary analysis techniques. Although neural networks have undergone a renaissance in the past few years, achieving breakthrough results in multiple application domains such as visual object recognition, language modeling, and speech recognition, no researchers have yet attempted to apply these techniques to problems in binary analysis. Using a dataset from prior work, we show that recurrent neural networks can identify functions in binaries with greater accuracy and efficiency than the state-of-the-art machine-learning-based method. We can train the model an order of magnitude faster and evaluate it on binaries hundreds of times faster. Furthermore, it halves the error rate on six out of eight benchmarks, and performs comparably on the remaining two.",
            "keywords": [
                "Binary Analysis",
                "Function Identification",
                "Recurrent Neural Networks",
                "Malware Detection",
                "Error Rate Reduction"
            ]
        },
        "url": "URL#4144990",
        "sema_paperId": "103de5df41ed33f1c0bd1710f582d720cb05e6fd"
    },
    {
        "@score": "1",
        "@id": "4144991",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "137/0885",
                        "text": "Igor Smolyar"
                    },
                    {
                        "@pid": "29/6946",
                        "text": "Muli Ben-Yehuda"
                    },
                    {
                        "@pid": "26/914",
                        "text": "Dan Tsafrir"
                    }
                ]
            },
            "title": "Securing Self-Virtualizing Ethernet Devices.",
            "venue": "USENIX Security Symposium",
            "pages": "335-350",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SmolyarBT15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/smolyar",
            "url": "https://dblp.org/rec/conf/uss/SmolyarBT15",
            "abstract": "Single root I/O virtualization (SRIOV) is a hardware/ software interface that allows devices to \"self virtualize\" and thereby remove the host from the critical I/O path. SRIOV thus brings near bare-metal performance to untrusted guest virtual machines (VMs) in public clouds, enterprise data centers, and high-performance computing setups. We identify a design flaw in current Ethernet SRIOV NIC deployments that enables untrusted VMs to completely control the throughput and latency of other, unrelated VMs. The attack exploits Ethernet \"pause\" frames, which enable network flow control functionality. We experimentally launch the attack across several NIC models and find that it is effective and highly accurate, with substantial consequences if left unmitigated: (1) to be safe, NIC vendors will have to modify their NICs so as to filter pause frames originating from SRIOV instances; (2) in the meantime, administrators will have to either trust their VMs, or configure their switches to ignore pause frames, thus relinquishing flow control, which might severely degrade networking performance. We present the Virtualization-Aware Network Flow Controller (VANFC), a software-based SRIOV NIC prototype that overcomes the attack. VANFC filters pause frames from malicious virtual machines without any loss of performance, while keeping SRIOV and Ethernet flow control hardware/software interfaces intact.",
            "keywords": [
                "SRIOV",
                "Ethernet NIC",
                "Network Flow Control",
                "Pause Frame Attack",
                "Virtualization-Aware Network Flow Controller (VANFC)"
            ]
        },
        "url": "URL#4144991",
        "sema_paperId": "5d0c846fc6974698067c8b96c8eea955a3d678e1"
    },
    {
        "@score": "1",
        "@id": "4144992",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "63/6883",
                        "text": "Yunmok Son"
                    },
                    {
                        "@pid": "140/4350",
                        "text": "Hocheol Shin"
                    },
                    {
                        "@pid": "62/10307-1",
                        "text": "Dongkwan Kim 0001"
                    },
                    {
                        "@pid": "94/8787",
                        "text": "Young-Seok Park"
                    },
                    {
                        "@pid": "167/0564",
                        "text": "Juhwan Noh"
                    },
                    {
                        "@pid": "167/0559",
                        "text": "Kibum Choi"
                    },
                    {
                        "@pid": "167/0367",
                        "text": "Jungwoo Choi"
                    },
                    {
                        "@pid": "20/6892",
                        "text": "Yongdae Kim"
                    }
                ]
            },
            "title": "Rocking Drones with Intentional Sound Noise on Gyroscopic Sensors.",
            "venue": "USENIX Security Symposium",
            "pages": "881-896",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SonSKPNCCK15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/son",
            "url": "https://dblp.org/rec/conf/uss/SonSKPNCCK15",
            "abstract": "Sensing and actuation systems contain sensors to observe the environment and actuators to influence it. However, these sensors can be tricked by maliciously fabricated physical properties. In this paper, we investigated whether an adversary could incapacitate drones equipped with Micro-Electro-Mechanical Systems (MEMS) gyroscopes using intentional sound noise. While MEMS gyroscopes are known to have resonant frequencies that degrade their accuracy, it is not known whether this property can be exploited maliciously to disrupt the operation of drones. \n \nWe first tested 15 kinds of MEMS gyroscopes against sound noise and discovered the resonant frequencies of seven MEMS gyroscopes by scanning the frequencies under 30 kHz using a consumer-grade speaker. The standard deviation of the resonant output from those gyroscopes was dozens of times larger than that of the normal output. After analyzing a target drone's flight control system, we performed real-world experiments and a software simulation to verify the effect of the crafted gyroscope output. Our real-world experiments showed that in all 20 trials, one of two target drones equipped with vulnerable gyroscopes lost control and crashed shortly after we started our attack. A few interesting applications and countermeasures are discussed at the conclusion of this paper.",
            "keywords": [
                "Drone Technology",
                "MEMS Gyroscopes",
                "Sound Noise Interference",
                "Flight Control Disruption",
                "Resonant Frequency Exploitation"
            ]
        },
        "url": "URL#4144992",
        "sema_paperId": "117bcf864b6f496d3627df5794b1d3f815770231"
    },
    {
        "@score": "1",
        "@id": "4144993",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "133/3572",
                        "text": "Kyle Soska"
                    },
                    {
                        "@pid": "c/NicolasChristin",
                        "text": "Nicolas Christin"
                    }
                ]
            },
            "title": "Measuring the Longitudinal Evolution of the Online Anonymous Marketplace Ecosystem.",
            "venue": "USENIX Security Symposium",
            "pages": "33-48",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SoskaC15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/soska",
            "url": "https://dblp.org/rec/conf/uss/SoskaC15",
            "abstract": "February 2011 saw the emergence of Silk Road, the first successful online anonymous marketplace, in which buyers and sellers could transact with anonymity properties far superior to those available in alternative online or offline means of commerce. Business on Silk Road, primarily involving narcotics trafficking, rapidly boomed, and competitors emerged. At the same time, law enforcement did not sit idle, and eventually managed to shut down Silk Road in October 2013 and arrest its operator. Far from causing the demise of this novel form of commerce, the Silk Road take-down spawned an entire, dynamic, online anonymous marketplace ecosystem, which has continued to evolve to this day. This paper presents a long-term measurement analysis of a large portion of this online anonymous marketplace ecosystem, including 16 different marketplaces, over more than two years (2013- 2015). By using long-term measurements, and combining our own data collection with publicly available previous efforts, we offer a detailed understanding of the growth of the online anonymous marketplace ecosystem. We are able to document the evolution of the types of goods being sold, and assess the effect (or lack thereof) of adversarial events, such as law enforcement operations or large-scale frauds, on the overall size of the economy. We also provide insights into how vendors are diversifying and replicating across marketplaces, and how vendor security practices (e.g., PGP adoption) are evolving. These different aspects help us understand how traditional, physical-world criminal activities are developing an online presence, in the same manner traditional commerce diversified online in the 1990s.",
            "keywords": [
                "Online Anonymous Marketplaces",
                "Silk Road",
                "Marketplace Ecosystem",
                "Vendor Security Practices",
                "Adversarial Events Impact"
            ]
        },
        "url": "URL#4144993",
        "sema_paperId": "532b0a835b9340ff8a123b672139fa2070ec539f"
    },
    {
        "@score": "1",
        "@id": "4144994",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "86/8823",
                        "text": "Gianluca Stringhini"
                    },
                    {
                        "@pid": "167/0404",
                        "text": "Pierre Mourlanne"
                    },
                    {
                        "@pid": "71/2622",
                        "text": "Gr\u00e9goire Jacob"
                    },
                    {
                        "@pid": "27/3108",
                        "text": "Manuel Egele"
                    },
                    {
                        "@pid": "k/ChristopherKruegel",
                        "text": "Christopher Kruegel"
                    },
                    {
                        "@pid": "v/GiovanniVigna",
                        "text": "Giovanni Vigna"
                    }
                ]
            },
            "title": "EVILCOHORT: Detecting Communities of Malicious Accounts on Online Services.",
            "venue": "USENIX Security Symposium",
            "pages": "563-578",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/StringhiniMJEKV15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/stringhini",
            "url": "https://dblp.org/rec/conf/uss/StringhiniMJEKV15",
            "abstract": "Cybercriminals misuse accounts on online services (e.g., webmails and online social networks) to perform malicious activity, such as spreading malicious content or stealing sensitive information. In this paper, we show that accounts that are accessed by botnets are a popular choice by cybercriminals. Since botnets are composed of a finite number of infected computers, we observe that cybercriminals tend to have their bots connect to multiple online accounts to perform malicious activity. \n \nWe present EVILCOHORT, a system that detects online accounts that are accessed by a common set of infected machines. EVILCOHORT only needs the mapping between an online account and an IP address to operate, and can therefore detect malicious accounts on any online service (webmail services, online social networks, storage services) regardless of the type of malicious activity that these accounts perform. Unlike previous work, our system can identify malicious accounts that are controlled by botnets but do not post any malicious content (e.g., spam) on the service. We evaluated EVILCOHORT on multiple online services of different types (a webmail service and four online social networks), and show that it accurately identifies malicious accounts.",
            "keywords": [
                "Malicious Account Detection",
                "Botnet Activity",
                "Cybercrime",
                "Online Services Security",
                "Community Detection"
            ]
        },
        "url": "URL#4144994",
        "sema_paperId": "63cffad7e19ef701afd1319eaca042500a0b1b29"
    },
    {
        "@score": "1",
        "@id": "4144995",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "139/9789",
                        "text": "Yixin Sun"
                    },
                    {
                        "@pid": "126/2313",
                        "text": "Anne Edmundson"
                    },
                    {
                        "@pid": "51/7546",
                        "text": "Laurent Vanbever"
                    },
                    {
                        "@pid": "160/8481",
                        "text": "Oscar Li"
                    },
                    {
                        "@pid": "r/JenniferRexford",
                        "text": "Jennifer Rexford"
                    },
                    {
                        "@pid": "61/5309",
                        "text": "Mung Chiang"
                    },
                    {
                        "@pid": "39/6266",
                        "text": "Prateek Mittal"
                    }
                ]
            },
            "title": "RAPTOR: Routing Attacks on Privacy in Tor.",
            "venue": "USENIX Security Symposium",
            "pages": "271-286",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/SunEVLRCM15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/sun",
            "url": "https://dblp.org/rec/conf/uss/SunEVLRCM15",
            "abstract": "The Tor network is a widely used system for anonymous communication. However, Tor is known to be vulnerable to attackers who can observe traffic at both ends of the communication path. In this paper, we show that prior attacks are just the tip of the iceberg. We present a suite of new attacks, called Raptor, that can be launched by Autonomous Systems (ASes) to compromise user anonymity. First, AS-level adversaries can exploit the asymmetric nature of Internet routing to increase the chance of observing at least one direction of user traffic at both ends of the communication. Second, AS-level adversaries can exploit natural churn in Internet routing to lie on the BGP paths for more users over time. Third, strategic adversaries can manipulate Internet routing via BGP hijacks (to discover the users using specific Tor guard nodes) and interceptions (to perform traffic analysis). We demonstrate the feasibility of Raptor attacks by analyzing historical BGP data and Traceroute data as well as performing real-world attacks on the live Tor network, while ensuring that we do not harm real users. In addition, we outline the design of two monitoring frameworks to counter these attacks: BGP monitoring to detect control-plane attacks, and Traceroute monitoring to detect data-plane anomalies. Overall, our work motivates the design of anonymity systems that are aware of the dynamics of Internet routing.",
            "keywords": [
                "Tor Network",
                "Anonymity",
                "Routing Attacks",
                "BGP Hijacks",
                "Traffic Analysis"
            ]
        },
        "url": "URL#4144995",
        "sema_paperId": "2c7de89466fc1cbaf51b4e4d64b3c95938fef7f0"
    },
    {
        "@score": "1",
        "@id": "4144996",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "66/9786",
                        "text": "Blase Ur"
                    },
                    {
                        "@pid": "71/9965",
                        "text": "Sean M. Segreti"
                    },
                    {
                        "@pid": "32/3440",
                        "text": "Lujo Bauer"
                    },
                    {
                        "@pid": "c/NicolasChristin",
                        "text": "Nicolas Christin"
                    },
                    {
                        "@pid": "03/1595",
                        "text": "Lorrie Faith Cranor"
                    },
                    {
                        "@pid": "05/6177",
                        "text": "Saranga Komanduri"
                    },
                    {
                        "@pid": "136/1017",
                        "text": "Darya Kurilova"
                    },
                    {
                        "@pid": "20/7983",
                        "text": "Michelle L. Mazurek"
                    },
                    {
                        "@pid": "138/1005",
                        "text": "William Melicher"
                    },
                    {
                        "@pid": "18/1031",
                        "text": "Richard Shay"
                    }
                ]
            },
            "title": "Measuring Real-World Accuracies and Biases in Modeling Password Guessability.",
            "venue": "USENIX Security Symposium",
            "pages": "463-481",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/UrSBCCKKMMS15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/ur",
            "url": "https://dblp.org/rec/conf/uss/UrSBCCKKMMS15",
            "abstract": "Parameterized password guessability--how many guesses a particular cracking algorithm with particular training data would take to guess a password--has become a common metric of password security. Unlike statistical metrics, it aims to model real-world attackers and to provide per-password strength estimates. We investigate how cracking approaches often used by researchers compare to real-world cracking by professionals, as well as how the choice of approach biases research conclusions. \n \nWe find that semi-automated cracking by professionals outperforms popular fully automated approaches, but can be approximated by combining multiple such approaches. These approaches are only effective, however, with careful configuration and tuning; in commonly used default configurations, they underestimate the real-world guessability of passwords. We find that analyses of large password sets are often robust to the algorithm used for guessing as long as it is configured effectively. However, cracking algorithms differ systematically in their effectiveness guessing passwords with certain common features (e.g., character substitutions). This has important implications for analyzing the security of specific password characteristics or of individual passwords (e.g., in a password meter or security audit). Our results highlight the danger of relying only on a single cracking algorithm as a measure of password strength and constitute the first scientific evidence that automated guessing can often approximate guessing by professionals.",
            "keywords": [
                "Password Guessability",
                "Cracking Algorithms",
                "Password Security",
                "Automated Cracking",
                "Bias in Password Strength Analysis"
            ]
        },
        "url": "URL#4144996",
        "sema_paperId": "ed60d62e282e8f3482056157ab02a36518fd7601"
    },
    {
        "@score": "1",
        "@id": "4144997",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "130/3608",
                        "text": "Mathy Vanhoef"
                    },
                    {
                        "@pid": "85/6647",
                        "text": "Frank Piessens"
                    }
                ]
            },
            "title": "All Your Biases Belong to Us: Breaking RC4 in WPA-TKIP and TLS.",
            "venue": "USENIX Security Symposium",
            "pages": "97-112",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/VanhoefP15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/vanhoef",
            "url": "https://dblp.org/rec/conf/uss/VanhoefP15",
            "abstract": "We present new biases in RC4, break the Wi-Fi Protected Access Temporal Key Integrity Protocol (WPA-TKIP), and design a practical plaintext recovery attack against the Transport Layer Security (TLS) protocol. To empirically find new biases in the RC4 keystream we use statistical hypothesis tests. This reveals many new biases in the initial keystream bytes, as well as several new longterm biases. Our fixed-plaintext recovery algorithms are capable of using multiple types of biases, and return a list of plaintext candidates in decreasing likelihood. To break WPA-TKIP we introduce a method to generate a large number of identical packets. This packet is decrypted by generating its plaintext candidate list, and using redundant packet structure to prune bad candidates. From the decrypted packet we derive the TKIP MIC key, which can be used to inject and decrypt packets. In practice the attack can be executed within an hour. We also attack TLS as used by HTTPS, where we show how to decrypt a secure cookie with a success rate of 94% using 9\u2022227 ciphertexts. This is done by injecting known data around the cookie, abusing this using Mantin\u2019s ABSAB bias, and brute-forcing the cookie by traversing the plaintext candidates. Using our traffic generation technique, we are able to execute the attack in merely 75 hours.",
            "pdf_url": "",
            "keywords": [
                "RC4 Biases",
                "WPA-TKIP",
                "TLS Vulnerabilities",
                "Plaintext Recovery Attack",
                "Traffic Generation Technique"
            ]
        },
        "url": "URL#4144997"
    },
    {
        "@score": "1",
        "@id": "4144998",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "17/8064",
                        "text": "Venkatanathan Varadarajan"
                    },
                    {
                        "@pid": "77/3503",
                        "text": "Yinqian Zhang"
                    },
                    {
                        "@pid": "26/3399",
                        "text": "Thomas Ristenpart"
                    },
                    {
                        "@pid": "s/MichaelMSwift",
                        "text": "Michael M. Swift"
                    }
                ]
            },
            "title": "A Placement Vulnerability Study in Multi-Tenant Public Clouds.",
            "venue": "USENIX Security Symposium",
            "pages": "913-928",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/VaradarajanZRS15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/varadarajan",
            "url": "https://dblp.org/rec/conf/uss/VaradarajanZRS15",
            "abstract": "Public infrastructure-as-a-service clouds, such as Amazon EC2, Google Compute Engine (GCE) and Microsoft Azure allow clients to run virtual machines (VMs) on shared physical infrastructure. This practice of multi-tenancy brings economies of scale, but also introduces the risk of sharing a physical server with an arbitrary and potentially malicious VM. Past works have demonstrated how to place a VM alongside a target victim (co-location) in early-generation clouds and how to extract secret information via side-channels. Although there have been numerous works on side-channel attacks, there have been no studies on placement vulnerabilities in public clouds since the adoption of stronger isolation technologies such as Virtual Private Clouds (VPCs).\nWe investigate this problem of placement vulnerabilities and quantitatively evaluate three popular public clouds for their susceptibility to co-location attacks. We find that adoption of new technologies (e.g., VPC) makes many prior attacks, such as cloud cartography, ineffective. We find new ways to reliably test for co-location across Amazon EC2, Google GCE, and Microsoft Azure. We also found ways to detect co-location with victim web servers in multi-tiered located behind a load balancer.\u00a0\nWe use our new co-residence tests and multiple customer accounts to launch VM instances under different strategies that seek to maximize the likelihood of co-residency. We find that it is much easier (10x higher success rate) and cheaper (up to $114 less) to achieve co-location in these three clouds when compared to a secure reference placement policy. \nKeywords: co-location detection, multi-tenancy, cloud security",
            "pdf_url": "",
            "keywords": [
                "Cloud Security",
                "Multi-Tenancy",
                "Co-Location Attacks",
                "Placement Vulnerabilities",
                "Virtual Private Clouds (VPC)"
            ]
        },
        "url": "URL#4144998"
    },
    {
        "@score": "1",
        "@id": "4144999",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "19/8917",
                        "text": "Ruowen Wang"
                    },
                    {
                        "@pid": "22/4463",
                        "text": "William Enck"
                    },
                    {
                        "@pid": "r/DouglasSReeves",
                        "text": "Douglas S. Reeves"
                    },
                    {
                        "@pid": "14/3612",
                        "text": "Xinwen Zhang"
                    },
                    {
                        "@pid": "76/1374",
                        "text": "Peng Ning"
                    },
                    {
                        "@pid": "50/4787",
                        "text": "Dingbang Xu"
                    },
                    {
                        "@pid": "14/7096-1",
                        "text": "Wu Zhou 0001"
                    },
                    {
                        "@pid": "09/2166",
                        "text": "Ahmed M. Azab"
                    }
                ]
            },
            "title": "EASEAndroid: Automatic Policy Analysis and Refinement for Security Enhanced Android via Large-Scale Semi-Supervised Learning.",
            "venue": "USENIX Security Symposium",
            "pages": "351-366",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WangERZNXZA15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/wang-ruowen",
            "url": "https://dblp.org/rec/conf/uss/WangERZNXZA15",
            "abstract": "Mandatory protection systems such as SELinux and SEAndroid harden operating system integrity. Unfortunately, policy development is error prone and requires lengthy refinement using audit logs from deployed systems. While prior work has studied SELinux policy in detail, SEAndroid is relatively new and has received little attention. SEAndroid policy engineering differs significantly from SELinux: Android fundamentally differs from traditional Linux; the same policy is used on millions of devices for which new audit logs are continually available; and audit logs contain a mix of benign and malicious accesses. In this paper, we propose EASEAndroid, the first SEAndroid analytic platform for automatic policy analysis and refinement. Our key insight is that the policy refinement process can be modeled and automated using semi-supervised learning. Given an existing policy and a small set of known access patterns, EASEAndroid continually expands the knowledge base as new audit logs become available, producing suggestions for policy refinement. We evaluate EASEAndroid on 1.3 million audit logs from real-world devices. EASEAndroid successfully learns 2,518 new access patterns and generates 331 new policy rules. During this process, EASEAndroid discovers eight categories of attack access patterns in real devices, two of which are new attacks directly against the SEAndroid MAC mechanism.",
            "keywords": [
                "SEAndroid",
                "Policy Refinement",
                "Mandatory Access Control",
                "Audit Log Analysis",
                "Attack Access Patterns"
            ]
        },
        "url": "URL#4144999",
        "sema_paperId": "93f6bea2b97a4cb99cee0e75149032a10a324645"
    },
    {
        "@score": "1",
        "@id": "4145000",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "42/1503-11",
                        "text": "Shuai Wang 0011"
                    },
                    {
                        "@pid": "83/4555-7",
                        "text": "Pei Wang 0007"
                    },
                    {
                        "@pid": "54/2696",
                        "text": "Dinghao Wu"
                    }
                ]
            },
            "title": "Reassembleable Disassembling.",
            "venue": "USENIX Security Symposium",
            "pages": "627-642",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WangWW15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/wang-shuai",
            "url": "https://dblp.org/rec/conf/uss/WangWW15",
            "abstract": "Reverse engineering has many important applications in computer security, one of which is retrofitting software for safety and security hardening when source code is not available. By surveying available commercial and academic reverse engineering tools, we surprisingly found that no existing tool is able to disassemble executable binaries into assembly code that can be correctly assembled back in a fully automated manner, even for simple programs. Actually in many cases, the resulted disassembled code is far from a state that an assembler accepts, which is hard to fix even by manual effort. This has become a severe obstacle. People have tried to overcome it by patching or duplicating new code sections for retrofitting of executables, which is not only inefficient but also cumbersome and restrictive on what retrofitting techniques can be applied to. \n \nIn this paper, we present UROBOROS, a tool that can disassemble executables to the extent that the generated code can be assembled back to working binaries without manual effort. By empirically studying 244 binaries, we summarize a set of rules that can make the disassembled code relocatable, which is the key to reassembleable disassembling. With UROBOROS, the disassembly-reassembly process can be repeated thousands of times. We have implemented a prototype of UROBOROS and tested over the whole set of GNU Coreutils, SPEC2006, and a set of other real-world application and server programs. The experiment results show that our tool is effective with a very modest cost.",
            "keywords": [
                "Reverse Engineering",
                "Disassembly",
                "Executable Binaries",
                "Reassembly",
                "UROBOROS"
            ]
        },
        "url": "URL#4145000",
        "sema_paperId": "6f45152ce34b4326fc0adfb7d7b6587b13d0a62c"
    },
    {
        "@score": "1",
        "@id": "4145001",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "150/8120",
                        "text": "Michael Weissbacher"
                    },
                    {
                        "@pid": "r/WilliamKRobertson",
                        "text": "William K. Robertson"
                    },
                    {
                        "@pid": "k/EnginKirda",
                        "text": "Engin Kirda"
                    },
                    {
                        "@pid": "k/ChristopherKruegel",
                        "text": "Christopher Kruegel"
                    },
                    {
                        "@pid": "v/GiovanniVigna",
                        "text": "Giovanni Vigna"
                    }
                ]
            },
            "title": "ZigZag: Automatically Hardening Web Applications Against Client-side Validation Vulnerabilities.",
            "venue": "USENIX Security Symposium",
            "pages": "737-752",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WeissbacherRKKV15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/weissbacher",
            "url": "https://dblp.org/rec/conf/uss/WeissbacherRKKV15",
            "abstract": "Modern web applications are increasingly moving program code to the client in the form of JavaScript. With the growing adoption of HTML5 APIs such as postMessage, client-side validation (CSV) vulnerabilities are consequently becoming increasingly important to address as well. However, while detecting and preventing attacks against web applications is a well-studied topic on the server, considerably less work has been performed for the client. Exacerbating this issue is the problem that defenses against CSVs must, in the general case, fundamentally exist in the browser, rendering current server-side defenses inadequate. \n \nIn this paper, we present ZigZag, a system for hardening JavaScript-based web applications against clientside validation attacks. ZigZag transparently instruments client-side code to perform dynamic invariant detection on security-sensitive code, generating models that describe how - and with whom - client-side components interact. ZigZag is capable of handling templated JavaScript, avoiding full re-instrumentation when JavaScript programs are structurally similar. Learned invariants are then enforced through a subsequent instrumentation step. Our evaluation demonstrates that ZigZag is capable of automatically hardening client-side code against both known and previously-unknown vulnerabilities. Finally, we show that ZigZag introduces acceptable overhead in many cases, and is compatible with popular websites drawn from the Alexa Top 20 without developer or user intervention.",
            "keywords": [
                "Client-side Validation",
                "Web Application Hardening",
                "JavaScript Security",
                "Dynamic Invariant Detection",
                "CSV Vulnerabilities"
            ]
        },
        "url": "URL#4145001",
        "sema_paperId": "1b6f5fa6f032a4cf9430dfe114bb2aedfaf1183e"
    },
    {
        "@score": "1",
        "@id": "4145002",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "162/0214",
                        "text": "Primal Wijesekera"
                    },
                    {
                        "@pid": "161/9928",
                        "text": "Arjun Baokar"
                    },
                    {
                        "@pid": "161/9776",
                        "text": "Ashkan Hosseini"
                    },
                    {
                        "@pid": "07/1108",
                        "text": "Serge Egelman"
                    },
                    {
                        "@pid": "42/5626",
                        "text": "David A. Wagner 0001"
                    },
                    {
                        "@pid": "47/6517",
                        "text": "Konstantin Beznosov"
                    }
                ]
            },
            "title": "Android Permissions Remystified: A Field Study on Contextual Integrity.",
            "venue": "USENIX Security Symposium",
            "pages": "499-514",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/WijesekeraBHEWB15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/wijesekera",
            "url": "https://dblp.org/rec/conf/uss/WijesekeraBHEWB15",
            "abstract": "We instrumented the Android platform to collect data regarding how often and under what circumstances smartphone applications access protected resources regulated by permissions. We performed a 36-person field study to explore the notion of \"contextual integrity,\" i.e., how often applications access protected resources when users are not expecting it. Based on our collection of 27M data points and exit interviews with participants, we examine the situations in which users would like the ability to deny applications access to protected resources. At least 80% of our participants would have preferred to prevent at least one permission request, and overall, they stated a desire to block over a third of all requests. Our findings pave the way for future systems to automatically determine the situations in which users would want to be confronted with security decisions.",
            "keywords": [
                "Android Permissions",
                "Contextual Integrity",
                "User Privacy",
                "Permission Requests",
                "Access Control Decisions"
            ]
        },
        "url": "URL#4145002",
        "sema_paperId": "3ce1072ac56cf77ed5c0f086b8ae629b574f0f41"
    },
    {
        "@score": "1",
        "@id": "4145003",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "61/7820",
                        "text": "Zhang Xu"
                    },
                    {
                        "@pid": "81/4036-1",
                        "text": "Haining Wang 0001"
                    },
                    {
                        "@pid": "87/6581-3",
                        "text": "Zhenyu Wu 0003"
                    }
                ]
            },
            "title": "A Measurement Study on Co-residence Threat inside the Cloud.",
            "venue": "USENIX Security Symposium",
            "pages": "929-944",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/XuWW15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/xu",
            "url": "https://dblp.org/rec/conf/uss/XuWW15",
            "abstract": "As the most basic cloud service model, Infrastructure as a Service (IaaS) has been widely used for serving the ever-growing computing demand due to the prevalence of the cloud. Using pools of hypervisors within the cloud, IaaS can support a large number of Virtual Machines (VMs) and scale services in a highly dynamic manner. However, it is well-known that the VMs in IaaS are vulnerable to co-residence threat, which can be easily exploited to launch different malicious attacks. In this measurement study, we investigate how IaaS evolves in VM placement, network management, and Virtual Private Cloud (VPC), as well as the impact upon co-residence. Specifically, through intensive measurement probing, we first profile the dynamic environment of cloud instances inside the cloud. Then using real experiments, we quantify the impacts of VM placement and network management upon co-residence. Moreover, we explore VPC, which is a defensive network-based service of Amazon EC2 for security enhancement, from the routing perspective. On one hand, our measurement shows that VPC is widely used and can indeed suppress co-residence threat. On the other hand, we demonstrate a new approach to achieving co-residence in VPC, indicating that co-residence threat still exists in the cloud.",
            "keywords": [
                "Infrastructure as a Service (IaaS)",
                "Co-residence Threat",
                "Virtual Machines (VMs)",
                "Virtual Private Cloud (VPC)",
                "Network Management"
            ]
        },
        "url": "URL#4145003",
        "sema_paperId": "2070cba05bc88f9f42661bd737fc251c5f0c6120"
    },
    {
        "@score": "1",
        "@id": "4145004",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "11/11005",
                        "text": "Xiaofeng Zheng"
                    },
                    {
                        "@pid": "00/2797-2",
                        "text": "Jian Jiang 0002"
                    },
                    {
                        "@pid": "56/8779",
                        "text": "Jinjin Liang"
                    },
                    {
                        "@pid": "36/5143",
                        "text": "Hai-Xin Duan"
                    },
                    {
                        "@pid": "00/6472-1",
                        "text": "Shuo Chen 0001"
                    },
                    {
                        "@pid": "62/2525-4",
                        "text": "Tao Wan 0004"
                    },
                    {
                        "@pid": "53/2937",
                        "text": "Nicholas Weaver"
                    }
                ]
            },
            "title": "Cookies Lack Integrity: Real-World Implications.",
            "venue": "USENIX Security Symposium",
            "pages": "707-721",
            "year": "2015",
            "type": "Conference and Workshop Papers",
            "access": "open",
            "key": "conf/uss/ZhengJLDCWW15",
            "ee": "https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/zheng",
            "url": "https://dblp.org/rec/conf/uss/ZhengJLDCWW15",
            "abstract": "A cookie can contain a \"secure\" flag, indicating that it should be only sent over an HTTPS connection. Yet there is no corresponding flag to indicate how a cookie was set: attackers who act as a man-in-the-midddle even temporarily on an HTTP session can inject cookies which will be attached to subsequent HTTPS connections. Similar attacks can also be launched by a web attacker from a related domain. Although an acknowledged threat, it has not yet been studied thoroughly. This paper aims to fill this gap with an in-depth empirical assessment of cookie injection attacks. We find that cookie-related vulnerabilities are present in important sites (such as Google and Bank of America), and can be made worse by the implementation weaknesses we discovered in major web browsers (such as Chrome, Firefox, and Safari). Our successful attacks have included privacy violation, online victimization, and even financial loss and account hijacking. We also discuss mitigation strategies such as HSTS, possible browser changes, and present a proof-of-concept browser extension to provide better cookie isolation between HTTP and HTTPS, and between related domains.",
            "keywords": [
                "Cookie Security",
                "Cookie Injection Attacks",
                "HTTPS Vulnerabilities",
                "Privacy Violations",
                "Cross-Domain Attacks"
            ]
        },
        "url": "URL#4145004",
        "sema_paperId": "5b556bcbd18db3d944096c13d4274aa01b4dc41c"
    },
    {
        "@score": "1",
        "@id": "4158646",
        "info": {
            "authors": {
                "author": [
                    {
                        "@pid": "j/JaeyeonJung",
                        "text": "Jaeyeon Jung"
                    },
                    {
                        "@pid": "h/ThorstenHolz",
                        "text": "Thorsten Holz"
                    }
                ]
            },
            "title": "24th USENIX Security Symposium, USENIX Security 15, Washington, D.C., USA, August 12-14, 2015.",
            "venue": "USENIX Security Symposium",
            "publisher": "USENIX Association",
            "year": "2015",
            "type": "Editorship",
            "access": "open",
            "key": "conf/uss/2015",
            "ee": "https://www.usenix.org/conference/usenixsecurity15",
            "url": "https://dblp.org/rec/conf/uss/2015",
            "abstract": null
        },
        "url": "URL#4158646",
        "sema_paperId": "5744c03f933c6bfa034529facd9a236d23f94936"
    }
]